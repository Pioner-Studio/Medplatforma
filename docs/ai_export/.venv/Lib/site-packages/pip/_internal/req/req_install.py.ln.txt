    1: from __future__ import annotations
    2: 
    3: import functools
    4: import logging
    5: import os
    6: import shutil
    7: import sys
    8: import uuid
    9: import zipfile
   10: from collections.abc import Collection, Iterable, Sequence
   11: from optparse import Values
   12: from pathlib import Path
   13: from typing import Any
   14: 
   15: from pip._vendor.packaging.markers import Marker
   16: from pip._vendor.packaging.requirements import Requirement
   17: from pip._vendor.packaging.specifiers import SpecifierSet
   18: from pip._vendor.packaging.utils import canonicalize_name
   19: from pip._vendor.packaging.version import Version
   20: from pip._vendor.packaging.version import parse as parse_version
   21: from pip._vendor.pyproject_hooks import BuildBackendHookCaller
   22: 
   23: from pip._internal.build_env import BuildEnvironment, NoOpBuildEnvironment
   24: from pip._internal.exceptions import InstallationError, PreviousBuildDirError
   25: from pip._internal.locations import get_scheme
   26: from pip._internal.metadata import (
   27:     BaseDistribution,
   28:     get_default_environment,
   29:     get_directory_distribution,
   30:     get_wheel_distribution,
   31: )
   32: from pip._internal.metadata.base import FilesystemWheel
   33: from pip._internal.models.direct_url import DirectUrl
   34: from pip._internal.models.link import Link
   35: from pip._internal.operations.build.metadata import generate_metadata
   36: from pip._internal.operations.build.metadata_editable import generate_editable_metadata
   37: from pip._internal.operations.build.metadata_legacy import (
   38:     generate_metadata as generate_metadata_legacy,
   39: )
   40: from pip._internal.operations.install.editable_legacy import (
   41:     install_editable as install_editable_legacy,
   42: )
   43: from pip._internal.operations.install.wheel import install_wheel
   44: from pip._internal.pyproject import load_pyproject_toml, make_pyproject_path
   45: from pip._internal.req.req_uninstall import UninstallPathSet
   46: from pip._internal.utils.deprecation import deprecated
   47: from pip._internal.utils.hashes import Hashes
   48: from pip._internal.utils.misc import (
   49:     ConfiguredBuildBackendHookCaller,
   50:     ask_path_exists,
   51:     backup_dir,
   52:     display_path,
   53:     hide_url,
   54:     is_installable_dir,
   55:     redact_auth_from_requirement,
   56:     redact_auth_from_url,
   57: )
   58: from pip._internal.utils.packaging import get_requirement
   59: from pip._internal.utils.subprocess import runner_with_spinner_message
   60: from pip._internal.utils.temp_dir import TempDirectory, tempdir_kinds
   61: from pip._internal.utils.unpacking import unpack_file
   62: from pip._internal.utils.virtualenv import running_under_virtualenv
   63: from pip._internal.vcs import vcs
   64: 
   65: logger = logging.getLogger(__name__)
   66: 
   67: 
   68: class InstallRequirement:
   69:     """
   70:     Represents something that may be installed later on, may have information
   71:     about where to fetch the relevant requirement and also contains logic for
   72:     installing the said requirement.
   73:     """
   74: 
   75:     def __init__(
   76:         self,
   77:         req: Requirement | None,
   78:         comes_from: str | InstallRequirement | None,
   79:         editable: bool = False,
   80:         link: Link | None = None,
   81:         markers: Marker | None = None,
   82:         use_pep517: bool | None = None,
   83:         isolated: bool = False,
   84:         *,
   85:         global_options: list[str] | None = None,
   86:         hash_options: dict[str, list[str]] | None = None,
   87:         config_settings: dict[str, str | list[str]] | None = None,
   88:         constraint: bool = False,
   89:         extras: Collection[str] = (),
   90:         user_supplied: bool = False,
   91:         permit_editable_wheels: bool = False,
   92:     ) -> None:
   93:         assert req is None or isinstance(req, Requirement), req
   94:         self.req = req
   95:         self.comes_from = comes_from
   96:         self.constraint = constraint
   97:         self.editable = editable
   98:         self.permit_editable_wheels = permit_editable_wheels
   99: 
  100:         # source_dir is the local directory where the linked requirement is
  101:         # located, or unpacked. In case unpacking is needed, creating and
  102:         # populating source_dir is done by the RequirementPreparer. Note this
  103:         # is not necessarily the directory where pyproject.toml or setup.py is
  104:         # located - that one is obtained via unpacked_source_directory.
  105:         self.source_dir: str | None = None
  106:         if self.editable:
  107:             assert link
  108:             if link.is_file:
  109:                 self.source_dir = os.path.normpath(os.path.abspath(link.file_path))
  110: 
  111:         # original_link is the direct URL that was provided by the user for the
  112:         # requirement, either directly or via a constraints file.
  113:         if link is None and req and req.url:
  114:             # PEP 508 URL requirement
  115:             link = Link(req.url)
  116:         self.link = self.original_link = link
  117: 
  118:         # When this InstallRequirement is a wheel obtained from the cache of locally
  119:         # built wheels, this is the source link corresponding to the cache entry, which
  120:         # was used to download and build the cached wheel.
  121:         self.cached_wheel_source_link: Link | None = None
  122: 
  123:         # Information about the location of the artifact that was downloaded . This
  124:         # property is guaranteed to be set in resolver results.
  125:         self.download_info: DirectUrl | None = None
  126: 
  127:         # Path to any downloaded or already-existing package.
  128:         self.local_file_path: str | None = None
  129:         if self.link and self.link.is_file:
  130:             self.local_file_path = self.link.file_path
  131: 
  132:         if extras:
  133:             self.extras = extras
  134:         elif req:
  135:             self.extras = req.extras
  136:         else:
  137:             self.extras = set()
  138:         if markers is None and req:
  139:             markers = req.marker
  140:         self.markers = markers
  141: 
  142:         # This holds the Distribution object if this requirement is already installed.
  143:         self.satisfied_by: BaseDistribution | None = None
  144:         # Whether the installation process should try to uninstall an existing
  145:         # distribution before installing this requirement.
  146:         self.should_reinstall = False
  147:         # Temporary build location
  148:         self._temp_build_dir: TempDirectory | None = None
  149:         # Set to True after successful installation
  150:         self.install_succeeded: bool | None = None
  151:         # Supplied options
  152:         self.global_options = global_options if global_options else []
  153:         self.hash_options = hash_options if hash_options else {}
  154:         self.config_settings = config_settings
  155:         # Set to True after successful preparation of this requirement
  156:         self.prepared = False
  157:         # User supplied requirement are explicitly requested for installation
  158:         # by the user via CLI arguments or requirements files, as opposed to,
  159:         # e.g. dependencies, extras or constraints.
  160:         self.user_supplied = user_supplied
  161: 
  162:         self.isolated = isolated
  163:         self.build_env: BuildEnvironment = NoOpBuildEnvironment()
  164: 
  165:         # For PEP 517, the directory where we request the project metadata
  166:         # gets stored. We need this to pass to build_wheel, so the backend
  167:         # can ensure that the wheel matches the metadata (see the PEP for
  168:         # details).
  169:         self.metadata_directory: str | None = None
  170: 
  171:         # The static build requirements (from pyproject.toml)
  172:         self.pyproject_requires: list[str] | None = None
  173: 
  174:         # Build requirements that we will check are available
  175:         self.requirements_to_check: list[str] = []
  176: 
  177:         # The PEP 517 backend we should use to build the project
  178:         self.pep517_backend: BuildBackendHookCaller | None = None
  179: 
  180:         # Are we using PEP 517 for this requirement?
  181:         # After pyproject.toml has been loaded, the only valid values are True
  182:         # and False. Before loading, None is valid (meaning "use the default").
  183:         # Setting an explicit value before loading pyproject.toml is supported,
  184:         # but after loading this flag should be treated as read only.
  185:         self.use_pep517 = use_pep517
  186: 
  187:         # If config settings are provided, enforce PEP 517.
  188:         if self.config_settings:
  189:             if self.use_pep517 is False:
  190:                 logger.warning(
  191:                     "--no-use-pep517 ignored for %s "
  192:                     "because --config-settings are specified.",
  193:                     self,
  194:                 )
  195:             self.use_pep517 = True
  196: 
  197:         # This requirement needs more preparation before it can be built
  198:         self.needs_more_preparation = False
  199: 
  200:         # This requirement needs to be unpacked before it can be installed.
  201:         self._archive_source: Path | None = None
  202: 
  203:     def __str__(self) -> str:
  204:         if self.req:
  205:             s = redact_auth_from_requirement(self.req)
  206:             if self.link:
  207:                 s += f" from {redact_auth_from_url(self.link.url)}"
  208:         elif self.link:
  209:             s = redact_auth_from_url(self.link.url)
  210:         else:
  211:             s = "<InstallRequirement>"
  212:         if self.satisfied_by is not None:
  213:             if self.satisfied_by.location is not None:
  214:                 location = display_path(self.satisfied_by.location)
  215:             else:
  216:                 location = "<memory>"
  217:             s += f" in {location}"
  218:         if self.comes_from:
  219:             if isinstance(self.comes_from, str):
  220:                 comes_from: str | None = self.comes_from
  221:             else:
  222:                 comes_from = self.comes_from.from_path()
  223:             if comes_from:
  224:                 s += f" (from {comes_from})"
  225:         return s
  226: 
  227:     def __repr__(self) -> str:
  228:         return (
  229:             f"<{self.__class__.__name__} object: "
  230:             f"{str(self)} editable={self.editable!r}>"
  231:         )
  232: 
  233:     def format_debug(self) -> str:
  234:         """An un-tested helper for getting state, for debugging."""
  235:         attributes = vars(self)
  236:         names = sorted(attributes)
  237: 
  238:         state = (f"{attr}={attributes[attr]!r}" for attr in sorted(names))
  239:         return "<{name} object: {{{state}}}>".format(
  240:             name=self.__class__.__name__,
  241:             state=", ".join(state),
  242:         )
  243: 
  244:     # Things that are valid for all kinds of requirements?
  245:     @property
  246:     def name(self) -> str | None:
  247:         if self.req is None:
  248:             return None
  249:         return self.req.name
  250: 
  251:     @functools.cached_property
  252:     def supports_pyproject_editable(self) -> bool:
  253:         if not self.use_pep517:
  254:             return False
  255:         assert self.pep517_backend
  256:         with self.build_env:
  257:             runner = runner_with_spinner_message(
  258:                 "Checking if build backend supports build_editable"
  259:             )
  260:             with self.pep517_backend.subprocess_runner(runner):
  261:                 return "build_editable" in self.pep517_backend._supported_features()
  262: 
  263:     @property
  264:     def specifier(self) -> SpecifierSet:
  265:         assert self.req is not None
  266:         return self.req.specifier
  267: 
  268:     @property
  269:     def is_direct(self) -> bool:
  270:         """Whether this requirement was specified as a direct URL."""
  271:         return self.original_link is not None
  272: 
  273:     @property
  274:     def is_pinned(self) -> bool:
  275:         """Return whether I am pinned to an exact version.
  276: 
  277:         For example, some-package==1.2 is pinned; some-package>1.2 is not.
  278:         """
  279:         assert self.req is not None
  280:         specifiers = self.req.specifier
  281:         return len(specifiers) == 1 and next(iter(specifiers)).operator in {"==", "==="}
  282: 
  283:     def match_markers(self, extras_requested: Iterable[str] | None = None) -> bool:
  284:         if not extras_requested:
  285:             # Provide an extra to safely evaluate the markers
  286:             # without matching any extra
  287:             extras_requested = ("",)
  288:         if self.markers is not None:
  289:             return any(
  290:                 self.markers.evaluate({"extra": extra}) for extra in extras_requested
  291:             )
  292:         else:
  293:             return True
  294: 
  295:     @property
  296:     def has_hash_options(self) -> bool:
  297:         """Return whether any known-good hashes are specified as options.
  298: 
  299:         These activate --require-hashes mode; hashes specified as part of a
  300:         URL do not.
  301: 
  302:         """
  303:         return bool(self.hash_options)
  304: 
  305:     def hashes(self, trust_internet: bool = True) -> Hashes:
  306:         """Return a hash-comparer that considers my option- and URL-based
  307:         hashes to be known-good.
  308: 
  309:         Hashes in URLs--ones embedded in the requirements file, not ones
  310:         downloaded from an index server--are almost peers with ones from
  311:         flags. They satisfy --require-hashes (whether it was implicitly or
  312:         explicitly activated) but do not activate it. md5 and sha224 are not
  313:         allowed in flags, which should nudge people toward good algos. We
  314:         always OR all hashes together, even ones from URLs.
  315: 
  316:         :param trust_internet: Whether to trust URL-based (#md5=...) hashes
  317:             downloaded from the internet, as by populate_link()
  318: 
  319:         """
  320:         good_hashes = self.hash_options.copy()
  321:         if trust_internet:
  322:             link = self.link
  323:         elif self.is_direct and self.user_supplied:
  324:             link = self.original_link
  325:         else:
  326:             link = None
  327:         if link and link.hash:
  328:             assert link.hash_name is not None
  329:             good_hashes.setdefault(link.hash_name, []).append(link.hash)
  330:         return Hashes(good_hashes)
  331: 
  332:     def from_path(self) -> str | None:
  333:         """Format a nice indicator to show where this "comes from" """
  334:         if self.req is None:
  335:             return None
  336:         s = str(self.req)
  337:         if self.comes_from:
  338:             comes_from: str | None
  339:             if isinstance(self.comes_from, str):
  340:                 comes_from = self.comes_from
  341:             else:
  342:                 comes_from = self.comes_from.from_path()
  343:             if comes_from:
  344:                 s += "->" + comes_from
  345:         return s
  346: 
  347:     def ensure_build_location(
  348:         self, build_dir: str, autodelete: bool, parallel_builds: bool
  349:     ) -> str:
  350:         assert build_dir is not None
  351:         if self._temp_build_dir is not None:
  352:             assert self._temp_build_dir.path
  353:             return self._temp_build_dir.path
  354:         if self.req is None:
  355:             # Some systems have /tmp as a symlink which confuses custom
  356:             # builds (such as numpy). Thus, we ensure that the real path
  357:             # is returned.
  358:             self._temp_build_dir = TempDirectory(
  359:                 kind=tempdir_kinds.REQ_BUILD, globally_managed=True
  360:             )
  361: 
  362:             return self._temp_build_dir.path
  363: 
  364:         # This is the only remaining place where we manually determine the path
  365:         # for the temporary directory. It is only needed for editables where
  366:         # it is the value of the --src option.
  367: 
  368:         # When parallel builds are enabled, add a UUID to the build directory
  369:         # name so multiple builds do not interfere with each other.
  370:         dir_name: str = canonicalize_name(self.req.name)
  371:         if parallel_builds:
  372:             dir_name = f"{dir_name}_{uuid.uuid4().hex}"
  373: 
  374:         # FIXME: Is there a better place to create the build_dir? (hg and bzr
  375:         # need this)
  376:         if not os.path.exists(build_dir):
  377:             logger.debug("Creating directory %s", build_dir)
  378:             os.makedirs(build_dir)
  379:         actual_build_dir = os.path.join(build_dir, dir_name)
  380:         # `None` indicates that we respect the globally-configured deletion
  381:         # settings, which is what we actually want when auto-deleting.
  382:         delete_arg = None if autodelete else False
  383:         return TempDirectory(
  384:             path=actual_build_dir,
  385:             delete=delete_arg,
  386:             kind=tempdir_kinds.REQ_BUILD,
  387:             globally_managed=True,
  388:         ).path
  389: 
  390:     def _set_requirement(self) -> None:
  391:         """Set requirement after generating metadata."""
  392:         assert self.req is None
  393:         assert self.metadata is not None
  394:         assert self.source_dir is not None
  395: 
  396:         # Construct a Requirement object from the generated metadata
  397:         if isinstance(parse_version(self.metadata["Version"]), Version):
  398:             op = "=="
  399:         else:
  400:             op = "==="
  401: 
  402:         self.req = get_requirement(
  403:             "".join(
  404:                 [
  405:                     self.metadata["Name"],
  406:                     op,
  407:                     self.metadata["Version"],
  408:                 ]
  409:             )
  410:         )
  411: 
  412:     def warn_on_mismatching_name(self) -> None:
  413:         assert self.req is not None
  414:         metadata_name = canonicalize_name(self.metadata["Name"])
  415:         if canonicalize_name(self.req.name) == metadata_name:
  416:             # Everything is fine.
  417:             return
  418: 
  419:         # If we're here, there's a mismatch. Log a warning about it.
  420:         logger.warning(
  421:             "Generating metadata for package %s "
  422:             "produced metadata for project name %s. Fix your "
  423:             "#egg=%s fragments.",
  424:             self.name,
  425:             metadata_name,
  426:             self.name,
  427:         )
  428:         self.req = get_requirement(metadata_name)
  429: 
  430:     def check_if_exists(self, use_user_site: bool) -> None:
  431:         """Find an installed distribution that satisfies or conflicts
  432:         with this requirement, and set self.satisfied_by or
  433:         self.should_reinstall appropriately.
  434:         """
  435:         if self.req is None:
  436:             return
  437:         existing_dist = get_default_environment().get_distribution(self.req.name)
  438:         if not existing_dist:
  439:             return
  440: 
  441:         version_compatible = self.req.specifier.contains(
  442:             existing_dist.version,
  443:             prereleases=True,
  444:         )
  445:         if not version_compatible:
  446:             self.satisfied_by = None
  447:             if use_user_site:
  448:                 if existing_dist.in_usersite:
  449:                     self.should_reinstall = True
  450:                 elif running_under_virtualenv() and existing_dist.in_site_packages:
  451:                     raise InstallationError(
  452:                         f"Will not install to the user site because it will "
  453:                         f"lack sys.path precedence to {existing_dist.raw_name} "
  454:                         f"in {existing_dist.location}"
  455:                     )
  456:             else:
  457:                 self.should_reinstall = True
  458:         else:
  459:             if self.editable:
  460:                 self.should_reinstall = True
  461:                 # when installing editables, nothing pre-existing should ever
  462:                 # satisfy
  463:                 self.satisfied_by = None
  464:             else:
  465:                 self.satisfied_by = existing_dist
  466: 
  467:     # Things valid for wheels
  468:     @property
  469:     def is_wheel(self) -> bool:
  470:         if not self.link:
  471:             return False
  472:         return self.link.is_wheel
  473: 
  474:     @property
  475:     def is_wheel_from_cache(self) -> bool:
  476:         # When True, it means that this InstallRequirement is a local wheel file in the
  477:         # cache of locally built wheels.
  478:         return self.cached_wheel_source_link is not None
  479: 
  480:     # Things valid for sdists
  481:     @property
  482:     def unpacked_source_directory(self) -> str:
  483:         assert self.source_dir, f"No source dir for {self}"
  484:         return os.path.join(
  485:             self.source_dir, self.link and self.link.subdirectory_fragment or ""
  486:         )
  487: 
  488:     @property
  489:     def setup_py_path(self) -> str:
  490:         assert self.source_dir, f"No source dir for {self}"
  491:         setup_py = os.path.join(self.unpacked_source_directory, "setup.py")
  492: 
  493:         return setup_py
  494: 
  495:     @property
  496:     def setup_cfg_path(self) -> str:
  497:         assert self.source_dir, f"No source dir for {self}"
  498:         setup_cfg = os.path.join(self.unpacked_source_directory, "setup.cfg")
  499: 
  500:         return setup_cfg
  501: 
  502:     @property
  503:     def pyproject_toml_path(self) -> str:
  504:         assert self.source_dir, f"No source dir for {self}"
  505:         return make_pyproject_path(self.unpacked_source_directory)
  506: 
  507:     def load_pyproject_toml(self) -> None:
  508:         """Load the pyproject.toml file.
  509: 
  510:         After calling this routine, all of the attributes related to PEP 517
  511:         processing for this requirement have been set. In particular, the
  512:         use_pep517 attribute can be used to determine whether we should
  513:         follow the PEP 517 or legacy (setup.py) code path.
  514:         """
  515:         pyproject_toml_data = load_pyproject_toml(
  516:             self.use_pep517, self.pyproject_toml_path, self.setup_py_path, str(self)
  517:         )
  518: 
  519:         if pyproject_toml_data is None:
  520:             assert not self.config_settings
  521:             self.use_pep517 = False
  522:             return
  523: 
  524:         self.use_pep517 = True
  525:         requires, backend, check, backend_path = pyproject_toml_data
  526:         self.requirements_to_check = check
  527:         self.pyproject_requires = requires
  528:         self.pep517_backend = ConfiguredBuildBackendHookCaller(
  529:             self,
  530:             self.unpacked_source_directory,
  531:             backend,
  532:             backend_path=backend_path,
  533:         )
  534: 
  535:     def isolated_editable_sanity_check(self) -> None:
  536:         """Check that an editable requirement if valid for use with PEP 517/518.
  537: 
  538:         This verifies that an editable that has a pyproject.toml either supports PEP 660
  539:         or as a setup.py or a setup.cfg
  540:         """
  541:         if (
  542:             self.editable
  543:             and self.use_pep517
  544:             and not self.supports_pyproject_editable
  545:             and not os.path.isfile(self.setup_py_path)
  546:             and not os.path.isfile(self.setup_cfg_path)
  547:         ):
  548:             raise InstallationError(
  549:                 f"Project {self} has a 'pyproject.toml' and its build "
  550:                 f"backend is missing the 'build_editable' hook. Since it does not "
  551:                 f"have a 'setup.py' nor a 'setup.cfg', "
  552:                 f"it cannot be installed in editable mode. "
  553:                 f"Consider using a build backend that supports PEP 660."
  554:             )
  555: 
  556:     def prepare_metadata(self) -> None:
  557:         """Ensure that project metadata is available.
  558: 
  559:         Under PEP 517 and PEP 660, call the backend hook to prepare the metadata.
  560:         Under legacy processing, call setup.py egg-info.
  561:         """
  562:         assert self.source_dir, f"No source dir for {self}"
  563:         details = self.name or f"from {self.link}"
  564: 
  565:         if self.use_pep517:
  566:             assert self.pep517_backend is not None
  567:             if (
  568:                 self.editable
  569:                 and self.permit_editable_wheels
  570:                 and self.supports_pyproject_editable
  571:             ):
  572:                 self.metadata_directory = generate_editable_metadata(
  573:                     build_env=self.build_env,
  574:                     backend=self.pep517_backend,
  575:                     details=details,
  576:                 )
  577:             else:
  578:                 self.metadata_directory = generate_metadata(
  579:                     build_env=self.build_env,
  580:                     backend=self.pep517_backend,
  581:                     details=details,
  582:                 )
  583:         else:
  584:             self.metadata_directory = generate_metadata_legacy(
  585:                 build_env=self.build_env,
  586:                 setup_py_path=self.setup_py_path,
  587:                 source_dir=self.unpacked_source_directory,
  588:                 isolated=self.isolated,
  589:                 details=details,
  590:             )
  591: 
  592:         # Act on the newly generated metadata, based on the name and version.
  593:         if not self.name:
  594:             self._set_requirement()
  595:         else:
  596:             self.warn_on_mismatching_name()
  597: 
  598:         self.assert_source_matches_version()
  599: 
  600:     @property
  601:     def metadata(self) -> Any:
  602:         if not hasattr(self, "_metadata"):
  603:             self._metadata = self.get_dist().metadata
  604: 
  605:         return self._metadata
  606: 
  607:     def get_dist(self) -> BaseDistribution:
  608:         if self.metadata_directory:
  609:             return get_directory_distribution(self.metadata_directory)
  610:         elif self.local_file_path and self.is_wheel:
  611:             assert self.req is not None
  612:             return get_wheel_distribution(
  613:                 FilesystemWheel(self.local_file_path),
  614:                 canonicalize_name(self.req.name),
  615:             )
  616:         raise AssertionError(
  617:             f"InstallRequirement {self} has no metadata directory and no wheel: "
  618:             f"can't make a distribution."
  619:         )
  620: 
  621:     def assert_source_matches_version(self) -> None:
  622:         assert self.source_dir, f"No source dir for {self}"
  623:         version = self.metadata["version"]
  624:         if self.req and self.req.specifier and version not in self.req.specifier:
  625:             logger.warning(
  626:                 "Requested %s, but installing version %s",
  627:                 self,
  628:                 version,
  629:             )
  630:         else:
  631:             logger.debug(
  632:                 "Source in %s has version %s, which satisfies requirement %s",
  633:                 display_path(self.source_dir),
  634:                 version,
  635:                 self,
  636:             )
  637: 
  638:     # For both source distributions and editables
  639:     def ensure_has_source_dir(
  640:         self,
  641:         parent_dir: str,
  642:         autodelete: bool = False,
  643:         parallel_builds: bool = False,
  644:     ) -> None:
  645:         """Ensure that a source_dir is set.
  646: 
  647:         This will create a temporary build dir if the name of the requirement
  648:         isn't known yet.
  649: 
  650:         :param parent_dir: The ideal pip parent_dir for the source_dir.
  651:             Generally src_dir for editables and build_dir for sdists.
  652:         :return: self.source_dir
  653:         """
  654:         if self.source_dir is None:
  655:             self.source_dir = self.ensure_build_location(
  656:                 parent_dir,
  657:                 autodelete=autodelete,
  658:                 parallel_builds=parallel_builds,
  659:             )
  660: 
  661:     def needs_unpacked_archive(self, archive_source: Path) -> None:
  662:         assert self._archive_source is None
  663:         self._archive_source = archive_source
  664: 
  665:     def ensure_pristine_source_checkout(self) -> None:
  666:         """Ensure the source directory has not yet been built in."""
  667:         assert self.source_dir is not None
  668:         if self._archive_source is not None:
  669:             unpack_file(str(self._archive_source), self.source_dir)
  670:         elif is_installable_dir(self.source_dir):
  671:             # If a checkout exists, it's unwise to keep going.
  672:             # version inconsistencies are logged later, but do not fail
  673:             # the installation.
  674:             raise PreviousBuildDirError(
  675:                 f"pip can't proceed with requirements '{self}' due to a "
  676:                 f"pre-existing build directory ({self.source_dir}). This is likely "
  677:                 "due to a previous installation that failed . pip is "
  678:                 "being responsible and not assuming it can delete this. "
  679:                 "Please delete it and try again."
  680:             )
  681: 
  682:     # For editable installations
  683:     def update_editable(self) -> None:
  684:         if not self.link:
  685:             logger.debug(
  686:                 "Cannot update repository at %s; repository location is unknown",
  687:                 self.source_dir,
  688:             )
  689:             return
  690:         assert self.editable
  691:         assert self.source_dir
  692:         if self.link.scheme == "file":
  693:             # Static paths don't get updated
  694:             return
  695:         vcs_backend = vcs.get_backend_for_scheme(self.link.scheme)
  696:         # Editable requirements are validated in Requirement constructors.
  697:         # So here, if it's neither a path nor a valid VCS URL, it's a bug.
  698:         assert vcs_backend, f"Unsupported VCS URL {self.link.url}"
  699:         hidden_url = hide_url(self.link.url)
  700:         vcs_backend.obtain(self.source_dir, url=hidden_url, verbosity=0)
  701: 
  702:     # Top-level Actions
  703:     def uninstall(
  704:         self, auto_confirm: bool = False, verbose: bool = False
  705:     ) -> UninstallPathSet | None:
  706:         """
  707:         Uninstall the distribution currently satisfying this requirement.
  708: 
  709:         Prompts before removing or modifying files unless
  710:         ``auto_confirm`` is True.
  711: 
  712:         Refuses to delete or modify files outside of ``sys.prefix`` -
  713:         thus uninstallation within a virtual environment can only
  714:         modify that virtual environment, even if the virtualenv is
  715:         linked to global site-packages.
  716: 
  717:         """
  718:         assert self.req
  719:         dist = get_default_environment().get_distribution(self.req.name)
  720:         if not dist:
  721:             logger.warning("Skipping %s as it is not installed.", self.name)
  722:             return None
  723:         logger.info("Found existing installation: %s", dist)
  724: 
  725:         uninstalled_pathset = UninstallPathSet.from_dist(dist)
  726:         uninstalled_pathset.remove(auto_confirm, verbose)
  727:         return uninstalled_pathset
  728: 
  729:     def _get_archive_name(self, path: str, parentdir: str, rootdir: str) -> str:
  730:         def _clean_zip_name(name: str, prefix: str) -> str:
  731:             assert name.startswith(
  732:                 prefix + os.path.sep
  733:             ), f"name {name!r} doesn't start with prefix {prefix!r}"
  734:             name = name[len(prefix) + 1 :]
  735:             name = name.replace(os.path.sep, "/")
  736:             return name
  737: 
  738:         assert self.req is not None
  739:         path = os.path.join(parentdir, path)
  740:         name = _clean_zip_name(path, rootdir)
  741:         return self.req.name + "/" + name
  742: 
  743:     def archive(self, build_dir: str | None) -> None:
  744:         """Saves archive to provided build_dir.
  745: 
  746:         Used for saving downloaded VCS requirements as part of `pip download`.
  747:         """
  748:         assert self.source_dir
  749:         if build_dir is None:
  750:             return
  751: 
  752:         create_archive = True
  753:         archive_name = "{}-{}.zip".format(self.name, self.metadata["version"])
  754:         archive_path = os.path.join(build_dir, archive_name)
  755: 
  756:         if os.path.exists(archive_path):
  757:             response = ask_path_exists(
  758:                 f"The file {display_path(archive_path)} exists. (i)gnore, (w)ipe, "
  759:                 "(b)ackup, (a)bort ",
  760:                 ("i", "w", "b", "a"),
  761:             )
  762:             if response == "i":
  763:                 create_archive = False
  764:             elif response == "w":
  765:                 logger.warning("Deleting %s", display_path(archive_path))
  766:                 os.remove(archive_path)
  767:             elif response == "b":
  768:                 dest_file = backup_dir(archive_path)
  769:                 logger.warning(
  770:                     "Backing up %s to %s",
  771:                     display_path(archive_path),
  772:                     display_path(dest_file),
  773:                 )
  774:                 shutil.move(archive_path, dest_file)
  775:             elif response == "a":
  776:                 sys.exit(-1)
  777: 
  778:         if not create_archive:
  779:             return
  780: 
  781:         zip_output = zipfile.ZipFile(
  782:             archive_path,
  783:             "w",
  784:             zipfile.ZIP_DEFLATED,
  785:             allowZip64=True,
  786:         )
  787:         with zip_output:
  788:             dir = os.path.normcase(os.path.abspath(self.unpacked_source_directory))
  789:             for dirpath, dirnames, filenames in os.walk(dir):
  790:                 for dirname in dirnames:
  791:                     dir_arcname = self._get_archive_name(
  792:                         dirname,
  793:                         parentdir=dirpath,
  794:                         rootdir=dir,
  795:                     )
  796:                     zipdir = zipfile.ZipInfo(dir_arcname + "/")
  797:                     zipdir.external_attr = 0x1ED << 16  # 0o755
  798:                     zip_output.writestr(zipdir, "")
  799:                 for filename in filenames:
  800:                     file_arcname = self._get_archive_name(
  801:                         filename,
  802:                         parentdir=dirpath,
  803:                         rootdir=dir,
  804:                     )
  805:                     filename = os.path.join(dirpath, filename)
  806:                     zip_output.write(filename, file_arcname)
  807: 
  808:         logger.info("Saved %s", display_path(archive_path))
  809: 
  810:     def install(
  811:         self,
  812:         global_options: Sequence[str] | None = None,
  813:         root: str | None = None,
  814:         home: str | None = None,
  815:         prefix: str | None = None,
  816:         warn_script_location: bool = True,
  817:         use_user_site: bool = False,
  818:         pycompile: bool = True,
  819:     ) -> None:
  820:         assert self.req is not None
  821:         scheme = get_scheme(
  822:             self.req.name,
  823:             user=use_user_site,
  824:             home=home,
  825:             root=root,
  826:             isolated=self.isolated,
  827:             prefix=prefix,
  828:         )
  829: 
  830:         if self.editable and not self.is_wheel:
  831:             deprecated(
  832:                 reason=(
  833:                     f"Legacy editable install of {self} (setup.py develop) "
  834:                     "is deprecated."
  835:                 ),
  836:                 replacement=(
  837:                     "to add a pyproject.toml or enable --use-pep517, "
  838:                     "and use setuptools >= 64. "
  839:                     "If the resulting installation is not behaving as expected, "
  840:                     "try using --config-settings editable_mode=compat. "
  841:                     "Please consult the setuptools documentation for more information"
  842:                 ),
  843:                 gone_in="25.3",
  844:                 issue=11457,
  845:             )
  846:             if self.config_settings:
  847:                 logger.warning(
  848:                     "--config-settings ignored for legacy editable install of %s. "
  849:                     "Consider upgrading to a version of setuptools "
  850:                     "that supports PEP 660 (>= 64).",
  851:                     self,
  852:                 )
  853:             install_editable_legacy(
  854:                 global_options=global_options if global_options is not None else [],
  855:                 prefix=prefix,
  856:                 home=home,
  857:                 use_user_site=use_user_site,
  858:                 name=self.req.name,
  859:                 setup_py_path=self.setup_py_path,
  860:                 isolated=self.isolated,
  861:                 build_env=self.build_env,
  862:                 unpacked_source_directory=self.unpacked_source_directory,
  863:             )
  864:             self.install_succeeded = True
  865:             return
  866: 
  867:         assert self.is_wheel
  868:         assert self.local_file_path
  869: 
  870:         install_wheel(
  871:             self.req.name,
  872:             self.local_file_path,
  873:             scheme=scheme,
  874:             req_description=str(self.req),
  875:             pycompile=pycompile,
  876:             warn_script_location=warn_script_location,
  877:             direct_url=self.download_info if self.is_direct else None,
  878:             requested=self.user_supplied,
  879:         )
  880:         self.install_succeeded = True
  881: 
  882: 
  883: def check_invalid_constraint_type(req: InstallRequirement) -> str:
  884:     # Check for unsupported forms
  885:     problem = ""
  886:     if not req.name:
  887:         problem = "Unnamed requirements are not allowed as constraints"
  888:     elif req.editable:
  889:         problem = "Editable requirements are not allowed as constraints"
  890:     elif req.extras:
  891:         problem = "Constraints cannot have extras"
  892: 
  893:     if problem:
  894:         deprecated(
  895:             reason=(
  896:                 "Constraints are only allowed to take the form of a package "
  897:                 "name and a version specifier. Other forms were originally "
  898:                 "permitted as an accident of the implementation, but were "
  899:                 "undocumented. The new implementation of the resolver no "
  900:                 "longer supports these forms."
  901:             ),
  902:             replacement="replacing the constraint with a requirement",
  903:             # No plan yet for when the new resolver becomes default
  904:             gone_in=None,
  905:             issue=8210,
  906:         )
  907: 
  908:     return problem
  909: 
  910: 
  911: def _has_option(options: Values, reqs: list[InstallRequirement], option: str) -> bool:
  912:     if getattr(options, option, None):
  913:         return True
  914:     for req in reqs:
  915:         if getattr(req, option, None):
  916:             return True
  917:     return False
  918: 
  919: 
  920: def check_legacy_setup_py_options(
  921:     options: Values,
  922:     reqs: list[InstallRequirement],
  923: ) -> None:
  924:     has_build_options = _has_option(options, reqs, "build_options")
  925:     has_global_options = _has_option(options, reqs, "global_options")
  926:     if has_build_options or has_global_options:
  927:         deprecated(
  928:             reason="--build-option and --global-option are deprecated.",
  929:             issue=11859,
  930:             replacement="to use --config-settings",
  931:             gone_in="25.3",
  932:         )
  933:         logger.warning(
  934:             "Implying --no-binary=:all: due to the presence of "
  935:             "--build-option / --global-option. "
  936:         )
  937:         options.format_control.disallow_binaries()
