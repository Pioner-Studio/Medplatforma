    1: """
    2: Requirements file parsing
    3: """
    4: 
    5: from __future__ import annotations
    6: 
    7: import codecs
    8: import locale
    9: import logging
   10: import optparse
   11: import os
   12: import re
   13: import shlex
   14: import sys
   15: import urllib.parse
   16: from collections.abc import Generator, Iterable
   17: from dataclasses import dataclass
   18: from optparse import Values
   19: from typing import (
   20:     TYPE_CHECKING,
   21:     Any,
   22:     Callable,
   23:     NoReturn,
   24: )
   25: 
   26: from pip._internal.cli import cmdoptions
   27: from pip._internal.exceptions import InstallationError, RequirementsFileParseError
   28: from pip._internal.models.search_scope import SearchScope
   29: 
   30: if TYPE_CHECKING:
   31:     from pip._internal.index.package_finder import PackageFinder
   32:     from pip._internal.network.session import PipSession
   33: 
   34: __all__ = ["parse_requirements"]
   35: 
   36: ReqFileLines = Iterable[tuple[int, str]]
   37: 
   38: LineParser = Callable[[str], tuple[str, Values]]
   39: 
   40: SCHEME_RE = re.compile(r"^(http|https|file):", re.I)
   41: COMMENT_RE = re.compile(r"(^|\s+)#.*$")
   42: 
   43: # Matches environment variable-style values in '${MY_VARIABLE_1}' with the
   44: # variable name consisting of only uppercase letters, digits or the '_'
   45: # (underscore). This follows the POSIX standard defined in IEEE Std 1003.1,
   46: # 2013 Edition.
   47: ENV_VAR_RE = re.compile(r"(?P<var>\$\{(?P<name>[A-Z0-9_]+)\})")
   48: 
   49: SUPPORTED_OPTIONS: list[Callable[..., optparse.Option]] = [
   50:     cmdoptions.index_url,
   51:     cmdoptions.extra_index_url,
   52:     cmdoptions.no_index,
   53:     cmdoptions.constraints,
   54:     cmdoptions.requirements,
   55:     cmdoptions.editable,
   56:     cmdoptions.find_links,
   57:     cmdoptions.no_binary,
   58:     cmdoptions.only_binary,
   59:     cmdoptions.prefer_binary,
   60:     cmdoptions.require_hashes,
   61:     cmdoptions.pre,
   62:     cmdoptions.trusted_host,
   63:     cmdoptions.use_new_feature,
   64: ]
   65: 
   66: # options to be passed to requirements
   67: SUPPORTED_OPTIONS_REQ: list[Callable[..., optparse.Option]] = [
   68:     cmdoptions.global_options,
   69:     cmdoptions.hash,
   70:     cmdoptions.config_settings,
   71: ]
   72: 
   73: SUPPORTED_OPTIONS_EDITABLE_REQ: list[Callable[..., optparse.Option]] = [
   74:     cmdoptions.config_settings,
   75: ]
   76: 
   77: 
   78: # the 'dest' string values
   79: SUPPORTED_OPTIONS_REQ_DEST = [str(o().dest) for o in SUPPORTED_OPTIONS_REQ]
   80: SUPPORTED_OPTIONS_EDITABLE_REQ_DEST = [
   81:     str(o().dest) for o in SUPPORTED_OPTIONS_EDITABLE_REQ
   82: ]
   83: 
   84: # order of BOMS is important: codecs.BOM_UTF16_LE is a prefix of codecs.BOM_UTF32_LE
   85: # so data.startswith(BOM_UTF16_LE) would be true for UTF32_LE data
   86: BOMS: list[tuple[bytes, str]] = [
   87:     (codecs.BOM_UTF8, "utf-8"),
   88:     (codecs.BOM_UTF32, "utf-32"),
   89:     (codecs.BOM_UTF32_BE, "utf-32-be"),
   90:     (codecs.BOM_UTF32_LE, "utf-32-le"),
   91:     (codecs.BOM_UTF16, "utf-16"),
   92:     (codecs.BOM_UTF16_BE, "utf-16-be"),
   93:     (codecs.BOM_UTF16_LE, "utf-16-le"),
   94: ]
   95: 
   96: PEP263_ENCODING_RE = re.compile(rb"coding[:=]\s*([-\w.]+)")
   97: DEFAULT_ENCODING = "utf-8"
   98: 
   99: logger = logging.getLogger(__name__)
  100: 
  101: 
  102: @dataclass(frozen=True)
  103: class ParsedRequirement:
  104:     # TODO: replace this with slots=True when dropping Python 3.9 support.
  105:     __slots__ = (
  106:         "requirement",
  107:         "is_editable",
  108:         "comes_from",
  109:         "constraint",
  110:         "options",
  111:         "line_source",
  112:     )
  113: 
  114:     requirement: str
  115:     is_editable: bool
  116:     comes_from: str
  117:     constraint: bool
  118:     options: dict[str, Any] | None
  119:     line_source: str | None
  120: 
  121: 
  122: @dataclass(frozen=True)
  123: class ParsedLine:
  124:     __slots__ = ("filename", "lineno", "args", "opts", "constraint")
  125: 
  126:     filename: str
  127:     lineno: int
  128:     args: str
  129:     opts: Values
  130:     constraint: bool
  131: 
  132:     @property
  133:     def is_editable(self) -> bool:
  134:         return bool(self.opts.editables)
  135: 
  136:     @property
  137:     def requirement(self) -> str | None:
  138:         if self.args:
  139:             return self.args
  140:         elif self.is_editable:
  141:             # We don't support multiple -e on one line
  142:             return self.opts.editables[0]
  143:         return None
  144: 
  145: 
  146: def parse_requirements(
  147:     filename: str,
  148:     session: PipSession,
  149:     finder: PackageFinder | None = None,
  150:     options: optparse.Values | None = None,
  151:     constraint: bool = False,
  152: ) -> Generator[ParsedRequirement, None, None]:
  153:     """Parse a requirements file and yield ParsedRequirement instances.
  154: 
  155:     :param filename:    Path or url of requirements file.
  156:     :param session:     PipSession instance.
  157:     :param finder:      Instance of pip.index.PackageFinder.
  158:     :param options:     cli options.
  159:     :param constraint:  If true, parsing a constraint file rather than
  160:         requirements file.
  161:     """
  162:     line_parser = get_line_parser(finder)
  163:     parser = RequirementsFileParser(session, line_parser)
  164: 
  165:     for parsed_line in parser.parse(filename, constraint):
  166:         parsed_req = handle_line(
  167:             parsed_line, options=options, finder=finder, session=session
  168:         )
  169:         if parsed_req is not None:
  170:             yield parsed_req
  171: 
  172: 
  173: def preprocess(content: str) -> ReqFileLines:
  174:     """Split, filter, and join lines, and return a line iterator
  175: 
  176:     :param content: the content of the requirements file
  177:     """
  178:     lines_enum: ReqFileLines = enumerate(content.splitlines(), start=1)
  179:     lines_enum = join_lines(lines_enum)
  180:     lines_enum = ignore_comments(lines_enum)
  181:     lines_enum = expand_env_variables(lines_enum)
  182:     return lines_enum
  183: 
  184: 
  185: def handle_requirement_line(
  186:     line: ParsedLine,
  187:     options: optparse.Values | None = None,
  188: ) -> ParsedRequirement:
  189:     # preserve for the nested code path
  190:     line_comes_from = "{} {} (line {})".format(
  191:         "-c" if line.constraint else "-r",
  192:         line.filename,
  193:         line.lineno,
  194:     )
  195: 
  196:     assert line.requirement is not None
  197: 
  198:     # get the options that apply to requirements
  199:     if line.is_editable:
  200:         supported_dest = SUPPORTED_OPTIONS_EDITABLE_REQ_DEST
  201:     else:
  202:         supported_dest = SUPPORTED_OPTIONS_REQ_DEST
  203:     req_options = {}
  204:     for dest in supported_dest:
  205:         if dest in line.opts.__dict__ and line.opts.__dict__[dest]:
  206:             req_options[dest] = line.opts.__dict__[dest]
  207: 
  208:     line_source = f"line {line.lineno} of {line.filename}"
  209:     return ParsedRequirement(
  210:         requirement=line.requirement,
  211:         is_editable=line.is_editable,
  212:         comes_from=line_comes_from,
  213:         constraint=line.constraint,
  214:         options=req_options,
  215:         line_source=line_source,
  216:     )
  217: 
  218: 
  219: def handle_option_line(
  220:     opts: Values,
  221:     filename: str,
  222:     lineno: int,
  223:     finder: PackageFinder | None = None,
  224:     options: optparse.Values | None = None,
  225:     session: PipSession | None = None,
  226: ) -> None:
  227:     if opts.hashes:
  228:         logger.warning(
  229:             "%s line %s has --hash but no requirement, and will be ignored.",
  230:             filename,
  231:             lineno,
  232:         )
  233: 
  234:     if options:
  235:         # percolate options upward
  236:         if opts.require_hashes:
  237:             options.require_hashes = opts.require_hashes
  238:         if opts.features_enabled:
  239:             options.features_enabled.extend(
  240:                 f for f in opts.features_enabled if f not in options.features_enabled
  241:             )
  242: 
  243:     # set finder options
  244:     if finder:
  245:         find_links = finder.find_links
  246:         index_urls = finder.index_urls
  247:         no_index = finder.search_scope.no_index
  248:         if opts.no_index is True:
  249:             no_index = True
  250:             index_urls = []
  251:         if opts.index_url and not no_index:
  252:             index_urls = [opts.index_url]
  253:         if opts.extra_index_urls and not no_index:
  254:             index_urls.extend(opts.extra_index_urls)
  255:         if opts.find_links:
  256:             # FIXME: it would be nice to keep track of the source
  257:             # of the find_links: support a find-links local path
  258:             # relative to a requirements file.
  259:             value = opts.find_links[0]
  260:             req_dir = os.path.dirname(os.path.abspath(filename))
  261:             relative_to_reqs_file = os.path.join(req_dir, value)
  262:             if os.path.exists(relative_to_reqs_file):
  263:                 value = relative_to_reqs_file
  264:             find_links.append(value)
  265: 
  266:         if session:
  267:             # We need to update the auth urls in session
  268:             session.update_index_urls(index_urls)
  269: 
  270:         search_scope = SearchScope(
  271:             find_links=find_links,
  272:             index_urls=index_urls,
  273:             no_index=no_index,
  274:         )
  275:         finder.search_scope = search_scope
  276: 
  277:         if opts.pre:
  278:             finder.set_allow_all_prereleases()
  279: 
  280:         if opts.prefer_binary:
  281:             finder.set_prefer_binary()
  282: 
  283:         if session:
  284:             for host in opts.trusted_hosts or []:
  285:                 source = f"line {lineno} of {filename}"
  286:                 session.add_trusted_host(host, source=source)
  287: 
  288: 
  289: def handle_line(
  290:     line: ParsedLine,
  291:     options: optparse.Values | None = None,
  292:     finder: PackageFinder | None = None,
  293:     session: PipSession | None = None,
  294: ) -> ParsedRequirement | None:
  295:     """Handle a single parsed requirements line; This can result in
  296:     creating/yielding requirements, or updating the finder.
  297: 
  298:     :param line:        The parsed line to be processed.
  299:     :param options:     CLI options.
  300:     :param finder:      The finder - updated by non-requirement lines.
  301:     :param session:     The session - updated by non-requirement lines.
  302: 
  303:     Returns a ParsedRequirement object if the line is a requirement line,
  304:     otherwise returns None.
  305: 
  306:     For lines that contain requirements, the only options that have an effect
  307:     are from SUPPORTED_OPTIONS_REQ, and they are scoped to the
  308:     requirement. Other options from SUPPORTED_OPTIONS may be present, but are
  309:     ignored.
  310: 
  311:     For lines that do not contain requirements, the only options that have an
  312:     effect are from SUPPORTED_OPTIONS. Options from SUPPORTED_OPTIONS_REQ may
  313:     be present, but are ignored. These lines may contain multiple options
  314:     (although our docs imply only one is supported), and all our parsed and
  315:     affect the finder.
  316:     """
  317: 
  318:     if line.requirement is not None:
  319:         parsed_req = handle_requirement_line(line, options)
  320:         return parsed_req
  321:     else:
  322:         handle_option_line(
  323:             line.opts,
  324:             line.filename,
  325:             line.lineno,
  326:             finder,
  327:             options,
  328:             session,
  329:         )
  330:         return None
  331: 
  332: 
  333: class RequirementsFileParser:
  334:     def __init__(
  335:         self,
  336:         session: PipSession,
  337:         line_parser: LineParser,
  338:     ) -> None:
  339:         self._session = session
  340:         self._line_parser = line_parser
  341: 
  342:     def parse(
  343:         self, filename: str, constraint: bool
  344:     ) -> Generator[ParsedLine, None, None]:
  345:         """Parse a given file, yielding parsed lines."""
  346:         yield from self._parse_and_recurse(
  347:             filename, constraint, [{os.path.abspath(filename): None}]
  348:         )
  349: 
  350:     def _parse_and_recurse(
  351:         self,
  352:         filename: str,
  353:         constraint: bool,
  354:         parsed_files_stack: list[dict[str, str | None]],
  355:     ) -> Generator[ParsedLine, None, None]:
  356:         for line in self._parse_file(filename, constraint):
  357:             if line.requirement is None and (
  358:                 line.opts.requirements or line.opts.constraints
  359:             ):
  360:                 # parse a nested requirements file
  361:                 if line.opts.requirements:
  362:                     req_path = line.opts.requirements[0]
  363:                     nested_constraint = False
  364:                 else:
  365:                     req_path = line.opts.constraints[0]
  366:                     nested_constraint = True
  367: 
  368:                 # original file is over http
  369:                 if SCHEME_RE.search(filename):
  370:                     # do a url join so relative paths work
  371:                     req_path = urllib.parse.urljoin(filename, req_path)
  372:                 # original file and nested file are paths
  373:                 elif not SCHEME_RE.search(req_path):
  374:                     # do a join so relative paths work
  375:                     # and then abspath so that we can identify recursive references
  376:                     req_path = os.path.abspath(
  377:                         os.path.join(
  378:                             os.path.dirname(filename),
  379:                             req_path,
  380:                         )
  381:                     )
  382:                 parsed_files = parsed_files_stack[0]
  383:                 if req_path in parsed_files:
  384:                     initial_file = parsed_files[req_path]
  385:                     tail = (
  386:                         f" and again in {initial_file}"
  387:                         if initial_file is not None
  388:                         else ""
  389:                     )
  390:                     raise RequirementsFileParseError(
  391:                         f"{req_path} recursively references itself in {filename}{tail}"
  392:                     )
  393:                 # Keeping a track where was each file first included in
  394:                 new_parsed_files = parsed_files.copy()
  395:                 new_parsed_files[req_path] = filename
  396:                 yield from self._parse_and_recurse(
  397:                     req_path, nested_constraint, [new_parsed_files, *parsed_files_stack]
  398:                 )
  399:             else:
  400:                 yield line
  401: 
  402:     def _parse_file(
  403:         self, filename: str, constraint: bool
  404:     ) -> Generator[ParsedLine, None, None]:
  405:         _, content = get_file_content(filename, self._session)
  406: 
  407:         lines_enum = preprocess(content)
  408: 
  409:         for line_number, line in lines_enum:
  410:             try:
  411:                 args_str, opts = self._line_parser(line)
  412:             except OptionParsingError as e:
  413:                 # add offending line
  414:                 msg = f"Invalid requirement: {line}\n{e.msg}"
  415:                 raise RequirementsFileParseError(msg)
  416: 
  417:             yield ParsedLine(
  418:                 filename,
  419:                 line_number,
  420:                 args_str,
  421:                 opts,
  422:                 constraint,
  423:             )
  424: 
  425: 
  426: def get_line_parser(finder: PackageFinder | None) -> LineParser:
  427:     def parse_line(line: str) -> tuple[str, Values]:
  428:         # Build new parser for each line since it accumulates appendable
  429:         # options.
  430:         parser = build_parser()
  431:         defaults = parser.get_default_values()
  432:         defaults.index_url = None
  433:         if finder:
  434:             defaults.format_control = finder.format_control
  435: 
  436:         args_str, options_str = break_args_options(line)
  437: 
  438:         try:
  439:             options = shlex.split(options_str)
  440:         except ValueError as e:
  441:             raise OptionParsingError(f"Could not split options: {options_str}") from e
  442: 
  443:         opts, _ = parser.parse_args(options, defaults)
  444: 
  445:         return args_str, opts
  446: 
  447:     return parse_line
  448: 
  449: 
  450: def break_args_options(line: str) -> tuple[str, str]:
  451:     """Break up the line into an args and options string.  We only want to shlex
  452:     (and then optparse) the options, not the args.  args can contain markers
  453:     which are corrupted by shlex.
  454:     """
  455:     tokens = line.split(" ")
  456:     args = []
  457:     options = tokens[:]
  458:     for token in tokens:
  459:         if token.startswith(("-", "--")):
  460:             break
  461:         else:
  462:             args.append(token)
  463:             options.pop(0)
  464:     return " ".join(args), " ".join(options)
  465: 
  466: 
  467: class OptionParsingError(Exception):
  468:     def __init__(self, msg: str) -> None:
  469:         self.msg = msg
  470: 
  471: 
  472: def build_parser() -> optparse.OptionParser:
  473:     """
  474:     Return a parser for parsing requirement lines
  475:     """
  476:     parser = optparse.OptionParser(add_help_option=False)
  477: 
  478:     option_factories = SUPPORTED_OPTIONS + SUPPORTED_OPTIONS_REQ
  479:     for option_factory in option_factories:
  480:         option = option_factory()
  481:         parser.add_option(option)
  482: 
  483:     # By default optparse sys.exits on parsing errors. We want to wrap
  484:     # that in our own exception.
  485:     def parser_exit(self: Any, msg: str) -> NoReturn:
  486:         raise OptionParsingError(msg)
  487: 
  488:     # NOTE: mypy disallows assigning to a method
  489:     #       https://github.com/python/mypy/issues/2427
  490:     parser.exit = parser_exit  # type: ignore
  491: 
  492:     return parser
  493: 
  494: 
  495: def join_lines(lines_enum: ReqFileLines) -> ReqFileLines:
  496:     """Joins a line ending in '\' with the previous line (except when following
  497:     comments).  The joined line takes on the index of the first line.
  498:     """
  499:     primary_line_number = None
  500:     new_line: list[str] = []
  501:     for line_number, line in lines_enum:
  502:         if not line.endswith("\\") or COMMENT_RE.match(line):
  503:             if COMMENT_RE.match(line):
  504:                 # this ensures comments are always matched later
  505:                 line = " " + line
  506:             if new_line:
  507:                 new_line.append(line)
  508:                 assert primary_line_number is not None
  509:                 yield primary_line_number, "".join(new_line)
  510:                 new_line = []
  511:             else:
  512:                 yield line_number, line
  513:         else:
  514:             if not new_line:
  515:                 primary_line_number = line_number
  516:             new_line.append(line.strip("\\"))
  517: 
  518:     # last line contains \
  519:     if new_line:
  520:         assert primary_line_number is not None
  521:         yield primary_line_number, "".join(new_line)
  522: 
  523:     # TODO: handle space after '\'.
  524: 
  525: 
  526: def ignore_comments(lines_enum: ReqFileLines) -> ReqFileLines:
  527:     """
  528:     Strips comments and filter empty lines.
  529:     """
  530:     for line_number, line in lines_enum:
  531:         line = COMMENT_RE.sub("", line)
  532:         line = line.strip()
  533:         if line:
  534:             yield line_number, line
  535: 
  536: 
  537: def expand_env_variables(lines_enum: ReqFileLines) -> ReqFileLines:
  538:     """Replace all environment variables that can be retrieved via `os.getenv`.
  539: 
  540:     The only allowed format for environment variables defined in the
  541:     requirement file is `${MY_VARIABLE_1}` to ensure two things:
  542: 
  543:     1. Strings that contain a `$` aren't accidentally (partially) expanded.
  544:     2. Ensure consistency across platforms for requirement files.
  545: 
  546:     These points are the result of a discussion on the `github pull
  547:     request #3514 <https://github.com/pypa/pip/pull/3514>`_.
  548: 
  549:     Valid characters in variable names follow the `POSIX standard
  550:     <http://pubs.opengroup.org/onlinepubs/9699919799/>`_ and are limited
  551:     to uppercase letter, digits and the `_` (underscore).
  552:     """
  553:     for line_number, line in lines_enum:
  554:         for env_var, var_name in ENV_VAR_RE.findall(line):
  555:             value = os.getenv(var_name)
  556:             if not value:
  557:                 continue
  558: 
  559:             line = line.replace(env_var, value)
  560: 
  561:         yield line_number, line
  562: 
  563: 
  564: def get_file_content(url: str, session: PipSession) -> tuple[str, str]:
  565:     """Gets the content of a file; it may be a filename, file: URL, or
  566:     http: URL.  Returns (location, content).  Content is unicode.
  567:     Respects # -*- coding: declarations on the retrieved files.
  568: 
  569:     :param url:         File path or url.
  570:     :param session:     PipSession instance.
  571:     """
  572:     scheme = urllib.parse.urlsplit(url).scheme
  573:     # Pip has special support for file:// URLs (LocalFSAdapter).
  574:     if scheme in ["http", "https", "file"]:
  575:         # Delay importing heavy network modules until absolutely necessary.
  576:         from pip._internal.network.utils import raise_for_status
  577: 
  578:         resp = session.get(url)
  579:         raise_for_status(resp)
  580:         return resp.url, resp.text
  581: 
  582:     # Assume this is a bare path.
  583:     try:
  584:         with open(url, "rb") as f:
  585:             raw_content = f.read()
  586:     except OSError as exc:
  587:         raise InstallationError(f"Could not open requirements file: {exc}")
  588: 
  589:     content = _decode_req_file(raw_content, url)
  590: 
  591:     return url, content
  592: 
  593: 
  594: def _decode_req_file(data: bytes, url: str) -> str:
  595:     for bom, encoding in BOMS:
  596:         if data.startswith(bom):
  597:             return data[len(bom) :].decode(encoding)
  598: 
  599:     for line in data.split(b"\n")[:2]:
  600:         if line[0:1] == b"#":
  601:             result = PEP263_ENCODING_RE.search(line)
  602:             if result is not None:
  603:                 encoding = result.groups()[0].decode("ascii")
  604:                 return data.decode(encoding)
  605: 
  606:     try:
  607:         return data.decode(DEFAULT_ENCODING)
  608:     except UnicodeDecodeError:
  609:         locale_encoding = locale.getpreferredencoding(False) or sys.getdefaultencoding()
  610:         logging.warning(
  611:             "unable to decode data from %s with default encoding %s, "
  612:             "falling back to encoding from locale: %s. "
  613:             "If this is intentional you should specify the encoding with a "
  614:             "PEP-263 style comment, e.g. '# -*- coding: %s -*-'",
  615:             url,
  616:             DEFAULT_ENCODING,
  617:             locale_encoding,
  618:             locale_encoding,
  619:         )
  620:         return data.decode(locale_encoding)
