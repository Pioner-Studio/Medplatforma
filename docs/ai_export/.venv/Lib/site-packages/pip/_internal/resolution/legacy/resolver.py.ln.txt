    1: """Dependency Resolution
    2: 
    3: The dependency resolution in pip is performed as follows:
    4: 
    5: for top-level requirements:
    6:     a. only one spec allowed per project, regardless of conflicts or not.
    7:        otherwise a "double requirement" exception is raised
    8:     b. they override sub-dependency requirements.
    9: for sub-dependencies
   10:     a. "first found, wins" (where the order is breadth first)
   11: """
   12: 
   13: from __future__ import annotations
   14: 
   15: import logging
   16: import sys
   17: from collections import defaultdict
   18: from collections.abc import Iterable
   19: from itertools import chain
   20: from typing import Optional
   21: 
   22: from pip._vendor.packaging import specifiers
   23: from pip._vendor.packaging.requirements import Requirement
   24: 
   25: from pip._internal.cache import WheelCache
   26: from pip._internal.exceptions import (
   27:     BestVersionAlreadyInstalled,
   28:     DistributionNotFound,
   29:     HashError,
   30:     HashErrors,
   31:     InstallationError,
   32:     NoneMetadataError,
   33:     UnsupportedPythonVersion,
   34: )
   35: from pip._internal.index.package_finder import PackageFinder
   36: from pip._internal.metadata import BaseDistribution
   37: from pip._internal.models.link import Link
   38: from pip._internal.models.wheel import Wheel
   39: from pip._internal.operations.prepare import RequirementPreparer
   40: from pip._internal.req.req_install import (
   41:     InstallRequirement,
   42:     check_invalid_constraint_type,
   43: )
   44: from pip._internal.req.req_set import RequirementSet
   45: from pip._internal.resolution.base import BaseResolver, InstallRequirementProvider
   46: from pip._internal.utils import compatibility_tags
   47: from pip._internal.utils.compatibility_tags import get_supported
   48: from pip._internal.utils.direct_url_helpers import direct_url_from_link
   49: from pip._internal.utils.logging import indent_log
   50: from pip._internal.utils.misc import normalize_version_info
   51: from pip._internal.utils.packaging import check_requires_python
   52: 
   53: logger = logging.getLogger(__name__)
   54: 
   55: DiscoveredDependencies = defaultdict[Optional[str], list[InstallRequirement]]
   56: 
   57: 
   58: def _check_dist_requires_python(
   59:     dist: BaseDistribution,
   60:     version_info: tuple[int, int, int],
   61:     ignore_requires_python: bool = False,
   62: ) -> None:
   63:     """
   64:     Check whether the given Python version is compatible with a distribution's
   65:     "Requires-Python" value.
   66: 
   67:     :param version_info: A 3-tuple of ints representing the Python
   68:         major-minor-micro version to check.
   69:     :param ignore_requires_python: Whether to ignore the "Requires-Python"
   70:         value if the given Python version isn't compatible.
   71: 
   72:     :raises UnsupportedPythonVersion: When the given Python version isn't
   73:         compatible.
   74:     """
   75:     # This idiosyncratically converts the SpecifierSet to str and let
   76:     # check_requires_python then parse it again into SpecifierSet. But this
   77:     # is the legacy resolver so I'm just not going to bother refactoring.
   78:     try:
   79:         requires_python = str(dist.requires_python)
   80:     except FileNotFoundError as e:
   81:         raise NoneMetadataError(dist, str(e))
   82:     try:
   83:         is_compatible = check_requires_python(
   84:             requires_python,
   85:             version_info=version_info,
   86:         )
   87:     except specifiers.InvalidSpecifier as exc:
   88:         logger.warning(
   89:             "Package %r has an invalid Requires-Python: %s", dist.raw_name, exc
   90:         )
   91:         return
   92: 
   93:     if is_compatible:
   94:         return
   95: 
   96:     version = ".".join(map(str, version_info))
   97:     if ignore_requires_python:
   98:         logger.debug(
   99:             "Ignoring failed Requires-Python check for package %r: %s not in %r",
  100:             dist.raw_name,
  101:             version,
  102:             requires_python,
  103:         )
  104:         return
  105: 
  106:     raise UnsupportedPythonVersion(
  107:         f"Package {dist.raw_name!r} requires a different Python: "
  108:         f"{version} not in {requires_python!r}"
  109:     )
  110: 
  111: 
  112: class Resolver(BaseResolver):
  113:     """Resolves which packages need to be installed/uninstalled to perform \
  114:     the requested operation without breaking the requirements of any package.
  115:     """
  116: 
  117:     _allowed_strategies = {"eager", "only-if-needed", "to-satisfy-only"}
  118: 
  119:     def __init__(
  120:         self,
  121:         preparer: RequirementPreparer,
  122:         finder: PackageFinder,
  123:         wheel_cache: WheelCache | None,
  124:         make_install_req: InstallRequirementProvider,
  125:         use_user_site: bool,
  126:         ignore_dependencies: bool,
  127:         ignore_installed: bool,
  128:         ignore_requires_python: bool,
  129:         force_reinstall: bool,
  130:         upgrade_strategy: str,
  131:         py_version_info: tuple[int, ...] | None = None,
  132:     ) -> None:
  133:         super().__init__()
  134:         assert upgrade_strategy in self._allowed_strategies
  135: 
  136:         if py_version_info is None:
  137:             py_version_info = sys.version_info[:3]
  138:         else:
  139:             py_version_info = normalize_version_info(py_version_info)
  140: 
  141:         self._py_version_info = py_version_info
  142: 
  143:         self.preparer = preparer
  144:         self.finder = finder
  145:         self.wheel_cache = wheel_cache
  146: 
  147:         self.upgrade_strategy = upgrade_strategy
  148:         self.force_reinstall = force_reinstall
  149:         self.ignore_dependencies = ignore_dependencies
  150:         self.ignore_installed = ignore_installed
  151:         self.ignore_requires_python = ignore_requires_python
  152:         self.use_user_site = use_user_site
  153:         self._make_install_req = make_install_req
  154: 
  155:         self._discovered_dependencies: DiscoveredDependencies = defaultdict(list)
  156: 
  157:     def resolve(
  158:         self, root_reqs: list[InstallRequirement], check_supported_wheels: bool
  159:     ) -> RequirementSet:
  160:         """Resolve what operations need to be done
  161: 
  162:         As a side-effect of this method, the packages (and their dependencies)
  163:         are downloaded, unpacked and prepared for installation. This
  164:         preparation is done by ``pip.operations.prepare``.
  165: 
  166:         Once PyPI has static dependency metadata available, it would be
  167:         possible to move the preparation to become a step separated from
  168:         dependency resolution.
  169:         """
  170:         requirement_set = RequirementSet(check_supported_wheels=check_supported_wheels)
  171:         for req in root_reqs:
  172:             if req.constraint:
  173:                 check_invalid_constraint_type(req)
  174:             self._add_requirement_to_set(requirement_set, req)
  175: 
  176:         # Actually prepare the files, and collect any exceptions. Most hash
  177:         # exceptions cannot be checked ahead of time, because
  178:         # _populate_link() needs to be called before we can make decisions
  179:         # based on link type.
  180:         discovered_reqs: list[InstallRequirement] = []
  181:         hash_errors = HashErrors()
  182:         for req in chain(requirement_set.all_requirements, discovered_reqs):
  183:             try:
  184:                 discovered_reqs.extend(self._resolve_one(requirement_set, req))
  185:             except HashError as exc:
  186:                 exc.req = req
  187:                 hash_errors.append(exc)
  188: 
  189:         if hash_errors:
  190:             raise hash_errors
  191: 
  192:         return requirement_set
  193: 
  194:     def _add_requirement_to_set(
  195:         self,
  196:         requirement_set: RequirementSet,
  197:         install_req: InstallRequirement,
  198:         parent_req_name: str | None = None,
  199:         extras_requested: Iterable[str] | None = None,
  200:     ) -> tuple[list[InstallRequirement], InstallRequirement | None]:
  201:         """Add install_req as a requirement to install.
  202: 
  203:         :param parent_req_name: The name of the requirement that needed this
  204:             added. The name is used because when multiple unnamed requirements
  205:             resolve to the same name, we could otherwise end up with dependency
  206:             links that point outside the Requirements set. parent_req must
  207:             already be added. Note that None implies that this is a user
  208:             supplied requirement, vs an inferred one.
  209:         :param extras_requested: an iterable of extras used to evaluate the
  210:             environment markers.
  211:         :return: Additional requirements to scan. That is either [] if
  212:             the requirement is not applicable, or [install_req] if the
  213:             requirement is applicable and has just been added.
  214:         """
  215:         # If the markers do not match, ignore this requirement.
  216:         if not install_req.match_markers(extras_requested):
  217:             logger.info(
  218:                 "Ignoring %s: markers '%s' don't match your environment",
  219:                 install_req.name,
  220:                 install_req.markers,
  221:             )
  222:             return [], None
  223: 
  224:         # If the wheel is not supported, raise an error.
  225:         # Should check this after filtering out based on environment markers to
  226:         # allow specifying different wheels based on the environment/OS, in a
  227:         # single requirements file.
  228:         if install_req.link and install_req.link.is_wheel:
  229:             wheel = Wheel(install_req.link.filename)
  230:             tags = compatibility_tags.get_supported()
  231:             if requirement_set.check_supported_wheels and not wheel.supported(tags):
  232:                 raise InstallationError(
  233:                     f"{wheel.filename} is not a supported wheel on this platform."
  234:                 )
  235: 
  236:         # This next bit is really a sanity check.
  237:         assert (
  238:             not install_req.user_supplied or parent_req_name is None
  239:         ), "a user supplied req shouldn't have a parent"
  240: 
  241:         # Unnamed requirements are scanned again and the requirement won't be
  242:         # added as a dependency until after scanning.
  243:         if not install_req.name:
  244:             requirement_set.add_unnamed_requirement(install_req)
  245:             return [install_req], None
  246: 
  247:         try:
  248:             existing_req: InstallRequirement | None = requirement_set.get_requirement(
  249:                 install_req.name
  250:             )
  251:         except KeyError:
  252:             existing_req = None
  253: 
  254:         has_conflicting_requirement = (
  255:             parent_req_name is None
  256:             and existing_req
  257:             and not existing_req.constraint
  258:             and existing_req.extras == install_req.extras
  259:             and existing_req.req
  260:             and install_req.req
  261:             and existing_req.req.specifier != install_req.req.specifier
  262:         )
  263:         if has_conflicting_requirement:
  264:             raise InstallationError(
  265:                 f"Double requirement given: {install_req} "
  266:                 f"(already in {existing_req}, name={install_req.name!r})"
  267:             )
  268: 
  269:         # When no existing requirement exists, add the requirement as a
  270:         # dependency and it will be scanned again after.
  271:         if not existing_req:
  272:             requirement_set.add_named_requirement(install_req)
  273:             # We'd want to rescan this requirement later
  274:             return [install_req], install_req
  275: 
  276:         # Assume there's no need to scan, and that we've already
  277:         # encountered this for scanning.
  278:         if install_req.constraint or not existing_req.constraint:
  279:             return [], existing_req
  280: 
  281:         does_not_satisfy_constraint = install_req.link and not (
  282:             existing_req.link and install_req.link.path == existing_req.link.path
  283:         )
  284:         if does_not_satisfy_constraint:
  285:             raise InstallationError(
  286:                 f"Could not satisfy constraints for '{install_req.name}': "
  287:                 "installation from path or url cannot be "
  288:                 "constrained to a version"
  289:             )
  290:         # If we're now installing a constraint, mark the existing
  291:         # object for real installation.
  292:         existing_req.constraint = False
  293:         # If we're now installing a user supplied requirement,
  294:         # mark the existing object as such.
  295:         if install_req.user_supplied:
  296:             existing_req.user_supplied = True
  297:         existing_req.extras = tuple(
  298:             sorted(set(existing_req.extras) | set(install_req.extras))
  299:         )
  300:         logger.debug(
  301:             "Setting %s extras to: %s",
  302:             existing_req,
  303:             existing_req.extras,
  304:         )
  305:         # Return the existing requirement for addition to the parent and
  306:         # scanning again.
  307:         return [existing_req], existing_req
  308: 
  309:     def _is_upgrade_allowed(self, req: InstallRequirement) -> bool:
  310:         if self.upgrade_strategy == "to-satisfy-only":
  311:             return False
  312:         elif self.upgrade_strategy == "eager":
  313:             return True
  314:         else:
  315:             assert self.upgrade_strategy == "only-if-needed"
  316:             return req.user_supplied or req.constraint
  317: 
  318:     def _set_req_to_reinstall(self, req: InstallRequirement) -> None:
  319:         """
  320:         Set a requirement to be installed.
  321:         """
  322:         # Don't uninstall the conflict if doing a user install and the
  323:         # conflict is not a user install.
  324:         assert req.satisfied_by is not None
  325:         if not self.use_user_site or req.satisfied_by.in_usersite:
  326:             req.should_reinstall = True
  327:         req.satisfied_by = None
  328: 
  329:     def _check_skip_installed(self, req_to_install: InstallRequirement) -> str | None:
  330:         """Check if req_to_install should be skipped.
  331: 
  332:         This will check if the req is installed, and whether we should upgrade
  333:         or reinstall it, taking into account all the relevant user options.
  334: 
  335:         After calling this req_to_install will only have satisfied_by set to
  336:         None if the req_to_install is to be upgraded/reinstalled etc. Any
  337:         other value will be a dist recording the current thing installed that
  338:         satisfies the requirement.
  339: 
  340:         Note that for vcs urls and the like we can't assess skipping in this
  341:         routine - we simply identify that we need to pull the thing down,
  342:         then later on it is pulled down and introspected to assess upgrade/
  343:         reinstalls etc.
  344: 
  345:         :return: A text reason for why it was skipped, or None.
  346:         """
  347:         if self.ignore_installed:
  348:             return None
  349: 
  350:         req_to_install.check_if_exists(self.use_user_site)
  351:         if not req_to_install.satisfied_by:
  352:             return None
  353: 
  354:         if self.force_reinstall:
  355:             self._set_req_to_reinstall(req_to_install)
  356:             return None
  357: 
  358:         if not self._is_upgrade_allowed(req_to_install):
  359:             if self.upgrade_strategy == "only-if-needed":
  360:                 return "already satisfied, skipping upgrade"
  361:             return "already satisfied"
  362: 
  363:         # Check for the possibility of an upgrade.  For link-based
  364:         # requirements we have to pull the tree down and inspect to assess
  365:         # the version #, so it's handled way down.
  366:         if not req_to_install.link:
  367:             try:
  368:                 self.finder.find_requirement(req_to_install, upgrade=True)
  369:             except BestVersionAlreadyInstalled:
  370:                 # Then the best version is installed.
  371:                 return "already up-to-date"
  372:             except DistributionNotFound:
  373:                 # No distribution found, so we squash the error.  It will
  374:                 # be raised later when we re-try later to do the install.
  375:                 # Why don't we just raise here?
  376:                 pass
  377: 
  378:         self._set_req_to_reinstall(req_to_install)
  379:         return None
  380: 
  381:     def _find_requirement_link(self, req: InstallRequirement) -> Link | None:
  382:         upgrade = self._is_upgrade_allowed(req)
  383:         best_candidate = self.finder.find_requirement(req, upgrade)
  384:         if not best_candidate:
  385:             return None
  386: 
  387:         # Log a warning per PEP 592 if necessary before returning.
  388:         link = best_candidate.link
  389:         if link.is_yanked:
  390:             reason = link.yanked_reason or "<none given>"
  391:             msg = (
  392:                 # Mark this as a unicode string to prevent
  393:                 # "UnicodeEncodeError: 'ascii' codec can't encode character"
  394:                 # in Python 2 when the reason contains non-ascii characters.
  395:                 "The candidate selected for download or install is a "
  396:                 f"yanked version: {best_candidate}\n"
  397:                 f"Reason for being yanked: {reason}"
  398:             )
  399:             logger.warning(msg)
  400: 
  401:         return link
  402: 
  403:     def _populate_link(self, req: InstallRequirement) -> None:
  404:         """Ensure that if a link can be found for this, that it is found.
  405: 
  406:         Note that req.link may still be None - if the requirement is already
  407:         installed and not needed to be upgraded based on the return value of
  408:         _is_upgrade_allowed().
  409: 
  410:         If preparer.require_hashes is True, don't use the wheel cache, because
  411:         cached wheels, always built locally, have different hashes than the
  412:         files downloaded from the index server and thus throw false hash
  413:         mismatches. Furthermore, cached wheels at present have undeterministic
  414:         contents due to file modification times.
  415:         """
  416:         if req.link is None:
  417:             req.link = self._find_requirement_link(req)
  418: 
  419:         if self.wheel_cache is None or self.preparer.require_hashes:
  420:             return
  421: 
  422:         assert req.link is not None, "_find_requirement_link unexpectedly returned None"
  423:         cache_entry = self.wheel_cache.get_cache_entry(
  424:             link=req.link,
  425:             package_name=req.name,
  426:             supported_tags=get_supported(),
  427:         )
  428:         if cache_entry is not None:
  429:             logger.debug("Using cached wheel link: %s", cache_entry.link)
  430:             if req.link is req.original_link and cache_entry.persistent:
  431:                 req.cached_wheel_source_link = req.link
  432:             if cache_entry.origin is not None:
  433:                 req.download_info = cache_entry.origin
  434:             else:
  435:                 # Legacy cache entry that does not have origin.json.
  436:                 # download_info may miss the archive_info.hashes field.
  437:                 req.download_info = direct_url_from_link(
  438:                     req.link, link_is_in_wheel_cache=cache_entry.persistent
  439:                 )
  440:             req.link = cache_entry.link
  441: 
  442:     def _get_dist_for(self, req: InstallRequirement) -> BaseDistribution:
  443:         """Takes a InstallRequirement and returns a single AbstractDist \
  444:         representing a prepared variant of the same.
  445:         """
  446:         if req.editable:
  447:             return self.preparer.prepare_editable_requirement(req)
  448: 
  449:         # satisfied_by is only evaluated by calling _check_skip_installed,
  450:         # so it must be None here.
  451:         assert req.satisfied_by is None
  452:         skip_reason = self._check_skip_installed(req)
  453: 
  454:         if req.satisfied_by:
  455:             return self.preparer.prepare_installed_requirement(req, skip_reason)
  456: 
  457:         # We eagerly populate the link, since that's our "legacy" behavior.
  458:         self._populate_link(req)
  459:         dist = self.preparer.prepare_linked_requirement(req)
  460: 
  461:         # NOTE
  462:         # The following portion is for determining if a certain package is
  463:         # going to be re-installed/upgraded or not and reporting to the user.
  464:         # This should probably get cleaned up in a future refactor.
  465: 
  466:         # req.req is only avail after unpack for URL
  467:         # pkgs repeat check_if_exists to uninstall-on-upgrade
  468:         # (#14)
  469:         if not self.ignore_installed:
  470:             req.check_if_exists(self.use_user_site)
  471: 
  472:         if req.satisfied_by:
  473:             should_modify = (
  474:                 self.upgrade_strategy != "to-satisfy-only"
  475:                 or self.force_reinstall
  476:                 or self.ignore_installed
  477:                 or req.link.scheme == "file"
  478:             )
  479:             if should_modify:
  480:                 self._set_req_to_reinstall(req)
  481:             else:
  482:                 logger.info(
  483:                     "Requirement already satisfied (use --upgrade to upgrade): %s",
  484:                     req,
  485:                 )
  486:         return dist
  487: 
  488:     def _resolve_one(
  489:         self,
  490:         requirement_set: RequirementSet,
  491:         req_to_install: InstallRequirement,
  492:     ) -> list[InstallRequirement]:
  493:         """Prepare a single requirements file.
  494: 
  495:         :return: A list of additional InstallRequirements to also install.
  496:         """
  497:         # Tell user what we are doing for this requirement:
  498:         # obtain (editable), skipping, processing (local url), collecting
  499:         # (remote url or package name)
  500:         if req_to_install.constraint or req_to_install.prepared:
  501:             return []
  502: 
  503:         req_to_install.prepared = True
  504: 
  505:         # Parse and return dependencies
  506:         dist = self._get_dist_for(req_to_install)
  507:         # This will raise UnsupportedPythonVersion if the given Python
  508:         # version isn't compatible with the distribution's Requires-Python.
  509:         _check_dist_requires_python(
  510:             dist,
  511:             version_info=self._py_version_info,
  512:             ignore_requires_python=self.ignore_requires_python,
  513:         )
  514: 
  515:         more_reqs: list[InstallRequirement] = []
  516: 
  517:         def add_req(subreq: Requirement, extras_requested: Iterable[str]) -> None:
  518:             # This idiosyncratically converts the Requirement to str and let
  519:             # make_install_req then parse it again into Requirement. But this is
  520:             # the legacy resolver so I'm just not going to bother refactoring.
  521:             sub_install_req = self._make_install_req(str(subreq), req_to_install)
  522:             parent_req_name = req_to_install.name
  523:             to_scan_again, add_to_parent = self._add_requirement_to_set(
  524:                 requirement_set,
  525:                 sub_install_req,
  526:                 parent_req_name=parent_req_name,
  527:                 extras_requested=extras_requested,
  528:             )
  529:             if parent_req_name and add_to_parent:
  530:                 self._discovered_dependencies[parent_req_name].append(add_to_parent)
  531:             more_reqs.extend(to_scan_again)
  532: 
  533:         with indent_log():
  534:             # We add req_to_install before its dependencies, so that we
  535:             # can refer to it when adding dependencies.
  536:             assert req_to_install.name is not None
  537:             if not requirement_set.has_requirement(req_to_install.name):
  538:                 # 'unnamed' requirements will get added here
  539:                 # 'unnamed' requirements can only come from being directly
  540:                 # provided by the user.
  541:                 assert req_to_install.user_supplied
  542:                 self._add_requirement_to_set(
  543:                     requirement_set, req_to_install, parent_req_name=None
  544:                 )
  545: 
  546:             if not self.ignore_dependencies:
  547:                 if req_to_install.extras:
  548:                     logger.debug(
  549:                         "Installing extra requirements: %r",
  550:                         ",".join(req_to_install.extras),
  551:                     )
  552:                 missing_requested = sorted(
  553:                     set(req_to_install.extras) - set(dist.iter_provided_extras())
  554:                 )
  555:                 for missing in missing_requested:
  556:                     logger.warning(
  557:                         "%s %s does not provide the extra '%s'",
  558:                         dist.raw_name,
  559:                         dist.version,
  560:                         missing,
  561:                     )
  562: 
  563:                 available_requested = sorted(
  564:                     set(dist.iter_provided_extras()) & set(req_to_install.extras)
  565:                 )
  566:                 for subreq in dist.iter_dependencies(available_requested):
  567:                     add_req(subreq, extras_requested=available_requested)
  568: 
  569:         return more_reqs
  570: 
  571:     def get_installation_order(
  572:         self, req_set: RequirementSet
  573:     ) -> list[InstallRequirement]:
  574:         """Create the installation order.
  575: 
  576:         The installation order is topological - requirements are installed
  577:         before the requiring thing. We break cycles at an arbitrary point,
  578:         and make no other guarantees.
  579:         """
  580:         # The current implementation, which we may change at any point
  581:         # installs the user specified things in the order given, except when
  582:         # dependencies must come earlier to achieve topological order.
  583:         order = []
  584:         ordered_reqs: set[InstallRequirement] = set()
  585: 
  586:         def schedule(req: InstallRequirement) -> None:
  587:             if req.satisfied_by or req in ordered_reqs:
  588:                 return
  589:             if req.constraint:
  590:                 return
  591:             ordered_reqs.add(req)
  592:             for dep in self._discovered_dependencies[req.name]:
  593:                 schedule(dep)
  594:             order.append(req)
  595: 
  596:         for install_req in req_set.requirements.values():
  597:             schedule(install_req)
  598:         return order
