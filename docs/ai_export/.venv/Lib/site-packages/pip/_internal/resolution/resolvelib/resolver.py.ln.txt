    1: from __future__ import annotations
    2: 
    3: import contextlib
    4: import functools
    5: import logging
    6: import os
    7: from typing import TYPE_CHECKING, cast
    8: 
    9: from pip._vendor.packaging.utils import canonicalize_name
   10: from pip._vendor.resolvelib import BaseReporter, ResolutionImpossible, ResolutionTooDeep
   11: from pip._vendor.resolvelib import Resolver as RLResolver
   12: from pip._vendor.resolvelib.structs import DirectedGraph
   13: 
   14: from pip._internal.cache import WheelCache
   15: from pip._internal.exceptions import ResolutionTooDeepError
   16: from pip._internal.index.package_finder import PackageFinder
   17: from pip._internal.operations.prepare import RequirementPreparer
   18: from pip._internal.req.constructors import install_req_extend_extras
   19: from pip._internal.req.req_install import InstallRequirement
   20: from pip._internal.req.req_set import RequirementSet
   21: from pip._internal.resolution.base import BaseResolver, InstallRequirementProvider
   22: from pip._internal.resolution.resolvelib.provider import PipProvider
   23: from pip._internal.resolution.resolvelib.reporter import (
   24:     PipDebuggingReporter,
   25:     PipReporter,
   26: )
   27: from pip._internal.utils.packaging import get_requirement
   28: 
   29: from .base import Candidate, Requirement
   30: from .factory import Factory
   31: 
   32: if TYPE_CHECKING:
   33:     from pip._vendor.resolvelib.resolvers import Result as RLResult
   34: 
   35:     Result = RLResult[Requirement, Candidate, str]
   36: 
   37: 
   38: logger = logging.getLogger(__name__)
   39: 
   40: 
   41: class Resolver(BaseResolver):
   42:     _allowed_strategies = {"eager", "only-if-needed", "to-satisfy-only"}
   43: 
   44:     def __init__(
   45:         self,
   46:         preparer: RequirementPreparer,
   47:         finder: PackageFinder,
   48:         wheel_cache: WheelCache | None,
   49:         make_install_req: InstallRequirementProvider,
   50:         use_user_site: bool,
   51:         ignore_dependencies: bool,
   52:         ignore_installed: bool,
   53:         ignore_requires_python: bool,
   54:         force_reinstall: bool,
   55:         upgrade_strategy: str,
   56:         py_version_info: tuple[int, ...] | None = None,
   57:     ):
   58:         super().__init__()
   59:         assert upgrade_strategy in self._allowed_strategies
   60: 
   61:         self.factory = Factory(
   62:             finder=finder,
   63:             preparer=preparer,
   64:             make_install_req=make_install_req,
   65:             wheel_cache=wheel_cache,
   66:             use_user_site=use_user_site,
   67:             force_reinstall=force_reinstall,
   68:             ignore_installed=ignore_installed,
   69:             ignore_requires_python=ignore_requires_python,
   70:             py_version_info=py_version_info,
   71:         )
   72:         self.ignore_dependencies = ignore_dependencies
   73:         self.upgrade_strategy = upgrade_strategy
   74:         self._result: Result | None = None
   75: 
   76:     def resolve(
   77:         self, root_reqs: list[InstallRequirement], check_supported_wheels: bool
   78:     ) -> RequirementSet:
   79:         collected = self.factory.collect_root_requirements(root_reqs)
   80:         provider = PipProvider(
   81:             factory=self.factory,
   82:             constraints=collected.constraints,
   83:             ignore_dependencies=self.ignore_dependencies,
   84:             upgrade_strategy=self.upgrade_strategy,
   85:             user_requested=collected.user_requested,
   86:         )
   87:         if "PIP_RESOLVER_DEBUG" in os.environ:
   88:             reporter: BaseReporter[Requirement, Candidate, str] = PipDebuggingReporter()
   89:         else:
   90:             reporter = PipReporter()
   91:         resolver: RLResolver[Requirement, Candidate, str] = RLResolver(
   92:             provider,
   93:             reporter,
   94:         )
   95: 
   96:         try:
   97:             limit_how_complex_resolution_can_be = 200000
   98:             result = self._result = resolver.resolve(
   99:                 collected.requirements, max_rounds=limit_how_complex_resolution_can_be
  100:             )
  101: 
  102:         except ResolutionImpossible as e:
  103:             error = self.factory.get_installation_error(
  104:                 cast("ResolutionImpossible[Requirement, Candidate]", e),
  105:                 collected.constraints,
  106:             )
  107:             raise error from e
  108:         except ResolutionTooDeep:
  109:             raise ResolutionTooDeepError from None
  110: 
  111:         req_set = RequirementSet(check_supported_wheels=check_supported_wheels)
  112:         # process candidates with extras last to ensure their base equivalent is
  113:         # already in the req_set if appropriate.
  114:         # Python's sort is stable so using a binary key function keeps relative order
  115:         # within both subsets.
  116:         for candidate in sorted(
  117:             result.mapping.values(), key=lambda c: c.name != c.project_name
  118:         ):
  119:             ireq = candidate.get_install_requirement()
  120:             if ireq is None:
  121:                 if candidate.name != candidate.project_name:
  122:                     # extend existing req's extras
  123:                     with contextlib.suppress(KeyError):
  124:                         req = req_set.get_requirement(candidate.project_name)
  125:                         req_set.add_named_requirement(
  126:                             install_req_extend_extras(
  127:                                 req, get_requirement(candidate.name).extras
  128:                             )
  129:                         )
  130:                 continue
  131: 
  132:             # Check if there is already an installation under the same name,
  133:             # and set a flag for later stages to uninstall it, if needed.
  134:             installed_dist = self.factory.get_dist_to_uninstall(candidate)
  135:             if installed_dist is None:
  136:                 # There is no existing installation -- nothing to uninstall.
  137:                 ireq.should_reinstall = False
  138:             elif self.factory.force_reinstall:
  139:                 # The --force-reinstall flag is set -- reinstall.
  140:                 ireq.should_reinstall = True
  141:             elif installed_dist.version != candidate.version:
  142:                 # The installation is different in version -- reinstall.
  143:                 ireq.should_reinstall = True
  144:             elif candidate.is_editable or installed_dist.editable:
  145:                 # The incoming distribution is editable, or different in
  146:                 # editable-ness to installation -- reinstall.
  147:                 ireq.should_reinstall = True
  148:             elif candidate.source_link and candidate.source_link.is_file:
  149:                 # The incoming distribution is under file://
  150:                 if candidate.source_link.is_wheel:
  151:                     # is a local wheel -- do nothing.
  152:                     logger.info(
  153:                         "%s is already installed with the same version as the "
  154:                         "provided wheel. Use --force-reinstall to force an "
  155:                         "installation of the wheel.",
  156:                         ireq.name,
  157:                     )
  158:                     continue
  159: 
  160:                 # is a local sdist or path -- reinstall
  161:                 ireq.should_reinstall = True
  162:             else:
  163:                 continue
  164: 
  165:             link = candidate.source_link
  166:             if link and link.is_yanked:
  167:                 # The reason can contain non-ASCII characters, Unicode
  168:                 # is required for Python 2.
  169:                 msg = (
  170:                     "The candidate selected for download or install is a "
  171:                     "yanked version: {name!r} candidate (version {version} "
  172:                     "at {link})\nReason for being yanked: {reason}"
  173:                 ).format(
  174:                     name=candidate.name,
  175:                     version=candidate.version,
  176:                     link=link,
  177:                     reason=link.yanked_reason or "<none given>",
  178:                 )
  179:                 logger.warning(msg)
  180: 
  181:             req_set.add_named_requirement(ireq)
  182: 
  183:         reqs = req_set.all_requirements
  184:         self.factory.preparer.prepare_linked_requirements_more(reqs)
  185:         for req in reqs:
  186:             req.prepared = True
  187:             req.needs_more_preparation = False
  188:         return req_set
  189: 
  190:     def get_installation_order(
  191:         self, req_set: RequirementSet
  192:     ) -> list[InstallRequirement]:
  193:         """Get order for installation of requirements in RequirementSet.
  194: 
  195:         The returned list contains a requirement before another that depends on
  196:         it. This helps ensure that the environment is kept consistent as they
  197:         get installed one-by-one.
  198: 
  199:         The current implementation creates a topological ordering of the
  200:         dependency graph, giving more weight to packages with less
  201:         or no dependencies, while breaking any cycles in the graph at
  202:         arbitrary points. We make no guarantees about where the cycle
  203:         would be broken, other than it *would* be broken.
  204:         """
  205:         assert self._result is not None, "must call resolve() first"
  206: 
  207:         if not req_set.requirements:
  208:             # Nothing is left to install, so we do not need an order.
  209:             return []
  210: 
  211:         graph = self._result.graph
  212:         weights = get_topological_weights(graph, set(req_set.requirements.keys()))
  213: 
  214:         sorted_items = sorted(
  215:             req_set.requirements.items(),
  216:             key=functools.partial(_req_set_item_sorter, weights=weights),
  217:             reverse=True,
  218:         )
  219:         return [ireq for _, ireq in sorted_items]
  220: 
  221: 
  222: def get_topological_weights(
  223:     graph: DirectedGraph[str | None], requirement_keys: set[str]
  224: ) -> dict[str | None, int]:
  225:     """Assign weights to each node based on how "deep" they are.
  226: 
  227:     This implementation may change at any point in the future without prior
  228:     notice.
  229: 
  230:     We first simplify the dependency graph by pruning any leaves and giving them
  231:     the highest weight: a package without any dependencies should be installed
  232:     first. This is done again and again in the same way, giving ever less weight
  233:     to the newly found leaves. The loop stops when no leaves are left: all
  234:     remaining packages have at least one dependency left in the graph.
  235: 
  236:     Then we continue with the remaining graph, by taking the length for the
  237:     longest path to any node from root, ignoring any paths that contain a single
  238:     node twice (i.e. cycles). This is done through a depth-first search through
  239:     the graph, while keeping track of the path to the node.
  240: 
  241:     Cycles in the graph result would result in node being revisited while also
  242:     being on its own path. In this case, take no action. This helps ensure we
  243:     don't get stuck in a cycle.
  244: 
  245:     When assigning weight, the longer path (i.e. larger length) is preferred.
  246: 
  247:     We are only interested in the weights of packages that are in the
  248:     requirement_keys.
  249:     """
  250:     path: set[str | None] = set()
  251:     weights: dict[str | None, list[int]] = {}
  252: 
  253:     def visit(node: str | None) -> None:
  254:         if node in path:
  255:             # We hit a cycle, so we'll break it here.
  256:             return
  257: 
  258:         # The walk is exponential and for pathologically connected graphs (which
  259:         # are the ones most likely to contain cycles in the first place) it can
  260:         # take until the heat-death of the universe. To counter this we limit
  261:         # the number of attempts to visit (i.e. traverse through) any given
  262:         # node. We choose a value here which gives decent enough coverage for
  263:         # fairly well behaved graphs, and still limits the walk complexity to be
  264:         # linear in nature.
  265:         cur_weights = weights.get(node, [])
  266:         if len(cur_weights) >= 5:
  267:             return
  268: 
  269:         # Time to visit the children!
  270:         path.add(node)
  271:         for child in graph.iter_children(node):
  272:             visit(child)
  273:         path.remove(node)
  274: 
  275:         if node not in requirement_keys:
  276:             return
  277: 
  278:         cur_weights.append(len(path))
  279:         weights[node] = cur_weights
  280: 
  281:     # Simplify the graph, pruning leaves that have no dependencies. This is
  282:     # needed for large graphs (say over 200 packages) because the `visit`
  283:     # function is slower for large/densely connected graphs, taking minutes.
  284:     # See https://github.com/pypa/pip/issues/10557
  285:     # We repeat the pruning step until we have no more leaves to remove.
  286:     while True:
  287:         leaves = set()
  288:         for key in graph:
  289:             if key is None:
  290:                 continue
  291:             for _child in graph.iter_children(key):
  292:                 # This means we have at least one child
  293:                 break
  294:             else:
  295:                 # No child.
  296:                 leaves.add(key)
  297:         if not leaves:
  298:             # We are done simplifying.
  299:             break
  300:         # Calculate the weight for the leaves.
  301:         weight = len(graph) - 1
  302:         for leaf in leaves:
  303:             if leaf not in requirement_keys:
  304:                 continue
  305:             weights[leaf] = [weight]
  306:         # Remove the leaves from the graph, making it simpler.
  307:         for leaf in leaves:
  308:             graph.remove(leaf)
  309: 
  310:     # Visit the remaining graph, this will only have nodes to handle if the
  311:     # graph had a cycle in it, which the pruning step above could not handle.
  312:     # `None` is guaranteed to be the root node by resolvelib.
  313:     visit(None)
  314: 
  315:     # Sanity check: all requirement keys should be in the weights,
  316:     # and no other keys should be in the weights.
  317:     difference = set(weights.keys()).difference(requirement_keys)
  318:     assert not difference, difference
  319: 
  320:     # Now give back all the weights, choosing the largest ones from what we
  321:     # accumulated.
  322:     return {node: max(wgts) for (node, wgts) in weights.items()}
  323: 
  324: 
  325: def _req_set_item_sorter(
  326:     item: tuple[str, InstallRequirement],
  327:     weights: dict[str | None, int],
  328: ) -> tuple[int, str]:
  329:     """Key function used to sort install requirements for installation.
  330: 
  331:     Based on the "weight" mapping calculated in ``get_installation_order()``.
  332:     The canonical package name is returned as the second member as a tie-
  333:     breaker to ensure the result is predictable, which is useful in tests.
  334:     """
  335:     name = canonicalize_name(item[0])
  336:     return weights[name], name
