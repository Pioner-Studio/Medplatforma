    1: """PipSession and supporting code, containing all pip-specific
    2: network request configuration and behavior.
    3: """
    4: 
    5: from __future__ import annotations
    6: 
    7: import email.utils
    8: import functools
    9: import io
   10: import ipaddress
   11: import json
   12: import logging
   13: import mimetypes
   14: import os
   15: import platform
   16: import shutil
   17: import subprocess
   18: import sys
   19: import urllib.parse
   20: import warnings
   21: from collections.abc import Generator, Mapping, Sequence
   22: from typing import (
   23:     TYPE_CHECKING,
   24:     Any,
   25:     Optional,
   26:     Union,
   27: )
   28: 
   29: from pip._vendor import requests, urllib3
   30: from pip._vendor.cachecontrol import CacheControlAdapter as _BaseCacheControlAdapter
   31: from pip._vendor.requests.adapters import DEFAULT_POOLBLOCK, BaseAdapter
   32: from pip._vendor.requests.adapters import HTTPAdapter as _BaseHTTPAdapter
   33: from pip._vendor.requests.models import PreparedRequest, Response
   34: from pip._vendor.requests.structures import CaseInsensitiveDict
   35: from pip._vendor.urllib3.connectionpool import ConnectionPool
   36: from pip._vendor.urllib3.exceptions import InsecureRequestWarning
   37: 
   38: from pip import __version__
   39: from pip._internal.metadata import get_default_environment
   40: from pip._internal.models.link import Link
   41: from pip._internal.network.auth import MultiDomainBasicAuth
   42: from pip._internal.network.cache import SafeFileCache
   43: 
   44: # Import ssl from compat so the initial import occurs in only one place.
   45: from pip._internal.utils.compat import has_tls
   46: from pip._internal.utils.glibc import libc_ver
   47: from pip._internal.utils.misc import build_url_from_netloc, parse_netloc
   48: from pip._internal.utils.urls import url_to_path
   49: 
   50: if TYPE_CHECKING:
   51:     from ssl import SSLContext
   52: 
   53:     from pip._vendor.urllib3.poolmanager import PoolManager
   54:     from pip._vendor.urllib3.proxymanager import ProxyManager
   55: 
   56: 
   57: logger = logging.getLogger(__name__)
   58: 
   59: SecureOrigin = tuple[str, str, Optional[Union[int, str]]]
   60: 
   61: 
   62: # Ignore warning raised when using --trusted-host.
   63: warnings.filterwarnings("ignore", category=InsecureRequestWarning)
   64: 
   65: 
   66: SECURE_ORIGINS: list[SecureOrigin] = [
   67:     # protocol, hostname, port
   68:     # Taken from Chrome's list of secure origins (See: http://bit.ly/1qrySKC)
   69:     ("https", "*", "*"),
   70:     ("*", "localhost", "*"),
   71:     ("*", "127.0.0.0/8", "*"),
   72:     ("*", "::1/128", "*"),
   73:     ("file", "*", None),
   74:     # ssh is always secure.
   75:     ("ssh", "*", "*"),
   76: ]
   77: 
   78: 
   79: # These are environment variables present when running under various
   80: # CI systems.  For each variable, some CI systems that use the variable
   81: # are indicated.  The collection was chosen so that for each of a number
   82: # of popular systems, at least one of the environment variables is used.
   83: # This list is used to provide some indication of and lower bound for
   84: # CI traffic to PyPI.  Thus, it is okay if the list is not comprehensive.
   85: # For more background, see: https://github.com/pypa/pip/issues/5499
   86: CI_ENVIRONMENT_VARIABLES = (
   87:     # Azure Pipelines
   88:     "BUILD_BUILDID",
   89:     # Jenkins
   90:     "BUILD_ID",
   91:     # AppVeyor, CircleCI, Codeship, Gitlab CI, Shippable, Travis CI
   92:     "CI",
   93:     # Explicit environment variable.
   94:     "PIP_IS_CI",
   95: )
   96: 
   97: 
   98: def looks_like_ci() -> bool:
   99:     """
  100:     Return whether it looks like pip is running under CI.
  101:     """
  102:     # We don't use the method of checking for a tty (e.g. using isatty())
  103:     # because some CI systems mimic a tty (e.g. Travis CI).  Thus that
  104:     # method doesn't provide definitive information in either direction.
  105:     return any(name in os.environ for name in CI_ENVIRONMENT_VARIABLES)
  106: 
  107: 
  108: @functools.lru_cache(maxsize=1)
  109: def user_agent() -> str:
  110:     """
  111:     Return a string representing the user agent.
  112:     """
  113:     data: dict[str, Any] = {
  114:         "installer": {"name": "pip", "version": __version__},
  115:         "python": platform.python_version(),
  116:         "implementation": {
  117:             "name": platform.python_implementation(),
  118:         },
  119:     }
  120: 
  121:     if data["implementation"]["name"] == "CPython":
  122:         data["implementation"]["version"] = platform.python_version()
  123:     elif data["implementation"]["name"] == "PyPy":
  124:         pypy_version_info = sys.pypy_version_info  # type: ignore
  125:         if pypy_version_info.releaselevel == "final":
  126:             pypy_version_info = pypy_version_info[:3]
  127:         data["implementation"]["version"] = ".".join(
  128:             [str(x) for x in pypy_version_info]
  129:         )
  130:     elif data["implementation"]["name"] == "Jython":
  131:         # Complete Guess
  132:         data["implementation"]["version"] = platform.python_version()
  133:     elif data["implementation"]["name"] == "IronPython":
  134:         # Complete Guess
  135:         data["implementation"]["version"] = platform.python_version()
  136: 
  137:     if sys.platform.startswith("linux"):
  138:         from pip._vendor import distro
  139: 
  140:         linux_distribution = distro.name(), distro.version(), distro.codename()
  141:         distro_infos: dict[str, Any] = dict(
  142:             filter(
  143:                 lambda x: x[1],
  144:                 zip(["name", "version", "id"], linux_distribution),
  145:             )
  146:         )
  147:         libc = dict(
  148:             filter(
  149:                 lambda x: x[1],
  150:                 zip(["lib", "version"], libc_ver()),
  151:             )
  152:         )
  153:         if libc:
  154:             distro_infos["libc"] = libc
  155:         if distro_infos:
  156:             data["distro"] = distro_infos
  157: 
  158:     if sys.platform.startswith("darwin") and platform.mac_ver()[0]:
  159:         data["distro"] = {"name": "macOS", "version": platform.mac_ver()[0]}
  160: 
  161:     if platform.system():
  162:         data.setdefault("system", {})["name"] = platform.system()
  163: 
  164:     if platform.release():
  165:         data.setdefault("system", {})["release"] = platform.release()
  166: 
  167:     if platform.machine():
  168:         data["cpu"] = platform.machine()
  169: 
  170:     if has_tls():
  171:         import _ssl as ssl
  172: 
  173:         data["openssl_version"] = ssl.OPENSSL_VERSION
  174: 
  175:     setuptools_dist = get_default_environment().get_distribution("setuptools")
  176:     if setuptools_dist is not None:
  177:         data["setuptools_version"] = str(setuptools_dist.version)
  178: 
  179:     if shutil.which("rustc") is not None:
  180:         # If for any reason `rustc --version` fails, silently ignore it
  181:         try:
  182:             rustc_output = subprocess.check_output(
  183:                 ["rustc", "--version"], stderr=subprocess.STDOUT, timeout=0.5
  184:             )
  185:         except Exception:
  186:             pass
  187:         else:
  188:             if rustc_output.startswith(b"rustc "):
  189:                 # The format of `rustc --version` is:
  190:                 # `b'rustc 1.52.1 (9bc8c42bb 2021-05-09)\n'`
  191:                 # We extract just the middle (1.52.1) part
  192:                 data["rustc_version"] = rustc_output.split(b" ")[1].decode()
  193: 
  194:     # Use None rather than False so as not to give the impression that
  195:     # pip knows it is not being run under CI.  Rather, it is a null or
  196:     # inconclusive result.  Also, we include some value rather than no
  197:     # value to make it easier to know that the check has been run.
  198:     data["ci"] = True if looks_like_ci() else None
  199: 
  200:     user_data = os.environ.get("PIP_USER_AGENT_USER_DATA")
  201:     if user_data is not None:
  202:         data["user_data"] = user_data
  203: 
  204:     return "{data[installer][name]}/{data[installer][version]} {json}".format(
  205:         data=data,
  206:         json=json.dumps(data, separators=(",", ":"), sort_keys=True),
  207:     )
  208: 
  209: 
  210: class LocalFSAdapter(BaseAdapter):
  211:     def send(
  212:         self,
  213:         request: PreparedRequest,
  214:         stream: bool = False,
  215:         timeout: float | tuple[float, float] | None = None,
  216:         verify: bool | str = True,
  217:         cert: str | tuple[str, str] | None = None,
  218:         proxies: Mapping[str, str] | None = None,
  219:     ) -> Response:
  220:         pathname = url_to_path(request.url)
  221: 
  222:         resp = Response()
  223:         resp.status_code = 200
  224:         resp.url = request.url
  225: 
  226:         try:
  227:             stats = os.stat(pathname)
  228:         except OSError as exc:
  229:             # format the exception raised as a io.BytesIO object,
  230:             # to return a better error message:
  231:             resp.status_code = 404
  232:             resp.reason = type(exc).__name__
  233:             resp.raw = io.BytesIO(f"{resp.reason}: {exc}".encode())
  234:         else:
  235:             modified = email.utils.formatdate(stats.st_mtime, usegmt=True)
  236:             content_type = mimetypes.guess_type(pathname)[0] or "text/plain"
  237:             resp.headers = CaseInsensitiveDict(
  238:                 {
  239:                     "Content-Type": content_type,
  240:                     "Content-Length": stats.st_size,
  241:                     "Last-Modified": modified,
  242:                 }
  243:             )
  244: 
  245:             resp.raw = open(pathname, "rb")
  246:             resp.close = resp.raw.close
  247: 
  248:         return resp
  249: 
  250:     def close(self) -> None:
  251:         pass
  252: 
  253: 
  254: class _SSLContextAdapterMixin:
  255:     """Mixin to add the ``ssl_context`` constructor argument to HTTP adapters.
  256: 
  257:     The additional argument is forwarded directly to the pool manager. This allows us
  258:     to dynamically decide what SSL store to use at runtime, which is used to implement
  259:     the optional ``truststore`` backend.
  260:     """
  261: 
  262:     def __init__(
  263:         self,
  264:         *,
  265:         ssl_context: SSLContext | None = None,
  266:         **kwargs: Any,
  267:     ) -> None:
  268:         self._ssl_context = ssl_context
  269:         super().__init__(**kwargs)
  270: 
  271:     def init_poolmanager(
  272:         self,
  273:         connections: int,
  274:         maxsize: int,
  275:         block: bool = DEFAULT_POOLBLOCK,
  276:         **pool_kwargs: Any,
  277:     ) -> PoolManager:
  278:         if self._ssl_context is not None:
  279:             pool_kwargs.setdefault("ssl_context", self._ssl_context)
  280:         return super().init_poolmanager(  # type: ignore[misc]
  281:             connections=connections,
  282:             maxsize=maxsize,
  283:             block=block,
  284:             **pool_kwargs,
  285:         )
  286: 
  287:     def proxy_manager_for(self, proxy: str, **proxy_kwargs: Any) -> ProxyManager:
  288:         # Proxy manager replaces the pool manager, so inject our SSL
  289:         # context here too. https://github.com/pypa/pip/issues/13288
  290:         if self._ssl_context is not None:
  291:             proxy_kwargs.setdefault("ssl_context", self._ssl_context)
  292:         return super().proxy_manager_for(proxy, **proxy_kwargs)  # type: ignore[misc]
  293: 
  294: 
  295: class HTTPAdapter(_SSLContextAdapterMixin, _BaseHTTPAdapter):
  296:     pass
  297: 
  298: 
  299: class CacheControlAdapter(_SSLContextAdapterMixin, _BaseCacheControlAdapter):
  300:     pass
  301: 
  302: 
  303: class InsecureHTTPAdapter(HTTPAdapter):
  304:     def cert_verify(
  305:         self,
  306:         conn: ConnectionPool,
  307:         url: str,
  308:         verify: bool | str,
  309:         cert: str | tuple[str, str] | None,
  310:     ) -> None:
  311:         super().cert_verify(conn=conn, url=url, verify=False, cert=cert)
  312: 
  313: 
  314: class InsecureCacheControlAdapter(CacheControlAdapter):
  315:     def cert_verify(
  316:         self,
  317:         conn: ConnectionPool,
  318:         url: str,
  319:         verify: bool | str,
  320:         cert: str | tuple[str, str] | None,
  321:     ) -> None:
  322:         super().cert_verify(conn=conn, url=url, verify=False, cert=cert)
  323: 
  324: 
  325: class PipSession(requests.Session):
  326:     timeout: int | None = None
  327: 
  328:     def __init__(
  329:         self,
  330:         *args: Any,
  331:         retries: int = 0,
  332:         cache: str | None = None,
  333:         trusted_hosts: Sequence[str] = (),
  334:         index_urls: list[str] | None = None,
  335:         ssl_context: SSLContext | None = None,
  336:         **kwargs: Any,
  337:     ) -> None:
  338:         """
  339:         :param trusted_hosts: Domains not to emit warnings for when not using
  340:             HTTPS.
  341:         """
  342:         super().__init__(*args, **kwargs)
  343: 
  344:         # Namespace the attribute with "pip_" just in case to prevent
  345:         # possible conflicts with the base class.
  346:         self.pip_trusted_origins: list[tuple[str, int | None]] = []
  347:         self.pip_proxy = None
  348: 
  349:         # Attach our User Agent to the request
  350:         self.headers["User-Agent"] = user_agent()
  351: 
  352:         # Attach our Authentication handler to the session
  353:         self.auth = MultiDomainBasicAuth(index_urls=index_urls)
  354: 
  355:         # Create our urllib3.Retry instance which will allow us to customize
  356:         # how we handle retries.
  357:         retries = urllib3.Retry(
  358:             # Set the total number of retries that a particular request can
  359:             # have.
  360:             total=retries,
  361:             # A 503 error from PyPI typically means that the Fastly -> Origin
  362:             # connection got interrupted in some way. A 503 error in general
  363:             # is typically considered a transient error so we'll go ahead and
  364:             # retry it.
  365:             # A 500 may indicate transient error in Amazon S3
  366:             # A 502 may be a transient error from a CDN like CloudFlare or CloudFront
  367:             # A 520 or 527 - may indicate transient error in CloudFlare
  368:             status_forcelist=[500, 502, 503, 520, 527],
  369:             # Add a small amount of back off between failed requests in
  370:             # order to prevent hammering the service.
  371:             backoff_factor=0.25,
  372:         )  # type: ignore
  373: 
  374:         # Our Insecure HTTPAdapter disables HTTPS validation. It does not
  375:         # support caching so we'll use it for all http:// URLs.
  376:         # If caching is disabled, we will also use it for
  377:         # https:// hosts that we've marked as ignoring
  378:         # TLS errors for (trusted-hosts).
  379:         insecure_adapter = InsecureHTTPAdapter(max_retries=retries)
  380: 
  381:         # We want to _only_ cache responses on securely fetched origins or when
  382:         # the host is specified as trusted. We do this because
  383:         # we can't validate the response of an insecurely/untrusted fetched
  384:         # origin, and we don't want someone to be able to poison the cache and
  385:         # require manual eviction from the cache to fix it.
  386:         if cache:
  387:             secure_adapter = CacheControlAdapter(
  388:                 cache=SafeFileCache(cache),
  389:                 max_retries=retries,
  390:                 ssl_context=ssl_context,
  391:             )
  392:             self._trusted_host_adapter = InsecureCacheControlAdapter(
  393:                 cache=SafeFileCache(cache),
  394:                 max_retries=retries,
  395:             )
  396:         else:
  397:             secure_adapter = HTTPAdapter(max_retries=retries, ssl_context=ssl_context)
  398:             self._trusted_host_adapter = insecure_adapter
  399: 
  400:         self.mount("https://", secure_adapter)
  401:         self.mount("http://", insecure_adapter)
  402: 
  403:         # Enable file:// urls
  404:         self.mount("file://", LocalFSAdapter())
  405: 
  406:         for host in trusted_hosts:
  407:             self.add_trusted_host(host, suppress_logging=True)
  408: 
  409:     def update_index_urls(self, new_index_urls: list[str]) -> None:
  410:         """
  411:         :param new_index_urls: New index urls to update the authentication
  412:             handler with.
  413:         """
  414:         self.auth.index_urls = new_index_urls
  415: 
  416:     def add_trusted_host(
  417:         self, host: str, source: str | None = None, suppress_logging: bool = False
  418:     ) -> None:
  419:         """
  420:         :param host: It is okay to provide a host that has previously been
  421:             added.
  422:         :param source: An optional source string, for logging where the host
  423:             string came from.
  424:         """
  425:         if not suppress_logging:
  426:             msg = f"adding trusted host: {host!r}"
  427:             if source is not None:
  428:                 msg += f" (from {source})"
  429:             logger.info(msg)
  430: 
  431:         parsed_host, parsed_port = parse_netloc(host)
  432:         if parsed_host is None:
  433:             raise ValueError(f"Trusted host URL must include a host part: {host!r}")
  434:         if (parsed_host, parsed_port) not in self.pip_trusted_origins:
  435:             self.pip_trusted_origins.append((parsed_host, parsed_port))
  436: 
  437:         self.mount(
  438:             build_url_from_netloc(host, scheme="http") + "/", self._trusted_host_adapter
  439:         )
  440:         self.mount(build_url_from_netloc(host) + "/", self._trusted_host_adapter)
  441:         if not parsed_port:
  442:             self.mount(
  443:                 build_url_from_netloc(host, scheme="http") + ":",
  444:                 self._trusted_host_adapter,
  445:             )
  446:             # Mount wildcard ports for the same host.
  447:             self.mount(build_url_from_netloc(host) + ":", self._trusted_host_adapter)
  448: 
  449:     def iter_secure_origins(self) -> Generator[SecureOrigin, None, None]:
  450:         yield from SECURE_ORIGINS
  451:         for host, port in self.pip_trusted_origins:
  452:             yield ("*", host, "*" if port is None else port)
  453: 
  454:     def is_secure_origin(self, location: Link) -> bool:
  455:         # Determine if this url used a secure transport mechanism
  456:         parsed = urllib.parse.urlparse(str(location))
  457:         origin_protocol, origin_host, origin_port = (
  458:             parsed.scheme,
  459:             parsed.hostname,
  460:             parsed.port,
  461:         )
  462: 
  463:         # The protocol to use to see if the protocol matches.
  464:         # Don't count the repository type as part of the protocol: in
  465:         # cases such as "git+ssh", only use "ssh". (I.e., Only verify against
  466:         # the last scheme.)
  467:         origin_protocol = origin_protocol.rsplit("+", 1)[-1]
  468: 
  469:         # Determine if our origin is a secure origin by looking through our
  470:         # hardcoded list of secure origins, as well as any additional ones
  471:         # configured on this PackageFinder instance.
  472:         for secure_origin in self.iter_secure_origins():
  473:             secure_protocol, secure_host, secure_port = secure_origin
  474:             if origin_protocol != secure_protocol and secure_protocol != "*":
  475:                 continue
  476: 
  477:             try:
  478:                 addr = ipaddress.ip_address(origin_host or "")
  479:                 network = ipaddress.ip_network(secure_host)
  480:             except ValueError:
  481:                 # We don't have both a valid address or a valid network, so
  482:                 # we'll check this origin against hostnames.
  483:                 if (
  484:                     origin_host
  485:                     and origin_host.lower() != secure_host.lower()
  486:                     and secure_host != "*"
  487:                 ):
  488:                     continue
  489:             else:
  490:                 # We have a valid address and network, so see if the address
  491:                 # is contained within the network.
  492:                 if addr not in network:
  493:                     continue
  494: 
  495:             # Check to see if the port matches.
  496:             if (
  497:                 origin_port != secure_port
  498:                 and secure_port != "*"
  499:                 and secure_port is not None
  500:             ):
  501:                 continue
  502: 
  503:             # If we've gotten here, then this origin matches the current
  504:             # secure origin and we should return True
  505:             return True
  506: 
  507:         # If we've gotten to this point, then the origin isn't secure and we
  508:         # will not accept it as a valid location to search. We will however
  509:         # log a warning that we are ignoring it.
  510:         logger.warning(
  511:             "The repository located at %s is not a trusted or secure host and "
  512:             "is being ignored. If this repository is available via HTTPS we "
  513:             "recommend you use HTTPS instead, otherwise you may silence "
  514:             "this warning and allow it anyway with '--trusted-host %s'.",
  515:             origin_host,
  516:             origin_host,
  517:         )
  518: 
  519:         return False
  520: 
  521:     def request(self, method: str, url: str, *args: Any, **kwargs: Any) -> Response:
  522:         # Allow setting a default timeout on a session
  523:         kwargs.setdefault("timeout", self.timeout)
  524:         # Allow setting a default proxies on a session
  525:         kwargs.setdefault("proxies", self.proxies)
  526: 
  527:         # Dispatch the actual request
  528:         return super().request(method, url, *args, **kwargs)
