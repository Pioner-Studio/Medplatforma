    1: """Download files with progress indicators."""
    2: 
    3: from __future__ import annotations
    4: 
    5: import email.message
    6: import logging
    7: import mimetypes
    8: import os
    9: from collections.abc import Iterable, Mapping
   10: from dataclasses import dataclass
   11: from http import HTTPStatus
   12: from typing import BinaryIO
   13: 
   14: from pip._vendor.requests import PreparedRequest
   15: from pip._vendor.requests.models import Response
   16: from pip._vendor.urllib3 import HTTPResponse as URLlib3Response
   17: from pip._vendor.urllib3._collections import HTTPHeaderDict
   18: from pip._vendor.urllib3.exceptions import ReadTimeoutError
   19: 
   20: from pip._internal.cli.progress_bars import BarType, get_download_progress_renderer
   21: from pip._internal.exceptions import IncompleteDownloadError, NetworkConnectionError
   22: from pip._internal.models.index import PyPI
   23: from pip._internal.models.link import Link
   24: from pip._internal.network.cache import SafeFileCache, is_from_cache
   25: from pip._internal.network.session import CacheControlAdapter, PipSession
   26: from pip._internal.network.utils import HEADERS, raise_for_status, response_chunks
   27: from pip._internal.utils.misc import format_size, redact_auth_from_url, splitext
   28: 
   29: logger = logging.getLogger(__name__)
   30: 
   31: 
   32: def _get_http_response_size(resp: Response) -> int | None:
   33:     try:
   34:         return int(resp.headers["content-length"])
   35:     except (ValueError, KeyError, TypeError):
   36:         return None
   37: 
   38: 
   39: def _get_http_response_etag_or_last_modified(resp: Response) -> str | None:
   40:     """
   41:     Return either the ETag or Last-Modified header (or None if neither exists).
   42:     The return value can be used in an If-Range header.
   43:     """
   44:     return resp.headers.get("etag", resp.headers.get("last-modified"))
   45: 
   46: 
   47: def _log_download(
   48:     resp: Response,
   49:     link: Link,
   50:     progress_bar: BarType,
   51:     total_length: int | None,
   52:     range_start: int | None = 0,
   53: ) -> Iterable[bytes]:
   54:     if link.netloc == PyPI.file_storage_domain:
   55:         url = link.show_url
   56:     else:
   57:         url = link.url_without_fragment
   58: 
   59:     logged_url = redact_auth_from_url(url)
   60: 
   61:     if total_length:
   62:         if range_start:
   63:             logged_url = (
   64:                 f"{logged_url} ({format_size(range_start)}/{format_size(total_length)})"
   65:             )
   66:         else:
   67:             logged_url = f"{logged_url} ({format_size(total_length)})"
   68: 
   69:     if is_from_cache(resp):
   70:         logger.info("Using cached %s", logged_url)
   71:     elif range_start:
   72:         logger.info("Resuming download %s", logged_url)
   73:     else:
   74:         logger.info("Downloading %s", logged_url)
   75: 
   76:     if logger.getEffectiveLevel() > logging.INFO:
   77:         show_progress = False
   78:     elif is_from_cache(resp):
   79:         show_progress = False
   80:     elif not total_length:
   81:         show_progress = True
   82:     elif total_length > (512 * 1024):
   83:         show_progress = True
   84:     else:
   85:         show_progress = False
   86: 
   87:     chunks = response_chunks(resp)
   88: 
   89:     if not show_progress:
   90:         return chunks
   91: 
   92:     renderer = get_download_progress_renderer(
   93:         bar_type=progress_bar, size=total_length, initial_progress=range_start
   94:     )
   95:     return renderer(chunks)
   96: 
   97: 
   98: def sanitize_content_filename(filename: str) -> str:
   99:     """
  100:     Sanitize the "filename" value from a Content-Disposition header.
  101:     """
  102:     return os.path.basename(filename)
  103: 
  104: 
  105: def parse_content_disposition(content_disposition: str, default_filename: str) -> str:
  106:     """
  107:     Parse the "filename" value from a Content-Disposition header, and
  108:     return the default filename if the result is empty.
  109:     """
  110:     m = email.message.Message()
  111:     m["content-type"] = content_disposition
  112:     filename = m.get_param("filename")
  113:     if filename:
  114:         # We need to sanitize the filename to prevent directory traversal
  115:         # in case the filename contains ".." path parts.
  116:         filename = sanitize_content_filename(str(filename))
  117:     return filename or default_filename
  118: 
  119: 
  120: def _get_http_response_filename(resp: Response, link: Link) -> str:
  121:     """Get an ideal filename from the given HTTP response, falling back to
  122:     the link filename if not provided.
  123:     """
  124:     filename = link.filename  # fallback
  125:     # Have a look at the Content-Disposition header for a better guess
  126:     content_disposition = resp.headers.get("content-disposition")
  127:     if content_disposition:
  128:         filename = parse_content_disposition(content_disposition, filename)
  129:     ext: str | None = splitext(filename)[1]
  130:     if not ext:
  131:         ext = mimetypes.guess_extension(resp.headers.get("content-type", ""))
  132:         if ext:
  133:             filename += ext
  134:     if not ext and link.url != resp.url:
  135:         ext = os.path.splitext(resp.url)[1]
  136:         if ext:
  137:             filename += ext
  138:     return filename
  139: 
  140: 
  141: @dataclass
  142: class _FileDownload:
  143:     """Stores the state of a single link download."""
  144: 
  145:     link: Link
  146:     output_file: BinaryIO
  147:     size: int | None
  148:     bytes_received: int = 0
  149:     reattempts: int = 0
  150: 
  151:     def is_incomplete(self) -> bool:
  152:         return bool(self.size is not None and self.bytes_received < self.size)
  153: 
  154:     def write_chunk(self, data: bytes) -> None:
  155:         self.bytes_received += len(data)
  156:         self.output_file.write(data)
  157: 
  158:     def reset_file(self) -> None:
  159:         """Delete any saved data and reset progress to zero."""
  160:         self.output_file.seek(0)
  161:         self.output_file.truncate()
  162:         self.bytes_received = 0
  163: 
  164: 
  165: class Downloader:
  166:     def __init__(
  167:         self,
  168:         session: PipSession,
  169:         progress_bar: BarType,
  170:         resume_retries: int,
  171:     ) -> None:
  172:         assert (
  173:             resume_retries >= 0
  174:         ), "Number of max resume retries must be bigger or equal to zero"
  175:         self._session = session
  176:         self._progress_bar = progress_bar
  177:         self._resume_retries = resume_retries
  178: 
  179:     def batch(
  180:         self, links: Iterable[Link], location: str
  181:     ) -> Iterable[tuple[Link, tuple[str, str]]]:
  182:         """Convenience method to download multiple links."""
  183:         for link in links:
  184:             filepath, content_type = self(link, location)
  185:             yield link, (filepath, content_type)
  186: 
  187:     def __call__(self, link: Link, location: str) -> tuple[str, str]:
  188:         """Download a link and save it under location."""
  189:         resp = self._http_get(link)
  190:         download_size = _get_http_response_size(resp)
  191: 
  192:         filepath = os.path.join(location, _get_http_response_filename(resp, link))
  193:         with open(filepath, "wb") as content_file:
  194:             download = _FileDownload(link, content_file, download_size)
  195:             self._process_response(download, resp)
  196:             if download.is_incomplete():
  197:                 self._attempt_resumes_or_redownloads(download, resp)
  198: 
  199:         content_type = resp.headers.get("Content-Type", "")
  200:         return filepath, content_type
  201: 
  202:     def _process_response(self, download: _FileDownload, resp: Response) -> None:
  203:         """Download and save chunks from a response."""
  204:         chunks = _log_download(
  205:             resp,
  206:             download.link,
  207:             self._progress_bar,
  208:             download.size,
  209:             range_start=download.bytes_received,
  210:         )
  211:         try:
  212:             for chunk in chunks:
  213:                 download.write_chunk(chunk)
  214:         except ReadTimeoutError as e:
  215:             # If the download size is not known, then give up downloading the file.
  216:             if download.size is None:
  217:                 raise e
  218: 
  219:             logger.warning("Connection timed out while downloading.")
  220: 
  221:     def _attempt_resumes_or_redownloads(
  222:         self, download: _FileDownload, first_resp: Response
  223:     ) -> None:
  224:         """Attempt to resume/restart the download if connection was dropped."""
  225: 
  226:         while download.reattempts < self._resume_retries and download.is_incomplete():
  227:             assert download.size is not None
  228:             download.reattempts += 1
  229:             logger.warning(
  230:                 "Attempting to resume incomplete download (%s/%s, attempt %d)",
  231:                 format_size(download.bytes_received),
  232:                 format_size(download.size),
  233:                 download.reattempts,
  234:             )
  235: 
  236:             try:
  237:                 resume_resp = self._http_get_resume(download, should_match=first_resp)
  238:                 # Fallback: if the server responded with 200 (i.e., the file has
  239:                 # since been modified or range requests are unsupported) or any
  240:                 # other unexpected status, restart the download from the beginning.
  241:                 must_restart = resume_resp.status_code != HTTPStatus.PARTIAL_CONTENT
  242:                 if must_restart:
  243:                     download.reset_file()
  244:                     download.size = _get_http_response_size(resume_resp)
  245:                     first_resp = resume_resp
  246: 
  247:                 self._process_response(download, resume_resp)
  248:             except (ConnectionError, ReadTimeoutError, OSError):
  249:                 continue
  250: 
  251:         # No more resume attempts. Raise an error if the download is still incomplete.
  252:         if download.is_incomplete():
  253:             os.remove(download.output_file.name)
  254:             raise IncompleteDownloadError(download)
  255: 
  256:         # If we successfully completed the download via resume, manually cache it
  257:         # as a complete response to enable future caching
  258:         if download.reattempts > 0:
  259:             self._cache_resumed_download(download, first_resp)
  260: 
  261:     def _cache_resumed_download(
  262:         self, download: _FileDownload, original_response: Response
  263:     ) -> None:
  264:         """
  265:         Manually cache a file that was successfully downloaded via resume retries.
  266: 
  267:         cachecontrol doesn't cache 206 (Partial Content) responses, since they
  268:         are not complete files. This method manually adds the final file to the
  269:         cache as though it was downloaded in a single request, so that future
  270:         requests can use the cache.
  271:         """
  272:         url = download.link.url_without_fragment
  273:         adapter = self._session.get_adapter(url)
  274: 
  275:         # Check if the adapter is the CacheControlAdapter (i.e. caching is enabled)
  276:         if not isinstance(adapter, CacheControlAdapter):
  277:             logger.debug(
  278:                 "Skipping resume download caching: no cache controller for %s", url
  279:             )
  280:             return
  281: 
  282:         # Check SafeFileCache is being used
  283:         assert isinstance(
  284:             adapter.cache, SafeFileCache
  285:         ), "separate body cache not in use!"
  286: 
  287:         synthetic_request = PreparedRequest()
  288:         synthetic_request.prepare(method="GET", url=url, headers={})
  289: 
  290:         synthetic_response_headers = HTTPHeaderDict()
  291:         for key, value in original_response.headers.items():
  292:             if key.lower() not in ["content-range", "content-length"]:
  293:                 synthetic_response_headers[key] = value
  294:         synthetic_response_headers["content-length"] = str(download.size)
  295: 
  296:         synthetic_response = URLlib3Response(
  297:             body="",
  298:             headers=synthetic_response_headers,
  299:             status=200,
  300:             preload_content=False,
  301:         )
  302: 
  303:         # Save metadata and then stream the file contents to cache.
  304:         cache_url = adapter.controller.cache_url(url)
  305:         metadata_blob = adapter.controller.serializer.dumps(
  306:             synthetic_request, synthetic_response, b""
  307:         )
  308:         adapter.cache.set(cache_url, metadata_blob)
  309:         download.output_file.flush()
  310:         with open(download.output_file.name, "rb") as f:
  311:             adapter.cache.set_body_from_io(cache_url, f)
  312: 
  313:         logger.debug(
  314:             "Cached resumed download as complete response for future use: %s", url
  315:         )
  316: 
  317:     def _http_get_resume(
  318:         self, download: _FileDownload, should_match: Response
  319:     ) -> Response:
  320:         """Issue a HTTP range request to resume the download."""
  321:         # To better understand the download resumption logic, see the mdn web docs:
  322:         # https://developer.mozilla.org/en-US/docs/Web/HTTP/Guides/Range_requests
  323:         headers = HEADERS.copy()
  324:         headers["Range"] = f"bytes={download.bytes_received}-"
  325:         # If possible, use a conditional range request to avoid corrupted
  326:         # downloads caused by the remote file changing in-between.
  327:         if identifier := _get_http_response_etag_or_last_modified(should_match):
  328:             headers["If-Range"] = identifier
  329:         return self._http_get(download.link, headers)
  330: 
  331:     def _http_get(self, link: Link, headers: Mapping[str, str] = HEADERS) -> Response:
  332:         target_url = link.url_without_fragment
  333:         try:
  334:             resp = self._session.get(target_url, headers=headers, stream=True)
  335:             raise_for_status(resp)
  336:         except NetworkConnectionError as e:
  337:             assert e.response is not None
  338:             logger.critical(
  339:                 "HTTP error %s while getting %s", e.response.status_code, link
  340:             )
  341:             raise
  342:         return resp
