    1: from __future__ import annotations
    2: 
    3: import contextlib
    4: import re
    5: from dataclasses import dataclass
    6: from typing import Iterator, NoReturn
    7: 
    8: from .specifiers import Specifier
    9: 
   10: 
   11: @dataclass
   12: class Token:
   13:     name: str
   14:     text: str
   15:     position: int
   16: 
   17: 
   18: class ParserSyntaxError(Exception):
   19:     """The provided source text could not be parsed correctly."""
   20: 
   21:     def __init__(
   22:         self,
   23:         message: str,
   24:         *,
   25:         source: str,
   26:         span: tuple[int, int],
   27:     ) -> None:
   28:         self.span = span
   29:         self.message = message
   30:         self.source = source
   31: 
   32:         super().__init__()
   33: 
   34:     def __str__(self) -> str:
   35:         marker = " " * self.span[0] + "~" * (self.span[1] - self.span[0]) + "^"
   36:         return "\n    ".join([self.message, self.source, marker])
   37: 
   38: 
   39: DEFAULT_RULES: dict[str, str | re.Pattern[str]] = {
   40:     "LEFT_PARENTHESIS": r"\(",
   41:     "RIGHT_PARENTHESIS": r"\)",
   42:     "LEFT_BRACKET": r"\[",
   43:     "RIGHT_BRACKET": r"\]",
   44:     "SEMICOLON": r";",
   45:     "COMMA": r",",
   46:     "QUOTED_STRING": re.compile(
   47:         r"""
   48:             (
   49:                 ('[^']*')
   50:                 |
   51:                 ("[^"]*")
   52:             )
   53:         """,
   54:         re.VERBOSE,
   55:     ),
   56:     "OP": r"(===|==|~=|!=|<=|>=|<|>)",
   57:     "BOOLOP": r"\b(or|and)\b",
   58:     "IN": r"\bin\b",
   59:     "NOT": r"\bnot\b",
   60:     "VARIABLE": re.compile(
   61:         r"""
   62:             \b(
   63:                 python_version
   64:                 |python_full_version
   65:                 |os[._]name
   66:                 |sys[._]platform
   67:                 |platform_(release|system)
   68:                 |platform[._](version|machine|python_implementation)
   69:                 |python_implementation
   70:                 |implementation_(name|version)
   71:                 |extras?
   72:                 |dependency_groups
   73:             )\b
   74:         """,
   75:         re.VERBOSE,
   76:     ),
   77:     "SPECIFIER": re.compile(
   78:         Specifier._operator_regex_str + Specifier._version_regex_str,
   79:         re.VERBOSE | re.IGNORECASE,
   80:     ),
   81:     "AT": r"\@",
   82:     "URL": r"[^ \t]+",
   83:     "IDENTIFIER": r"\b[a-zA-Z0-9][a-zA-Z0-9._-]*\b",
   84:     "VERSION_PREFIX_TRAIL": r"\.\*",
   85:     "VERSION_LOCAL_LABEL_TRAIL": r"\+[a-z0-9]+(?:[-_\.][a-z0-9]+)*",
   86:     "WS": r"[ \t]+",
   87:     "END": r"$",
   88: }
   89: 
   90: 
   91: class Tokenizer:
   92:     """Context-sensitive token parsing.
   93: 
   94:     Provides methods to examine the input stream to check whether the next token
   95:     matches.
   96:     """
   97: 
   98:     def __init__(
   99:         self,
  100:         source: str,
  101:         *,
  102:         rules: dict[str, str | re.Pattern[str]],
  103:     ) -> None:
  104:         self.source = source
  105:         self.rules: dict[str, re.Pattern[str]] = {
  106:             name: re.compile(pattern) for name, pattern in rules.items()
  107:         }
  108:         self.next_token: Token | None = None
  109:         self.position = 0
  110: 
  111:     def consume(self, name: str) -> None:
  112:         """Move beyond provided token name, if at current position."""
  113:         if self.check(name):
  114:             self.read()
  115: 
  116:     def check(self, name: str, *, peek: bool = False) -> bool:
  117:         """Check whether the next token has the provided name.
  118: 
  119:         By default, if the check succeeds, the token *must* be read before
  120:         another check. If `peek` is set to `True`, the token is not loaded and
  121:         would need to be checked again.
  122:         """
  123:         assert self.next_token is None, (
  124:             f"Cannot check for {name!r}, already have {self.next_token!r}"
  125:         )
  126:         assert name in self.rules, f"Unknown token name: {name!r}"
  127: 
  128:         expression = self.rules[name]
  129: 
  130:         match = expression.match(self.source, self.position)
  131:         if match is None:
  132:             return False
  133:         if not peek:
  134:             self.next_token = Token(name, match[0], self.position)
  135:         return True
  136: 
  137:     def expect(self, name: str, *, expected: str) -> Token:
  138:         """Expect a certain token name next, failing with a syntax error otherwise.
  139: 
  140:         The token is *not* read.
  141:         """
  142:         if not self.check(name):
  143:             raise self.raise_syntax_error(f"Expected {expected}")
  144:         return self.read()
  145: 
  146:     def read(self) -> Token:
  147:         """Consume the next token and return it."""
  148:         token = self.next_token
  149:         assert token is not None
  150: 
  151:         self.position += len(token.text)
  152:         self.next_token = None
  153: 
  154:         return token
  155: 
  156:     def raise_syntax_error(
  157:         self,
  158:         message: str,
  159:         *,
  160:         span_start: int | None = None,
  161:         span_end: int | None = None,
  162:     ) -> NoReturn:
  163:         """Raise ParserSyntaxError at the given position."""
  164:         span = (
  165:             self.position if span_start is None else span_start,
  166:             self.position if span_end is None else span_end,
  167:         )
  168:         raise ParserSyntaxError(
  169:             message,
  170:             source=self.source,
  171:             span=span,
  172:         )
  173: 
  174:     @contextlib.contextmanager
  175:     def enclosing_tokens(
  176:         self, open_token: str, close_token: str, *, around: str
  177:     ) -> Iterator[None]:
  178:         if self.check(open_token):
  179:             open_position = self.position
  180:             self.read()
  181:         else:
  182:             open_position = None
  183: 
  184:         yield
  185: 
  186:         if open_position is None:
  187:             return
  188: 
  189:         if not self.check(close_token):
  190:             self.raise_syntax_error(
  191:                 f"Expected matching {close_token} for {open_token}, after {around}",
  192:                 span_start=open_position,
  193:             )
  194: 
  195:         self.read()
