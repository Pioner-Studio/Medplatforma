    1: from __future__ import annotations
    2: 
    3: from decimal import Decimal
    4: import operator
    5: import os
    6: from sys import byteorder
    7: from typing import (
    8:     TYPE_CHECKING,
    9:     Callable,
   10:     ContextManager,
   11:     cast,
   12: )
   13: import warnings
   14: 
   15: import numpy as np
   16: 
   17: from pandas._config.localization import (
   18:     can_set_locale,
   19:     get_locales,
   20:     set_locale,
   21: )
   22: 
   23: from pandas.compat import pa_version_under10p1
   24: 
   25: from pandas.core.dtypes.common import is_string_dtype
   26: 
   27: import pandas as pd
   28: from pandas import (
   29:     ArrowDtype,
   30:     DataFrame,
   31:     Index,
   32:     MultiIndex,
   33:     RangeIndex,
   34:     Series,
   35: )
   36: from pandas._testing._io import (
   37:     round_trip_localpath,
   38:     round_trip_pathlib,
   39:     round_trip_pickle,
   40:     write_to_compressed,
   41: )
   42: from pandas._testing._warnings import (
   43:     assert_produces_warning,
   44:     maybe_produces_warning,
   45: )
   46: from pandas._testing.asserters import (
   47:     assert_almost_equal,
   48:     assert_attr_equal,
   49:     assert_categorical_equal,
   50:     assert_class_equal,
   51:     assert_contains_all,
   52:     assert_copy,
   53:     assert_datetime_array_equal,
   54:     assert_dict_equal,
   55:     assert_equal,
   56:     assert_extension_array_equal,
   57:     assert_frame_equal,
   58:     assert_index_equal,
   59:     assert_indexing_slices_equivalent,
   60:     assert_interval_array_equal,
   61:     assert_is_sorted,
   62:     assert_is_valid_plot_return_object,
   63:     assert_metadata_equivalent,
   64:     assert_numpy_array_equal,
   65:     assert_period_array_equal,
   66:     assert_series_equal,
   67:     assert_sp_array_equal,
   68:     assert_timedelta_array_equal,
   69:     raise_assert_detail,
   70: )
   71: from pandas._testing.compat import (
   72:     get_dtype,
   73:     get_obj,
   74: )
   75: from pandas._testing.contexts import (
   76:     assert_cow_warning,
   77:     decompress_file,
   78:     ensure_clean,
   79:     raises_chained_assignment_error,
   80:     set_timezone,
   81:     use_numexpr,
   82:     with_csv_dialect,
   83: )
   84: from pandas.core.arrays import (
   85:     BaseMaskedArray,
   86:     ExtensionArray,
   87:     NumpyExtensionArray,
   88: )
   89: from pandas.core.arrays._mixins import NDArrayBackedExtensionArray
   90: from pandas.core.construction import extract_array
   91: 
   92: if TYPE_CHECKING:
   93:     from pandas._typing import (
   94:         Dtype,
   95:         NpDtype,
   96:     )
   97: 
   98:     from pandas.core.arrays import ArrowExtensionArray
   99: 
  100: UNSIGNED_INT_NUMPY_DTYPES: list[NpDtype] = ["uint8", "uint16", "uint32", "uint64"]
  101: UNSIGNED_INT_EA_DTYPES: list[Dtype] = ["UInt8", "UInt16", "UInt32", "UInt64"]
  102: SIGNED_INT_NUMPY_DTYPES: list[NpDtype] = [int, "int8", "int16", "int32", "int64"]
  103: SIGNED_INT_EA_DTYPES: list[Dtype] = ["Int8", "Int16", "Int32", "Int64"]
  104: ALL_INT_NUMPY_DTYPES = UNSIGNED_INT_NUMPY_DTYPES + SIGNED_INT_NUMPY_DTYPES
  105: ALL_INT_EA_DTYPES = UNSIGNED_INT_EA_DTYPES + SIGNED_INT_EA_DTYPES
  106: ALL_INT_DTYPES: list[Dtype] = [*ALL_INT_NUMPY_DTYPES, *ALL_INT_EA_DTYPES]
  107: 
  108: FLOAT_NUMPY_DTYPES: list[NpDtype] = [float, "float32", "float64"]
  109: FLOAT_EA_DTYPES: list[Dtype] = ["Float32", "Float64"]
  110: ALL_FLOAT_DTYPES: list[Dtype] = [*FLOAT_NUMPY_DTYPES, *FLOAT_EA_DTYPES]
  111: 
  112: COMPLEX_DTYPES: list[Dtype] = [complex, "complex64", "complex128"]
  113: STRING_DTYPES: list[Dtype] = [str, "str", "U"]
  114: 
  115: DATETIME64_DTYPES: list[Dtype] = ["datetime64[ns]", "M8[ns]"]
  116: TIMEDELTA64_DTYPES: list[Dtype] = ["timedelta64[ns]", "m8[ns]"]
  117: 
  118: BOOL_DTYPES: list[Dtype] = [bool, "bool"]
  119: BYTES_DTYPES: list[Dtype] = [bytes, "bytes"]
  120: OBJECT_DTYPES: list[Dtype] = [object, "object"]
  121: 
  122: ALL_REAL_NUMPY_DTYPES = FLOAT_NUMPY_DTYPES + ALL_INT_NUMPY_DTYPES
  123: ALL_REAL_EXTENSION_DTYPES = FLOAT_EA_DTYPES + ALL_INT_EA_DTYPES
  124: ALL_REAL_DTYPES: list[Dtype] = [*ALL_REAL_NUMPY_DTYPES, *ALL_REAL_EXTENSION_DTYPES]
  125: ALL_NUMERIC_DTYPES: list[Dtype] = [*ALL_REAL_DTYPES, *COMPLEX_DTYPES]
  126: 
  127: ALL_NUMPY_DTYPES = (
  128:     ALL_REAL_NUMPY_DTYPES
  129:     + COMPLEX_DTYPES
  130:     + STRING_DTYPES
  131:     + DATETIME64_DTYPES
  132:     + TIMEDELTA64_DTYPES
  133:     + BOOL_DTYPES
  134:     + OBJECT_DTYPES
  135:     + BYTES_DTYPES
  136: )
  137: 
  138: NARROW_NP_DTYPES = [
  139:     np.float16,
  140:     np.float32,
  141:     np.int8,
  142:     np.int16,
  143:     np.int32,
  144:     np.uint8,
  145:     np.uint16,
  146:     np.uint32,
  147: ]
  148: 
  149: PYTHON_DATA_TYPES = [
  150:     str,
  151:     int,
  152:     float,
  153:     complex,
  154:     list,
  155:     tuple,
  156:     range,
  157:     dict,
  158:     set,
  159:     frozenset,
  160:     bool,
  161:     bytes,
  162:     bytearray,
  163:     memoryview,
  164: ]
  165: 
  166: ENDIAN = {"little": "<", "big": ">"}[byteorder]
  167: 
  168: NULL_OBJECTS = [None, np.nan, pd.NaT, float("nan"), pd.NA, Decimal("NaN")]
  169: NP_NAT_OBJECTS = [
  170:     cls("NaT", unit)
  171:     for cls in [np.datetime64, np.timedelta64]
  172:     for unit in [
  173:         "Y",
  174:         "M",
  175:         "W",
  176:         "D",
  177:         "h",
  178:         "m",
  179:         "s",
  180:         "ms",
  181:         "us",
  182:         "ns",
  183:         "ps",
  184:         "fs",
  185:         "as",
  186:     ]
  187: ]
  188: 
  189: if not pa_version_under10p1:
  190:     import pyarrow as pa
  191: 
  192:     UNSIGNED_INT_PYARROW_DTYPES = [pa.uint8(), pa.uint16(), pa.uint32(), pa.uint64()]
  193:     SIGNED_INT_PYARROW_DTYPES = [pa.int8(), pa.int16(), pa.int32(), pa.int64()]
  194:     ALL_INT_PYARROW_DTYPES = UNSIGNED_INT_PYARROW_DTYPES + SIGNED_INT_PYARROW_DTYPES
  195:     ALL_INT_PYARROW_DTYPES_STR_REPR = [
  196:         str(ArrowDtype(typ)) for typ in ALL_INT_PYARROW_DTYPES
  197:     ]
  198: 
  199:     # pa.float16 doesn't seem supported
  200:     # https://github.com/apache/arrow/blob/master/python/pyarrow/src/arrow/python/helpers.cc#L86
  201:     FLOAT_PYARROW_DTYPES = [pa.float32(), pa.float64()]
  202:     FLOAT_PYARROW_DTYPES_STR_REPR = [
  203:         str(ArrowDtype(typ)) for typ in FLOAT_PYARROW_DTYPES
  204:     ]
  205:     DECIMAL_PYARROW_DTYPES = [pa.decimal128(7, 3)]
  206:     STRING_PYARROW_DTYPES = [pa.string()]
  207:     BINARY_PYARROW_DTYPES = [pa.binary()]
  208: 
  209:     TIME_PYARROW_DTYPES = [
  210:         pa.time32("s"),
  211:         pa.time32("ms"),
  212:         pa.time64("us"),
  213:         pa.time64("ns"),
  214:     ]
  215:     DATE_PYARROW_DTYPES = [pa.date32(), pa.date64()]
  216:     DATETIME_PYARROW_DTYPES = [
  217:         pa.timestamp(unit=unit, tz=tz)
  218:         for unit in ["s", "ms", "us", "ns"]
  219:         for tz in [None, "UTC", "US/Pacific", "US/Eastern"]
  220:     ]
  221:     TIMEDELTA_PYARROW_DTYPES = [pa.duration(unit) for unit in ["s", "ms", "us", "ns"]]
  222: 
  223:     BOOL_PYARROW_DTYPES = [pa.bool_()]
  224: 
  225:     # TODO: Add container like pyarrow types:
  226:     #  https://arrow.apache.org/docs/python/api/datatypes.html#factory-functions
  227:     ALL_PYARROW_DTYPES = (
  228:         ALL_INT_PYARROW_DTYPES
  229:         + FLOAT_PYARROW_DTYPES
  230:         + DECIMAL_PYARROW_DTYPES
  231:         + STRING_PYARROW_DTYPES
  232:         + BINARY_PYARROW_DTYPES
  233:         + TIME_PYARROW_DTYPES
  234:         + DATE_PYARROW_DTYPES
  235:         + DATETIME_PYARROW_DTYPES
  236:         + TIMEDELTA_PYARROW_DTYPES
  237:         + BOOL_PYARROW_DTYPES
  238:     )
  239:     ALL_REAL_PYARROW_DTYPES_STR_REPR = (
  240:         ALL_INT_PYARROW_DTYPES_STR_REPR + FLOAT_PYARROW_DTYPES_STR_REPR
  241:     )
  242: else:
  243:     FLOAT_PYARROW_DTYPES_STR_REPR = []
  244:     ALL_INT_PYARROW_DTYPES_STR_REPR = []
  245:     ALL_PYARROW_DTYPES = []
  246:     ALL_REAL_PYARROW_DTYPES_STR_REPR = []
  247: 
  248: ALL_REAL_NULLABLE_DTYPES = (
  249:     FLOAT_NUMPY_DTYPES + ALL_REAL_EXTENSION_DTYPES + ALL_REAL_PYARROW_DTYPES_STR_REPR
  250: )
  251: 
  252: arithmetic_dunder_methods = [
  253:     "__add__",
  254:     "__radd__",
  255:     "__sub__",
  256:     "__rsub__",
  257:     "__mul__",
  258:     "__rmul__",
  259:     "__floordiv__",
  260:     "__rfloordiv__",
  261:     "__truediv__",
  262:     "__rtruediv__",
  263:     "__pow__",
  264:     "__rpow__",
  265:     "__mod__",
  266:     "__rmod__",
  267: ]
  268: 
  269: comparison_dunder_methods = ["__eq__", "__ne__", "__le__", "__lt__", "__ge__", "__gt__"]
  270: 
  271: 
  272: # -----------------------------------------------------------------------------
  273: # Comparators
  274: 
  275: 
  276: def box_expected(expected, box_cls, transpose: bool = True):
  277:     """
  278:     Helper function to wrap the expected output of a test in a given box_class.
  279: 
  280:     Parameters
  281:     ----------
  282:     expected : np.ndarray, Index, Series
  283:     box_cls : {Index, Series, DataFrame}
  284: 
  285:     Returns
  286:     -------
  287:     subclass of box_cls
  288:     """
  289:     if box_cls is pd.array:
  290:         if isinstance(expected, RangeIndex):
  291:             # pd.array would return an IntegerArray
  292:             expected = NumpyExtensionArray(np.asarray(expected._values))
  293:         else:
  294:             expected = pd.array(expected, copy=False)
  295:     elif box_cls is Index:
  296:         with warnings.catch_warnings():
  297:             warnings.filterwarnings("ignore", "Dtype inference", category=FutureWarning)
  298:             expected = Index(expected)
  299:     elif box_cls is Series:
  300:         with warnings.catch_warnings():
  301:             warnings.filterwarnings("ignore", "Dtype inference", category=FutureWarning)
  302:             expected = Series(expected)
  303:     elif box_cls is DataFrame:
  304:         with warnings.catch_warnings():
  305:             warnings.filterwarnings("ignore", "Dtype inference", category=FutureWarning)
  306:             expected = Series(expected).to_frame()
  307:         if transpose:
  308:             # for vector operations, we need a DataFrame to be a single-row,
  309:             #  not a single-column, in order to operate against non-DataFrame
  310:             #  vectors of the same length. But convert to two rows to avoid
  311:             #  single-row special cases in datetime arithmetic
  312:             expected = expected.T
  313:             expected = pd.concat([expected] * 2, ignore_index=True)
  314:     elif box_cls is np.ndarray or box_cls is np.array:
  315:         expected = np.array(expected)
  316:     elif box_cls is to_array:
  317:         expected = to_array(expected)
  318:     else:
  319:         raise NotImplementedError(box_cls)
  320:     return expected
  321: 
  322: 
  323: def to_array(obj):
  324:     """
  325:     Similar to pd.array, but does not cast numpy dtypes to nullable dtypes.
  326:     """
  327:     # temporary implementation until we get pd.array in place
  328:     dtype = getattr(obj, "dtype", None)
  329: 
  330:     if dtype is None:
  331:         return np.asarray(obj)
  332: 
  333:     return extract_array(obj, extract_numpy=True)
  334: 
  335: 
  336: class SubclassedSeries(Series):
  337:     _metadata = ["testattr", "name"]
  338: 
  339:     @property
  340:     def _constructor(self):
  341:         # For testing, those properties return a generic callable, and not
  342:         # the actual class. In this case that is equivalent, but it is to
  343:         # ensure we don't rely on the property returning a class
  344:         # See https://github.com/pandas-dev/pandas/pull/46018 and
  345:         # https://github.com/pandas-dev/pandas/issues/32638 and linked issues
  346:         return lambda *args, **kwargs: SubclassedSeries(*args, **kwargs)
  347: 
  348:     @property
  349:     def _constructor_expanddim(self):
  350:         return lambda *args, **kwargs: SubclassedDataFrame(*args, **kwargs)
  351: 
  352: 
  353: class SubclassedDataFrame(DataFrame):
  354:     _metadata = ["testattr"]
  355: 
  356:     @property
  357:     def _constructor(self):
  358:         return lambda *args, **kwargs: SubclassedDataFrame(*args, **kwargs)
  359: 
  360:     @property
  361:     def _constructor_sliced(self):
  362:         return lambda *args, **kwargs: SubclassedSeries(*args, **kwargs)
  363: 
  364: 
  365: def convert_rows_list_to_csv_str(rows_list: list[str]) -> str:
  366:     """
  367:     Convert list of CSV rows to single CSV-formatted string for current OS.
  368: 
  369:     This method is used for creating expected value of to_csv() method.
  370: 
  371:     Parameters
  372:     ----------
  373:     rows_list : List[str]
  374:         Each element represents the row of csv.
  375: 
  376:     Returns
  377:     -------
  378:     str
  379:         Expected output of to_csv() in current OS.
  380:     """
  381:     sep = os.linesep
  382:     return sep.join(rows_list) + sep
  383: 
  384: 
  385: def external_error_raised(expected_exception: type[Exception]) -> ContextManager:
  386:     """
  387:     Helper function to mark pytest.raises that have an external error message.
  388: 
  389:     Parameters
  390:     ----------
  391:     expected_exception : Exception
  392:         Expected error to raise.
  393: 
  394:     Returns
  395:     -------
  396:     Callable
  397:         Regular `pytest.raises` function with `match` equal to `None`.
  398:     """
  399:     import pytest
  400: 
  401:     return pytest.raises(expected_exception, match=None)
  402: 
  403: 
  404: cython_table = pd.core.common._cython_table.items()
  405: 
  406: 
  407: def get_cython_table_params(ndframe, func_names_and_expected):
  408:     """
  409:     Combine frame, functions from com._cython_table
  410:     keys and expected result.
  411: 
  412:     Parameters
  413:     ----------
  414:     ndframe : DataFrame or Series
  415:     func_names_and_expected : Sequence of two items
  416:         The first item is a name of a NDFrame method ('sum', 'prod') etc.
  417:         The second item is the expected return value.
  418: 
  419:     Returns
  420:     -------
  421:     list
  422:         List of three items (DataFrame, function, expected result)
  423:     """
  424:     results = []
  425:     for func_name, expected in func_names_and_expected:
  426:         results.append((ndframe, func_name, expected))
  427:         results += [
  428:             (ndframe, func, expected)
  429:             for func, name in cython_table
  430:             if name == func_name
  431:         ]
  432:     return results
  433: 
  434: 
  435: def get_op_from_name(op_name: str) -> Callable:
  436:     """
  437:     The operator function for a given op name.
  438: 
  439:     Parameters
  440:     ----------
  441:     op_name : str
  442:         The op name, in form of "add" or "__add__".
  443: 
  444:     Returns
  445:     -------
  446:     function
  447:         A function performing the operation.
  448:     """
  449:     short_opname = op_name.strip("_")
  450:     try:
  451:         op = getattr(operator, short_opname)
  452:     except AttributeError:
  453:         # Assume it is the reverse operator
  454:         rop = getattr(operator, short_opname[1:])
  455:         op = lambda x, y: rop(y, x)
  456: 
  457:     return op
  458: 
  459: 
  460: # -----------------------------------------------------------------------------
  461: # Indexing test helpers
  462: 
  463: 
  464: def getitem(x):
  465:     return x
  466: 
  467: 
  468: def setitem(x):
  469:     return x
  470: 
  471: 
  472: def loc(x):
  473:     return x.loc
  474: 
  475: 
  476: def iloc(x):
  477:     return x.iloc
  478: 
  479: 
  480: def at(x):
  481:     return x.at
  482: 
  483: 
  484: def iat(x):
  485:     return x.iat
  486: 
  487: 
  488: # -----------------------------------------------------------------------------
  489: 
  490: _UNITS = ["s", "ms", "us", "ns"]
  491: 
  492: 
  493: def get_finest_unit(left: str, right: str):
  494:     """
  495:     Find the higher of two datetime64 units.
  496:     """
  497:     if _UNITS.index(left) >= _UNITS.index(right):
  498:         return left
  499:     return right
  500: 
  501: 
  502: def shares_memory(left, right) -> bool:
  503:     """
  504:     Pandas-compat for np.shares_memory.
  505:     """
  506:     if isinstance(left, np.ndarray) and isinstance(right, np.ndarray):
  507:         return np.shares_memory(left, right)
  508:     elif isinstance(left, np.ndarray):
  509:         # Call with reversed args to get to unpacking logic below.
  510:         return shares_memory(right, left)
  511: 
  512:     if isinstance(left, RangeIndex):
  513:         return False
  514:     if isinstance(left, MultiIndex):
  515:         return shares_memory(left._codes, right)
  516:     if isinstance(left, (Index, Series)):
  517:         return shares_memory(left._values, right)
  518: 
  519:     if isinstance(left, NDArrayBackedExtensionArray):
  520:         return shares_memory(left._ndarray, right)
  521:     if isinstance(left, pd.core.arrays.SparseArray):
  522:         return shares_memory(left.sp_values, right)
  523:     if isinstance(left, pd.core.arrays.IntervalArray):
  524:         return shares_memory(left._left, right) or shares_memory(left._right, right)
  525: 
  526:     if (
  527:         isinstance(left, ExtensionArray)
  528:         and is_string_dtype(left.dtype)
  529:         and left.dtype.storage in ("pyarrow", "pyarrow_numpy")  # type: ignore[attr-defined]
  530:     ):
  531:         # https://github.com/pandas-dev/pandas/pull/43930#discussion_r736862669
  532:         left = cast("ArrowExtensionArray", left)
  533:         if (
  534:             isinstance(right, ExtensionArray)
  535:             and is_string_dtype(right.dtype)
  536:             and right.dtype.storage in ("pyarrow", "pyarrow_numpy")  # type: ignore[attr-defined]
  537:         ):
  538:             right = cast("ArrowExtensionArray", right)
  539:             left_pa_data = left._pa_array
  540:             right_pa_data = right._pa_array
  541:             left_buf1 = left_pa_data.chunk(0).buffers()[1]
  542:             right_buf1 = right_pa_data.chunk(0).buffers()[1]
  543:             return left_buf1 == right_buf1
  544: 
  545:     if isinstance(left, BaseMaskedArray) and isinstance(right, BaseMaskedArray):
  546:         # By convention, we'll say these share memory if they share *either*
  547:         #  the _data or the _mask
  548:         return np.shares_memory(left._data, right._data) or np.shares_memory(
  549:             left._mask, right._mask
  550:         )
  551: 
  552:     if isinstance(left, DataFrame) and len(left._mgr.arrays) == 1:
  553:         arr = left._mgr.arrays[0]
  554:         return shares_memory(arr, right)
  555: 
  556:     raise NotImplementedError(type(left), type(right))
  557: 
  558: 
  559: __all__ = [
  560:     "ALL_INT_EA_DTYPES",
  561:     "ALL_INT_NUMPY_DTYPES",
  562:     "ALL_NUMPY_DTYPES",
  563:     "ALL_REAL_NUMPY_DTYPES",
  564:     "assert_almost_equal",
  565:     "assert_attr_equal",
  566:     "assert_categorical_equal",
  567:     "assert_class_equal",
  568:     "assert_contains_all",
  569:     "assert_copy",
  570:     "assert_datetime_array_equal",
  571:     "assert_dict_equal",
  572:     "assert_equal",
  573:     "assert_extension_array_equal",
  574:     "assert_frame_equal",
  575:     "assert_index_equal",
  576:     "assert_indexing_slices_equivalent",
  577:     "assert_interval_array_equal",
  578:     "assert_is_sorted",
  579:     "assert_is_valid_plot_return_object",
  580:     "assert_metadata_equivalent",
  581:     "assert_numpy_array_equal",
  582:     "assert_period_array_equal",
  583:     "assert_produces_warning",
  584:     "assert_series_equal",
  585:     "assert_sp_array_equal",
  586:     "assert_timedelta_array_equal",
  587:     "assert_cow_warning",
  588:     "at",
  589:     "BOOL_DTYPES",
  590:     "box_expected",
  591:     "BYTES_DTYPES",
  592:     "can_set_locale",
  593:     "COMPLEX_DTYPES",
  594:     "convert_rows_list_to_csv_str",
  595:     "DATETIME64_DTYPES",
  596:     "decompress_file",
  597:     "ENDIAN",
  598:     "ensure_clean",
  599:     "external_error_raised",
  600:     "FLOAT_EA_DTYPES",
  601:     "FLOAT_NUMPY_DTYPES",
  602:     "get_cython_table_params",
  603:     "get_dtype",
  604:     "getitem",
  605:     "get_locales",
  606:     "get_finest_unit",
  607:     "get_obj",
  608:     "get_op_from_name",
  609:     "iat",
  610:     "iloc",
  611:     "loc",
  612:     "maybe_produces_warning",
  613:     "NARROW_NP_DTYPES",
  614:     "NP_NAT_OBJECTS",
  615:     "NULL_OBJECTS",
  616:     "OBJECT_DTYPES",
  617:     "raise_assert_detail",
  618:     "raises_chained_assignment_error",
  619:     "round_trip_localpath",
  620:     "round_trip_pathlib",
  621:     "round_trip_pickle",
  622:     "setitem",
  623:     "set_locale",
  624:     "set_timezone",
  625:     "shares_memory",
  626:     "SIGNED_INT_EA_DTYPES",
  627:     "SIGNED_INT_NUMPY_DTYPES",
  628:     "STRING_DTYPES",
  629:     "SubclassedDataFrame",
  630:     "SubclassedSeries",
  631:     "TIMEDELTA64_DTYPES",
  632:     "to_array",
  633:     "UNSIGNED_INT_EA_DTYPES",
  634:     "UNSIGNED_INT_NUMPY_DTYPES",
  635:     "use_numexpr",
  636:     "with_csv_dialect",
  637:     "write_to_compressed",
  638: ]
