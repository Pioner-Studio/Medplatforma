    1: from __future__ import annotations
    2: 
    3: from datetime import timedelta
    4: import operator
    5: from typing import (
    6:     TYPE_CHECKING,
    7:     cast,
    8: )
    9: 
   10: import numpy as np
   11: 
   12: from pandas._libs import (
   13:     lib,
   14:     tslibs,
   15: )
   16: from pandas._libs.tslibs import (
   17:     NaT,
   18:     NaTType,
   19:     Tick,
   20:     Timedelta,
   21:     astype_overflowsafe,
   22:     get_supported_dtype,
   23:     iNaT,
   24:     is_supported_dtype,
   25:     periods_per_second,
   26: )
   27: from pandas._libs.tslibs.conversion import cast_from_unit_vectorized
   28: from pandas._libs.tslibs.fields import (
   29:     get_timedelta_days,
   30:     get_timedelta_field,
   31: )
   32: from pandas._libs.tslibs.timedeltas import (
   33:     array_to_timedelta64,
   34:     floordiv_object_array,
   35:     ints_to_pytimedelta,
   36:     parse_timedelta_unit,
   37:     truediv_object_array,
   38: )
   39: from pandas.compat.numpy import function as nv
   40: from pandas.util._validators import validate_endpoints
   41: 
   42: from pandas.core.dtypes.common import (
   43:     TD64NS_DTYPE,
   44:     is_float_dtype,
   45:     is_integer_dtype,
   46:     is_object_dtype,
   47:     is_scalar,
   48:     is_string_dtype,
   49:     pandas_dtype,
   50: )
   51: from pandas.core.dtypes.dtypes import ExtensionDtype
   52: from pandas.core.dtypes.missing import isna
   53: 
   54: from pandas.core import (
   55:     nanops,
   56:     roperator,
   57: )
   58: from pandas.core.array_algos import datetimelike_accumulations
   59: from pandas.core.arrays import datetimelike as dtl
   60: from pandas.core.arrays._ranges import generate_regular_range
   61: import pandas.core.common as com
   62: from pandas.core.ops.common import unpack_zerodim_and_defer
   63: 
   64: if TYPE_CHECKING:
   65:     from collections.abc import Iterator
   66: 
   67:     from pandas._typing import (
   68:         AxisInt,
   69:         DateTimeErrorChoices,
   70:         DtypeObj,
   71:         NpDtype,
   72:         Self,
   73:         npt,
   74:     )
   75: 
   76:     from pandas import DataFrame
   77: 
   78: import textwrap
   79: 
   80: 
   81: def _field_accessor(name: str, alias: str, docstring: str):
   82:     def f(self) -> np.ndarray:
   83:         values = self.asi8
   84:         if alias == "days":
   85:             result = get_timedelta_days(values, reso=self._creso)
   86:         else:
   87:             # error: Incompatible types in assignment (
   88:             # expression has type "ndarray[Any, dtype[signedinteger[_32Bit]]]",
   89:             # variable has type "ndarray[Any, dtype[signedinteger[_64Bit]]]
   90:             result = get_timedelta_field(values, alias, reso=self._creso)  # type: ignore[assignment]
   91:         if self._hasna:
   92:             result = self._maybe_mask_results(
   93:                 result, fill_value=None, convert="float64"
   94:             )
   95: 
   96:         return result
   97: 
   98:     f.__name__ = name
   99:     f.__doc__ = f"\n{docstring}\n"
  100:     return property(f)
  101: 
  102: 
  103: class TimedeltaArray(dtl.TimelikeOps):
  104:     """
  105:     Pandas ExtensionArray for timedelta data.
  106: 
  107:     .. warning::
  108: 
  109:        TimedeltaArray is currently experimental, and its API may change
  110:        without warning. In particular, :attr:`TimedeltaArray.dtype` is
  111:        expected to change to be an instance of an ``ExtensionDtype``
  112:        subclass.
  113: 
  114:     Parameters
  115:     ----------
  116:     values : array-like
  117:         The timedelta data.
  118: 
  119:     dtype : numpy.dtype
  120:         Currently, only ``numpy.dtype("timedelta64[ns]")`` is accepted.
  121:     freq : Offset, optional
  122:     copy : bool, default False
  123:         Whether to copy the underlying array of data.
  124: 
  125:     Attributes
  126:     ----------
  127:     None
  128: 
  129:     Methods
  130:     -------
  131:     None
  132: 
  133:     Examples
  134:     --------
  135:     >>> pd.arrays.TimedeltaArray._from_sequence(pd.TimedeltaIndex(['1h', '2h']))
  136:     <TimedeltaArray>
  137:     ['0 days 01:00:00', '0 days 02:00:00']
  138:     Length: 2, dtype: timedelta64[ns]
  139:     """
  140: 
  141:     _typ = "timedeltaarray"
  142:     _internal_fill_value = np.timedelta64("NaT", "ns")
  143:     _recognized_scalars = (timedelta, np.timedelta64, Tick)
  144:     _is_recognized_dtype = lambda x: lib.is_np_dtype(x, "m")
  145:     _infer_matches = ("timedelta", "timedelta64")
  146: 
  147:     @property
  148:     def _scalar_type(self) -> type[Timedelta]:
  149:         return Timedelta
  150: 
  151:     __array_priority__ = 1000
  152:     # define my properties & methods for delegation
  153:     _other_ops: list[str] = []
  154:     _bool_ops: list[str] = []
  155:     _object_ops: list[str] = ["freq"]
  156:     _field_ops: list[str] = ["days", "seconds", "microseconds", "nanoseconds"]
  157:     _datetimelike_ops: list[str] = _field_ops + _object_ops + _bool_ops + ["unit"]
  158:     _datetimelike_methods: list[str] = [
  159:         "to_pytimedelta",
  160:         "total_seconds",
  161:         "round",
  162:         "floor",
  163:         "ceil",
  164:         "as_unit",
  165:     ]
  166: 
  167:     # Note: ndim must be defined to ensure NaT.__richcmp__(TimedeltaArray)
  168:     #  operates pointwise.
  169: 
  170:     def _box_func(self, x: np.timedelta64) -> Timedelta | NaTType:
  171:         y = x.view("i8")
  172:         if y == NaT._value:
  173:             return NaT
  174:         return Timedelta._from_value_and_reso(y, reso=self._creso)
  175: 
  176:     @property
  177:     # error: Return type "dtype" of "dtype" incompatible with return type
  178:     # "ExtensionDtype" in supertype "ExtensionArray"
  179:     def dtype(self) -> np.dtype[np.timedelta64]:  # type: ignore[override]
  180:         """
  181:         The dtype for the TimedeltaArray.
  182: 
  183:         .. warning::
  184: 
  185:            A future version of pandas will change dtype to be an instance
  186:            of a :class:`pandas.api.extensions.ExtensionDtype` subclass,
  187:            not a ``numpy.dtype``.
  188: 
  189:         Returns
  190:         -------
  191:         numpy.dtype
  192:         """
  193:         return self._ndarray.dtype
  194: 
  195:     # ----------------------------------------------------------------
  196:     # Constructors
  197: 
  198:     _freq = None
  199:     _default_dtype = TD64NS_DTYPE  # used in TimeLikeOps.__init__
  200: 
  201:     @classmethod
  202:     def _validate_dtype(cls, values, dtype):
  203:         # used in TimeLikeOps.__init__
  204:         dtype = _validate_td64_dtype(dtype)
  205:         _validate_td64_dtype(values.dtype)
  206:         if dtype != values.dtype:
  207:             raise ValueError("Values resolution does not match dtype.")
  208:         return dtype
  209: 
  210:     # error: Signature of "_simple_new" incompatible with supertype "NDArrayBacked"
  211:     @classmethod
  212:     def _simple_new(  # type: ignore[override]
  213:         cls,
  214:         values: npt.NDArray[np.timedelta64],
  215:         freq: Tick | None = None,
  216:         dtype: np.dtype[np.timedelta64] = TD64NS_DTYPE,
  217:     ) -> Self:
  218:         # Require td64 dtype, not unit-less, matching values.dtype
  219:         assert lib.is_np_dtype(dtype, "m")
  220:         assert not tslibs.is_unitless(dtype)
  221:         assert isinstance(values, np.ndarray), type(values)
  222:         assert dtype == values.dtype
  223:         assert freq is None or isinstance(freq, Tick)
  224: 
  225:         result = super()._simple_new(values=values, dtype=dtype)
  226:         result._freq = freq
  227:         return result
  228: 
  229:     @classmethod
  230:     def _from_sequence(cls, data, *, dtype=None, copy: bool = False) -> Self:
  231:         if dtype:
  232:             dtype = _validate_td64_dtype(dtype)
  233: 
  234:         data, freq = sequence_to_td64ns(data, copy=copy, unit=None)
  235: 
  236:         if dtype is not None:
  237:             data = astype_overflowsafe(data, dtype=dtype, copy=False)
  238: 
  239:         return cls._simple_new(data, dtype=data.dtype, freq=freq)
  240: 
  241:     @classmethod
  242:     def _from_sequence_not_strict(
  243:         cls,
  244:         data,
  245:         *,
  246:         dtype=None,
  247:         copy: bool = False,
  248:         freq=lib.no_default,
  249:         unit=None,
  250:     ) -> Self:
  251:         """
  252:         _from_sequence_not_strict but without responsibility for finding the
  253:         result's `freq`.
  254:         """
  255:         if dtype:
  256:             dtype = _validate_td64_dtype(dtype)
  257: 
  258:         assert unit not in ["Y", "y", "M"]  # caller is responsible for checking
  259: 
  260:         data, inferred_freq = sequence_to_td64ns(data, copy=copy, unit=unit)
  261: 
  262:         if dtype is not None:
  263:             data = astype_overflowsafe(data, dtype=dtype, copy=False)
  264: 
  265:         result = cls._simple_new(data, dtype=data.dtype, freq=inferred_freq)
  266: 
  267:         result._maybe_pin_freq(freq, {})
  268:         return result
  269: 
  270:     @classmethod
  271:     def _generate_range(
  272:         cls, start, end, periods, freq, closed=None, *, unit: str | None = None
  273:     ) -> Self:
  274:         periods = dtl.validate_periods(periods)
  275:         if freq is None and any(x is None for x in [periods, start, end]):
  276:             raise ValueError("Must provide freq argument if no data is supplied")
  277: 
  278:         if com.count_not_none(start, end, periods, freq) != 3:
  279:             raise ValueError(
  280:                 "Of the four parameters: start, end, periods, "
  281:                 "and freq, exactly three must be specified"
  282:             )
  283: 
  284:         if start is not None:
  285:             start = Timedelta(start).as_unit("ns")
  286: 
  287:         if end is not None:
  288:             end = Timedelta(end).as_unit("ns")
  289: 
  290:         if unit is not None:
  291:             if unit not in ["s", "ms", "us", "ns"]:
  292:                 raise ValueError("'unit' must be one of 's', 'ms', 'us', 'ns'")
  293:         else:
  294:             unit = "ns"
  295: 
  296:         if start is not None and unit is not None:
  297:             start = start.as_unit(unit, round_ok=False)
  298:         if end is not None and unit is not None:
  299:             end = end.as_unit(unit, round_ok=False)
  300: 
  301:         left_closed, right_closed = validate_endpoints(closed)
  302: 
  303:         if freq is not None:
  304:             index = generate_regular_range(start, end, periods, freq, unit=unit)
  305:         else:
  306:             index = np.linspace(start._value, end._value, periods).astype("i8")
  307: 
  308:         if not left_closed:
  309:             index = index[1:]
  310:         if not right_closed:
  311:             index = index[:-1]
  312: 
  313:         td64values = index.view(f"m8[{unit}]")
  314:         return cls._simple_new(td64values, dtype=td64values.dtype, freq=freq)
  315: 
  316:     # ----------------------------------------------------------------
  317:     # DatetimeLike Interface
  318: 
  319:     def _unbox_scalar(self, value) -> np.timedelta64:
  320:         if not isinstance(value, self._scalar_type) and value is not NaT:
  321:             raise ValueError("'value' should be a Timedelta.")
  322:         self._check_compatible_with(value)
  323:         if value is NaT:
  324:             return np.timedelta64(value._value, self.unit)
  325:         else:
  326:             return value.as_unit(self.unit).asm8
  327: 
  328:     def _scalar_from_string(self, value) -> Timedelta | NaTType:
  329:         return Timedelta(value)
  330: 
  331:     def _check_compatible_with(self, other) -> None:
  332:         # we don't have anything to validate.
  333:         pass
  334: 
  335:     # ----------------------------------------------------------------
  336:     # Array-Like / EA-Interface Methods
  337: 
  338:     def astype(self, dtype, copy: bool = True):
  339:         # We handle
  340:         #   --> timedelta64[ns]
  341:         #   --> timedelta64
  342:         # DatetimeLikeArrayMixin super call handles other cases
  343:         dtype = pandas_dtype(dtype)
  344: 
  345:         if lib.is_np_dtype(dtype, "m"):
  346:             if dtype == self.dtype:
  347:                 if copy:
  348:                     return self.copy()
  349:                 return self
  350: 
  351:             if is_supported_dtype(dtype):
  352:                 # unit conversion e.g. timedelta64[s]
  353:                 res_values = astype_overflowsafe(self._ndarray, dtype, copy=False)
  354:                 return type(self)._simple_new(
  355:                     res_values, dtype=res_values.dtype, freq=self.freq
  356:                 )
  357:             else:
  358:                 raise ValueError(
  359:                     f"Cannot convert from {self.dtype} to {dtype}. "
  360:                     "Supported resolutions are 's', 'ms', 'us', 'ns'"
  361:                 )
  362: 
  363:         return dtl.DatetimeLikeArrayMixin.astype(self, dtype, copy=copy)
  364: 
  365:     def __iter__(self) -> Iterator:
  366:         if self.ndim > 1:
  367:             for i in range(len(self)):
  368:                 yield self[i]
  369:         else:
  370:             # convert in chunks of 10k for efficiency
  371:             data = self._ndarray
  372:             length = len(self)
  373:             chunksize = 10000
  374:             chunks = (length // chunksize) + 1
  375:             for i in range(chunks):
  376:                 start_i = i * chunksize
  377:                 end_i = min((i + 1) * chunksize, length)
  378:                 converted = ints_to_pytimedelta(data[start_i:end_i], box=True)
  379:                 yield from converted
  380: 
  381:     # ----------------------------------------------------------------
  382:     # Reductions
  383: 
  384:     def sum(
  385:         self,
  386:         *,
  387:         axis: AxisInt | None = None,
  388:         dtype: NpDtype | None = None,
  389:         out=None,
  390:         keepdims: bool = False,
  391:         initial=None,
  392:         skipna: bool = True,
  393:         min_count: int = 0,
  394:     ):
  395:         nv.validate_sum(
  396:             (), {"dtype": dtype, "out": out, "keepdims": keepdims, "initial": initial}
  397:         )
  398: 
  399:         result = nanops.nansum(
  400:             self._ndarray, axis=axis, skipna=skipna, min_count=min_count
  401:         )
  402:         return self._wrap_reduction_result(axis, result)
  403: 
  404:     def std(
  405:         self,
  406:         *,
  407:         axis: AxisInt | None = None,
  408:         dtype: NpDtype | None = None,
  409:         out=None,
  410:         ddof: int = 1,
  411:         keepdims: bool = False,
  412:         skipna: bool = True,
  413:     ):
  414:         nv.validate_stat_ddof_func(
  415:             (), {"dtype": dtype, "out": out, "keepdims": keepdims}, fname="std"
  416:         )
  417: 
  418:         result = nanops.nanstd(self._ndarray, axis=axis, skipna=skipna, ddof=ddof)
  419:         if axis is None or self.ndim == 1:
  420:             return self._box_func(result)
  421:         return self._from_backing_data(result)
  422: 
  423:     # ----------------------------------------------------------------
  424:     # Accumulations
  425: 
  426:     def _accumulate(self, name: str, *, skipna: bool = True, **kwargs):
  427:         if name == "cumsum":
  428:             op = getattr(datetimelike_accumulations, name)
  429:             result = op(self._ndarray.copy(), skipna=skipna, **kwargs)
  430: 
  431:             return type(self)._simple_new(result, freq=None, dtype=self.dtype)
  432:         elif name == "cumprod":
  433:             raise TypeError("cumprod not supported for Timedelta.")
  434: 
  435:         else:
  436:             return super()._accumulate(name, skipna=skipna, **kwargs)
  437: 
  438:     # ----------------------------------------------------------------
  439:     # Rendering Methods
  440: 
  441:     def _formatter(self, boxed: bool = False):
  442:         from pandas.io.formats.format import get_format_timedelta64
  443: 
  444:         return get_format_timedelta64(self, box=True)
  445: 
  446:     def _format_native_types(
  447:         self, *, na_rep: str | float = "NaT", date_format=None, **kwargs
  448:     ) -> npt.NDArray[np.object_]:
  449:         from pandas.io.formats.format import get_format_timedelta64
  450: 
  451:         # Relies on TimeDelta._repr_base
  452:         formatter = get_format_timedelta64(self, na_rep)
  453:         # equiv: np.array([formatter(x) for x in self._ndarray])
  454:         #  but independent of dimension
  455:         return np.frompyfunc(formatter, 1, 1)(self._ndarray)
  456: 
  457:     # ----------------------------------------------------------------
  458:     # Arithmetic Methods
  459: 
  460:     def _add_offset(self, other):
  461:         assert not isinstance(other, Tick)
  462:         raise TypeError(
  463:             f"cannot add the type {type(other).__name__} to a {type(self).__name__}"
  464:         )
  465: 
  466:     @unpack_zerodim_and_defer("__mul__")
  467:     def __mul__(self, other) -> Self:
  468:         if is_scalar(other):
  469:             # numpy will accept float and int, raise TypeError for others
  470:             result = self._ndarray * other
  471:             freq = None
  472:             if self.freq is not None and not isna(other):
  473:                 freq = self.freq * other
  474:                 if freq.n == 0:
  475:                     # GH#51575 Better to have no freq than an incorrect one
  476:                     freq = None
  477:             return type(self)._simple_new(result, dtype=result.dtype, freq=freq)
  478: 
  479:         if not hasattr(other, "dtype"):
  480:             # list, tuple
  481:             other = np.array(other)
  482:         if len(other) != len(self) and not lib.is_np_dtype(other.dtype, "m"):
  483:             # Exclude timedelta64 here so we correctly raise TypeError
  484:             #  for that instead of ValueError
  485:             raise ValueError("Cannot multiply with unequal lengths")
  486: 
  487:         if is_object_dtype(other.dtype):
  488:             # this multiplication will succeed only if all elements of other
  489:             #  are int or float scalars, so we will end up with
  490:             #  timedelta64[ns]-dtyped result
  491:             arr = self._ndarray
  492:             result = [arr[n] * other[n] for n in range(len(self))]
  493:             result = np.array(result)
  494:             return type(self)._simple_new(result, dtype=result.dtype)
  495: 
  496:         # numpy will accept float or int dtype, raise TypeError for others
  497:         result = self._ndarray * other
  498:         return type(self)._simple_new(result, dtype=result.dtype)
  499: 
  500:     __rmul__ = __mul__
  501: 
  502:     def _scalar_divlike_op(self, other, op):
  503:         """
  504:         Shared logic for __truediv__, __rtruediv__, __floordiv__, __rfloordiv__
  505:         with scalar 'other'.
  506:         """
  507:         if isinstance(other, self._recognized_scalars):
  508:             other = Timedelta(other)
  509:             # mypy assumes that __new__ returns an instance of the class
  510:             # github.com/python/mypy/issues/1020
  511:             if cast("Timedelta | NaTType", other) is NaT:
  512:                 # specifically timedelta64-NaT
  513:                 res = np.empty(self.shape, dtype=np.float64)
  514:                 res.fill(np.nan)
  515:                 return res
  516: 
  517:             # otherwise, dispatch to Timedelta implementation
  518:             return op(self._ndarray, other)
  519: 
  520:         else:
  521:             # caller is responsible for checking lib.is_scalar(other)
  522:             # assume other is numeric, otherwise numpy will raise
  523: 
  524:             if op in [roperator.rtruediv, roperator.rfloordiv]:
  525:                 raise TypeError(
  526:                     f"Cannot divide {type(other).__name__} by {type(self).__name__}"
  527:                 )
  528: 
  529:             result = op(self._ndarray, other)
  530:             freq = None
  531: 
  532:             if self.freq is not None:
  533:                 # Note: freq gets division, not floor-division, even if op
  534:                 #  is floordiv.
  535:                 freq = self.freq / other
  536:                 if freq.nanos == 0 and self.freq.nanos != 0:
  537:                     # e.g. if self.freq is Nano(1) then dividing by 2
  538:                     #  rounds down to zero
  539:                     freq = None
  540: 
  541:             return type(self)._simple_new(result, dtype=result.dtype, freq=freq)
  542: 
  543:     def _cast_divlike_op(self, other):
  544:         if not hasattr(other, "dtype"):
  545:             # e.g. list, tuple
  546:             other = np.array(other)
  547: 
  548:         if len(other) != len(self):
  549:             raise ValueError("Cannot divide vectors with unequal lengths")
  550:         return other
  551: 
  552:     def _vector_divlike_op(self, other, op) -> np.ndarray | Self:
  553:         """
  554:         Shared logic for __truediv__, __floordiv__, and their reversed versions
  555:         with timedelta64-dtype ndarray other.
  556:         """
  557:         # Let numpy handle it
  558:         result = op(self._ndarray, np.asarray(other))
  559: 
  560:         if (is_integer_dtype(other.dtype) or is_float_dtype(other.dtype)) and op in [
  561:             operator.truediv,
  562:             operator.floordiv,
  563:         ]:
  564:             return type(self)._simple_new(result, dtype=result.dtype)
  565: 
  566:         if op in [operator.floordiv, roperator.rfloordiv]:
  567:             mask = self.isna() | isna(other)
  568:             if mask.any():
  569:                 result = result.astype(np.float64)
  570:                 np.putmask(result, mask, np.nan)
  571: 
  572:         return result
  573: 
  574:     @unpack_zerodim_and_defer("__truediv__")
  575:     def __truediv__(self, other):
  576:         # timedelta / X is well-defined for timedelta-like or numeric X
  577:         op = operator.truediv
  578:         if is_scalar(other):
  579:             return self._scalar_divlike_op(other, op)
  580: 
  581:         other = self._cast_divlike_op(other)
  582:         if (
  583:             lib.is_np_dtype(other.dtype, "m")
  584:             or is_integer_dtype(other.dtype)
  585:             or is_float_dtype(other.dtype)
  586:         ):
  587:             return self._vector_divlike_op(other, op)
  588: 
  589:         if is_object_dtype(other.dtype):
  590:             other = np.asarray(other)
  591:             if self.ndim > 1:
  592:                 res_cols = [left / right for left, right in zip(self, other)]
  593:                 res_cols2 = [x.reshape(1, -1) for x in res_cols]
  594:                 result = np.concatenate(res_cols2, axis=0)
  595:             else:
  596:                 result = truediv_object_array(self._ndarray, other)
  597: 
  598:             return result
  599: 
  600:         else:
  601:             return NotImplemented
  602: 
  603:     @unpack_zerodim_and_defer("__rtruediv__")
  604:     def __rtruediv__(self, other):
  605:         # X / timedelta is defined only for timedelta-like X
  606:         op = roperator.rtruediv
  607:         if is_scalar(other):
  608:             return self._scalar_divlike_op(other, op)
  609: 
  610:         other = self._cast_divlike_op(other)
  611:         if lib.is_np_dtype(other.dtype, "m"):
  612:             return self._vector_divlike_op(other, op)
  613: 
  614:         elif is_object_dtype(other.dtype):
  615:             # Note: unlike in __truediv__, we do not _need_ to do type
  616:             #  inference on the result.  It does not raise, a numeric array
  617:             #  is returned.  GH#23829
  618:             result_list = [other[n] / self[n] for n in range(len(self))]
  619:             return np.array(result_list)
  620: 
  621:         else:
  622:             return NotImplemented
  623: 
  624:     @unpack_zerodim_and_defer("__floordiv__")
  625:     def __floordiv__(self, other):
  626:         op = operator.floordiv
  627:         if is_scalar(other):
  628:             return self._scalar_divlike_op(other, op)
  629: 
  630:         other = self._cast_divlike_op(other)
  631:         if (
  632:             lib.is_np_dtype(other.dtype, "m")
  633:             or is_integer_dtype(other.dtype)
  634:             or is_float_dtype(other.dtype)
  635:         ):
  636:             return self._vector_divlike_op(other, op)
  637: 
  638:         elif is_object_dtype(other.dtype):
  639:             other = np.asarray(other)
  640:             if self.ndim > 1:
  641:                 res_cols = [left // right for left, right in zip(self, other)]
  642:                 res_cols2 = [x.reshape(1, -1) for x in res_cols]
  643:                 result = np.concatenate(res_cols2, axis=0)
  644:             else:
  645:                 result = floordiv_object_array(self._ndarray, other)
  646: 
  647:             assert result.dtype == object
  648:             return result
  649: 
  650:         else:
  651:             return NotImplemented
  652: 
  653:     @unpack_zerodim_and_defer("__rfloordiv__")
  654:     def __rfloordiv__(self, other):
  655:         op = roperator.rfloordiv
  656:         if is_scalar(other):
  657:             return self._scalar_divlike_op(other, op)
  658: 
  659:         other = self._cast_divlike_op(other)
  660:         if lib.is_np_dtype(other.dtype, "m"):
  661:             return self._vector_divlike_op(other, op)
  662: 
  663:         elif is_object_dtype(other.dtype):
  664:             result_list = [other[n] // self[n] for n in range(len(self))]
  665:             result = np.array(result_list)
  666:             return result
  667: 
  668:         else:
  669:             return NotImplemented
  670: 
  671:     @unpack_zerodim_and_defer("__mod__")
  672:     def __mod__(self, other):
  673:         # Note: This is a naive implementation, can likely be optimized
  674:         if isinstance(other, self._recognized_scalars):
  675:             other = Timedelta(other)
  676:         return self - (self // other) * other
  677: 
  678:     @unpack_zerodim_and_defer("__rmod__")
  679:     def __rmod__(self, other):
  680:         # Note: This is a naive implementation, can likely be optimized
  681:         if isinstance(other, self._recognized_scalars):
  682:             other = Timedelta(other)
  683:         return other - (other // self) * self
  684: 
  685:     @unpack_zerodim_and_defer("__divmod__")
  686:     def __divmod__(self, other):
  687:         # Note: This is a naive implementation, can likely be optimized
  688:         if isinstance(other, self._recognized_scalars):
  689:             other = Timedelta(other)
  690: 
  691:         res1 = self // other
  692:         res2 = self - res1 * other
  693:         return res1, res2
  694: 
  695:     @unpack_zerodim_and_defer("__rdivmod__")
  696:     def __rdivmod__(self, other):
  697:         # Note: This is a naive implementation, can likely be optimized
  698:         if isinstance(other, self._recognized_scalars):
  699:             other = Timedelta(other)
  700: 
  701:         res1 = other // self
  702:         res2 = other - res1 * self
  703:         return res1, res2
  704: 
  705:     def __neg__(self) -> TimedeltaArray:
  706:         freq = None
  707:         if self.freq is not None:
  708:             freq = -self.freq
  709:         return type(self)._simple_new(-self._ndarray, dtype=self.dtype, freq=freq)
  710: 
  711:     def __pos__(self) -> TimedeltaArray:
  712:         return type(self)._simple_new(
  713:             self._ndarray.copy(), dtype=self.dtype, freq=self.freq
  714:         )
  715: 
  716:     def __abs__(self) -> TimedeltaArray:
  717:         # Note: freq is not preserved
  718:         return type(self)._simple_new(np.abs(self._ndarray), dtype=self.dtype)
  719: 
  720:     # ----------------------------------------------------------------
  721:     # Conversion Methods - Vectorized analogues of Timedelta methods
  722: 
  723:     def total_seconds(self) -> npt.NDArray[np.float64]:
  724:         """
  725:         Return total duration of each element expressed in seconds.
  726: 
  727:         This method is available directly on TimedeltaArray, TimedeltaIndex
  728:         and on Series containing timedelta values under the ``.dt`` namespace.
  729: 
  730:         Returns
  731:         -------
  732:         ndarray, Index or Series
  733:             When the calling object is a TimedeltaArray, the return type
  734:             is ndarray.  When the calling object is a TimedeltaIndex,
  735:             the return type is an Index with a float64 dtype. When the calling object
  736:             is a Series, the return type is Series of type `float64` whose
  737:             index is the same as the original.
  738: 
  739:         See Also
  740:         --------
  741:         datetime.timedelta.total_seconds : Standard library version
  742:             of this method.
  743:         TimedeltaIndex.components : Return a DataFrame with components of
  744:             each Timedelta.
  745: 
  746:         Examples
  747:         --------
  748:         **Series**
  749: 
  750:         >>> s = pd.Series(pd.to_timedelta(np.arange(5), unit='d'))
  751:         >>> s
  752:         0   0 days
  753:         1   1 days
  754:         2   2 days
  755:         3   3 days
  756:         4   4 days
  757:         dtype: timedelta64[ns]
  758: 
  759:         >>> s.dt.total_seconds()
  760:         0         0.0
  761:         1     86400.0
  762:         2    172800.0
  763:         3    259200.0
  764:         4    345600.0
  765:         dtype: float64
  766: 
  767:         **TimedeltaIndex**
  768: 
  769:         >>> idx = pd.to_timedelta(np.arange(5), unit='d')
  770:         >>> idx
  771:         TimedeltaIndex(['0 days', '1 days', '2 days', '3 days', '4 days'],
  772:                        dtype='timedelta64[ns]', freq=None)
  773: 
  774:         >>> idx.total_seconds()
  775:         Index([0.0, 86400.0, 172800.0, 259200.0, 345600.0], dtype='float64')
  776:         """
  777:         pps = periods_per_second(self._creso)
  778:         return self._maybe_mask_results(self.asi8 / pps, fill_value=None)
  779: 
  780:     def to_pytimedelta(self) -> npt.NDArray[np.object_]:
  781:         """
  782:         Return an ndarray of datetime.timedelta objects.
  783: 
  784:         Returns
  785:         -------
  786:         numpy.ndarray
  787: 
  788:         Examples
  789:         --------
  790:         >>> tdelta_idx = pd.to_timedelta([1, 2, 3], unit='D')
  791:         >>> tdelta_idx
  792:         TimedeltaIndex(['1 days', '2 days', '3 days'],
  793:                         dtype='timedelta64[ns]', freq=None)
  794:         >>> tdelta_idx.to_pytimedelta()
  795:         array([datetime.timedelta(days=1), datetime.timedelta(days=2),
  796:                datetime.timedelta(days=3)], dtype=object)
  797:         """
  798:         return ints_to_pytimedelta(self._ndarray)
  799: 
  800:     days_docstring = textwrap.dedent(
  801:         """Number of days for each element.
  802: 
  803:     Examples
  804:     --------
  805:     For Series:
  806: 
  807:     >>> ser = pd.Series(pd.to_timedelta([1, 2, 3], unit='d'))
  808:     >>> ser
  809:     0   1 days
  810:     1   2 days
  811:     2   3 days
  812:     dtype: timedelta64[ns]
  813:     >>> ser.dt.days
  814:     0    1
  815:     1    2
  816:     2    3
  817:     dtype: int64
  818: 
  819:     For TimedeltaIndex:
  820: 
  821:     >>> tdelta_idx = pd.to_timedelta(["0 days", "10 days", "20 days"])
  822:     >>> tdelta_idx
  823:     TimedeltaIndex(['0 days', '10 days', '20 days'],
  824:                     dtype='timedelta64[ns]', freq=None)
  825:     >>> tdelta_idx.days
  826:     Index([0, 10, 20], dtype='int64')"""
  827:     )
  828:     days = _field_accessor("days", "days", days_docstring)
  829: 
  830:     seconds_docstring = textwrap.dedent(
  831:         """Number of seconds (>= 0 and less than 1 day) for each element.
  832: 
  833:     Examples
  834:     --------
  835:     For Series:
  836: 
  837:     >>> ser = pd.Series(pd.to_timedelta([1, 2, 3], unit='s'))
  838:     >>> ser
  839:     0   0 days 00:00:01
  840:     1   0 days 00:00:02
  841:     2   0 days 00:00:03
  842:     dtype: timedelta64[ns]
  843:     >>> ser.dt.seconds
  844:     0    1
  845:     1    2
  846:     2    3
  847:     dtype: int32
  848: 
  849:     For TimedeltaIndex:
  850: 
  851:     >>> tdelta_idx = pd.to_timedelta([1, 2, 3], unit='s')
  852:     >>> tdelta_idx
  853:     TimedeltaIndex(['0 days 00:00:01', '0 days 00:00:02', '0 days 00:00:03'],
  854:                    dtype='timedelta64[ns]', freq=None)
  855:     >>> tdelta_idx.seconds
  856:     Index([1, 2, 3], dtype='int32')"""
  857:     )
  858:     seconds = _field_accessor(
  859:         "seconds",
  860:         "seconds",
  861:         seconds_docstring,
  862:     )
  863: 
  864:     microseconds_docstring = textwrap.dedent(
  865:         """Number of microseconds (>= 0 and less than 1 second) for each element.
  866: 
  867:     Examples
  868:     --------
  869:     For Series:
  870: 
  871:     >>> ser = pd.Series(pd.to_timedelta([1, 2, 3], unit='us'))
  872:     >>> ser
  873:     0   0 days 00:00:00.000001
  874:     1   0 days 00:00:00.000002
  875:     2   0 days 00:00:00.000003
  876:     dtype: timedelta64[ns]
  877:     >>> ser.dt.microseconds
  878:     0    1
  879:     1    2
  880:     2    3
  881:     dtype: int32
  882: 
  883:     For TimedeltaIndex:
  884: 
  885:     >>> tdelta_idx = pd.to_timedelta([1, 2, 3], unit='us')
  886:     >>> tdelta_idx
  887:     TimedeltaIndex(['0 days 00:00:00.000001', '0 days 00:00:00.000002',
  888:                     '0 days 00:00:00.000003'],
  889:                    dtype='timedelta64[ns]', freq=None)
  890:     >>> tdelta_idx.microseconds
  891:     Index([1, 2, 3], dtype='int32')"""
  892:     )
  893:     microseconds = _field_accessor(
  894:         "microseconds",
  895:         "microseconds",
  896:         microseconds_docstring,
  897:     )
  898: 
  899:     nanoseconds_docstring = textwrap.dedent(
  900:         """Number of nanoseconds (>= 0 and less than 1 microsecond) for each element.
  901: 
  902:     Examples
  903:     --------
  904:     For Series:
  905: 
  906:     >>> ser = pd.Series(pd.to_timedelta([1, 2, 3], unit='ns'))
  907:     >>> ser
  908:     0   0 days 00:00:00.000000001
  909:     1   0 days 00:00:00.000000002
  910:     2   0 days 00:00:00.000000003
  911:     dtype: timedelta64[ns]
  912:     >>> ser.dt.nanoseconds
  913:     0    1
  914:     1    2
  915:     2    3
  916:     dtype: int32
  917: 
  918:     For TimedeltaIndex:
  919: 
  920:     >>> tdelta_idx = pd.to_timedelta([1, 2, 3], unit='ns')
  921:     >>> tdelta_idx
  922:     TimedeltaIndex(['0 days 00:00:00.000000001', '0 days 00:00:00.000000002',
  923:                     '0 days 00:00:00.000000003'],
  924:                    dtype='timedelta64[ns]', freq=None)
  925:     >>> tdelta_idx.nanoseconds
  926:     Index([1, 2, 3], dtype='int32')"""
  927:     )
  928:     nanoseconds = _field_accessor(
  929:         "nanoseconds",
  930:         "nanoseconds",
  931:         nanoseconds_docstring,
  932:     )
  933: 
  934:     @property
  935:     def components(self) -> DataFrame:
  936:         """
  937:         Return a DataFrame of the individual resolution components of the Timedeltas.
  938: 
  939:         The components (days, hours, minutes seconds, milliseconds, microseconds,
  940:         nanoseconds) are returned as columns in a DataFrame.
  941: 
  942:         Returns
  943:         -------
  944:         DataFrame
  945: 
  946:         Examples
  947:         --------
  948:         >>> tdelta_idx = pd.to_timedelta(['1 day 3 min 2 us 42 ns'])
  949:         >>> tdelta_idx
  950:         TimedeltaIndex(['1 days 00:03:00.000002042'],
  951:                        dtype='timedelta64[ns]', freq=None)
  952:         >>> tdelta_idx.components
  953:            days  hours  minutes  seconds  milliseconds  microseconds  nanoseconds
  954:         0     1      0        3        0             0             2           42
  955:         """
  956:         from pandas import DataFrame
  957: 
  958:         columns = [
  959:             "days",
  960:             "hours",
  961:             "minutes",
  962:             "seconds",
  963:             "milliseconds",
  964:             "microseconds",
  965:             "nanoseconds",
  966:         ]
  967:         hasnans = self._hasna
  968:         if hasnans:
  969: 
  970:             def f(x):
  971:                 if isna(x):
  972:                     return [np.nan] * len(columns)
  973:                 return x.components
  974: 
  975:         else:
  976: 
  977:             def f(x):
  978:                 return x.components
  979: 
  980:         result = DataFrame([f(x) for x in self], columns=columns)
  981:         if not hasnans:
  982:             result = result.astype("int64")
  983:         return result
  984: 
  985: 
  986: # ---------------------------------------------------------------------
  987: # Constructor Helpers
  988: 
  989: 
  990: def sequence_to_td64ns(
  991:     data,
  992:     copy: bool = False,
  993:     unit=None,
  994:     errors: DateTimeErrorChoices = "raise",
  995: ) -> tuple[np.ndarray, Tick | None]:
  996:     """
  997:     Parameters
  998:     ----------
  999:     data : list-like
 1000:     copy : bool, default False
 1001:     unit : str, optional
 1002:         The timedelta unit to treat integers as multiples of. For numeric
 1003:         data this defaults to ``'ns'``.
 1004:         Must be un-specified if the data contains a str and ``errors=="raise"``.
 1005:     errors : {"raise", "coerce", "ignore"}, default "raise"
 1006:         How to handle elements that cannot be converted to timedelta64[ns].
 1007:         See ``pandas.to_timedelta`` for details.
 1008: 
 1009:     Returns
 1010:     -------
 1011:     converted : numpy.ndarray
 1012:         The sequence converted to a numpy array with dtype ``timedelta64[ns]``.
 1013:     inferred_freq : Tick or None
 1014:         The inferred frequency of the sequence.
 1015: 
 1016:     Raises
 1017:     ------
 1018:     ValueError : Data cannot be converted to timedelta64[ns].
 1019: 
 1020:     Notes
 1021:     -----
 1022:     Unlike `pandas.to_timedelta`, if setting ``errors=ignore`` will not cause
 1023:     errors to be ignored; they are caught and subsequently ignored at a
 1024:     higher level.
 1025:     """
 1026:     assert unit not in ["Y", "y", "M"]  # caller is responsible for checking
 1027: 
 1028:     inferred_freq = None
 1029:     if unit is not None:
 1030:         unit = parse_timedelta_unit(unit)
 1031: 
 1032:     data, copy = dtl.ensure_arraylike_for_datetimelike(
 1033:         data, copy, cls_name="TimedeltaArray"
 1034:     )
 1035: 
 1036:     if isinstance(data, TimedeltaArray):
 1037:         inferred_freq = data.freq
 1038: 
 1039:     # Convert whatever we have into timedelta64[ns] dtype
 1040:     if data.dtype == object or is_string_dtype(data.dtype):
 1041:         # no need to make a copy, need to convert if string-dtyped
 1042:         data = _objects_to_td64ns(data, unit=unit, errors=errors)
 1043:         copy = False
 1044: 
 1045:     elif is_integer_dtype(data.dtype):
 1046:         # treat as multiples of the given unit
 1047:         data, copy_made = _ints_to_td64ns(data, unit=unit)
 1048:         copy = copy and not copy_made
 1049: 
 1050:     elif is_float_dtype(data.dtype):
 1051:         # cast the unit, multiply base/frac separately
 1052:         # to avoid precision issues from float -> int
 1053:         if isinstance(data.dtype, ExtensionDtype):
 1054:             mask = data._mask
 1055:             data = data._data
 1056:         else:
 1057:             mask = np.isnan(data)
 1058: 
 1059:         data = cast_from_unit_vectorized(data, unit or "ns")
 1060:         data[mask] = iNaT
 1061:         data = data.view("m8[ns]")
 1062:         copy = False
 1063: 
 1064:     elif lib.is_np_dtype(data.dtype, "m"):
 1065:         if not is_supported_dtype(data.dtype):
 1066:             # cast to closest supported unit, i.e. s or ns
 1067:             new_dtype = get_supported_dtype(data.dtype)
 1068:             data = astype_overflowsafe(data, dtype=new_dtype, copy=False)
 1069:             copy = False
 1070: 
 1071:     else:
 1072:         # This includes datetime64-dtype, see GH#23539, GH#29794
 1073:         raise TypeError(f"dtype {data.dtype} cannot be converted to timedelta64[ns]")
 1074: 
 1075:     if not copy:
 1076:         data = np.asarray(data)
 1077:     else:
 1078:         data = np.array(data, copy=copy)
 1079: 
 1080:     assert data.dtype.kind == "m"
 1081:     assert data.dtype != "m8"  # i.e. not unit-less
 1082: 
 1083:     return data, inferred_freq
 1084: 
 1085: 
 1086: def _ints_to_td64ns(data, unit: str = "ns"):
 1087:     """
 1088:     Convert an ndarray with integer-dtype to timedelta64[ns] dtype, treating
 1089:     the integers as multiples of the given timedelta unit.
 1090: 
 1091:     Parameters
 1092:     ----------
 1093:     data : numpy.ndarray with integer-dtype
 1094:     unit : str, default "ns"
 1095:         The timedelta unit to treat integers as multiples of.
 1096: 
 1097:     Returns
 1098:     -------
 1099:     numpy.ndarray : timedelta64[ns] array converted from data
 1100:     bool : whether a copy was made
 1101:     """
 1102:     copy_made = False
 1103:     unit = unit if unit is not None else "ns"
 1104: 
 1105:     if data.dtype != np.int64:
 1106:         # converting to int64 makes a copy, so we can avoid
 1107:         # re-copying later
 1108:         data = data.astype(np.int64)
 1109:         copy_made = True
 1110: 
 1111:     if unit != "ns":
 1112:         dtype_str = f"timedelta64[{unit}]"
 1113:         data = data.view(dtype_str)
 1114: 
 1115:         data = astype_overflowsafe(data, dtype=TD64NS_DTYPE)
 1116: 
 1117:         # the astype conversion makes a copy, so we can avoid re-copying later
 1118:         copy_made = True
 1119: 
 1120:     else:
 1121:         data = data.view("timedelta64[ns]")
 1122: 
 1123:     return data, copy_made
 1124: 
 1125: 
 1126: def _objects_to_td64ns(data, unit=None, errors: DateTimeErrorChoices = "raise"):
 1127:     """
 1128:     Convert a object-dtyped or string-dtyped array into an
 1129:     timedelta64[ns]-dtyped array.
 1130: 
 1131:     Parameters
 1132:     ----------
 1133:     data : ndarray or Index
 1134:     unit : str, default "ns"
 1135:         The timedelta unit to treat integers as multiples of.
 1136:         Must not be specified if the data contains a str.
 1137:     errors : {"raise", "coerce", "ignore"}, default "raise"
 1138:         How to handle elements that cannot be converted to timedelta64[ns].
 1139:         See ``pandas.to_timedelta`` for details.
 1140: 
 1141:     Returns
 1142:     -------
 1143:     numpy.ndarray : timedelta64[ns] array converted from data
 1144: 
 1145:     Raises
 1146:     ------
 1147:     ValueError : Data cannot be converted to timedelta64[ns].
 1148: 
 1149:     Notes
 1150:     -----
 1151:     Unlike `pandas.to_timedelta`, if setting `errors=ignore` will not cause
 1152:     errors to be ignored; they are caught and subsequently ignored at a
 1153:     higher level.
 1154:     """
 1155:     # coerce Index to np.ndarray, converting string-dtype if necessary
 1156:     values = np.asarray(data, dtype=np.object_)
 1157: 
 1158:     result = array_to_timedelta64(values, unit=unit, errors=errors)
 1159:     return result.view("timedelta64[ns]")
 1160: 
 1161: 
 1162: def _validate_td64_dtype(dtype) -> DtypeObj:
 1163:     dtype = pandas_dtype(dtype)
 1164:     if dtype == np.dtype("m8"):
 1165:         # no precision disallowed GH#24806
 1166:         msg = (
 1167:             "Passing in 'timedelta' dtype with no precision is not allowed. "
 1168:             "Please pass in 'timedelta64[ns]' instead."
 1169:         )
 1170:         raise ValueError(msg)
 1171: 
 1172:     if not lib.is_np_dtype(dtype, "m"):
 1173:         raise ValueError(f"dtype '{dtype}' is invalid, should be np.timedelta64 dtype")
 1174:     elif not is_supported_dtype(dtype):
 1175:         raise ValueError("Supported timedelta64 resolutions are 's', 'ms', 'us', 'ns'")
 1176: 
 1177:     return dtype
