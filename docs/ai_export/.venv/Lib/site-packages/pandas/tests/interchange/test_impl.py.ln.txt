    1: from datetime import (
    2:     datetime,
    3:     timezone,
    4: )
    5: 
    6: import numpy as np
    7: import pytest
    8: 
    9: from pandas._libs.tslibs import iNaT
   10: from pandas.compat import (
   11:     is_ci_environment,
   12:     is_platform_windows,
   13: )
   14: from pandas.compat.numpy import np_version_lt1p23
   15: 
   16: import pandas as pd
   17: import pandas._testing as tm
   18: from pandas.core.interchange.column import PandasColumn
   19: from pandas.core.interchange.dataframe_protocol import (
   20:     ColumnNullType,
   21:     DtypeKind,
   22: )
   23: from pandas.core.interchange.from_dataframe import from_dataframe
   24: from pandas.core.interchange.utils import ArrowCTypes
   25: 
   26: 
   27: @pytest.fixture
   28: def data_categorical():
   29:     return {
   30:         "ordered": pd.Categorical(list("testdata") * 30, ordered=True),
   31:         "unordered": pd.Categorical(list("testdata") * 30, ordered=False),
   32:     }
   33: 
   34: 
   35: @pytest.fixture
   36: def string_data():
   37:     return {
   38:         "separator data": [
   39:             "abC|DeF,Hik",
   40:             "234,3245.67",
   41:             "gSaf,qWer|Gre",
   42:             "asd3,4sad|",
   43:             np.nan,
   44:         ]
   45:     }
   46: 
   47: 
   48: @pytest.mark.parametrize("data", [("ordered", True), ("unordered", False)])
   49: def test_categorical_dtype(data, data_categorical):
   50:     df = pd.DataFrame({"A": (data_categorical[data[0]])})
   51: 
   52:     col = df.__dataframe__().get_column_by_name("A")
   53:     assert col.dtype[0] == DtypeKind.CATEGORICAL
   54:     assert col.null_count == 0
   55:     assert col.describe_null == (ColumnNullType.USE_SENTINEL, -1)
   56:     assert col.num_chunks() == 1
   57:     desc_cat = col.describe_categorical
   58:     assert desc_cat["is_ordered"] == data[1]
   59:     assert desc_cat["is_dictionary"] is True
   60:     assert isinstance(desc_cat["categories"], PandasColumn)
   61:     tm.assert_series_equal(
   62:         desc_cat["categories"]._col, pd.Series(["a", "d", "e", "s", "t"])
   63:     )
   64: 
   65:     tm.assert_frame_equal(df, from_dataframe(df.__dataframe__()))
   66: 
   67: 
   68: def test_categorical_pyarrow():
   69:     # GH 49889
   70:     pa = pytest.importorskip("pyarrow", "11.0.0")
   71: 
   72:     arr = ["Mon", "Tue", "Mon", "Wed", "Mon", "Thu", "Fri", "Sat", "Sun"]
   73:     table = pa.table({"weekday": pa.array(arr).dictionary_encode()})
   74:     exchange_df = table.__dataframe__()
   75:     result = from_dataframe(exchange_df)
   76:     weekday = pd.Categorical(
   77:         arr, categories=["Mon", "Tue", "Wed", "Thu", "Fri", "Sat", "Sun"]
   78:     )
   79:     expected = pd.DataFrame({"weekday": weekday})
   80:     tm.assert_frame_equal(result, expected)
   81: 
   82: 
   83: def test_empty_categorical_pyarrow():
   84:     # https://github.com/pandas-dev/pandas/issues/53077
   85:     pa = pytest.importorskip("pyarrow", "11.0.0")
   86: 
   87:     arr = [None]
   88:     table = pa.table({"arr": pa.array(arr, "float64").dictionary_encode()})
   89:     exchange_df = table.__dataframe__()
   90:     result = pd.api.interchange.from_dataframe(exchange_df)
   91:     expected = pd.DataFrame({"arr": pd.Categorical([np.nan])})
   92:     tm.assert_frame_equal(result, expected)
   93: 
   94: 
   95: def test_large_string_pyarrow():
   96:     # GH 52795
   97:     pa = pytest.importorskip("pyarrow", "11.0.0")
   98: 
   99:     arr = ["Mon", "Tue"]
  100:     table = pa.table({"weekday": pa.array(arr, "large_string")})
  101:     exchange_df = table.__dataframe__()
  102:     result = from_dataframe(exchange_df)
  103:     expected = pd.DataFrame({"weekday": ["Mon", "Tue"]})
  104:     tm.assert_frame_equal(result, expected)
  105: 
  106:     # check round-trip
  107:     assert pa.Table.equals(pa.interchange.from_dataframe(result), table)
  108: 
  109: 
  110: @pytest.mark.parametrize(
  111:     ("offset", "length", "expected_values"),
  112:     [
  113:         (0, None, [3.3, float("nan"), 2.1]),
  114:         (1, None, [float("nan"), 2.1]),
  115:         (2, None, [2.1]),
  116:         (0, 2, [3.3, float("nan")]),
  117:         (0, 1, [3.3]),
  118:         (1, 1, [float("nan")]),
  119:     ],
  120: )
  121: def test_bitmasks_pyarrow(offset, length, expected_values):
  122:     # GH 52795
  123:     pa = pytest.importorskip("pyarrow", "11.0.0")
  124: 
  125:     arr = [3.3, None, 2.1]
  126:     table = pa.table({"arr": arr}).slice(offset, length)
  127:     exchange_df = table.__dataframe__()
  128:     result = from_dataframe(exchange_df)
  129:     expected = pd.DataFrame({"arr": expected_values})
  130:     tm.assert_frame_equal(result, expected)
  131: 
  132:     # check round-trip
  133:     assert pa.Table.equals(pa.interchange.from_dataframe(result), table)
  134: 
  135: 
  136: @pytest.mark.parametrize(
  137:     "data",
  138:     [
  139:         lambda: np.random.default_rng(2).integers(-100, 100),
  140:         lambda: np.random.default_rng(2).integers(1, 100),
  141:         lambda: np.random.default_rng(2).random(),
  142:         lambda: np.random.default_rng(2).choice([True, False]),
  143:         lambda: datetime(
  144:             year=np.random.default_rng(2).integers(1900, 2100),
  145:             month=np.random.default_rng(2).integers(1, 12),
  146:             day=np.random.default_rng(2).integers(1, 20),
  147:         ),
  148:     ],
  149: )
  150: def test_dataframe(data):
  151:     NCOLS, NROWS = 10, 20
  152:     data = {
  153:         f"col{int((i - NCOLS / 2) % NCOLS + 1)}": [data() for _ in range(NROWS)]
  154:         for i in range(NCOLS)
  155:     }
  156:     df = pd.DataFrame(data)
  157: 
  158:     df2 = df.__dataframe__()
  159: 
  160:     assert df2.num_columns() == NCOLS
  161:     assert df2.num_rows() == NROWS
  162: 
  163:     assert list(df2.column_names()) == list(data.keys())
  164: 
  165:     indices = (0, 2)
  166:     names = tuple(list(data.keys())[idx] for idx in indices)
  167: 
  168:     result = from_dataframe(df2.select_columns(indices))
  169:     expected = from_dataframe(df2.select_columns_by_name(names))
  170:     tm.assert_frame_equal(result, expected)
  171: 
  172:     assert isinstance(result.attrs["_INTERCHANGE_PROTOCOL_BUFFERS"], list)
  173:     assert isinstance(expected.attrs["_INTERCHANGE_PROTOCOL_BUFFERS"], list)
  174: 
  175: 
  176: def test_missing_from_masked():
  177:     df = pd.DataFrame(
  178:         {
  179:             "x": np.array([1.0, 2.0, 3.0, 4.0, 0.0]),
  180:             "y": np.array([1.5, 2.5, 3.5, 4.5, 0]),
  181:             "z": np.array([1.0, 0.0, 1.0, 1.0, 1.0]),
  182:         }
  183:     )
  184: 
  185:     rng = np.random.default_rng(2)
  186:     dict_null = {col: rng.integers(low=0, high=len(df)) for col in df.columns}
  187:     for col, num_nulls in dict_null.items():
  188:         null_idx = df.index[
  189:             rng.choice(np.arange(len(df)), size=num_nulls, replace=False)
  190:         ]
  191:         df.loc[null_idx, col] = None
  192: 
  193:     df2 = df.__dataframe__()
  194: 
  195:     assert df2.get_column_by_name("x").null_count == dict_null["x"]
  196:     assert df2.get_column_by_name("y").null_count == dict_null["y"]
  197:     assert df2.get_column_by_name("z").null_count == dict_null["z"]
  198: 
  199: 
  200: @pytest.mark.parametrize(
  201:     "data",
  202:     [
  203:         {"x": [1.5, 2.5, 3.5], "y": [9.2, 10.5, 11.8]},
  204:         {"x": [1, 2, 0], "y": [9.2, 10.5, 11.8]},
  205:         {
  206:             "x": np.array([True, True, False]),
  207:             "y": np.array([1, 2, 0]),
  208:             "z": np.array([9.2, 10.5, 11.8]),
  209:         },
  210:     ],
  211: )
  212: def test_mixed_data(data):
  213:     df = pd.DataFrame(data)
  214:     df2 = df.__dataframe__()
  215: 
  216:     for col_name in df.columns:
  217:         assert df2.get_column_by_name(col_name).null_count == 0
  218: 
  219: 
  220: def test_mixed_missing():
  221:     df = pd.DataFrame(
  222:         {
  223:             "x": np.array([True, None, False, None, True]),
  224:             "y": np.array([None, 2, None, 1, 2]),
  225:             "z": np.array([9.2, 10.5, None, 11.8, None]),
  226:         }
  227:     )
  228: 
  229:     df2 = df.__dataframe__()
  230: 
  231:     for col_name in df.columns:
  232:         assert df2.get_column_by_name(col_name).null_count == 2
  233: 
  234: 
  235: def test_string(string_data):
  236:     test_str_data = string_data["separator data"] + [""]
  237:     df = pd.DataFrame({"A": test_str_data})
  238:     col = df.__dataframe__().get_column_by_name("A")
  239: 
  240:     assert col.size() == 6
  241:     assert col.null_count == 1
  242:     assert col.dtype[0] == DtypeKind.STRING
  243:     assert col.describe_null == (ColumnNullType.USE_BYTEMASK, 0)
  244: 
  245:     df_sliced = df[1:]
  246:     col = df_sliced.__dataframe__().get_column_by_name("A")
  247:     assert col.size() == 5
  248:     assert col.null_count == 1
  249:     assert col.dtype[0] == DtypeKind.STRING
  250:     assert col.describe_null == (ColumnNullType.USE_BYTEMASK, 0)
  251: 
  252: 
  253: def test_nonstring_object():
  254:     df = pd.DataFrame({"A": ["a", 10, 1.0, ()]})
  255:     col = df.__dataframe__().get_column_by_name("A")
  256:     with pytest.raises(NotImplementedError, match="not supported yet"):
  257:         col.dtype
  258: 
  259: 
  260: def test_datetime():
  261:     df = pd.DataFrame({"A": [pd.Timestamp("2022-01-01"), pd.NaT]})
  262:     col = df.__dataframe__().get_column_by_name("A")
  263: 
  264:     assert col.size() == 2
  265:     assert col.null_count == 1
  266:     assert col.dtype[0] == DtypeKind.DATETIME
  267:     assert col.describe_null == (ColumnNullType.USE_SENTINEL, iNaT)
  268: 
  269:     tm.assert_frame_equal(df, from_dataframe(df.__dataframe__()))
  270: 
  271: 
  272: @pytest.mark.skipif(np_version_lt1p23, reason="Numpy > 1.23 required")
  273: def test_categorical_to_numpy_dlpack():
  274:     # https://github.com/pandas-dev/pandas/issues/48393
  275:     df = pd.DataFrame({"A": pd.Categorical(["a", "b", "a"])})
  276:     col = df.__dataframe__().get_column_by_name("A")
  277:     result = np.from_dlpack(col.get_buffers()["data"][0])
  278:     expected = np.array([0, 1, 0], dtype="int8")
  279:     tm.assert_numpy_array_equal(result, expected)
  280: 
  281: 
  282: @pytest.mark.parametrize("data", [{}, {"a": []}])
  283: def test_empty_pyarrow(data):
  284:     # GH 53155
  285:     pytest.importorskip("pyarrow", "11.0.0")
  286:     from pyarrow.interchange import from_dataframe as pa_from_dataframe
  287: 
  288:     expected = pd.DataFrame(data)
  289:     arrow_df = pa_from_dataframe(expected)
  290:     result = from_dataframe(arrow_df)
  291:     tm.assert_frame_equal(result, expected)
  292: 
  293: 
  294: def test_multi_chunk_pyarrow() -> None:
  295:     pa = pytest.importorskip("pyarrow", "11.0.0")
  296:     n_legs = pa.chunked_array([[2, 2, 4], [4, 5, 100]])
  297:     names = ["n_legs"]
  298:     table = pa.table([n_legs], names=names)
  299:     with pytest.raises(
  300:         RuntimeError,
  301:         match="To join chunks a copy is required which is "
  302:         "forbidden by allow_copy=False",
  303:     ):
  304:         pd.api.interchange.from_dataframe(table, allow_copy=False)
  305: 
  306: 
  307: def test_multi_chunk_column() -> None:
  308:     pytest.importorskip("pyarrow", "11.0.0")
  309:     ser = pd.Series([1, 2, None], dtype="Int64[pyarrow]")
  310:     df = pd.concat([ser, ser], ignore_index=True).to_frame("a")
  311:     df_orig = df.copy()
  312:     with pytest.raises(
  313:         RuntimeError, match="Found multi-chunk pyarrow array, but `allow_copy` is False"
  314:     ):
  315:         pd.api.interchange.from_dataframe(df.__dataframe__(allow_copy=False))
  316:     result = pd.api.interchange.from_dataframe(df.__dataframe__(allow_copy=True))
  317:     # Interchange protocol defaults to creating numpy-backed columns, so currently this
  318:     # is 'float64'.
  319:     expected = pd.DataFrame({"a": [1.0, 2.0, None, 1.0, 2.0, None]}, dtype="float64")
  320:     tm.assert_frame_equal(result, expected)
  321: 
  322:     # Check that the rechunking we did didn't modify the original DataFrame.
  323:     tm.assert_frame_equal(df, df_orig)
  324:     assert len(df["a"].array._pa_array.chunks) == 2
  325:     assert len(df_orig["a"].array._pa_array.chunks) == 2
  326: 
  327: 
  328: def test_timestamp_ns_pyarrow():
  329:     # GH 56712
  330:     pytest.importorskip("pyarrow", "11.0.0")
  331:     timestamp_args = {
  332:         "year": 2000,
  333:         "month": 1,
  334:         "day": 1,
  335:         "hour": 1,
  336:         "minute": 1,
  337:         "second": 1,
  338:     }
  339:     df = pd.Series(
  340:         [datetime(**timestamp_args)],
  341:         dtype="timestamp[ns][pyarrow]",
  342:         name="col0",
  343:     ).to_frame()
  344: 
  345:     dfi = df.__dataframe__()
  346:     result = pd.api.interchange.from_dataframe(dfi)["col0"].item()
  347: 
  348:     expected = pd.Timestamp(**timestamp_args)
  349:     assert result == expected
  350: 
  351: 
  352: @pytest.mark.parametrize("tz", ["UTC", "US/Pacific"])
  353: @pytest.mark.parametrize("unit", ["s", "ms", "us", "ns"])
  354: def test_datetimetzdtype(tz, unit):
  355:     # GH 54239
  356:     tz_data = (
  357:         pd.date_range("2018-01-01", periods=5, freq="D").tz_localize(tz).as_unit(unit)
  358:     )
  359:     df = pd.DataFrame({"ts_tz": tz_data})
  360:     tm.assert_frame_equal(df, from_dataframe(df.__dataframe__()))
  361: 
  362: 
  363: def test_interchange_from_non_pandas_tz_aware(request):
  364:     # GH 54239, 54287
  365:     pa = pytest.importorskip("pyarrow", "11.0.0")
  366:     import pyarrow.compute as pc
  367: 
  368:     if is_platform_windows() and is_ci_environment():
  369:         mark = pytest.mark.xfail(
  370:             raises=pa.ArrowInvalid,
  371:             reason=(
  372:                 "TODO: Set ARROW_TIMEZONE_DATABASE environment variable "
  373:                 "on CI to path to the tzdata for pyarrow."
  374:             ),
  375:         )
  376:         request.applymarker(mark)
  377: 
  378:     arr = pa.array([datetime(2020, 1, 1), None, datetime(2020, 1, 2)])
  379:     arr = pc.assume_timezone(arr, "Asia/Kathmandu")
  380:     table = pa.table({"arr": arr})
  381:     exchange_df = table.__dataframe__()
  382:     result = from_dataframe(exchange_df)
  383: 
  384:     expected = pd.DataFrame(
  385:         ["2020-01-01 00:00:00+05:45", "NaT", "2020-01-02 00:00:00+05:45"],
  386:         columns=["arr"],
  387:         dtype="datetime64[us, Asia/Kathmandu]",
  388:     )
  389:     tm.assert_frame_equal(expected, result)
  390: 
  391: 
  392: def test_interchange_from_corrected_buffer_dtypes(monkeypatch) -> None:
  393:     # https://github.com/pandas-dev/pandas/issues/54781
  394:     df = pd.DataFrame({"a": ["foo", "bar"]}).__dataframe__()
  395:     interchange = df.__dataframe__()
  396:     column = interchange.get_column_by_name("a")
  397:     buffers = column.get_buffers()
  398:     buffers_data = buffers["data"]
  399:     buffer_dtype = buffers_data[1]
  400:     buffer_dtype = (
  401:         DtypeKind.UINT,
  402:         8,
  403:         ArrowCTypes.UINT8,
  404:         buffer_dtype[3],
  405:     )
  406:     buffers["data"] = (buffers_data[0], buffer_dtype)
  407:     column.get_buffers = lambda: buffers
  408:     interchange.get_column_by_name = lambda _: column
  409:     monkeypatch.setattr(df, "__dataframe__", lambda allow_copy: interchange)
  410:     pd.api.interchange.from_dataframe(df)
  411: 
  412: 
  413: def test_empty_string_column():
  414:     # https://github.com/pandas-dev/pandas/issues/56703
  415:     df = pd.DataFrame({"a": []}, dtype=str)
  416:     df2 = df.__dataframe__()
  417:     result = pd.api.interchange.from_dataframe(df2)
  418:     tm.assert_frame_equal(df, result)
  419: 
  420: 
  421: def test_large_string():
  422:     # GH#56702
  423:     pytest.importorskip("pyarrow")
  424:     df = pd.DataFrame({"a": ["x"]}, dtype="large_string[pyarrow]")
  425:     result = pd.api.interchange.from_dataframe(df.__dataframe__())
  426:     expected = pd.DataFrame({"a": ["x"]}, dtype="object")
  427:     tm.assert_frame_equal(result, expected)
  428: 
  429: 
  430: def test_non_str_names():
  431:     # https://github.com/pandas-dev/pandas/issues/56701
  432:     df = pd.Series([1, 2, 3], name=0).to_frame()
  433:     names = df.__dataframe__().column_names()
  434:     assert names == ["0"]
  435: 
  436: 
  437: def test_non_str_names_w_duplicates():
  438:     # https://github.com/pandas-dev/pandas/issues/56701
  439:     df = pd.DataFrame({"0": [1, 2, 3], 0: [4, 5, 6]})
  440:     dfi = df.__dataframe__()
  441:     with pytest.raises(
  442:         TypeError,
  443:         match=(
  444:             "Expected a Series, got a DataFrame. This likely happened because you "
  445:             "called __dataframe__ on a DataFrame which, after converting column "
  446:             r"names to string, resulted in duplicated names: Index\(\['0', '0'\], "
  447:             r"dtype='object'\). Please rename these columns before using the "
  448:             "interchange protocol."
  449:         ),
  450:     ):
  451:         pd.api.interchange.from_dataframe(dfi, allow_copy=False)
  452: 
  453: 
  454: @pytest.mark.parametrize(
  455:     ("data", "dtype", "expected_dtype"),
  456:     [
  457:         ([1, 2, None], "Int64", "int64"),
  458:         ([1, 2, None], "Int64[pyarrow]", "int64"),
  459:         ([1, 2, None], "Int8", "int8"),
  460:         ([1, 2, None], "Int8[pyarrow]", "int8"),
  461:         (
  462:             [1, 2, None],
  463:             "UInt64",
  464:             "uint64",
  465:         ),
  466:         (
  467:             [1, 2, None],
  468:             "UInt64[pyarrow]",
  469:             "uint64",
  470:         ),
  471:         ([1.0, 2.25, None], "Float32", "float32"),
  472:         ([1.0, 2.25, None], "Float32[pyarrow]", "float32"),
  473:         ([True, False, None], "boolean", "bool"),
  474:         ([True, False, None], "boolean[pyarrow]", "bool"),
  475:         (["much ado", "about", None], "string[pyarrow_numpy]", "large_string"),
  476:         (["much ado", "about", None], "string[pyarrow]", "large_string"),
  477:         (
  478:             [datetime(2020, 1, 1), datetime(2020, 1, 2), None],
  479:             "timestamp[ns][pyarrow]",
  480:             "timestamp[ns]",
  481:         ),
  482:         (
  483:             [datetime(2020, 1, 1), datetime(2020, 1, 2), None],
  484:             "timestamp[us][pyarrow]",
  485:             "timestamp[us]",
  486:         ),
  487:         (
  488:             [
  489:                 datetime(2020, 1, 1, tzinfo=timezone.utc),
  490:                 datetime(2020, 1, 2, tzinfo=timezone.utc),
  491:                 None,
  492:             ],
  493:             "timestamp[us, Asia/Kathmandu][pyarrow]",
  494:             "timestamp[us, tz=Asia/Kathmandu]",
  495:         ),
  496:     ],
  497: )
  498: def test_pandas_nullable_with_missing_values(
  499:     data: list, dtype: str, expected_dtype: str
  500: ) -> None:
  501:     # https://github.com/pandas-dev/pandas/issues/57643
  502:     # https://github.com/pandas-dev/pandas/issues/57664
  503:     pa = pytest.importorskip("pyarrow", "11.0.0")
  504:     import pyarrow.interchange as pai
  505: 
  506:     if expected_dtype == "timestamp[us, tz=Asia/Kathmandu]":
  507:         expected_dtype = pa.timestamp("us", "Asia/Kathmandu")
  508: 
  509:     df = pd.DataFrame({"a": data}, dtype=dtype)
  510:     result = pai.from_dataframe(df.__dataframe__())["a"]
  511:     assert result.type == expected_dtype
  512:     assert result[0].as_py() == data[0]
  513:     assert result[1].as_py() == data[1]
  514:     assert result[2].as_py() is None
  515: 
  516: 
  517: @pytest.mark.parametrize(
  518:     ("data", "dtype", "expected_dtype"),
  519:     [
  520:         ([1, 2, 3], "Int64", "int64"),
  521:         ([1, 2, 3], "Int64[pyarrow]", "int64"),
  522:         ([1, 2, 3], "Int8", "int8"),
  523:         ([1, 2, 3], "Int8[pyarrow]", "int8"),
  524:         (
  525:             [1, 2, 3],
  526:             "UInt64",
  527:             "uint64",
  528:         ),
  529:         (
  530:             [1, 2, 3],
  531:             "UInt64[pyarrow]",
  532:             "uint64",
  533:         ),
  534:         ([1.0, 2.25, 5.0], "Float32", "float32"),
  535:         ([1.0, 2.25, 5.0], "Float32[pyarrow]", "float32"),
  536:         ([True, False, False], "boolean", "bool"),
  537:         ([True, False, False], "boolean[pyarrow]", "bool"),
  538:         (["much ado", "about", "nothing"], "string[pyarrow_numpy]", "large_string"),
  539:         (["much ado", "about", "nothing"], "string[pyarrow]", "large_string"),
  540:         (
  541:             [datetime(2020, 1, 1), datetime(2020, 1, 2), datetime(2020, 1, 3)],
  542:             "timestamp[ns][pyarrow]",
  543:             "timestamp[ns]",
  544:         ),
  545:         (
  546:             [datetime(2020, 1, 1), datetime(2020, 1, 2), datetime(2020, 1, 3)],
  547:             "timestamp[us][pyarrow]",
  548:             "timestamp[us]",
  549:         ),
  550:         (
  551:             [
  552:                 datetime(2020, 1, 1, tzinfo=timezone.utc),
  553:                 datetime(2020, 1, 2, tzinfo=timezone.utc),
  554:                 datetime(2020, 1, 3, tzinfo=timezone.utc),
  555:             ],
  556:             "timestamp[us, Asia/Kathmandu][pyarrow]",
  557:             "timestamp[us, tz=Asia/Kathmandu]",
  558:         ),
  559:     ],
  560: )
  561: def test_pandas_nullable_without_missing_values(
  562:     data: list, dtype: str, expected_dtype: str
  563: ) -> None:
  564:     # https://github.com/pandas-dev/pandas/issues/57643
  565:     pa = pytest.importorskip("pyarrow", "11.0.0")
  566:     import pyarrow.interchange as pai
  567: 
  568:     if expected_dtype == "timestamp[us, tz=Asia/Kathmandu]":
  569:         expected_dtype = pa.timestamp("us", "Asia/Kathmandu")
  570: 
  571:     df = pd.DataFrame({"a": data}, dtype=dtype)
  572:     result = pai.from_dataframe(df.__dataframe__())["a"]
  573:     assert result.type == expected_dtype
  574:     assert result[0].as_py() == data[0]
  575:     assert result[1].as_py() == data[1]
  576:     assert result[2].as_py() == data[2]
  577: 
  578: 
  579: def test_string_validity_buffer() -> None:
  580:     # https://github.com/pandas-dev/pandas/issues/57761
  581:     pytest.importorskip("pyarrow", "11.0.0")
  582:     df = pd.DataFrame({"a": ["x"]}, dtype="large_string[pyarrow]")
  583:     result = df.__dataframe__().get_column_by_name("a").get_buffers()["validity"]
  584:     assert result is None
  585: 
  586: 
  587: def test_string_validity_buffer_no_missing() -> None:
  588:     # https://github.com/pandas-dev/pandas/issues/57762
  589:     pytest.importorskip("pyarrow", "11.0.0")
  590:     df = pd.DataFrame({"a": ["x", None]}, dtype="large_string[pyarrow]")
  591:     validity = df.__dataframe__().get_column_by_name("a").get_buffers()["validity"]
  592:     assert validity is not None
  593:     result = validity[1]
  594:     expected = (DtypeKind.BOOL, 1, ArrowCTypes.BOOL, "=")
  595:     assert result == expected
  596: 
  597: 
  598: def test_empty_dataframe():
  599:     # https://github.com/pandas-dev/pandas/issues/56700
  600:     df = pd.DataFrame({"a": []}, dtype="int8")
  601:     dfi = df.__dataframe__()
  602:     result = pd.api.interchange.from_dataframe(dfi, allow_copy=False)
  603:     expected = pd.DataFrame({"a": []}, dtype="int8")
  604:     tm.assert_frame_equal(result, expected)
