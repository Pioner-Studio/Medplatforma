    1: # Arithmetic tests for DataFrame/Series/Index/Array classes that should
    2: # behave identically.
    3: # Specifically for datetime64 and datetime64tz dtypes
    4: from datetime import (
    5:     datetime,
    6:     time,
    7:     timedelta,
    8: )
    9: from itertools import (
   10:     product,
   11:     starmap,
   12: )
   13: import operator
   14: 
   15: import numpy as np
   16: import pytest
   17: import pytz
   18: 
   19: from pandas._libs.tslibs.conversion import localize_pydatetime
   20: from pandas._libs.tslibs.offsets import shift_months
   21: from pandas.errors import PerformanceWarning
   22: 
   23: import pandas as pd
   24: from pandas import (
   25:     DateOffset,
   26:     DatetimeIndex,
   27:     NaT,
   28:     Period,
   29:     Series,
   30:     Timedelta,
   31:     TimedeltaIndex,
   32:     Timestamp,
   33:     date_range,
   34: )
   35: import pandas._testing as tm
   36: from pandas.core import roperator
   37: from pandas.tests.arithmetic.common import (
   38:     assert_cannot_add,
   39:     assert_invalid_addsub_type,
   40:     assert_invalid_comparison,
   41:     get_upcast_box,
   42: )
   43: 
   44: # ------------------------------------------------------------------
   45: # Comparisons
   46: 
   47: 
   48: class TestDatetime64ArrayLikeComparisons:
   49:     # Comparison tests for datetime64 vectors fully parametrized over
   50:     #  DataFrame/Series/DatetimeIndex/DatetimeArray.  Ideally all comparison
   51:     #  tests will eventually end up here.
   52: 
   53:     def test_compare_zerodim(self, tz_naive_fixture, box_with_array):
   54:         # Test comparison with zero-dimensional array is unboxed
   55:         tz = tz_naive_fixture
   56:         box = box_with_array
   57:         dti = date_range("20130101", periods=3, tz=tz)
   58: 
   59:         other = np.array(dti.to_numpy()[0])
   60: 
   61:         dtarr = tm.box_expected(dti, box)
   62:         xbox = get_upcast_box(dtarr, other, True)
   63:         result = dtarr <= other
   64:         expected = np.array([True, False, False])
   65:         expected = tm.box_expected(expected, xbox)
   66:         tm.assert_equal(result, expected)
   67: 
   68:     @pytest.mark.parametrize(
   69:         "other",
   70:         [
   71:             "foo",
   72:             -1,
   73:             99,
   74:             4.0,
   75:             object(),
   76:             timedelta(days=2),
   77:             # GH#19800, GH#19301 datetime.date comparison raises to
   78:             #  match DatetimeIndex/Timestamp.  This also matches the behavior
   79:             #  of stdlib datetime.datetime
   80:             datetime(2001, 1, 1).date(),
   81:             # GH#19301 None and NaN are *not* cast to NaT for comparisons
   82:             None,
   83:             np.nan,
   84:         ],
   85:     )
   86:     def test_dt64arr_cmp_scalar_invalid(self, other, tz_naive_fixture, box_with_array):
   87:         # GH#22074, GH#15966
   88:         tz = tz_naive_fixture
   89: 
   90:         rng = date_range("1/1/2000", periods=10, tz=tz)
   91:         dtarr = tm.box_expected(rng, box_with_array)
   92:         assert_invalid_comparison(dtarr, other, box_with_array)
   93: 
   94:     @pytest.mark.parametrize(
   95:         "other",
   96:         [
   97:             # GH#4968 invalid date/int comparisons
   98:             list(range(10)),
   99:             np.arange(10),
  100:             np.arange(10).astype(np.float32),
  101:             np.arange(10).astype(object),
  102:             pd.timedelta_range("1ns", periods=10).array,
  103:             np.array(pd.timedelta_range("1ns", periods=10)),
  104:             list(pd.timedelta_range("1ns", periods=10)),
  105:             pd.timedelta_range("1 Day", periods=10).astype(object),
  106:             pd.period_range("1971-01-01", freq="D", periods=10).array,
  107:             pd.period_range("1971-01-01", freq="D", periods=10).astype(object),
  108:         ],
  109:     )
  110:     def test_dt64arr_cmp_arraylike_invalid(
  111:         self, other, tz_naive_fixture, box_with_array
  112:     ):
  113:         tz = tz_naive_fixture
  114: 
  115:         dta = date_range("1970-01-01", freq="ns", periods=10, tz=tz)._data
  116:         obj = tm.box_expected(dta, box_with_array)
  117:         assert_invalid_comparison(obj, other, box_with_array)
  118: 
  119:     def test_dt64arr_cmp_mixed_invalid(self, tz_naive_fixture):
  120:         tz = tz_naive_fixture
  121: 
  122:         dta = date_range("1970-01-01", freq="h", periods=5, tz=tz)._data
  123: 
  124:         other = np.array([0, 1, 2, dta[3], Timedelta(days=1)])
  125:         result = dta == other
  126:         expected = np.array([False, False, False, True, False])
  127:         tm.assert_numpy_array_equal(result, expected)
  128: 
  129:         result = dta != other
  130:         tm.assert_numpy_array_equal(result, ~expected)
  131: 
  132:         msg = "Invalid comparison between|Cannot compare type|not supported between"
  133:         with pytest.raises(TypeError, match=msg):
  134:             dta < other
  135:         with pytest.raises(TypeError, match=msg):
  136:             dta > other
  137:         with pytest.raises(TypeError, match=msg):
  138:             dta <= other
  139:         with pytest.raises(TypeError, match=msg):
  140:             dta >= other
  141: 
  142:     def test_dt64arr_nat_comparison(self, tz_naive_fixture, box_with_array):
  143:         # GH#22242, GH#22163 DataFrame considered NaT == ts incorrectly
  144:         tz = tz_naive_fixture
  145:         box = box_with_array
  146: 
  147:         ts = Timestamp("2021-01-01", tz=tz)
  148:         ser = Series([ts, NaT])
  149: 
  150:         obj = tm.box_expected(ser, box)
  151:         xbox = get_upcast_box(obj, ts, True)
  152: 
  153:         expected = Series([True, False], dtype=np.bool_)
  154:         expected = tm.box_expected(expected, xbox)
  155: 
  156:         result = obj == ts
  157:         tm.assert_equal(result, expected)
  158: 
  159: 
  160: class TestDatetime64SeriesComparison:
  161:     # TODO: moved from tests.series.test_operators; needs cleanup
  162: 
  163:     @pytest.mark.parametrize(
  164:         "pair",
  165:         [
  166:             (
  167:                 [Timestamp("2011-01-01"), NaT, Timestamp("2011-01-03")],
  168:                 [NaT, NaT, Timestamp("2011-01-03")],
  169:             ),
  170:             (
  171:                 [Timedelta("1 days"), NaT, Timedelta("3 days")],
  172:                 [NaT, NaT, Timedelta("3 days")],
  173:             ),
  174:             (
  175:                 [Period("2011-01", freq="M"), NaT, Period("2011-03", freq="M")],
  176:                 [NaT, NaT, Period("2011-03", freq="M")],
  177:             ),
  178:         ],
  179:     )
  180:     @pytest.mark.parametrize("reverse", [True, False])
  181:     @pytest.mark.parametrize("dtype", [None, object])
  182:     @pytest.mark.parametrize(
  183:         "op, expected",
  184:         [
  185:             (operator.eq, Series([False, False, True])),
  186:             (operator.ne, Series([True, True, False])),
  187:             (operator.lt, Series([False, False, False])),
  188:             (operator.gt, Series([False, False, False])),
  189:             (operator.ge, Series([False, False, True])),
  190:             (operator.le, Series([False, False, True])),
  191:         ],
  192:     )
  193:     def test_nat_comparisons(
  194:         self,
  195:         dtype,
  196:         index_or_series,
  197:         reverse,
  198:         pair,
  199:         op,
  200:         expected,
  201:     ):
  202:         box = index_or_series
  203:         lhs, rhs = pair
  204:         if reverse:
  205:             # add lhs / rhs switched data
  206:             lhs, rhs = rhs, lhs
  207: 
  208:         left = Series(lhs, dtype=dtype)
  209:         right = box(rhs, dtype=dtype)
  210: 
  211:         result = op(left, right)
  212: 
  213:         tm.assert_series_equal(result, expected)
  214: 
  215:     @pytest.mark.parametrize(
  216:         "data",
  217:         [
  218:             [Timestamp("2011-01-01"), NaT, Timestamp("2011-01-03")],
  219:             [Timedelta("1 days"), NaT, Timedelta("3 days")],
  220:             [Period("2011-01", freq="M"), NaT, Period("2011-03", freq="M")],
  221:         ],
  222:     )
  223:     @pytest.mark.parametrize("dtype", [None, object])
  224:     def test_nat_comparisons_scalar(self, dtype, data, box_with_array):
  225:         box = box_with_array
  226: 
  227:         left = Series(data, dtype=dtype)
  228:         left = tm.box_expected(left, box)
  229:         xbox = get_upcast_box(left, NaT, True)
  230: 
  231:         expected = [False, False, False]
  232:         expected = tm.box_expected(expected, xbox)
  233:         if box is pd.array and dtype is object:
  234:             expected = pd.array(expected, dtype="bool")
  235: 
  236:         tm.assert_equal(left == NaT, expected)
  237:         tm.assert_equal(NaT == left, expected)
  238: 
  239:         expected = [True, True, True]
  240:         expected = tm.box_expected(expected, xbox)
  241:         if box is pd.array and dtype is object:
  242:             expected = pd.array(expected, dtype="bool")
  243:         tm.assert_equal(left != NaT, expected)
  244:         tm.assert_equal(NaT != left, expected)
  245: 
  246:         expected = [False, False, False]
  247:         expected = tm.box_expected(expected, xbox)
  248:         if box is pd.array and dtype is object:
  249:             expected = pd.array(expected, dtype="bool")
  250:         tm.assert_equal(left < NaT, expected)
  251:         tm.assert_equal(NaT > left, expected)
  252:         tm.assert_equal(left <= NaT, expected)
  253:         tm.assert_equal(NaT >= left, expected)
  254: 
  255:         tm.assert_equal(left > NaT, expected)
  256:         tm.assert_equal(NaT < left, expected)
  257:         tm.assert_equal(left >= NaT, expected)
  258:         tm.assert_equal(NaT <= left, expected)
  259: 
  260:     @pytest.mark.parametrize("val", [datetime(2000, 1, 4), datetime(2000, 1, 5)])
  261:     def test_series_comparison_scalars(self, val):
  262:         series = Series(date_range("1/1/2000", periods=10))
  263: 
  264:         result = series > val
  265:         expected = Series([x > val for x in series])
  266:         tm.assert_series_equal(result, expected)
  267: 
  268:     @pytest.mark.parametrize(
  269:         "left,right", [("lt", "gt"), ("le", "ge"), ("eq", "eq"), ("ne", "ne")]
  270:     )
  271:     def test_timestamp_compare_series(self, left, right):
  272:         # see gh-4982
  273:         # Make sure we can compare Timestamps on the right AND left hand side.
  274:         ser = Series(date_range("20010101", periods=10), name="dates")
  275:         s_nat = ser.copy(deep=True)
  276: 
  277:         ser[0] = Timestamp("nat")
  278:         ser[3] = Timestamp("nat")
  279: 
  280:         left_f = getattr(operator, left)
  281:         right_f = getattr(operator, right)
  282: 
  283:         # No NaT
  284:         expected = left_f(ser, Timestamp("20010109"))
  285:         result = right_f(Timestamp("20010109"), ser)
  286:         tm.assert_series_equal(result, expected)
  287: 
  288:         # NaT
  289:         expected = left_f(ser, Timestamp("nat"))
  290:         result = right_f(Timestamp("nat"), ser)
  291:         tm.assert_series_equal(result, expected)
  292: 
  293:         # Compare to Timestamp with series containing NaT
  294:         expected = left_f(s_nat, Timestamp("20010109"))
  295:         result = right_f(Timestamp("20010109"), s_nat)
  296:         tm.assert_series_equal(result, expected)
  297: 
  298:         # Compare to NaT with series containing NaT
  299:         expected = left_f(s_nat, NaT)
  300:         result = right_f(NaT, s_nat)
  301:         tm.assert_series_equal(result, expected)
  302: 
  303:     def test_dt64arr_timestamp_equality(self, box_with_array):
  304:         # GH#11034
  305:         box = box_with_array
  306: 
  307:         ser = Series([Timestamp("2000-01-29 01:59:00"), Timestamp("2000-01-30"), NaT])
  308:         ser = tm.box_expected(ser, box)
  309:         xbox = get_upcast_box(ser, ser, True)
  310: 
  311:         result = ser != ser
  312:         expected = tm.box_expected([False, False, True], xbox)
  313:         tm.assert_equal(result, expected)
  314: 
  315:         if box is pd.DataFrame:
  316:             # alignment for frame vs series comparisons deprecated
  317:             #  in GH#46795 enforced 2.0
  318:             with pytest.raises(ValueError, match="not aligned"):
  319:                 ser != ser[0]
  320: 
  321:         else:
  322:             result = ser != ser[0]
  323:             expected = tm.box_expected([False, True, True], xbox)
  324:             tm.assert_equal(result, expected)
  325: 
  326:         if box is pd.DataFrame:
  327:             # alignment for frame vs series comparisons deprecated
  328:             #  in GH#46795 enforced 2.0
  329:             with pytest.raises(ValueError, match="not aligned"):
  330:                 ser != ser[2]
  331:         else:
  332:             result = ser != ser[2]
  333:             expected = tm.box_expected([True, True, True], xbox)
  334:             tm.assert_equal(result, expected)
  335: 
  336:         result = ser == ser
  337:         expected = tm.box_expected([True, True, False], xbox)
  338:         tm.assert_equal(result, expected)
  339: 
  340:         if box is pd.DataFrame:
  341:             # alignment for frame vs series comparisons deprecated
  342:             #  in GH#46795 enforced 2.0
  343:             with pytest.raises(ValueError, match="not aligned"):
  344:                 ser == ser[0]
  345:         else:
  346:             result = ser == ser[0]
  347:             expected = tm.box_expected([True, False, False], xbox)
  348:             tm.assert_equal(result, expected)
  349: 
  350:         if box is pd.DataFrame:
  351:             # alignment for frame vs series comparisons deprecated
  352:             #  in GH#46795 enforced 2.0
  353:             with pytest.raises(ValueError, match="not aligned"):
  354:                 ser == ser[2]
  355:         else:
  356:             result = ser == ser[2]
  357:             expected = tm.box_expected([False, False, False], xbox)
  358:             tm.assert_equal(result, expected)
  359: 
  360:     @pytest.mark.parametrize(
  361:         "datetimelike",
  362:         [
  363:             Timestamp("20130101"),
  364:             datetime(2013, 1, 1),
  365:             np.datetime64("2013-01-01T00:00", "ns"),
  366:         ],
  367:     )
  368:     @pytest.mark.parametrize(
  369:         "op,expected",
  370:         [
  371:             (operator.lt, [True, False, False, False]),
  372:             (operator.le, [True, True, False, False]),
  373:             (operator.eq, [False, True, False, False]),
  374:             (operator.gt, [False, False, False, True]),
  375:         ],
  376:     )
  377:     def test_dt64_compare_datetime_scalar(self, datetimelike, op, expected):
  378:         # GH#17965, test for ability to compare datetime64[ns] columns
  379:         #  to datetimelike
  380:         ser = Series(
  381:             [
  382:                 Timestamp("20120101"),
  383:                 Timestamp("20130101"),
  384:                 np.nan,
  385:                 Timestamp("20130103"),
  386:             ],
  387:             name="A",
  388:         )
  389:         result = op(ser, datetimelike)
  390:         expected = Series(expected, name="A")
  391:         tm.assert_series_equal(result, expected)
  392: 
  393: 
  394: class TestDatetimeIndexComparisons:
  395:     # TODO: moved from tests.indexes.test_base; parametrize and de-duplicate
  396:     def test_comparators(self, comparison_op):
  397:         index = date_range("2020-01-01", periods=10)
  398:         element = index[len(index) // 2]
  399:         element = Timestamp(element).to_datetime64()
  400: 
  401:         arr = np.array(index)
  402:         arr_result = comparison_op(arr, element)
  403:         index_result = comparison_op(index, element)
  404: 
  405:         assert isinstance(index_result, np.ndarray)
  406:         tm.assert_numpy_array_equal(arr_result, index_result)
  407: 
  408:     @pytest.mark.parametrize(
  409:         "other",
  410:         [datetime(2016, 1, 1), Timestamp("2016-01-01"), np.datetime64("2016-01-01")],
  411:     )
  412:     def test_dti_cmp_datetimelike(self, other, tz_naive_fixture):
  413:         tz = tz_naive_fixture
  414:         dti = date_range("2016-01-01", periods=2, tz=tz)
  415:         if tz is not None:
  416:             if isinstance(other, np.datetime64):
  417:                 pytest.skip(f"{type(other).__name__} is not tz aware")
  418:             other = localize_pydatetime(other, dti.tzinfo)
  419: 
  420:         result = dti == other
  421:         expected = np.array([True, False])
  422:         tm.assert_numpy_array_equal(result, expected)
  423: 
  424:         result = dti > other
  425:         expected = np.array([False, True])
  426:         tm.assert_numpy_array_equal(result, expected)
  427: 
  428:         result = dti >= other
  429:         expected = np.array([True, True])
  430:         tm.assert_numpy_array_equal(result, expected)
  431: 
  432:         result = dti < other
  433:         expected = np.array([False, False])
  434:         tm.assert_numpy_array_equal(result, expected)
  435: 
  436:         result = dti <= other
  437:         expected = np.array([True, False])
  438:         tm.assert_numpy_array_equal(result, expected)
  439: 
  440:     @pytest.mark.parametrize("dtype", [None, object])
  441:     def test_dti_cmp_nat(self, dtype, box_with_array):
  442:         left = DatetimeIndex([Timestamp("2011-01-01"), NaT, Timestamp("2011-01-03")])
  443:         right = DatetimeIndex([NaT, NaT, Timestamp("2011-01-03")])
  444: 
  445:         left = tm.box_expected(left, box_with_array)
  446:         right = tm.box_expected(right, box_with_array)
  447:         xbox = get_upcast_box(left, right, True)
  448: 
  449:         lhs, rhs = left, right
  450:         if dtype is object:
  451:             lhs, rhs = left.astype(object), right.astype(object)
  452: 
  453:         result = rhs == lhs
  454:         expected = np.array([False, False, True])
  455:         expected = tm.box_expected(expected, xbox)
  456:         tm.assert_equal(result, expected)
  457: 
  458:         result = lhs != rhs
  459:         expected = np.array([True, True, False])
  460:         expected = tm.box_expected(expected, xbox)
  461:         tm.assert_equal(result, expected)
  462: 
  463:         expected = np.array([False, False, False])
  464:         expected = tm.box_expected(expected, xbox)
  465:         tm.assert_equal(lhs == NaT, expected)
  466:         tm.assert_equal(NaT == rhs, expected)
  467: 
  468:         expected = np.array([True, True, True])
  469:         expected = tm.box_expected(expected, xbox)
  470:         tm.assert_equal(lhs != NaT, expected)
  471:         tm.assert_equal(NaT != lhs, expected)
  472: 
  473:         expected = np.array([False, False, False])
  474:         expected = tm.box_expected(expected, xbox)
  475:         tm.assert_equal(lhs < NaT, expected)
  476:         tm.assert_equal(NaT > lhs, expected)
  477: 
  478:     def test_dti_cmp_nat_behaves_like_float_cmp_nan(self):
  479:         fidx1 = pd.Index([1.0, np.nan, 3.0, np.nan, 5.0, 7.0])
  480:         fidx2 = pd.Index([2.0, 3.0, np.nan, np.nan, 6.0, 7.0])
  481: 
  482:         didx1 = DatetimeIndex(
  483:             ["2014-01-01", NaT, "2014-03-01", NaT, "2014-05-01", "2014-07-01"]
  484:         )
  485:         didx2 = DatetimeIndex(
  486:             ["2014-02-01", "2014-03-01", NaT, NaT, "2014-06-01", "2014-07-01"]
  487:         )
  488:         darr = np.array(
  489:             [
  490:                 np.datetime64("2014-02-01 00:00"),
  491:                 np.datetime64("2014-03-01 00:00"),
  492:                 np.datetime64("nat"),
  493:                 np.datetime64("nat"),
  494:                 np.datetime64("2014-06-01 00:00"),
  495:                 np.datetime64("2014-07-01 00:00"),
  496:             ]
  497:         )
  498: 
  499:         cases = [(fidx1, fidx2), (didx1, didx2), (didx1, darr)]
  500: 
  501:         # Check pd.NaT is handles as the same as np.nan
  502:         with tm.assert_produces_warning(None):
  503:             for idx1, idx2 in cases:
  504:                 result = idx1 < idx2
  505:                 expected = np.array([True, False, False, False, True, False])
  506:                 tm.assert_numpy_array_equal(result, expected)
  507: 
  508:                 result = idx2 > idx1
  509:                 expected = np.array([True, False, False, False, True, False])
  510:                 tm.assert_numpy_array_equal(result, expected)
  511: 
  512:                 result = idx1 <= idx2
  513:                 expected = np.array([True, False, False, False, True, True])
  514:                 tm.assert_numpy_array_equal(result, expected)
  515: 
  516:                 result = idx2 >= idx1
  517:                 expected = np.array([True, False, False, False, True, True])
  518:                 tm.assert_numpy_array_equal(result, expected)
  519: 
  520:                 result = idx1 == idx2
  521:                 expected = np.array([False, False, False, False, False, True])
  522:                 tm.assert_numpy_array_equal(result, expected)
  523: 
  524:                 result = idx1 != idx2
  525:                 expected = np.array([True, True, True, True, True, False])
  526:                 tm.assert_numpy_array_equal(result, expected)
  527: 
  528:         with tm.assert_produces_warning(None):
  529:             for idx1, val in [(fidx1, np.nan), (didx1, NaT)]:
  530:                 result = idx1 < val
  531:                 expected = np.array([False, False, False, False, False, False])
  532:                 tm.assert_numpy_array_equal(result, expected)
  533:                 result = idx1 > val
  534:                 tm.assert_numpy_array_equal(result, expected)
  535: 
  536:                 result = idx1 <= val
  537:                 tm.assert_numpy_array_equal(result, expected)
  538:                 result = idx1 >= val
  539:                 tm.assert_numpy_array_equal(result, expected)
  540: 
  541:                 result = idx1 == val
  542:                 tm.assert_numpy_array_equal(result, expected)
  543: 
  544:                 result = idx1 != val
  545:                 expected = np.array([True, True, True, True, True, True])
  546:                 tm.assert_numpy_array_equal(result, expected)
  547: 
  548:         # Check pd.NaT is handles as the same as np.nan
  549:         with tm.assert_produces_warning(None):
  550:             for idx1, val in [(fidx1, 3), (didx1, datetime(2014, 3, 1))]:
  551:                 result = idx1 < val
  552:                 expected = np.array([True, False, False, False, False, False])
  553:                 tm.assert_numpy_array_equal(result, expected)
  554:                 result = idx1 > val
  555:                 expected = np.array([False, False, False, False, True, True])
  556:                 tm.assert_numpy_array_equal(result, expected)
  557: 
  558:                 result = idx1 <= val
  559:                 expected = np.array([True, False, True, False, False, False])
  560:                 tm.assert_numpy_array_equal(result, expected)
  561:                 result = idx1 >= val
  562:                 expected = np.array([False, False, True, False, True, True])
  563:                 tm.assert_numpy_array_equal(result, expected)
  564: 
  565:                 result = idx1 == val
  566:                 expected = np.array([False, False, True, False, False, False])
  567:                 tm.assert_numpy_array_equal(result, expected)
  568: 
  569:                 result = idx1 != val
  570:                 expected = np.array([True, True, False, True, True, True])
  571:                 tm.assert_numpy_array_equal(result, expected)
  572: 
  573:     def test_comparison_tzawareness_compat(self, comparison_op, box_with_array):
  574:         # GH#18162
  575:         op = comparison_op
  576:         box = box_with_array
  577: 
  578:         dr = date_range("2016-01-01", periods=6)
  579:         dz = dr.tz_localize("US/Pacific")
  580: 
  581:         dr = tm.box_expected(dr, box)
  582:         dz = tm.box_expected(dz, box)
  583: 
  584:         if box is pd.DataFrame:
  585:             tolist = lambda x: x.astype(object).values.tolist()[0]
  586:         else:
  587:             tolist = list
  588: 
  589:         if op not in [operator.eq, operator.ne]:
  590:             msg = (
  591:                 r"Invalid comparison between dtype=datetime64\[ns.*\] "
  592:                 "and (Timestamp|DatetimeArray|list|ndarray)"
  593:             )
  594:             with pytest.raises(TypeError, match=msg):
  595:                 op(dr, dz)
  596: 
  597:             with pytest.raises(TypeError, match=msg):
  598:                 op(dr, tolist(dz))
  599:             with pytest.raises(TypeError, match=msg):
  600:                 op(dr, np.array(tolist(dz), dtype=object))
  601:             with pytest.raises(TypeError, match=msg):
  602:                 op(dz, dr)
  603: 
  604:             with pytest.raises(TypeError, match=msg):
  605:                 op(dz, tolist(dr))
  606:             with pytest.raises(TypeError, match=msg):
  607:                 op(dz, np.array(tolist(dr), dtype=object))
  608: 
  609:         # The aware==aware and naive==naive comparisons should *not* raise
  610:         assert np.all(dr == dr)
  611:         assert np.all(dr == tolist(dr))
  612:         assert np.all(tolist(dr) == dr)
  613:         assert np.all(np.array(tolist(dr), dtype=object) == dr)
  614:         assert np.all(dr == np.array(tolist(dr), dtype=object))
  615: 
  616:         assert np.all(dz == dz)
  617:         assert np.all(dz == tolist(dz))
  618:         assert np.all(tolist(dz) == dz)
  619:         assert np.all(np.array(tolist(dz), dtype=object) == dz)
  620:         assert np.all(dz == np.array(tolist(dz), dtype=object))
  621: 
  622:     def test_comparison_tzawareness_compat_scalars(self, comparison_op, box_with_array):
  623:         # GH#18162
  624:         op = comparison_op
  625: 
  626:         dr = date_range("2016-01-01", periods=6)
  627:         dz = dr.tz_localize("US/Pacific")
  628: 
  629:         dr = tm.box_expected(dr, box_with_array)
  630:         dz = tm.box_expected(dz, box_with_array)
  631: 
  632:         # Check comparisons against scalar Timestamps
  633:         ts = Timestamp("2000-03-14 01:59")
  634:         ts_tz = Timestamp("2000-03-14 01:59", tz="Europe/Amsterdam")
  635: 
  636:         assert np.all(dr > ts)
  637:         msg = r"Invalid comparison between dtype=datetime64\[ns.*\] and Timestamp"
  638:         if op not in [operator.eq, operator.ne]:
  639:             with pytest.raises(TypeError, match=msg):
  640:                 op(dr, ts_tz)
  641: 
  642:         assert np.all(dz > ts_tz)
  643:         if op not in [operator.eq, operator.ne]:
  644:             with pytest.raises(TypeError, match=msg):
  645:                 op(dz, ts)
  646: 
  647:         if op not in [operator.eq, operator.ne]:
  648:             # GH#12601: Check comparison against Timestamps and DatetimeIndex
  649:             with pytest.raises(TypeError, match=msg):
  650:                 op(ts, dz)
  651: 
  652:     @pytest.mark.parametrize(
  653:         "other",
  654:         [datetime(2016, 1, 1), Timestamp("2016-01-01"), np.datetime64("2016-01-01")],
  655:     )
  656:     # Bug in NumPy? https://github.com/numpy/numpy/issues/13841
  657:     # Raising in __eq__ will fallback to NumPy, which warns, fails,
  658:     # then re-raises the original exception. So we just need to ignore.
  659:     @pytest.mark.filterwarnings("ignore:elementwise comp:DeprecationWarning")
  660:     def test_scalar_comparison_tzawareness(
  661:         self, comparison_op, other, tz_aware_fixture, box_with_array
  662:     ):
  663:         op = comparison_op
  664:         tz = tz_aware_fixture
  665:         dti = date_range("2016-01-01", periods=2, tz=tz)
  666: 
  667:         dtarr = tm.box_expected(dti, box_with_array)
  668:         xbox = get_upcast_box(dtarr, other, True)
  669:         if op in [operator.eq, operator.ne]:
  670:             exbool = op is operator.ne
  671:             expected = np.array([exbool, exbool], dtype=bool)
  672:             expected = tm.box_expected(expected, xbox)
  673: 
  674:             result = op(dtarr, other)
  675:             tm.assert_equal(result, expected)
  676: 
  677:             result = op(other, dtarr)
  678:             tm.assert_equal(result, expected)
  679:         else:
  680:             msg = (
  681:                 r"Invalid comparison between dtype=datetime64\[ns, .*\] "
  682:                 f"and {type(other).__name__}"
  683:             )
  684:             with pytest.raises(TypeError, match=msg):
  685:                 op(dtarr, other)
  686:             with pytest.raises(TypeError, match=msg):
  687:                 op(other, dtarr)
  688: 
  689:     def test_nat_comparison_tzawareness(self, comparison_op):
  690:         # GH#19276
  691:         # tzaware DatetimeIndex should not raise when compared to NaT
  692:         op = comparison_op
  693: 
  694:         dti = DatetimeIndex(
  695:             ["2014-01-01", NaT, "2014-03-01", NaT, "2014-05-01", "2014-07-01"]
  696:         )
  697:         expected = np.array([op == operator.ne] * len(dti))
  698:         result = op(dti, NaT)
  699:         tm.assert_numpy_array_equal(result, expected)
  700: 
  701:         result = op(dti.tz_localize("US/Pacific"), NaT)
  702:         tm.assert_numpy_array_equal(result, expected)
  703: 
  704:     def test_dti_cmp_str(self, tz_naive_fixture):
  705:         # GH#22074
  706:         # regardless of tz, we expect these comparisons are valid
  707:         tz = tz_naive_fixture
  708:         rng = date_range("1/1/2000", periods=10, tz=tz)
  709:         other = "1/1/2000"
  710: 
  711:         result = rng == other
  712:         expected = np.array([True] + [False] * 9)
  713:         tm.assert_numpy_array_equal(result, expected)
  714: 
  715:         result = rng != other
  716:         expected = np.array([False] + [True] * 9)
  717:         tm.assert_numpy_array_equal(result, expected)
  718: 
  719:         result = rng < other
  720:         expected = np.array([False] * 10)
  721:         tm.assert_numpy_array_equal(result, expected)
  722: 
  723:         result = rng <= other
  724:         expected = np.array([True] + [False] * 9)
  725:         tm.assert_numpy_array_equal(result, expected)
  726: 
  727:         result = rng > other
  728:         expected = np.array([False] + [True] * 9)
  729:         tm.assert_numpy_array_equal(result, expected)
  730: 
  731:         result = rng >= other
  732:         expected = np.array([True] * 10)
  733:         tm.assert_numpy_array_equal(result, expected)
  734: 
  735:     def test_dti_cmp_list(self):
  736:         rng = date_range("1/1/2000", periods=10)
  737: 
  738:         result = rng == list(rng)
  739:         expected = rng == rng
  740:         tm.assert_numpy_array_equal(result, expected)
  741: 
  742:     @pytest.mark.parametrize(
  743:         "other",
  744:         [
  745:             pd.timedelta_range("1D", periods=10),
  746:             pd.timedelta_range("1D", periods=10).to_series(),
  747:             pd.timedelta_range("1D", periods=10).asi8.view("m8[ns]"),
  748:         ],
  749:         ids=lambda x: type(x).__name__,
  750:     )
  751:     def test_dti_cmp_tdi_tzawareness(self, other):
  752:         # GH#22074
  753:         # reversion test that we _don't_ call _assert_tzawareness_compat
  754:         # when comparing against TimedeltaIndex
  755:         dti = date_range("2000-01-01", periods=10, tz="Asia/Tokyo")
  756: 
  757:         result = dti == other
  758:         expected = np.array([False] * 10)
  759:         tm.assert_numpy_array_equal(result, expected)
  760: 
  761:         result = dti != other
  762:         expected = np.array([True] * 10)
  763:         tm.assert_numpy_array_equal(result, expected)
  764:         msg = "Invalid comparison between"
  765:         with pytest.raises(TypeError, match=msg):
  766:             dti < other
  767:         with pytest.raises(TypeError, match=msg):
  768:             dti <= other
  769:         with pytest.raises(TypeError, match=msg):
  770:             dti > other
  771:         with pytest.raises(TypeError, match=msg):
  772:             dti >= other
  773: 
  774:     def test_dti_cmp_object_dtype(self):
  775:         # GH#22074
  776:         dti = date_range("2000-01-01", periods=10, tz="Asia/Tokyo")
  777: 
  778:         other = dti.astype("O")
  779: 
  780:         result = dti == other
  781:         expected = np.array([True] * 10)
  782:         tm.assert_numpy_array_equal(result, expected)
  783: 
  784:         other = dti.tz_localize(None)
  785:         result = dti != other
  786:         tm.assert_numpy_array_equal(result, expected)
  787: 
  788:         other = np.array(list(dti[:5]) + [Timedelta(days=1)] * 5)
  789:         result = dti == other
  790:         expected = np.array([True] * 5 + [False] * 5)
  791:         tm.assert_numpy_array_equal(result, expected)
  792:         msg = ">=' not supported between instances of 'Timestamp' and 'Timedelta'"
  793:         with pytest.raises(TypeError, match=msg):
  794:             dti >= other
  795: 
  796: 
  797: # ------------------------------------------------------------------
  798: # Arithmetic
  799: 
  800: 
  801: class TestDatetime64Arithmetic:
  802:     # This class is intended for "finished" tests that are fully parametrized
  803:     #  over DataFrame/Series/Index/DatetimeArray
  804: 
  805:     # -------------------------------------------------------------
  806:     # Addition/Subtraction of timedelta-like
  807: 
  808:     @pytest.mark.arm_slow
  809:     def test_dt64arr_add_timedeltalike_scalar(
  810:         self, tz_naive_fixture, two_hours, box_with_array
  811:     ):
  812:         # GH#22005, GH#22163 check DataFrame doesn't raise TypeError
  813:         tz = tz_naive_fixture
  814: 
  815:         rng = date_range("2000-01-01", "2000-02-01", tz=tz)
  816:         expected = date_range("2000-01-01 02:00", "2000-02-01 02:00", tz=tz)
  817: 
  818:         rng = tm.box_expected(rng, box_with_array)
  819:         expected = tm.box_expected(expected, box_with_array)
  820: 
  821:         result = rng + two_hours
  822:         tm.assert_equal(result, expected)
  823: 
  824:         result = two_hours + rng
  825:         tm.assert_equal(result, expected)
  826: 
  827:         rng += two_hours
  828:         tm.assert_equal(rng, expected)
  829: 
  830:     def test_dt64arr_sub_timedeltalike_scalar(
  831:         self, tz_naive_fixture, two_hours, box_with_array
  832:     ):
  833:         tz = tz_naive_fixture
  834: 
  835:         rng = date_range("2000-01-01", "2000-02-01", tz=tz)
  836:         expected = date_range("1999-12-31 22:00", "2000-01-31 22:00", tz=tz)
  837: 
  838:         rng = tm.box_expected(rng, box_with_array)
  839:         expected = tm.box_expected(expected, box_with_array)
  840: 
  841:         result = rng - two_hours
  842:         tm.assert_equal(result, expected)
  843: 
  844:         rng -= two_hours
  845:         tm.assert_equal(rng, expected)
  846: 
  847:     def test_dt64_array_sub_dt_with_different_timezone(self, box_with_array):
  848:         t1 = date_range("20130101", periods=3).tz_localize("US/Eastern")
  849:         t1 = tm.box_expected(t1, box_with_array)
  850:         t2 = Timestamp("20130101").tz_localize("CET")
  851:         tnaive = Timestamp(20130101)
  852: 
  853:         result = t1 - t2
  854:         expected = TimedeltaIndex(
  855:             ["0 days 06:00:00", "1 days 06:00:00", "2 days 06:00:00"]
  856:         )
  857:         expected = tm.box_expected(expected, box_with_array)
  858:         tm.assert_equal(result, expected)
  859: 
  860:         result = t2 - t1
  861:         expected = TimedeltaIndex(
  862:             ["-1 days +18:00:00", "-2 days +18:00:00", "-3 days +18:00:00"]
  863:         )
  864:         expected = tm.box_expected(expected, box_with_array)
  865:         tm.assert_equal(result, expected)
  866: 
  867:         msg = "Cannot subtract tz-naive and tz-aware datetime-like objects"
  868:         with pytest.raises(TypeError, match=msg):
  869:             t1 - tnaive
  870: 
  871:         with pytest.raises(TypeError, match=msg):
  872:             tnaive - t1
  873: 
  874:     def test_dt64_array_sub_dt64_array_with_different_timezone(self, box_with_array):
  875:         t1 = date_range("20130101", periods=3).tz_localize("US/Eastern")
  876:         t1 = tm.box_expected(t1, box_with_array)
  877:         t2 = date_range("20130101", periods=3).tz_localize("CET")
  878:         t2 = tm.box_expected(t2, box_with_array)
  879:         tnaive = date_range("20130101", periods=3)
  880: 
  881:         result = t1 - t2
  882:         expected = TimedeltaIndex(
  883:             ["0 days 06:00:00", "0 days 06:00:00", "0 days 06:00:00"]
  884:         )
  885:         expected = tm.box_expected(expected, box_with_array)
  886:         tm.assert_equal(result, expected)
  887: 
  888:         result = t2 - t1
  889:         expected = TimedeltaIndex(
  890:             ["-1 days +18:00:00", "-1 days +18:00:00", "-1 days +18:00:00"]
  891:         )
  892:         expected = tm.box_expected(expected, box_with_array)
  893:         tm.assert_equal(result, expected)
  894: 
  895:         msg = "Cannot subtract tz-naive and tz-aware datetime-like objects"
  896:         with pytest.raises(TypeError, match=msg):
  897:             t1 - tnaive
  898: 
  899:         with pytest.raises(TypeError, match=msg):
  900:             tnaive - t1
  901: 
  902:     def test_dt64arr_add_sub_td64_nat(self, box_with_array, tz_naive_fixture):
  903:         # GH#23320 special handling for timedelta64("NaT")
  904:         tz = tz_naive_fixture
  905: 
  906:         dti = date_range("1994-04-01", periods=9, tz=tz, freq="QS")
  907:         other = np.timedelta64("NaT")
  908:         expected = DatetimeIndex(["NaT"] * 9, tz=tz).as_unit("ns")
  909: 
  910:         obj = tm.box_expected(dti, box_with_array)
  911:         expected = tm.box_expected(expected, box_with_array)
  912: 
  913:         result = obj + other
  914:         tm.assert_equal(result, expected)
  915:         result = other + obj
  916:         tm.assert_equal(result, expected)
  917:         result = obj - other
  918:         tm.assert_equal(result, expected)
  919:         msg = "cannot subtract"
  920:         with pytest.raises(TypeError, match=msg):
  921:             other - obj
  922: 
  923:     def test_dt64arr_add_sub_td64ndarray(self, tz_naive_fixture, box_with_array):
  924:         tz = tz_naive_fixture
  925:         dti = date_range("2016-01-01", periods=3, tz=tz)
  926:         tdi = TimedeltaIndex(["-1 Day", "-1 Day", "-1 Day"])
  927:         tdarr = tdi.values
  928: 
  929:         expected = date_range("2015-12-31", "2016-01-02", periods=3, tz=tz)
  930: 
  931:         dtarr = tm.box_expected(dti, box_with_array)
  932:         expected = tm.box_expected(expected, box_with_array)
  933: 
  934:         result = dtarr + tdarr
  935:         tm.assert_equal(result, expected)
  936:         result = tdarr + dtarr
  937:         tm.assert_equal(result, expected)
  938: 
  939:         expected = date_range("2016-01-02", "2016-01-04", periods=3, tz=tz)
  940:         expected = tm.box_expected(expected, box_with_array)
  941: 
  942:         result = dtarr - tdarr
  943:         tm.assert_equal(result, expected)
  944:         msg = "cannot subtract|(bad|unsupported) operand type for unary"
  945:         with pytest.raises(TypeError, match=msg):
  946:             tdarr - dtarr
  947: 
  948:     # -----------------------------------------------------------------
  949:     # Subtraction of datetime-like scalars
  950: 
  951:     @pytest.mark.parametrize(
  952:         "ts",
  953:         [
  954:             Timestamp("2013-01-01"),
  955:             Timestamp("2013-01-01").to_pydatetime(),
  956:             Timestamp("2013-01-01").to_datetime64(),
  957:             # GH#7996, GH#22163 ensure non-nano datetime64 is converted to nano
  958:             #  for DataFrame operation
  959:             np.datetime64("2013-01-01", "D"),
  960:         ],
  961:     )
  962:     def test_dt64arr_sub_dtscalar(self, box_with_array, ts):
  963:         # GH#8554, GH#22163 DataFrame op should _not_ return dt64 dtype
  964:         idx = date_range("2013-01-01", periods=3)._with_freq(None)
  965:         idx = tm.box_expected(idx, box_with_array)
  966: 
  967:         expected = TimedeltaIndex(["0 Days", "1 Day", "2 Days"])
  968:         expected = tm.box_expected(expected, box_with_array)
  969: 
  970:         result = idx - ts
  971:         tm.assert_equal(result, expected)
  972: 
  973:         result = ts - idx
  974:         tm.assert_equal(result, -expected)
  975:         tm.assert_equal(result, -expected)
  976: 
  977:     def test_dt64arr_sub_timestamp_tzaware(self, box_with_array):
  978:         ser = date_range("2014-03-17", periods=2, freq="D", tz="US/Eastern")
  979:         ser = ser._with_freq(None)
  980:         ts = ser[0]
  981: 
  982:         ser = tm.box_expected(ser, box_with_array)
  983: 
  984:         delta_series = Series([np.timedelta64(0, "D"), np.timedelta64(1, "D")])
  985:         expected = tm.box_expected(delta_series, box_with_array)
  986: 
  987:         tm.assert_equal(ser - ts, expected)
  988:         tm.assert_equal(ts - ser, -expected)
  989: 
  990:     def test_dt64arr_sub_NaT(self, box_with_array, unit):
  991:         # GH#18808
  992:         dti = DatetimeIndex([NaT, Timestamp("19900315")]).as_unit(unit)
  993:         ser = tm.box_expected(dti, box_with_array)
  994: 
  995:         result = ser - NaT
  996:         expected = Series([NaT, NaT], dtype=f"timedelta64[{unit}]")
  997:         expected = tm.box_expected(expected, box_with_array)
  998:         tm.assert_equal(result, expected)
  999: 
 1000:         dti_tz = dti.tz_localize("Asia/Tokyo")
 1001:         ser_tz = tm.box_expected(dti_tz, box_with_array)
 1002: 
 1003:         result = ser_tz - NaT
 1004:         expected = Series([NaT, NaT], dtype=f"timedelta64[{unit}]")
 1005:         expected = tm.box_expected(expected, box_with_array)
 1006:         tm.assert_equal(result, expected)
 1007: 
 1008:     # -------------------------------------------------------------
 1009:     # Subtraction of datetime-like array-like
 1010: 
 1011:     def test_dt64arr_sub_dt64object_array(self, box_with_array, tz_naive_fixture):
 1012:         dti = date_range("2016-01-01", periods=3, tz=tz_naive_fixture)
 1013:         expected = dti - dti
 1014: 
 1015:         obj = tm.box_expected(dti, box_with_array)
 1016:         expected = tm.box_expected(expected, box_with_array).astype(object)
 1017: 
 1018:         with tm.assert_produces_warning(PerformanceWarning):
 1019:             result = obj - obj.astype(object)
 1020:         tm.assert_equal(result, expected)
 1021: 
 1022:     def test_dt64arr_naive_sub_dt64ndarray(self, box_with_array):
 1023:         dti = date_range("2016-01-01", periods=3, tz=None)
 1024:         dt64vals = dti.values
 1025: 
 1026:         dtarr = tm.box_expected(dti, box_with_array)
 1027: 
 1028:         expected = dtarr - dtarr
 1029:         result = dtarr - dt64vals
 1030:         tm.assert_equal(result, expected)
 1031:         result = dt64vals - dtarr
 1032:         tm.assert_equal(result, expected)
 1033: 
 1034:     def test_dt64arr_aware_sub_dt64ndarray_raises(
 1035:         self, tz_aware_fixture, box_with_array
 1036:     ):
 1037:         tz = tz_aware_fixture
 1038:         dti = date_range("2016-01-01", periods=3, tz=tz)
 1039:         dt64vals = dti.values
 1040: 
 1041:         dtarr = tm.box_expected(dti, box_with_array)
 1042:         msg = "Cannot subtract tz-naive and tz-aware datetime"
 1043:         with pytest.raises(TypeError, match=msg):
 1044:             dtarr - dt64vals
 1045:         with pytest.raises(TypeError, match=msg):
 1046:             dt64vals - dtarr
 1047: 
 1048:     # -------------------------------------------------------------
 1049:     # Addition of datetime-like others (invalid)
 1050: 
 1051:     def test_dt64arr_add_dtlike_raises(self, tz_naive_fixture, box_with_array):
 1052:         # GH#22163 ensure DataFrame doesn't cast Timestamp to i8
 1053:         # GH#9631
 1054:         tz = tz_naive_fixture
 1055: 
 1056:         dti = date_range("2016-01-01", periods=3, tz=tz)
 1057:         if tz is None:
 1058:             dti2 = dti.tz_localize("US/Eastern")
 1059:         else:
 1060:             dti2 = dti.tz_localize(None)
 1061:         dtarr = tm.box_expected(dti, box_with_array)
 1062: 
 1063:         assert_cannot_add(dtarr, dti.values)
 1064:         assert_cannot_add(dtarr, dti)
 1065:         assert_cannot_add(dtarr, dtarr)
 1066:         assert_cannot_add(dtarr, dti[0])
 1067:         assert_cannot_add(dtarr, dti[0].to_pydatetime())
 1068:         assert_cannot_add(dtarr, dti[0].to_datetime64())
 1069:         assert_cannot_add(dtarr, dti2[0])
 1070:         assert_cannot_add(dtarr, dti2[0].to_pydatetime())
 1071:         assert_cannot_add(dtarr, np.datetime64("2011-01-01", "D"))
 1072: 
 1073:     # -------------------------------------------------------------
 1074:     # Other Invalid Addition/Subtraction
 1075: 
 1076:     # Note: freq here includes both Tick and non-Tick offsets; this is
 1077:     #  relevant because historically integer-addition was allowed if we had
 1078:     #  a freq.
 1079:     @pytest.mark.parametrize("freq", ["h", "D", "W", "2ME", "MS", "QE", "B", None])
 1080:     @pytest.mark.parametrize("dtype", [None, "uint8"])
 1081:     def test_dt64arr_addsub_intlike(
 1082:         self, request, dtype, index_or_series_or_array, freq, tz_naive_fixture
 1083:     ):
 1084:         # GH#19959, GH#19123, GH#19012
 1085:         # GH#55860 use index_or_series_or_array instead of box_with_array
 1086:         #  bc DataFrame alignment makes it inapplicable
 1087:         tz = tz_naive_fixture
 1088: 
 1089:         if freq is None:
 1090:             dti = DatetimeIndex(["NaT", "2017-04-05 06:07:08"], tz=tz)
 1091:         else:
 1092:             dti = date_range("2016-01-01", periods=2, freq=freq, tz=tz)
 1093: 
 1094:         obj = index_or_series_or_array(dti)
 1095:         other = np.array([4, -1])
 1096:         if dtype is not None:
 1097:             other = other.astype(dtype)
 1098: 
 1099:         msg = "|".join(
 1100:             [
 1101:                 "Addition/subtraction of integers",
 1102:                 "cannot subtract DatetimeArray from",
 1103:                 # IntegerArray
 1104:                 "can only perform ops with numeric values",
 1105:                 "unsupported operand type.*Categorical",
 1106:                 r"unsupported operand type\(s\) for -: 'int' and 'Timestamp'",
 1107:             ]
 1108:         )
 1109:         assert_invalid_addsub_type(obj, 1, msg)
 1110:         assert_invalid_addsub_type(obj, np.int64(2), msg)
 1111:         assert_invalid_addsub_type(obj, np.array(3, dtype=np.int64), msg)
 1112:         assert_invalid_addsub_type(obj, other, msg)
 1113:         assert_invalid_addsub_type(obj, np.array(other), msg)
 1114:         assert_invalid_addsub_type(obj, pd.array(other), msg)
 1115:         assert_invalid_addsub_type(obj, pd.Categorical(other), msg)
 1116:         assert_invalid_addsub_type(obj, pd.Index(other), msg)
 1117:         assert_invalid_addsub_type(obj, Series(other), msg)
 1118: 
 1119:     @pytest.mark.parametrize(
 1120:         "other",
 1121:         [
 1122:             3.14,
 1123:             np.array([2.0, 3.0]),
 1124:             # GH#13078 datetime +/- Period is invalid
 1125:             Period("2011-01-01", freq="D"),
 1126:             # https://github.com/pandas-dev/pandas/issues/10329
 1127:             time(1, 2, 3),
 1128:         ],
 1129:     )
 1130:     @pytest.mark.parametrize("dti_freq", [None, "D"])
 1131:     def test_dt64arr_add_sub_invalid(self, dti_freq, other, box_with_array):
 1132:         dti = DatetimeIndex(["2011-01-01", "2011-01-02"], freq=dti_freq)
 1133:         dtarr = tm.box_expected(dti, box_with_array)
 1134:         msg = "|".join(
 1135:             [
 1136:                 "unsupported operand type",
 1137:                 "cannot (add|subtract)",
 1138:                 "cannot use operands with types",
 1139:                 "ufunc '?(add|subtract)'? cannot use operands with types",
 1140:                 "Concatenation operation is not implemented for NumPy arrays",
 1141:             ]
 1142:         )
 1143:         assert_invalid_addsub_type(dtarr, other, msg)
 1144: 
 1145:     @pytest.mark.parametrize("pi_freq", ["D", "W", "Q", "h"])
 1146:     @pytest.mark.parametrize("dti_freq", [None, "D"])
 1147:     def test_dt64arr_add_sub_parr(
 1148:         self, dti_freq, pi_freq, box_with_array, box_with_array2
 1149:     ):
 1150:         # GH#20049 subtracting PeriodIndex should raise TypeError
 1151:         dti = DatetimeIndex(["2011-01-01", "2011-01-02"], freq=dti_freq)
 1152:         pi = dti.to_period(pi_freq)
 1153: 
 1154:         dtarr = tm.box_expected(dti, box_with_array)
 1155:         parr = tm.box_expected(pi, box_with_array2)
 1156:         msg = "|".join(
 1157:             [
 1158:                 "cannot (add|subtract)",
 1159:                 "unsupported operand",
 1160:                 "descriptor.*requires",
 1161:                 "ufunc.*cannot use operands",
 1162:             ]
 1163:         )
 1164:         assert_invalid_addsub_type(dtarr, parr, msg)
 1165: 
 1166:     @pytest.mark.filterwarnings("ignore::pandas.errors.PerformanceWarning")
 1167:     def test_dt64arr_addsub_time_objects_raises(self, box_with_array, tz_naive_fixture):
 1168:         # https://github.com/pandas-dev/pandas/issues/10329
 1169: 
 1170:         tz = tz_naive_fixture
 1171: 
 1172:         obj1 = date_range("2012-01-01", periods=3, tz=tz)
 1173:         obj2 = [time(i, i, i) for i in range(3)]
 1174: 
 1175:         obj1 = tm.box_expected(obj1, box_with_array)
 1176:         obj2 = tm.box_expected(obj2, box_with_array)
 1177: 
 1178:         msg = "|".join(
 1179:             [
 1180:                 "unsupported operand",
 1181:                 "cannot subtract DatetimeArray from ndarray",
 1182:             ]
 1183:         )
 1184:         # pandas.errors.PerformanceWarning: Non-vectorized DateOffset being
 1185:         # applied to Series or DatetimeIndex
 1186:         # we aren't testing that here, so ignore.
 1187:         assert_invalid_addsub_type(obj1, obj2, msg=msg)
 1188: 
 1189:     # -------------------------------------------------------------
 1190:     # Other invalid operations
 1191: 
 1192:     @pytest.mark.parametrize(
 1193:         "dt64_series",
 1194:         [
 1195:             Series([Timestamp("19900315"), Timestamp("19900315")]),
 1196:             Series([NaT, Timestamp("19900315")]),
 1197:             Series([NaT, NaT], dtype="datetime64[ns]"),
 1198:         ],
 1199:     )
 1200:     @pytest.mark.parametrize("one", [1, 1.0, np.array(1)])
 1201:     def test_dt64_mul_div_numeric_invalid(self, one, dt64_series, box_with_array):
 1202:         obj = tm.box_expected(dt64_series, box_with_array)
 1203: 
 1204:         msg = "cannot perform .* with this index type"
 1205: 
 1206:         # multiplication
 1207:         with pytest.raises(TypeError, match=msg):
 1208:             obj * one
 1209:         with pytest.raises(TypeError, match=msg):
 1210:             one * obj
 1211: 
 1212:         # division
 1213:         with pytest.raises(TypeError, match=msg):
 1214:             obj / one
 1215:         with pytest.raises(TypeError, match=msg):
 1216:             one / obj
 1217: 
 1218: 
 1219: class TestDatetime64DateOffsetArithmetic:
 1220:     # -------------------------------------------------------------
 1221:     # Tick DateOffsets
 1222: 
 1223:     # TODO: parametrize over timezone?
 1224:     @pytest.mark.parametrize("unit", ["s", "ms", "us", "ns"])
 1225:     def test_dt64arr_series_add_tick_DateOffset(self, box_with_array, unit):
 1226:         # GH#4532
 1227:         # operate with pd.offsets
 1228:         ser = Series(
 1229:             [Timestamp("20130101 9:01"), Timestamp("20130101 9:02")]
 1230:         ).dt.as_unit(unit)
 1231:         expected = Series(
 1232:             [Timestamp("20130101 9:01:05"), Timestamp("20130101 9:02:05")]
 1233:         ).dt.as_unit(unit)
 1234: 
 1235:         ser = tm.box_expected(ser, box_with_array)
 1236:         expected = tm.box_expected(expected, box_with_array)
 1237: 
 1238:         result = ser + pd.offsets.Second(5)
 1239:         tm.assert_equal(result, expected)
 1240: 
 1241:         result2 = pd.offsets.Second(5) + ser
 1242:         tm.assert_equal(result2, expected)
 1243: 
 1244:     def test_dt64arr_series_sub_tick_DateOffset(self, box_with_array):
 1245:         # GH#4532
 1246:         # operate with pd.offsets
 1247:         ser = Series([Timestamp("20130101 9:01"), Timestamp("20130101 9:02")])
 1248:         expected = Series(
 1249:             [Timestamp("20130101 9:00:55"), Timestamp("20130101 9:01:55")]
 1250:         )
 1251: 
 1252:         ser = tm.box_expected(ser, box_with_array)
 1253:         expected = tm.box_expected(expected, box_with_array)
 1254: 
 1255:         result = ser - pd.offsets.Second(5)
 1256:         tm.assert_equal(result, expected)
 1257: 
 1258:         result2 = -pd.offsets.Second(5) + ser
 1259:         tm.assert_equal(result2, expected)
 1260:         msg = "(bad|unsupported) operand type for unary"
 1261:         with pytest.raises(TypeError, match=msg):
 1262:             pd.offsets.Second(5) - ser
 1263: 
 1264:     @pytest.mark.parametrize(
 1265:         "cls_name", ["Day", "Hour", "Minute", "Second", "Milli", "Micro", "Nano"]
 1266:     )
 1267:     def test_dt64arr_add_sub_tick_DateOffset_smoke(self, cls_name, box_with_array):
 1268:         # GH#4532
 1269:         # smoke tests for valid DateOffsets
 1270:         ser = Series([Timestamp("20130101 9:01"), Timestamp("20130101 9:02")])
 1271:         ser = tm.box_expected(ser, box_with_array)
 1272: 
 1273:         offset_cls = getattr(pd.offsets, cls_name)
 1274:         ser + offset_cls(5)
 1275:         offset_cls(5) + ser
 1276:         ser - offset_cls(5)
 1277: 
 1278:     def test_dti_add_tick_tzaware(self, tz_aware_fixture, box_with_array):
 1279:         # GH#21610, GH#22163 ensure DataFrame doesn't return object-dtype
 1280:         tz = tz_aware_fixture
 1281:         if tz == "US/Pacific":
 1282:             dates = date_range("2012-11-01", periods=3, tz=tz)
 1283:             offset = dates + pd.offsets.Hour(5)
 1284:             assert dates[0] + pd.offsets.Hour(5) == offset[0]
 1285: 
 1286:         dates = date_range("2010-11-01 00:00", periods=3, tz=tz, freq="h")
 1287:         expected = DatetimeIndex(
 1288:             ["2010-11-01 05:00", "2010-11-01 06:00", "2010-11-01 07:00"],
 1289:             freq="h",
 1290:             tz=tz,
 1291:         ).as_unit("ns")
 1292: 
 1293:         dates = tm.box_expected(dates, box_with_array)
 1294:         expected = tm.box_expected(expected, box_with_array)
 1295: 
 1296:         for scalar in [pd.offsets.Hour(5), np.timedelta64(5, "h"), timedelta(hours=5)]:
 1297:             offset = dates + scalar
 1298:             tm.assert_equal(offset, expected)
 1299:             offset = scalar + dates
 1300:             tm.assert_equal(offset, expected)
 1301: 
 1302:             roundtrip = offset - scalar
 1303:             tm.assert_equal(roundtrip, dates)
 1304: 
 1305:             msg = "|".join(
 1306:                 ["bad operand type for unary -", "cannot subtract DatetimeArray"]
 1307:             )
 1308:             with pytest.raises(TypeError, match=msg):
 1309:                 scalar - dates
 1310: 
 1311:     # -------------------------------------------------------------
 1312:     # RelativeDelta DateOffsets
 1313: 
 1314:     @pytest.mark.parametrize("unit", ["s", "ms", "us", "ns"])
 1315:     def test_dt64arr_add_sub_relativedelta_offsets(self, box_with_array, unit):
 1316:         # GH#10699
 1317:         vec = DatetimeIndex(
 1318:             [
 1319:                 Timestamp("2000-01-05 00:15:00"),
 1320:                 Timestamp("2000-01-31 00:23:00"),
 1321:                 Timestamp("2000-01-01"),
 1322:                 Timestamp("2000-03-31"),
 1323:                 Timestamp("2000-02-29"),
 1324:                 Timestamp("2000-12-31"),
 1325:                 Timestamp("2000-05-15"),
 1326:                 Timestamp("2001-06-15"),
 1327:             ]
 1328:         ).as_unit(unit)
 1329:         vec = tm.box_expected(vec, box_with_array)
 1330:         vec_items = vec.iloc[0] if box_with_array is pd.DataFrame else vec
 1331: 
 1332:         # DateOffset relativedelta fastpath
 1333:         relative_kwargs = [
 1334:             ("years", 2),
 1335:             ("months", 5),
 1336:             ("days", 3),
 1337:             ("hours", 5),
 1338:             ("minutes", 10),
 1339:             ("seconds", 2),
 1340:             ("microseconds", 5),
 1341:         ]
 1342:         for i, (offset_unit, value) in enumerate(relative_kwargs):
 1343:             off = DateOffset(**{offset_unit: value})
 1344: 
 1345:             exp_unit = unit
 1346:             if offset_unit == "microseconds" and unit != "ns":
 1347:                 exp_unit = "us"
 1348: 
 1349:             # TODO(GH#55564): as_unit will be unnecessary
 1350:             expected = DatetimeIndex([x + off for x in vec_items]).as_unit(exp_unit)
 1351:             expected = tm.box_expected(expected, box_with_array)
 1352:             tm.assert_equal(expected, vec + off)
 1353: 
 1354:             expected = DatetimeIndex([x - off for x in vec_items]).as_unit(exp_unit)
 1355:             expected = tm.box_expected(expected, box_with_array)
 1356:             tm.assert_equal(expected, vec - off)
 1357: 
 1358:             off = DateOffset(**dict(relative_kwargs[: i + 1]))
 1359: 
 1360:             expected = DatetimeIndex([x + off for x in vec_items]).as_unit(exp_unit)
 1361:             expected = tm.box_expected(expected, box_with_array)
 1362:             tm.assert_equal(expected, vec + off)
 1363: 
 1364:             expected = DatetimeIndex([x - off for x in vec_items]).as_unit(exp_unit)
 1365:             expected = tm.box_expected(expected, box_with_array)
 1366:             tm.assert_equal(expected, vec - off)
 1367:             msg = "(bad|unsupported) operand type for unary"
 1368:             with pytest.raises(TypeError, match=msg):
 1369:                 off - vec
 1370: 
 1371:     # -------------------------------------------------------------
 1372:     # Non-Tick, Non-RelativeDelta DateOffsets
 1373: 
 1374:     # TODO: redundant with test_dt64arr_add_sub_DateOffset?  that includes
 1375:     #  tz-aware cases which this does not
 1376:     @pytest.mark.filterwarnings("ignore::pandas.errors.PerformanceWarning")
 1377:     @pytest.mark.parametrize(
 1378:         "cls_and_kwargs",
 1379:         [
 1380:             "YearBegin",
 1381:             ("YearBegin", {"month": 5}),
 1382:             "YearEnd",
 1383:             ("YearEnd", {"month": 5}),
 1384:             "MonthBegin",
 1385:             "MonthEnd",
 1386:             "SemiMonthEnd",
 1387:             "SemiMonthBegin",
 1388:             "Week",
 1389:             ("Week", {"weekday": 3}),
 1390:             "Week",
 1391:             ("Week", {"weekday": 6}),
 1392:             "BusinessDay",
 1393:             "BDay",
 1394:             "QuarterEnd",
 1395:             "QuarterBegin",
 1396:             "CustomBusinessDay",
 1397:             "CDay",
 1398:             "CBMonthEnd",
 1399:             "CBMonthBegin",
 1400:             "BMonthBegin",
 1401:             "BMonthEnd",
 1402:             "BusinessHour",
 1403:             "BYearBegin",
 1404:             "BYearEnd",
 1405:             "BQuarterBegin",
 1406:             ("LastWeekOfMonth", {"weekday": 2}),
 1407:             (
 1408:                 "FY5253Quarter",
 1409:                 {
 1410:                     "qtr_with_extra_week": 1,
 1411:                     "startingMonth": 1,
 1412:                     "weekday": 2,
 1413:                     "variation": "nearest",
 1414:                 },
 1415:             ),
 1416:             ("FY5253", {"weekday": 0, "startingMonth": 2, "variation": "nearest"}),
 1417:             ("WeekOfMonth", {"weekday": 2, "week": 2}),
 1418:             "Easter",
 1419:             ("DateOffset", {"day": 4}),
 1420:             ("DateOffset", {"month": 5}),
 1421:         ],
 1422:     )
 1423:     @pytest.mark.parametrize("normalize", [True, False])
 1424:     @pytest.mark.parametrize("n", [0, 5])
 1425:     @pytest.mark.parametrize("unit", ["s", "ms", "us", "ns"])
 1426:     @pytest.mark.parametrize("tz", [None, "US/Central"])
 1427:     def test_dt64arr_add_sub_DateOffsets(
 1428:         self, box_with_array, n, normalize, cls_and_kwargs, unit, tz
 1429:     ):
 1430:         # GH#10699
 1431:         # assert vectorized operation matches pointwise operations
 1432: 
 1433:         if isinstance(cls_and_kwargs, tuple):
 1434:             # If cls_name param is a tuple, then 2nd entry is kwargs for
 1435:             # the offset constructor
 1436:             cls_name, kwargs = cls_and_kwargs
 1437:         else:
 1438:             cls_name = cls_and_kwargs
 1439:             kwargs = {}
 1440: 
 1441:         if n == 0 and cls_name in [
 1442:             "WeekOfMonth",
 1443:             "LastWeekOfMonth",
 1444:             "FY5253Quarter",
 1445:             "FY5253",
 1446:         ]:
 1447:             # passing n = 0 is invalid for these offset classes
 1448:             return
 1449: 
 1450:         vec = (
 1451:             DatetimeIndex(
 1452:                 [
 1453:                     Timestamp("2000-01-05 00:15:00"),
 1454:                     Timestamp("2000-01-31 00:23:00"),
 1455:                     Timestamp("2000-01-01"),
 1456:                     Timestamp("2000-03-31"),
 1457:                     Timestamp("2000-02-29"),
 1458:                     Timestamp("2000-12-31"),
 1459:                     Timestamp("2000-05-15"),
 1460:                     Timestamp("2001-06-15"),
 1461:                 ]
 1462:             )
 1463:             .as_unit(unit)
 1464:             .tz_localize(tz)
 1465:         )
 1466:         vec = tm.box_expected(vec, box_with_array)
 1467:         vec_items = vec.iloc[0] if box_with_array is pd.DataFrame else vec
 1468: 
 1469:         offset_cls = getattr(pd.offsets, cls_name)
 1470:         offset = offset_cls(n, normalize=normalize, **kwargs)
 1471: 
 1472:         # TODO(GH#55564): as_unit will be unnecessary
 1473:         expected = DatetimeIndex([x + offset for x in vec_items]).as_unit(unit)
 1474:         expected = tm.box_expected(expected, box_with_array)
 1475:         tm.assert_equal(expected, vec + offset)
 1476:         tm.assert_equal(expected, offset + vec)
 1477: 
 1478:         expected = DatetimeIndex([x - offset for x in vec_items]).as_unit(unit)
 1479:         expected = tm.box_expected(expected, box_with_array)
 1480:         tm.assert_equal(expected, vec - offset)
 1481: 
 1482:         expected = DatetimeIndex([offset + x for x in vec_items]).as_unit(unit)
 1483:         expected = tm.box_expected(expected, box_with_array)
 1484:         tm.assert_equal(expected, offset + vec)
 1485:         msg = "(bad|unsupported) operand type for unary"
 1486:         with pytest.raises(TypeError, match=msg):
 1487:             offset - vec
 1488: 
 1489:     @pytest.mark.parametrize(
 1490:         "other",
 1491:         [
 1492:             np.array([pd.offsets.MonthEnd(), pd.offsets.Day(n=2)]),
 1493:             np.array([pd.offsets.DateOffset(years=1), pd.offsets.MonthEnd()]),
 1494:             np.array(  # matching offsets
 1495:                 [pd.offsets.DateOffset(years=1), pd.offsets.DateOffset(years=1)]
 1496:             ),
 1497:         ],
 1498:     )
 1499:     @pytest.mark.parametrize("op", [operator.add, roperator.radd, operator.sub])
 1500:     def test_dt64arr_add_sub_offset_array(
 1501:         self, tz_naive_fixture, box_with_array, op, other
 1502:     ):
 1503:         # GH#18849
 1504:         # GH#10699 array of offsets
 1505: 
 1506:         tz = tz_naive_fixture
 1507:         dti = date_range("2017-01-01", periods=2, tz=tz)
 1508:         dtarr = tm.box_expected(dti, box_with_array)
 1509: 
 1510:         expected = DatetimeIndex([op(dti[n], other[n]) for n in range(len(dti))])
 1511:         expected = tm.box_expected(expected, box_with_array).astype(object)
 1512: 
 1513:         with tm.assert_produces_warning(PerformanceWarning):
 1514:             res = op(dtarr, other)
 1515:         tm.assert_equal(res, expected)
 1516: 
 1517:         # Same thing but boxing other
 1518:         other = tm.box_expected(other, box_with_array)
 1519:         if box_with_array is pd.array and op is roperator.radd:
 1520:             # We expect a NumpyExtensionArray, not ndarray[object] here
 1521:             expected = pd.array(expected, dtype=object)
 1522:         with tm.assert_produces_warning(PerformanceWarning):
 1523:             res = op(dtarr, other)
 1524:         tm.assert_equal(res, expected)
 1525: 
 1526:     @pytest.mark.parametrize(
 1527:         "op, offset, exp, exp_freq",
 1528:         [
 1529:             (
 1530:                 "__add__",
 1531:                 DateOffset(months=3, days=10),
 1532:                 [
 1533:                     Timestamp("2014-04-11"),
 1534:                     Timestamp("2015-04-11"),
 1535:                     Timestamp("2016-04-11"),
 1536:                     Timestamp("2017-04-11"),
 1537:                 ],
 1538:                 None,
 1539:             ),
 1540:             (
 1541:                 "__add__",
 1542:                 DateOffset(months=3),
 1543:                 [
 1544:                     Timestamp("2014-04-01"),
 1545:                     Timestamp("2015-04-01"),
 1546:                     Timestamp("2016-04-01"),
 1547:                     Timestamp("2017-04-01"),
 1548:                 ],
 1549:                 "YS-APR",
 1550:             ),
 1551:             (
 1552:                 "__sub__",
 1553:                 DateOffset(months=3, days=10),
 1554:                 [
 1555:                     Timestamp("2013-09-21"),
 1556:                     Timestamp("2014-09-21"),
 1557:                     Timestamp("2015-09-21"),
 1558:                     Timestamp("2016-09-21"),
 1559:                 ],
 1560:                 None,
 1561:             ),
 1562:             (
 1563:                 "__sub__",
 1564:                 DateOffset(months=3),
 1565:                 [
 1566:                     Timestamp("2013-10-01"),
 1567:                     Timestamp("2014-10-01"),
 1568:                     Timestamp("2015-10-01"),
 1569:                     Timestamp("2016-10-01"),
 1570:                 ],
 1571:                 "YS-OCT",
 1572:             ),
 1573:         ],
 1574:     )
 1575:     def test_dti_add_sub_nonzero_mth_offset(
 1576:         self, op, offset, exp, exp_freq, tz_aware_fixture, box_with_array
 1577:     ):
 1578:         # GH 26258
 1579:         tz = tz_aware_fixture
 1580:         date = date_range(start="01 Jan 2014", end="01 Jan 2017", freq="YS", tz=tz)
 1581:         date = tm.box_expected(date, box_with_array, False)
 1582:         mth = getattr(date, op)
 1583:         result = mth(offset)
 1584: 
 1585:         expected = DatetimeIndex(exp, tz=tz).as_unit("ns")
 1586:         expected = tm.box_expected(expected, box_with_array, False)
 1587:         tm.assert_equal(result, expected)
 1588: 
 1589:     def test_dt64arr_series_add_DateOffset_with_milli(self):
 1590:         # GH 57529
 1591:         dti = DatetimeIndex(
 1592:             [
 1593:                 "2000-01-01 00:00:00.012345678",
 1594:                 "2000-01-31 00:00:00.012345678",
 1595:                 "2000-02-29 00:00:00.012345678",
 1596:             ],
 1597:             dtype="datetime64[ns]",
 1598:         )
 1599:         result = dti + DateOffset(milliseconds=4)
 1600:         expected = DatetimeIndex(
 1601:             [
 1602:                 "2000-01-01 00:00:00.016345678",
 1603:                 "2000-01-31 00:00:00.016345678",
 1604:                 "2000-02-29 00:00:00.016345678",
 1605:             ],
 1606:             dtype="datetime64[ns]",
 1607:         )
 1608:         tm.assert_index_equal(result, expected)
 1609: 
 1610:         result = dti + DateOffset(days=1, milliseconds=4)
 1611:         expected = DatetimeIndex(
 1612:             [
 1613:                 "2000-01-02 00:00:00.016345678",
 1614:                 "2000-02-01 00:00:00.016345678",
 1615:                 "2000-03-01 00:00:00.016345678",
 1616:             ],
 1617:             dtype="datetime64[ns]",
 1618:         )
 1619:         tm.assert_index_equal(result, expected)
 1620: 
 1621: 
 1622: class TestDatetime64OverflowHandling:
 1623:     # TODO: box + de-duplicate
 1624: 
 1625:     def test_dt64_overflow_masking(self, box_with_array):
 1626:         # GH#25317
 1627:         left = Series([Timestamp("1969-12-31")], dtype="M8[ns]")
 1628:         right = Series([NaT])
 1629: 
 1630:         left = tm.box_expected(left, box_with_array)
 1631:         right = tm.box_expected(right, box_with_array)
 1632: 
 1633:         expected = TimedeltaIndex([NaT], dtype="m8[ns]")
 1634:         expected = tm.box_expected(expected, box_with_array)
 1635: 
 1636:         result = left - right
 1637:         tm.assert_equal(result, expected)
 1638: 
 1639:     def test_dt64_series_arith_overflow(self):
 1640:         # GH#12534, fixed by GH#19024
 1641:         dt = Timestamp("1700-01-31")
 1642:         td = Timedelta("20000 Days")
 1643:         dti = date_range("1949-09-30", freq="100YE", periods=4)
 1644:         ser = Series(dti)
 1645:         msg = "Overflow in int64 addition"
 1646:         with pytest.raises(OverflowError, match=msg):
 1647:             ser - dt
 1648:         with pytest.raises(OverflowError, match=msg):
 1649:             dt - ser
 1650:         with pytest.raises(OverflowError, match=msg):
 1651:             ser + td
 1652:         with pytest.raises(OverflowError, match=msg):
 1653:             td + ser
 1654: 
 1655:         ser.iloc[-1] = NaT
 1656:         expected = Series(
 1657:             ["2004-10-03", "2104-10-04", "2204-10-04", "NaT"], dtype="datetime64[ns]"
 1658:         )
 1659:         res = ser + td
 1660:         tm.assert_series_equal(res, expected)
 1661:         res = td + ser
 1662:         tm.assert_series_equal(res, expected)
 1663: 
 1664:         ser.iloc[1:] = NaT
 1665:         expected = Series(["91279 Days", "NaT", "NaT", "NaT"], dtype="timedelta64[ns]")
 1666:         res = ser - dt
 1667:         tm.assert_series_equal(res, expected)
 1668:         res = dt - ser
 1669:         tm.assert_series_equal(res, -expected)
 1670: 
 1671:     def test_datetimeindex_sub_timestamp_overflow(self):
 1672:         dtimax = pd.to_datetime(["2021-12-28 17:19", Timestamp.max]).as_unit("ns")
 1673:         dtimin = pd.to_datetime(["2021-12-28 17:19", Timestamp.min]).as_unit("ns")
 1674: 
 1675:         tsneg = Timestamp("1950-01-01").as_unit("ns")
 1676:         ts_neg_variants = [
 1677:             tsneg,
 1678:             tsneg.to_pydatetime(),
 1679:             tsneg.to_datetime64().astype("datetime64[ns]"),
 1680:             tsneg.to_datetime64().astype("datetime64[D]"),
 1681:         ]
 1682: 
 1683:         tspos = Timestamp("1980-01-01").as_unit("ns")
 1684:         ts_pos_variants = [
 1685:             tspos,
 1686:             tspos.to_pydatetime(),
 1687:             tspos.to_datetime64().astype("datetime64[ns]"),
 1688:             tspos.to_datetime64().astype("datetime64[D]"),
 1689:         ]
 1690:         msg = "Overflow in int64 addition"
 1691:         for variant in ts_neg_variants:
 1692:             with pytest.raises(OverflowError, match=msg):
 1693:                 dtimax - variant
 1694: 
 1695:         expected = Timestamp.max._value - tspos._value
 1696:         for variant in ts_pos_variants:
 1697:             res = dtimax - variant
 1698:             assert res[1]._value == expected
 1699: 
 1700:         expected = Timestamp.min._value - tsneg._value
 1701:         for variant in ts_neg_variants:
 1702:             res = dtimin - variant
 1703:             assert res[1]._value == expected
 1704: 
 1705:         for variant in ts_pos_variants:
 1706:             with pytest.raises(OverflowError, match=msg):
 1707:                 dtimin - variant
 1708: 
 1709:     def test_datetimeindex_sub_datetimeindex_overflow(self):
 1710:         # GH#22492, GH#22508
 1711:         dtimax = pd.to_datetime(["2021-12-28 17:19", Timestamp.max]).as_unit("ns")
 1712:         dtimin = pd.to_datetime(["2021-12-28 17:19", Timestamp.min]).as_unit("ns")
 1713: 
 1714:         ts_neg = pd.to_datetime(["1950-01-01", "1950-01-01"]).as_unit("ns")
 1715:         ts_pos = pd.to_datetime(["1980-01-01", "1980-01-01"]).as_unit("ns")
 1716: 
 1717:         # General tests
 1718:         expected = Timestamp.max._value - ts_pos[1]._value
 1719:         result = dtimax - ts_pos
 1720:         assert result[1]._value == expected
 1721: 
 1722:         expected = Timestamp.min._value - ts_neg[1]._value
 1723:         result = dtimin - ts_neg
 1724:         assert result[1]._value == expected
 1725:         msg = "Overflow in int64 addition"
 1726:         with pytest.raises(OverflowError, match=msg):
 1727:             dtimax - ts_neg
 1728: 
 1729:         with pytest.raises(OverflowError, match=msg):
 1730:             dtimin - ts_pos
 1731: 
 1732:         # Edge cases
 1733:         tmin = pd.to_datetime([Timestamp.min])
 1734:         t1 = tmin + Timedelta.max + Timedelta("1us")
 1735:         with pytest.raises(OverflowError, match=msg):
 1736:             t1 - tmin
 1737: 
 1738:         tmax = pd.to_datetime([Timestamp.max])
 1739:         t2 = tmax + Timedelta.min - Timedelta("1us")
 1740:         with pytest.raises(OverflowError, match=msg):
 1741:             tmax - t2
 1742: 
 1743: 
 1744: class TestTimestampSeriesArithmetic:
 1745:     def test_empty_series_add_sub(self, box_with_array):
 1746:         # GH#13844
 1747:         a = Series(dtype="M8[ns]")
 1748:         b = Series(dtype="m8[ns]")
 1749:         a = box_with_array(a)
 1750:         b = box_with_array(b)
 1751:         tm.assert_equal(a, a + b)
 1752:         tm.assert_equal(a, a - b)
 1753:         tm.assert_equal(a, b + a)
 1754:         msg = "cannot subtract"
 1755:         with pytest.raises(TypeError, match=msg):
 1756:             b - a
 1757: 
 1758:     def test_operators_datetimelike(self):
 1759:         # ## timedelta64 ###
 1760:         td1 = Series([timedelta(minutes=5, seconds=3)] * 3)
 1761:         td1.iloc[2] = np.nan
 1762: 
 1763:         # ## datetime64 ###
 1764:         dt1 = Series(
 1765:             [
 1766:                 Timestamp("20111230"),
 1767:                 Timestamp("20120101"),
 1768:                 Timestamp("20120103"),
 1769:             ]
 1770:         )
 1771:         dt1.iloc[2] = np.nan
 1772:         dt2 = Series(
 1773:             [
 1774:                 Timestamp("20111231"),
 1775:                 Timestamp("20120102"),
 1776:                 Timestamp("20120104"),
 1777:             ]
 1778:         )
 1779:         dt1 - dt2
 1780:         dt2 - dt1
 1781: 
 1782:         # datetime64 with timetimedelta
 1783:         dt1 + td1
 1784:         td1 + dt1
 1785:         dt1 - td1
 1786: 
 1787:         # timetimedelta with datetime64
 1788:         td1 + dt1
 1789:         dt1 + td1
 1790: 
 1791:     def test_dt64ser_sub_datetime_dtype(self, unit):
 1792:         ts = Timestamp(datetime(1993, 1, 7, 13, 30, 00))
 1793:         dt = datetime(1993, 6, 22, 13, 30)
 1794:         ser = Series([ts], dtype=f"M8[{unit}]")
 1795:         result = ser - dt
 1796: 
 1797:         # the expected unit is the max of `unit` and the unit imputed to `dt`,
 1798:         #  which is "us"
 1799:         exp_unit = tm.get_finest_unit(unit, "us")
 1800:         assert result.dtype == f"timedelta64[{exp_unit}]"
 1801: 
 1802:     # -------------------------------------------------------------
 1803:     # TODO: This next block of tests came from tests.series.test_operators,
 1804:     # needs to be de-duplicated and parametrized over `box` classes
 1805: 
 1806:     @pytest.mark.parametrize(
 1807:         "left, right, op_fail",
 1808:         [
 1809:             [
 1810:                 [Timestamp("20111230"), Timestamp("20120101"), NaT],
 1811:                 [Timestamp("20111231"), Timestamp("20120102"), Timestamp("20120104")],
 1812:                 ["__sub__", "__rsub__"],
 1813:             ],
 1814:             [
 1815:                 [Timestamp("20111230"), Timestamp("20120101"), NaT],
 1816:                 [timedelta(minutes=5, seconds=3), timedelta(minutes=5, seconds=3), NaT],
 1817:                 ["__add__", "__radd__", "__sub__"],
 1818:             ],
 1819:             [
 1820:                 [
 1821:                     Timestamp("20111230", tz="US/Eastern"),
 1822:                     Timestamp("20111230", tz="US/Eastern"),
 1823:                     NaT,
 1824:                 ],
 1825:                 [timedelta(minutes=5, seconds=3), NaT, timedelta(minutes=5, seconds=3)],
 1826:                 ["__add__", "__radd__", "__sub__"],
 1827:             ],
 1828:         ],
 1829:     )
 1830:     def test_operators_datetimelike_invalid(
 1831:         self, left, right, op_fail, all_arithmetic_operators
 1832:     ):
 1833:         # these are all TypeError ops
 1834:         op_str = all_arithmetic_operators
 1835:         arg1 = Series(left)
 1836:         arg2 = Series(right)
 1837:         # check that we are getting a TypeError
 1838:         # with 'operate' (from core/ops.py) for the ops that are not
 1839:         # defined
 1840:         op = getattr(arg1, op_str, None)
 1841:         # Previously, _validate_for_numeric_binop in core/indexes/base.py
 1842:         # did this for us.
 1843:         if op_str not in op_fail:
 1844:             with pytest.raises(
 1845:                 TypeError, match="operate|[cC]annot|unsupported operand"
 1846:             ):
 1847:                 op(arg2)
 1848:         else:
 1849:             # Smoke test
 1850:             op(arg2)
 1851: 
 1852:     def test_sub_single_tz(self, unit):
 1853:         # GH#12290
 1854:         s1 = Series([Timestamp("2016-02-10", tz="America/Sao_Paulo")]).dt.as_unit(unit)
 1855:         s2 = Series([Timestamp("2016-02-08", tz="America/Sao_Paulo")]).dt.as_unit(unit)
 1856:         result = s1 - s2
 1857:         expected = Series([Timedelta("2days")]).dt.as_unit(unit)
 1858:         tm.assert_series_equal(result, expected)
 1859:         result = s2 - s1
 1860:         expected = Series([Timedelta("-2days")]).dt.as_unit(unit)
 1861:         tm.assert_series_equal(result, expected)
 1862: 
 1863:     def test_dt64tz_series_sub_dtitz(self):
 1864:         # GH#19071 subtracting tzaware DatetimeIndex from tzaware Series
 1865:         # (with same tz) raises, fixed by #19024
 1866:         dti = date_range("1999-09-30", periods=10, tz="US/Pacific")
 1867:         ser = Series(dti)
 1868:         expected = Series(TimedeltaIndex(["0days"] * 10))
 1869: 
 1870:         res = dti - ser
 1871:         tm.assert_series_equal(res, expected)
 1872:         res = ser - dti
 1873:         tm.assert_series_equal(res, expected)
 1874: 
 1875:     def test_sub_datetime_compat(self, unit):
 1876:         # see GH#14088
 1877:         ser = Series([datetime(2016, 8, 23, 12, tzinfo=pytz.utc), NaT]).dt.as_unit(unit)
 1878:         dt = datetime(2016, 8, 22, 12, tzinfo=pytz.utc)
 1879:         # The datetime object has "us" so we upcast lower units
 1880:         exp_unit = tm.get_finest_unit(unit, "us")
 1881:         exp = Series([Timedelta("1 days"), NaT]).dt.as_unit(exp_unit)
 1882:         result = ser - dt
 1883:         tm.assert_series_equal(result, exp)
 1884:         result2 = ser - Timestamp(dt)
 1885:         tm.assert_series_equal(result2, exp)
 1886: 
 1887:     def test_dt64_series_add_mixed_tick_DateOffset(self):
 1888:         # GH#4532
 1889:         # operate with pd.offsets
 1890:         s = Series([Timestamp("20130101 9:01"), Timestamp("20130101 9:02")])
 1891: 
 1892:         result = s + pd.offsets.Milli(5)
 1893:         result2 = pd.offsets.Milli(5) + s
 1894:         expected = Series(
 1895:             [Timestamp("20130101 9:01:00.005"), Timestamp("20130101 9:02:00.005")]
 1896:         )
 1897:         tm.assert_series_equal(result, expected)
 1898:         tm.assert_series_equal(result2, expected)
 1899: 
 1900:         result = s + pd.offsets.Minute(5) + pd.offsets.Milli(5)
 1901:         expected = Series(
 1902:             [Timestamp("20130101 9:06:00.005"), Timestamp("20130101 9:07:00.005")]
 1903:         )
 1904:         tm.assert_series_equal(result, expected)
 1905: 
 1906:     def test_datetime64_ops_nat(self, unit):
 1907:         # GH#11349
 1908:         datetime_series = Series([NaT, Timestamp("19900315")]).dt.as_unit(unit)
 1909:         nat_series_dtype_timestamp = Series([NaT, NaT], dtype=f"datetime64[{unit}]")
 1910:         single_nat_dtype_datetime = Series([NaT], dtype=f"datetime64[{unit}]")
 1911: 
 1912:         # subtraction
 1913:         tm.assert_series_equal(-NaT + datetime_series, nat_series_dtype_timestamp)
 1914:         msg = "bad operand type for unary -: 'DatetimeArray'"
 1915:         with pytest.raises(TypeError, match=msg):
 1916:             -single_nat_dtype_datetime + datetime_series
 1917: 
 1918:         tm.assert_series_equal(
 1919:             -NaT + nat_series_dtype_timestamp, nat_series_dtype_timestamp
 1920:         )
 1921:         with pytest.raises(TypeError, match=msg):
 1922:             -single_nat_dtype_datetime + nat_series_dtype_timestamp
 1923: 
 1924:         # addition
 1925:         tm.assert_series_equal(
 1926:             nat_series_dtype_timestamp + NaT, nat_series_dtype_timestamp
 1927:         )
 1928:         tm.assert_series_equal(
 1929:             NaT + nat_series_dtype_timestamp, nat_series_dtype_timestamp
 1930:         )
 1931: 
 1932:         tm.assert_series_equal(
 1933:             nat_series_dtype_timestamp + NaT, nat_series_dtype_timestamp
 1934:         )
 1935:         tm.assert_series_equal(
 1936:             NaT + nat_series_dtype_timestamp, nat_series_dtype_timestamp
 1937:         )
 1938: 
 1939:     # -------------------------------------------------------------
 1940:     # Timezone-Centric Tests
 1941: 
 1942:     def test_operators_datetimelike_with_timezones(self):
 1943:         tz = "US/Eastern"
 1944:         dt1 = Series(date_range("2000-01-01 09:00:00", periods=5, tz=tz), name="foo")
 1945:         dt2 = dt1.copy()
 1946:         dt2.iloc[2] = np.nan
 1947: 
 1948:         td1 = Series(pd.timedelta_range("1 days 1 min", periods=5, freq="h"))
 1949:         td2 = td1.copy()
 1950:         td2.iloc[1] = np.nan
 1951:         assert td2._values.freq is None
 1952: 
 1953:         result = dt1 + td1[0]
 1954:         exp = (dt1.dt.tz_localize(None) + td1[0]).dt.tz_localize(tz)
 1955:         tm.assert_series_equal(result, exp)
 1956: 
 1957:         result = dt2 + td2[0]
 1958:         exp = (dt2.dt.tz_localize(None) + td2[0]).dt.tz_localize(tz)
 1959:         tm.assert_series_equal(result, exp)
 1960: 
 1961:         # odd numpy behavior with scalar timedeltas
 1962:         result = td1[0] + dt1
 1963:         exp = (dt1.dt.tz_localize(None) + td1[0]).dt.tz_localize(tz)
 1964:         tm.assert_series_equal(result, exp)
 1965: 
 1966:         result = td2[0] + dt2
 1967:         exp = (dt2.dt.tz_localize(None) + td2[0]).dt.tz_localize(tz)
 1968:         tm.assert_series_equal(result, exp)
 1969: 
 1970:         result = dt1 - td1[0]
 1971:         exp = (dt1.dt.tz_localize(None) - td1[0]).dt.tz_localize(tz)
 1972:         tm.assert_series_equal(result, exp)
 1973:         msg = "(bad|unsupported) operand type for unary"
 1974:         with pytest.raises(TypeError, match=msg):
 1975:             td1[0] - dt1
 1976: 
 1977:         result = dt2 - td2[0]
 1978:         exp = (dt2.dt.tz_localize(None) - td2[0]).dt.tz_localize(tz)
 1979:         tm.assert_series_equal(result, exp)
 1980:         with pytest.raises(TypeError, match=msg):
 1981:             td2[0] - dt2
 1982: 
 1983:         result = dt1 + td1
 1984:         exp = (dt1.dt.tz_localize(None) + td1).dt.tz_localize(tz)
 1985:         tm.assert_series_equal(result, exp)
 1986: 
 1987:         result = dt2 + td2
 1988:         exp = (dt2.dt.tz_localize(None) + td2).dt.tz_localize(tz)
 1989:         tm.assert_series_equal(result, exp)
 1990: 
 1991:         result = dt1 - td1
 1992:         exp = (dt1.dt.tz_localize(None) - td1).dt.tz_localize(tz)
 1993:         tm.assert_series_equal(result, exp)
 1994: 
 1995:         result = dt2 - td2
 1996:         exp = (dt2.dt.tz_localize(None) - td2).dt.tz_localize(tz)
 1997:         tm.assert_series_equal(result, exp)
 1998:         msg = "cannot (add|subtract)"
 1999:         with pytest.raises(TypeError, match=msg):
 2000:             td1 - dt1
 2001:         with pytest.raises(TypeError, match=msg):
 2002:             td2 - dt2
 2003: 
 2004: 
 2005: class TestDatetimeIndexArithmetic:
 2006:     # -------------------------------------------------------------
 2007:     # Binary operations DatetimeIndex and TimedeltaIndex/array
 2008: 
 2009:     def test_dti_add_tdi(self, tz_naive_fixture):
 2010:         # GH#17558
 2011:         tz = tz_naive_fixture
 2012:         dti = DatetimeIndex([Timestamp("2017-01-01", tz=tz)] * 10)
 2013:         tdi = pd.timedelta_range("0 days", periods=10)
 2014:         expected = date_range("2017-01-01", periods=10, tz=tz)
 2015:         expected = expected._with_freq(None)
 2016: 
 2017:         # add with TimedeltaIndex
 2018:         result = dti + tdi
 2019:         tm.assert_index_equal(result, expected)
 2020: 
 2021:         result = tdi + dti
 2022:         tm.assert_index_equal(result, expected)
 2023: 
 2024:         # add with timedelta64 array
 2025:         result = dti + tdi.values
 2026:         tm.assert_index_equal(result, expected)
 2027: 
 2028:         result = tdi.values + dti
 2029:         tm.assert_index_equal(result, expected)
 2030: 
 2031:     def test_dti_iadd_tdi(self, tz_naive_fixture):
 2032:         # GH#17558
 2033:         tz = tz_naive_fixture
 2034:         dti = DatetimeIndex([Timestamp("2017-01-01", tz=tz)] * 10)
 2035:         tdi = pd.timedelta_range("0 days", periods=10)
 2036:         expected = date_range("2017-01-01", periods=10, tz=tz)
 2037:         expected = expected._with_freq(None)
 2038: 
 2039:         # iadd with TimedeltaIndex
 2040:         result = DatetimeIndex([Timestamp("2017-01-01", tz=tz)] * 10)
 2041:         result += tdi
 2042:         tm.assert_index_equal(result, expected)
 2043: 
 2044:         result = pd.timedelta_range("0 days", periods=10)
 2045:         result += dti
 2046:         tm.assert_index_equal(result, expected)
 2047: 
 2048:         # iadd with timedelta64 array
 2049:         result = DatetimeIndex([Timestamp("2017-01-01", tz=tz)] * 10)
 2050:         result += tdi.values
 2051:         tm.assert_index_equal(result, expected)
 2052: 
 2053:         result = pd.timedelta_range("0 days", periods=10)
 2054:         result += dti
 2055:         tm.assert_index_equal(result, expected)
 2056: 
 2057:     def test_dti_sub_tdi(self, tz_naive_fixture):
 2058:         # GH#17558
 2059:         tz = tz_naive_fixture
 2060:         dti = DatetimeIndex([Timestamp("2017-01-01", tz=tz)] * 10)
 2061:         tdi = pd.timedelta_range("0 days", periods=10)
 2062:         expected = date_range("2017-01-01", periods=10, tz=tz, freq="-1D")
 2063:         expected = expected._with_freq(None)
 2064: 
 2065:         # sub with TimedeltaIndex
 2066:         result = dti - tdi
 2067:         tm.assert_index_equal(result, expected)
 2068: 
 2069:         msg = "cannot subtract .*TimedeltaArray"
 2070:         with pytest.raises(TypeError, match=msg):
 2071:             tdi - dti
 2072: 
 2073:         # sub with timedelta64 array
 2074:         result = dti - tdi.values
 2075:         tm.assert_index_equal(result, expected)
 2076: 
 2077:         msg = "cannot subtract a datelike from a TimedeltaArray"
 2078:         with pytest.raises(TypeError, match=msg):
 2079:             tdi.values - dti
 2080: 
 2081:     def test_dti_isub_tdi(self, tz_naive_fixture, unit):
 2082:         # GH#17558
 2083:         tz = tz_naive_fixture
 2084:         dti = DatetimeIndex([Timestamp("2017-01-01", tz=tz)] * 10).as_unit(unit)
 2085:         tdi = pd.timedelta_range("0 days", periods=10, unit=unit)
 2086:         expected = date_range("2017-01-01", periods=10, tz=tz, freq="-1D", unit=unit)
 2087:         expected = expected._with_freq(None)
 2088: 
 2089:         # isub with TimedeltaIndex
 2090:         result = DatetimeIndex([Timestamp("2017-01-01", tz=tz)] * 10).as_unit(unit)
 2091:         result -= tdi
 2092:         tm.assert_index_equal(result, expected)
 2093: 
 2094:         # DTA.__isub__ GH#43904
 2095:         dta = dti._data.copy()
 2096:         dta -= tdi
 2097:         tm.assert_datetime_array_equal(dta, expected._data)
 2098: 
 2099:         out = dti._data.copy()
 2100:         np.subtract(out, tdi, out=out)
 2101:         tm.assert_datetime_array_equal(out, expected._data)
 2102: 
 2103:         msg = "cannot subtract a datelike from a TimedeltaArray"
 2104:         with pytest.raises(TypeError, match=msg):
 2105:             tdi -= dti
 2106: 
 2107:         # isub with timedelta64 array
 2108:         result = DatetimeIndex([Timestamp("2017-01-01", tz=tz)] * 10).as_unit(unit)
 2109:         result -= tdi.values
 2110:         tm.assert_index_equal(result, expected)
 2111: 
 2112:         with pytest.raises(TypeError, match=msg):
 2113:             tdi.values -= dti
 2114: 
 2115:         with pytest.raises(TypeError, match=msg):
 2116:             tdi._values -= dti
 2117: 
 2118:     # -------------------------------------------------------------
 2119:     # Binary Operations DatetimeIndex and datetime-like
 2120:     # TODO: A couple other tests belong in this section.  Move them in
 2121:     # A PR where there isn't already a giant diff.
 2122: 
 2123:     # -------------------------------------------------------------
 2124: 
 2125:     def test_dta_add_sub_index(self, tz_naive_fixture):
 2126:         # Check that DatetimeArray defers to Index classes
 2127:         dti = date_range("20130101", periods=3, tz=tz_naive_fixture)
 2128:         dta = dti.array
 2129:         result = dta - dti
 2130:         expected = dti - dti
 2131:         tm.assert_index_equal(result, expected)
 2132: 
 2133:         tdi = result
 2134:         result = dta + tdi
 2135:         expected = dti + tdi
 2136:         tm.assert_index_equal(result, expected)
 2137: 
 2138:         result = dta - tdi
 2139:         expected = dti - tdi
 2140:         tm.assert_index_equal(result, expected)
 2141: 
 2142:     def test_sub_dti_dti(self, unit):
 2143:         # previously performed setop (deprecated in 0.16.0), now changed to
 2144:         # return subtraction -> TimeDeltaIndex (GH ...)
 2145: 
 2146:         dti = date_range("20130101", periods=3, unit=unit)
 2147:         dti_tz = date_range("20130101", periods=3, unit=unit).tz_localize("US/Eastern")
 2148:         expected = TimedeltaIndex([0, 0, 0]).as_unit(unit)
 2149: 
 2150:         result = dti - dti
 2151:         tm.assert_index_equal(result, expected)
 2152: 
 2153:         result = dti_tz - dti_tz
 2154:         tm.assert_index_equal(result, expected)
 2155:         msg = "Cannot subtract tz-naive and tz-aware datetime-like objects"
 2156:         with pytest.raises(TypeError, match=msg):
 2157:             dti_tz - dti
 2158: 
 2159:         with pytest.raises(TypeError, match=msg):
 2160:             dti - dti_tz
 2161: 
 2162:         # isub
 2163:         dti -= dti
 2164:         tm.assert_index_equal(dti, expected)
 2165: 
 2166:         # different length raises ValueError
 2167:         dti1 = date_range("20130101", periods=3, unit=unit)
 2168:         dti2 = date_range("20130101", periods=4, unit=unit)
 2169:         msg = "cannot add indices of unequal length"
 2170:         with pytest.raises(ValueError, match=msg):
 2171:             dti1 - dti2
 2172: 
 2173:         # NaN propagation
 2174:         dti1 = DatetimeIndex(["2012-01-01", np.nan, "2012-01-03"]).as_unit(unit)
 2175:         dti2 = DatetimeIndex(["2012-01-02", "2012-01-03", np.nan]).as_unit(unit)
 2176:         expected = TimedeltaIndex(["1 days", np.nan, np.nan]).as_unit(unit)
 2177:         result = dti2 - dti1
 2178:         tm.assert_index_equal(result, expected)
 2179: 
 2180:     # -------------------------------------------------------------------
 2181:     # TODO: Most of this block is moved from series or frame tests, needs
 2182:     # cleanup, box-parametrization, and de-duplication
 2183: 
 2184:     @pytest.mark.parametrize("op", [operator.add, operator.sub])
 2185:     def test_timedelta64_equal_timedelta_supported_ops(self, op, box_with_array):
 2186:         ser = Series(
 2187:             [
 2188:                 Timestamp("20130301"),
 2189:                 Timestamp("20130228 23:00:00"),
 2190:                 Timestamp("20130228 22:00:00"),
 2191:                 Timestamp("20130228 21:00:00"),
 2192:             ]
 2193:         )
 2194:         obj = box_with_array(ser)
 2195: 
 2196:         intervals = ["D", "h", "m", "s", "us"]
 2197: 
 2198:         def timedelta64(*args):
 2199:             # see casting notes in NumPy gh-12927
 2200:             return np.sum(list(starmap(np.timedelta64, zip(args, intervals))))
 2201: 
 2202:         for d, h, m, s, us in product(*([range(2)] * 5)):
 2203:             nptd = timedelta64(d, h, m, s, us)
 2204:             pytd = timedelta(days=d, hours=h, minutes=m, seconds=s, microseconds=us)
 2205:             lhs = op(obj, nptd)
 2206:             rhs = op(obj, pytd)
 2207: 
 2208:             tm.assert_equal(lhs, rhs)
 2209: 
 2210:     def test_ops_nat_mixed_datetime64_timedelta64(self):
 2211:         # GH#11349
 2212:         timedelta_series = Series([NaT, Timedelta("1s")])
 2213:         datetime_series = Series([NaT, Timestamp("19900315")])
 2214:         nat_series_dtype_timedelta = Series([NaT, NaT], dtype="timedelta64[ns]")
 2215:         nat_series_dtype_timestamp = Series([NaT, NaT], dtype="datetime64[ns]")
 2216:         single_nat_dtype_datetime = Series([NaT], dtype="datetime64[ns]")
 2217:         single_nat_dtype_timedelta = Series([NaT], dtype="timedelta64[ns]")
 2218: 
 2219:         # subtraction
 2220:         tm.assert_series_equal(
 2221:             datetime_series - single_nat_dtype_datetime, nat_series_dtype_timedelta
 2222:         )
 2223: 
 2224:         tm.assert_series_equal(
 2225:             datetime_series - single_nat_dtype_timedelta, nat_series_dtype_timestamp
 2226:         )
 2227:         tm.assert_series_equal(
 2228:             -single_nat_dtype_timedelta + datetime_series, nat_series_dtype_timestamp
 2229:         )
 2230: 
 2231:         # without a Series wrapping the NaT, it is ambiguous
 2232:         # whether it is a datetime64 or timedelta64
 2233:         # defaults to interpreting it as timedelta64
 2234:         tm.assert_series_equal(
 2235:             nat_series_dtype_timestamp - single_nat_dtype_datetime,
 2236:             nat_series_dtype_timedelta,
 2237:         )
 2238: 
 2239:         tm.assert_series_equal(
 2240:             nat_series_dtype_timestamp - single_nat_dtype_timedelta,
 2241:             nat_series_dtype_timestamp,
 2242:         )
 2243:         tm.assert_series_equal(
 2244:             -single_nat_dtype_timedelta + nat_series_dtype_timestamp,
 2245:             nat_series_dtype_timestamp,
 2246:         )
 2247:         msg = "cannot subtract a datelike"
 2248:         with pytest.raises(TypeError, match=msg):
 2249:             timedelta_series - single_nat_dtype_datetime
 2250: 
 2251:         # addition
 2252:         tm.assert_series_equal(
 2253:             nat_series_dtype_timestamp + single_nat_dtype_timedelta,
 2254:             nat_series_dtype_timestamp,
 2255:         )
 2256:         tm.assert_series_equal(
 2257:             single_nat_dtype_timedelta + nat_series_dtype_timestamp,
 2258:             nat_series_dtype_timestamp,
 2259:         )
 2260: 
 2261:         tm.assert_series_equal(
 2262:             nat_series_dtype_timestamp + single_nat_dtype_timedelta,
 2263:             nat_series_dtype_timestamp,
 2264:         )
 2265:         tm.assert_series_equal(
 2266:             single_nat_dtype_timedelta + nat_series_dtype_timestamp,
 2267:             nat_series_dtype_timestamp,
 2268:         )
 2269: 
 2270:         tm.assert_series_equal(
 2271:             nat_series_dtype_timedelta + single_nat_dtype_datetime,
 2272:             nat_series_dtype_timestamp,
 2273:         )
 2274:         tm.assert_series_equal(
 2275:             single_nat_dtype_datetime + nat_series_dtype_timedelta,
 2276:             nat_series_dtype_timestamp,
 2277:         )
 2278: 
 2279:     def test_ufunc_coercions(self, unit):
 2280:         idx = date_range("2011-01-01", periods=3, freq="2D", name="x", unit=unit)
 2281: 
 2282:         delta = np.timedelta64(1, "D")
 2283:         exp = date_range("2011-01-02", periods=3, freq="2D", name="x", unit=unit)
 2284:         for result in [idx + delta, np.add(idx, delta)]:
 2285:             assert isinstance(result, DatetimeIndex)
 2286:             tm.assert_index_equal(result, exp)
 2287:             assert result.freq == "2D"
 2288: 
 2289:         exp = date_range("2010-12-31", periods=3, freq="2D", name="x", unit=unit)
 2290: 
 2291:         for result in [idx - delta, np.subtract(idx, delta)]:
 2292:             assert isinstance(result, DatetimeIndex)
 2293:             tm.assert_index_equal(result, exp)
 2294:             assert result.freq == "2D"
 2295: 
 2296:         # When adding/subtracting an ndarray (which has no .freq), the result
 2297:         #  does not infer freq
 2298:         idx = idx._with_freq(None)
 2299:         delta = np.array(
 2300:             [np.timedelta64(1, "D"), np.timedelta64(2, "D"), np.timedelta64(3, "D")]
 2301:         )
 2302:         exp = DatetimeIndex(
 2303:             ["2011-01-02", "2011-01-05", "2011-01-08"], name="x"
 2304:         ).as_unit(unit)
 2305: 
 2306:         for result in [idx + delta, np.add(idx, delta)]:
 2307:             tm.assert_index_equal(result, exp)
 2308:             assert result.freq == exp.freq
 2309: 
 2310:         exp = DatetimeIndex(
 2311:             ["2010-12-31", "2011-01-01", "2011-01-02"], name="x"
 2312:         ).as_unit(unit)
 2313:         for result in [idx - delta, np.subtract(idx, delta)]:
 2314:             assert isinstance(result, DatetimeIndex)
 2315:             tm.assert_index_equal(result, exp)
 2316:             assert result.freq == exp.freq
 2317: 
 2318:     def test_dti_add_series(self, tz_naive_fixture, names):
 2319:         # GH#13905
 2320:         tz = tz_naive_fixture
 2321:         index = DatetimeIndex(
 2322:             ["2016-06-28 05:30", "2016-06-28 05:31"], tz=tz, name=names[0]
 2323:         ).as_unit("ns")
 2324:         ser = Series([Timedelta(seconds=5)] * 2, index=index, name=names[1])
 2325:         expected = Series(index + Timedelta(seconds=5), index=index, name=names[2])
 2326: 
 2327:         # passing name arg isn't enough when names[2] is None
 2328:         expected.name = names[2]
 2329:         assert expected.dtype == index.dtype
 2330:         result = ser + index
 2331:         tm.assert_series_equal(result, expected)
 2332:         result2 = index + ser
 2333:         tm.assert_series_equal(result2, expected)
 2334: 
 2335:         expected = index + Timedelta(seconds=5)
 2336:         result3 = ser.values + index
 2337:         tm.assert_index_equal(result3, expected)
 2338:         result4 = index + ser.values
 2339:         tm.assert_index_equal(result4, expected)
 2340: 
 2341:     @pytest.mark.parametrize("op", [operator.add, roperator.radd, operator.sub])
 2342:     def test_dti_addsub_offset_arraylike(
 2343:         self, tz_naive_fixture, names, op, index_or_series
 2344:     ):
 2345:         # GH#18849, GH#19744
 2346:         other_box = index_or_series
 2347: 
 2348:         tz = tz_naive_fixture
 2349:         dti = date_range("2017-01-01", periods=2, tz=tz, name=names[0])
 2350:         other = other_box([pd.offsets.MonthEnd(), pd.offsets.Day(n=2)], name=names[1])
 2351: 
 2352:         xbox = get_upcast_box(dti, other)
 2353: 
 2354:         with tm.assert_produces_warning(PerformanceWarning):
 2355:             res = op(dti, other)
 2356: 
 2357:         expected = DatetimeIndex(
 2358:             [op(dti[n], other[n]) for n in range(len(dti))], name=names[2], freq="infer"
 2359:         )
 2360:         expected = tm.box_expected(expected, xbox).astype(object)
 2361:         tm.assert_equal(res, expected)
 2362: 
 2363:     @pytest.mark.parametrize("other_box", [pd.Index, np.array])
 2364:     def test_dti_addsub_object_arraylike(
 2365:         self, tz_naive_fixture, box_with_array, other_box
 2366:     ):
 2367:         tz = tz_naive_fixture
 2368: 
 2369:         dti = date_range("2017-01-01", periods=2, tz=tz)
 2370:         dtarr = tm.box_expected(dti, box_with_array)
 2371:         other = other_box([pd.offsets.MonthEnd(), Timedelta(days=4)])
 2372:         xbox = get_upcast_box(dtarr, other)
 2373: 
 2374:         expected = DatetimeIndex(["2017-01-31", "2017-01-06"], tz=tz_naive_fixture)
 2375:         expected = tm.box_expected(expected, xbox).astype(object)
 2376: 
 2377:         with tm.assert_produces_warning(PerformanceWarning):
 2378:             result = dtarr + other
 2379:         tm.assert_equal(result, expected)
 2380: 
 2381:         expected = DatetimeIndex(["2016-12-31", "2016-12-29"], tz=tz_naive_fixture)
 2382:         expected = tm.box_expected(expected, xbox).astype(object)
 2383: 
 2384:         with tm.assert_produces_warning(PerformanceWarning):
 2385:             result = dtarr - other
 2386:         tm.assert_equal(result, expected)
 2387: 
 2388: 
 2389: @pytest.mark.parametrize("years", [-1, 0, 1])
 2390: @pytest.mark.parametrize("months", [-2, 0, 2])
 2391: @pytest.mark.parametrize("unit", ["s", "ms", "us", "ns"])
 2392: def test_shift_months(years, months, unit):
 2393:     dti = DatetimeIndex(
 2394:         [
 2395:             Timestamp("2000-01-05 00:15:00"),
 2396:             Timestamp("2000-01-31 00:23:00"),
 2397:             Timestamp("2000-01-01"),
 2398:             Timestamp("2000-02-29"),
 2399:             Timestamp("2000-12-31"),
 2400:         ]
 2401:     ).as_unit(unit)
 2402:     shifted = shift_months(dti.asi8, years * 12 + months, reso=dti._data._creso)
 2403:     shifted_dt64 = shifted.view(f"M8[{dti.unit}]")
 2404:     actual = DatetimeIndex(shifted_dt64)
 2405: 
 2406:     raw = [x + pd.offsets.DateOffset(years=years, months=months) for x in dti]
 2407:     expected = DatetimeIndex(raw).as_unit(dti.unit)
 2408:     tm.assert_index_equal(actual, expected)
 2409: 
 2410: 
 2411: def test_dt64arr_addsub_object_dtype_2d():
 2412:     # block-wise DataFrame operations will require operating on 2D
 2413:     #  DatetimeArray/TimedeltaArray, so check that specifically.
 2414:     dti = date_range("1994-02-13", freq="2W", periods=4)
 2415:     dta = dti._data.reshape((4, 1))
 2416: 
 2417:     other = np.array([[pd.offsets.Day(n)] for n in range(4)])
 2418:     assert other.shape == dta.shape
 2419: 
 2420:     with tm.assert_produces_warning(PerformanceWarning):
 2421:         result = dta + other
 2422:     with tm.assert_produces_warning(PerformanceWarning):
 2423:         expected = (dta[:, 0] + other[:, 0]).reshape(-1, 1)
 2424: 
 2425:     tm.assert_numpy_array_equal(result, expected)
 2426: 
 2427:     with tm.assert_produces_warning(PerformanceWarning):
 2428:         # Case where we expect to get a TimedeltaArray back
 2429:         result2 = dta - dta.astype(object)
 2430: 
 2431:     assert result2.shape == (4, 1)
 2432:     assert all(td._value == 0 for td in result2.ravel())
 2433: 
 2434: 
 2435: def test_non_nano_dt64_addsub_np_nat_scalars():
 2436:     # GH 52295
 2437:     ser = Series([1233242342344, 232432434324, 332434242344], dtype="datetime64[ms]")
 2438:     result = ser - np.datetime64("nat", "ms")
 2439:     expected = Series([NaT] * 3, dtype="timedelta64[ms]")
 2440:     tm.assert_series_equal(result, expected)
 2441: 
 2442:     result = ser + np.timedelta64("nat", "ms")
 2443:     expected = Series([NaT] * 3, dtype="datetime64[ms]")
 2444:     tm.assert_series_equal(result, expected)
 2445: 
 2446: 
 2447: def test_non_nano_dt64_addsub_np_nat_scalars_unitless():
 2448:     # GH 52295
 2449:     # TODO: Can we default to the ser unit?
 2450:     ser = Series([1233242342344, 232432434324, 332434242344], dtype="datetime64[ms]")
 2451:     result = ser - np.datetime64("nat")
 2452:     expected = Series([NaT] * 3, dtype="timedelta64[ns]")
 2453:     tm.assert_series_equal(result, expected)
 2454: 
 2455:     result = ser + np.timedelta64("nat")
 2456:     expected = Series([NaT] * 3, dtype="datetime64[ns]")
 2457:     tm.assert_series_equal(result, expected)
 2458: 
 2459: 
 2460: def test_non_nano_dt64_addsub_np_nat_scalars_unsupported_unit():
 2461:     # GH 52295
 2462:     ser = Series([12332, 23243, 33243], dtype="datetime64[s]")
 2463:     result = ser - np.datetime64("nat", "D")
 2464:     expected = Series([NaT] * 3, dtype="timedelta64[s]")
 2465:     tm.assert_series_equal(result, expected)
 2466: 
 2467:     result = ser + np.timedelta64("nat", "D")
 2468:     expected = Series([NaT] * 3, dtype="datetime64[s]")
 2469:     tm.assert_series_equal(result, expected)
