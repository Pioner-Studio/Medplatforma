    1: from collections.abc import Generator
    2: from contextlib import contextmanager
    3: import re
    4: import struct
    5: import tracemalloc
    6: 
    7: import numpy as np
    8: import pytest
    9: 
   10: from pandas._libs import hashtable as ht
   11: 
   12: import pandas as pd
   13: import pandas._testing as tm
   14: from pandas.core.algorithms import isin
   15: 
   16: 
   17: @contextmanager
   18: def activated_tracemalloc() -> Generator[None, None, None]:
   19:     tracemalloc.start()
   20:     try:
   21:         yield
   22:     finally:
   23:         tracemalloc.stop()
   24: 
   25: 
   26: def get_allocated_khash_memory():
   27:     snapshot = tracemalloc.take_snapshot()
   28:     snapshot = snapshot.filter_traces(
   29:         (tracemalloc.DomainFilter(True, ht.get_hashtable_trace_domain()),)
   30:     )
   31:     return sum(x.size for x in snapshot.traces)
   32: 
   33: 
   34: @pytest.mark.parametrize(
   35:     "table_type, dtype",
   36:     [
   37:         (ht.PyObjectHashTable, np.object_),
   38:         (ht.Complex128HashTable, np.complex128),
   39:         (ht.Int64HashTable, np.int64),
   40:         (ht.UInt64HashTable, np.uint64),
   41:         (ht.Float64HashTable, np.float64),
   42:         (ht.Complex64HashTable, np.complex64),
   43:         (ht.Int32HashTable, np.int32),
   44:         (ht.UInt32HashTable, np.uint32),
   45:         (ht.Float32HashTable, np.float32),
   46:         (ht.Int16HashTable, np.int16),
   47:         (ht.UInt16HashTable, np.uint16),
   48:         (ht.Int8HashTable, np.int8),
   49:         (ht.UInt8HashTable, np.uint8),
   50:         (ht.IntpHashTable, np.intp),
   51:     ],
   52: )
   53: class TestHashTable:
   54:     def test_get_set_contains_len(self, table_type, dtype):
   55:         index = 5
   56:         table = table_type(55)
   57:         assert len(table) == 0
   58:         assert index not in table
   59: 
   60:         table.set_item(index, 42)
   61:         assert len(table) == 1
   62:         assert index in table
   63:         assert table.get_item(index) == 42
   64: 
   65:         table.set_item(index + 1, 41)
   66:         assert index in table
   67:         assert index + 1 in table
   68:         assert len(table) == 2
   69:         assert table.get_item(index) == 42
   70:         assert table.get_item(index + 1) == 41
   71: 
   72:         table.set_item(index, 21)
   73:         assert index in table
   74:         assert index + 1 in table
   75:         assert len(table) == 2
   76:         assert table.get_item(index) == 21
   77:         assert table.get_item(index + 1) == 41
   78:         assert index + 2 not in table
   79: 
   80:         table.set_item(index + 1, 21)
   81:         assert index in table
   82:         assert index + 1 in table
   83:         assert len(table) == 2
   84:         assert table.get_item(index) == 21
   85:         assert table.get_item(index + 1) == 21
   86: 
   87:         with pytest.raises(KeyError, match=str(index + 2)):
   88:             table.get_item(index + 2)
   89: 
   90:     def test_get_set_contains_len_mask(self, table_type, dtype):
   91:         if table_type == ht.PyObjectHashTable:
   92:             pytest.skip("Mask not supported for object")
   93:         index = 5
   94:         table = table_type(55, uses_mask=True)
   95:         assert len(table) == 0
   96:         assert index not in table
   97: 
   98:         table.set_item(index, 42)
   99:         assert len(table) == 1
  100:         assert index in table
  101:         assert table.get_item(index) == 42
  102:         with pytest.raises(KeyError, match="NA"):
  103:             table.get_na()
  104: 
  105:         table.set_item(index + 1, 41)
  106:         table.set_na(41)
  107:         assert pd.NA in table
  108:         assert index in table
  109:         assert index + 1 in table
  110:         assert len(table) == 3
  111:         assert table.get_item(index) == 42
  112:         assert table.get_item(index + 1) == 41
  113:         assert table.get_na() == 41
  114: 
  115:         table.set_na(21)
  116:         assert index in table
  117:         assert index + 1 in table
  118:         assert len(table) == 3
  119:         assert table.get_item(index + 1) == 41
  120:         assert table.get_na() == 21
  121:         assert index + 2 not in table
  122: 
  123:         with pytest.raises(KeyError, match=str(index + 2)):
  124:             table.get_item(index + 2)
  125: 
  126:     def test_map_keys_to_values(self, table_type, dtype, writable):
  127:         # only Int64HashTable has this method
  128:         if table_type == ht.Int64HashTable:
  129:             N = 77
  130:             table = table_type()
  131:             keys = np.arange(N).astype(dtype)
  132:             vals = np.arange(N).astype(np.int64) + N
  133:             keys.flags.writeable = writable
  134:             vals.flags.writeable = writable
  135:             table.map_keys_to_values(keys, vals)
  136:             for i in range(N):
  137:                 assert table.get_item(keys[i]) == i + N
  138: 
  139:     def test_map_locations(self, table_type, dtype, writable):
  140:         N = 8
  141:         table = table_type()
  142:         keys = (np.arange(N) + N).astype(dtype)
  143:         keys.flags.writeable = writable
  144:         table.map_locations(keys)
  145:         for i in range(N):
  146:             assert table.get_item(keys[i]) == i
  147: 
  148:     def test_map_locations_mask(self, table_type, dtype, writable):
  149:         if table_type == ht.PyObjectHashTable:
  150:             pytest.skip("Mask not supported for object")
  151:         N = 3
  152:         table = table_type(uses_mask=True)
  153:         keys = (np.arange(N) + N).astype(dtype)
  154:         keys.flags.writeable = writable
  155:         table.map_locations(keys, np.array([False, False, True]))
  156:         for i in range(N - 1):
  157:             assert table.get_item(keys[i]) == i
  158: 
  159:         with pytest.raises(KeyError, match=re.escape(str(keys[N - 1]))):
  160:             table.get_item(keys[N - 1])
  161: 
  162:         assert table.get_na() == 2
  163: 
  164:     def test_lookup(self, table_type, dtype, writable):
  165:         N = 3
  166:         table = table_type()
  167:         keys = (np.arange(N) + N).astype(dtype)
  168:         keys.flags.writeable = writable
  169:         table.map_locations(keys)
  170:         result = table.lookup(keys)
  171:         expected = np.arange(N)
  172:         tm.assert_numpy_array_equal(result.astype(np.int64), expected.astype(np.int64))
  173: 
  174:     def test_lookup_wrong(self, table_type, dtype):
  175:         if dtype in (np.int8, np.uint8):
  176:             N = 100
  177:         else:
  178:             N = 512
  179:         table = table_type()
  180:         keys = (np.arange(N) + N).astype(dtype)
  181:         table.map_locations(keys)
  182:         wrong_keys = np.arange(N).astype(dtype)
  183:         result = table.lookup(wrong_keys)
  184:         assert np.all(result == -1)
  185: 
  186:     def test_lookup_mask(self, table_type, dtype, writable):
  187:         if table_type == ht.PyObjectHashTable:
  188:             pytest.skip("Mask not supported for object")
  189:         N = 3
  190:         table = table_type(uses_mask=True)
  191:         keys = (np.arange(N) + N).astype(dtype)
  192:         mask = np.array([False, True, False])
  193:         keys.flags.writeable = writable
  194:         table.map_locations(keys, mask)
  195:         result = table.lookup(keys, mask)
  196:         expected = np.arange(N)
  197:         tm.assert_numpy_array_equal(result.astype(np.int64), expected.astype(np.int64))
  198: 
  199:         result = table.lookup(np.array([1 + N]).astype(dtype), np.array([False]))
  200:         tm.assert_numpy_array_equal(
  201:             result.astype(np.int64), np.array([-1], dtype=np.int64)
  202:         )
  203: 
  204:     def test_unique(self, table_type, dtype, writable):
  205:         if dtype in (np.int8, np.uint8):
  206:             N = 88
  207:         else:
  208:             N = 1000
  209:         table = table_type()
  210:         expected = (np.arange(N) + N).astype(dtype)
  211:         keys = np.repeat(expected, 5)
  212:         keys.flags.writeable = writable
  213:         unique = table.unique(keys)
  214:         tm.assert_numpy_array_equal(unique, expected)
  215: 
  216:     def test_tracemalloc_works(self, table_type, dtype):
  217:         if dtype in (np.int8, np.uint8):
  218:             N = 256
  219:         else:
  220:             N = 30000
  221:         keys = np.arange(N).astype(dtype)
  222:         with activated_tracemalloc():
  223:             table = table_type()
  224:             table.map_locations(keys)
  225:             used = get_allocated_khash_memory()
  226:             my_size = table.sizeof()
  227:             assert used == my_size
  228:             del table
  229:             assert get_allocated_khash_memory() == 0
  230: 
  231:     def test_tracemalloc_for_empty(self, table_type, dtype):
  232:         with activated_tracemalloc():
  233:             table = table_type()
  234:             used = get_allocated_khash_memory()
  235:             my_size = table.sizeof()
  236:             assert used == my_size
  237:             del table
  238:             assert get_allocated_khash_memory() == 0
  239: 
  240:     def test_get_state(self, table_type, dtype):
  241:         table = table_type(1000)
  242:         state = table.get_state()
  243:         assert state["size"] == 0
  244:         assert state["n_occupied"] == 0
  245:         assert "n_buckets" in state
  246:         assert "upper_bound" in state
  247: 
  248:     @pytest.mark.parametrize("N", range(1, 110))
  249:     def test_no_reallocation(self, table_type, dtype, N):
  250:         keys = np.arange(N).astype(dtype)
  251:         preallocated_table = table_type(N)
  252:         n_buckets_start = preallocated_table.get_state()["n_buckets"]
  253:         preallocated_table.map_locations(keys)
  254:         n_buckets_end = preallocated_table.get_state()["n_buckets"]
  255:         # original number of buckets was enough:
  256:         assert n_buckets_start == n_buckets_end
  257:         # check with clean table (not too much preallocated)
  258:         clean_table = table_type()
  259:         clean_table.map_locations(keys)
  260:         assert n_buckets_start == clean_table.get_state()["n_buckets"]
  261: 
  262: 
  263: class TestHashTableUnsorted:
  264:     # TODO: moved from test_algos; may be redundancies with other tests
  265:     def test_string_hashtable_set_item_signature(self):
  266:         # GH#30419 fix typing in StringHashTable.set_item to prevent segfault
  267:         tbl = ht.StringHashTable()
  268: 
  269:         tbl.set_item("key", 1)
  270:         assert tbl.get_item("key") == 1
  271: 
  272:         with pytest.raises(TypeError, match="'key' has incorrect type"):
  273:             # key arg typed as string, not object
  274:             tbl.set_item(4, 6)
  275:         with pytest.raises(TypeError, match="'val' has incorrect type"):
  276:             tbl.get_item(4)
  277: 
  278:     def test_lookup_nan(self, writable):
  279:         # GH#21688 ensure we can deal with readonly memory views
  280:         xs = np.array([2.718, 3.14, np.nan, -7, 5, 2, 3])
  281:         xs.setflags(write=writable)
  282:         m = ht.Float64HashTable()
  283:         m.map_locations(xs)
  284:         tm.assert_numpy_array_equal(m.lookup(xs), np.arange(len(xs), dtype=np.intp))
  285: 
  286:     def test_add_signed_zeros(self):
  287:         # GH#21866 inconsistent hash-function for float64
  288:         # default hash-function would lead to different hash-buckets
  289:         # for 0.0 and -0.0 if there are more than 2^30 hash-buckets
  290:         # but this would mean 16GB
  291:         N = 4  # 12 * 10**8 would trigger the error, if you have enough memory
  292:         m = ht.Float64HashTable(N)
  293:         m.set_item(0.0, 0)
  294:         m.set_item(-0.0, 0)
  295:         assert len(m) == 1  # 0.0 and -0.0 are equivalent
  296: 
  297:     def test_add_different_nans(self):
  298:         # GH#21866 inconsistent hash-function for float64
  299:         # create different nans from bit-patterns:
  300:         NAN1 = struct.unpack("d", struct.pack("=Q", 0x7FF8000000000000))[0]
  301:         NAN2 = struct.unpack("d", struct.pack("=Q", 0x7FF8000000000001))[0]
  302:         assert NAN1 != NAN1
  303:         assert NAN2 != NAN2
  304:         # default hash function would lead to different hash-buckets
  305:         # for NAN1 and NAN2 even if there are only 4 buckets:
  306:         m = ht.Float64HashTable()
  307:         m.set_item(NAN1, 0)
  308:         m.set_item(NAN2, 0)
  309:         assert len(m) == 1  # NAN1 and NAN2 are equivalent
  310: 
  311:     def test_lookup_overflow(self, writable):
  312:         xs = np.array([1, 2, 2**63], dtype=np.uint64)
  313:         # GH 21688 ensure we can deal with readonly memory views
  314:         xs.setflags(write=writable)
  315:         m = ht.UInt64HashTable()
  316:         m.map_locations(xs)
  317:         tm.assert_numpy_array_equal(m.lookup(xs), np.arange(len(xs), dtype=np.intp))
  318: 
  319:     @pytest.mark.parametrize("nvals", [0, 10])  # resizing to 0 is special case
  320:     @pytest.mark.parametrize(
  321:         "htable, uniques, dtype, safely_resizes",
  322:         [
  323:             (ht.PyObjectHashTable, ht.ObjectVector, "object", False),
  324:             (ht.StringHashTable, ht.ObjectVector, "object", True),
  325:             (ht.Float64HashTable, ht.Float64Vector, "float64", False),
  326:             (ht.Int64HashTable, ht.Int64Vector, "int64", False),
  327:             (ht.Int32HashTable, ht.Int32Vector, "int32", False),
  328:             (ht.UInt64HashTable, ht.UInt64Vector, "uint64", False),
  329:         ],
  330:     )
  331:     def test_vector_resize(
  332:         self, writable, htable, uniques, dtype, safely_resizes, nvals
  333:     ):
  334:         # Test for memory errors after internal vector
  335:         # reallocations (GH 7157)
  336:         # Changed from using np.random.default_rng(2).rand to range
  337:         # which could cause flaky CI failures when safely_resizes=False
  338:         vals = np.array(range(1000), dtype=dtype)
  339: 
  340:         # GH 21688 ensures we can deal with read-only memory views
  341:         vals.setflags(write=writable)
  342: 
  343:         # initialise instances; cannot initialise in parametrization,
  344:         # as otherwise external views would be held on the array (which is
  345:         # one of the things this test is checking)
  346:         htable = htable()
  347:         uniques = uniques()
  348: 
  349:         # get_labels may append to uniques
  350:         htable.get_labels(vals[:nvals], uniques, 0, -1)
  351:         # to_array() sets an external_view_exists flag on uniques.
  352:         tmp = uniques.to_array()
  353:         oldshape = tmp.shape
  354: 
  355:         # subsequent get_labels() calls can no longer append to it
  356:         # (except for StringHashTables + ObjectVector)
  357:         if safely_resizes:
  358:             htable.get_labels(vals, uniques, 0, -1)
  359:         else:
  360:             with pytest.raises(ValueError, match="external reference.*"):
  361:                 htable.get_labels(vals, uniques, 0, -1)
  362: 
  363:         uniques.to_array()  # should not raise here
  364:         assert tmp.shape == oldshape
  365: 
  366:     @pytest.mark.parametrize(
  367:         "hashtable",
  368:         [
  369:             ht.PyObjectHashTable,
  370:             ht.StringHashTable,
  371:             ht.Float64HashTable,
  372:             ht.Int64HashTable,
  373:             ht.Int32HashTable,
  374:             ht.UInt64HashTable,
  375:         ],
  376:     )
  377:     def test_hashtable_large_sizehint(self, hashtable):
  378:         # GH#22729 smoketest for not raising when passing a large size_hint
  379:         size_hint = np.iinfo(np.uint32).max + 1
  380:         hashtable(size_hint=size_hint)
  381: 
  382: 
  383: class TestPyObjectHashTableWithNans:
  384:     def test_nan_float(self):
  385:         nan1 = float("nan")
  386:         nan2 = float("nan")
  387:         assert nan1 is not nan2
  388:         table = ht.PyObjectHashTable()
  389:         table.set_item(nan1, 42)
  390:         assert table.get_item(nan2) == 42
  391: 
  392:     def test_nan_complex_both(self):
  393:         nan1 = complex(float("nan"), float("nan"))
  394:         nan2 = complex(float("nan"), float("nan"))
  395:         assert nan1 is not nan2
  396:         table = ht.PyObjectHashTable()
  397:         table.set_item(nan1, 42)
  398:         assert table.get_item(nan2) == 42
  399: 
  400:     def test_nan_complex_real(self):
  401:         nan1 = complex(float("nan"), 1)
  402:         nan2 = complex(float("nan"), 1)
  403:         other = complex(float("nan"), 2)
  404:         assert nan1 is not nan2
  405:         table = ht.PyObjectHashTable()
  406:         table.set_item(nan1, 42)
  407:         assert table.get_item(nan2) == 42
  408:         with pytest.raises(KeyError, match=None) as error:
  409:             table.get_item(other)
  410:         assert str(error.value) == str(other)
  411: 
  412:     def test_nan_complex_imag(self):
  413:         nan1 = complex(1, float("nan"))
  414:         nan2 = complex(1, float("nan"))
  415:         other = complex(2, float("nan"))
  416:         assert nan1 is not nan2
  417:         table = ht.PyObjectHashTable()
  418:         table.set_item(nan1, 42)
  419:         assert table.get_item(nan2) == 42
  420:         with pytest.raises(KeyError, match=None) as error:
  421:             table.get_item(other)
  422:         assert str(error.value) == str(other)
  423: 
  424:     def test_nan_in_tuple(self):
  425:         nan1 = (float("nan"),)
  426:         nan2 = (float("nan"),)
  427:         assert nan1[0] is not nan2[0]
  428:         table = ht.PyObjectHashTable()
  429:         table.set_item(nan1, 42)
  430:         assert table.get_item(nan2) == 42
  431: 
  432:     def test_nan_in_nested_tuple(self):
  433:         nan1 = (1, (2, (float("nan"),)))
  434:         nan2 = (1, (2, (float("nan"),)))
  435:         other = (1, 2)
  436:         table = ht.PyObjectHashTable()
  437:         table.set_item(nan1, 42)
  438:         assert table.get_item(nan2) == 42
  439:         with pytest.raises(KeyError, match=None) as error:
  440:             table.get_item(other)
  441:         assert str(error.value) == str(other)
  442: 
  443: 
  444: def test_hash_equal_tuple_with_nans():
  445:     a = (float("nan"), (float("nan"), float("nan")))
  446:     b = (float("nan"), (float("nan"), float("nan")))
  447:     assert ht.object_hash(a) == ht.object_hash(b)
  448:     assert ht.objects_are_equal(a, b)
  449: 
  450: 
  451: def test_get_labels_groupby_for_Int64(writable):
  452:     table = ht.Int64HashTable()
  453:     vals = np.array([1, 2, -1, 2, 1, -1], dtype=np.int64)
  454:     vals.flags.writeable = writable
  455:     arr, unique = table.get_labels_groupby(vals)
  456:     expected_arr = np.array([0, 1, -1, 1, 0, -1], dtype=np.intp)
  457:     expected_unique = np.array([1, 2], dtype=np.int64)
  458:     tm.assert_numpy_array_equal(arr, expected_arr)
  459:     tm.assert_numpy_array_equal(unique, expected_unique)
  460: 
  461: 
  462: def test_tracemalloc_works_for_StringHashTable():
  463:     N = 1000
  464:     keys = np.arange(N).astype(np.str_).astype(np.object_)
  465:     with activated_tracemalloc():
  466:         table = ht.StringHashTable()
  467:         table.map_locations(keys)
  468:         used = get_allocated_khash_memory()
  469:         my_size = table.sizeof()
  470:         assert used == my_size
  471:         del table
  472:         assert get_allocated_khash_memory() == 0
  473: 
  474: 
  475: def test_tracemalloc_for_empty_StringHashTable():
  476:     with activated_tracemalloc():
  477:         table = ht.StringHashTable()
  478:         used = get_allocated_khash_memory()
  479:         my_size = table.sizeof()
  480:         assert used == my_size
  481:         del table
  482:         assert get_allocated_khash_memory() == 0
  483: 
  484: 
  485: @pytest.mark.parametrize("N", range(1, 110))
  486: def test_no_reallocation_StringHashTable(N):
  487:     keys = np.arange(N).astype(np.str_).astype(np.object_)
  488:     preallocated_table = ht.StringHashTable(N)
  489:     n_buckets_start = preallocated_table.get_state()["n_buckets"]
  490:     preallocated_table.map_locations(keys)
  491:     n_buckets_end = preallocated_table.get_state()["n_buckets"]
  492:     # original number of buckets was enough:
  493:     assert n_buckets_start == n_buckets_end
  494:     # check with clean table (not too much preallocated)
  495:     clean_table = ht.StringHashTable()
  496:     clean_table.map_locations(keys)
  497:     assert n_buckets_start == clean_table.get_state()["n_buckets"]
  498: 
  499: 
  500: @pytest.mark.parametrize(
  501:     "table_type, dtype",
  502:     [
  503:         (ht.Float64HashTable, np.float64),
  504:         (ht.Float32HashTable, np.float32),
  505:         (ht.Complex128HashTable, np.complex128),
  506:         (ht.Complex64HashTable, np.complex64),
  507:     ],
  508: )
  509: class TestHashTableWithNans:
  510:     def test_get_set_contains_len(self, table_type, dtype):
  511:         index = float("nan")
  512:         table = table_type()
  513:         assert index not in table
  514: 
  515:         table.set_item(index, 42)
  516:         assert len(table) == 1
  517:         assert index in table
  518:         assert table.get_item(index) == 42
  519: 
  520:         table.set_item(index, 41)
  521:         assert len(table) == 1
  522:         assert index in table
  523:         assert table.get_item(index) == 41
  524: 
  525:     def test_map_locations(self, table_type, dtype):
  526:         N = 10
  527:         table = table_type()
  528:         keys = np.full(N, np.nan, dtype=dtype)
  529:         table.map_locations(keys)
  530:         assert len(table) == 1
  531:         assert table.get_item(np.nan) == N - 1
  532: 
  533:     def test_unique(self, table_type, dtype):
  534:         N = 1020
  535:         table = table_type()
  536:         keys = np.full(N, np.nan, dtype=dtype)
  537:         unique = table.unique(keys)
  538:         assert np.all(np.isnan(unique)) and len(unique) == 1
  539: 
  540: 
  541: def test_unique_for_nan_objects_floats():
  542:     table = ht.PyObjectHashTable()
  543:     keys = np.array([float("nan") for i in range(50)], dtype=np.object_)
  544:     unique = table.unique(keys)
  545:     assert len(unique) == 1
  546: 
  547: 
  548: def test_unique_for_nan_objects_complex():
  549:     table = ht.PyObjectHashTable()
  550:     keys = np.array([complex(float("nan"), 1.0) for i in range(50)], dtype=np.object_)
  551:     unique = table.unique(keys)
  552:     assert len(unique) == 1
  553: 
  554: 
  555: def test_unique_for_nan_objects_tuple():
  556:     table = ht.PyObjectHashTable()
  557:     keys = np.array(
  558:         [1] + [(1.0, (float("nan"), 1.0)) for i in range(50)], dtype=np.object_
  559:     )
  560:     unique = table.unique(keys)
  561:     assert len(unique) == 2
  562: 
  563: 
  564: @pytest.mark.parametrize(
  565:     "dtype",
  566:     [
  567:         np.object_,
  568:         np.complex128,
  569:         np.int64,
  570:         np.uint64,
  571:         np.float64,
  572:         np.complex64,
  573:         np.int32,
  574:         np.uint32,
  575:         np.float32,
  576:         np.int16,
  577:         np.uint16,
  578:         np.int8,
  579:         np.uint8,
  580:         np.intp,
  581:     ],
  582: )
  583: class TestHelpFunctions:
  584:     def test_value_count(self, dtype, writable):
  585:         N = 43
  586:         expected = (np.arange(N) + N).astype(dtype)
  587:         values = np.repeat(expected, 5)
  588:         values.flags.writeable = writable
  589:         keys, counts, _ = ht.value_count(values, False)
  590:         tm.assert_numpy_array_equal(np.sort(keys), expected)
  591:         assert np.all(counts == 5)
  592: 
  593:     def test_value_count_mask(self, dtype):
  594:         if dtype == np.object_:
  595:             pytest.skip("mask not implemented for object dtype")
  596:         values = np.array([1] * 5, dtype=dtype)
  597:         mask = np.zeros((5,), dtype=np.bool_)
  598:         mask[1] = True
  599:         mask[4] = True
  600:         keys, counts, na_counter = ht.value_count(values, False, mask=mask)
  601:         assert len(keys) == 2
  602:         assert na_counter == 2
  603: 
  604:     def test_value_count_stable(self, dtype, writable):
  605:         # GH12679
  606:         values = np.array([2, 1, 5, 22, 3, -1, 8]).astype(dtype)
  607:         values.flags.writeable = writable
  608:         keys, counts, _ = ht.value_count(values, False)
  609:         tm.assert_numpy_array_equal(keys, values)
  610:         assert np.all(counts == 1)
  611: 
  612:     def test_duplicated_first(self, dtype, writable):
  613:         N = 100
  614:         values = np.repeat(np.arange(N).astype(dtype), 5)
  615:         values.flags.writeable = writable
  616:         result = ht.duplicated(values)
  617:         expected = np.ones_like(values, dtype=np.bool_)
  618:         expected[::5] = False
  619:         tm.assert_numpy_array_equal(result, expected)
  620: 
  621:     def test_ismember_yes(self, dtype, writable):
  622:         N = 127
  623:         arr = np.arange(N).astype(dtype)
  624:         values = np.arange(N).astype(dtype)
  625:         arr.flags.writeable = writable
  626:         values.flags.writeable = writable
  627:         result = ht.ismember(arr, values)
  628:         expected = np.ones_like(values, dtype=np.bool_)
  629:         tm.assert_numpy_array_equal(result, expected)
  630: 
  631:     def test_ismember_no(self, dtype):
  632:         N = 17
  633:         arr = np.arange(N).astype(dtype)
  634:         values = (np.arange(N) + N).astype(dtype)
  635:         result = ht.ismember(arr, values)
  636:         expected = np.zeros_like(values, dtype=np.bool_)
  637:         tm.assert_numpy_array_equal(result, expected)
  638: 
  639:     def test_mode(self, dtype, writable):
  640:         if dtype in (np.int8, np.uint8):
  641:             N = 53
  642:         else:
  643:             N = 11111
  644:         values = np.repeat(np.arange(N).astype(dtype), 5)
  645:         values[0] = 42
  646:         values.flags.writeable = writable
  647:         result = ht.mode(values, False)[0]
  648:         assert result == 42
  649: 
  650:     def test_mode_stable(self, dtype, writable):
  651:         values = np.array([2, 1, 5, 22, 3, -1, 8]).astype(dtype)
  652:         values.flags.writeable = writable
  653:         keys = ht.mode(values, False)[0]
  654:         tm.assert_numpy_array_equal(keys, values)
  655: 
  656: 
  657: def test_modes_with_nans():
  658:     # GH42688, nans aren't mangled
  659:     nulls = [pd.NA, np.nan, pd.NaT, None]
  660:     values = np.array([True] + nulls * 2, dtype=np.object_)
  661:     modes = ht.mode(values, False)[0]
  662:     assert modes.size == len(nulls)
  663: 
  664: 
  665: def test_unique_label_indices_intp(writable):
  666:     keys = np.array([1, 2, 2, 2, 1, 3], dtype=np.intp)
  667:     keys.flags.writeable = writable
  668:     result = ht.unique_label_indices(keys)
  669:     expected = np.array([0, 1, 5], dtype=np.intp)
  670:     tm.assert_numpy_array_equal(result, expected)
  671: 
  672: 
  673: def test_unique_label_indices():
  674:     a = np.random.default_rng(2).integers(1, 1 << 10, 1 << 15).astype(np.intp)
  675: 
  676:     left = ht.unique_label_indices(a)
  677:     right = np.unique(a, return_index=True)[1]
  678: 
  679:     tm.assert_numpy_array_equal(left, right, check_dtype=False)
  680: 
  681:     a[np.random.default_rng(2).choice(len(a), 10)] = -1
  682:     left = ht.unique_label_indices(a)
  683:     right = np.unique(a, return_index=True)[1][1:]
  684:     tm.assert_numpy_array_equal(left, right, check_dtype=False)
  685: 
  686: 
  687: @pytest.mark.parametrize(
  688:     "dtype",
  689:     [
  690:         np.float64,
  691:         np.float32,
  692:         np.complex128,
  693:         np.complex64,
  694:     ],
  695: )
  696: class TestHelpFunctionsWithNans:
  697:     def test_value_count(self, dtype):
  698:         values = np.array([np.nan, np.nan, np.nan], dtype=dtype)
  699:         keys, counts, _ = ht.value_count(values, True)
  700:         assert len(keys) == 0
  701:         keys, counts, _ = ht.value_count(values, False)
  702:         assert len(keys) == 1 and np.all(np.isnan(keys))
  703:         assert counts[0] == 3
  704: 
  705:     def test_duplicated_first(self, dtype):
  706:         values = np.array([np.nan, np.nan, np.nan], dtype=dtype)
  707:         result = ht.duplicated(values)
  708:         expected = np.array([False, True, True])
  709:         tm.assert_numpy_array_equal(result, expected)
  710: 
  711:     def test_ismember_yes(self, dtype):
  712:         arr = np.array([np.nan, np.nan, np.nan], dtype=dtype)
  713:         values = np.array([np.nan, np.nan], dtype=dtype)
  714:         result = ht.ismember(arr, values)
  715:         expected = np.array([True, True, True], dtype=np.bool_)
  716:         tm.assert_numpy_array_equal(result, expected)
  717: 
  718:     def test_ismember_no(self, dtype):
  719:         arr = np.array([np.nan, np.nan, np.nan], dtype=dtype)
  720:         values = np.array([1], dtype=dtype)
  721:         result = ht.ismember(arr, values)
  722:         expected = np.array([False, False, False], dtype=np.bool_)
  723:         tm.assert_numpy_array_equal(result, expected)
  724: 
  725:     def test_mode(self, dtype):
  726:         values = np.array([42, np.nan, np.nan, np.nan], dtype=dtype)
  727:         assert ht.mode(values, True)[0] == 42
  728:         assert np.isnan(ht.mode(values, False)[0])
  729: 
  730: 
  731: def test_ismember_tuple_with_nans():
  732:     # GH-41836
  733:     values = [("a", float("nan")), ("b", 1)]
  734:     comps = [("a", float("nan"))]
  735: 
  736:     msg = "isin with argument that is not not a Series"
  737:     with tm.assert_produces_warning(FutureWarning, match=msg):
  738:         result = isin(values, comps)
  739:     expected = np.array([True, False], dtype=np.bool_)
  740:     tm.assert_numpy_array_equal(result, expected)
  741: 
  742: 
  743: def test_float_complex_int_are_equal_as_objects():
  744:     values = ["a", 5, 5.0, 5.0 + 0j]
  745:     comps = list(range(129))
  746:     result = isin(np.array(values, dtype=object), np.asarray(comps))
  747:     expected = np.array([False, True, True, True], dtype=np.bool_)
  748:     tm.assert_numpy_array_equal(result, expected)
