    1: from collections.abc import Iterator
    2: from io import StringIO
    3: from pathlib import Path
    4: 
    5: import numpy as np
    6: import pytest
    7: 
    8: import pandas as pd
    9: from pandas import (
   10:     DataFrame,
   11:     read_json,
   12: )
   13: import pandas._testing as tm
   14: 
   15: from pandas.io.json._json import JsonReader
   16: 
   17: pytestmark = pytest.mark.filterwarnings(
   18:     "ignore:Passing a BlockManager to DataFrame:DeprecationWarning"
   19: )
   20: 
   21: 
   22: @pytest.fixture
   23: def lines_json_df():
   24:     df = DataFrame({"A": [1, 2, 3], "B": [4, 5, 6]})
   25:     return df.to_json(lines=True, orient="records")
   26: 
   27: 
   28: @pytest.fixture(params=["ujson", "pyarrow"])
   29: def engine(request):
   30:     if request.param == "pyarrow":
   31:         pytest.importorskip("pyarrow.json")
   32:     return request.param
   33: 
   34: 
   35: def test_read_jsonl():
   36:     # GH9180
   37:     result = read_json(StringIO('{"a": 1, "b": 2}\n{"b":2, "a" :1}\n'), lines=True)
   38:     expected = DataFrame([[1, 2], [1, 2]], columns=["a", "b"])
   39:     tm.assert_frame_equal(result, expected)
   40: 
   41: 
   42: def test_read_jsonl_engine_pyarrow(datapath, engine):
   43:     result = read_json(
   44:         datapath("io", "json", "data", "line_delimited.json"),
   45:         lines=True,
   46:         engine=engine,
   47:     )
   48:     expected = DataFrame({"a": [1, 3, 5], "b": [2, 4, 6]})
   49:     tm.assert_frame_equal(result, expected)
   50: 
   51: 
   52: def test_read_datetime(request, engine):
   53:     # GH33787
   54:     if engine == "pyarrow":
   55:         # GH 48893
   56:         reason = "Pyarrow only supports a file path as an input and line delimited json"
   57:         request.applymarker(pytest.mark.xfail(reason=reason, raises=ValueError))
   58: 
   59:     df = DataFrame(
   60:         [([1, 2], ["2020-03-05", "2020-04-08T09:58:49+00:00"], "hector")],
   61:         columns=["accounts", "date", "name"],
   62:     )
   63:     json_line = df.to_json(lines=True, orient="records")
   64: 
   65:     if engine == "pyarrow":
   66:         result = read_json(StringIO(json_line), engine=engine)
   67:     else:
   68:         result = read_json(StringIO(json_line), engine=engine)
   69:     expected = DataFrame(
   70:         [[1, "2020-03-05", "hector"], [2, "2020-04-08T09:58:49+00:00", "hector"]],
   71:         columns=["accounts", "date", "name"],
   72:     )
   73:     tm.assert_frame_equal(result, expected)
   74: 
   75: 
   76: def test_read_jsonl_unicode_chars():
   77:     # GH15132: non-ascii unicode characters
   78:     # \u201d == RIGHT DOUBLE QUOTATION MARK
   79: 
   80:     # simulate file handle
   81:     json = '{"a": "fooвЂќ", "b": "bar"}\n{"a": "foo", "b": "bar"}\n'
   82:     json = StringIO(json)
   83:     result = read_json(json, lines=True)
   84:     expected = DataFrame([["foo\u201d", "bar"], ["foo", "bar"]], columns=["a", "b"])
   85:     tm.assert_frame_equal(result, expected)
   86: 
   87:     # simulate string
   88:     json = '{"a": "fooвЂќ", "b": "bar"}\n{"a": "foo", "b": "bar"}\n'
   89:     result = read_json(StringIO(json), lines=True)
   90:     expected = DataFrame([["foo\u201d", "bar"], ["foo", "bar"]], columns=["a", "b"])
   91:     tm.assert_frame_equal(result, expected)
   92: 
   93: 
   94: def test_to_jsonl():
   95:     # GH9180
   96:     df = DataFrame([[1, 2], [1, 2]], columns=["a", "b"])
   97:     result = df.to_json(orient="records", lines=True)
   98:     expected = '{"a":1,"b":2}\n{"a":1,"b":2}\n'
   99:     assert result == expected
  100: 
  101:     df = DataFrame([["foo}", "bar"], ['foo"', "bar"]], columns=["a", "b"])
  102:     result = df.to_json(orient="records", lines=True)
  103:     expected = '{"a":"foo}","b":"bar"}\n{"a":"foo\\"","b":"bar"}\n'
  104:     assert result == expected
  105:     tm.assert_frame_equal(read_json(StringIO(result), lines=True), df)
  106: 
  107:     # GH15096: escaped characters in columns and data
  108:     df = DataFrame([["foo\\", "bar"], ['foo"', "bar"]], columns=["a\\", "b"])
  109:     result = df.to_json(orient="records", lines=True)
  110:     expected = '{"a\\\\":"foo\\\\","b":"bar"}\n{"a\\\\":"foo\\"","b":"bar"}\n'
  111:     assert result == expected
  112:     tm.assert_frame_equal(read_json(StringIO(result), lines=True), df)
  113: 
  114: 
  115: def test_to_jsonl_count_new_lines():
  116:     # GH36888
  117:     df = DataFrame([[1, 2], [1, 2]], columns=["a", "b"])
  118:     actual_new_lines_count = df.to_json(orient="records", lines=True).count("\n")
  119:     expected_new_lines_count = 2
  120:     assert actual_new_lines_count == expected_new_lines_count
  121: 
  122: 
  123: @pytest.mark.parametrize("chunksize", [1, 1.0])
  124: def test_readjson_chunks(request, lines_json_df, chunksize, engine):
  125:     # Basic test that read_json(chunks=True) gives the same result as
  126:     # read_json(chunks=False)
  127:     # GH17048: memory usage when lines=True
  128: 
  129:     if engine == "pyarrow":
  130:         # GH 48893
  131:         reason = (
  132:             "Pyarrow only supports a file path as an input and line delimited json"
  133:             "and doesn't support chunksize parameter."
  134:         )
  135:         request.applymarker(pytest.mark.xfail(reason=reason, raises=ValueError))
  136: 
  137:     unchunked = read_json(StringIO(lines_json_df), lines=True)
  138:     with read_json(
  139:         StringIO(lines_json_df), lines=True, chunksize=chunksize, engine=engine
  140:     ) as reader:
  141:         chunked = pd.concat(reader)
  142: 
  143:     tm.assert_frame_equal(chunked, unchunked)
  144: 
  145: 
  146: def test_readjson_chunksize_requires_lines(lines_json_df, engine):
  147:     msg = "chunksize can only be passed if lines=True"
  148:     with pytest.raises(ValueError, match=msg):
  149:         with read_json(
  150:             StringIO(lines_json_df), lines=False, chunksize=2, engine=engine
  151:         ) as _:
  152:             pass
  153: 
  154: 
  155: def test_readjson_chunks_series(request, engine):
  156:     if engine == "pyarrow":
  157:         # GH 48893
  158:         reason = (
  159:             "Pyarrow only supports a file path as an input and line delimited json"
  160:             "and doesn't support chunksize parameter."
  161:         )
  162:         request.applymarker(pytest.mark.xfail(reason=reason))
  163: 
  164:     # Test reading line-format JSON to Series with chunksize param
  165:     s = pd.Series({"A": 1, "B": 2})
  166: 
  167:     strio = StringIO(s.to_json(lines=True, orient="records"))
  168:     unchunked = read_json(strio, lines=True, typ="Series", engine=engine)
  169: 
  170:     strio = StringIO(s.to_json(lines=True, orient="records"))
  171:     with read_json(
  172:         strio, lines=True, typ="Series", chunksize=1, engine=engine
  173:     ) as reader:
  174:         chunked = pd.concat(reader)
  175: 
  176:     tm.assert_series_equal(chunked, unchunked)
  177: 
  178: 
  179: def test_readjson_each_chunk(request, lines_json_df, engine):
  180:     if engine == "pyarrow":
  181:         # GH 48893
  182:         reason = (
  183:             "Pyarrow only supports a file path as an input and line delimited json"
  184:             "and doesn't support chunksize parameter."
  185:         )
  186:         request.applymarker(pytest.mark.xfail(reason=reason, raises=ValueError))
  187: 
  188:     # Other tests check that the final result of read_json(chunksize=True)
  189:     # is correct. This checks the intermediate chunks.
  190:     with read_json(
  191:         StringIO(lines_json_df), lines=True, chunksize=2, engine=engine
  192:     ) as reader:
  193:         chunks = list(reader)
  194:     assert chunks[0].shape == (2, 2)
  195:     assert chunks[1].shape == (1, 2)
  196: 
  197: 
  198: def test_readjson_chunks_from_file(request, engine):
  199:     if engine == "pyarrow":
  200:         # GH 48893
  201:         reason = (
  202:             "Pyarrow only supports a file path as an input and line delimited json"
  203:             "and doesn't support chunksize parameter."
  204:         )
  205:         request.applymarker(pytest.mark.xfail(reason=reason, raises=ValueError))
  206: 
  207:     with tm.ensure_clean("test.json") as path:
  208:         df = DataFrame({"A": [1, 2, 3], "B": [4, 5, 6]})
  209:         df.to_json(path, lines=True, orient="records")
  210:         with read_json(path, lines=True, chunksize=1, engine=engine) as reader:
  211:             chunked = pd.concat(reader)
  212:         unchunked = read_json(path, lines=True, engine=engine)
  213:         tm.assert_frame_equal(unchunked, chunked)
  214: 
  215: 
  216: @pytest.mark.parametrize("chunksize", [None, 1])
  217: def test_readjson_chunks_closes(chunksize):
  218:     with tm.ensure_clean("test.json") as path:
  219:         df = DataFrame({"A": [1, 2, 3], "B": [4, 5, 6]})
  220:         df.to_json(path, lines=True, orient="records")
  221:         reader = JsonReader(
  222:             path,
  223:             orient=None,
  224:             typ="frame",
  225:             dtype=True,
  226:             convert_axes=True,
  227:             convert_dates=True,
  228:             keep_default_dates=True,
  229:             precise_float=False,
  230:             date_unit=None,
  231:             encoding=None,
  232:             lines=True,
  233:             chunksize=chunksize,
  234:             compression=None,
  235:             nrows=None,
  236:         )
  237:         with reader:
  238:             reader.read()
  239:         assert (
  240:             reader.handles.handle.closed
  241:         ), f"didn't close stream with chunksize = {chunksize}"
  242: 
  243: 
  244: @pytest.mark.parametrize("chunksize", [0, -1, 2.2, "foo"])
  245: def test_readjson_invalid_chunksize(lines_json_df, chunksize, engine):
  246:     msg = r"'chunksize' must be an integer >=1"
  247: 
  248:     with pytest.raises(ValueError, match=msg):
  249:         with read_json(
  250:             StringIO(lines_json_df), lines=True, chunksize=chunksize, engine=engine
  251:         ) as _:
  252:             pass
  253: 
  254: 
  255: @pytest.mark.parametrize("chunksize", [None, 1, 2])
  256: def test_readjson_chunks_multiple_empty_lines(chunksize):
  257:     j = """
  258: 
  259:     {"A":1,"B":4}
  260: 
  261: 
  262: 
  263:     {"A":2,"B":5}
  264: 
  265: 
  266: 
  267: 
  268: 
  269: 
  270: 
  271:     {"A":3,"B":6}
  272:     """
  273:     orig = DataFrame({"A": [1, 2, 3], "B": [4, 5, 6]})
  274:     test = read_json(StringIO(j), lines=True, chunksize=chunksize)
  275:     if chunksize is not None:
  276:         with test:
  277:             test = pd.concat(test)
  278:     tm.assert_frame_equal(orig, test, obj=f"chunksize: {chunksize}")
  279: 
  280: 
  281: def test_readjson_unicode(request, monkeypatch, engine):
  282:     if engine == "pyarrow":
  283:         # GH 48893
  284:         reason = (
  285:             "Pyarrow only supports a file path as an input and line delimited json"
  286:             "and doesn't support chunksize parameter."
  287:         )
  288:         request.applymarker(pytest.mark.xfail(reason=reason, raises=ValueError))
  289: 
  290:     with tm.ensure_clean("test.json") as path:
  291:         monkeypatch.setattr("locale.getpreferredencoding", lambda do_setlocale: "cp949")
  292:         with open(path, "w", encoding="utf-8") as f:
  293:             f.write('{"ВЈВ©ВµГЂГ†Г–ГћГџГ©Г¶Гї":["РђР‘Р’Р“Р”Р°Р±РІРіРґк°Ђ"]}')
  294: 
  295:         result = read_json(path, engine=engine)
  296:         expected = DataFrame({"ВЈВ©ВµГЂГ†Г–ГћГџГ©Г¶Гї": ["РђР‘Р’Р“Р”Р°Р±РІРіРґк°Ђ"]})
  297:         tm.assert_frame_equal(result, expected)
  298: 
  299: 
  300: @pytest.mark.parametrize("nrows", [1, 2])
  301: def test_readjson_nrows(nrows, engine):
  302:     # GH 33916
  303:     # Test reading line-format JSON to Series with nrows param
  304:     jsonl = """{"a": 1, "b": 2}
  305:         {"a": 3, "b": 4}
  306:         {"a": 5, "b": 6}
  307:         {"a": 7, "b": 8}"""
  308:     result = read_json(StringIO(jsonl), lines=True, nrows=nrows)
  309:     expected = DataFrame({"a": [1, 3, 5, 7], "b": [2, 4, 6, 8]}).iloc[:nrows]
  310:     tm.assert_frame_equal(result, expected)
  311: 
  312: 
  313: @pytest.mark.parametrize("nrows,chunksize", [(2, 2), (4, 2)])
  314: def test_readjson_nrows_chunks(request, nrows, chunksize, engine):
  315:     # GH 33916
  316:     # Test reading line-format JSON to Series with nrows and chunksize param
  317:     if engine == "pyarrow":
  318:         # GH 48893
  319:         reason = (
  320:             "Pyarrow only supports a file path as an input and line delimited json"
  321:             "and doesn't support chunksize parameter."
  322:         )
  323:         request.applymarker(pytest.mark.xfail(reason=reason, raises=ValueError))
  324: 
  325:     jsonl = """{"a": 1, "b": 2}
  326:         {"a": 3, "b": 4}
  327:         {"a": 5, "b": 6}
  328:         {"a": 7, "b": 8}"""
  329: 
  330:     if engine != "pyarrow":
  331:         with read_json(
  332:             StringIO(jsonl), lines=True, nrows=nrows, chunksize=chunksize, engine=engine
  333:         ) as reader:
  334:             chunked = pd.concat(reader)
  335:     else:
  336:         with read_json(
  337:             jsonl, lines=True, nrows=nrows, chunksize=chunksize, engine=engine
  338:         ) as reader:
  339:             chunked = pd.concat(reader)
  340:     expected = DataFrame({"a": [1, 3, 5, 7], "b": [2, 4, 6, 8]}).iloc[:nrows]
  341:     tm.assert_frame_equal(chunked, expected)
  342: 
  343: 
  344: def test_readjson_nrows_requires_lines(engine):
  345:     # GH 33916
  346:     # Test ValueError raised if nrows is set without setting lines in read_json
  347:     jsonl = """{"a": 1, "b": 2}
  348:         {"a": 3, "b": 4}
  349:         {"a": 5, "b": 6}
  350:         {"a": 7, "b": 8}"""
  351:     msg = "nrows can only be passed if lines=True"
  352:     with pytest.raises(ValueError, match=msg):
  353:         read_json(jsonl, lines=False, nrows=2, engine=engine)
  354: 
  355: 
  356: def test_readjson_lines_chunks_fileurl(request, datapath, engine):
  357:     # GH 27135
  358:     # Test reading line-format JSON from file url
  359:     if engine == "pyarrow":
  360:         # GH 48893
  361:         reason = (
  362:             "Pyarrow only supports a file path as an input and line delimited json"
  363:             "and doesn't support chunksize parameter."
  364:         )
  365:         request.applymarker(pytest.mark.xfail(reason=reason, raises=ValueError))
  366: 
  367:     df_list_expected = [
  368:         DataFrame([[1, 2]], columns=["a", "b"], index=[0]),
  369:         DataFrame([[3, 4]], columns=["a", "b"], index=[1]),
  370:         DataFrame([[5, 6]], columns=["a", "b"], index=[2]),
  371:     ]
  372:     os_path = datapath("io", "json", "data", "line_delimited.json")
  373:     file_url = Path(os_path).as_uri()
  374:     with read_json(file_url, lines=True, chunksize=1, engine=engine) as url_reader:
  375:         for index, chuck in enumerate(url_reader):
  376:             tm.assert_frame_equal(chuck, df_list_expected[index])
  377: 
  378: 
  379: def test_chunksize_is_incremental():
  380:     # See https://github.com/pandas-dev/pandas/issues/34548
  381:     jsonl = (
  382:         """{"a": 1, "b": 2}
  383:         {"a": 3, "b": 4}
  384:         {"a": 5, "b": 6}
  385:         {"a": 7, "b": 8}\n"""
  386:         * 1000
  387:     )
  388: 
  389:     class MyReader:
  390:         def __init__(self, contents) -> None:
  391:             self.read_count = 0
  392:             self.stringio = StringIO(contents)
  393: 
  394:         def read(self, *args):
  395:             self.read_count += 1
  396:             return self.stringio.read(*args)
  397: 
  398:         def __iter__(self) -> Iterator:
  399:             self.read_count += 1
  400:             return iter(self.stringio)
  401: 
  402:     reader = MyReader(jsonl)
  403:     assert len(list(read_json(reader, lines=True, chunksize=100))) > 1
  404:     assert reader.read_count > 10
  405: 
  406: 
  407: @pytest.mark.parametrize("orient_", ["split", "index", "table"])
  408: def test_to_json_append_orient(orient_):
  409:     # GH 35849
  410:     # Test ValueError when orient is not 'records'
  411:     df = DataFrame({"col1": [1, 2], "col2": ["a", "b"]})
  412:     msg = (
  413:         r"mode='a' \(append\) is only supported when "
  414:         "lines is True and orient is 'records'"
  415:     )
  416:     with pytest.raises(ValueError, match=msg):
  417:         df.to_json(mode="a", orient=orient_)
  418: 
  419: 
  420: def test_to_json_append_lines():
  421:     # GH 35849
  422:     # Test ValueError when lines is not True
  423:     df = DataFrame({"col1": [1, 2], "col2": ["a", "b"]})
  424:     msg = (
  425:         r"mode='a' \(append\) is only supported when "
  426:         "lines is True and orient is 'records'"
  427:     )
  428:     with pytest.raises(ValueError, match=msg):
  429:         df.to_json(mode="a", lines=False, orient="records")
  430: 
  431: 
  432: @pytest.mark.parametrize("mode_", ["r", "x"])
  433: def test_to_json_append_mode(mode_):
  434:     # GH 35849
  435:     # Test ValueError when mode is not supported option
  436:     df = DataFrame({"col1": [1, 2], "col2": ["a", "b"]})
  437:     msg = (
  438:         f"mode={mode_} is not a valid option."
  439:         "Only 'w' and 'a' are currently supported."
  440:     )
  441:     with pytest.raises(ValueError, match=msg):
  442:         df.to_json(mode=mode_, lines=False, orient="records")
  443: 
  444: 
  445: def test_to_json_append_output_consistent_columns():
  446:     # GH 35849
  447:     # Testing that resulting output reads in as expected.
  448:     # Testing same columns, new rows
  449:     df1 = DataFrame({"col1": [1, 2], "col2": ["a", "b"]})
  450:     df2 = DataFrame({"col1": [3, 4], "col2": ["c", "d"]})
  451: 
  452:     expected = DataFrame({"col1": [1, 2, 3, 4], "col2": ["a", "b", "c", "d"]})
  453:     with tm.ensure_clean("test.json") as path:
  454:         # Save dataframes to the same file
  455:         df1.to_json(path, lines=True, orient="records")
  456:         df2.to_json(path, mode="a", lines=True, orient="records")
  457: 
  458:         # Read path file
  459:         result = read_json(path, lines=True)
  460:         tm.assert_frame_equal(result, expected)
  461: 
  462: 
  463: def test_to_json_append_output_inconsistent_columns():
  464:     # GH 35849
  465:     # Testing that resulting output reads in as expected.
  466:     # Testing one new column, one old column, new rows
  467:     df1 = DataFrame({"col1": [1, 2], "col2": ["a", "b"]})
  468:     df3 = DataFrame({"col2": ["e", "f"], "col3": ["!", "#"]})
  469: 
  470:     expected = DataFrame(
  471:         {
  472:             "col1": [1, 2, None, None],
  473:             "col2": ["a", "b", "e", "f"],
  474:             "col3": [np.nan, np.nan, "!", "#"],
  475:         }
  476:     )
  477:     with tm.ensure_clean("test.json") as path:
  478:         # Save dataframes to the same file
  479:         df1.to_json(path, mode="a", lines=True, orient="records")
  480:         df3.to_json(path, mode="a", lines=True, orient="records")
  481: 
  482:         # Read path file
  483:         result = read_json(path, lines=True)
  484:         tm.assert_frame_equal(result, expected)
  485: 
  486: 
  487: def test_to_json_append_output_different_columns():
  488:     # GH 35849
  489:     # Testing that resulting output reads in as expected.
  490:     # Testing same, differing and new columns
  491:     df1 = DataFrame({"col1": [1, 2], "col2": ["a", "b"]})
  492:     df2 = DataFrame({"col1": [3, 4], "col2": ["c", "d"]})
  493:     df3 = DataFrame({"col2": ["e", "f"], "col3": ["!", "#"]})
  494:     df4 = DataFrame({"col4": [True, False]})
  495: 
  496:     expected = DataFrame(
  497:         {
  498:             "col1": [1, 2, 3, 4, None, None, None, None],
  499:             "col2": ["a", "b", "c", "d", "e", "f", np.nan, np.nan],
  500:             "col3": [np.nan, np.nan, np.nan, np.nan, "!", "#", np.nan, np.nan],
  501:             "col4": [None, None, None, None, None, None, True, False],
  502:         }
  503:     ).astype({"col4": "float"})
  504:     with tm.ensure_clean("test.json") as path:
  505:         # Save dataframes to the same file
  506:         df1.to_json(path, mode="a", lines=True, orient="records")
  507:         df2.to_json(path, mode="a", lines=True, orient="records")
  508:         df3.to_json(path, mode="a", lines=True, orient="records")
  509:         df4.to_json(path, mode="a", lines=True, orient="records")
  510: 
  511:         # Read path file
  512:         result = read_json(path, lines=True)
  513:         tm.assert_frame_equal(result, expected)
  514: 
  515: 
  516: def test_to_json_append_output_different_columns_reordered():
  517:     # GH 35849
  518:     # Testing that resulting output reads in as expected.
  519:     # Testing specific result column order.
  520:     df1 = DataFrame({"col1": [1, 2], "col2": ["a", "b"]})
  521:     df2 = DataFrame({"col1": [3, 4], "col2": ["c", "d"]})
  522:     df3 = DataFrame({"col2": ["e", "f"], "col3": ["!", "#"]})
  523:     df4 = DataFrame({"col4": [True, False]})
  524: 
  525:     # df4, df3, df2, df1 (in that order)
  526:     expected = DataFrame(
  527:         {
  528:             "col4": [True, False, None, None, None, None, None, None],
  529:             "col2": [np.nan, np.nan, "e", "f", "c", "d", "a", "b"],
  530:             "col3": [np.nan, np.nan, "!", "#", np.nan, np.nan, np.nan, np.nan],
  531:             "col1": [None, None, None, None, 3, 4, 1, 2],
  532:         }
  533:     ).astype({"col4": "float"})
  534:     with tm.ensure_clean("test.json") as path:
  535:         # Save dataframes to the same file
  536:         df4.to_json(path, mode="a", lines=True, orient="records")
  537:         df3.to_json(path, mode="a", lines=True, orient="records")
  538:         df2.to_json(path, mode="a", lines=True, orient="records")
  539:         df1.to_json(path, mode="a", lines=True, orient="records")
  540: 
  541:         # Read path file
  542:         result = read_json(path, lines=True)
  543:         tm.assert_frame_equal(result, expected)
