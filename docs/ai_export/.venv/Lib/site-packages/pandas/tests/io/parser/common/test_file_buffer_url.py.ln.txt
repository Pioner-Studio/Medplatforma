    1: """
    2: Tests that work on both the Python and C engines but do not have a
    3: specific classification into the other test modules.
    4: """
    5: from io import (
    6:     BytesIO,
    7:     StringIO,
    8: )
    9: import os
   10: import platform
   11: from urllib.error import URLError
   12: import uuid
   13: 
   14: import numpy as np
   15: import pytest
   16: 
   17: from pandas.errors import (
   18:     EmptyDataError,
   19:     ParserError,
   20: )
   21: import pandas.util._test_decorators as td
   22: 
   23: from pandas import (
   24:     DataFrame,
   25:     Index,
   26: )
   27: import pandas._testing as tm
   28: 
   29: pytestmark = pytest.mark.filterwarnings(
   30:     "ignore:Passing a BlockManager to DataFrame:DeprecationWarning"
   31: )
   32: 
   33: xfail_pyarrow = pytest.mark.usefixtures("pyarrow_xfail")
   34: skip_pyarrow = pytest.mark.usefixtures("pyarrow_skip")
   35: 
   36: 
   37: @pytest.mark.network
   38: @pytest.mark.single_cpu
   39: def test_url(all_parsers, csv_dir_path, httpserver):
   40:     parser = all_parsers
   41:     kwargs = {"sep": "\t"}
   42: 
   43:     local_path = os.path.join(csv_dir_path, "salaries.csv")
   44:     with open(local_path, encoding="utf-8") as f:
   45:         httpserver.serve_content(content=f.read())
   46: 
   47:     url_result = parser.read_csv(httpserver.url, **kwargs)
   48: 
   49:     local_result = parser.read_csv(local_path, **kwargs)
   50:     tm.assert_frame_equal(url_result, local_result)
   51: 
   52: 
   53: @pytest.mark.slow
   54: def test_local_file(all_parsers, csv_dir_path):
   55:     parser = all_parsers
   56:     kwargs = {"sep": "\t"}
   57: 
   58:     local_path = os.path.join(csv_dir_path, "salaries.csv")
   59:     local_result = parser.read_csv(local_path, **kwargs)
   60:     url = "file://localhost/" + local_path
   61: 
   62:     try:
   63:         url_result = parser.read_csv(url, **kwargs)
   64:         tm.assert_frame_equal(url_result, local_result)
   65:     except URLError:
   66:         # Fails on some systems.
   67:         pytest.skip("Failing on: " + " ".join(platform.uname()))
   68: 
   69: 
   70: @xfail_pyarrow  # AssertionError: DataFrame.index are different
   71: def test_path_path_lib(all_parsers):
   72:     parser = all_parsers
   73:     df = DataFrame(
   74:         1.1 * np.arange(120).reshape((30, 4)),
   75:         columns=Index(list("ABCD"), dtype=object),
   76:         index=Index([f"i-{i}" for i in range(30)], dtype=object),
   77:     )
   78:     result = tm.round_trip_pathlib(df.to_csv, lambda p: parser.read_csv(p, index_col=0))
   79:     tm.assert_frame_equal(df, result)
   80: 
   81: 
   82: @xfail_pyarrow  # AssertionError: DataFrame.index are different
   83: def test_path_local_path(all_parsers):
   84:     parser = all_parsers
   85:     df = DataFrame(
   86:         1.1 * np.arange(120).reshape((30, 4)),
   87:         columns=Index(list("ABCD"), dtype=object),
   88:         index=Index([f"i-{i}" for i in range(30)], dtype=object),
   89:     )
   90:     result = tm.round_trip_localpath(
   91:         df.to_csv, lambda p: parser.read_csv(p, index_col=0)
   92:     )
   93:     tm.assert_frame_equal(df, result)
   94: 
   95: 
   96: def test_nonexistent_path(all_parsers):
   97:     # gh-2428: pls no segfault
   98:     # gh-14086: raise more helpful FileNotFoundError
   99:     # GH#29233 "File foo" instead of "File b'foo'"
  100:     parser = all_parsers
  101:     path = f"{uuid.uuid4()}.csv"
  102: 
  103:     msg = r"\[Errno 2\]"
  104:     with pytest.raises(FileNotFoundError, match=msg) as e:
  105:         parser.read_csv(path)
  106:     assert path == e.value.filename
  107: 
  108: 
  109: @td.skip_if_windows  # os.chmod does not work in windows
  110: def test_no_permission(all_parsers):
  111:     # GH 23784
  112:     parser = all_parsers
  113: 
  114:     msg = r"\[Errno 13\]"
  115:     with tm.ensure_clean() as path:
  116:         os.chmod(path, 0)  # make file unreadable
  117: 
  118:         # verify that this process cannot open the file (not running as sudo)
  119:         try:
  120:             with open(path, encoding="utf-8"):
  121:                 pass
  122:             pytest.skip("Running as sudo.")
  123:         except PermissionError:
  124:             pass
  125: 
  126:         with pytest.raises(PermissionError, match=msg) as e:
  127:             parser.read_csv(path)
  128:         assert path == e.value.filename
  129: 
  130: 
  131: @pytest.mark.parametrize(
  132:     "data,kwargs,expected,msg",
  133:     [
  134:         # gh-10728: WHITESPACE_LINE
  135:         (
  136:             "a,b,c\n4,5,6\n ",
  137:             {},
  138:             DataFrame([[4, 5, 6]], columns=["a", "b", "c"]),
  139:             None,
  140:         ),
  141:         # gh-10548: EAT_LINE_COMMENT
  142:         (
  143:             "a,b,c\n4,5,6\n#comment",
  144:             {"comment": "#"},
  145:             DataFrame([[4, 5, 6]], columns=["a", "b", "c"]),
  146:             None,
  147:         ),
  148:         # EAT_CRNL_NOP
  149:         (
  150:             "a,b,c\n4,5,6\n\r",
  151:             {},
  152:             DataFrame([[4, 5, 6]], columns=["a", "b", "c"]),
  153:             None,
  154:         ),
  155:         # EAT_COMMENT
  156:         (
  157:             "a,b,c\n4,5,6#comment",
  158:             {"comment": "#"},
  159:             DataFrame([[4, 5, 6]], columns=["a", "b", "c"]),
  160:             None,
  161:         ),
  162:         # SKIP_LINE
  163:         (
  164:             "a,b,c\n4,5,6\nskipme",
  165:             {"skiprows": [2]},
  166:             DataFrame([[4, 5, 6]], columns=["a", "b", "c"]),
  167:             None,
  168:         ),
  169:         # EAT_LINE_COMMENT
  170:         (
  171:             "a,b,c\n4,5,6\n#comment",
  172:             {"comment": "#", "skip_blank_lines": False},
  173:             DataFrame([[4, 5, 6]], columns=["a", "b", "c"]),
  174:             None,
  175:         ),
  176:         # IN_FIELD
  177:         (
  178:             "a,b,c\n4,5,6\n ",
  179:             {"skip_blank_lines": False},
  180:             DataFrame([["4", 5, 6], [" ", None, None]], columns=["a", "b", "c"]),
  181:             None,
  182:         ),
  183:         # EAT_CRNL
  184:         (
  185:             "a,b,c\n4,5,6\n\r",
  186:             {"skip_blank_lines": False},
  187:             DataFrame([[4, 5, 6], [None, None, None]], columns=["a", "b", "c"]),
  188:             None,
  189:         ),
  190:         # ESCAPED_CHAR
  191:         (
  192:             "a,b,c\n4,5,6\n\\",
  193:             {"escapechar": "\\"},
  194:             None,
  195:             "(EOF following escape character)|(unexpected end of data)",
  196:         ),
  197:         # ESCAPE_IN_QUOTED_FIELD
  198:         (
  199:             'a,b,c\n4,5,6\n"\\',
  200:             {"escapechar": "\\"},
  201:             None,
  202:             "(EOF inside string starting at row 2)|(unexpected end of data)",
  203:         ),
  204:         # IN_QUOTED_FIELD
  205:         (
  206:             'a,b,c\n4,5,6\n"',
  207:             {"escapechar": "\\"},
  208:             None,
  209:             "(EOF inside string starting at row 2)|(unexpected end of data)",
  210:         ),
  211:     ],
  212:     ids=[
  213:         "whitespace-line",
  214:         "eat-line-comment",
  215:         "eat-crnl-nop",
  216:         "eat-comment",
  217:         "skip-line",
  218:         "eat-line-comment",
  219:         "in-field",
  220:         "eat-crnl",
  221:         "escaped-char",
  222:         "escape-in-quoted-field",
  223:         "in-quoted-field",
  224:     ],
  225: )
  226: def test_eof_states(all_parsers, data, kwargs, expected, msg, request):
  227:     # see gh-10728, gh-10548
  228:     parser = all_parsers
  229: 
  230:     if parser.engine == "pyarrow" and "comment" in kwargs:
  231:         msg = "The 'comment' option is not supported with the 'pyarrow' engine"
  232:         with pytest.raises(ValueError, match=msg):
  233:             parser.read_csv(StringIO(data), **kwargs)
  234:         return
  235: 
  236:     if parser.engine == "pyarrow" and "\r" not in data:
  237:         # pandas.errors.ParserError: CSV parse error: Expected 3 columns, got 1:
  238:         # ValueError: skiprows argument must be an integer when using engine='pyarrow'
  239:         # AssertionError: Regex pattern did not match.
  240:         pytest.skip(reason="https://github.com/apache/arrow/issues/38676")
  241: 
  242:     if expected is None:
  243:         with pytest.raises(ParserError, match=msg):
  244:             parser.read_csv(StringIO(data), **kwargs)
  245:     else:
  246:         result = parser.read_csv(StringIO(data), **kwargs)
  247:         tm.assert_frame_equal(result, expected)
  248: 
  249: 
  250: def test_temporary_file(all_parsers):
  251:     # see gh-13398
  252:     parser = all_parsers
  253:     data = "0 0"
  254: 
  255:     with tm.ensure_clean(mode="w+", return_filelike=True) as new_file:
  256:         new_file.write(data)
  257:         new_file.flush()
  258:         new_file.seek(0)
  259: 
  260:         if parser.engine == "pyarrow":
  261:             msg = "the 'pyarrow' engine does not support regex separators"
  262:             with pytest.raises(ValueError, match=msg):
  263:                 parser.read_csv(new_file, sep=r"\s+", header=None)
  264:             return
  265: 
  266:         result = parser.read_csv(new_file, sep=r"\s+", header=None)
  267: 
  268:         expected = DataFrame([[0, 0]])
  269:         tm.assert_frame_equal(result, expected)
  270: 
  271: 
  272: def test_internal_eof_byte(all_parsers):
  273:     # see gh-5500
  274:     parser = all_parsers
  275:     data = "a,b\n1\x1a,2"
  276: 
  277:     expected = DataFrame([["1\x1a", 2]], columns=["a", "b"])
  278:     result = parser.read_csv(StringIO(data))
  279:     tm.assert_frame_equal(result, expected)
  280: 
  281: 
  282: def test_internal_eof_byte_to_file(all_parsers):
  283:     # see gh-16559
  284:     parser = all_parsers
  285:     data = b'c1,c2\r\n"test \x1a    test", test\r\n'
  286:     expected = DataFrame([["test \x1a    test", " test"]], columns=["c1", "c2"])
  287:     path = f"__{uuid.uuid4()}__.csv"
  288: 
  289:     with tm.ensure_clean(path) as path:
  290:         with open(path, "wb") as f:
  291:             f.write(data)
  292: 
  293:         result = parser.read_csv(path)
  294:         tm.assert_frame_equal(result, expected)
  295: 
  296: 
  297: def test_file_handle_string_io(all_parsers):
  298:     # gh-14418
  299:     #
  300:     # Don't close user provided file handles.
  301:     parser = all_parsers
  302:     data = "a,b\n1,2"
  303: 
  304:     fh = StringIO(data)
  305:     parser.read_csv(fh)
  306:     assert not fh.closed
  307: 
  308: 
  309: def test_file_handles_with_open(all_parsers, csv1):
  310:     # gh-14418
  311:     #
  312:     # Don't close user provided file handles.
  313:     parser = all_parsers
  314: 
  315:     for mode in ["r", "rb"]:
  316:         with open(csv1, mode, encoding="utf-8" if mode == "r" else None) as f:
  317:             parser.read_csv(f)
  318:             assert not f.closed
  319: 
  320: 
  321: def test_invalid_file_buffer_class(all_parsers):
  322:     # see gh-15337
  323:     class InvalidBuffer:
  324:         pass
  325: 
  326:     parser = all_parsers
  327:     msg = "Invalid file path or buffer object type"
  328: 
  329:     with pytest.raises(ValueError, match=msg):
  330:         parser.read_csv(InvalidBuffer())
  331: 
  332: 
  333: def test_invalid_file_buffer_mock(all_parsers):
  334:     # see gh-15337
  335:     parser = all_parsers
  336:     msg = "Invalid file path or buffer object type"
  337: 
  338:     class Foo:
  339:         pass
  340: 
  341:     with pytest.raises(ValueError, match=msg):
  342:         parser.read_csv(Foo())
  343: 
  344: 
  345: def test_valid_file_buffer_seems_invalid(all_parsers):
  346:     # gh-16135: we want to ensure that "tell" and "seek"
  347:     # aren't actually being used when we call `read_csv`
  348:     #
  349:     # Thus, while the object may look "invalid" (these
  350:     # methods are attributes of the `StringIO` class),
  351:     # it is still a valid file-object for our purposes.
  352:     class NoSeekTellBuffer(StringIO):
  353:         def tell(self):
  354:             raise AttributeError("No tell method")
  355: 
  356:         def seek(self, pos, whence=0):
  357:             raise AttributeError("No seek method")
  358: 
  359:     data = "a\n1"
  360:     parser = all_parsers
  361:     expected = DataFrame({"a": [1]})
  362: 
  363:     result = parser.read_csv(NoSeekTellBuffer(data))
  364:     tm.assert_frame_equal(result, expected)
  365: 
  366: 
  367: @pytest.mark.parametrize("io_class", [StringIO, BytesIO])
  368: @pytest.mark.parametrize("encoding", [None, "utf-8"])
  369: def test_read_csv_file_handle(all_parsers, io_class, encoding):
  370:     """
  371:     Test whether read_csv does not close user-provided file handles.
  372: 
  373:     GH 36980
  374:     """
  375:     parser = all_parsers
  376:     expected = DataFrame({"a": [1], "b": [2]})
  377: 
  378:     content = "a,b\n1,2"
  379:     handle = io_class(content.encode("utf-8") if io_class == BytesIO else content)
  380: 
  381:     tm.assert_frame_equal(parser.read_csv(handle, encoding=encoding), expected)
  382:     assert not handle.closed
  383: 
  384: 
  385: def test_memory_map_compression(all_parsers, compression):
  386:     """
  387:     Support memory map for compressed files.
  388: 
  389:     GH 37621
  390:     """
  391:     parser = all_parsers
  392:     expected = DataFrame({"a": [1], "b": [2]})
  393: 
  394:     with tm.ensure_clean() as path:
  395:         expected.to_csv(path, index=False, compression=compression)
  396: 
  397:         if parser.engine == "pyarrow":
  398:             msg = "The 'memory_map' option is not supported with the 'pyarrow' engine"
  399:             with pytest.raises(ValueError, match=msg):
  400:                 parser.read_csv(path, memory_map=True, compression=compression)
  401:             return
  402: 
  403:         result = parser.read_csv(path, memory_map=True, compression=compression)
  404: 
  405:     tm.assert_frame_equal(
  406:         result,
  407:         expected,
  408:     )
  409: 
  410: 
  411: def test_context_manager(all_parsers, datapath):
  412:     # make sure that opened files are closed
  413:     parser = all_parsers
  414: 
  415:     path = datapath("io", "data", "csv", "iris.csv")
  416: 
  417:     if parser.engine == "pyarrow":
  418:         msg = "The 'chunksize' option is not supported with the 'pyarrow' engine"
  419:         with pytest.raises(ValueError, match=msg):
  420:             parser.read_csv(path, chunksize=1)
  421:         return
  422: 
  423:     reader = parser.read_csv(path, chunksize=1)
  424:     assert not reader.handles.handle.closed
  425:     try:
  426:         with reader:
  427:             next(reader)
  428:             assert False
  429:     except AssertionError:
  430:         assert reader.handles.handle.closed
  431: 
  432: 
  433: def test_context_manageri_user_provided(all_parsers, datapath):
  434:     # make sure that user-provided handles are not closed
  435:     parser = all_parsers
  436: 
  437:     with open(datapath("io", "data", "csv", "iris.csv"), encoding="utf-8") as path:
  438:         if parser.engine == "pyarrow":
  439:             msg = "The 'chunksize' option is not supported with the 'pyarrow' engine"
  440:             with pytest.raises(ValueError, match=msg):
  441:                 parser.read_csv(path, chunksize=1)
  442:             return
  443: 
  444:         reader = parser.read_csv(path, chunksize=1)
  445:         assert not reader.handles.handle.closed
  446:         try:
  447:             with reader:
  448:                 next(reader)
  449:                 assert False
  450:         except AssertionError:
  451:             assert not reader.handles.handle.closed
  452: 
  453: 
  454: @skip_pyarrow  # ParserError: Empty CSV file
  455: def test_file_descriptor_leak(all_parsers, using_copy_on_write):
  456:     # GH 31488
  457:     parser = all_parsers
  458:     with tm.ensure_clean() as path:
  459:         with pytest.raises(EmptyDataError, match="No columns to parse from file"):
  460:             parser.read_csv(path)
  461: 
  462: 
  463: def test_memory_map(all_parsers, csv_dir_path):
  464:     mmap_file = os.path.join(csv_dir_path, "test_mmap.csv")
  465:     parser = all_parsers
  466: 
  467:     expected = DataFrame(
  468:         {"a": [1, 2, 3], "b": ["one", "two", "three"], "c": ["I", "II", "III"]}
  469:     )
  470: 
  471:     if parser.engine == "pyarrow":
  472:         msg = "The 'memory_map' option is not supported with the 'pyarrow' engine"
  473:         with pytest.raises(ValueError, match=msg):
  474:             parser.read_csv(mmap_file, memory_map=True)
  475:         return
  476: 
  477:     result = parser.read_csv(mmap_file, memory_map=True)
  478:     tm.assert_frame_equal(result, expected)
