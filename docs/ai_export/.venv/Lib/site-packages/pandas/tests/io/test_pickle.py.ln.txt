    1: """
    2: manage legacy pickle tests
    3: 
    4: How to add pickle tests:
    5: 
    6: 1. Install pandas version intended to output the pickle.
    7: 
    8: 2. Execute "generate_legacy_storage_files.py" to create the pickle.
    9: $ python generate_legacy_storage_files.py <output_dir> pickle
   10: 
   11: 3. Move the created pickle to "data/legacy_pickle/<version>" directory.
   12: """
   13: from __future__ import annotations
   14: 
   15: from array import array
   16: import bz2
   17: import datetime
   18: import functools
   19: from functools import partial
   20: import gzip
   21: import io
   22: import os
   23: from pathlib import Path
   24: import pickle
   25: import shutil
   26: import tarfile
   27: from typing import Any
   28: import uuid
   29: import zipfile
   30: 
   31: import numpy as np
   32: import pytest
   33: 
   34: from pandas.compat import (
   35:     get_lzma_file,
   36:     is_platform_little_endian,
   37: )
   38: from pandas.compat._optional import import_optional_dependency
   39: from pandas.compat.compressors import flatten_buffer
   40: import pandas.util._test_decorators as td
   41: 
   42: import pandas as pd
   43: from pandas import (
   44:     DataFrame,
   45:     Index,
   46:     Series,
   47:     period_range,
   48: )
   49: import pandas._testing as tm
   50: from pandas.tests.io.generate_legacy_storage_files import create_pickle_data
   51: 
   52: import pandas.io.common as icom
   53: from pandas.tseries.offsets import (
   54:     Day,
   55:     MonthEnd,
   56: )
   57: 
   58: 
   59: # ---------------------
   60: # comparison functions
   61: # ---------------------
   62: def compare_element(result, expected, typ):
   63:     if isinstance(expected, Index):
   64:         tm.assert_index_equal(expected, result)
   65:         return
   66: 
   67:     if typ.startswith("sp_"):
   68:         tm.assert_equal(result, expected)
   69:     elif typ == "timestamp":
   70:         if expected is pd.NaT:
   71:             assert result is pd.NaT
   72:         else:
   73:             assert result == expected
   74:     else:
   75:         comparator = getattr(tm, f"assert_{typ}_equal", tm.assert_almost_equal)
   76:         comparator(result, expected)
   77: 
   78: 
   79: # ---------------------
   80: # tests
   81: # ---------------------
   82: 
   83: 
   84: @pytest.mark.parametrize(
   85:     "data",
   86:     [
   87:         b"123",
   88:         b"123456",
   89:         bytearray(b"123"),
   90:         memoryview(b"123"),
   91:         pickle.PickleBuffer(b"123"),
   92:         array("I", [1, 2, 3]),
   93:         memoryview(b"123456").cast("B", (3, 2)),
   94:         memoryview(b"123456").cast("B", (3, 2))[::2],
   95:         np.arange(12).reshape((3, 4), order="C"),
   96:         np.arange(12).reshape((3, 4), order="F"),
   97:         np.arange(12).reshape((3, 4), order="C")[:, ::2],
   98:     ],
   99: )
  100: def test_flatten_buffer(data):
  101:     result = flatten_buffer(data)
  102:     expected = memoryview(data).tobytes("A")
  103:     assert result == expected
  104:     if isinstance(data, (bytes, bytearray)):
  105:         assert result is data
  106:     elif isinstance(result, memoryview):
  107:         assert result.ndim == 1
  108:         assert result.format == "B"
  109:         assert result.contiguous
  110:         assert result.shape == (result.nbytes,)
  111: 
  112: 
  113: def test_pickles(datapath):
  114:     if not is_platform_little_endian():
  115:         pytest.skip("known failure on non-little endian")
  116: 
  117:     # For loop for compat with --strict-data-files
  118:     for legacy_pickle in Path(__file__).parent.glob("data/legacy_pickle/*/*.p*kl*"):
  119:         legacy_pickle = datapath(legacy_pickle)
  120: 
  121:         data = pd.read_pickle(legacy_pickle)
  122: 
  123:         for typ, dv in data.items():
  124:             for dt, result in dv.items():
  125:                 expected = data[typ][dt]
  126: 
  127:                 if typ == "series" and dt == "ts":
  128:                     # GH 7748
  129:                     tm.assert_series_equal(result, expected)
  130:                     assert result.index.freq == expected.index.freq
  131:                     assert not result.index.freq.normalize
  132:                     tm.assert_series_equal(result > 0, expected > 0)
  133: 
  134:                     # GH 9291
  135:                     freq = result.index.freq
  136:                     assert freq + Day(1) == Day(2)
  137: 
  138:                     res = freq + pd.Timedelta(hours=1)
  139:                     assert isinstance(res, pd.Timedelta)
  140:                     assert res == pd.Timedelta(days=1, hours=1)
  141: 
  142:                     res = freq + pd.Timedelta(nanoseconds=1)
  143:                     assert isinstance(res, pd.Timedelta)
  144:                     assert res == pd.Timedelta(days=1, nanoseconds=1)
  145:                 elif typ == "index" and dt == "period":
  146:                     tm.assert_index_equal(result, expected)
  147:                     assert isinstance(result.freq, MonthEnd)
  148:                     assert result.freq == MonthEnd()
  149:                     assert result.freqstr == "M"
  150:                     tm.assert_index_equal(result.shift(2), expected.shift(2))
  151:                 elif typ == "series" and dt in ("dt_tz", "cat"):
  152:                     tm.assert_series_equal(result, expected)
  153:                 elif typ == "frame" and dt in (
  154:                     "dt_mixed_tzs",
  155:                     "cat_onecol",
  156:                     "cat_and_float",
  157:                 ):
  158:                     tm.assert_frame_equal(result, expected)
  159:                 else:
  160:                     compare_element(result, expected, typ)
  161: 
  162: 
  163: def python_pickler(obj, path):
  164:     with open(path, "wb") as fh:
  165:         pickle.dump(obj, fh, protocol=-1)
  166: 
  167: 
  168: def python_unpickler(path):
  169:     with open(path, "rb") as fh:
  170:         fh.seek(0)
  171:         return pickle.load(fh)
  172: 
  173: 
  174: def flatten(data: dict) -> list[tuple[str, Any]]:
  175:     """Flatten create_pickle_data"""
  176:     return [
  177:         (typ, example)
  178:         for typ, examples in data.items()
  179:         for example in examples.values()
  180:     ]
  181: 
  182: 
  183: @pytest.mark.parametrize(
  184:     "pickle_writer",
  185:     [
  186:         pytest.param(python_pickler, id="python"),
  187:         pytest.param(pd.to_pickle, id="pandas_proto_default"),
  188:         pytest.param(
  189:             functools.partial(pd.to_pickle, protocol=pickle.HIGHEST_PROTOCOL),
  190:             id="pandas_proto_highest",
  191:         ),
  192:         pytest.param(functools.partial(pd.to_pickle, protocol=4), id="pandas_proto_4"),
  193:         pytest.param(
  194:             functools.partial(pd.to_pickle, protocol=5),
  195:             id="pandas_proto_5",
  196:         ),
  197:     ],
  198: )
  199: @pytest.mark.parametrize("writer", [pd.to_pickle, python_pickler])
  200: @pytest.mark.parametrize("typ, expected", flatten(create_pickle_data()))
  201: def test_round_trip_current(typ, expected, pickle_writer, writer):
  202:     with tm.ensure_clean() as path:
  203:         # test writing with each pickler
  204:         pickle_writer(expected, path)
  205: 
  206:         # test reading with each unpickler
  207:         result = pd.read_pickle(path)
  208:         compare_element(result, expected, typ)
  209: 
  210:         result = python_unpickler(path)
  211:         compare_element(result, expected, typ)
  212: 
  213:         # and the same for file objects (GH 35679)
  214:         with open(path, mode="wb") as handle:
  215:             writer(expected, path)
  216:             handle.seek(0)  # shouldn't close file handle
  217:         with open(path, mode="rb") as handle:
  218:             result = pd.read_pickle(handle)
  219:             handle.seek(0)  # shouldn't close file handle
  220:         compare_element(result, expected, typ)
  221: 
  222: 
  223: def test_pickle_path_pathlib():
  224:     df = DataFrame(
  225:         1.1 * np.arange(120).reshape((30, 4)),
  226:         columns=Index(list("ABCD"), dtype=object),
  227:         index=Index([f"i-{i}" for i in range(30)], dtype=object),
  228:     )
  229:     result = tm.round_trip_pathlib(df.to_pickle, pd.read_pickle)
  230:     tm.assert_frame_equal(df, result)
  231: 
  232: 
  233: def test_pickle_path_localpath():
  234:     df = DataFrame(
  235:         1.1 * np.arange(120).reshape((30, 4)),
  236:         columns=Index(list("ABCD"), dtype=object),
  237:         index=Index([f"i-{i}" for i in range(30)], dtype=object),
  238:     )
  239:     result = tm.round_trip_localpath(df.to_pickle, pd.read_pickle)
  240:     tm.assert_frame_equal(df, result)
  241: 
  242: 
  243: # ---------------------
  244: # test pickle compression
  245: # ---------------------
  246: 
  247: 
  248: @pytest.fixture
  249: def get_random_path():
  250:     return f"__{uuid.uuid4()}__.pickle"
  251: 
  252: 
  253: class TestCompression:
  254:     _extension_to_compression = icom.extension_to_compression
  255: 
  256:     def compress_file(self, src_path, dest_path, compression):
  257:         if compression is None:
  258:             shutil.copyfile(src_path, dest_path)
  259:             return
  260: 
  261:         if compression == "gzip":
  262:             f = gzip.open(dest_path, "w")
  263:         elif compression == "bz2":
  264:             f = bz2.BZ2File(dest_path, "w")
  265:         elif compression == "zip":
  266:             with zipfile.ZipFile(dest_path, "w", compression=zipfile.ZIP_DEFLATED) as f:
  267:                 f.write(src_path, os.path.basename(src_path))
  268:         elif compression == "tar":
  269:             with open(src_path, "rb") as fh:
  270:                 with tarfile.open(dest_path, mode="w") as tar:
  271:                     tarinfo = tar.gettarinfo(src_path, os.path.basename(src_path))
  272:                     tar.addfile(tarinfo, fh)
  273:         elif compression == "xz":
  274:             f = get_lzma_file()(dest_path, "w")
  275:         elif compression == "zstd":
  276:             f = import_optional_dependency("zstandard").open(dest_path, "wb")
  277:         else:
  278:             msg = f"Unrecognized compression type: {compression}"
  279:             raise ValueError(msg)
  280: 
  281:         if compression not in ["zip", "tar"]:
  282:             with open(src_path, "rb") as fh:
  283:                 with f:
  284:                     f.write(fh.read())
  285: 
  286:     def test_write_explicit(self, compression, get_random_path):
  287:         base = get_random_path
  288:         path1 = base + ".compressed"
  289:         path2 = base + ".raw"
  290: 
  291:         with tm.ensure_clean(path1) as p1, tm.ensure_clean(path2) as p2:
  292:             df = DataFrame(
  293:                 1.1 * np.arange(120).reshape((30, 4)),
  294:                 columns=Index(list("ABCD"), dtype=object),
  295:                 index=Index([f"i-{i}" for i in range(30)], dtype=object),
  296:             )
  297: 
  298:             # write to compressed file
  299:             df.to_pickle(p1, compression=compression)
  300: 
  301:             # decompress
  302:             with tm.decompress_file(p1, compression=compression) as f:
  303:                 with open(p2, "wb") as fh:
  304:                     fh.write(f.read())
  305: 
  306:             # read decompressed file
  307:             df2 = pd.read_pickle(p2, compression=None)
  308: 
  309:             tm.assert_frame_equal(df, df2)
  310: 
  311:     @pytest.mark.parametrize("compression", ["", "None", "bad", "7z"])
  312:     def test_write_explicit_bad(self, compression, get_random_path):
  313:         with pytest.raises(ValueError, match="Unrecognized compression type"):
  314:             with tm.ensure_clean(get_random_path) as path:
  315:                 df = DataFrame(
  316:                     1.1 * np.arange(120).reshape((30, 4)),
  317:                     columns=Index(list("ABCD"), dtype=object),
  318:                     index=Index([f"i-{i}" for i in range(30)], dtype=object),
  319:                 )
  320:                 df.to_pickle(path, compression=compression)
  321: 
  322:     def test_write_infer(self, compression_ext, get_random_path):
  323:         base = get_random_path
  324:         path1 = base + compression_ext
  325:         path2 = base + ".raw"
  326:         compression = self._extension_to_compression.get(compression_ext.lower())
  327: 
  328:         with tm.ensure_clean(path1) as p1, tm.ensure_clean(path2) as p2:
  329:             df = DataFrame(
  330:                 1.1 * np.arange(120).reshape((30, 4)),
  331:                 columns=Index(list("ABCD"), dtype=object),
  332:                 index=Index([f"i-{i}" for i in range(30)], dtype=object),
  333:             )
  334: 
  335:             # write to compressed file by inferred compression method
  336:             df.to_pickle(p1)
  337: 
  338:             # decompress
  339:             with tm.decompress_file(p1, compression=compression) as f:
  340:                 with open(p2, "wb") as fh:
  341:                     fh.write(f.read())
  342: 
  343:             # read decompressed file
  344:             df2 = pd.read_pickle(p2, compression=None)
  345: 
  346:             tm.assert_frame_equal(df, df2)
  347: 
  348:     def test_read_explicit(self, compression, get_random_path):
  349:         base = get_random_path
  350:         path1 = base + ".raw"
  351:         path2 = base + ".compressed"
  352: 
  353:         with tm.ensure_clean(path1) as p1, tm.ensure_clean(path2) as p2:
  354:             df = DataFrame(
  355:                 1.1 * np.arange(120).reshape((30, 4)),
  356:                 columns=Index(list("ABCD"), dtype=object),
  357:                 index=Index([f"i-{i}" for i in range(30)], dtype=object),
  358:             )
  359: 
  360:             # write to uncompressed file
  361:             df.to_pickle(p1, compression=None)
  362: 
  363:             # compress
  364:             self.compress_file(p1, p2, compression=compression)
  365: 
  366:             # read compressed file
  367:             df2 = pd.read_pickle(p2, compression=compression)
  368:             tm.assert_frame_equal(df, df2)
  369: 
  370:     def test_read_infer(self, compression_ext, get_random_path):
  371:         base = get_random_path
  372:         path1 = base + ".raw"
  373:         path2 = base + compression_ext
  374:         compression = self._extension_to_compression.get(compression_ext.lower())
  375: 
  376:         with tm.ensure_clean(path1) as p1, tm.ensure_clean(path2) as p2:
  377:             df = DataFrame(
  378:                 1.1 * np.arange(120).reshape((30, 4)),
  379:                 columns=Index(list("ABCD"), dtype=object),
  380:                 index=Index([f"i-{i}" for i in range(30)], dtype=object),
  381:             )
  382: 
  383:             # write to uncompressed file
  384:             df.to_pickle(p1, compression=None)
  385: 
  386:             # compress
  387:             self.compress_file(p1, p2, compression=compression)
  388: 
  389:             # read compressed file by inferred compression method
  390:             df2 = pd.read_pickle(p2)
  391:             tm.assert_frame_equal(df, df2)
  392: 
  393: 
  394: # ---------------------
  395: # test pickle compression
  396: # ---------------------
  397: 
  398: 
  399: class TestProtocol:
  400:     @pytest.mark.parametrize("protocol", [-1, 0, 1, 2])
  401:     def test_read(self, protocol, get_random_path):
  402:         with tm.ensure_clean(get_random_path) as path:
  403:             df = DataFrame(
  404:                 1.1 * np.arange(120).reshape((30, 4)),
  405:                 columns=Index(list("ABCD"), dtype=object),
  406:                 index=Index([f"i-{i}" for i in range(30)], dtype=object),
  407:             )
  408:             df.to_pickle(path, protocol=protocol)
  409:             df2 = pd.read_pickle(path)
  410:             tm.assert_frame_equal(df, df2)
  411: 
  412: 
  413: @pytest.mark.parametrize(
  414:     ["pickle_file", "excols"],
  415:     [
  416:         ("test_py27.pkl", Index(["a", "b", "c"])),
  417:         (
  418:             "test_mi_py27.pkl",
  419:             pd.MultiIndex.from_arrays([["a", "b", "c"], ["A", "B", "C"]]),
  420:         ),
  421:     ],
  422: )
  423: def test_unicode_decode_error(datapath, pickle_file, excols):
  424:     # pickle file written with py27, should be readable without raising
  425:     #  UnicodeDecodeError, see GH#28645 and GH#31988
  426:     path = datapath("io", "data", "pickle", pickle_file)
  427:     df = pd.read_pickle(path)
  428: 
  429:     # just test the columns are correct since the values are random
  430:     tm.assert_index_equal(df.columns, excols)
  431: 
  432: 
  433: # ---------------------
  434: # tests for buffer I/O
  435: # ---------------------
  436: 
  437: 
  438: def test_pickle_buffer_roundtrip():
  439:     with tm.ensure_clean() as path:
  440:         df = DataFrame(
  441:             1.1 * np.arange(120).reshape((30, 4)),
  442:             columns=Index(list("ABCD"), dtype=object),
  443:             index=Index([f"i-{i}" for i in range(30)], dtype=object),
  444:         )
  445:         with open(path, "wb") as fh:
  446:             df.to_pickle(fh)
  447:         with open(path, "rb") as fh:
  448:             result = pd.read_pickle(fh)
  449:         tm.assert_frame_equal(df, result)
  450: 
  451: 
  452: # ---------------------
  453: # tests for URL I/O
  454: # ---------------------
  455: 
  456: 
  457: @pytest.mark.parametrize(
  458:     "mockurl", ["http://url.com", "ftp://test.com", "http://gzip.com"]
  459: )
  460: def test_pickle_generalurl_read(monkeypatch, mockurl):
  461:     def python_pickler(obj, path):
  462:         with open(path, "wb") as fh:
  463:             pickle.dump(obj, fh, protocol=-1)
  464: 
  465:     class MockReadResponse:
  466:         def __init__(self, path) -> None:
  467:             self.file = open(path, "rb")
  468:             if "gzip" in path:
  469:                 self.headers = {"Content-Encoding": "gzip"}
  470:             else:
  471:                 self.headers = {"Content-Encoding": ""}
  472: 
  473:         def __enter__(self):
  474:             return self
  475: 
  476:         def __exit__(self, *args):
  477:             self.close()
  478: 
  479:         def read(self):
  480:             return self.file.read()
  481: 
  482:         def close(self):
  483:             return self.file.close()
  484: 
  485:     with tm.ensure_clean() as path:
  486: 
  487:         def mock_urlopen_read(*args, **kwargs):
  488:             return MockReadResponse(path)
  489: 
  490:         df = DataFrame(
  491:             1.1 * np.arange(120).reshape((30, 4)),
  492:             columns=Index(list("ABCD"), dtype=object),
  493:             index=Index([f"i-{i}" for i in range(30)], dtype=object),
  494:         )
  495:         python_pickler(df, path)
  496:         monkeypatch.setattr("urllib.request.urlopen", mock_urlopen_read)
  497:         result = pd.read_pickle(mockurl)
  498:         tm.assert_frame_equal(df, result)
  499: 
  500: 
  501: def test_pickle_fsspec_roundtrip():
  502:     pytest.importorskip("fsspec")
  503:     with tm.ensure_clean():
  504:         mockurl = "memory://mockfile"
  505:         df = DataFrame(
  506:             1.1 * np.arange(120).reshape((30, 4)),
  507:             columns=Index(list("ABCD"), dtype=object),
  508:             index=Index([f"i-{i}" for i in range(30)], dtype=object),
  509:         )
  510:         df.to_pickle(mockurl)
  511:         result = pd.read_pickle(mockurl)
  512:         tm.assert_frame_equal(df, result)
  513: 
  514: 
  515: class MyTz(datetime.tzinfo):
  516:     def __init__(self) -> None:
  517:         pass
  518: 
  519: 
  520: def test_read_pickle_with_subclass():
  521:     # GH 12163
  522:     expected = Series(dtype=object), MyTz()
  523:     result = tm.round_trip_pickle(expected)
  524: 
  525:     tm.assert_series_equal(result[0], expected[0])
  526:     assert isinstance(result[1], MyTz)
  527: 
  528: 
  529: def test_pickle_binary_object_compression(compression):
  530:     """
  531:     Read/write from binary file-objects w/wo compression.
  532: 
  533:     GH 26237, GH 29054, and GH 29570
  534:     """
  535:     df = DataFrame(
  536:         1.1 * np.arange(120).reshape((30, 4)),
  537:         columns=Index(list("ABCD"), dtype=object),
  538:         index=Index([f"i-{i}" for i in range(30)], dtype=object),
  539:     )
  540: 
  541:     # reference for compression
  542:     with tm.ensure_clean() as path:
  543:         df.to_pickle(path, compression=compression)
  544:         reference = Path(path).read_bytes()
  545: 
  546:     # write
  547:     buffer = io.BytesIO()
  548:     df.to_pickle(buffer, compression=compression)
  549:     buffer.seek(0)
  550: 
  551:     # gzip  and zip safe the filename: cannot compare the compressed content
  552:     assert buffer.getvalue() == reference or compression in ("gzip", "zip", "tar")
  553: 
  554:     # read
  555:     read_df = pd.read_pickle(buffer, compression=compression)
  556:     buffer.seek(0)
  557:     tm.assert_frame_equal(df, read_df)
  558: 
  559: 
  560: def test_pickle_dataframe_with_multilevel_index(
  561:     multiindex_year_month_day_dataframe_random_data,
  562:     multiindex_dataframe_random_data,
  563: ):
  564:     ymd = multiindex_year_month_day_dataframe_random_data
  565:     frame = multiindex_dataframe_random_data
  566: 
  567:     def _test_roundtrip(frame):
  568:         unpickled = tm.round_trip_pickle(frame)
  569:         tm.assert_frame_equal(frame, unpickled)
  570: 
  571:     _test_roundtrip(frame)
  572:     _test_roundtrip(frame.T)
  573:     _test_roundtrip(ymd)
  574:     _test_roundtrip(ymd.T)
  575: 
  576: 
  577: def test_pickle_timeseries_periodindex():
  578:     # GH#2891
  579:     prng = period_range("1/1/2011", "1/1/2012", freq="M")
  580:     ts = Series(np.random.default_rng(2).standard_normal(len(prng)), prng)
  581:     new_ts = tm.round_trip_pickle(ts)
  582:     assert new_ts.index.freqstr == "M"
  583: 
  584: 
  585: @pytest.mark.parametrize(
  586:     "name", [777, 777.0, "name", datetime.datetime(2001, 11, 11), (1, 2)]
  587: )
  588: def test_pickle_preserve_name(name):
  589:     unpickled = tm.round_trip_pickle(Series(np.arange(10, dtype=np.float64), name=name))
  590:     assert unpickled.name == name
  591: 
  592: 
  593: def test_pickle_datetimes(datetime_series):
  594:     unp_ts = tm.round_trip_pickle(datetime_series)
  595:     tm.assert_series_equal(unp_ts, datetime_series)
  596: 
  597: 
  598: def test_pickle_strings(string_series):
  599:     unp_series = tm.round_trip_pickle(string_series)
  600:     tm.assert_series_equal(unp_series, string_series)
  601: 
  602: 
  603: @td.skip_array_manager_invalid_test
  604: def test_pickle_preserves_block_ndim():
  605:     # GH#37631
  606:     ser = Series(list("abc")).astype("category").iloc[[0]]
  607:     res = tm.round_trip_pickle(ser)
  608: 
  609:     assert res._mgr.blocks[0].ndim == 1
  610:     assert res._mgr.blocks[0].shape == (1,)
  611: 
  612:     # GH#37631 OP issue was about indexing, underlying problem was pickle
  613:     tm.assert_series_equal(res[[True]], ser)
  614: 
  615: 
  616: @pytest.mark.parametrize("protocol", [pickle.DEFAULT_PROTOCOL, pickle.HIGHEST_PROTOCOL])
  617: def test_pickle_big_dataframe_compression(protocol, compression):
  618:     # GH#39002
  619:     df = DataFrame(range(100000))
  620:     result = tm.round_trip_pathlib(
  621:         partial(df.to_pickle, protocol=protocol, compression=compression),
  622:         partial(pd.read_pickle, compression=compression),
  623:     )
  624:     tm.assert_frame_equal(df, result)
  625: 
  626: 
  627: def test_pickle_frame_v124_unpickle_130(datapath):
  628:     # GH#42345 DataFrame created in 1.2.x, unpickle in 1.3.x
  629:     path = datapath(
  630:         Path(__file__).parent,
  631:         "data",
  632:         "legacy_pickle",
  633:         "1.2.4",
  634:         "empty_frame_v1_2_4-GH#42345.pkl",
  635:     )
  636:     with open(path, "rb") as fd:
  637:         df = pickle.load(fd)
  638: 
  639:     expected = DataFrame(index=[], columns=[])
  640:     tm.assert_frame_equal(df, expected)
  641: 
  642: 
  643: def test_pickle_pos_args_deprecation():
  644:     # GH-54229
  645:     df = DataFrame({"a": [1, 2, 3]})
  646:     msg = (
  647:         r"Starting with pandas version 3.0 all arguments of to_pickle except for the "
  648:         r"argument 'path' will be keyword-only."
  649:     )
  650:     with tm.assert_produces_warning(FutureWarning, match=msg):
  651:         buffer = io.BytesIO()
  652:         df.to_pickle(buffer, "infer")
