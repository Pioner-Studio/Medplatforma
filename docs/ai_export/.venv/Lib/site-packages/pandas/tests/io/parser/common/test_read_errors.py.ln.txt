    1: """
    2: Tests that work on the Python, C and PyArrow engines but do not have a
    3: specific classification into the other test modules.
    4: """
    5: import codecs
    6: import csv
    7: from io import StringIO
    8: import os
    9: from pathlib import Path
   10: 
   11: import numpy as np
   12: import pytest
   13: 
   14: from pandas.compat import PY311
   15: from pandas.errors import (
   16:     EmptyDataError,
   17:     ParserError,
   18:     ParserWarning,
   19: )
   20: 
   21: from pandas import DataFrame
   22: import pandas._testing as tm
   23: 
   24: xfail_pyarrow = pytest.mark.usefixtures("pyarrow_xfail")
   25: skip_pyarrow = pytest.mark.usefixtures("pyarrow_skip")
   26: 
   27: 
   28: def test_empty_decimal_marker(all_parsers):
   29:     data = """A|B|C
   30: 1|2,334|5
   31: 10|13|10.
   32: """
   33:     # Parsers support only length-1 decimals
   34:     msg = "Only length-1 decimal markers supported"
   35:     parser = all_parsers
   36: 
   37:     if parser.engine == "pyarrow":
   38:         msg = (
   39:             "only single character unicode strings can be "
   40:             "converted to Py_UCS4, got length 0"
   41:         )
   42: 
   43:     with pytest.raises(ValueError, match=msg):
   44:         parser.read_csv(StringIO(data), decimal="")
   45: 
   46: 
   47: def test_bad_stream_exception(all_parsers, csv_dir_path):
   48:     # see gh-13652
   49:     #
   50:     # This test validates that both the Python engine and C engine will
   51:     # raise UnicodeDecodeError instead of C engine raising ParserError
   52:     # and swallowing the exception that caused read to fail.
   53:     path = os.path.join(csv_dir_path, "sauron.SHIFT_JIS.csv")
   54:     codec = codecs.lookup("utf-8")
   55:     utf8 = codecs.lookup("utf-8")
   56:     parser = all_parsers
   57:     msg = "'utf-8' codec can't decode byte"
   58: 
   59:     # Stream must be binary UTF8.
   60:     with open(path, "rb") as handle, codecs.StreamRecoder(
   61:         handle, utf8.encode, utf8.decode, codec.streamreader, codec.streamwriter
   62:     ) as stream:
   63:         with pytest.raises(UnicodeDecodeError, match=msg):
   64:             parser.read_csv(stream)
   65: 
   66: 
   67: def test_malformed(all_parsers):
   68:     # see gh-6607
   69:     parser = all_parsers
   70:     data = """ignore
   71: A,B,C
   72: 1,2,3 # comment
   73: 1,2,3,4,5
   74: 2,3,4
   75: """
   76:     msg = "Expected 3 fields in line 4, saw 5"
   77:     err = ParserError
   78:     if parser.engine == "pyarrow":
   79:         msg = "The 'comment' option is not supported with the 'pyarrow' engine"
   80:         err = ValueError
   81:     with pytest.raises(err, match=msg):
   82:         parser.read_csv(StringIO(data), header=1, comment="#")
   83: 
   84: 
   85: @pytest.mark.parametrize("nrows", [5, 3, None])
   86: def test_malformed_chunks(all_parsers, nrows):
   87:     data = """ignore
   88: A,B,C
   89: skip
   90: 1,2,3
   91: 3,5,10 # comment
   92: 1,2,3,4,5
   93: 2,3,4
   94: """
   95:     parser = all_parsers
   96: 
   97:     if parser.engine == "pyarrow":
   98:         msg = "The 'iterator' option is not supported with the 'pyarrow' engine"
   99:         with pytest.raises(ValueError, match=msg):
  100:             parser.read_csv(
  101:                 StringIO(data),
  102:                 header=1,
  103:                 comment="#",
  104:                 iterator=True,
  105:                 chunksize=1,
  106:                 skiprows=[2],
  107:             )
  108:         return
  109: 
  110:     msg = "Expected 3 fields in line 6, saw 5"
  111:     with parser.read_csv(
  112:         StringIO(data), header=1, comment="#", iterator=True, chunksize=1, skiprows=[2]
  113:     ) as reader:
  114:         with pytest.raises(ParserError, match=msg):
  115:             reader.read(nrows)
  116: 
  117: 
  118: @xfail_pyarrow  # does not raise
  119: def test_catch_too_many_names(all_parsers):
  120:     # see gh-5156
  121:     data = """\
  122: 1,2,3
  123: 4,,6
  124: 7,8,9
  125: 10,11,12\n"""
  126:     parser = all_parsers
  127:     msg = (
  128:         "Too many columns specified: expected 4 and found 3"
  129:         if parser.engine == "c"
  130:         else "Number of passed names did not match "
  131:         "number of header fields in the file"
  132:     )
  133: 
  134:     with pytest.raises(ValueError, match=msg):
  135:         parser.read_csv(StringIO(data), header=0, names=["a", "b", "c", "d"])
  136: 
  137: 
  138: @skip_pyarrow  # CSV parse error: Empty CSV file or block
  139: @pytest.mark.parametrize("nrows", [0, 1, 2, 3, 4, 5])
  140: def test_raise_on_no_columns(all_parsers, nrows):
  141:     parser = all_parsers
  142:     data = "\n" * nrows
  143: 
  144:     msg = "No columns to parse from file"
  145:     with pytest.raises(EmptyDataError, match=msg):
  146:         parser.read_csv(StringIO(data))
  147: 
  148: 
  149: def test_unexpected_keyword_parameter_exception(all_parsers):
  150:     # GH-34976
  151:     parser = all_parsers
  152: 
  153:     msg = "{}\\(\\) got an unexpected keyword argument 'foo'"
  154:     with pytest.raises(TypeError, match=msg.format("read_csv")):
  155:         parser.read_csv("foo.csv", foo=1)
  156:     with pytest.raises(TypeError, match=msg.format("read_table")):
  157:         parser.read_table("foo.tsv", foo=1)
  158: 
  159: 
  160: def test_suppress_error_output(all_parsers):
  161:     # see gh-15925
  162:     parser = all_parsers
  163:     data = "a\n1\n1,2,3\n4\n5,6,7"
  164:     expected = DataFrame({"a": [1, 4]})
  165: 
  166:     result = parser.read_csv(StringIO(data), on_bad_lines="skip")
  167:     tm.assert_frame_equal(result, expected)
  168: 
  169: 
  170: def test_error_bad_lines(all_parsers):
  171:     # see gh-15925
  172:     parser = all_parsers
  173:     data = "a\n1\n1,2,3\n4\n5,6,7"
  174: 
  175:     msg = "Expected 1 fields in line 3, saw 3"
  176: 
  177:     if parser.engine == "pyarrow":
  178:         # "CSV parse error: Expected 1 columns, got 3: 1,2,3"
  179:         pytest.skip(reason="https://github.com/apache/arrow/issues/38676")
  180: 
  181:     with pytest.raises(ParserError, match=msg):
  182:         parser.read_csv(StringIO(data), on_bad_lines="error")
  183: 
  184: 
  185: def test_warn_bad_lines(all_parsers):
  186:     # see gh-15925
  187:     parser = all_parsers
  188:     data = "a\n1\n1,2,3\n4\n5,6,7"
  189:     expected = DataFrame({"a": [1, 4]})
  190:     match_msg = "Skipping line"
  191: 
  192:     expected_warning = ParserWarning
  193:     if parser.engine == "pyarrow":
  194:         match_msg = "Expected 1 columns, but found 3: 1,2,3"
  195:         expected_warning = (ParserWarning, DeprecationWarning)
  196: 
  197:     with tm.assert_produces_warning(
  198:         expected_warning, match=match_msg, check_stacklevel=False
  199:     ):
  200:         result = parser.read_csv(StringIO(data), on_bad_lines="warn")
  201:     tm.assert_frame_equal(result, expected)
  202: 
  203: 
  204: def test_read_csv_wrong_num_columns(all_parsers):
  205:     # Too few columns.
  206:     data = """A,B,C,D,E,F
  207: 1,2,3,4,5,6
  208: 6,7,8,9,10,11,12
  209: 11,12,13,14,15,16
  210: """
  211:     parser = all_parsers
  212:     msg = "Expected 6 fields in line 3, saw 7"
  213: 
  214:     if parser.engine == "pyarrow":
  215:         # Expected 6 columns, got 7: 6,7,8,9,10,11,12
  216:         pytest.skip(reason="https://github.com/apache/arrow/issues/38676")
  217: 
  218:     with pytest.raises(ParserError, match=msg):
  219:         parser.read_csv(StringIO(data))
  220: 
  221: 
  222: def test_null_byte_char(request, all_parsers):
  223:     # see gh-2741
  224:     data = "\x00,foo"
  225:     names = ["a", "b"]
  226:     parser = all_parsers
  227: 
  228:     if parser.engine == "c" or (parser.engine == "python" and PY311):
  229:         if parser.engine == "python" and PY311:
  230:             request.applymarker(
  231:                 pytest.mark.xfail(
  232:                     reason="In Python 3.11, this is read as an empty character not null"
  233:                 )
  234:             )
  235:         expected = DataFrame([[np.nan, "foo"]], columns=names)
  236:         out = parser.read_csv(StringIO(data), names=names)
  237:         tm.assert_frame_equal(out, expected)
  238:     else:
  239:         if parser.engine == "pyarrow":
  240:             # CSV parse error: Empty CSV file or block: "
  241:             # cannot infer number of columns"
  242:             pytest.skip(reason="https://github.com/apache/arrow/issues/38676")
  243:         else:
  244:             msg = "NULL byte detected"
  245:         with pytest.raises(ParserError, match=msg):
  246:             parser.read_csv(StringIO(data), names=names)
  247: 
  248: 
  249: @pytest.mark.filterwarnings("always::ResourceWarning")
  250: def test_open_file(request, all_parsers):
  251:     # GH 39024
  252:     parser = all_parsers
  253: 
  254:     msg = "Could not determine delimiter"
  255:     err = csv.Error
  256:     if parser.engine == "c":
  257:         msg = "the 'c' engine does not support sep=None with delim_whitespace=False"
  258:         err = ValueError
  259:     elif parser.engine == "pyarrow":
  260:         msg = (
  261:             "the 'pyarrow' engine does not support sep=None with delim_whitespace=False"
  262:         )
  263:         err = ValueError
  264: 
  265:     with tm.ensure_clean() as path:
  266:         file = Path(path)
  267:         file.write_bytes(b"\xe4\na\n1")
  268: 
  269:         with tm.assert_produces_warning(None):
  270:             # should not trigger a ResourceWarning
  271:             with pytest.raises(err, match=msg):
  272:                 parser.read_csv(file, sep=None, encoding_errors="replace")
  273: 
  274: 
  275: def test_invalid_on_bad_line(all_parsers):
  276:     parser = all_parsers
  277:     data = "a\n1\n1,2,3\n4\n5,6,7"
  278:     with pytest.raises(ValueError, match="Argument abc is invalid for on_bad_lines"):
  279:         parser.read_csv(StringIO(data), on_bad_lines="abc")
  280: 
  281: 
  282: def test_bad_header_uniform_error(all_parsers):
  283:     parser = all_parsers
  284:     data = "+++123456789...\ncol1,col2,col3,col4\n1,2,3,4\n"
  285:     msg = "Expected 2 fields in line 2, saw 4"
  286:     if parser.engine == "c":
  287:         msg = (
  288:             "Could not construct index. Requested to use 1 "
  289:             "number of columns, but 3 left to parse."
  290:         )
  291:     elif parser.engine == "pyarrow":
  292:         # "CSV parse error: Expected 1 columns, got 4: col1,col2,col3,col4"
  293:         pytest.skip(reason="https://github.com/apache/arrow/issues/38676")
  294: 
  295:     with pytest.raises(ParserError, match=msg):
  296:         parser.read_csv(StringIO(data), index_col=0, on_bad_lines="error")
  297: 
  298: 
  299: def test_on_bad_lines_warn_correct_formatting(all_parsers):
  300:     # see gh-15925
  301:     parser = all_parsers
  302:     data = """1,2
  303: a,b
  304: a,b,c
  305: a,b,d
  306: a,b
  307: """
  308:     expected = DataFrame({"1": "a", "2": ["b"] * 2})
  309:     match_msg = "Skipping line"
  310: 
  311:     expected_warning = ParserWarning
  312:     if parser.engine == "pyarrow":
  313:         match_msg = "Expected 2 columns, but found 3: a,b,c"
  314:         expected_warning = (ParserWarning, DeprecationWarning)
  315: 
  316:     with tm.assert_produces_warning(
  317:         expected_warning, match=match_msg, check_stacklevel=False
  318:     ):
  319:         result = parser.read_csv(StringIO(data), on_bad_lines="warn")
  320:     tm.assert_frame_equal(result, expected)
