    1: import io
    2: 
    3: import numpy as np
    4: import pytest
    5: 
    6: from pandas import (
    7:     DataFrame,
    8:     date_range,
    9:     read_csv,
   10:     read_excel,
   11:     read_feather,
   12:     read_json,
   13:     read_parquet,
   14:     read_pickle,
   15:     read_stata,
   16:     read_table,
   17: )
   18: import pandas._testing as tm
   19: from pandas.util import _test_decorators as td
   20: 
   21: pytestmark = pytest.mark.filterwarnings(
   22:     "ignore:Passing a BlockManager to DataFrame:DeprecationWarning"
   23: )
   24: 
   25: 
   26: @pytest.fixture
   27: def fsspectest():
   28:     pytest.importorskip("fsspec")
   29:     from fsspec import register_implementation
   30:     from fsspec.implementations.memory import MemoryFileSystem
   31:     from fsspec.registry import _registry as registry
   32: 
   33:     class TestMemoryFS(MemoryFileSystem):
   34:         protocol = "testmem"
   35:         test = [None]
   36: 
   37:         def __init__(self, **kwargs) -> None:
   38:             self.test[0] = kwargs.pop("test", None)
   39:             super().__init__(**kwargs)
   40: 
   41:     register_implementation("testmem", TestMemoryFS, clobber=True)
   42:     yield TestMemoryFS()
   43:     registry.pop("testmem", None)
   44:     TestMemoryFS.test[0] = None
   45:     TestMemoryFS.store.clear()
   46: 
   47: 
   48: @pytest.fixture
   49: def df1():
   50:     return DataFrame(
   51:         {
   52:             "int": [1, 3],
   53:             "float": [2.0, np.nan],
   54:             "str": ["t", "s"],
   55:             "dt": date_range("2018-06-18", periods=2),
   56:         }
   57:     )
   58: 
   59: 
   60: @pytest.fixture
   61: def cleared_fs():
   62:     fsspec = pytest.importorskip("fsspec")
   63: 
   64:     memfs = fsspec.filesystem("memory")
   65:     yield memfs
   66:     memfs.store.clear()
   67: 
   68: 
   69: def test_read_csv(cleared_fs, df1):
   70:     text = str(df1.to_csv(index=False)).encode()
   71:     with cleared_fs.open("test/test.csv", "wb") as w:
   72:         w.write(text)
   73:     df2 = read_csv("memory://test/test.csv", parse_dates=["dt"])
   74: 
   75:     tm.assert_frame_equal(df1, df2)
   76: 
   77: 
   78: def test_reasonable_error(monkeypatch, cleared_fs):
   79:     from fsspec.registry import known_implementations
   80: 
   81:     with pytest.raises(ValueError, match="nosuchprotocol"):
   82:         read_csv("nosuchprotocol://test/test.csv")
   83:     err_msg = "test error message"
   84:     monkeypatch.setitem(
   85:         known_implementations,
   86:         "couldexist",
   87:         {"class": "unimportable.CouldExist", "err": err_msg},
   88:     )
   89:     with pytest.raises(ImportError, match=err_msg):
   90:         read_csv("couldexist://test/test.csv")
   91: 
   92: 
   93: def test_to_csv(cleared_fs, df1):
   94:     df1.to_csv("memory://test/test.csv", index=True)
   95: 
   96:     df2 = read_csv("memory://test/test.csv", parse_dates=["dt"], index_col=0)
   97: 
   98:     tm.assert_frame_equal(df1, df2)
   99: 
  100: 
  101: def test_to_excel(cleared_fs, df1):
  102:     pytest.importorskip("openpyxl")
  103:     ext = "xlsx"
  104:     path = f"memory://test/test.{ext}"
  105:     df1.to_excel(path, index=True)
  106: 
  107:     df2 = read_excel(path, parse_dates=["dt"], index_col=0)
  108: 
  109:     tm.assert_frame_equal(df1, df2)
  110: 
  111: 
  112: @pytest.mark.parametrize("binary_mode", [False, True])
  113: def test_to_csv_fsspec_object(cleared_fs, binary_mode, df1):
  114:     fsspec = pytest.importorskip("fsspec")
  115: 
  116:     path = "memory://test/test.csv"
  117:     mode = "wb" if binary_mode else "w"
  118:     with fsspec.open(path, mode=mode).open() as fsspec_object:
  119:         df1.to_csv(fsspec_object, index=True)
  120:         assert not fsspec_object.closed
  121: 
  122:     mode = mode.replace("w", "r")
  123:     with fsspec.open(path, mode=mode) as fsspec_object:
  124:         df2 = read_csv(
  125:             fsspec_object,
  126:             parse_dates=["dt"],
  127:             index_col=0,
  128:         )
  129:         assert not fsspec_object.closed
  130: 
  131:     tm.assert_frame_equal(df1, df2)
  132: 
  133: 
  134: def test_csv_options(fsspectest):
  135:     df = DataFrame({"a": [0]})
  136:     df.to_csv(
  137:         "testmem://test/test.csv", storage_options={"test": "csv_write"}, index=False
  138:     )
  139:     assert fsspectest.test[0] == "csv_write"
  140:     read_csv("testmem://test/test.csv", storage_options={"test": "csv_read"})
  141:     assert fsspectest.test[0] == "csv_read"
  142: 
  143: 
  144: def test_read_table_options(fsspectest):
  145:     # GH #39167
  146:     df = DataFrame({"a": [0]})
  147:     df.to_csv(
  148:         "testmem://test/test.csv", storage_options={"test": "csv_write"}, index=False
  149:     )
  150:     assert fsspectest.test[0] == "csv_write"
  151:     read_table("testmem://test/test.csv", storage_options={"test": "csv_read"})
  152:     assert fsspectest.test[0] == "csv_read"
  153: 
  154: 
  155: def test_excel_options(fsspectest):
  156:     pytest.importorskip("openpyxl")
  157:     extension = "xlsx"
  158: 
  159:     df = DataFrame({"a": [0]})
  160: 
  161:     path = f"testmem://test/test.{extension}"
  162: 
  163:     df.to_excel(path, storage_options={"test": "write"}, index=False)
  164:     assert fsspectest.test[0] == "write"
  165:     read_excel(path, storage_options={"test": "read"})
  166:     assert fsspectest.test[0] == "read"
  167: 
  168: 
  169: def test_to_parquet_new_file(cleared_fs, df1):
  170:     """Regression test for writing to a not-yet-existent GCS Parquet file."""
  171:     pytest.importorskip("fastparquet")
  172: 
  173:     df1.to_parquet(
  174:         "memory://test/test.csv", index=True, engine="fastparquet", compression=None
  175:     )
  176: 
  177: 
  178: def test_arrowparquet_options(fsspectest):
  179:     """Regression test for writing to a not-yet-existent GCS Parquet file."""
  180:     pytest.importorskip("pyarrow")
  181:     df = DataFrame({"a": [0]})
  182:     df.to_parquet(
  183:         "testmem://test/test.csv",
  184:         engine="pyarrow",
  185:         compression=None,
  186:         storage_options={"test": "parquet_write"},
  187:     )
  188:     assert fsspectest.test[0] == "parquet_write"
  189:     read_parquet(
  190:         "testmem://test/test.csv",
  191:         engine="pyarrow",
  192:         storage_options={"test": "parquet_read"},
  193:     )
  194:     assert fsspectest.test[0] == "parquet_read"
  195: 
  196: 
  197: @td.skip_array_manager_not_yet_implemented  # TODO(ArrayManager) fastparquet
  198: def test_fastparquet_options(fsspectest):
  199:     """Regression test for writing to a not-yet-existent GCS Parquet file."""
  200:     pytest.importorskip("fastparquet")
  201: 
  202:     df = DataFrame({"a": [0]})
  203:     df.to_parquet(
  204:         "testmem://test/test.csv",
  205:         engine="fastparquet",
  206:         compression=None,
  207:         storage_options={"test": "parquet_write"},
  208:     )
  209:     assert fsspectest.test[0] == "parquet_write"
  210:     read_parquet(
  211:         "testmem://test/test.csv",
  212:         engine="fastparquet",
  213:         storage_options={"test": "parquet_read"},
  214:     )
  215:     assert fsspectest.test[0] == "parquet_read"
  216: 
  217: 
  218: @pytest.mark.single_cpu
  219: def test_from_s3_csv(s3_public_bucket_with_data, tips_file, s3so):
  220:     pytest.importorskip("s3fs")
  221:     tm.assert_equal(
  222:         read_csv(
  223:             f"s3://{s3_public_bucket_with_data.name}/tips.csv", storage_options=s3so
  224:         ),
  225:         read_csv(tips_file),
  226:     )
  227:     # the following are decompressed by pandas, not fsspec
  228:     tm.assert_equal(
  229:         read_csv(
  230:             f"s3://{s3_public_bucket_with_data.name}/tips.csv.gz", storage_options=s3so
  231:         ),
  232:         read_csv(tips_file),
  233:     )
  234:     tm.assert_equal(
  235:         read_csv(
  236:             f"s3://{s3_public_bucket_with_data.name}/tips.csv.bz2", storage_options=s3so
  237:         ),
  238:         read_csv(tips_file),
  239:     )
  240: 
  241: 
  242: @pytest.mark.single_cpu
  243: @pytest.mark.parametrize("protocol", ["s3", "s3a", "s3n"])
  244: def test_s3_protocols(s3_public_bucket_with_data, tips_file, protocol, s3so):
  245:     pytest.importorskip("s3fs")
  246:     tm.assert_equal(
  247:         read_csv(
  248:             f"{protocol}://{s3_public_bucket_with_data.name}/tips.csv",
  249:             storage_options=s3so,
  250:         ),
  251:         read_csv(tips_file),
  252:     )
  253: 
  254: 
  255: @pytest.mark.single_cpu
  256: @td.skip_array_manager_not_yet_implemented  # TODO(ArrayManager) fastparquet
  257: def test_s3_parquet(s3_public_bucket, s3so, df1):
  258:     pytest.importorskip("fastparquet")
  259:     pytest.importorskip("s3fs")
  260: 
  261:     fn = f"s3://{s3_public_bucket.name}/test.parquet"
  262:     df1.to_parquet(
  263:         fn, index=False, engine="fastparquet", compression=None, storage_options=s3so
  264:     )
  265:     df2 = read_parquet(fn, engine="fastparquet", storage_options=s3so)
  266:     tm.assert_equal(df1, df2)
  267: 
  268: 
  269: @td.skip_if_installed("fsspec")
  270: def test_not_present_exception():
  271:     msg = "Missing optional dependency 'fsspec'|fsspec library is required"
  272:     with pytest.raises(ImportError, match=msg):
  273:         read_csv("memory://test/test.csv")
  274: 
  275: 
  276: def test_feather_options(fsspectest):
  277:     pytest.importorskip("pyarrow")
  278:     df = DataFrame({"a": [0]})
  279:     df.to_feather("testmem://mockfile", storage_options={"test": "feather_write"})
  280:     assert fsspectest.test[0] == "feather_write"
  281:     out = read_feather("testmem://mockfile", storage_options={"test": "feather_read"})
  282:     assert fsspectest.test[0] == "feather_read"
  283:     tm.assert_frame_equal(df, out)
  284: 
  285: 
  286: def test_pickle_options(fsspectest):
  287:     df = DataFrame({"a": [0]})
  288:     df.to_pickle("testmem://mockfile", storage_options={"test": "pickle_write"})
  289:     assert fsspectest.test[0] == "pickle_write"
  290:     out = read_pickle("testmem://mockfile", storage_options={"test": "pickle_read"})
  291:     assert fsspectest.test[0] == "pickle_read"
  292:     tm.assert_frame_equal(df, out)
  293: 
  294: 
  295: def test_json_options(fsspectest, compression):
  296:     df = DataFrame({"a": [0]})
  297:     df.to_json(
  298:         "testmem://mockfile",
  299:         compression=compression,
  300:         storage_options={"test": "json_write"},
  301:     )
  302:     assert fsspectest.test[0] == "json_write"
  303:     out = read_json(
  304:         "testmem://mockfile",
  305:         compression=compression,
  306:         storage_options={"test": "json_read"},
  307:     )
  308:     assert fsspectest.test[0] == "json_read"
  309:     tm.assert_frame_equal(df, out)
  310: 
  311: 
  312: def test_stata_options(fsspectest):
  313:     df = DataFrame({"a": [0]})
  314:     df.to_stata(
  315:         "testmem://mockfile", storage_options={"test": "stata_write"}, write_index=False
  316:     )
  317:     assert fsspectest.test[0] == "stata_write"
  318:     out = read_stata("testmem://mockfile", storage_options={"test": "stata_read"})
  319:     assert fsspectest.test[0] == "stata_read"
  320:     tm.assert_frame_equal(df, out.astype("int64"))
  321: 
  322: 
  323: def test_markdown_options(fsspectest):
  324:     pytest.importorskip("tabulate")
  325:     df = DataFrame({"a": [0]})
  326:     df.to_markdown("testmem://mockfile", storage_options={"test": "md_write"})
  327:     assert fsspectest.test[0] == "md_write"
  328:     assert fsspectest.cat("testmem://mockfile")
  329: 
  330: 
  331: def test_non_fsspec_options():
  332:     pytest.importorskip("pyarrow")
  333:     with pytest.raises(ValueError, match="storage_options"):
  334:         read_csv("localfile", storage_options={"a": True})
  335:     with pytest.raises(ValueError, match="storage_options"):
  336:         # separate test for parquet, which has a different code path
  337:         read_parquet("localfile", storage_options={"a": True})
  338:     by = io.BytesIO()
  339: 
  340:     with pytest.raises(ValueError, match="storage_options"):
  341:         read_csv(by, storage_options={"a": True})
  342: 
  343:     df = DataFrame({"a": [0]})
  344:     with pytest.raises(ValueError, match="storage_options"):
  345:         df.to_parquet("nonfsspecpath", storage_options={"a": True})
