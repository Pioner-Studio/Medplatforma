    1: """
    2: Tests for the pandas.io.common functionalities
    3: """
    4: import codecs
    5: import errno
    6: from functools import partial
    7: from io import (
    8:     BytesIO,
    9:     StringIO,
   10:     UnsupportedOperation,
   11: )
   12: import mmap
   13: import os
   14: from pathlib import Path
   15: import pickle
   16: import tempfile
   17: 
   18: import numpy as np
   19: import pytest
   20: 
   21: from pandas.compat import is_platform_windows
   22: import pandas.util._test_decorators as td
   23: 
   24: import pandas as pd
   25: import pandas._testing as tm
   26: 
   27: import pandas.io.common as icom
   28: 
   29: pytestmark = pytest.mark.filterwarnings(
   30:     "ignore:Passing a BlockManager to DataFrame:DeprecationWarning"
   31: )
   32: 
   33: 
   34: class CustomFSPath:
   35:     """For testing fspath on unknown objects"""
   36: 
   37:     def __init__(self, path) -> None:
   38:         self.path = path
   39: 
   40:     def __fspath__(self):
   41:         return self.path
   42: 
   43: 
   44: # Functions that consume a string path and return a string or path-like object
   45: path_types = [str, CustomFSPath, Path]
   46: 
   47: try:
   48:     from py.path import local as LocalPath
   49: 
   50:     path_types.append(LocalPath)
   51: except ImportError:
   52:     pass
   53: 
   54: HERE = os.path.abspath(os.path.dirname(__file__))
   55: 
   56: 
   57: # https://github.com/cython/cython/issues/1720
   58: class TestCommonIOCapabilities:
   59:     data1 = """index,A,B,C,D
   60: foo,2,3,4,5
   61: bar,7,8,9,10
   62: baz,12,13,14,15
   63: qux,12,13,14,15
   64: foo2,12,13,14,15
   65: bar2,12,13,14,15
   66: """
   67: 
   68:     def test_expand_user(self):
   69:         filename = "~/sometest"
   70:         expanded_name = icom._expand_user(filename)
   71: 
   72:         assert expanded_name != filename
   73:         assert os.path.isabs(expanded_name)
   74:         assert os.path.expanduser(filename) == expanded_name
   75: 
   76:     def test_expand_user_normal_path(self):
   77:         filename = "/somefolder/sometest"
   78:         expanded_name = icom._expand_user(filename)
   79: 
   80:         assert expanded_name == filename
   81:         assert os.path.expanduser(filename) == expanded_name
   82: 
   83:     def test_stringify_path_pathlib(self):
   84:         rel_path = icom.stringify_path(Path("."))
   85:         assert rel_path == "."
   86:         redundant_path = icom.stringify_path(Path("foo//bar"))
   87:         assert redundant_path == os.path.join("foo", "bar")
   88: 
   89:     @td.skip_if_no("py.path")
   90:     def test_stringify_path_localpath(self):
   91:         path = os.path.join("foo", "bar")
   92:         abs_path = os.path.abspath(path)
   93:         lpath = LocalPath(path)
   94:         assert icom.stringify_path(lpath) == abs_path
   95: 
   96:     def test_stringify_path_fspath(self):
   97:         p = CustomFSPath("foo/bar.csv")
   98:         result = icom.stringify_path(p)
   99:         assert result == "foo/bar.csv"
  100: 
  101:     def test_stringify_file_and_path_like(self):
  102:         # GH 38125: do not stringify file objects that are also path-like
  103:         fsspec = pytest.importorskip("fsspec")
  104:         with tm.ensure_clean() as path:
  105:             with fsspec.open(f"file://{path}", mode="wb") as fsspec_obj:
  106:                 assert fsspec_obj == icom.stringify_path(fsspec_obj)
  107: 
  108:     @pytest.mark.parametrize("path_type", path_types)
  109:     def test_infer_compression_from_path(self, compression_format, path_type):
  110:         extension, expected = compression_format
  111:         path = path_type("foo/bar.csv" + extension)
  112:         compression = icom.infer_compression(path, compression="infer")
  113:         assert compression == expected
  114: 
  115:     @pytest.mark.parametrize("path_type", [str, CustomFSPath, Path])
  116:     def test_get_handle_with_path(self, path_type):
  117:         # ignore LocalPath: it creates strange paths: /absolute/~/sometest
  118:         with tempfile.TemporaryDirectory(dir=Path.home()) as tmp:
  119:             filename = path_type("~/" + Path(tmp).name + "/sometest")
  120:             with icom.get_handle(filename, "w") as handles:
  121:                 assert Path(handles.handle.name).is_absolute()
  122:                 assert os.path.expanduser(filename) == handles.handle.name
  123: 
  124:     def test_get_handle_with_buffer(self):
  125:         with StringIO() as input_buffer:
  126:             with icom.get_handle(input_buffer, "r") as handles:
  127:                 assert handles.handle == input_buffer
  128:             assert not input_buffer.closed
  129:         assert input_buffer.closed
  130: 
  131:     # Test that BytesIOWrapper(get_handle) returns correct amount of bytes every time
  132:     def test_bytesiowrapper_returns_correct_bytes(self):
  133:         # Test latin1, ucs-2, and ucs-4 chars
  134:         data = """a,b,c
  135: 1,2,3
  136: В©,В®,В®
  137: Look,a snake,рџђЌ"""
  138:         with icom.get_handle(StringIO(data), "rb", is_text=False) as handles:
  139:             result = b""
  140:             chunksize = 5
  141:             while True:
  142:                 chunk = handles.handle.read(chunksize)
  143:                 # Make sure each chunk is correct amount of bytes
  144:                 assert len(chunk) <= chunksize
  145:                 if len(chunk) < chunksize:
  146:                     # Can be less amount of bytes, but only at EOF
  147:                     # which happens when read returns empty
  148:                     assert len(handles.handle.read()) == 0
  149:                     result += chunk
  150:                     break
  151:                 result += chunk
  152:             assert result == data.encode("utf-8")
  153: 
  154:     # Test that pyarrow can handle a file opened with get_handle
  155:     def test_get_handle_pyarrow_compat(self):
  156:         pa_csv = pytest.importorskip("pyarrow.csv")
  157: 
  158:         # Test latin1, ucs-2, and ucs-4 chars
  159:         data = """a,b,c
  160: 1,2,3
  161: В©,В®,В®
  162: Look,a snake,рџђЌ"""
  163:         expected = pd.DataFrame(
  164:             {"a": ["1", "В©", "Look"], "b": ["2", "В®", "a snake"], "c": ["3", "В®", "рџђЌ"]}
  165:         )
  166:         s = StringIO(data)
  167:         with icom.get_handle(s, "rb", is_text=False) as handles:
  168:             df = pa_csv.read_csv(handles.handle).to_pandas()
  169:             tm.assert_frame_equal(df, expected)
  170:             assert not s.closed
  171: 
  172:     def test_iterator(self):
  173:         with pd.read_csv(StringIO(self.data1), chunksize=1) as reader:
  174:             result = pd.concat(reader, ignore_index=True)
  175:         expected = pd.read_csv(StringIO(self.data1))
  176:         tm.assert_frame_equal(result, expected)
  177: 
  178:         # GH12153
  179:         with pd.read_csv(StringIO(self.data1), chunksize=1) as it:
  180:             first = next(it)
  181:             tm.assert_frame_equal(first, expected.iloc[[0]])
  182:             tm.assert_frame_equal(pd.concat(it), expected.iloc[1:])
  183: 
  184:     @pytest.mark.parametrize(
  185:         "reader, module, error_class, fn_ext",
  186:         [
  187:             (pd.read_csv, "os", FileNotFoundError, "csv"),
  188:             (pd.read_fwf, "os", FileNotFoundError, "txt"),
  189:             (pd.read_excel, "xlrd", FileNotFoundError, "xlsx"),
  190:             (pd.read_feather, "pyarrow", OSError, "feather"),
  191:             (pd.read_hdf, "tables", FileNotFoundError, "h5"),
  192:             (pd.read_stata, "os", FileNotFoundError, "dta"),
  193:             (pd.read_sas, "os", FileNotFoundError, "sas7bdat"),
  194:             (pd.read_json, "os", FileNotFoundError, "json"),
  195:             (pd.read_pickle, "os", FileNotFoundError, "pickle"),
  196:         ],
  197:     )
  198:     def test_read_non_existent(self, reader, module, error_class, fn_ext):
  199:         pytest.importorskip(module)
  200: 
  201:         path = os.path.join(HERE, "data", "does_not_exist." + fn_ext)
  202:         msg1 = rf"File (b')?.+does_not_exist\.{fn_ext}'? does not exist"
  203:         msg2 = rf"\[Errno 2\] No such file or directory: '.+does_not_exist\.{fn_ext}'"
  204:         msg3 = "Expected object or value"
  205:         msg4 = "path_or_buf needs to be a string file path or file-like"
  206:         msg5 = (
  207:             rf"\[Errno 2\] File .+does_not_exist\.{fn_ext} does not exist: "
  208:             rf"'.+does_not_exist\.{fn_ext}'"
  209:         )
  210:         msg6 = rf"\[Errno 2\] жІЎжњ‰й‚ЈдёЄж–‡д»¶ж€–з›®еЅ•: '.+does_not_exist\.{fn_ext}'"
  211:         msg7 = (
  212:             rf"\[Errno 2\] File o directory non esistente: '.+does_not_exist\.{fn_ext}'"
  213:         )
  214:         msg8 = rf"Failed to open local file.+does_not_exist\.{fn_ext}"
  215: 
  216:         with pytest.raises(
  217:             error_class,
  218:             match=rf"({msg1}|{msg2}|{msg3}|{msg4}|{msg5}|{msg6}|{msg7}|{msg8})",
  219:         ):
  220:             reader(path)
  221: 
  222:     @pytest.mark.parametrize(
  223:         "method, module, error_class, fn_ext",
  224:         [
  225:             (pd.DataFrame.to_csv, "os", OSError, "csv"),
  226:             (pd.DataFrame.to_html, "os", OSError, "html"),
  227:             (pd.DataFrame.to_excel, "xlrd", OSError, "xlsx"),
  228:             (pd.DataFrame.to_feather, "pyarrow", OSError, "feather"),
  229:             (pd.DataFrame.to_parquet, "pyarrow", OSError, "parquet"),
  230:             (pd.DataFrame.to_stata, "os", OSError, "dta"),
  231:             (pd.DataFrame.to_json, "os", OSError, "json"),
  232:             (pd.DataFrame.to_pickle, "os", OSError, "pickle"),
  233:         ],
  234:     )
  235:     # NOTE: Missing parent directory for pd.DataFrame.to_hdf is handled by PyTables
  236:     def test_write_missing_parent_directory(self, method, module, error_class, fn_ext):
  237:         pytest.importorskip(module)
  238: 
  239:         dummy_frame = pd.DataFrame({"a": [1, 2, 3], "b": [2, 3, 4], "c": [3, 4, 5]})
  240: 
  241:         path = os.path.join(HERE, "data", "missing_folder", "does_not_exist." + fn_ext)
  242: 
  243:         with pytest.raises(
  244:             error_class,
  245:             match=r"Cannot save file into a non-existent directory: .*missing_folder",
  246:         ):
  247:             method(dummy_frame, path)
  248: 
  249:     @pytest.mark.parametrize(
  250:         "reader, module, error_class, fn_ext",
  251:         [
  252:             (pd.read_csv, "os", FileNotFoundError, "csv"),
  253:             (pd.read_table, "os", FileNotFoundError, "csv"),
  254:             (pd.read_fwf, "os", FileNotFoundError, "txt"),
  255:             (pd.read_excel, "xlrd", FileNotFoundError, "xlsx"),
  256:             (pd.read_feather, "pyarrow", OSError, "feather"),
  257:             (pd.read_hdf, "tables", FileNotFoundError, "h5"),
  258:             (pd.read_stata, "os", FileNotFoundError, "dta"),
  259:             (pd.read_sas, "os", FileNotFoundError, "sas7bdat"),
  260:             (pd.read_json, "os", FileNotFoundError, "json"),
  261:             (pd.read_pickle, "os", FileNotFoundError, "pickle"),
  262:         ],
  263:     )
  264:     def test_read_expands_user_home_dir(
  265:         self, reader, module, error_class, fn_ext, monkeypatch
  266:     ):
  267:         pytest.importorskip(module)
  268: 
  269:         path = os.path.join("~", "does_not_exist." + fn_ext)
  270:         monkeypatch.setattr(icom, "_expand_user", lambda x: os.path.join("foo", x))
  271: 
  272:         msg1 = rf"File (b')?.+does_not_exist\.{fn_ext}'? does not exist"
  273:         msg2 = rf"\[Errno 2\] No such file or directory: '.+does_not_exist\.{fn_ext}'"
  274:         msg3 = "Unexpected character found when decoding 'false'"
  275:         msg4 = "path_or_buf needs to be a string file path or file-like"
  276:         msg5 = (
  277:             rf"\[Errno 2\] File .+does_not_exist\.{fn_ext} does not exist: "
  278:             rf"'.+does_not_exist\.{fn_ext}'"
  279:         )
  280:         msg6 = rf"\[Errno 2\] жІЎжњ‰й‚ЈдёЄж–‡д»¶ж€–з›®еЅ•: '.+does_not_exist\.{fn_ext}'"
  281:         msg7 = (
  282:             rf"\[Errno 2\] File o directory non esistente: '.+does_not_exist\.{fn_ext}'"
  283:         )
  284:         msg8 = rf"Failed to open local file.+does_not_exist\.{fn_ext}"
  285: 
  286:         with pytest.raises(
  287:             error_class,
  288:             match=rf"({msg1}|{msg2}|{msg3}|{msg4}|{msg5}|{msg6}|{msg7}|{msg8})",
  289:         ):
  290:             reader(path)
  291: 
  292:     @pytest.mark.parametrize(
  293:         "reader, module, path",
  294:         [
  295:             (pd.read_csv, "os", ("io", "data", "csv", "iris.csv")),
  296:             (pd.read_table, "os", ("io", "data", "csv", "iris.csv")),
  297:             (
  298:                 pd.read_fwf,
  299:                 "os",
  300:                 ("io", "data", "fixed_width", "fixed_width_format.txt"),
  301:             ),
  302:             (pd.read_excel, "xlrd", ("io", "data", "excel", "test1.xlsx")),
  303:             (
  304:                 pd.read_feather,
  305:                 "pyarrow",
  306:                 ("io", "data", "feather", "feather-0_3_1.feather"),
  307:             ),
  308:             (
  309:                 pd.read_hdf,
  310:                 "tables",
  311:                 ("io", "data", "legacy_hdf", "datetimetz_object.h5"),
  312:             ),
  313:             (pd.read_stata, "os", ("io", "data", "stata", "stata10_115.dta")),
  314:             (pd.read_sas, "os", ("io", "sas", "data", "test1.sas7bdat")),
  315:             (pd.read_json, "os", ("io", "json", "data", "tsframe_v012.json")),
  316:             (
  317:                 pd.read_pickle,
  318:                 "os",
  319:                 ("io", "data", "pickle", "categorical.0.25.0.pickle"),
  320:             ),
  321:         ],
  322:     )
  323:     def test_read_fspath_all(self, reader, module, path, datapath):
  324:         pytest.importorskip(module)
  325:         path = datapath(*path)
  326: 
  327:         mypath = CustomFSPath(path)
  328:         result = reader(mypath)
  329:         expected = reader(path)
  330: 
  331:         if path.endswith(".pickle"):
  332:             # categorical
  333:             tm.assert_categorical_equal(result, expected)
  334:         else:
  335:             tm.assert_frame_equal(result, expected)
  336: 
  337:     @pytest.mark.parametrize(
  338:         "writer_name, writer_kwargs, module",
  339:         [
  340:             ("to_csv", {}, "os"),
  341:             ("to_excel", {"engine": "openpyxl"}, "openpyxl"),
  342:             ("to_feather", {}, "pyarrow"),
  343:             ("to_html", {}, "os"),
  344:             ("to_json", {}, "os"),
  345:             ("to_latex", {}, "os"),
  346:             ("to_pickle", {}, "os"),
  347:             ("to_stata", {"time_stamp": pd.to_datetime("2019-01-01 00:00")}, "os"),
  348:         ],
  349:     )
  350:     def test_write_fspath_all(self, writer_name, writer_kwargs, module):
  351:         if writer_name in ["to_latex"]:  # uses Styler implementation
  352:             pytest.importorskip("jinja2")
  353:         p1 = tm.ensure_clean("string")
  354:         p2 = tm.ensure_clean("fspath")
  355:         df = pd.DataFrame({"A": [1, 2]})
  356: 
  357:         with p1 as string, p2 as fspath:
  358:             pytest.importorskip(module)
  359:             mypath = CustomFSPath(fspath)
  360:             writer = getattr(df, writer_name)
  361: 
  362:             writer(string, **writer_kwargs)
  363:             writer(mypath, **writer_kwargs)
  364:             with open(string, "rb") as f_str, open(fspath, "rb") as f_path:
  365:                 if writer_name == "to_excel":
  366:                     # binary representation of excel contains time creation
  367:                     # data that causes flaky CI failures
  368:                     result = pd.read_excel(f_str, **writer_kwargs)
  369:                     expected = pd.read_excel(f_path, **writer_kwargs)
  370:                     tm.assert_frame_equal(result, expected)
  371:                 else:
  372:                     result = f_str.read()
  373:                     expected = f_path.read()
  374:                     assert result == expected
  375: 
  376:     def test_write_fspath_hdf5(self):
  377:         # Same test as write_fspath_all, except HDF5 files aren't
  378:         # necessarily byte-for-byte identical for a given dataframe, so we'll
  379:         # have to read and compare equality
  380:         pytest.importorskip("tables")
  381: 
  382:         df = pd.DataFrame({"A": [1, 2]})
  383:         p1 = tm.ensure_clean("string")
  384:         p2 = tm.ensure_clean("fspath")
  385: 
  386:         with p1 as string, p2 as fspath:
  387:             mypath = CustomFSPath(fspath)
  388:             df.to_hdf(mypath, key="bar")
  389:             df.to_hdf(string, key="bar")
  390: 
  391:             result = pd.read_hdf(fspath, key="bar")
  392:             expected = pd.read_hdf(string, key="bar")
  393: 
  394:         tm.assert_frame_equal(result, expected)
  395: 
  396: 
  397: @pytest.fixture
  398: def mmap_file(datapath):
  399:     return datapath("io", "data", "csv", "test_mmap.csv")
  400: 
  401: 
  402: class TestMMapWrapper:
  403:     def test_constructor_bad_file(self, mmap_file):
  404:         non_file = StringIO("I am not a file")
  405:         non_file.fileno = lambda: -1
  406: 
  407:         # the error raised is different on Windows
  408:         if is_platform_windows():
  409:             msg = "The parameter is incorrect"
  410:             err = OSError
  411:         else:
  412:             msg = "[Errno 22]"
  413:             err = mmap.error
  414: 
  415:         with pytest.raises(err, match=msg):
  416:             icom._maybe_memory_map(non_file, True)
  417: 
  418:         with open(mmap_file, encoding="utf-8") as target:
  419:             pass
  420: 
  421:         msg = "I/O operation on closed file"
  422:         with pytest.raises(ValueError, match=msg):
  423:             icom._maybe_memory_map(target, True)
  424: 
  425:     def test_next(self, mmap_file):
  426:         with open(mmap_file, encoding="utf-8") as target:
  427:             lines = target.readlines()
  428: 
  429:             with icom.get_handle(
  430:                 target, "r", is_text=True, memory_map=True
  431:             ) as wrappers:
  432:                 wrapper = wrappers.handle
  433:                 assert isinstance(wrapper.buffer.buffer, mmap.mmap)
  434: 
  435:                 for line in lines:
  436:                     next_line = next(wrapper)
  437:                     assert next_line.strip() == line.strip()
  438: 
  439:                 with pytest.raises(StopIteration, match=r"^$"):
  440:                     next(wrapper)
  441: 
  442:     def test_unknown_engine(self):
  443:         with tm.ensure_clean() as path:
  444:             df = pd.DataFrame(
  445:                 1.1 * np.arange(120).reshape((30, 4)),
  446:                 columns=pd.Index(list("ABCD"), dtype=object),
  447:                 index=pd.Index([f"i-{i}" for i in range(30)], dtype=object),
  448:             )
  449:             df.to_csv(path)
  450:             with pytest.raises(ValueError, match="Unknown engine"):
  451:                 pd.read_csv(path, engine="pyt")
  452: 
  453:     def test_binary_mode(self):
  454:         """
  455:         'encoding' shouldn't be passed to 'open' in binary mode.
  456: 
  457:         GH 35058
  458:         """
  459:         with tm.ensure_clean() as path:
  460:             df = pd.DataFrame(
  461:                 1.1 * np.arange(120).reshape((30, 4)),
  462:                 columns=pd.Index(list("ABCD"), dtype=object),
  463:                 index=pd.Index([f"i-{i}" for i in range(30)], dtype=object),
  464:             )
  465:             df.to_csv(path, mode="w+b")
  466:             tm.assert_frame_equal(df, pd.read_csv(path, index_col=0))
  467: 
  468:     @pytest.mark.parametrize("encoding", ["utf-16", "utf-32"])
  469:     @pytest.mark.parametrize("compression_", ["bz2", "xz"])
  470:     def test_warning_missing_utf_bom(self, encoding, compression_):
  471:         """
  472:         bz2 and xz do not write the byte order mark (BOM) for utf-16/32.
  473: 
  474:         https://stackoverflow.com/questions/55171439
  475: 
  476:         GH 35681
  477:         """
  478:         df = pd.DataFrame(
  479:             1.1 * np.arange(120).reshape((30, 4)),
  480:             columns=pd.Index(list("ABCD"), dtype=object),
  481:             index=pd.Index([f"i-{i}" for i in range(30)], dtype=object),
  482:         )
  483:         with tm.ensure_clean() as path:
  484:             with tm.assert_produces_warning(UnicodeWarning):
  485:                 df.to_csv(path, compression=compression_, encoding=encoding)
  486: 
  487:             # reading should fail (otherwise we wouldn't need the warning)
  488:             msg = r"UTF-\d+ stream does not start with BOM"
  489:             with pytest.raises(UnicodeError, match=msg):
  490:                 pd.read_csv(path, compression=compression_, encoding=encoding)
  491: 
  492: 
  493: def test_is_fsspec_url():
  494:     assert icom.is_fsspec_url("gcs://pandas/somethingelse.com")
  495:     assert icom.is_fsspec_url("gs://pandas/somethingelse.com")
  496:     # the following is the only remote URL that is handled without fsspec
  497:     assert not icom.is_fsspec_url("http://pandas/somethingelse.com")
  498:     assert not icom.is_fsspec_url("random:pandas/somethingelse.com")
  499:     assert not icom.is_fsspec_url("/local/path")
  500:     assert not icom.is_fsspec_url("relative/local/path")
  501:     # fsspec URL in string should not be recognized
  502:     assert not icom.is_fsspec_url("this is not fsspec://url")
  503:     assert not icom.is_fsspec_url("{'url': 'gs://pandas/somethingelse.com'}")
  504:     # accept everything that conforms to RFC 3986 schema
  505:     assert icom.is_fsspec_url("RFC-3986+compliant.spec://something")
  506: 
  507: 
  508: @pytest.mark.parametrize("encoding", [None, "utf-8"])
  509: @pytest.mark.parametrize("format", ["csv", "json"])
  510: def test_codecs_encoding(encoding, format):
  511:     # GH39247
  512:     expected = pd.DataFrame(
  513:         1.1 * np.arange(120).reshape((30, 4)),
  514:         columns=pd.Index(list("ABCD"), dtype=object),
  515:         index=pd.Index([f"i-{i}" for i in range(30)], dtype=object),
  516:     )
  517:     with tm.ensure_clean() as path:
  518:         with codecs.open(path, mode="w", encoding=encoding) as handle:
  519:             getattr(expected, f"to_{format}")(handle)
  520:         with codecs.open(path, mode="r", encoding=encoding) as handle:
  521:             if format == "csv":
  522:                 df = pd.read_csv(handle, index_col=0)
  523:             else:
  524:                 df = pd.read_json(handle)
  525:     tm.assert_frame_equal(expected, df)
  526: 
  527: 
  528: def test_codecs_get_writer_reader():
  529:     # GH39247
  530:     expected = pd.DataFrame(
  531:         1.1 * np.arange(120).reshape((30, 4)),
  532:         columns=pd.Index(list("ABCD"), dtype=object),
  533:         index=pd.Index([f"i-{i}" for i in range(30)], dtype=object),
  534:     )
  535:     with tm.ensure_clean() as path:
  536:         with open(path, "wb") as handle:
  537:             with codecs.getwriter("utf-8")(handle) as encoded:
  538:                 expected.to_csv(encoded)
  539:         with open(path, "rb") as handle:
  540:             with codecs.getreader("utf-8")(handle) as encoded:
  541:                 df = pd.read_csv(encoded, index_col=0)
  542:     tm.assert_frame_equal(expected, df)
  543: 
  544: 
  545: @pytest.mark.parametrize(
  546:     "io_class,mode,msg",
  547:     [
  548:         (BytesIO, "t", "a bytes-like object is required, not 'str'"),
  549:         (StringIO, "b", "string argument expected, got 'bytes'"),
  550:     ],
  551: )
  552: def test_explicit_encoding(io_class, mode, msg):
  553:     # GH39247; this test makes sure that if a user provides mode="*t" or "*b",
  554:     # it is used. In the case of this test it leads to an error as intentionally the
  555:     # wrong mode is requested
  556:     expected = pd.DataFrame(
  557:         1.1 * np.arange(120).reshape((30, 4)),
  558:         columns=pd.Index(list("ABCD"), dtype=object),
  559:         index=pd.Index([f"i-{i}" for i in range(30)], dtype=object),
  560:     )
  561:     with io_class() as buffer:
  562:         with pytest.raises(TypeError, match=msg):
  563:             expected.to_csv(buffer, mode=f"w{mode}")
  564: 
  565: 
  566: @pytest.mark.parametrize("encoding_errors", [None, "strict", "replace"])
  567: @pytest.mark.parametrize("format", ["csv", "json"])
  568: def test_encoding_errors(encoding_errors, format):
  569:     # GH39450
  570:     msg = "'utf-8' codec can't decode byte"
  571:     bad_encoding = b"\xe4"
  572: 
  573:     if format == "csv":
  574:         content = b"," + bad_encoding + b"\n" + bad_encoding * 2 + b"," + bad_encoding
  575:         reader = partial(pd.read_csv, index_col=0)
  576:     else:
  577:         content = (
  578:             b'{"'
  579:             + bad_encoding * 2
  580:             + b'": {"'
  581:             + bad_encoding
  582:             + b'":"'
  583:             + bad_encoding
  584:             + b'"}}'
  585:         )
  586:         reader = partial(pd.read_json, orient="index")
  587:     with tm.ensure_clean() as path:
  588:         file = Path(path)
  589:         file.write_bytes(content)
  590: 
  591:         if encoding_errors != "replace":
  592:             with pytest.raises(UnicodeDecodeError, match=msg):
  593:                 reader(path, encoding_errors=encoding_errors)
  594:         else:
  595:             df = reader(path, encoding_errors=encoding_errors)
  596:             decoded = bad_encoding.decode(errors=encoding_errors)
  597:             expected = pd.DataFrame({decoded: [decoded]}, index=[decoded * 2])
  598:             tm.assert_frame_equal(df, expected)
  599: 
  600: 
  601: def test_bad_encdoing_errors():
  602:     # GH 39777
  603:     with tm.ensure_clean() as path:
  604:         with pytest.raises(LookupError, match="unknown error handler name"):
  605:             icom.get_handle(path, "w", errors="bad")
  606: 
  607: 
  608: def test_errno_attribute():
  609:     # GH 13872
  610:     with pytest.raises(FileNotFoundError, match="\\[Errno 2\\]") as err:
  611:         pd.read_csv("doesnt_exist")
  612:         assert err.errno == errno.ENOENT
  613: 
  614: 
  615: def test_fail_mmap():
  616:     with pytest.raises(UnsupportedOperation, match="fileno"):
  617:         with BytesIO() as buffer:
  618:             icom.get_handle(buffer, "rb", memory_map=True)
  619: 
  620: 
  621: def test_close_on_error():
  622:     # GH 47136
  623:     class TestError:
  624:         def close(self):
  625:             raise OSError("test")
  626: 
  627:     with pytest.raises(OSError, match="test"):
  628:         with BytesIO() as buffer:
  629:             with icom.get_handle(buffer, "rb") as handles:
  630:                 handles.created_handles.append(TestError())
  631: 
  632: 
  633: @pytest.mark.parametrize(
  634:     "reader",
  635:     [
  636:         pd.read_csv,
  637:         pd.read_fwf,
  638:         pd.read_excel,
  639:         pd.read_feather,
  640:         pd.read_hdf,
  641:         pd.read_stata,
  642:         pd.read_sas,
  643:         pd.read_json,
  644:         pd.read_pickle,
  645:     ],
  646: )
  647: def test_pickle_reader(reader):
  648:     # GH 22265
  649:     with BytesIO() as buffer:
  650:         pickle.dump(reader, buffer)
