    1: """
    2: Tests date parsing functionality for all of the
    3: parsers defined in parsers.py
    4: """
    5: 
    6: from datetime import (
    7:     date,
    8:     datetime,
    9:     timedelta,
   10:     timezone,
   11: )
   12: from io import StringIO
   13: 
   14: from dateutil.parser import parse as du_parse
   15: import numpy as np
   16: import pytest
   17: import pytz
   18: 
   19: from pandas._libs.tslibs import parsing
   20: 
   21: import pandas as pd
   22: from pandas import (
   23:     DataFrame,
   24:     DatetimeIndex,
   25:     Index,
   26:     MultiIndex,
   27:     Series,
   28:     Timestamp,
   29: )
   30: import pandas._testing as tm
   31: from pandas.core.indexes.datetimes import date_range
   32: from pandas.core.tools.datetimes import start_caching_at
   33: 
   34: from pandas.io.parsers import read_csv
   35: 
   36: pytestmark = pytest.mark.filterwarnings(
   37:     "ignore:Passing a BlockManager to DataFrame:DeprecationWarning"
   38: )
   39: 
   40: xfail_pyarrow = pytest.mark.usefixtures("pyarrow_xfail")
   41: skip_pyarrow = pytest.mark.usefixtures("pyarrow_skip")
   42: 
   43: 
   44: @xfail_pyarrow
   45: def test_read_csv_with_custom_date_parser(all_parsers):
   46:     # GH36111
   47:     def __custom_date_parser(time):
   48:         time = time.astype(np.float64)
   49:         time = time.astype(int)  # convert float seconds to int type
   50:         return pd.to_timedelta(time, unit="s")
   51: 
   52:     testdata = StringIO(
   53:         """time e n h
   54:         41047.00 -98573.7297 871458.0640 389.0089
   55:         41048.00 -98573.7299 871458.0640 389.0089
   56:         41049.00 -98573.7300 871458.0642 389.0088
   57:         41050.00 -98573.7299 871458.0643 389.0088
   58:         41051.00 -98573.7302 871458.0640 389.0086
   59:         """
   60:     )
   61:     result = all_parsers.read_csv_check_warnings(
   62:         FutureWarning,
   63:         "Please use 'date_format' instead",
   64:         testdata,
   65:         delim_whitespace=True,
   66:         parse_dates=True,
   67:         date_parser=__custom_date_parser,
   68:         index_col="time",
   69:     )
   70:     time = [41047, 41048, 41049, 41050, 41051]
   71:     time = pd.TimedeltaIndex([pd.to_timedelta(i, unit="s") for i in time], name="time")
   72:     expected = DataFrame(
   73:         {
   74:             "e": [-98573.7297, -98573.7299, -98573.7300, -98573.7299, -98573.7302],
   75:             "n": [871458.0640, 871458.0640, 871458.0642, 871458.0643, 871458.0640],
   76:             "h": [389.0089, 389.0089, 389.0088, 389.0088, 389.0086],
   77:         },
   78:         index=time,
   79:     )
   80: 
   81:     tm.assert_frame_equal(result, expected)
   82: 
   83: 
   84: @xfail_pyarrow
   85: def test_read_csv_with_custom_date_parser_parse_dates_false(all_parsers):
   86:     # GH44366
   87:     def __custom_date_parser(time):
   88:         time = time.astype(np.float64)
   89:         time = time.astype(int)  # convert float seconds to int type
   90:         return pd.to_timedelta(time, unit="s")
   91: 
   92:     testdata = StringIO(
   93:         """time e
   94:         41047.00 -93.77
   95:         41048.00 -95.79
   96:         41049.00 -98.73
   97:         41050.00 -93.99
   98:         41051.00 -97.72
   99:         """
  100:     )
  101:     result = all_parsers.read_csv_check_warnings(
  102:         FutureWarning,
  103:         "Please use 'date_format' instead",
  104:         testdata,
  105:         delim_whitespace=True,
  106:         parse_dates=False,
  107:         date_parser=__custom_date_parser,
  108:         index_col="time",
  109:     )
  110:     time = Series([41047.00, 41048.00, 41049.00, 41050.00, 41051.00], name="time")
  111:     expected = DataFrame(
  112:         {"e": [-93.77, -95.79, -98.73, -93.99, -97.72]},
  113:         index=time,
  114:     )
  115: 
  116:     tm.assert_frame_equal(result, expected)
  117: 
  118: 
  119: @xfail_pyarrow
  120: def test_separator_date_conflict(all_parsers):
  121:     # Regression test for gh-4678
  122:     #
  123:     # Make sure thousands separator and
  124:     # date parsing do not conflict.
  125:     parser = all_parsers
  126:     data = "06-02-2013;13:00;1-000.215"
  127:     expected = DataFrame(
  128:         [[datetime(2013, 6, 2, 13, 0, 0), 1000.215]], columns=["Date", 2]
  129:     )
  130: 
  131:     depr_msg = (
  132:         "Support for nested sequences for 'parse_dates' in pd.read_csv is deprecated"
  133:     )
  134:     with tm.assert_produces_warning(
  135:         FutureWarning, match=depr_msg, check_stacklevel=False
  136:     ):
  137:         df = parser.read_csv(
  138:             StringIO(data),
  139:             sep=";",
  140:             thousands="-",
  141:             parse_dates={"Date": [0, 1]},
  142:             header=None,
  143:         )
  144:     tm.assert_frame_equal(df, expected)
  145: 
  146: 
  147: @pytest.mark.parametrize("keep_date_col", [True, False])
  148: def test_multiple_date_col_custom(all_parsers, keep_date_col, request):
  149:     data = """\
  150: KORD,19990127, 19:00:00, 18:56:00, 0.8100, 2.8100, 7.2000, 0.0000, 280.0000
  151: KORD,19990127, 20:00:00, 19:56:00, 0.0100, 2.2100, 7.2000, 0.0000, 260.0000
  152: KORD,19990127, 21:00:00, 20:56:00, -0.5900, 2.2100, 5.7000, 0.0000, 280.0000
  153: KORD,19990127, 21:00:00, 21:18:00, -0.9900, 2.0100, 3.6000, 0.0000, 270.0000
  154: KORD,19990127, 22:00:00, 21:56:00, -0.5900, 1.7100, 5.1000, 0.0000, 290.0000
  155: KORD,19990127, 23:00:00, 22:56:00, -0.5900, 1.7100, 4.6000, 0.0000, 280.0000
  156: """
  157:     parser = all_parsers
  158: 
  159:     if keep_date_col and parser.engine == "pyarrow":
  160:         # For this to pass, we need to disable auto-inference on the date columns
  161:         # in parse_dates. We have no way of doing this though
  162:         mark = pytest.mark.xfail(
  163:             reason="pyarrow doesn't support disabling auto-inference on column numbers."
  164:         )
  165:         request.applymarker(mark)
  166: 
  167:     def date_parser(*date_cols):
  168:         """
  169:         Test date parser.
  170: 
  171:         Parameters
  172:         ----------
  173:         date_cols : args
  174:             The list of data columns to parse.
  175: 
  176:         Returns
  177:         -------
  178:         parsed : Series
  179:         """
  180:         return parsing.try_parse_dates(
  181:             parsing.concat_date_cols(date_cols), parser=du_parse
  182:         )
  183: 
  184:     kwds = {
  185:         "header": None,
  186:         "date_parser": date_parser,
  187:         "parse_dates": {"actual": [1, 2], "nominal": [1, 3]},
  188:         "keep_date_col": keep_date_col,
  189:         "names": ["X0", "X1", "X2", "X3", "X4", "X5", "X6", "X7", "X8"],
  190:     }
  191:     result = parser.read_csv_check_warnings(
  192:         FutureWarning,
  193:         "use 'date_format' instead",
  194:         StringIO(data),
  195:         **kwds,
  196:         raise_on_extra_warnings=False,
  197:     )
  198: 
  199:     expected = DataFrame(
  200:         [
  201:             [
  202:                 datetime(1999, 1, 27, 19, 0),
  203:                 datetime(1999, 1, 27, 18, 56),
  204:                 "KORD",
  205:                 "19990127",
  206:                 " 19:00:00",
  207:                 " 18:56:00",
  208:                 0.81,
  209:                 2.81,
  210:                 7.2,
  211:                 0.0,
  212:                 280.0,
  213:             ],
  214:             [
  215:                 datetime(1999, 1, 27, 20, 0),
  216:                 datetime(1999, 1, 27, 19, 56),
  217:                 "KORD",
  218:                 "19990127",
  219:                 " 20:00:00",
  220:                 " 19:56:00",
  221:                 0.01,
  222:                 2.21,
  223:                 7.2,
  224:                 0.0,
  225:                 260.0,
  226:             ],
  227:             [
  228:                 datetime(1999, 1, 27, 21, 0),
  229:                 datetime(1999, 1, 27, 20, 56),
  230:                 "KORD",
  231:                 "19990127",
  232:                 " 21:00:00",
  233:                 " 20:56:00",
  234:                 -0.59,
  235:                 2.21,
  236:                 5.7,
  237:                 0.0,
  238:                 280.0,
  239:             ],
  240:             [
  241:                 datetime(1999, 1, 27, 21, 0),
  242:                 datetime(1999, 1, 27, 21, 18),
  243:                 "KORD",
  244:                 "19990127",
  245:                 " 21:00:00",
  246:                 " 21:18:00",
  247:                 -0.99,
  248:                 2.01,
  249:                 3.6,
  250:                 0.0,
  251:                 270.0,
  252:             ],
  253:             [
  254:                 datetime(1999, 1, 27, 22, 0),
  255:                 datetime(1999, 1, 27, 21, 56),
  256:                 "KORD",
  257:                 "19990127",
  258:                 " 22:00:00",
  259:                 " 21:56:00",
  260:                 -0.59,
  261:                 1.71,
  262:                 5.1,
  263:                 0.0,
  264:                 290.0,
  265:             ],
  266:             [
  267:                 datetime(1999, 1, 27, 23, 0),
  268:                 datetime(1999, 1, 27, 22, 56),
  269:                 "KORD",
  270:                 "19990127",
  271:                 " 23:00:00",
  272:                 " 22:56:00",
  273:                 -0.59,
  274:                 1.71,
  275:                 4.6,
  276:                 0.0,
  277:                 280.0,
  278:             ],
  279:         ],
  280:         columns=[
  281:             "actual",
  282:             "nominal",
  283:             "X0",
  284:             "X1",
  285:             "X2",
  286:             "X3",
  287:             "X4",
  288:             "X5",
  289:             "X6",
  290:             "X7",
  291:             "X8",
  292:         ],
  293:     )
  294: 
  295:     if not keep_date_col:
  296:         expected = expected.drop(["X1", "X2", "X3"], axis=1)
  297: 
  298:     # Python can sometimes be flaky about how
  299:     # the aggregated columns are entered, so
  300:     # this standardizes the order.
  301:     result = result[expected.columns]
  302:     tm.assert_frame_equal(result, expected)
  303: 
  304: 
  305: @pytest.mark.parametrize("container", [list, tuple, Index, Series])
  306: @pytest.mark.parametrize("dim", [1, 2])
  307: def test_concat_date_col_fail(container, dim):
  308:     msg = "not all elements from date_cols are numpy arrays"
  309:     value = "19990127"
  310: 
  311:     date_cols = tuple(container([value]) for _ in range(dim))
  312: 
  313:     with pytest.raises(ValueError, match=msg):
  314:         parsing.concat_date_cols(date_cols)
  315: 
  316: 
  317: @pytest.mark.parametrize("keep_date_col", [True, False])
  318: def test_multiple_date_col(all_parsers, keep_date_col, request):
  319:     data = """\
  320: KORD,19990127, 19:00:00, 18:56:00, 0.8100, 2.8100, 7.2000, 0.0000, 280.0000
  321: KORD,19990127, 20:00:00, 19:56:00, 0.0100, 2.2100, 7.2000, 0.0000, 260.0000
  322: KORD,19990127, 21:00:00, 20:56:00, -0.5900, 2.2100, 5.7000, 0.0000, 280.0000
  323: KORD,19990127, 21:00:00, 21:18:00, -0.9900, 2.0100, 3.6000, 0.0000, 270.0000
  324: KORD,19990127, 22:00:00, 21:56:00, -0.5900, 1.7100, 5.1000, 0.0000, 290.0000
  325: KORD,19990127, 23:00:00, 22:56:00, -0.5900, 1.7100, 4.6000, 0.0000, 280.0000
  326: """
  327:     parser = all_parsers
  328: 
  329:     if keep_date_col and parser.engine == "pyarrow":
  330:         # For this to pass, we need to disable auto-inference on the date columns
  331:         # in parse_dates. We have no way of doing this though
  332:         mark = pytest.mark.xfail(
  333:             reason="pyarrow doesn't support disabling auto-inference on column numbers."
  334:         )
  335:         request.applymarker(mark)
  336: 
  337:     depr_msg = "The 'keep_date_col' keyword in pd.read_csv is deprecated"
  338: 
  339:     kwds = {
  340:         "header": None,
  341:         "parse_dates": [[1, 2], [1, 3]],
  342:         "keep_date_col": keep_date_col,
  343:         "names": ["X0", "X1", "X2", "X3", "X4", "X5", "X6", "X7", "X8"],
  344:     }
  345:     with tm.assert_produces_warning(
  346:         (DeprecationWarning, FutureWarning), match=depr_msg, check_stacklevel=False
  347:     ):
  348:         result = parser.read_csv(StringIO(data), **kwds)
  349: 
  350:     expected = DataFrame(
  351:         [
  352:             [
  353:                 datetime(1999, 1, 27, 19, 0),
  354:                 datetime(1999, 1, 27, 18, 56),
  355:                 "KORD",
  356:                 "19990127",
  357:                 " 19:00:00",
  358:                 " 18:56:00",
  359:                 0.81,
  360:                 2.81,
  361:                 7.2,
  362:                 0.0,
  363:                 280.0,
  364:             ],
  365:             [
  366:                 datetime(1999, 1, 27, 20, 0),
  367:                 datetime(1999, 1, 27, 19, 56),
  368:                 "KORD",
  369:                 "19990127",
  370:                 " 20:00:00",
  371:                 " 19:56:00",
  372:                 0.01,
  373:                 2.21,
  374:                 7.2,
  375:                 0.0,
  376:                 260.0,
  377:             ],
  378:             [
  379:                 datetime(1999, 1, 27, 21, 0),
  380:                 datetime(1999, 1, 27, 20, 56),
  381:                 "KORD",
  382:                 "19990127",
  383:                 " 21:00:00",
  384:                 " 20:56:00",
  385:                 -0.59,
  386:                 2.21,
  387:                 5.7,
  388:                 0.0,
  389:                 280.0,
  390:             ],
  391:             [
  392:                 datetime(1999, 1, 27, 21, 0),
  393:                 datetime(1999, 1, 27, 21, 18),
  394:                 "KORD",
  395:                 "19990127",
  396:                 " 21:00:00",
  397:                 " 21:18:00",
  398:                 -0.99,
  399:                 2.01,
  400:                 3.6,
  401:                 0.0,
  402:                 270.0,
  403:             ],
  404:             [
  405:                 datetime(1999, 1, 27, 22, 0),
  406:                 datetime(1999, 1, 27, 21, 56),
  407:                 "KORD",
  408:                 "19990127",
  409:                 " 22:00:00",
  410:                 " 21:56:00",
  411:                 -0.59,
  412:                 1.71,
  413:                 5.1,
  414:                 0.0,
  415:                 290.0,
  416:             ],
  417:             [
  418:                 datetime(1999, 1, 27, 23, 0),
  419:                 datetime(1999, 1, 27, 22, 56),
  420:                 "KORD",
  421:                 "19990127",
  422:                 " 23:00:00",
  423:                 " 22:56:00",
  424:                 -0.59,
  425:                 1.71,
  426:                 4.6,
  427:                 0.0,
  428:                 280.0,
  429:             ],
  430:         ],
  431:         columns=[
  432:             "X1_X2",
  433:             "X1_X3",
  434:             "X0",
  435:             "X1",
  436:             "X2",
  437:             "X3",
  438:             "X4",
  439:             "X5",
  440:             "X6",
  441:             "X7",
  442:             "X8",
  443:         ],
  444:     )
  445: 
  446:     if not keep_date_col:
  447:         expected = expected.drop(["X1", "X2", "X3"], axis=1)
  448: 
  449:     tm.assert_frame_equal(result, expected)
  450: 
  451: 
  452: def test_date_col_as_index_col(all_parsers):
  453:     data = """\
  454: KORD,19990127 19:00:00, 18:56:00, 0.8100, 2.8100, 7.2000, 0.0000, 280.0000
  455: KORD,19990127 20:00:00, 19:56:00, 0.0100, 2.2100, 7.2000, 0.0000, 260.0000
  456: KORD,19990127 21:00:00, 20:56:00, -0.5900, 2.2100, 5.7000, 0.0000, 280.0000
  457: KORD,19990127 21:00:00, 21:18:00, -0.9900, 2.0100, 3.6000, 0.0000, 270.0000
  458: KORD,19990127 22:00:00, 21:56:00, -0.5900, 1.7100, 5.1000, 0.0000, 290.0000
  459: """
  460:     parser = all_parsers
  461:     kwds = {
  462:         "header": None,
  463:         "parse_dates": [1],
  464:         "index_col": 1,
  465:         "names": ["X0", "X1", "X2", "X3", "X4", "X5", "X6", "X7"],
  466:     }
  467:     result = parser.read_csv(StringIO(data), **kwds)
  468: 
  469:     index = Index(
  470:         [
  471:             datetime(1999, 1, 27, 19, 0),
  472:             datetime(1999, 1, 27, 20, 0),
  473:             datetime(1999, 1, 27, 21, 0),
  474:             datetime(1999, 1, 27, 21, 0),
  475:             datetime(1999, 1, 27, 22, 0),
  476:         ],
  477:         name="X1",
  478:     )
  479:     expected = DataFrame(
  480:         [
  481:             ["KORD", " 18:56:00", 0.81, 2.81, 7.2, 0.0, 280.0],
  482:             ["KORD", " 19:56:00", 0.01, 2.21, 7.2, 0.0, 260.0],
  483:             ["KORD", " 20:56:00", -0.59, 2.21, 5.7, 0.0, 280.0],
  484:             ["KORD", " 21:18:00", -0.99, 2.01, 3.6, 0.0, 270.0],
  485:             ["KORD", " 21:56:00", -0.59, 1.71, 5.1, 0.0, 290.0],
  486:         ],
  487:         columns=["X0", "X2", "X3", "X4", "X5", "X6", "X7"],
  488:         index=index,
  489:     )
  490:     if parser.engine == "pyarrow":
  491:         # https://github.com/pandas-dev/pandas/issues/44231
  492:         # pyarrow 6.0 starts to infer time type
  493:         expected["X2"] = pd.to_datetime("1970-01-01" + expected["X2"]).dt.time
  494: 
  495:     tm.assert_frame_equal(result, expected)
  496: 
  497: 
  498: def test_multiple_date_cols_int_cast(all_parsers):
  499:     data = (
  500:         "KORD,19990127, 19:00:00, 18:56:00, 0.8100\n"
  501:         "KORD,19990127, 20:00:00, 19:56:00, 0.0100\n"
  502:         "KORD,19990127, 21:00:00, 20:56:00, -0.5900\n"
  503:         "KORD,19990127, 21:00:00, 21:18:00, -0.9900\n"
  504:         "KORD,19990127, 22:00:00, 21:56:00, -0.5900\n"
  505:         "KORD,19990127, 23:00:00, 22:56:00, -0.5900"
  506:     )
  507:     parse_dates = {"actual": [1, 2], "nominal": [1, 3]}
  508:     parser = all_parsers
  509: 
  510:     kwds = {
  511:         "header": None,
  512:         "parse_dates": parse_dates,
  513:         "date_parser": pd.to_datetime,
  514:     }
  515:     result = parser.read_csv_check_warnings(
  516:         FutureWarning,
  517:         "use 'date_format' instead",
  518:         StringIO(data),
  519:         **kwds,
  520:         raise_on_extra_warnings=False,
  521:     )
  522: 
  523:     expected = DataFrame(
  524:         [
  525:             [datetime(1999, 1, 27, 19, 0), datetime(1999, 1, 27, 18, 56), "KORD", 0.81],
  526:             [datetime(1999, 1, 27, 20, 0), datetime(1999, 1, 27, 19, 56), "KORD", 0.01],
  527:             [
  528:                 datetime(1999, 1, 27, 21, 0),
  529:                 datetime(1999, 1, 27, 20, 56),
  530:                 "KORD",
  531:                 -0.59,
  532:             ],
  533:             [
  534:                 datetime(1999, 1, 27, 21, 0),
  535:                 datetime(1999, 1, 27, 21, 18),
  536:                 "KORD",
  537:                 -0.99,
  538:             ],
  539:             [
  540:                 datetime(1999, 1, 27, 22, 0),
  541:                 datetime(1999, 1, 27, 21, 56),
  542:                 "KORD",
  543:                 -0.59,
  544:             ],
  545:             [
  546:                 datetime(1999, 1, 27, 23, 0),
  547:                 datetime(1999, 1, 27, 22, 56),
  548:                 "KORD",
  549:                 -0.59,
  550:             ],
  551:         ],
  552:         columns=["actual", "nominal", 0, 4],
  553:     )
  554: 
  555:     # Python can sometimes be flaky about how
  556:     # the aggregated columns are entered, so
  557:     # this standardizes the order.
  558:     result = result[expected.columns]
  559:     tm.assert_frame_equal(result, expected)
  560: 
  561: 
  562: def test_multiple_date_col_timestamp_parse(all_parsers):
  563:     parser = all_parsers
  564:     data = """05/31/2012,15:30:00.029,1306.25,1,E,0,,1306.25
  565: 05/31/2012,15:30:00.029,1306.25,8,E,0,,1306.25"""
  566: 
  567:     result = parser.read_csv_check_warnings(
  568:         FutureWarning,
  569:         "use 'date_format' instead",
  570:         StringIO(data),
  571:         parse_dates=[[0, 1]],
  572:         header=None,
  573:         date_parser=Timestamp,
  574:         raise_on_extra_warnings=False,
  575:     )
  576:     expected = DataFrame(
  577:         [
  578:             [
  579:                 Timestamp("05/31/2012, 15:30:00.029"),
  580:                 1306.25,
  581:                 1,
  582:                 "E",
  583:                 0,
  584:                 np.nan,
  585:                 1306.25,
  586:             ],
  587:             [
  588:                 Timestamp("05/31/2012, 15:30:00.029"),
  589:                 1306.25,
  590:                 8,
  591:                 "E",
  592:                 0,
  593:                 np.nan,
  594:                 1306.25,
  595:             ],
  596:         ],
  597:         columns=["0_1", 2, 3, 4, 5, 6, 7],
  598:     )
  599:     tm.assert_frame_equal(result, expected)
  600: 
  601: 
  602: @xfail_pyarrow
  603: def test_multiple_date_cols_with_header(all_parsers):
  604:     parser = all_parsers
  605:     data = """\
  606: ID,date,NominalTime,ActualTime,TDew,TAir,Windspeed,Precip,WindDir
  607: KORD,19990127, 19:00:00, 18:56:00, 0.8100, 2.8100, 7.2000, 0.0000, 280.0000
  608: KORD,19990127, 20:00:00, 19:56:00, 0.0100, 2.2100, 7.2000, 0.0000, 260.0000
  609: KORD,19990127, 21:00:00, 20:56:00, -0.5900, 2.2100, 5.7000, 0.0000, 280.0000
  610: KORD,19990127, 21:00:00, 21:18:00, -0.9900, 2.0100, 3.6000, 0.0000, 270.0000
  611: KORD,19990127, 22:00:00, 21:56:00, -0.5900, 1.7100, 5.1000, 0.0000, 290.0000
  612: KORD,19990127, 23:00:00, 22:56:00, -0.5900, 1.7100, 4.6000, 0.0000, 280.0000"""
  613: 
  614:     depr_msg = (
  615:         "Support for nested sequences for 'parse_dates' in pd.read_csv is deprecated"
  616:     )
  617:     with tm.assert_produces_warning(
  618:         FutureWarning, match=depr_msg, check_stacklevel=False
  619:     ):
  620:         result = parser.read_csv(StringIO(data), parse_dates={"nominal": [1, 2]})
  621:     expected = DataFrame(
  622:         [
  623:             [
  624:                 datetime(1999, 1, 27, 19, 0),
  625:                 "KORD",
  626:                 " 18:56:00",
  627:                 0.81,
  628:                 2.81,
  629:                 7.2,
  630:                 0.0,
  631:                 280.0,
  632:             ],
  633:             [
  634:                 datetime(1999, 1, 27, 20, 0),
  635:                 "KORD",
  636:                 " 19:56:00",
  637:                 0.01,
  638:                 2.21,
  639:                 7.2,
  640:                 0.0,
  641:                 260.0,
  642:             ],
  643:             [
  644:                 datetime(1999, 1, 27, 21, 0),
  645:                 "KORD",
  646:                 " 20:56:00",
  647:                 -0.59,
  648:                 2.21,
  649:                 5.7,
  650:                 0.0,
  651:                 280.0,
  652:             ],
  653:             [
  654:                 datetime(1999, 1, 27, 21, 0),
  655:                 "KORD",
  656:                 " 21:18:00",
  657:                 -0.99,
  658:                 2.01,
  659:                 3.6,
  660:                 0.0,
  661:                 270.0,
  662:             ],
  663:             [
  664:                 datetime(1999, 1, 27, 22, 0),
  665:                 "KORD",
  666:                 " 21:56:00",
  667:                 -0.59,
  668:                 1.71,
  669:                 5.1,
  670:                 0.0,
  671:                 290.0,
  672:             ],
  673:             [
  674:                 datetime(1999, 1, 27, 23, 0),
  675:                 "KORD",
  676:                 " 22:56:00",
  677:                 -0.59,
  678:                 1.71,
  679:                 4.6,
  680:                 0.0,
  681:                 280.0,
  682:             ],
  683:         ],
  684:         columns=[
  685:             "nominal",
  686:             "ID",
  687:             "ActualTime",
  688:             "TDew",
  689:             "TAir",
  690:             "Windspeed",
  691:             "Precip",
  692:             "WindDir",
  693:         ],
  694:     )
  695:     tm.assert_frame_equal(result, expected)
  696: 
  697: 
  698: @pytest.mark.parametrize(
  699:     "data,parse_dates,msg",
  700:     [
  701:         (
  702:             """\
  703: date_NominalTime,date,NominalTime
  704: KORD1,19990127, 19:00:00
  705: KORD2,19990127, 20:00:00""",
  706:             [[1, 2]],
  707:             ("New date column already in dict date_NominalTime"),
  708:         ),
  709:         (
  710:             """\
  711: ID,date,nominalTime
  712: KORD,19990127, 19:00:00
  713: KORD,19990127, 20:00:00""",
  714:             {"ID": [1, 2]},
  715:             "Date column ID already in dict",
  716:         ),
  717:     ],
  718: )
  719: def test_multiple_date_col_name_collision(all_parsers, data, parse_dates, msg):
  720:     parser = all_parsers
  721: 
  722:     depr_msg = (
  723:         "Support for nested sequences for 'parse_dates' in pd.read_csv is deprecated"
  724:     )
  725:     with pytest.raises(ValueError, match=msg):
  726:         with tm.assert_produces_warning(
  727:             (FutureWarning, DeprecationWarning), match=depr_msg, check_stacklevel=False
  728:         ):
  729:             parser.read_csv(StringIO(data), parse_dates=parse_dates)
  730: 
  731: 
  732: def test_date_parser_int_bug(all_parsers):
  733:     # see gh-3071
  734:     parser = all_parsers
  735:     data = (
  736:         "posix_timestamp,elapsed,sys,user,queries,query_time,rows,"
  737:         "accountid,userid,contactid,level,silo,method\n"
  738:         "1343103150,0.062353,0,4,6,0.01690,3,"
  739:         "12345,1,-1,3,invoice_InvoiceResource,search\n"
  740:     )
  741: 
  742:     result = parser.read_csv_check_warnings(
  743:         FutureWarning,
  744:         "use 'date_format' instead",
  745:         StringIO(data),
  746:         index_col=0,
  747:         parse_dates=[0],
  748:         # Note: we must pass tz and then drop the tz attribute
  749:         # (if we don't CI will flake out depending on the runner's local time)
  750:         date_parser=lambda x: datetime.fromtimestamp(int(x), tz=timezone.utc).replace(
  751:             tzinfo=None
  752:         ),
  753:         raise_on_extra_warnings=False,
  754:     )
  755:     expected = DataFrame(
  756:         [
  757:             [
  758:                 0.062353,
  759:                 0,
  760:                 4,
  761:                 6,
  762:                 0.01690,
  763:                 3,
  764:                 12345,
  765:                 1,
  766:                 -1,
  767:                 3,
  768:                 "invoice_InvoiceResource",
  769:                 "search",
  770:             ]
  771:         ],
  772:         columns=[
  773:             "elapsed",
  774:             "sys",
  775:             "user",
  776:             "queries",
  777:             "query_time",
  778:             "rows",
  779:             "accountid",
  780:             "userid",
  781:             "contactid",
  782:             "level",
  783:             "silo",
  784:             "method",
  785:         ],
  786:         index=Index([Timestamp("2012-07-24 04:12:30")], name="posix_timestamp"),
  787:     )
  788:     tm.assert_frame_equal(result, expected)
  789: 
  790: 
  791: @xfail_pyarrow
  792: def test_nat_parse(all_parsers):
  793:     # see gh-3062
  794:     parser = all_parsers
  795:     df = DataFrame(
  796:         {
  797:             "A": np.arange(10, dtype="float64"),
  798:             "B": Timestamp("20010101").as_unit("ns"),
  799:         }
  800:     )
  801:     df.iloc[3:6, :] = np.nan
  802: 
  803:     with tm.ensure_clean("__nat_parse_.csv") as path:
  804:         df.to_csv(path)
  805: 
  806:         result = parser.read_csv(path, index_col=0, parse_dates=["B"])
  807:         tm.assert_frame_equal(result, df)
  808: 
  809: 
  810: @skip_pyarrow
  811: def test_csv_custom_parser(all_parsers):
  812:     data = """A,B,C
  813: 20090101,a,1,2
  814: 20090102,b,3,4
  815: 20090103,c,4,5
  816: """
  817:     parser = all_parsers
  818:     result = parser.read_csv_check_warnings(
  819:         FutureWarning,
  820:         "use 'date_format' instead",
  821:         StringIO(data),
  822:         date_parser=lambda x: datetime.strptime(x, "%Y%m%d"),
  823:     )
  824:     expected = parser.read_csv(StringIO(data), parse_dates=True)
  825:     tm.assert_frame_equal(result, expected)
  826:     result = parser.read_csv(StringIO(data), date_format="%Y%m%d")
  827:     tm.assert_frame_equal(result, expected)
  828: 
  829: 
  830: @skip_pyarrow
  831: def test_parse_dates_implicit_first_col(all_parsers):
  832:     data = """A,B,C
  833: 20090101,a,1,2
  834: 20090102,b,3,4
  835: 20090103,c,4,5
  836: """
  837:     parser = all_parsers
  838:     result = parser.read_csv(StringIO(data), parse_dates=True)
  839: 
  840:     expected = parser.read_csv(StringIO(data), index_col=0, parse_dates=True)
  841:     tm.assert_frame_equal(result, expected)
  842: 
  843: 
  844: @xfail_pyarrow
  845: def test_parse_dates_string(all_parsers):
  846:     data = """date,A,B,C
  847: 20090101,a,1,2
  848: 20090102,b,3,4
  849: 20090103,c,4,5
  850: """
  851:     parser = all_parsers
  852:     result = parser.read_csv(StringIO(data), index_col="date", parse_dates=["date"])
  853:     # freq doesn't round-trip
  854:     index = date_range("1/1/2009", periods=3, name="date")._with_freq(None)
  855: 
  856:     expected = DataFrame(
  857:         {"A": ["a", "b", "c"], "B": [1, 3, 4], "C": [2, 4, 5]}, index=index
  858:     )
  859:     tm.assert_frame_equal(result, expected)
  860: 
  861: 
  862: # Bug in https://github.com/dateutil/dateutil/issues/217
  863: # has been addressed, but we just don't pass in the `yearfirst`
  864: @pytest.mark.xfail(reason="yearfirst is not surfaced in read_*")
  865: @pytest.mark.parametrize("parse_dates", [[["date", "time"]], [[0, 1]]])
  866: def test_yy_format_with_year_first(all_parsers, parse_dates):
  867:     data = """date,time,B,C
  868: 090131,0010,1,2
  869: 090228,1020,3,4
  870: 090331,0830,5,6
  871: """
  872:     parser = all_parsers
  873:     result = parser.read_csv_check_warnings(
  874:         UserWarning,
  875:         "Could not infer format",
  876:         StringIO(data),
  877:         index_col=0,
  878:         parse_dates=parse_dates,
  879:     )
  880:     index = DatetimeIndex(
  881:         [
  882:             datetime(2009, 1, 31, 0, 10, 0),
  883:             datetime(2009, 2, 28, 10, 20, 0),
  884:             datetime(2009, 3, 31, 8, 30, 0),
  885:         ],
  886:         dtype=object,
  887:         name="date_time",
  888:     )
  889:     expected = DataFrame({"B": [1, 3, 5], "C": [2, 4, 6]}, index=index)
  890:     tm.assert_frame_equal(result, expected)
  891: 
  892: 
  893: @xfail_pyarrow
  894: @pytest.mark.parametrize("parse_dates", [[0, 2], ["a", "c"]])
  895: def test_parse_dates_column_list(all_parsers, parse_dates):
  896:     data = "a,b,c\n01/01/2010,1,15/02/2010"
  897:     parser = all_parsers
  898: 
  899:     expected = DataFrame(
  900:         {"a": [datetime(2010, 1, 1)], "b": [1], "c": [datetime(2010, 2, 15)]}
  901:     )
  902:     expected = expected.set_index(["a", "b"])
  903: 
  904:     result = parser.read_csv(
  905:         StringIO(data), index_col=[0, 1], parse_dates=parse_dates, dayfirst=True
  906:     )
  907:     tm.assert_frame_equal(result, expected)
  908: 
  909: 
  910: @xfail_pyarrow
  911: @pytest.mark.parametrize("index_col", [[0, 1], [1, 0]])
  912: def test_multi_index_parse_dates(all_parsers, index_col):
  913:     data = """index1,index2,A,B,C
  914: 20090101,one,a,1,2
  915: 20090101,two,b,3,4
  916: 20090101,three,c,4,5
  917: 20090102,one,a,1,2
  918: 20090102,two,b,3,4
  919: 20090102,three,c,4,5
  920: 20090103,one,a,1,2
  921: 20090103,two,b,3,4
  922: 20090103,three,c,4,5
  923: """
  924:     parser = all_parsers
  925:     index = MultiIndex.from_product(
  926:         [
  927:             (datetime(2009, 1, 1), datetime(2009, 1, 2), datetime(2009, 1, 3)),
  928:             ("one", "two", "three"),
  929:         ],
  930:         names=["index1", "index2"],
  931:     )
  932: 
  933:     # Out of order.
  934:     if index_col == [1, 0]:
  935:         index = index.swaplevel(0, 1)
  936: 
  937:     expected = DataFrame(
  938:         [
  939:             ["a", 1, 2],
  940:             ["b", 3, 4],
  941:             ["c", 4, 5],
  942:             ["a", 1, 2],
  943:             ["b", 3, 4],
  944:             ["c", 4, 5],
  945:             ["a", 1, 2],
  946:             ["b", 3, 4],
  947:             ["c", 4, 5],
  948:         ],
  949:         columns=["A", "B", "C"],
  950:         index=index,
  951:     )
  952:     result = parser.read_csv_check_warnings(
  953:         UserWarning,
  954:         "Could not infer format",
  955:         StringIO(data),
  956:         index_col=index_col,
  957:         parse_dates=True,
  958:     )
  959:     tm.assert_frame_equal(result, expected)
  960: 
  961: 
  962: @xfail_pyarrow
  963: @pytest.mark.parametrize("kwargs", [{"dayfirst": True}, {"day_first": True}])
  964: def test_parse_dates_custom_euro_format(all_parsers, kwargs):
  965:     parser = all_parsers
  966:     data = """foo,bar,baz
  967: 31/01/2010,1,2
  968: 01/02/2010,1,NA
  969: 02/02/2010,1,2
  970: """
  971:     if "dayfirst" in kwargs:
  972:         df = parser.read_csv_check_warnings(
  973:             FutureWarning,
  974:             "use 'date_format' instead",
  975:             StringIO(data),
  976:             names=["time", "Q", "NTU"],
  977:             date_parser=lambda d: du_parse(d, **kwargs),
  978:             header=0,
  979:             index_col=0,
  980:             parse_dates=True,
  981:             na_values=["NA"],
  982:         )
  983:         exp_index = Index(
  984:             [datetime(2010, 1, 31), datetime(2010, 2, 1), datetime(2010, 2, 2)],
  985:             name="time",
  986:         )
  987:         expected = DataFrame(
  988:             {"Q": [1, 1, 1], "NTU": [2, np.nan, 2]},
  989:             index=exp_index,
  990:             columns=["Q", "NTU"],
  991:         )
  992:         tm.assert_frame_equal(df, expected)
  993:     else:
  994:         msg = "got an unexpected keyword argument 'day_first'"
  995:         with pytest.raises(TypeError, match=msg):
  996:             parser.read_csv_check_warnings(
  997:                 FutureWarning,
  998:                 "use 'date_format' instead",
  999:                 StringIO(data),
 1000:                 names=["time", "Q", "NTU"],
 1001:                 date_parser=lambda d: du_parse(d, **kwargs),
 1002:                 skiprows=[0],
 1003:                 index_col=0,
 1004:                 parse_dates=True,
 1005:                 na_values=["NA"],
 1006:             )
 1007: 
 1008: 
 1009: def test_parse_tz_aware(all_parsers):
 1010:     # See gh-1693
 1011:     parser = all_parsers
 1012:     data = "Date,x\n2012-06-13T01:39:00Z,0.5"
 1013: 
 1014:     result = parser.read_csv(StringIO(data), index_col=0, parse_dates=True)
 1015:     # TODO: make unit check more specific
 1016:     if parser.engine == "pyarrow":
 1017:         result.index = result.index.as_unit("ns")
 1018:     expected = DataFrame(
 1019:         {"x": [0.5]}, index=Index([Timestamp("2012-06-13 01:39:00+00:00")], name="Date")
 1020:     )
 1021:     if parser.engine == "pyarrow":
 1022:         expected_tz = pytz.utc
 1023:     else:
 1024:         expected_tz = timezone.utc
 1025:     tm.assert_frame_equal(result, expected)
 1026:     assert result.index.tz is expected_tz
 1027: 
 1028: 
 1029: @xfail_pyarrow
 1030: @pytest.mark.parametrize(
 1031:     "parse_dates,index_col",
 1032:     [({"nominal": [1, 2]}, "nominal"), ({"nominal": [1, 2]}, 0), ([[1, 2]], 0)],
 1033: )
 1034: def test_multiple_date_cols_index(all_parsers, parse_dates, index_col):
 1035:     parser = all_parsers
 1036:     data = """
 1037: ID,date,NominalTime,ActualTime,TDew,TAir,Windspeed,Precip,WindDir
 1038: KORD1,19990127, 19:00:00, 18:56:00, 0.8100, 2.8100, 7.2000, 0.0000, 280.0000
 1039: KORD2,19990127, 20:00:00, 19:56:00, 0.0100, 2.2100, 7.2000, 0.0000, 260.0000
 1040: KORD3,19990127, 21:00:00, 20:56:00, -0.5900, 2.2100, 5.7000, 0.0000, 280.0000
 1041: KORD4,19990127, 21:00:00, 21:18:00, -0.9900, 2.0100, 3.6000, 0.0000, 270.0000
 1042: KORD5,19990127, 22:00:00, 21:56:00, -0.5900, 1.7100, 5.1000, 0.0000, 290.0000
 1043: KORD6,19990127, 23:00:00, 22:56:00, -0.5900, 1.7100, 4.6000, 0.0000, 280.0000
 1044: """
 1045:     expected = DataFrame(
 1046:         [
 1047:             [
 1048:                 datetime(1999, 1, 27, 19, 0),
 1049:                 "KORD1",
 1050:                 " 18:56:00",
 1051:                 0.81,
 1052:                 2.81,
 1053:                 7.2,
 1054:                 0.0,
 1055:                 280.0,
 1056:             ],
 1057:             [
 1058:                 datetime(1999, 1, 27, 20, 0),
 1059:                 "KORD2",
 1060:                 " 19:56:00",
 1061:                 0.01,
 1062:                 2.21,
 1063:                 7.2,
 1064:                 0.0,
 1065:                 260.0,
 1066:             ],
 1067:             [
 1068:                 datetime(1999, 1, 27, 21, 0),
 1069:                 "KORD3",
 1070:                 " 20:56:00",
 1071:                 -0.59,
 1072:                 2.21,
 1073:                 5.7,
 1074:                 0.0,
 1075:                 280.0,
 1076:             ],
 1077:             [
 1078:                 datetime(1999, 1, 27, 21, 0),
 1079:                 "KORD4",
 1080:                 " 21:18:00",
 1081:                 -0.99,
 1082:                 2.01,
 1083:                 3.6,
 1084:                 0.0,
 1085:                 270.0,
 1086:             ],
 1087:             [
 1088:                 datetime(1999, 1, 27, 22, 0),
 1089:                 "KORD5",
 1090:                 " 21:56:00",
 1091:                 -0.59,
 1092:                 1.71,
 1093:                 5.1,
 1094:                 0.0,
 1095:                 290.0,
 1096:             ],
 1097:             [
 1098:                 datetime(1999, 1, 27, 23, 0),
 1099:                 "KORD6",
 1100:                 " 22:56:00",
 1101:                 -0.59,
 1102:                 1.71,
 1103:                 4.6,
 1104:                 0.0,
 1105:                 280.0,
 1106:             ],
 1107:         ],
 1108:         columns=[
 1109:             "nominal",
 1110:             "ID",
 1111:             "ActualTime",
 1112:             "TDew",
 1113:             "TAir",
 1114:             "Windspeed",
 1115:             "Precip",
 1116:             "WindDir",
 1117:         ],
 1118:     )
 1119:     expected = expected.set_index("nominal")
 1120: 
 1121:     if not isinstance(parse_dates, dict):
 1122:         expected.index.name = "date_NominalTime"
 1123: 
 1124:     depr_msg = (
 1125:         "Support for nested sequences for 'parse_dates' in pd.read_csv is deprecated"
 1126:     )
 1127:     with tm.assert_produces_warning(
 1128:         FutureWarning, match=depr_msg, check_stacklevel=False
 1129:     ):
 1130:         result = parser.read_csv(
 1131:             StringIO(data), parse_dates=parse_dates, index_col=index_col
 1132:         )
 1133:     tm.assert_frame_equal(result, expected)
 1134: 
 1135: 
 1136: @xfail_pyarrow
 1137: def test_multiple_date_cols_chunked(all_parsers):
 1138:     parser = all_parsers
 1139:     data = """\
 1140: ID,date,nominalTime,actualTime,A,B,C,D,E
 1141: KORD,19990127, 19:00:00, 18:56:00, 0.8100, 2.8100, 7.2000, 0.0000, 280.0000
 1142: KORD,19990127, 20:00:00, 19:56:00, 0.0100, 2.2100, 7.2000, 0.0000, 260.0000
 1143: KORD,19990127, 21:00:00, 20:56:00, -0.5900, 2.2100, 5.7000, 0.0000, 280.0000
 1144: KORD,19990127, 21:00:00, 21:18:00, -0.9900, 2.0100, 3.6000, 0.0000, 270.0000
 1145: KORD,19990127, 22:00:00, 21:56:00, -0.5900, 1.7100, 5.1000, 0.0000, 290.0000
 1146: KORD,19990127, 23:00:00, 22:56:00, -0.5900, 1.7100, 4.6000, 0.0000, 280.0000
 1147: """
 1148: 
 1149:     expected = DataFrame(
 1150:         [
 1151:             [
 1152:                 datetime(1999, 1, 27, 19, 0),
 1153:                 "KORD",
 1154:                 " 18:56:00",
 1155:                 0.81,
 1156:                 2.81,
 1157:                 7.2,
 1158:                 0.0,
 1159:                 280.0,
 1160:             ],
 1161:             [
 1162:                 datetime(1999, 1, 27, 20, 0),
 1163:                 "KORD",
 1164:                 " 19:56:00",
 1165:                 0.01,
 1166:                 2.21,
 1167:                 7.2,
 1168:                 0.0,
 1169:                 260.0,
 1170:             ],
 1171:             [
 1172:                 datetime(1999, 1, 27, 21, 0),
 1173:                 "KORD",
 1174:                 " 20:56:00",
 1175:                 -0.59,
 1176:                 2.21,
 1177:                 5.7,
 1178:                 0.0,
 1179:                 280.0,
 1180:             ],
 1181:             [
 1182:                 datetime(1999, 1, 27, 21, 0),
 1183:                 "KORD",
 1184:                 " 21:18:00",
 1185:                 -0.99,
 1186:                 2.01,
 1187:                 3.6,
 1188:                 0.0,
 1189:                 270.0,
 1190:             ],
 1191:             [
 1192:                 datetime(1999, 1, 27, 22, 0),
 1193:                 "KORD",
 1194:                 " 21:56:00",
 1195:                 -0.59,
 1196:                 1.71,
 1197:                 5.1,
 1198:                 0.0,
 1199:                 290.0,
 1200:             ],
 1201:             [
 1202:                 datetime(1999, 1, 27, 23, 0),
 1203:                 "KORD",
 1204:                 " 22:56:00",
 1205:                 -0.59,
 1206:                 1.71,
 1207:                 4.6,
 1208:                 0.0,
 1209:                 280.0,
 1210:             ],
 1211:         ],
 1212:         columns=["nominal", "ID", "actualTime", "A", "B", "C", "D", "E"],
 1213:     )
 1214:     expected = expected.set_index("nominal")
 1215: 
 1216:     depr_msg = (
 1217:         "Support for nested sequences for 'parse_dates' in pd.read_csv is deprecated"
 1218:     )
 1219:     with tm.assert_produces_warning(
 1220:         FutureWarning, match=depr_msg, check_stacklevel=False
 1221:     ):
 1222:         with parser.read_csv(
 1223:             StringIO(data),
 1224:             parse_dates={"nominal": [1, 2]},
 1225:             index_col="nominal",
 1226:             chunksize=2,
 1227:         ) as reader:
 1228:             chunks = list(reader)
 1229: 
 1230:     tm.assert_frame_equal(chunks[0], expected[:2])
 1231:     tm.assert_frame_equal(chunks[1], expected[2:4])
 1232:     tm.assert_frame_equal(chunks[2], expected[4:])
 1233: 
 1234: 
 1235: def test_multiple_date_col_named_index_compat(all_parsers):
 1236:     parser = all_parsers
 1237:     data = """\
 1238: ID,date,nominalTime,actualTime,A,B,C,D,E
 1239: KORD,19990127, 19:00:00, 18:56:00, 0.8100, 2.8100, 7.2000, 0.0000, 280.0000
 1240: KORD,19990127, 20:00:00, 19:56:00, 0.0100, 2.2100, 7.2000, 0.0000, 260.0000
 1241: KORD,19990127, 21:00:00, 20:56:00, -0.5900, 2.2100, 5.7000, 0.0000, 280.0000
 1242: KORD,19990127, 21:00:00, 21:18:00, -0.9900, 2.0100, 3.6000, 0.0000, 270.0000
 1243: KORD,19990127, 22:00:00, 21:56:00, -0.5900, 1.7100, 5.1000, 0.0000, 290.0000
 1244: KORD,19990127, 23:00:00, 22:56:00, -0.5900, 1.7100, 4.6000, 0.0000, 280.0000
 1245: """
 1246: 
 1247:     depr_msg = (
 1248:         "Support for nested sequences for 'parse_dates' in pd.read_csv is deprecated"
 1249:     )
 1250:     with tm.assert_produces_warning(
 1251:         (FutureWarning, DeprecationWarning), match=depr_msg, check_stacklevel=False
 1252:     ):
 1253:         with_indices = parser.read_csv(
 1254:             StringIO(data), parse_dates={"nominal": [1, 2]}, index_col="nominal"
 1255:         )
 1256: 
 1257:     with tm.assert_produces_warning(
 1258:         (FutureWarning, DeprecationWarning), match=depr_msg, check_stacklevel=False
 1259:     ):
 1260:         with_names = parser.read_csv(
 1261:             StringIO(data),
 1262:             index_col="nominal",
 1263:             parse_dates={"nominal": ["date", "nominalTime"]},
 1264:         )
 1265:     tm.assert_frame_equal(with_indices, with_names)
 1266: 
 1267: 
 1268: def test_multiple_date_col_multiple_index_compat(all_parsers):
 1269:     parser = all_parsers
 1270:     data = """\
 1271: ID,date,nominalTime,actualTime,A,B,C,D,E
 1272: KORD,19990127, 19:00:00, 18:56:00, 0.8100, 2.8100, 7.2000, 0.0000, 280.0000
 1273: KORD,19990127, 20:00:00, 19:56:00, 0.0100, 2.2100, 7.2000, 0.0000, 260.0000
 1274: KORD,19990127, 21:00:00, 20:56:00, -0.5900, 2.2100, 5.7000, 0.0000, 280.0000
 1275: KORD,19990127, 21:00:00, 21:18:00, -0.9900, 2.0100, 3.6000, 0.0000, 270.0000
 1276: KORD,19990127, 22:00:00, 21:56:00, -0.5900, 1.7100, 5.1000, 0.0000, 290.0000
 1277: KORD,19990127, 23:00:00, 22:56:00, -0.5900, 1.7100, 4.6000, 0.0000, 280.0000
 1278: """
 1279:     depr_msg = (
 1280:         "Support for nested sequences for 'parse_dates' in pd.read_csv is deprecated"
 1281:     )
 1282:     with tm.assert_produces_warning(
 1283:         (FutureWarning, DeprecationWarning), match=depr_msg, check_stacklevel=False
 1284:     ):
 1285:         result = parser.read_csv(
 1286:             StringIO(data), index_col=["nominal", "ID"], parse_dates={"nominal": [1, 2]}
 1287:         )
 1288:     with tm.assert_produces_warning(
 1289:         (FutureWarning, DeprecationWarning), match=depr_msg, check_stacklevel=False
 1290:     ):
 1291:         expected = parser.read_csv(StringIO(data), parse_dates={"nominal": [1, 2]})
 1292: 
 1293:     expected = expected.set_index(["nominal", "ID"])
 1294:     tm.assert_frame_equal(result, expected)
 1295: 
 1296: 
 1297: @pytest.mark.parametrize("kwargs", [{}, {"index_col": "C"}])
 1298: def test_read_with_parse_dates_scalar_non_bool(all_parsers, kwargs):
 1299:     # see gh-5636
 1300:     parser = all_parsers
 1301:     msg = (
 1302:         "Only booleans, lists, and dictionaries "
 1303:         "are accepted for the 'parse_dates' parameter"
 1304:     )
 1305:     data = """A,B,C
 1306:     1,2,2003-11-1"""
 1307: 
 1308:     with pytest.raises(TypeError, match=msg):
 1309:         parser.read_csv(StringIO(data), parse_dates="C", **kwargs)
 1310: 
 1311: 
 1312: @pytest.mark.parametrize("parse_dates", [(1,), np.array([4, 5]), {1, 3}])
 1313: def test_read_with_parse_dates_invalid_type(all_parsers, parse_dates):
 1314:     parser = all_parsers
 1315:     msg = (
 1316:         "Only booleans, lists, and dictionaries "
 1317:         "are accepted for the 'parse_dates' parameter"
 1318:     )
 1319:     data = """A,B,C
 1320:     1,2,2003-11-1"""
 1321: 
 1322:     with pytest.raises(TypeError, match=msg):
 1323:         parser.read_csv(StringIO(data), parse_dates=(1,))
 1324: 
 1325: 
 1326: @pytest.mark.parametrize("cache_dates", [True, False])
 1327: @pytest.mark.parametrize("value", ["nan", ""])
 1328: def test_bad_date_parse(all_parsers, cache_dates, value):
 1329:     # if we have an invalid date make sure that we handle this with
 1330:     # and w/o the cache properly
 1331:     parser = all_parsers
 1332:     s = StringIO((f"{value},\n") * (start_caching_at + 1))
 1333: 
 1334:     parser.read_csv(
 1335:         s,
 1336:         header=None,
 1337:         names=["foo", "bar"],
 1338:         parse_dates=["foo"],
 1339:         cache_dates=cache_dates,
 1340:     )
 1341: 
 1342: 
 1343: @pytest.mark.parametrize("cache_dates", [True, False])
 1344: @pytest.mark.parametrize("value", ["0"])
 1345: def test_bad_date_parse_with_warning(all_parsers, cache_dates, value):
 1346:     # if we have an invalid date make sure that we handle this with
 1347:     # and w/o the cache properly.
 1348:     parser = all_parsers
 1349:     s = StringIO((f"{value},\n") * 50000)
 1350: 
 1351:     if parser.engine == "pyarrow":
 1352:         # pyarrow reads "0" as 0 (of type int64), and so
 1353:         # pandas doesn't try to guess the datetime format
 1354:         # TODO: parse dates directly in pyarrow, see
 1355:         # https://github.com/pandas-dev/pandas/issues/48017
 1356:         warn = None
 1357:     elif cache_dates:
 1358:         # Note: warning is not raised if 'cache_dates', because here there is only a
 1359:         # single unique date and hence no risk of inconsistent parsing.
 1360:         warn = None
 1361:     else:
 1362:         warn = UserWarning
 1363:     parser.read_csv_check_warnings(
 1364:         warn,
 1365:         "Could not infer format",
 1366:         s,
 1367:         header=None,
 1368:         names=["foo", "bar"],
 1369:         parse_dates=["foo"],
 1370:         cache_dates=cache_dates,
 1371:         raise_on_extra_warnings=False,
 1372:     )
 1373: 
 1374: 
 1375: @xfail_pyarrow
 1376: def test_parse_dates_empty_string(all_parsers):
 1377:     # see gh-2263
 1378:     parser = all_parsers
 1379:     data = "Date,test\n2012-01-01,1\n,2"
 1380:     result = parser.read_csv(StringIO(data), parse_dates=["Date"], na_filter=False)
 1381: 
 1382:     expected = DataFrame(
 1383:         [[datetime(2012, 1, 1), 1], [pd.NaT, 2]], columns=["Date", "test"]
 1384:     )
 1385:     tm.assert_frame_equal(result, expected)
 1386: 
 1387: 
 1388: @pytest.mark.parametrize(
 1389:     "reader", ["read_csv_check_warnings", "read_table_check_warnings"]
 1390: )
 1391: def test_parse_dates_infer_datetime_format_warning(all_parsers, reader):
 1392:     # GH 49024, 51017
 1393:     parser = all_parsers
 1394:     data = "Date,test\n2012-01-01,1\n,2"
 1395: 
 1396:     getattr(parser, reader)(
 1397:         FutureWarning,
 1398:         "The argument 'infer_datetime_format' is deprecated",
 1399:         StringIO(data),
 1400:         parse_dates=["Date"],
 1401:         infer_datetime_format=True,
 1402:         sep=",",
 1403:         raise_on_extra_warnings=False,
 1404:     )
 1405: 
 1406: 
 1407: @pytest.mark.parametrize(
 1408:     "reader", ["read_csv_check_warnings", "read_table_check_warnings"]
 1409: )
 1410: def test_parse_dates_date_parser_and_date_format(all_parsers, reader):
 1411:     # GH 50601
 1412:     parser = all_parsers
 1413:     data = "Date,test\n2012-01-01,1\n,2"
 1414:     msg = "Cannot use both 'date_parser' and 'date_format'"
 1415:     with pytest.raises(TypeError, match=msg):
 1416:         getattr(parser, reader)(
 1417:             FutureWarning,
 1418:             "use 'date_format' instead",
 1419:             StringIO(data),
 1420:             parse_dates=["Date"],
 1421:             date_parser=pd.to_datetime,
 1422:             date_format="ISO8601",
 1423:             sep=",",
 1424:         )
 1425: 
 1426: 
 1427: @xfail_pyarrow
 1428: @pytest.mark.parametrize(
 1429:     "data,kwargs,expected",
 1430:     [
 1431:         (
 1432:             "a\n04.15.2016",
 1433:             {"parse_dates": ["a"]},
 1434:             DataFrame([datetime(2016, 4, 15)], columns=["a"]),
 1435:         ),
 1436:         (
 1437:             "a\n04.15.2016",
 1438:             {"parse_dates": True, "index_col": 0},
 1439:             DataFrame(index=DatetimeIndex(["2016-04-15"], name="a"), columns=[]),
 1440:         ),
 1441:         (
 1442:             "a,b\n04.15.2016,09.16.2013",
 1443:             {"parse_dates": ["a", "b"]},
 1444:             DataFrame(
 1445:                 [[datetime(2016, 4, 15), datetime(2013, 9, 16)]], columns=["a", "b"]
 1446:             ),
 1447:         ),
 1448:         (
 1449:             "a,b\n04.15.2016,09.16.2013",
 1450:             {"parse_dates": True, "index_col": [0, 1]},
 1451:             DataFrame(
 1452:                 index=MultiIndex.from_tuples(
 1453:                     [(datetime(2016, 4, 15), datetime(2013, 9, 16))], names=["a", "b"]
 1454:                 ),
 1455:                 columns=[],
 1456:             ),
 1457:         ),
 1458:     ],
 1459: )
 1460: def test_parse_dates_no_convert_thousands(all_parsers, data, kwargs, expected):
 1461:     # see gh-14066
 1462:     parser = all_parsers
 1463: 
 1464:     result = parser.read_csv(StringIO(data), thousands=".", **kwargs)
 1465:     tm.assert_frame_equal(result, expected)
 1466: 
 1467: 
 1468: @xfail_pyarrow
 1469: def test_parse_date_time_multi_level_column_name(all_parsers):
 1470:     data = """\
 1471: D,T,A,B
 1472: date, time,a,b
 1473: 2001-01-05, 09:00:00, 0.0, 10.
 1474: 2001-01-06, 00:00:00, 1.0, 11.
 1475: """
 1476:     parser = all_parsers
 1477:     result = parser.read_csv_check_warnings(
 1478:         FutureWarning,
 1479:         "use 'date_format' instead",
 1480:         StringIO(data),
 1481:         header=[0, 1],
 1482:         parse_dates={"date_time": [0, 1]},
 1483:         date_parser=pd.to_datetime,
 1484:     )
 1485: 
 1486:     expected_data = [
 1487:         [datetime(2001, 1, 5, 9, 0, 0), 0.0, 10.0],
 1488:         [datetime(2001, 1, 6, 0, 0, 0), 1.0, 11.0],
 1489:     ]
 1490:     expected = DataFrame(expected_data, columns=["date_time", ("A", "a"), ("B", "b")])
 1491:     tm.assert_frame_equal(result, expected)
 1492: 
 1493: 
 1494: @pytest.mark.parametrize(
 1495:     "data,kwargs,expected",
 1496:     [
 1497:         (
 1498:             """\
 1499: date,time,a,b
 1500: 2001-01-05, 10:00:00, 0.0, 10.
 1501: 2001-01-05, 00:00:00, 1., 11.
 1502: """,
 1503:             {"header": 0, "parse_dates": {"date_time": [0, 1]}},
 1504:             DataFrame(
 1505:                 [
 1506:                     [datetime(2001, 1, 5, 10, 0, 0), 0.0, 10],
 1507:                     [datetime(2001, 1, 5, 0, 0, 0), 1.0, 11.0],
 1508:                 ],
 1509:                 columns=["date_time", "a", "b"],
 1510:             ),
 1511:         ),
 1512:         (
 1513:             (
 1514:                 "KORD,19990127, 19:00:00, 18:56:00, 0.8100\n"
 1515:                 "KORD,19990127, 20:00:00, 19:56:00, 0.0100\n"
 1516:                 "KORD,19990127, 21:00:00, 20:56:00, -0.5900\n"
 1517:                 "KORD,19990127, 21:00:00, 21:18:00, -0.9900\n"
 1518:                 "KORD,19990127, 22:00:00, 21:56:00, -0.5900\n"
 1519:                 "KORD,19990127, 23:00:00, 22:56:00, -0.5900"
 1520:             ),
 1521:             {"header": None, "parse_dates": {"actual": [1, 2], "nominal": [1, 3]}},
 1522:             DataFrame(
 1523:                 [
 1524:                     [
 1525:                         datetime(1999, 1, 27, 19, 0),
 1526:                         datetime(1999, 1, 27, 18, 56),
 1527:                         "KORD",
 1528:                         0.81,
 1529:                     ],
 1530:                     [
 1531:                         datetime(1999, 1, 27, 20, 0),
 1532:                         datetime(1999, 1, 27, 19, 56),
 1533:                         "KORD",
 1534:                         0.01,
 1535:                     ],
 1536:                     [
 1537:                         datetime(1999, 1, 27, 21, 0),
 1538:                         datetime(1999, 1, 27, 20, 56),
 1539:                         "KORD",
 1540:                         -0.59,
 1541:                     ],
 1542:                     [
 1543:                         datetime(1999, 1, 27, 21, 0),
 1544:                         datetime(1999, 1, 27, 21, 18),
 1545:                         "KORD",
 1546:                         -0.99,
 1547:                     ],
 1548:                     [
 1549:                         datetime(1999, 1, 27, 22, 0),
 1550:                         datetime(1999, 1, 27, 21, 56),
 1551:                         "KORD",
 1552:                         -0.59,
 1553:                     ],
 1554:                     [
 1555:                         datetime(1999, 1, 27, 23, 0),
 1556:                         datetime(1999, 1, 27, 22, 56),
 1557:                         "KORD",
 1558:                         -0.59,
 1559:                     ],
 1560:                 ],
 1561:                 columns=["actual", "nominal", 0, 4],
 1562:             ),
 1563:         ),
 1564:     ],
 1565: )
 1566: def test_parse_date_time(all_parsers, data, kwargs, expected):
 1567:     parser = all_parsers
 1568:     result = parser.read_csv_check_warnings(
 1569:         FutureWarning,
 1570:         "use 'date_format' instead",
 1571:         StringIO(data),
 1572:         date_parser=pd.to_datetime,
 1573:         **kwargs,
 1574:         raise_on_extra_warnings=False,
 1575:     )
 1576: 
 1577:     # Python can sometimes be flaky about how
 1578:     # the aggregated columns are entered, so
 1579:     # this standardizes the order.
 1580:     result = result[expected.columns]
 1581:     tm.assert_frame_equal(result, expected)
 1582: 
 1583: 
 1584: def test_parse_date_fields(all_parsers):
 1585:     parser = all_parsers
 1586:     data = "year,month,day,a\n2001,01,10,10.\n2001,02,1,11."
 1587:     result = parser.read_csv_check_warnings(
 1588:         FutureWarning,
 1589:         "use 'date_format' instead",
 1590:         StringIO(data),
 1591:         header=0,
 1592:         parse_dates={"ymd": [0, 1, 2]},
 1593:         date_parser=lambda x: x,
 1594:         raise_on_extra_warnings=False,
 1595:     )
 1596: 
 1597:     expected = DataFrame(
 1598:         [[datetime(2001, 1, 10), 10.0], [datetime(2001, 2, 1), 11.0]],
 1599:         columns=["ymd", "a"],
 1600:     )
 1601:     tm.assert_frame_equal(result, expected)
 1602: 
 1603: 
 1604: @pytest.mark.parametrize(
 1605:     ("key", "value", "warn"),
 1606:     [
 1607:         (
 1608:             "date_parser",
 1609:             lambda x: pd.to_datetime(x, format="%Y %m %d %H %M %S"),
 1610:             FutureWarning,
 1611:         ),
 1612:         ("date_format", "%Y %m %d %H %M %S", None),
 1613:     ],
 1614: )
 1615: def test_parse_date_all_fields(all_parsers, key, value, warn):
 1616:     parser = all_parsers
 1617:     data = """\
 1618: year,month,day,hour,minute,second,a,b
 1619: 2001,01,05,10,00,0,0.0,10.
 1620: 2001,01,5,10,0,00,1.,11.
 1621: """
 1622:     result = parser.read_csv_check_warnings(
 1623:         warn,
 1624:         "use 'date_format' instead",
 1625:         StringIO(data),
 1626:         header=0,
 1627:         parse_dates={"ymdHMS": [0, 1, 2, 3, 4, 5]},
 1628:         **{key: value},
 1629:         raise_on_extra_warnings=False,
 1630:     )
 1631:     expected = DataFrame(
 1632:         [
 1633:             [datetime(2001, 1, 5, 10, 0, 0), 0.0, 10.0],
 1634:             [datetime(2001, 1, 5, 10, 0, 0), 1.0, 11.0],
 1635:         ],
 1636:         columns=["ymdHMS", "a", "b"],
 1637:     )
 1638:     tm.assert_frame_equal(result, expected)
 1639: 
 1640: 
 1641: @pytest.mark.parametrize(
 1642:     ("key", "value", "warn"),
 1643:     [
 1644:         (
 1645:             "date_parser",
 1646:             lambda x: pd.to_datetime(x, format="%Y %m %d %H %M %S.%f"),
 1647:             FutureWarning,
 1648:         ),
 1649:         ("date_format", "%Y %m %d %H %M %S.%f", None),
 1650:     ],
 1651: )
 1652: def test_datetime_fractional_seconds(all_parsers, key, value, warn):
 1653:     parser = all_parsers
 1654:     data = """\
 1655: year,month,day,hour,minute,second,a,b
 1656: 2001,01,05,10,00,0.123456,0.0,10.
 1657: 2001,01,5,10,0,0.500000,1.,11.
 1658: """
 1659:     result = parser.read_csv_check_warnings(
 1660:         warn,
 1661:         "use 'date_format' instead",
 1662:         StringIO(data),
 1663:         header=0,
 1664:         parse_dates={"ymdHMS": [0, 1, 2, 3, 4, 5]},
 1665:         **{key: value},
 1666:         raise_on_extra_warnings=False,
 1667:     )
 1668:     expected = DataFrame(
 1669:         [
 1670:             [datetime(2001, 1, 5, 10, 0, 0, microsecond=123456), 0.0, 10.0],
 1671:             [datetime(2001, 1, 5, 10, 0, 0, microsecond=500000), 1.0, 11.0],
 1672:         ],
 1673:         columns=["ymdHMS", "a", "b"],
 1674:     )
 1675:     tm.assert_frame_equal(result, expected)
 1676: 
 1677: 
 1678: def test_generic(all_parsers):
 1679:     parser = all_parsers
 1680:     data = "year,month,day,a\n2001,01,10,10.\n2001,02,1,11."
 1681: 
 1682:     def parse_function(yy, mm):
 1683:         return [date(year=int(y), month=int(m), day=1) for y, m in zip(yy, mm)]
 1684: 
 1685:     result = parser.read_csv_check_warnings(
 1686:         FutureWarning,
 1687:         "use 'date_format' instead",
 1688:         StringIO(data),
 1689:         header=0,
 1690:         parse_dates={"ym": [0, 1]},
 1691:         date_parser=parse_function,
 1692:         raise_on_extra_warnings=False,
 1693:     )
 1694:     expected = DataFrame(
 1695:         [[date(2001, 1, 1), 10, 10.0], [date(2001, 2, 1), 1, 11.0]],
 1696:         columns=["ym", "day", "a"],
 1697:     )
 1698:     expected["ym"] = expected["ym"].astype("datetime64[ns]")
 1699:     tm.assert_frame_equal(result, expected)
 1700: 
 1701: 
 1702: @xfail_pyarrow
 1703: def test_date_parser_resolution_if_not_ns(all_parsers):
 1704:     # see gh-10245
 1705:     parser = all_parsers
 1706:     data = """\
 1707: date,time,prn,rxstatus
 1708: 2013-11-03,19:00:00,126,00E80000
 1709: 2013-11-03,19:00:00,23,00E80000
 1710: 2013-11-03,19:00:00,13,00E80000
 1711: """
 1712: 
 1713:     def date_parser(dt, time):
 1714:         try:
 1715:             arr = dt + "T" + time
 1716:         except TypeError:
 1717:             # dt & time are date/time objects
 1718:             arr = [datetime.combine(d, t) for d, t in zip(dt, time)]
 1719:         return np.array(arr, dtype="datetime64[s]")
 1720: 
 1721:     result = parser.read_csv_check_warnings(
 1722:         FutureWarning,
 1723:         "use 'date_format' instead",
 1724:         StringIO(data),
 1725:         date_parser=date_parser,
 1726:         parse_dates={"datetime": ["date", "time"]},
 1727:         index_col=["datetime", "prn"],
 1728:     )
 1729: 
 1730:     datetimes = np.array(["2013-11-03T19:00:00"] * 3, dtype="datetime64[s]")
 1731:     expected = DataFrame(
 1732:         data={"rxstatus": ["00E80000"] * 3},
 1733:         index=MultiIndex.from_arrays(
 1734:             [datetimes, [126, 23, 13]],
 1735:             names=["datetime", "prn"],
 1736:         ),
 1737:     )
 1738:     tm.assert_frame_equal(result, expected)
 1739: 
 1740: 
 1741: def test_parse_date_column_with_empty_string(all_parsers):
 1742:     # see gh-6428
 1743:     parser = all_parsers
 1744:     data = "case,opdate\n7,10/18/2006\n7,10/18/2008\n621, "
 1745:     result = parser.read_csv(StringIO(data), parse_dates=["opdate"])
 1746: 
 1747:     expected_data = [[7, "10/18/2006"], [7, "10/18/2008"], [621, " "]]
 1748:     expected = DataFrame(expected_data, columns=["case", "opdate"])
 1749:     tm.assert_frame_equal(result, expected)
 1750: 
 1751: 
 1752: @pytest.mark.parametrize(
 1753:     "data,expected",
 1754:     [
 1755:         (
 1756:             "a\n135217135789158401\n1352171357E+5",
 1757:             DataFrame({"a": [135217135789158401, 135217135700000]}, dtype="float64"),
 1758:         ),
 1759:         (
 1760:             "a\n99999999999\n123456789012345\n1234E+0",
 1761:             DataFrame({"a": [99999999999, 123456789012345, 1234]}, dtype="float64"),
 1762:         ),
 1763:     ],
 1764: )
 1765: @pytest.mark.parametrize("parse_dates", [True, False])
 1766: def test_parse_date_float(all_parsers, data, expected, parse_dates):
 1767:     # see gh-2697
 1768:     #
 1769:     # Date parsing should fail, so we leave the data untouched
 1770:     # (i.e. float precision should remain unchanged).
 1771:     parser = all_parsers
 1772: 
 1773:     result = parser.read_csv(StringIO(data), parse_dates=parse_dates)
 1774:     tm.assert_frame_equal(result, expected)
 1775: 
 1776: 
 1777: def test_parse_timezone(all_parsers):
 1778:     # see gh-22256
 1779:     parser = all_parsers
 1780:     data = """dt,val
 1781:               2018-01-04 09:01:00+09:00,23350
 1782:               2018-01-04 09:02:00+09:00,23400
 1783:               2018-01-04 09:03:00+09:00,23400
 1784:               2018-01-04 09:04:00+09:00,23400
 1785:               2018-01-04 09:05:00+09:00,23400"""
 1786:     result = parser.read_csv(StringIO(data), parse_dates=["dt"])
 1787: 
 1788:     dti = date_range(
 1789:         start="2018-01-04 09:01:00",
 1790:         end="2018-01-04 09:05:00",
 1791:         freq="1min",
 1792:         tz=timezone(timedelta(minutes=540)),
 1793:     )._with_freq(None)
 1794:     expected_data = {"dt": dti, "val": [23350, 23400, 23400, 23400, 23400]}
 1795: 
 1796:     expected = DataFrame(expected_data)
 1797:     tm.assert_frame_equal(result, expected)
 1798: 
 1799: 
 1800: @skip_pyarrow  # pandas.errors.ParserError: CSV parse error
 1801: @pytest.mark.parametrize(
 1802:     "date_string",
 1803:     ["32/32/2019", "02/30/2019", "13/13/2019", "13/2019", "a3/11/2018", "10/11/2o17"],
 1804: )
 1805: def test_invalid_parse_delimited_date(all_parsers, date_string):
 1806:     parser = all_parsers
 1807:     expected = DataFrame({0: [date_string]}, dtype="object")
 1808:     result = parser.read_csv(
 1809:         StringIO(date_string),
 1810:         header=None,
 1811:         parse_dates=[0],
 1812:     )
 1813:     tm.assert_frame_equal(result, expected)
 1814: 
 1815: 
 1816: @pytest.mark.parametrize(
 1817:     "date_string,dayfirst,expected",
 1818:     [
 1819:         # %d/%m/%Y; month > 12 thus replacement
 1820:         ("13/02/2019", True, datetime(2019, 2, 13)),
 1821:         # %m/%d/%Y; day > 12 thus there will be no replacement
 1822:         ("02/13/2019", False, datetime(2019, 2, 13)),
 1823:         # %d/%m/%Y; dayfirst==True thus replacement
 1824:         ("04/02/2019", True, datetime(2019, 2, 4)),
 1825:     ],
 1826: )
 1827: def test_parse_delimited_date_swap_no_warning(
 1828:     all_parsers, date_string, dayfirst, expected, request
 1829: ):
 1830:     parser = all_parsers
 1831:     expected = DataFrame({0: [expected]}, dtype="datetime64[ns]")
 1832:     if parser.engine == "pyarrow":
 1833:         if not dayfirst:
 1834:             # "CSV parse error: Empty CSV file or block"
 1835:             pytest.skip(reason="https://github.com/apache/arrow/issues/38676")
 1836:         msg = "The 'dayfirst' option is not supported with the 'pyarrow' engine"
 1837:         with pytest.raises(ValueError, match=msg):
 1838:             parser.read_csv(
 1839:                 StringIO(date_string), header=None, dayfirst=dayfirst, parse_dates=[0]
 1840:             )
 1841:         return
 1842: 
 1843:     result = parser.read_csv(
 1844:         StringIO(date_string), header=None, dayfirst=dayfirst, parse_dates=[0]
 1845:     )
 1846:     tm.assert_frame_equal(result, expected)
 1847: 
 1848: 
 1849: # ArrowInvalid: CSV parse error: Empty CSV file or block: cannot infer number of columns
 1850: @skip_pyarrow
 1851: @pytest.mark.parametrize(
 1852:     "date_string,dayfirst,expected",
 1853:     [
 1854:         # %d/%m/%Y; month > 12
 1855:         ("13/02/2019", False, datetime(2019, 2, 13)),
 1856:         # %m/%d/%Y; day > 12
 1857:         ("02/13/2019", True, datetime(2019, 2, 13)),
 1858:     ],
 1859: )
 1860: def test_parse_delimited_date_swap_with_warning(
 1861:     all_parsers, date_string, dayfirst, expected
 1862: ):
 1863:     parser = all_parsers
 1864:     expected = DataFrame({0: [expected]}, dtype="datetime64[ns]")
 1865:     warning_msg = (
 1866:         "Parsing dates in .* format when dayfirst=.* was specified. "
 1867:         "Pass `dayfirst=.*` or specify a format to silence this warning."
 1868:     )
 1869:     result = parser.read_csv_check_warnings(
 1870:         UserWarning,
 1871:         warning_msg,
 1872:         StringIO(date_string),
 1873:         header=None,
 1874:         dayfirst=dayfirst,
 1875:         parse_dates=[0],
 1876:     )
 1877:     tm.assert_frame_equal(result, expected)
 1878: 
 1879: 
 1880: def test_parse_multiple_delimited_dates_with_swap_warnings():
 1881:     # GH46210
 1882:     with pytest.raises(
 1883:         ValueError,
 1884:         match=(
 1885:             r'^time data "31/05/2000" doesn\'t match format "%m/%d/%Y", '
 1886:             r"at position 1. You might want to try:"
 1887:         ),
 1888:     ):
 1889:         pd.to_datetime(["01/01/2000", "31/05/2000", "31/05/2001", "01/02/2000"])
 1890: 
 1891: 
 1892: # ArrowKeyError: Column 'fdate1' in include_columns does not exist in CSV file
 1893: @skip_pyarrow
 1894: @pytest.mark.parametrize(
 1895:     "names, usecols, parse_dates, missing_cols",
 1896:     [
 1897:         (None, ["val"], ["date", "time"], "date, time"),
 1898:         (None, ["val"], [0, "time"], "time"),
 1899:         (None, ["val"], [["date", "time"]], "date, time"),
 1900:         (None, ["val"], [[0, "time"]], "time"),
 1901:         (None, ["val"], {"date": [0, "time"]}, "time"),
 1902:         (None, ["val"], {"date": ["date", "time"]}, "date, time"),
 1903:         (None, ["val"], [["date", "time"], "date"], "date, time"),
 1904:         (["date1", "time1", "temperature"], None, ["date", "time"], "date, time"),
 1905:         (
 1906:             ["date1", "time1", "temperature"],
 1907:             ["date1", "temperature"],
 1908:             ["date1", "time"],
 1909:             "time",
 1910:         ),
 1911:     ],
 1912: )
 1913: def test_missing_parse_dates_column_raises(
 1914:     all_parsers, names, usecols, parse_dates, missing_cols
 1915: ):
 1916:     # gh-31251 column names provided in parse_dates could be missing.
 1917:     parser = all_parsers
 1918:     content = StringIO("date,time,val\n2020-01-31,04:20:32,32\n")
 1919:     msg = f"Missing column provided to 'parse_dates': '{missing_cols}'"
 1920: 
 1921:     depr_msg = (
 1922:         "Support for nested sequences for 'parse_dates' in pd.read_csv is deprecated"
 1923:     )
 1924:     warn = FutureWarning
 1925:     if isinstance(parse_dates, list) and all(
 1926:         isinstance(x, (int, str)) for x in parse_dates
 1927:     ):
 1928:         warn = None
 1929: 
 1930:     with pytest.raises(ValueError, match=msg):
 1931:         with tm.assert_produces_warning(warn, match=depr_msg, check_stacklevel=False):
 1932:             parser.read_csv(
 1933:                 content, sep=",", names=names, usecols=usecols, parse_dates=parse_dates
 1934:             )
 1935: 
 1936: 
 1937: @xfail_pyarrow  # mismatched shape
 1938: def test_date_parser_and_names(all_parsers):
 1939:     # GH#33699
 1940:     parser = all_parsers
 1941:     data = StringIO("""x,y\n1,2""")
 1942:     warn = UserWarning
 1943:     if parser.engine == "pyarrow":
 1944:         # DeprecationWarning for passing a Manager object
 1945:         warn = (UserWarning, DeprecationWarning)
 1946:     result = parser.read_csv_check_warnings(
 1947:         warn,
 1948:         "Could not infer format",
 1949:         data,
 1950:         parse_dates=["B"],
 1951:         names=["B"],
 1952:     )
 1953:     expected = DataFrame({"B": ["y", "2"]}, index=["x", "1"])
 1954:     tm.assert_frame_equal(result, expected)
 1955: 
 1956: 
 1957: @xfail_pyarrow  # TypeError: an integer is required
 1958: def test_date_parser_multiindex_columns(all_parsers):
 1959:     parser = all_parsers
 1960:     data = """a,b
 1961: 1,2
 1962: 2019-12-31,6"""
 1963:     result = parser.read_csv(StringIO(data), parse_dates=[("a", "1")], header=[0, 1])
 1964:     expected = DataFrame(
 1965:         {("a", "1"): Timestamp("2019-12-31").as_unit("ns"), ("b", "2"): [6]}
 1966:     )
 1967:     tm.assert_frame_equal(result, expected)
 1968: 
 1969: 
 1970: @xfail_pyarrow  # TypeError: an integer is required
 1971: @pytest.mark.parametrize(
 1972:     "parse_spec, col_name",
 1973:     [
 1974:         ([[("a", "1"), ("b", "2")]], ("a_b", "1_2")),
 1975:         ({("foo", "1"): [("a", "1"), ("b", "2")]}, ("foo", "1")),
 1976:     ],
 1977: )
 1978: def test_date_parser_multiindex_columns_combine_cols(all_parsers, parse_spec, col_name):
 1979:     parser = all_parsers
 1980:     data = """a,b,c
 1981: 1,2,3
 1982: 2019-12,-31,6"""
 1983: 
 1984:     depr_msg = (
 1985:         "Support for nested sequences for 'parse_dates' in pd.read_csv is deprecated"
 1986:     )
 1987:     with tm.assert_produces_warning(
 1988:         FutureWarning, match=depr_msg, check_stacklevel=False
 1989:     ):
 1990:         result = parser.read_csv(
 1991:             StringIO(data),
 1992:             parse_dates=parse_spec,
 1993:             header=[0, 1],
 1994:         )
 1995:     expected = DataFrame(
 1996:         {col_name: Timestamp("2019-12-31").as_unit("ns"), ("c", "3"): [6]}
 1997:     )
 1998:     tm.assert_frame_equal(result, expected)
 1999: 
 2000: 
 2001: def test_date_parser_usecols_thousands(all_parsers):
 2002:     # GH#39365
 2003:     data = """A,B,C
 2004:     1,3,20-09-01-01
 2005:     2,4,20-09-01-01
 2006:     """
 2007: 
 2008:     parser = all_parsers
 2009: 
 2010:     if parser.engine == "pyarrow":
 2011:         # DeprecationWarning for passing a Manager object
 2012:         msg = "The 'thousands' option is not supported with the 'pyarrow' engine"
 2013:         with pytest.raises(ValueError, match=msg):
 2014:             parser.read_csv(
 2015:                 StringIO(data),
 2016:                 parse_dates=[1],
 2017:                 usecols=[1, 2],
 2018:                 thousands="-",
 2019:             )
 2020:         return
 2021: 
 2022:     result = parser.read_csv_check_warnings(
 2023:         UserWarning,
 2024:         "Could not infer format",
 2025:         StringIO(data),
 2026:         parse_dates=[1],
 2027:         usecols=[1, 2],
 2028:         thousands="-",
 2029:     )
 2030:     expected = DataFrame({"B": [3, 4], "C": [Timestamp("20-09-2001 01:00:00")] * 2})
 2031:     tm.assert_frame_equal(result, expected)
 2032: 
 2033: 
 2034: @xfail_pyarrow  # mismatched shape
 2035: def test_parse_dates_and_keep_original_column(all_parsers):
 2036:     # GH#13378
 2037:     parser = all_parsers
 2038:     data = """A
 2039: 20150908
 2040: 20150909
 2041: """
 2042:     depr_msg = "The 'keep_date_col' keyword in pd.read_csv is deprecated"
 2043:     with tm.assert_produces_warning(
 2044:         FutureWarning, match=depr_msg, check_stacklevel=False
 2045:     ):
 2046:         result = parser.read_csv(
 2047:             StringIO(data), parse_dates={"date": ["A"]}, keep_date_col=True
 2048:         )
 2049:     expected_data = [Timestamp("2015-09-08"), Timestamp("2015-09-09")]
 2050:     expected = DataFrame({"date": expected_data, "A": expected_data})
 2051:     tm.assert_frame_equal(result, expected)
 2052: 
 2053: 
 2054: def test_dayfirst_warnings():
 2055:     # GH 12585
 2056: 
 2057:     # CASE 1: valid input
 2058:     input = "date\n31/12/2014\n10/03/2011"
 2059:     expected = DatetimeIndex(
 2060:         ["2014-12-31", "2011-03-10"], dtype="datetime64[ns]", freq=None, name="date"
 2061:     )
 2062:     warning_msg = (
 2063:         "Parsing dates in .* format when dayfirst=.* was specified. "
 2064:         "Pass `dayfirst=.*` or specify a format to silence this warning."
 2065:     )
 2066: 
 2067:     # A. dayfirst arg correct, no warning
 2068:     res1 = read_csv(
 2069:         StringIO(input), parse_dates=["date"], dayfirst=True, index_col="date"
 2070:     ).index
 2071:     tm.assert_index_equal(expected, res1)
 2072: 
 2073:     # B. dayfirst arg incorrect, warning
 2074:     with tm.assert_produces_warning(UserWarning, match=warning_msg):
 2075:         res2 = read_csv(
 2076:             StringIO(input), parse_dates=["date"], dayfirst=False, index_col="date"
 2077:         ).index
 2078:     tm.assert_index_equal(expected, res2)
 2079: 
 2080:     # CASE 2: invalid input
 2081:     # cannot consistently process with single format
 2082:     # return to user unaltered
 2083: 
 2084:     # first in DD/MM/YYYY, second in MM/DD/YYYY
 2085:     input = "date\n31/12/2014\n03/30/2011"
 2086:     expected = Index(["31/12/2014", "03/30/2011"], dtype="object", name="date")
 2087: 
 2088:     # A. use dayfirst=True
 2089:     res5 = read_csv(
 2090:         StringIO(input), parse_dates=["date"], dayfirst=True, index_col="date"
 2091:     ).index
 2092:     tm.assert_index_equal(expected, res5)
 2093: 
 2094:     # B. use dayfirst=False
 2095:     with tm.assert_produces_warning(UserWarning, match=warning_msg):
 2096:         res6 = read_csv(
 2097:             StringIO(input), parse_dates=["date"], dayfirst=False, index_col="date"
 2098:         ).index
 2099:     tm.assert_index_equal(expected, res6)
 2100: 
 2101: 
 2102: @pytest.mark.parametrize(
 2103:     "date_string, dayfirst",
 2104:     [
 2105:         pytest.param(
 2106:             "31/1/2014",
 2107:             False,
 2108:             id="second date is single-digit",
 2109:         ),
 2110:         pytest.param(
 2111:             "1/31/2014",
 2112:             True,
 2113:             id="first date is single-digit",
 2114:         ),
 2115:     ],
 2116: )
 2117: def test_dayfirst_warnings_no_leading_zero(date_string, dayfirst):
 2118:     # GH47880
 2119:     initial_value = f"date\n{date_string}"
 2120:     expected = DatetimeIndex(
 2121:         ["2014-01-31"], dtype="datetime64[ns]", freq=None, name="date"
 2122:     )
 2123:     warning_msg = (
 2124:         "Parsing dates in .* format when dayfirst=.* was specified. "
 2125:         "Pass `dayfirst=.*` or specify a format to silence this warning."
 2126:     )
 2127:     with tm.assert_produces_warning(UserWarning, match=warning_msg):
 2128:         res = read_csv(
 2129:             StringIO(initial_value),
 2130:             parse_dates=["date"],
 2131:             index_col="date",
 2132:             dayfirst=dayfirst,
 2133:         ).index
 2134:     tm.assert_index_equal(expected, res)
 2135: 
 2136: 
 2137: @skip_pyarrow  # CSV parse error: Expected 3 columns, got 4
 2138: def test_infer_first_column_as_index(all_parsers):
 2139:     # GH#11019
 2140:     parser = all_parsers
 2141:     data = "a,b,c\n1970-01-01,2,3,4"
 2142:     result = parser.read_csv(
 2143:         StringIO(data),
 2144:         parse_dates=["a"],
 2145:     )
 2146:     expected = DataFrame({"a": "2", "b": 3, "c": 4}, index=["1970-01-01"])
 2147:     tm.assert_frame_equal(result, expected)
 2148: 
 2149: 
 2150: @xfail_pyarrow  # pyarrow engine doesn't support passing a dict for na_values
 2151: @pytest.mark.parametrize(
 2152:     ("key", "value", "warn"),
 2153:     [
 2154:         ("date_parser", lambda x: pd.to_datetime(x, format="%Y-%m-%d"), FutureWarning),
 2155:         ("date_format", "%Y-%m-%d", None),
 2156:     ],
 2157: )
 2158: def test_replace_nans_before_parsing_dates(all_parsers, key, value, warn):
 2159:     # GH#26203
 2160:     parser = all_parsers
 2161:     data = """Test
 2162: 2012-10-01
 2163: 0
 2164: 2015-05-15
 2165: #
 2166: 2017-09-09
 2167: """
 2168:     result = parser.read_csv_check_warnings(
 2169:         warn,
 2170:         "use 'date_format' instead",
 2171:         StringIO(data),
 2172:         na_values={"Test": ["#", "0"]},
 2173:         parse_dates=["Test"],
 2174:         **{key: value},
 2175:     )
 2176:     expected = DataFrame(
 2177:         {
 2178:             "Test": [
 2179:                 Timestamp("2012-10-01"),
 2180:                 pd.NaT,
 2181:                 Timestamp("2015-05-15"),
 2182:                 pd.NaT,
 2183:                 Timestamp("2017-09-09"),
 2184:             ]
 2185:         }
 2186:     )
 2187:     tm.assert_frame_equal(result, expected)
 2188: 
 2189: 
 2190: @xfail_pyarrow  # string[python] instead of dt64[ns]
 2191: def test_parse_dates_and_string_dtype(all_parsers):
 2192:     # GH#34066
 2193:     parser = all_parsers
 2194:     data = """a,b
 2195: 1,2019-12-31
 2196: """
 2197:     result = parser.read_csv(StringIO(data), dtype="string", parse_dates=["b"])
 2198:     expected = DataFrame({"a": ["1"], "b": [Timestamp("2019-12-31")]})
 2199:     expected["a"] = expected["a"].astype("string")
 2200:     tm.assert_frame_equal(result, expected)
 2201: 
 2202: 
 2203: def test_parse_dot_separated_dates(all_parsers):
 2204:     # https://github.com/pandas-dev/pandas/issues/2586
 2205:     parser = all_parsers
 2206:     data = """a,b
 2207: 27.03.2003 14:55:00.000,1
 2208: 03.08.2003 15:20:00.000,2"""
 2209:     if parser.engine == "pyarrow":
 2210:         expected_index = Index(
 2211:             ["27.03.2003 14:55:00.000", "03.08.2003 15:20:00.000"],
 2212:             dtype="object",
 2213:             name="a",
 2214:         )
 2215:         warn = None
 2216:     else:
 2217:         expected_index = DatetimeIndex(
 2218:             ["2003-03-27 14:55:00", "2003-08-03 15:20:00"],
 2219:             dtype="datetime64[ns]",
 2220:             name="a",
 2221:         )
 2222:         warn = UserWarning
 2223:     msg = r"when dayfirst=False \(the default\) was specified"
 2224:     result = parser.read_csv_check_warnings(
 2225:         warn,
 2226:         msg,
 2227:         StringIO(data),
 2228:         parse_dates=True,
 2229:         index_col=0,
 2230:         raise_on_extra_warnings=False,
 2231:     )
 2232:     expected = DataFrame({"b": [1, 2]}, index=expected_index)
 2233:     tm.assert_frame_equal(result, expected)
 2234: 
 2235: 
 2236: def test_parse_dates_dict_format(all_parsers):
 2237:     # GH#51240
 2238:     parser = all_parsers
 2239:     data = """a,b
 2240: 2019-12-31,31-12-2019
 2241: 2020-12-31,31-12-2020"""
 2242: 
 2243:     result = parser.read_csv(
 2244:         StringIO(data),
 2245:         date_format={"a": "%Y-%m-%d", "b": "%d-%m-%Y"},
 2246:         parse_dates=["a", "b"],
 2247:     )
 2248:     expected = DataFrame(
 2249:         {
 2250:             "a": [Timestamp("2019-12-31"), Timestamp("2020-12-31")],
 2251:             "b": [Timestamp("2019-12-31"), Timestamp("2020-12-31")],
 2252:         }
 2253:     )
 2254:     tm.assert_frame_equal(result, expected)
 2255: 
 2256: 
 2257: @pytest.mark.parametrize(
 2258:     "key, parse_dates", [("a_b", [[0, 1]]), ("foo", {"foo": [0, 1]})]
 2259: )
 2260: def test_parse_dates_dict_format_two_columns(all_parsers, key, parse_dates):
 2261:     # GH#51240
 2262:     parser = all_parsers
 2263:     data = """a,b
 2264: 31-,12-2019
 2265: 31-,12-2020"""
 2266: 
 2267:     depr_msg = (
 2268:         "Support for nested sequences for 'parse_dates' in pd.read_csv is deprecated"
 2269:     )
 2270:     with tm.assert_produces_warning(
 2271:         (FutureWarning, DeprecationWarning), match=depr_msg, check_stacklevel=False
 2272:     ):
 2273:         result = parser.read_csv(
 2274:             StringIO(data), date_format={key: "%d- %m-%Y"}, parse_dates=parse_dates
 2275:         )
 2276:     expected = DataFrame(
 2277:         {
 2278:             key: [Timestamp("2019-12-31"), Timestamp("2020-12-31")],
 2279:         }
 2280:     )
 2281:     tm.assert_frame_equal(result, expected)
 2282: 
 2283: 
 2284: @xfail_pyarrow  # object dtype index
 2285: def test_parse_dates_dict_format_index(all_parsers):
 2286:     # GH#51240
 2287:     parser = all_parsers
 2288:     data = """a,b
 2289: 2019-12-31,31-12-2019
 2290: 2020-12-31,31-12-2020"""
 2291: 
 2292:     result = parser.read_csv(
 2293:         StringIO(data), date_format={"a": "%Y-%m-%d"}, parse_dates=True, index_col=0
 2294:     )
 2295:     expected = DataFrame(
 2296:         {
 2297:             "b": ["31-12-2019", "31-12-2020"],
 2298:         },
 2299:         index=Index([Timestamp("2019-12-31"), Timestamp("2020-12-31")], name="a"),
 2300:     )
 2301:     tm.assert_frame_equal(result, expected)
 2302: 
 2303: 
 2304: def test_parse_dates_arrow_engine(all_parsers):
 2305:     # GH#53295
 2306:     parser = all_parsers
 2307:     data = """a,b
 2308: 2000-01-01 00:00:00,1
 2309: 2000-01-01 00:00:01,1"""
 2310: 
 2311:     result = parser.read_csv(StringIO(data), parse_dates=["a"])
 2312:     # TODO: make unit check more specific
 2313:     if parser.engine == "pyarrow":
 2314:         result["a"] = result["a"].dt.as_unit("ns")
 2315:     expected = DataFrame(
 2316:         {
 2317:             "a": [
 2318:                 Timestamp("2000-01-01 00:00:00"),
 2319:                 Timestamp("2000-01-01 00:00:01"),
 2320:             ],
 2321:             "b": 1,
 2322:         }
 2323:     )
 2324:     tm.assert_frame_equal(result, expected)
 2325: 
 2326: 
 2327: @xfail_pyarrow  # object dtype index
 2328: def test_from_csv_with_mixed_offsets(all_parsers):
 2329:     parser = all_parsers
 2330:     data = "a\n2020-01-01T00:00:00+01:00\n2020-01-01T00:00:00+00:00"
 2331:     result = parser.read_csv(StringIO(data), parse_dates=["a"])["a"]
 2332:     expected = Series(
 2333:         [
 2334:             Timestamp("2020-01-01 00:00:00+01:00"),
 2335:             Timestamp("2020-01-01 00:00:00+00:00"),
 2336:         ],
 2337:         name="a",
 2338:         index=[0, 1],
 2339:     )
 2340:     tm.assert_series_equal(result, expected)
