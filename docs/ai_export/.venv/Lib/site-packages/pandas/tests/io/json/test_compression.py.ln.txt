    1: from io import (
    2:     BytesIO,
    3:     StringIO,
    4: )
    5: 
    6: import pytest
    7: 
    8: import pandas.util._test_decorators as td
    9: 
   10: import pandas as pd
   11: import pandas._testing as tm
   12: 
   13: 
   14: def test_compression_roundtrip(compression):
   15:     df = pd.DataFrame(
   16:         [[0.123456, 0.234567, 0.567567], [12.32112, 123123.2, 321321.2]],
   17:         index=["A", "B"],
   18:         columns=["X", "Y", "Z"],
   19:     )
   20: 
   21:     with tm.ensure_clean() as path:
   22:         df.to_json(path, compression=compression)
   23:         tm.assert_frame_equal(df, pd.read_json(path, compression=compression))
   24: 
   25:         # explicitly ensure file was compressed.
   26:         with tm.decompress_file(path, compression) as fh:
   27:             result = fh.read().decode("utf8")
   28:             data = StringIO(result)
   29:         tm.assert_frame_equal(df, pd.read_json(data))
   30: 
   31: 
   32: def test_read_zipped_json(datapath):
   33:     uncompressed_path = datapath("io", "json", "data", "tsframe_v012.json")
   34:     uncompressed_df = pd.read_json(uncompressed_path)
   35: 
   36:     compressed_path = datapath("io", "json", "data", "tsframe_v012.json.zip")
   37:     compressed_df = pd.read_json(compressed_path, compression="zip")
   38: 
   39:     tm.assert_frame_equal(uncompressed_df, compressed_df)
   40: 
   41: 
   42: @td.skip_if_not_us_locale
   43: @pytest.mark.single_cpu
   44: def test_with_s3_url(compression, s3_public_bucket, s3so):
   45:     # Bucket created in tests/io/conftest.py
   46:     df = pd.read_json(StringIO('{"a": [1, 2, 3], "b": [4, 5, 6]}'))
   47: 
   48:     with tm.ensure_clean() as path:
   49:         df.to_json(path, compression=compression)
   50:         with open(path, "rb") as f:
   51:             s3_public_bucket.put_object(Key="test-1", Body=f)
   52: 
   53:     roundtripped_df = pd.read_json(
   54:         f"s3://{s3_public_bucket.name}/test-1",
   55:         compression=compression,
   56:         storage_options=s3so,
   57:     )
   58:     tm.assert_frame_equal(df, roundtripped_df)
   59: 
   60: 
   61: def test_lines_with_compression(compression):
   62:     with tm.ensure_clean() as path:
   63:         df = pd.read_json(StringIO('{"a": [1, 2, 3], "b": [4, 5, 6]}'))
   64:         df.to_json(path, orient="records", lines=True, compression=compression)
   65:         roundtripped_df = pd.read_json(path, lines=True, compression=compression)
   66:         tm.assert_frame_equal(df, roundtripped_df)
   67: 
   68: 
   69: def test_chunksize_with_compression(compression):
   70:     with tm.ensure_clean() as path:
   71:         df = pd.read_json(StringIO('{"a": ["foo", "bar", "baz"], "b": [4, 5, 6]}'))
   72:         df.to_json(path, orient="records", lines=True, compression=compression)
   73: 
   74:         with pd.read_json(
   75:             path, lines=True, chunksize=1, compression=compression
   76:         ) as res:
   77:             roundtripped_df = pd.concat(res)
   78:         tm.assert_frame_equal(df, roundtripped_df)
   79: 
   80: 
   81: def test_write_unsupported_compression_type():
   82:     df = pd.read_json(StringIO('{"a": [1, 2, 3], "b": [4, 5, 6]}'))
   83:     with tm.ensure_clean() as path:
   84:         msg = "Unrecognized compression type: unsupported"
   85:         with pytest.raises(ValueError, match=msg):
   86:             df.to_json(path, compression="unsupported")
   87: 
   88: 
   89: def test_read_unsupported_compression_type():
   90:     with tm.ensure_clean() as path:
   91:         msg = "Unrecognized compression type: unsupported"
   92:         with pytest.raises(ValueError, match=msg):
   93:             pd.read_json(path, compression="unsupported")
   94: 
   95: 
   96: @pytest.mark.parametrize(
   97:     "infer_string", [False, pytest.param(True, marks=td.skip_if_no("pyarrow"))]
   98: )
   99: @pytest.mark.parametrize("to_infer", [True, False])
  100: @pytest.mark.parametrize("read_infer", [True, False])
  101: def test_to_json_compression(
  102:     compression_only, read_infer, to_infer, compression_to_extension, infer_string
  103: ):
  104:     with pd.option_context("future.infer_string", infer_string):
  105:         # see gh-15008
  106:         compression = compression_only
  107: 
  108:         # We'll complete file extension subsequently.
  109:         filename = "test."
  110:         filename += compression_to_extension[compression]
  111: 
  112:         df = pd.DataFrame({"A": [1]})
  113: 
  114:         to_compression = "infer" if to_infer else compression
  115:         read_compression = "infer" if read_infer else compression
  116: 
  117:         with tm.ensure_clean(filename) as path:
  118:             df.to_json(path, compression=to_compression)
  119:             result = pd.read_json(path, compression=read_compression)
  120:             tm.assert_frame_equal(result, df)
  121: 
  122: 
  123: def test_to_json_compression_mode(compression):
  124:     # GH 39985 (read_json does not support user-provided binary files)
  125:     expected = pd.DataFrame({"A": [1]})
  126: 
  127:     with BytesIO() as buffer:
  128:         expected.to_json(buffer, compression=compression)
  129:         # df = pd.read_json(buffer, compression=compression)
  130:         # tm.assert_frame_equal(expected, df)
