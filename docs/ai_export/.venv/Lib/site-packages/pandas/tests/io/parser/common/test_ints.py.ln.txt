    1: """
    2: Tests that work on both the Python and C engines but do not have a
    3: specific classification into the other test modules.
    4: """
    5: from io import StringIO
    6: 
    7: import numpy as np
    8: import pytest
    9: 
   10: from pandas import (
   11:     DataFrame,
   12:     Series,
   13: )
   14: import pandas._testing as tm
   15: 
   16: pytestmark = pytest.mark.filterwarnings(
   17:     "ignore:Passing a BlockManager to DataFrame:DeprecationWarning"
   18: )
   19: 
   20: xfail_pyarrow = pytest.mark.usefixtures("pyarrow_xfail")
   21: skip_pyarrow = pytest.mark.usefixtures("pyarrow_skip")
   22: 
   23: 
   24: def test_int_conversion(all_parsers):
   25:     data = """A,B
   26: 1.0,1
   27: 2.0,2
   28: 3.0,3
   29: """
   30:     parser = all_parsers
   31:     result = parser.read_csv(StringIO(data))
   32: 
   33:     expected = DataFrame([[1.0, 1], [2.0, 2], [3.0, 3]], columns=["A", "B"])
   34:     tm.assert_frame_equal(result, expected)
   35: 
   36: 
   37: @pytest.mark.parametrize(
   38:     "data,kwargs,expected",
   39:     [
   40:         (
   41:             "A,B\nTrue,1\nFalse,2\nTrue,3",
   42:             {},
   43:             DataFrame([[True, 1], [False, 2], [True, 3]], columns=["A", "B"]),
   44:         ),
   45:         (
   46:             "A,B\nYES,1\nno,2\nyes,3\nNo,3\nYes,3",
   47:             {"true_values": ["yes", "Yes", "YES"], "false_values": ["no", "NO", "No"]},
   48:             DataFrame(
   49:                 [[True, 1], [False, 2], [True, 3], [False, 3], [True, 3]],
   50:                 columns=["A", "B"],
   51:             ),
   52:         ),
   53:         (
   54:             "A,B\nTRUE,1\nFALSE,2\nTRUE,3",
   55:             {},
   56:             DataFrame([[True, 1], [False, 2], [True, 3]], columns=["A", "B"]),
   57:         ),
   58:         (
   59:             "A,B\nfoo,bar\nbar,foo",
   60:             {"true_values": ["foo"], "false_values": ["bar"]},
   61:             DataFrame([[True, False], [False, True]], columns=["A", "B"]),
   62:         ),
   63:     ],
   64: )
   65: def test_parse_bool(all_parsers, data, kwargs, expected):
   66:     parser = all_parsers
   67:     result = parser.read_csv(StringIO(data), **kwargs)
   68:     tm.assert_frame_equal(result, expected)
   69: 
   70: 
   71: def test_parse_integers_above_fp_precision(all_parsers):
   72:     data = """Numbers
   73: 17007000002000191
   74: 17007000002000191
   75: 17007000002000191
   76: 17007000002000191
   77: 17007000002000192
   78: 17007000002000192
   79: 17007000002000192
   80: 17007000002000192
   81: 17007000002000192
   82: 17007000002000194"""
   83:     parser = all_parsers
   84:     result = parser.read_csv(StringIO(data))
   85:     expected = DataFrame(
   86:         {
   87:             "Numbers": [
   88:                 17007000002000191,
   89:                 17007000002000191,
   90:                 17007000002000191,
   91:                 17007000002000191,
   92:                 17007000002000192,
   93:                 17007000002000192,
   94:                 17007000002000192,
   95:                 17007000002000192,
   96:                 17007000002000192,
   97:                 17007000002000194,
   98:             ]
   99:         }
  100:     )
  101:     tm.assert_frame_equal(result, expected)
  102: 
  103: 
  104: @pytest.mark.parametrize("sep", [" ", r"\s+"])
  105: def test_integer_overflow_bug(all_parsers, sep):
  106:     # see gh-2601
  107:     data = "65248E10 11\n55555E55 22\n"
  108:     parser = all_parsers
  109:     if parser.engine == "pyarrow" and sep != " ":
  110:         msg = "the 'pyarrow' engine does not support regex separators"
  111:         with pytest.raises(ValueError, match=msg):
  112:             parser.read_csv(StringIO(data), header=None, sep=sep)
  113:         return
  114: 
  115:     result = parser.read_csv(StringIO(data), header=None, sep=sep)
  116:     expected = DataFrame([[6.5248e14, 11], [5.5555e59, 22]])
  117:     tm.assert_frame_equal(result, expected)
  118: 
  119: 
  120: def test_int64_min_issues(all_parsers):
  121:     # see gh-2599
  122:     parser = all_parsers
  123:     data = "A,B\n0,0\n0,"
  124:     result = parser.read_csv(StringIO(data))
  125: 
  126:     expected = DataFrame({"A": [0, 0], "B": [0, np.nan]})
  127:     tm.assert_frame_equal(result, expected)
  128: 
  129: 
  130: @pytest.mark.parametrize("conv", [None, np.int64, np.uint64])
  131: def test_int64_overflow(all_parsers, conv, request):
  132:     data = """ID
  133: 00013007854817840016671868
  134: 00013007854817840016749251
  135: 00013007854817840016754630
  136: 00013007854817840016781876
  137: 00013007854817840017028824
  138: 00013007854817840017963235
  139: 00013007854817840018860166"""
  140:     parser = all_parsers
  141: 
  142:     if conv is None:
  143:         # 13007854817840016671868 > UINT64_MAX, so this
  144:         # will overflow and return object as the dtype.
  145:         if parser.engine == "pyarrow":
  146:             mark = pytest.mark.xfail(reason="parses to float64")
  147:             request.applymarker(mark)
  148: 
  149:         result = parser.read_csv(StringIO(data))
  150:         expected = DataFrame(
  151:             [
  152:                 "00013007854817840016671868",
  153:                 "00013007854817840016749251",
  154:                 "00013007854817840016754630",
  155:                 "00013007854817840016781876",
  156:                 "00013007854817840017028824",
  157:                 "00013007854817840017963235",
  158:                 "00013007854817840018860166",
  159:             ],
  160:             columns=["ID"],
  161:         )
  162:         tm.assert_frame_equal(result, expected)
  163:     else:
  164:         # 13007854817840016671868 > UINT64_MAX, so attempts
  165:         # to cast to either int64 or uint64 will result in
  166:         # an OverflowError being raised.
  167:         msg = "|".join(
  168:             [
  169:                 "Python int too large to convert to C long",
  170:                 "long too big to convert",
  171:                 "int too big to convert",
  172:             ]
  173:         )
  174:         err = OverflowError
  175:         if parser.engine == "pyarrow":
  176:             err = ValueError
  177:             msg = "The 'converters' option is not supported with the 'pyarrow' engine"
  178: 
  179:         with pytest.raises(err, match=msg):
  180:             parser.read_csv(StringIO(data), converters={"ID": conv})
  181: 
  182: 
  183: @skip_pyarrow  # CSV parse error: Empty CSV file or block
  184: @pytest.mark.parametrize(
  185:     "val", [np.iinfo(np.uint64).max, np.iinfo(np.int64).max, np.iinfo(np.int64).min]
  186: )
  187: def test_int64_uint64_range(all_parsers, val):
  188:     # These numbers fall right inside the int64-uint64
  189:     # range, so they should be parsed as string.
  190:     parser = all_parsers
  191:     result = parser.read_csv(StringIO(str(val)), header=None)
  192: 
  193:     expected = DataFrame([val])
  194:     tm.assert_frame_equal(result, expected)
  195: 
  196: 
  197: @skip_pyarrow  # CSV parse error: Empty CSV file or block
  198: @pytest.mark.parametrize(
  199:     "val", [np.iinfo(np.uint64).max + 1, np.iinfo(np.int64).min - 1]
  200: )
  201: def test_outside_int64_uint64_range(all_parsers, val):
  202:     # These numbers fall just outside the int64-uint64
  203:     # range, so they should be parsed as string.
  204:     parser = all_parsers
  205:     result = parser.read_csv(StringIO(str(val)), header=None)
  206: 
  207:     expected = DataFrame([str(val)])
  208:     tm.assert_frame_equal(result, expected)
  209: 
  210: 
  211: @xfail_pyarrow  # gets float64 dtype instead of object
  212: @pytest.mark.parametrize("exp_data", [[str(-1), str(2**63)], [str(2**63), str(-1)]])
  213: def test_numeric_range_too_wide(all_parsers, exp_data):
  214:     # No numerical dtype can hold both negative and uint64
  215:     # values, so they should be cast as string.
  216:     parser = all_parsers
  217:     data = "\n".join(exp_data)
  218:     expected = DataFrame(exp_data)
  219: 
  220:     result = parser.read_csv(StringIO(data), header=None)
  221:     tm.assert_frame_equal(result, expected)
  222: 
  223: 
  224: def test_integer_precision(all_parsers):
  225:     # Gh 7072
  226:     s = """1,1;0;0;0;1;1;3844;3844;3844;1;1;1;1;1;1;0;0;1;1;0;0,,,4321583677327450765
  227: 5,1;0;0;0;1;1;843;843;843;1;1;1;1;1;1;0;0;1;1;0;0,64.0,;,4321113141090630389"""
  228:     parser = all_parsers
  229:     result = parser.read_csv(StringIO(s), header=None)[4]
  230:     expected = Series([4321583677327450765, 4321113141090630389], name=4)
  231:     tm.assert_series_equal(result, expected)
