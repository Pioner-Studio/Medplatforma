    1: import os
    2: 
    3: import numpy as np
    4: import pytest
    5: 
    6: from pandas.compat import (
    7:     PY311,
    8:     is_ci_environment,
    9:     is_platform_linux,
   10:     is_platform_little_endian,
   11: )
   12: from pandas.errors import (
   13:     ClosedFileError,
   14:     PossibleDataLossError,
   15: )
   16: 
   17: from pandas import (
   18:     DataFrame,
   19:     HDFStore,
   20:     Index,
   21:     Series,
   22:     _testing as tm,
   23:     date_range,
   24:     read_hdf,
   25: )
   26: from pandas.tests.io.pytables.common import (
   27:     _maybe_remove,
   28:     ensure_clean_store,
   29:     tables,
   30: )
   31: 
   32: from pandas.io import pytables
   33: from pandas.io.pytables import Term
   34: 
   35: pytestmark = pytest.mark.single_cpu
   36: 
   37: 
   38: @pytest.mark.parametrize("mode", ["r", "r+", "a", "w"])
   39: def test_mode(setup_path, tmp_path, mode):
   40:     df = DataFrame(
   41:         np.random.default_rng(2).standard_normal((10, 4)),
   42:         columns=Index(list("ABCD"), dtype=object),
   43:         index=date_range("2000-01-01", periods=10, freq="B"),
   44:     )
   45:     msg = r"[\S]* does not exist"
   46:     path = tmp_path / setup_path
   47: 
   48:     # constructor
   49:     if mode in ["r", "r+"]:
   50:         with pytest.raises(OSError, match=msg):
   51:             HDFStore(path, mode=mode)
   52: 
   53:     else:
   54:         with HDFStore(path, mode=mode) as store:
   55:             assert store._handle.mode == mode
   56: 
   57:     path = tmp_path / setup_path
   58: 
   59:     # context
   60:     if mode in ["r", "r+"]:
   61:         with pytest.raises(OSError, match=msg):
   62:             with HDFStore(path, mode=mode) as store:
   63:                 pass
   64:     else:
   65:         with HDFStore(path, mode=mode) as store:
   66:             assert store._handle.mode == mode
   67: 
   68:     path = tmp_path / setup_path
   69: 
   70:     # conv write
   71:     if mode in ["r", "r+"]:
   72:         with pytest.raises(OSError, match=msg):
   73:             df.to_hdf(path, key="df", mode=mode)
   74:         df.to_hdf(path, key="df", mode="w")
   75:     else:
   76:         df.to_hdf(path, key="df", mode=mode)
   77: 
   78:     # conv read
   79:     if mode in ["w"]:
   80:         msg = (
   81:             "mode w is not allowed while performing a read. "
   82:             r"Allowed modes are r, r\+ and a."
   83:         )
   84:         with pytest.raises(ValueError, match=msg):
   85:             read_hdf(path, "df", mode=mode)
   86:     else:
   87:         result = read_hdf(path, "df", mode=mode)
   88:         tm.assert_frame_equal(result, df)
   89: 
   90: 
   91: def test_default_mode(tmp_path, setup_path):
   92:     # read_hdf uses default mode
   93:     df = DataFrame(
   94:         np.random.default_rng(2).standard_normal((10, 4)),
   95:         columns=Index(list("ABCD"), dtype=object),
   96:         index=date_range("2000-01-01", periods=10, freq="B"),
   97:     )
   98:     path = tmp_path / setup_path
   99:     df.to_hdf(path, key="df", mode="w")
  100:     result = read_hdf(path, "df")
  101:     tm.assert_frame_equal(result, df)
  102: 
  103: 
  104: def test_reopen_handle(tmp_path, setup_path):
  105:     path = tmp_path / setup_path
  106: 
  107:     store = HDFStore(path, mode="a")
  108:     store["a"] = Series(
  109:         np.arange(10, dtype=np.float64), index=date_range("2020-01-01", periods=10)
  110:     )
  111: 
  112:     msg = (
  113:         r"Re-opening the file \[[\S]*\] with mode \[a\] will delete the "
  114:         "current file!"
  115:     )
  116:     # invalid mode change
  117:     with pytest.raises(PossibleDataLossError, match=msg):
  118:         store.open("w")
  119: 
  120:     store.close()
  121:     assert not store.is_open
  122: 
  123:     # truncation ok here
  124:     store.open("w")
  125:     assert store.is_open
  126:     assert len(store) == 0
  127:     store.close()
  128:     assert not store.is_open
  129: 
  130:     store = HDFStore(path, mode="a")
  131:     store["a"] = Series(
  132:         np.arange(10, dtype=np.float64), index=date_range("2020-01-01", periods=10)
  133:     )
  134: 
  135:     # reopen as read
  136:     store.open("r")
  137:     assert store.is_open
  138:     assert len(store) == 1
  139:     assert store._mode == "r"
  140:     store.close()
  141:     assert not store.is_open
  142: 
  143:     # reopen as append
  144:     store.open("a")
  145:     assert store.is_open
  146:     assert len(store) == 1
  147:     assert store._mode == "a"
  148:     store.close()
  149:     assert not store.is_open
  150: 
  151:     # reopen as append (again)
  152:     store.open("a")
  153:     assert store.is_open
  154:     assert len(store) == 1
  155:     assert store._mode == "a"
  156:     store.close()
  157:     assert not store.is_open
  158: 
  159: 
  160: def test_open_args(setup_path):
  161:     with tm.ensure_clean(setup_path) as path:
  162:         df = DataFrame(
  163:             1.1 * np.arange(120).reshape((30, 4)),
  164:             columns=Index(list("ABCD"), dtype=object),
  165:             index=Index([f"i-{i}" for i in range(30)], dtype=object),
  166:         )
  167: 
  168:         # create an in memory store
  169:         store = HDFStore(
  170:             path, mode="a", driver="H5FD_CORE", driver_core_backing_store=0
  171:         )
  172:         store["df"] = df
  173:         store.append("df2", df)
  174: 
  175:         tm.assert_frame_equal(store["df"], df)
  176:         tm.assert_frame_equal(store["df2"], df)
  177: 
  178:         store.close()
  179: 
  180:     # the file should not have actually been written
  181:     assert not os.path.exists(path)
  182: 
  183: 
  184: def test_flush(setup_path):
  185:     with ensure_clean_store(setup_path) as store:
  186:         store["a"] = Series(range(5))
  187:         store.flush()
  188:         store.flush(fsync=True)
  189: 
  190: 
  191: def test_complibs_default_settings(tmp_path, setup_path):
  192:     # GH15943
  193:     df = DataFrame(
  194:         1.1 * np.arange(120).reshape((30, 4)),
  195:         columns=Index(list("ABCD"), dtype=object),
  196:         index=Index([f"i-{i}" for i in range(30)], dtype=object),
  197:     )
  198: 
  199:     # Set complevel and check if complib is automatically set to
  200:     # default value
  201:     tmpfile = tmp_path / setup_path
  202:     df.to_hdf(tmpfile, key="df", complevel=9)
  203:     result = read_hdf(tmpfile, "df")
  204:     tm.assert_frame_equal(result, df)
  205: 
  206:     with tables.open_file(tmpfile, mode="r") as h5file:
  207:         for node in h5file.walk_nodes(where="/df", classname="Leaf"):
  208:             assert node.filters.complevel == 9
  209:             assert node.filters.complib == "zlib"
  210: 
  211:     # Set complib and check to see if compression is disabled
  212:     tmpfile = tmp_path / setup_path
  213:     df.to_hdf(tmpfile, key="df", complib="zlib")
  214:     result = read_hdf(tmpfile, "df")
  215:     tm.assert_frame_equal(result, df)
  216: 
  217:     with tables.open_file(tmpfile, mode="r") as h5file:
  218:         for node in h5file.walk_nodes(where="/df", classname="Leaf"):
  219:             assert node.filters.complevel == 0
  220:             assert node.filters.complib is None
  221: 
  222:     # Check if not setting complib or complevel results in no compression
  223:     tmpfile = tmp_path / setup_path
  224:     df.to_hdf(tmpfile, key="df")
  225:     result = read_hdf(tmpfile, "df")
  226:     tm.assert_frame_equal(result, df)
  227: 
  228:     with tables.open_file(tmpfile, mode="r") as h5file:
  229:         for node in h5file.walk_nodes(where="/df", classname="Leaf"):
  230:             assert node.filters.complevel == 0
  231:             assert node.filters.complib is None
  232: 
  233: 
  234: def test_complibs_default_settings_override(tmp_path, setup_path):
  235:     # Check if file-defaults can be overridden on a per table basis
  236:     df = DataFrame(
  237:         1.1 * np.arange(120).reshape((30, 4)),
  238:         columns=Index(list("ABCD"), dtype=object),
  239:         index=Index([f"i-{i}" for i in range(30)], dtype=object),
  240:     )
  241:     tmpfile = tmp_path / setup_path
  242:     store = HDFStore(tmpfile)
  243:     store.append("dfc", df, complevel=9, complib="blosc")
  244:     store.append("df", df)
  245:     store.close()
  246: 
  247:     with tables.open_file(tmpfile, mode="r") as h5file:
  248:         for node in h5file.walk_nodes(where="/df", classname="Leaf"):
  249:             assert node.filters.complevel == 0
  250:             assert node.filters.complib is None
  251:         for node in h5file.walk_nodes(where="/dfc", classname="Leaf"):
  252:             assert node.filters.complevel == 9
  253:             assert node.filters.complib == "blosc"
  254: 
  255: 
  256: @pytest.mark.parametrize("lvl", range(10))
  257: @pytest.mark.parametrize("lib", tables.filters.all_complibs)
  258: @pytest.mark.filterwarnings("ignore:object name is not a valid")
  259: @pytest.mark.skipif(
  260:     not PY311 and is_ci_environment() and is_platform_linux(),
  261:     reason="Segfaulting in a CI environment"
  262:     # with xfail, would sometimes raise UnicodeDecodeError
  263:     # invalid state byte
  264: )
  265: def test_complibs(tmp_path, lvl, lib, request):
  266:     # GH14478
  267:     if PY311 and is_platform_linux() and lib == "blosc2" and lvl != 0:
  268:         request.applymarker(
  269:             pytest.mark.xfail(reason=f"Fails for {lib} on Linux and PY > 3.11")
  270:         )
  271:     df = DataFrame(
  272:         np.ones((30, 4)), columns=list("ABCD"), index=np.arange(30).astype(np.str_)
  273:     )
  274: 
  275:     # Remove lzo if its not available on this platform
  276:     if not tables.which_lib_version("lzo"):
  277:         pytest.skip("lzo not available")
  278:     # Remove bzip2 if its not available on this platform
  279:     if not tables.which_lib_version("bzip2"):
  280:         pytest.skip("bzip2 not available")
  281: 
  282:     tmpfile = tmp_path / f"{lvl}_{lib}.h5"
  283:     gname = f"{lvl}_{lib}"
  284: 
  285:     # Write and read file to see if data is consistent
  286:     df.to_hdf(tmpfile, key=gname, complib=lib, complevel=lvl)
  287:     result = read_hdf(tmpfile, gname)
  288:     tm.assert_frame_equal(result, df)
  289: 
  290:     # Open file and check metadata for correct amount of compression
  291:     with tables.open_file(tmpfile, mode="r") as h5table:
  292:         for node in h5table.walk_nodes(where="/" + gname, classname="Leaf"):
  293:             assert node.filters.complevel == lvl
  294:             if lvl == 0:
  295:                 assert node.filters.complib is None
  296:             else:
  297:                 assert node.filters.complib == lib
  298: 
  299: 
  300: @pytest.mark.skipif(
  301:     not is_platform_little_endian(), reason="reason platform is not little endian"
  302: )
  303: def test_encoding(setup_path):
  304:     with ensure_clean_store(setup_path) as store:
  305:         df = DataFrame({"A": "foo", "B": "bar"}, index=range(5))
  306:         df.loc[2, "A"] = np.nan
  307:         df.loc[3, "B"] = np.nan
  308:         _maybe_remove(store, "df")
  309:         store.append("df", df, encoding="ascii")
  310:         tm.assert_frame_equal(store["df"], df)
  311: 
  312:         expected = df.reindex(columns=["A"])
  313:         result = store.select("df", Term("columns=A", encoding="ascii"))
  314:         tm.assert_frame_equal(result, expected)
  315: 
  316: 
  317: @pytest.mark.parametrize(
  318:     "val",
  319:     [
  320:         [b"E\xc9, 17", b"", b"a", b"b", b"c"],
  321:         [b"E\xc9, 17", b"a", b"b", b"c"],
  322:         [b"EE, 17", b"", b"a", b"b", b"c"],
  323:         [b"E\xc9, 17", b"\xf8\xfc", b"a", b"b", b"c"],
  324:         [b"", b"a", b"b", b"c"],
  325:         [b"\xf8\xfc", b"a", b"b", b"c"],
  326:         [b"A\xf8\xfc", b"", b"a", b"b", b"c"],
  327:         [np.nan, b"", b"b", b"c"],
  328:         [b"A\xf8\xfc", np.nan, b"", b"b", b"c"],
  329:     ],
  330: )
  331: @pytest.mark.parametrize("dtype", ["category", object])
  332: def test_latin_encoding(tmp_path, setup_path, dtype, val):
  333:     enc = "latin-1"
  334:     nan_rep = ""
  335:     key = "data"
  336: 
  337:     val = [x.decode(enc) if isinstance(x, bytes) else x for x in val]
  338:     ser = Series(val, dtype=dtype)
  339: 
  340:     store = tmp_path / setup_path
  341:     ser.to_hdf(store, key=key, format="table", encoding=enc, nan_rep=nan_rep)
  342:     retr = read_hdf(store, key)
  343: 
  344:     # TODO:(3.0): once Categorical replace deprecation is enforced,
  345:     #  we may be able to re-simplify the construction of s_nan
  346:     if dtype == "category":
  347:         if nan_rep in ser.cat.categories:
  348:             s_nan = ser.cat.remove_categories([nan_rep])
  349:         else:
  350:             s_nan = ser
  351:     else:
  352:         s_nan = ser.replace(nan_rep, np.nan)
  353: 
  354:     tm.assert_series_equal(s_nan, retr)
  355: 
  356: 
  357: def test_multiple_open_close(tmp_path, setup_path):
  358:     # gh-4409: open & close multiple times
  359: 
  360:     path = tmp_path / setup_path
  361: 
  362:     df = DataFrame(
  363:         1.1 * np.arange(120).reshape((30, 4)),
  364:         columns=Index(list("ABCD"), dtype=object),
  365:         index=Index([f"i-{i}" for i in range(30)], dtype=object),
  366:     )
  367:     df.to_hdf(path, key="df", mode="w", format="table")
  368: 
  369:     # single
  370:     store = HDFStore(path)
  371:     assert "CLOSED" not in store.info()
  372:     assert store.is_open
  373: 
  374:     store.close()
  375:     assert "CLOSED" in store.info()
  376:     assert not store.is_open
  377: 
  378:     path = tmp_path / setup_path
  379: 
  380:     if pytables._table_file_open_policy_is_strict:
  381:         # multiples
  382:         store1 = HDFStore(path)
  383:         msg = (
  384:             r"The file [\S]* is already opened\.  Please close it before "
  385:             r"reopening in write mode\."
  386:         )
  387:         with pytest.raises(ValueError, match=msg):
  388:             HDFStore(path)
  389: 
  390:         store1.close()
  391:     else:
  392:         # multiples
  393:         store1 = HDFStore(path)
  394:         store2 = HDFStore(path)
  395: 
  396:         assert "CLOSED" not in store1.info()
  397:         assert "CLOSED" not in store2.info()
  398:         assert store1.is_open
  399:         assert store2.is_open
  400: 
  401:         store1.close()
  402:         assert "CLOSED" in store1.info()
  403:         assert not store1.is_open
  404:         assert "CLOSED" not in store2.info()
  405:         assert store2.is_open
  406: 
  407:         store2.close()
  408:         assert "CLOSED" in store1.info()
  409:         assert "CLOSED" in store2.info()
  410:         assert not store1.is_open
  411:         assert not store2.is_open
  412: 
  413:         # nested close
  414:         store = HDFStore(path, mode="w")
  415:         store.append("df", df)
  416: 
  417:         store2 = HDFStore(path)
  418:         store2.append("df2", df)
  419:         store2.close()
  420:         assert "CLOSED" in store2.info()
  421:         assert not store2.is_open
  422: 
  423:         store.close()
  424:         assert "CLOSED" in store.info()
  425:         assert not store.is_open
  426: 
  427:         # double closing
  428:         store = HDFStore(path, mode="w")
  429:         store.append("df", df)
  430: 
  431:         store2 = HDFStore(path)
  432:         store.close()
  433:         assert "CLOSED" in store.info()
  434:         assert not store.is_open
  435: 
  436:         store2.close()
  437:         assert "CLOSED" in store2.info()
  438:         assert not store2.is_open
  439: 
  440:     # ops on a closed store
  441:     path = tmp_path / setup_path
  442: 
  443:     df = DataFrame(
  444:         1.1 * np.arange(120).reshape((30, 4)),
  445:         columns=Index(list("ABCD"), dtype=object),
  446:         index=Index([f"i-{i}" for i in range(30)], dtype=object),
  447:     )
  448:     df.to_hdf(path, key="df", mode="w", format="table")
  449: 
  450:     store = HDFStore(path)
  451:     store.close()
  452: 
  453:     msg = r"[\S]* file is not open!"
  454:     with pytest.raises(ClosedFileError, match=msg):
  455:         store.keys()
  456: 
  457:     with pytest.raises(ClosedFileError, match=msg):
  458:         "df" in store
  459: 
  460:     with pytest.raises(ClosedFileError, match=msg):
  461:         len(store)
  462: 
  463:     with pytest.raises(ClosedFileError, match=msg):
  464:         store["df"]
  465: 
  466:     with pytest.raises(ClosedFileError, match=msg):
  467:         store.select("df")
  468: 
  469:     with pytest.raises(ClosedFileError, match=msg):
  470:         store.get("df")
  471: 
  472:     with pytest.raises(ClosedFileError, match=msg):
  473:         store.append("df2", df)
  474: 
  475:     with pytest.raises(ClosedFileError, match=msg):
  476:         store.put("df3", df)
  477: 
  478:     with pytest.raises(ClosedFileError, match=msg):
  479:         store.get_storer("df2")
  480: 
  481:     with pytest.raises(ClosedFileError, match=msg):
  482:         store.remove("df2")
  483: 
  484:     with pytest.raises(ClosedFileError, match=msg):
  485:         store.select("df")
  486: 
  487:     msg = "'HDFStore' object has no attribute 'df'"
  488:     with pytest.raises(AttributeError, match=msg):
  489:         store.df
  490: 
  491: 
  492: def test_fspath():
  493:     with tm.ensure_clean("foo.h5") as path:
  494:         with HDFStore(path) as store:
  495:             assert os.fspath(store) == str(path)
