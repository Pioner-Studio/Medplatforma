    1: import json
    2: 
    3: import numpy as np
    4: import pytest
    5: 
    6: from pandas import (
    7:     DataFrame,
    8:     Index,
    9:     Series,
   10:     json_normalize,
   11: )
   12: import pandas._testing as tm
   13: 
   14: from pandas.io.json._normalize import nested_to_record
   15: 
   16: 
   17: @pytest.fixture
   18: def deep_nested():
   19:     # deeply nested data
   20:     return [
   21:         {
   22:             "country": "USA",
   23:             "states": [
   24:                 {
   25:                     "name": "California",
   26:                     "cities": [
   27:                         {"name": "San Francisco", "pop": 12345},
   28:                         {"name": "Los Angeles", "pop": 12346},
   29:                     ],
   30:                 },
   31:                 {
   32:                     "name": "Ohio",
   33:                     "cities": [
   34:                         {"name": "Columbus", "pop": 1234},
   35:                         {"name": "Cleveland", "pop": 1236},
   36:                     ],
   37:                 },
   38:             ],
   39:         },
   40:         {
   41:             "country": "Germany",
   42:             "states": [
   43:                 {"name": "Bayern", "cities": [{"name": "Munich", "pop": 12347}]},
   44:                 {
   45:                     "name": "Nordrhein-Westfalen",
   46:                     "cities": [
   47:                         {"name": "Duesseldorf", "pop": 1238},
   48:                         {"name": "Koeln", "pop": 1239},
   49:                     ],
   50:                 },
   51:             ],
   52:         },
   53:     ]
   54: 
   55: 
   56: @pytest.fixture
   57: def state_data():
   58:     return [
   59:         {
   60:             "counties": [
   61:                 {"name": "Dade", "population": 12345},
   62:                 {"name": "Broward", "population": 40000},
   63:                 {"name": "Palm Beach", "population": 60000},
   64:             ],
   65:             "info": {"governor": "Rick Scott"},
   66:             "shortname": "FL",
   67:             "state": "Florida",
   68:         },
   69:         {
   70:             "counties": [
   71:                 {"name": "Summit", "population": 1234},
   72:                 {"name": "Cuyahoga", "population": 1337},
   73:             ],
   74:             "info": {"governor": "John Kasich"},
   75:             "shortname": "OH",
   76:             "state": "Ohio",
   77:         },
   78:     ]
   79: 
   80: 
   81: @pytest.fixture
   82: def author_missing_data():
   83:     return [
   84:         {"info": None},
   85:         {
   86:             "info": {"created_at": "11/08/1993", "last_updated": "26/05/2012"},
   87:             "author_name": {"first": "Jane", "last_name": "Doe"},
   88:         },
   89:     ]
   90: 
   91: 
   92: @pytest.fixture
   93: def missing_metadata():
   94:     return [
   95:         {
   96:             "name": "Alice",
   97:             "addresses": [
   98:                 {
   99:                     "number": 9562,
  100:                     "street": "Morris St.",
  101:                     "city": "Massillon",
  102:                     "state": "OH",
  103:                     "zip": 44646,
  104:                 }
  105:             ],
  106:             "previous_residences": {"cities": [{"city_name": "Foo York City"}]},
  107:         },
  108:         {
  109:             "addresses": [
  110:                 {
  111:                     "number": 8449,
  112:                     "street": "Spring St.",
  113:                     "city": "Elizabethton",
  114:                     "state": "TN",
  115:                     "zip": 37643,
  116:                 }
  117:             ],
  118:             "previous_residences": {"cities": [{"city_name": "Barmingham"}]},
  119:         },
  120:     ]
  121: 
  122: 
  123: @pytest.fixture
  124: def max_level_test_input_data():
  125:     """
  126:     input data to test json_normalize with max_level param
  127:     """
  128:     return [
  129:         {
  130:             "CreatedBy": {"Name": "User001"},
  131:             "Lookup": {
  132:                 "TextField": "Some text",
  133:                 "UserField": {"Id": "ID001", "Name": "Name001"},
  134:             },
  135:             "Image": {"a": "b"},
  136:         }
  137:     ]
  138: 
  139: 
  140: class TestJSONNormalize:
  141:     def test_simple_records(self):
  142:         recs = [
  143:             {"a": 1, "b": 2, "c": 3},
  144:             {"a": 4, "b": 5, "c": 6},
  145:             {"a": 7, "b": 8, "c": 9},
  146:             {"a": 10, "b": 11, "c": 12},
  147:         ]
  148: 
  149:         result = json_normalize(recs)
  150:         expected = DataFrame(recs)
  151: 
  152:         tm.assert_frame_equal(result, expected)
  153: 
  154:     def test_simple_normalize(self, state_data):
  155:         result = json_normalize(state_data[0], "counties")
  156:         expected = DataFrame(state_data[0]["counties"])
  157:         tm.assert_frame_equal(result, expected)
  158: 
  159:         result = json_normalize(state_data, "counties")
  160: 
  161:         expected = []
  162:         for rec in state_data:
  163:             expected.extend(rec["counties"])
  164:         expected = DataFrame(expected)
  165: 
  166:         tm.assert_frame_equal(result, expected)
  167: 
  168:         result = json_normalize(state_data, "counties", meta="state")
  169:         expected["state"] = np.array(["Florida", "Ohio"]).repeat([3, 2])
  170: 
  171:         tm.assert_frame_equal(result, expected)
  172: 
  173:     def test_fields_list_type_normalize(self):
  174:         parse_metadata_fields_list_type = [
  175:             {"values": [1, 2, 3], "metadata": {"listdata": [1, 2]}}
  176:         ]
  177:         result = json_normalize(
  178:             parse_metadata_fields_list_type,
  179:             record_path=["values"],
  180:             meta=[["metadata", "listdata"]],
  181:         )
  182:         expected = DataFrame(
  183:             {0: [1, 2, 3], "metadata.listdata": [[1, 2], [1, 2], [1, 2]]}
  184:         )
  185:         tm.assert_frame_equal(result, expected)
  186: 
  187:     def test_empty_array(self):
  188:         result = json_normalize([])
  189:         expected = DataFrame()
  190:         tm.assert_frame_equal(result, expected)
  191: 
  192:     @pytest.mark.parametrize(
  193:         "data, record_path, exception_type",
  194:         [
  195:             ([{"a": 0}, {"a": 1}], None, None),
  196:             ({"a": [{"a": 0}, {"a": 1}]}, "a", None),
  197:             ('{"a": [{"a": 0}, {"a": 1}]}', None, NotImplementedError),
  198:             (None, None, NotImplementedError),
  199:         ],
  200:     )
  201:     def test_accepted_input(self, data, record_path, exception_type):
  202:         if exception_type is not None:
  203:             with pytest.raises(exception_type, match=""):
  204:                 json_normalize(data, record_path=record_path)
  205:         else:
  206:             result = json_normalize(data, record_path=record_path)
  207:             expected = DataFrame([0, 1], columns=["a"])
  208:             tm.assert_frame_equal(result, expected)
  209: 
  210:     def test_simple_normalize_with_separator(self, deep_nested):
  211:         # GH 14883
  212:         result = json_normalize({"A": {"A": 1, "B": 2}})
  213:         expected = DataFrame([[1, 2]], columns=["A.A", "A.B"])
  214:         tm.assert_frame_equal(result.reindex_like(expected), expected)
  215: 
  216:         result = json_normalize({"A": {"A": 1, "B": 2}}, sep="_")
  217:         expected = DataFrame([[1, 2]], columns=["A_A", "A_B"])
  218:         tm.assert_frame_equal(result.reindex_like(expected), expected)
  219: 
  220:         result = json_normalize({"A": {"A": 1, "B": 2}}, sep="\u03c3")
  221:         expected = DataFrame([[1, 2]], columns=["A\u03c3A", "A\u03c3B"])
  222:         tm.assert_frame_equal(result.reindex_like(expected), expected)
  223: 
  224:         result = json_normalize(
  225:             deep_nested,
  226:             ["states", "cities"],
  227:             meta=["country", ["states", "name"]],
  228:             sep="_",
  229:         )
  230:         expected = Index(["name", "pop", "country", "states_name"]).sort_values()
  231:         assert result.columns.sort_values().equals(expected)
  232: 
  233:     def test_normalize_with_multichar_separator(self):
  234:         # GH #43831
  235:         data = {"a": [1, 2], "b": {"b_1": 2, "b_2": (3, 4)}}
  236:         result = json_normalize(data, sep="__")
  237:         expected = DataFrame([[[1, 2], 2, (3, 4)]], columns=["a", "b__b_1", "b__b_2"])
  238:         tm.assert_frame_equal(result, expected)
  239: 
  240:     def test_value_array_record_prefix(self):
  241:         # GH 21536
  242:         result = json_normalize({"A": [1, 2]}, "A", record_prefix="Prefix.")
  243:         expected = DataFrame([[1], [2]], columns=["Prefix.0"])
  244:         tm.assert_frame_equal(result, expected)
  245: 
  246:     def test_nested_object_record_path(self):
  247:         # GH 22706
  248:         data = {
  249:             "state": "Florida",
  250:             "info": {
  251:                 "governor": "Rick Scott",
  252:                 "counties": [
  253:                     {"name": "Dade", "population": 12345},
  254:                     {"name": "Broward", "population": 40000},
  255:                     {"name": "Palm Beach", "population": 60000},
  256:                 ],
  257:             },
  258:         }
  259:         result = json_normalize(data, record_path=["info", "counties"])
  260:         expected = DataFrame(
  261:             [["Dade", 12345], ["Broward", 40000], ["Palm Beach", 60000]],
  262:             columns=["name", "population"],
  263:         )
  264:         tm.assert_frame_equal(result, expected)
  265: 
  266:     def test_more_deeply_nested(self, deep_nested):
  267:         result = json_normalize(
  268:             deep_nested, ["states", "cities"], meta=["country", ["states", "name"]]
  269:         )
  270:         ex_data = {
  271:             "country": ["USA"] * 4 + ["Germany"] * 3,
  272:             "states.name": [
  273:                 "California",
  274:                 "California",
  275:                 "Ohio",
  276:                 "Ohio",
  277:                 "Bayern",
  278:                 "Nordrhein-Westfalen",
  279:                 "Nordrhein-Westfalen",
  280:             ],
  281:             "name": [
  282:                 "San Francisco",
  283:                 "Los Angeles",
  284:                 "Columbus",
  285:                 "Cleveland",
  286:                 "Munich",
  287:                 "Duesseldorf",
  288:                 "Koeln",
  289:             ],
  290:             "pop": [12345, 12346, 1234, 1236, 12347, 1238, 1239],
  291:         }
  292: 
  293:         expected = DataFrame(ex_data, columns=result.columns)
  294:         tm.assert_frame_equal(result, expected)
  295: 
  296:     def test_shallow_nested(self):
  297:         data = [
  298:             {
  299:                 "state": "Florida",
  300:                 "shortname": "FL",
  301:                 "info": {"governor": "Rick Scott"},
  302:                 "counties": [
  303:                     {"name": "Dade", "population": 12345},
  304:                     {"name": "Broward", "population": 40000},
  305:                     {"name": "Palm Beach", "population": 60000},
  306:                 ],
  307:             },
  308:             {
  309:                 "state": "Ohio",
  310:                 "shortname": "OH",
  311:                 "info": {"governor": "John Kasich"},
  312:                 "counties": [
  313:                     {"name": "Summit", "population": 1234},
  314:                     {"name": "Cuyahoga", "population": 1337},
  315:                 ],
  316:             },
  317:         ]
  318: 
  319:         result = json_normalize(
  320:             data, "counties", ["state", "shortname", ["info", "governor"]]
  321:         )
  322:         ex_data = {
  323:             "name": ["Dade", "Broward", "Palm Beach", "Summit", "Cuyahoga"],
  324:             "state": ["Florida"] * 3 + ["Ohio"] * 2,
  325:             "shortname": ["FL", "FL", "FL", "OH", "OH"],
  326:             "info.governor": ["Rick Scott"] * 3 + ["John Kasich"] * 2,
  327:             "population": [12345, 40000, 60000, 1234, 1337],
  328:         }
  329:         expected = DataFrame(ex_data, columns=result.columns)
  330:         tm.assert_frame_equal(result, expected)
  331: 
  332:     def test_nested_meta_path_with_nested_record_path(self, state_data):
  333:         # GH 27220
  334:         result = json_normalize(
  335:             data=state_data,
  336:             record_path=["counties"],
  337:             meta=["state", "shortname", ["info", "governor"]],
  338:             errors="ignore",
  339:         )
  340: 
  341:         ex_data = {
  342:             "name": ["Dade", "Broward", "Palm Beach", "Summit", "Cuyahoga"],
  343:             "population": [12345, 40000, 60000, 1234, 1337],
  344:             "state": ["Florida"] * 3 + ["Ohio"] * 2,
  345:             "shortname": ["FL"] * 3 + ["OH"] * 2,
  346:             "info.governor": ["Rick Scott"] * 3 + ["John Kasich"] * 2,
  347:         }
  348: 
  349:         expected = DataFrame(ex_data)
  350:         tm.assert_frame_equal(result, expected)
  351: 
  352:     def test_meta_name_conflict(self):
  353:         data = [
  354:             {
  355:                 "foo": "hello",
  356:                 "bar": "there",
  357:                 "data": [
  358:                     {"foo": "something", "bar": "else"},
  359:                     {"foo": "something2", "bar": "else2"},
  360:                 ],
  361:             }
  362:         ]
  363: 
  364:         msg = r"Conflicting metadata name (foo|bar), need distinguishing prefix"
  365:         with pytest.raises(ValueError, match=msg):
  366:             json_normalize(data, "data", meta=["foo", "bar"])
  367: 
  368:         result = json_normalize(data, "data", meta=["foo", "bar"], meta_prefix="meta")
  369: 
  370:         for val in ["metafoo", "metabar", "foo", "bar"]:
  371:             assert val in result
  372: 
  373:     def test_meta_parameter_not_modified(self):
  374:         # GH 18610
  375:         data = [
  376:             {
  377:                 "foo": "hello",
  378:                 "bar": "there",
  379:                 "data": [
  380:                     {"foo": "something", "bar": "else"},
  381:                     {"foo": "something2", "bar": "else2"},
  382:                 ],
  383:             }
  384:         ]
  385: 
  386:         COLUMNS = ["foo", "bar"]
  387:         result = json_normalize(data, "data", meta=COLUMNS, meta_prefix="meta")
  388: 
  389:         assert COLUMNS == ["foo", "bar"]
  390:         for val in ["metafoo", "metabar", "foo", "bar"]:
  391:             assert val in result
  392: 
  393:     def test_record_prefix(self, state_data):
  394:         result = json_normalize(state_data[0], "counties")
  395:         expected = DataFrame(state_data[0]["counties"])
  396:         tm.assert_frame_equal(result, expected)
  397: 
  398:         result = json_normalize(
  399:             state_data, "counties", meta="state", record_prefix="county_"
  400:         )
  401: 
  402:         expected = []
  403:         for rec in state_data:
  404:             expected.extend(rec["counties"])
  405:         expected = DataFrame(expected)
  406:         expected = expected.rename(columns=lambda x: "county_" + x)
  407:         expected["state"] = np.array(["Florida", "Ohio"]).repeat([3, 2])
  408: 
  409:         tm.assert_frame_equal(result, expected)
  410: 
  411:     def test_non_ascii_key(self):
  412:         testjson = (
  413:             b'[{"\xc3\x9cnic\xc3\xb8de":0,"sub":{"A":1, "B":2}},'
  414:             b'{"\xc3\x9cnic\xc3\xb8de":1,"sub":{"A":3, "B":4}}]'
  415:         ).decode("utf8")
  416: 
  417:         testdata = {
  418:             b"\xc3\x9cnic\xc3\xb8de".decode("utf8"): [0, 1],
  419:             "sub.A": [1, 3],
  420:             "sub.B": [2, 4],
  421:         }
  422:         expected = DataFrame(testdata)
  423: 
  424:         result = json_normalize(json.loads(testjson))
  425:         tm.assert_frame_equal(result, expected)
  426: 
  427:     def test_missing_field(self, author_missing_data):
  428:         # GH20030:
  429:         result = json_normalize(author_missing_data)
  430:         ex_data = [
  431:             {
  432:                 "info": np.nan,
  433:                 "info.created_at": np.nan,
  434:                 "info.last_updated": np.nan,
  435:                 "author_name.first": np.nan,
  436:                 "author_name.last_name": np.nan,
  437:             },
  438:             {
  439:                 "info": None,
  440:                 "info.created_at": "11/08/1993",
  441:                 "info.last_updated": "26/05/2012",
  442:                 "author_name.first": "Jane",
  443:                 "author_name.last_name": "Doe",
  444:             },
  445:         ]
  446:         expected = DataFrame(ex_data)
  447:         tm.assert_frame_equal(result, expected)
  448: 
  449:     @pytest.mark.parametrize(
  450:         "max_level,expected",
  451:         [
  452:             (
  453:                 0,
  454:                 [
  455:                     {
  456:                         "TextField": "Some text",
  457:                         "UserField": {"Id": "ID001", "Name": "Name001"},
  458:                         "CreatedBy": {"Name": "User001"},
  459:                         "Image": {"a": "b"},
  460:                     },
  461:                     {
  462:                         "TextField": "Some text",
  463:                         "UserField": {"Id": "ID001", "Name": "Name001"},
  464:                         "CreatedBy": {"Name": "User001"},
  465:                         "Image": {"a": "b"},
  466:                     },
  467:                 ],
  468:             ),
  469:             (
  470:                 1,
  471:                 [
  472:                     {
  473:                         "TextField": "Some text",
  474:                         "UserField.Id": "ID001",
  475:                         "UserField.Name": "Name001",
  476:                         "CreatedBy": {"Name": "User001"},
  477:                         "Image": {"a": "b"},
  478:                     },
  479:                     {
  480:                         "TextField": "Some text",
  481:                         "UserField.Id": "ID001",
  482:                         "UserField.Name": "Name001",
  483:                         "CreatedBy": {"Name": "User001"},
  484:                         "Image": {"a": "b"},
  485:                     },
  486:                 ],
  487:             ),
  488:         ],
  489:     )
  490:     def test_max_level_with_records_path(self, max_level, expected):
  491:         # GH23843: Enhanced JSON normalize
  492:         test_input = [
  493:             {
  494:                 "CreatedBy": {"Name": "User001"},
  495:                 "Lookup": [
  496:                     {
  497:                         "TextField": "Some text",
  498:                         "UserField": {"Id": "ID001", "Name": "Name001"},
  499:                     },
  500:                     {
  501:                         "TextField": "Some text",
  502:                         "UserField": {"Id": "ID001", "Name": "Name001"},
  503:                     },
  504:                 ],
  505:                 "Image": {"a": "b"},
  506:                 "tags": [
  507:                     {"foo": "something", "bar": "else"},
  508:                     {"foo": "something2", "bar": "else2"},
  509:                 ],
  510:             }
  511:         ]
  512: 
  513:         result = json_normalize(
  514:             test_input,
  515:             record_path=["Lookup"],
  516:             meta=[["CreatedBy"], ["Image"]],
  517:             max_level=max_level,
  518:         )
  519:         expected_df = DataFrame(data=expected, columns=result.columns.values)
  520:         tm.assert_equal(expected_df, result)
  521: 
  522:     def test_nested_flattening_consistent(self):
  523:         # see gh-21537
  524:         df1 = json_normalize([{"A": {"B": 1}}])
  525:         df2 = json_normalize({"dummy": [{"A": {"B": 1}}]}, "dummy")
  526: 
  527:         # They should be the same.
  528:         tm.assert_frame_equal(df1, df2)
  529: 
  530:     def test_nonetype_record_path(self, nulls_fixture):
  531:         # see gh-30148
  532:         # should not raise TypeError
  533:         result = json_normalize(
  534:             [
  535:                 {"state": "Texas", "info": nulls_fixture},
  536:                 {"state": "Florida", "info": [{"i": 2}]},
  537:             ],
  538:             record_path=["info"],
  539:         )
  540:         expected = DataFrame({"i": 2}, index=[0])
  541:         tm.assert_equal(result, expected)
  542: 
  543:     @pytest.mark.parametrize("value", ["false", "true", "{}", "1", '"text"'])
  544:     def test_non_list_record_path_errors(self, value):
  545:         # see gh-30148, GH 26284
  546:         parsed_value = json.loads(value)
  547:         test_input = {"state": "Texas", "info": parsed_value}
  548:         test_path = "info"
  549:         msg = (
  550:             f"{test_input} has non list value {parsed_value} for path {test_path}. "
  551:             "Must be list or null."
  552:         )
  553:         with pytest.raises(TypeError, match=msg):
  554:             json_normalize([test_input], record_path=[test_path])
  555: 
  556:     def test_meta_non_iterable(self):
  557:         # GH 31507
  558:         data = """[{"id": 99, "data": [{"one": 1, "two": 2}]}]"""
  559: 
  560:         result = json_normalize(json.loads(data), record_path=["data"], meta=["id"])
  561:         expected = DataFrame(
  562:             {"one": [1], "two": [2], "id": np.array([99], dtype=object)}
  563:         )
  564:         tm.assert_frame_equal(result, expected)
  565: 
  566:     def test_generator(self, state_data):
  567:         # GH35923 Fix pd.json_normalize to not skip the first element of a
  568:         # generator input
  569:         def generator_data():
  570:             yield from state_data[0]["counties"]
  571: 
  572:         result = json_normalize(generator_data())
  573:         expected = DataFrame(state_data[0]["counties"])
  574: 
  575:         tm.assert_frame_equal(result, expected)
  576: 
  577:     def test_top_column_with_leading_underscore(self):
  578:         # 49861
  579:         data = {"_id": {"a1": 10, "l2": {"l3": 0}}, "gg": 4}
  580:         result = json_normalize(data, sep="_")
  581:         expected = DataFrame([[4, 10, 0]], columns=["gg", "_id_a1", "_id_l2_l3"])
  582: 
  583:         tm.assert_frame_equal(result, expected)
  584: 
  585: 
  586: class TestNestedToRecord:
  587:     def test_flat_stays_flat(self):
  588:         recs = [{"flat1": 1, "flat2": 2}, {"flat3": 3, "flat2": 4}]
  589:         result = nested_to_record(recs)
  590:         expected = recs
  591:         assert result == expected
  592: 
  593:     def test_one_level_deep_flattens(self):
  594:         data = {"flat1": 1, "dict1": {"c": 1, "d": 2}}
  595: 
  596:         result = nested_to_record(data)
  597:         expected = {"dict1.c": 1, "dict1.d": 2, "flat1": 1}
  598: 
  599:         assert result == expected
  600: 
  601:     def test_nested_flattens(self):
  602:         data = {
  603:             "flat1": 1,
  604:             "dict1": {"c": 1, "d": 2},
  605:             "nested": {"e": {"c": 1, "d": 2}, "d": 2},
  606:         }
  607: 
  608:         result = nested_to_record(data)
  609:         expected = {
  610:             "dict1.c": 1,
  611:             "dict1.d": 2,
  612:             "flat1": 1,
  613:             "nested.d": 2,
  614:             "nested.e.c": 1,
  615:             "nested.e.d": 2,
  616:         }
  617: 
  618:         assert result == expected
  619: 
  620:     def test_json_normalize_errors(self, missing_metadata):
  621:         # GH14583:
  622:         # If meta keys are not always present a new option to set
  623:         # errors='ignore' has been implemented
  624: 
  625:         msg = (
  626:             "Key 'name' not found. To replace missing values of "
  627:             "'name' with np.nan, pass in errors='ignore'"
  628:         )
  629:         with pytest.raises(KeyError, match=msg):
  630:             json_normalize(
  631:                 data=missing_metadata,
  632:                 record_path="addresses",
  633:                 meta="name",
  634:                 errors="raise",
  635:             )
  636: 
  637:     def test_missing_meta(self, missing_metadata):
  638:         # GH25468
  639:         # If metadata is nullable with errors set to ignore, the null values
  640:         # should be numpy.nan values
  641:         result = json_normalize(
  642:             data=missing_metadata, record_path="addresses", meta="name", errors="ignore"
  643:         )
  644:         ex_data = [
  645:             [9562, "Morris St.", "Massillon", "OH", 44646, "Alice"],
  646:             [8449, "Spring St.", "Elizabethton", "TN", 37643, np.nan],
  647:         ]
  648:         columns = ["number", "street", "city", "state", "zip", "name"]
  649:         expected = DataFrame(ex_data, columns=columns)
  650:         tm.assert_frame_equal(result, expected)
  651: 
  652:     def test_missing_nested_meta(self):
  653:         # GH44312
  654:         # If errors="ignore" and nested metadata is null, we should return nan
  655:         data = {"meta": "foo", "nested_meta": None, "value": [{"rec": 1}, {"rec": 2}]}
  656:         result = json_normalize(
  657:             data,
  658:             record_path="value",
  659:             meta=["meta", ["nested_meta", "leaf"]],
  660:             errors="ignore",
  661:         )
  662:         ex_data = [[1, "foo", np.nan], [2, "foo", np.nan]]
  663:         columns = ["rec", "meta", "nested_meta.leaf"]
  664:         expected = DataFrame(ex_data, columns=columns).astype(
  665:             {"nested_meta.leaf": object}
  666:         )
  667:         tm.assert_frame_equal(result, expected)
  668: 
  669:         # If errors="raise" and nested metadata is null, we should raise with the
  670:         # key of the first missing level
  671:         with pytest.raises(KeyError, match="'leaf' not found"):
  672:             json_normalize(
  673:                 data,
  674:                 record_path="value",
  675:                 meta=["meta", ["nested_meta", "leaf"]],
  676:                 errors="raise",
  677:             )
  678: 
  679:     def test_missing_meta_multilevel_record_path_errors_raise(self, missing_metadata):
  680:         # GH41876
  681:         # Ensure errors='raise' works as intended even when a record_path of length
  682:         # greater than one is passed in
  683:         msg = (
  684:             "Key 'name' not found. To replace missing values of "
  685:             "'name' with np.nan, pass in errors='ignore'"
  686:         )
  687:         with pytest.raises(KeyError, match=msg):
  688:             json_normalize(
  689:                 data=missing_metadata,
  690:                 record_path=["previous_residences", "cities"],
  691:                 meta="name",
  692:                 errors="raise",
  693:             )
  694: 
  695:     def test_missing_meta_multilevel_record_path_errors_ignore(self, missing_metadata):
  696:         # GH41876
  697:         # Ensure errors='ignore' works as intended even when a record_path of length
  698:         # greater than one is passed in
  699:         result = json_normalize(
  700:             data=missing_metadata,
  701:             record_path=["previous_residences", "cities"],
  702:             meta="name",
  703:             errors="ignore",
  704:         )
  705:         ex_data = [
  706:             ["Foo York City", "Alice"],
  707:             ["Barmingham", np.nan],
  708:         ]
  709:         columns = ["city_name", "name"]
  710:         expected = DataFrame(ex_data, columns=columns)
  711:         tm.assert_frame_equal(result, expected)
  712: 
  713:     def test_donot_drop_nonevalues(self):
  714:         # GH21356
  715:         data = [
  716:             {"info": None, "author_name": {"first": "Smith", "last_name": "Appleseed"}},
  717:             {
  718:                 "info": {"created_at": "11/08/1993", "last_updated": "26/05/2012"},
  719:                 "author_name": {"first": "Jane", "last_name": "Doe"},
  720:             },
  721:         ]
  722:         result = nested_to_record(data)
  723:         expected = [
  724:             {
  725:                 "info": None,
  726:                 "author_name.first": "Smith",
  727:                 "author_name.last_name": "Appleseed",
  728:             },
  729:             {
  730:                 "author_name.first": "Jane",
  731:                 "author_name.last_name": "Doe",
  732:                 "info.created_at": "11/08/1993",
  733:                 "info.last_updated": "26/05/2012",
  734:             },
  735:         ]
  736: 
  737:         assert result == expected
  738: 
  739:     def test_nonetype_top_level_bottom_level(self):
  740:         # GH21158: If inner level json has a key with a null value
  741:         # make sure it does not do a new_d.pop twice and except
  742:         data = {
  743:             "id": None,
  744:             "location": {
  745:                 "country": {
  746:                     "state": {
  747:                         "id": None,
  748:                         "town.info": {
  749:                             "id": None,
  750:                             "region": None,
  751:                             "x": 49.151580810546875,
  752:                             "y": -33.148521423339844,
  753:                             "z": 27.572303771972656,
  754:                         },
  755:                     }
  756:                 }
  757:             },
  758:         }
  759:         result = nested_to_record(data)
  760:         expected = {
  761:             "id": None,
  762:             "location.country.state.id": None,
  763:             "location.country.state.town.info.id": None,
  764:             "location.country.state.town.info.region": None,
  765:             "location.country.state.town.info.x": 49.151580810546875,
  766:             "location.country.state.town.info.y": -33.148521423339844,
  767:             "location.country.state.town.info.z": 27.572303771972656,
  768:         }
  769:         assert result == expected
  770: 
  771:     def test_nonetype_multiple_levels(self):
  772:         # GH21158: If inner level json has a key with a null value
  773:         # make sure it does not do a new_d.pop twice and except
  774:         data = {
  775:             "id": None,
  776:             "location": {
  777:                 "id": None,
  778:                 "country": {
  779:                     "id": None,
  780:                     "state": {
  781:                         "id": None,
  782:                         "town.info": {
  783:                             "region": None,
  784:                             "x": 49.151580810546875,
  785:                             "y": -33.148521423339844,
  786:                             "z": 27.572303771972656,
  787:                         },
  788:                     },
  789:                 },
  790:             },
  791:         }
  792:         result = nested_to_record(data)
  793:         expected = {
  794:             "id": None,
  795:             "location.id": None,
  796:             "location.country.id": None,
  797:             "location.country.state.id": None,
  798:             "location.country.state.town.info.region": None,
  799:             "location.country.state.town.info.x": 49.151580810546875,
  800:             "location.country.state.town.info.y": -33.148521423339844,
  801:             "location.country.state.town.info.z": 27.572303771972656,
  802:         }
  803:         assert result == expected
  804: 
  805:     @pytest.mark.parametrize(
  806:         "max_level, expected",
  807:         [
  808:             (
  809:                 None,
  810:                 [
  811:                     {
  812:                         "CreatedBy.Name": "User001",
  813:                         "Lookup.TextField": "Some text",
  814:                         "Lookup.UserField.Id": "ID001",
  815:                         "Lookup.UserField.Name": "Name001",
  816:                         "Image.a": "b",
  817:                     }
  818:                 ],
  819:             ),
  820:             (
  821:                 0,
  822:                 [
  823:                     {
  824:                         "CreatedBy": {"Name": "User001"},
  825:                         "Lookup": {
  826:                             "TextField": "Some text",
  827:                             "UserField": {"Id": "ID001", "Name": "Name001"},
  828:                         },
  829:                         "Image": {"a": "b"},
  830:                     }
  831:                 ],
  832:             ),
  833:             (
  834:                 1,
  835:                 [
  836:                     {
  837:                         "CreatedBy.Name": "User001",
  838:                         "Lookup.TextField": "Some text",
  839:                         "Lookup.UserField": {"Id": "ID001", "Name": "Name001"},
  840:                         "Image.a": "b",
  841:                     }
  842:                 ],
  843:             ),
  844:         ],
  845:     )
  846:     def test_with_max_level(self, max_level, expected, max_level_test_input_data):
  847:         # GH23843: Enhanced JSON normalize
  848:         output = nested_to_record(max_level_test_input_data, max_level=max_level)
  849:         assert output == expected
  850: 
  851:     def test_with_large_max_level(self):
  852:         # GH23843: Enhanced JSON normalize
  853:         max_level = 100
  854:         input_data = [
  855:             {
  856:                 "CreatedBy": {
  857:                     "user": {
  858:                         "name": {"firstname": "Leo", "LastName": "Thomson"},
  859:                         "family_tree": {
  860:                             "father": {
  861:                                 "name": "Father001",
  862:                                 "father": {
  863:                                     "Name": "Father002",
  864:                                     "father": {
  865:                                         "name": "Father003",
  866:                                         "father": {"Name": "Father004"},
  867:                                     },
  868:                                 },
  869:                             }
  870:                         },
  871:                     }
  872:                 }
  873:             }
  874:         ]
  875:         expected = [
  876:             {
  877:                 "CreatedBy.user.name.firstname": "Leo",
  878:                 "CreatedBy.user.name.LastName": "Thomson",
  879:                 "CreatedBy.user.family_tree.father.name": "Father001",
  880:                 "CreatedBy.user.family_tree.father.father.Name": "Father002",
  881:                 "CreatedBy.user.family_tree.father.father.father.name": "Father003",
  882:                 "CreatedBy.user.family_tree.father.father.father.father.Name": "Father004",  # noqa: E501
  883:             }
  884:         ]
  885:         output = nested_to_record(input_data, max_level=max_level)
  886:         assert output == expected
  887: 
  888:     def test_series_non_zero_index(self):
  889:         # GH 19020
  890:         data = {
  891:             0: {"id": 1, "name": "Foo", "elements": {"a": 1}},
  892:             1: {"id": 2, "name": "Bar", "elements": {"b": 2}},
  893:             2: {"id": 3, "name": "Baz", "elements": {"c": 3}},
  894:         }
  895:         s = Series(data)
  896:         s.index = [1, 2, 3]
  897:         result = json_normalize(s)
  898:         expected = DataFrame(
  899:             {
  900:                 "id": [1, 2, 3],
  901:                 "name": ["Foo", "Bar", "Baz"],
  902:                 "elements.a": [1.0, np.nan, np.nan],
  903:                 "elements.b": [np.nan, 2.0, np.nan],
  904:                 "elements.c": [np.nan, np.nan, 3.0],
  905:             }
  906:         )
  907:         tm.assert_frame_equal(result, expected)
