    1: """
    2: Tests for the file pandas.io.formats.format, *not* tests for general formatting
    3: of pandas objects.
    4: """
    5: from datetime import datetime
    6: from io import StringIO
    7: from pathlib import Path
    8: import re
    9: from shutil import get_terminal_size
   10: 
   11: import numpy as np
   12: import pytest
   13: 
   14: from pandas._config import using_pyarrow_string_dtype
   15: 
   16: import pandas as pd
   17: from pandas import (
   18:     DataFrame,
   19:     Index,
   20:     MultiIndex,
   21:     NaT,
   22:     Series,
   23:     Timestamp,
   24:     date_range,
   25:     get_option,
   26:     option_context,
   27:     read_csv,
   28:     reset_option,
   29: )
   30: 
   31: from pandas.io.formats import printing
   32: import pandas.io.formats.format as fmt
   33: 
   34: 
   35: @pytest.fixture(params=["string", "pathlike", "buffer"])
   36: def filepath_or_buffer_id(request):
   37:     """
   38:     A fixture yielding test ids for filepath_or_buffer testing.
   39:     """
   40:     return request.param
   41: 
   42: 
   43: @pytest.fixture
   44: def filepath_or_buffer(filepath_or_buffer_id, tmp_path):
   45:     """
   46:     A fixture yielding a string representing a filepath, a path-like object
   47:     and a StringIO buffer. Also checks that buffer is not closed.
   48:     """
   49:     if filepath_or_buffer_id == "buffer":
   50:         buf = StringIO()
   51:         yield buf
   52:         assert not buf.closed
   53:     else:
   54:         assert isinstance(tmp_path, Path)
   55:         if filepath_or_buffer_id == "pathlike":
   56:             yield tmp_path / "foo"
   57:         else:
   58:             yield str(tmp_path / "foo")
   59: 
   60: 
   61: @pytest.fixture
   62: def assert_filepath_or_buffer_equals(
   63:     filepath_or_buffer, filepath_or_buffer_id, encoding
   64: ):
   65:     """
   66:     Assertion helper for checking filepath_or_buffer.
   67:     """
   68:     if encoding is None:
   69:         encoding = "utf-8"
   70: 
   71:     def _assert_filepath_or_buffer_equals(expected):
   72:         if filepath_or_buffer_id == "string":
   73:             with open(filepath_or_buffer, encoding=encoding) as f:
   74:                 result = f.read()
   75:         elif filepath_or_buffer_id == "pathlike":
   76:             result = filepath_or_buffer.read_text(encoding=encoding)
   77:         elif filepath_or_buffer_id == "buffer":
   78:             result = filepath_or_buffer.getvalue()
   79:         assert result == expected
   80: 
   81:     return _assert_filepath_or_buffer_equals
   82: 
   83: 
   84: def has_info_repr(df):
   85:     r = repr(df)
   86:     c1 = r.split("\n")[0].startswith("<class")
   87:     c2 = r.split("\n")[0].startswith(r"&lt;class")  # _repr_html_
   88:     return c1 or c2
   89: 
   90: 
   91: def has_non_verbose_info_repr(df):
   92:     has_info = has_info_repr(df)
   93:     r = repr(df)
   94: 
   95:     # 1. <class>
   96:     # 2. Index
   97:     # 3. Columns
   98:     # 4. dtype
   99:     # 5. memory usage
  100:     # 6. trailing newline
  101:     nv = len(r.split("\n")) == 6
  102:     return has_info and nv
  103: 
  104: 
  105: def has_horizontally_truncated_repr(df):
  106:     try:  # Check header row
  107:         fst_line = np.array(repr(df).splitlines()[0].split())
  108:         cand_col = np.where(fst_line == "...")[0][0]
  109:     except IndexError:
  110:         return False
  111:     # Make sure each row has this ... in the same place
  112:     r = repr(df)
  113:     for ix, _ in enumerate(r.splitlines()):
  114:         if not r.split()[cand_col] == "...":
  115:             return False
  116:     return True
  117: 
  118: 
  119: def has_vertically_truncated_repr(df):
  120:     r = repr(df)
  121:     only_dot_row = False
  122:     for row in r.splitlines():
  123:         if re.match(r"^[\.\ ]+$", row):
  124:             only_dot_row = True
  125:     return only_dot_row
  126: 
  127: 
  128: def has_truncated_repr(df):
  129:     return has_horizontally_truncated_repr(df) or has_vertically_truncated_repr(df)
  130: 
  131: 
  132: def has_doubly_truncated_repr(df):
  133:     return has_horizontally_truncated_repr(df) and has_vertically_truncated_repr(df)
  134: 
  135: 
  136: def has_expanded_repr(df):
  137:     r = repr(df)
  138:     for line in r.split("\n"):
  139:         if line.endswith("\\"):
  140:             return True
  141:     return False
  142: 
  143: 
  144: class TestDataFrameFormatting:
  145:     def test_repr_truncation(self):
  146:         max_len = 20
  147:         with option_context("display.max_colwidth", max_len):
  148:             df = DataFrame(
  149:                 {
  150:                     "A": np.random.default_rng(2).standard_normal(10),
  151:                     "B": [
  152:                         "a"
  153:                         * np.random.default_rng(2).integers(max_len - 1, max_len + 1)
  154:                         for _ in range(10)
  155:                     ],
  156:                 }
  157:             )
  158:             r = repr(df)
  159:             r = r[r.find("\n") + 1 :]
  160: 
  161:             adj = printing.get_adjustment()
  162: 
  163:             for line, value in zip(r.split("\n"), df["B"]):
  164:                 if adj.len(value) + 1 > max_len:
  165:                     assert "..." in line
  166:                 else:
  167:                     assert "..." not in line
  168: 
  169:         with option_context("display.max_colwidth", 999999):
  170:             assert "..." not in repr(df)
  171: 
  172:         with option_context("display.max_colwidth", max_len + 2):
  173:             assert "..." not in repr(df)
  174: 
  175:     def test_repr_truncation_preserves_na(self):
  176:         # https://github.com/pandas-dev/pandas/issues/55630
  177:         df = DataFrame({"a": [pd.NA for _ in range(10)]})
  178:         with option_context("display.max_rows", 2, "display.show_dimensions", False):
  179:             assert repr(df) == "       a\n0   <NA>\n..   ...\n9   <NA>"
  180: 
  181:     def test_max_colwidth_negative_int_raises(self):
  182:         # Deprecation enforced from:
  183:         # https://github.com/pandas-dev/pandas/issues/31532
  184:         with pytest.raises(
  185:             ValueError, match="Value must be a nonnegative integer or None"
  186:         ):
  187:             with option_context("display.max_colwidth", -1):
  188:                 pass
  189: 
  190:     def test_repr_chop_threshold(self):
  191:         df = DataFrame([[0.1, 0.5], [0.5, -0.1]])
  192:         reset_option("display.chop_threshold")  # default None
  193:         assert repr(df) == "     0    1\n0  0.1  0.5\n1  0.5 -0.1"
  194: 
  195:         with option_context("display.chop_threshold", 0.2):
  196:             assert repr(df) == "     0    1\n0  0.0  0.5\n1  0.5  0.0"
  197: 
  198:         with option_context("display.chop_threshold", 0.6):
  199:             assert repr(df) == "     0    1\n0  0.0  0.0\n1  0.0  0.0"
  200: 
  201:         with option_context("display.chop_threshold", None):
  202:             assert repr(df) == "     0    1\n0  0.1  0.5\n1  0.5 -0.1"
  203: 
  204:     def test_repr_chop_threshold_column_below(self):
  205:         # GH 6839: validation case
  206: 
  207:         df = DataFrame([[10, 20, 30, 40], [8e-10, -1e-11, 2e-9, -2e-11]]).T
  208: 
  209:         with option_context("display.chop_threshold", 0):
  210:             assert repr(df) == (
  211:                 "      0             1\n"
  212:                 "0  10.0  8.000000e-10\n"
  213:                 "1  20.0 -1.000000e-11\n"
  214:                 "2  30.0  2.000000e-09\n"
  215:                 "3  40.0 -2.000000e-11"
  216:             )
  217: 
  218:         with option_context("display.chop_threshold", 1e-8):
  219:             assert repr(df) == (
  220:                 "      0             1\n"
  221:                 "0  10.0  0.000000e+00\n"
  222:                 "1  20.0  0.000000e+00\n"
  223:                 "2  30.0  0.000000e+00\n"
  224:                 "3  40.0  0.000000e+00"
  225:             )
  226: 
  227:         with option_context("display.chop_threshold", 5e-11):
  228:             assert repr(df) == (
  229:                 "      0             1\n"
  230:                 "0  10.0  8.000000e-10\n"
  231:                 "1  20.0  0.000000e+00\n"
  232:                 "2  30.0  2.000000e-09\n"
  233:                 "3  40.0  0.000000e+00"
  234:             )
  235: 
  236:     def test_repr_no_backslash(self):
  237:         with option_context("mode.sim_interactive", True):
  238:             df = DataFrame(np.random.default_rng(2).standard_normal((10, 4)))
  239:             assert "\\" not in repr(df)
  240: 
  241:     def test_expand_frame_repr(self):
  242:         df_small = DataFrame("hello", index=[0], columns=[0])
  243:         df_wide = DataFrame("hello", index=[0], columns=range(10))
  244:         df_tall = DataFrame("hello", index=range(30), columns=range(5))
  245: 
  246:         with option_context("mode.sim_interactive", True):
  247:             with option_context(
  248:                 "display.max_columns",
  249:                 10,
  250:                 "display.width",
  251:                 20,
  252:                 "display.max_rows",
  253:                 20,
  254:                 "display.show_dimensions",
  255:                 True,
  256:             ):
  257:                 with option_context("display.expand_frame_repr", True):
  258:                     assert not has_truncated_repr(df_small)
  259:                     assert not has_expanded_repr(df_small)
  260:                     assert not has_truncated_repr(df_wide)
  261:                     assert has_expanded_repr(df_wide)
  262:                     assert has_vertically_truncated_repr(df_tall)
  263:                     assert has_expanded_repr(df_tall)
  264: 
  265:                 with option_context("display.expand_frame_repr", False):
  266:                     assert not has_truncated_repr(df_small)
  267:                     assert not has_expanded_repr(df_small)
  268:                     assert not has_horizontally_truncated_repr(df_wide)
  269:                     assert not has_expanded_repr(df_wide)
  270:                     assert has_vertically_truncated_repr(df_tall)
  271:                     assert not has_expanded_repr(df_tall)
  272: 
  273:     def test_repr_non_interactive(self):
  274:         # in non interactive mode, there can be no dependency on the
  275:         # result of terminal auto size detection
  276:         df = DataFrame("hello", index=range(1000), columns=range(5))
  277: 
  278:         with option_context(
  279:             "mode.sim_interactive", False, "display.width", 0, "display.max_rows", 5000
  280:         ):
  281:             assert not has_truncated_repr(df)
  282:             assert not has_expanded_repr(df)
  283: 
  284:     def test_repr_truncates_terminal_size(self, monkeypatch):
  285:         # see gh-21180
  286: 
  287:         terminal_size = (118, 96)
  288:         monkeypatch.setattr(
  289:             "pandas.io.formats.format.get_terminal_size", lambda: terminal_size
  290:         )
  291: 
  292:         index = range(5)
  293:         columns = MultiIndex.from_tuples(
  294:             [
  295:                 ("This is a long title with > 37 chars.", "cat"),
  296:                 ("This is a loooooonger title with > 43 chars.", "dog"),
  297:             ]
  298:         )
  299:         df = DataFrame(1, index=index, columns=columns)
  300: 
  301:         result = repr(df)
  302: 
  303:         h1, h2 = result.split("\n")[:2]
  304:         assert "long" in h1
  305:         assert "loooooonger" in h1
  306:         assert "cat" in h2
  307:         assert "dog" in h2
  308: 
  309:         # regular columns
  310:         df2 = DataFrame({"A" * 41: [1, 2], "B" * 41: [1, 2]})
  311:         result = repr(df2)
  312: 
  313:         assert df2.columns[0] in result.split("\n")[0]
  314: 
  315:     def test_repr_truncates_terminal_size_full(self, monkeypatch):
  316:         # GH 22984 ensure entire window is filled
  317:         terminal_size = (80, 24)
  318:         df = DataFrame(np.random.default_rng(2).random((1, 7)))
  319: 
  320:         monkeypatch.setattr(
  321:             "pandas.io.formats.format.get_terminal_size", lambda: terminal_size
  322:         )
  323:         assert "..." not in str(df)
  324: 
  325:     def test_repr_truncation_column_size(self):
  326:         # dataframe with last column very wide -> check it is not used to
  327:         # determine size of truncation (...) column
  328:         df = DataFrame(
  329:             {
  330:                 "a": [108480, 30830],
  331:                 "b": [12345, 12345],
  332:                 "c": [12345, 12345],
  333:                 "d": [12345, 12345],
  334:                 "e": ["a" * 50] * 2,
  335:             }
  336:         )
  337:         assert "..." in str(df)
  338:         assert "    ...    " not in str(df)
  339: 
  340:     def test_repr_max_columns_max_rows(self):
  341:         term_width, term_height = get_terminal_size()
  342:         if term_width < 10 or term_height < 10:
  343:             pytest.skip(f"terminal size too small, {term_width} x {term_height}")
  344: 
  345:         def mkframe(n):
  346:             index = [f"{i:05d}" for i in range(n)]
  347:             return DataFrame(0, index, index)
  348: 
  349:         df6 = mkframe(6)
  350:         df10 = mkframe(10)
  351:         with option_context("mode.sim_interactive", True):
  352:             with option_context("display.width", term_width * 2):
  353:                 with option_context("display.max_rows", 5, "display.max_columns", 5):
  354:                     assert not has_expanded_repr(mkframe(4))
  355:                     assert not has_expanded_repr(mkframe(5))
  356:                     assert not has_expanded_repr(df6)
  357:                     assert has_doubly_truncated_repr(df6)
  358: 
  359:                 with option_context("display.max_rows", 20, "display.max_columns", 10):
  360:                     # Out off max_columns boundary, but no extending
  361:                     # since not exceeding width
  362:                     assert not has_expanded_repr(df6)
  363:                     assert not has_truncated_repr(df6)
  364: 
  365:                 with option_context("display.max_rows", 9, "display.max_columns", 10):
  366:                     # out vertical bounds can not result in expanded repr
  367:                     assert not has_expanded_repr(df10)
  368:                     assert has_vertically_truncated_repr(df10)
  369: 
  370:             # width=None in terminal, auto detection
  371:             with option_context(
  372:                 "display.max_columns",
  373:                 100,
  374:                 "display.max_rows",
  375:                 term_width * 20,
  376:                 "display.width",
  377:                 None,
  378:             ):
  379:                 df = mkframe((term_width // 7) - 2)
  380:                 assert not has_expanded_repr(df)
  381:                 df = mkframe((term_width // 7) + 2)
  382:                 printing.pprint_thing(df._repr_fits_horizontal_())
  383:                 assert has_expanded_repr(df)
  384: 
  385:     def test_repr_min_rows(self):
  386:         df = DataFrame({"a": range(20)})
  387: 
  388:         # default setting no truncation even if above min_rows
  389:         assert ".." not in repr(df)
  390:         assert ".." not in df._repr_html_()
  391: 
  392:         df = DataFrame({"a": range(61)})
  393: 
  394:         # default of max_rows 60 triggers truncation if above
  395:         assert ".." in repr(df)
  396:         assert ".." in df._repr_html_()
  397: 
  398:         with option_context("display.max_rows", 10, "display.min_rows", 4):
  399:             # truncated after first two rows
  400:             assert ".." in repr(df)
  401:             assert "2  " not in repr(df)
  402:             assert "..." in df._repr_html_()
  403:             assert "<td>2</td>" not in df._repr_html_()
  404: 
  405:         with option_context("display.max_rows", 12, "display.min_rows", None):
  406:             # when set to None, follow value of max_rows
  407:             assert "5    5" in repr(df)
  408:             assert "<td>5</td>" in df._repr_html_()
  409: 
  410:         with option_context("display.max_rows", 10, "display.min_rows", 12):
  411:             # when set value higher as max_rows, use the minimum
  412:             assert "5    5" not in repr(df)
  413:             assert "<td>5</td>" not in df._repr_html_()
  414: 
  415:         with option_context("display.max_rows", None, "display.min_rows", 12):
  416:             # max_rows of None -> never truncate
  417:             assert ".." not in repr(df)
  418:             assert ".." not in df._repr_html_()
  419: 
  420:     def test_str_max_colwidth(self):
  421:         # GH 7856
  422:         df = DataFrame(
  423:             [
  424:                 {
  425:                     "a": "foo",
  426:                     "b": "bar",
  427:                     "c": "uncomfortably long line with lots of stuff",
  428:                     "d": 1,
  429:                 },
  430:                 {"a": "foo", "b": "bar", "c": "stuff", "d": 1},
  431:             ]
  432:         )
  433:         df.set_index(["a", "b", "c"])
  434:         assert str(df) == (
  435:             "     a    b                                           c  d\n"
  436:             "0  foo  bar  uncomfortably long line with lots of stuff  1\n"
  437:             "1  foo  bar                                       stuff  1"
  438:         )
  439:         with option_context("max_colwidth", 20):
  440:             assert str(df) == (
  441:                 "     a    b                    c  d\n"
  442:                 "0  foo  bar  uncomfortably lo...  1\n"
  443:                 "1  foo  bar                stuff  1"
  444:             )
  445: 
  446:     def test_auto_detect(self):
  447:         term_width, term_height = get_terminal_size()
  448:         fac = 1.05  # Arbitrary large factor to exceed term width
  449:         cols = range(int(term_width * fac))
  450:         index = range(10)
  451:         df = DataFrame(index=index, columns=cols)
  452:         with option_context("mode.sim_interactive", True):
  453:             with option_context("display.max_rows", None):
  454:                 with option_context("display.max_columns", None):
  455:                     # Wrap around with None
  456:                     assert has_expanded_repr(df)
  457:             with option_context("display.max_rows", 0):
  458:                 with option_context("display.max_columns", 0):
  459:                     # Truncate with auto detection.
  460:                     assert has_horizontally_truncated_repr(df)
  461: 
  462:             index = range(int(term_height * fac))
  463:             df = DataFrame(index=index, columns=cols)
  464:             with option_context("display.max_rows", 0):
  465:                 with option_context("display.max_columns", None):
  466:                     # Wrap around with None
  467:                     assert has_expanded_repr(df)
  468:                     # Truncate vertically
  469:                     assert has_vertically_truncated_repr(df)
  470: 
  471:             with option_context("display.max_rows", None):
  472:                 with option_context("display.max_columns", 0):
  473:                     assert has_horizontally_truncated_repr(df)
  474: 
  475:     def test_to_string_repr_unicode2(self):
  476:         idx = Index(["abc", "\u03c3a", "aegdvg"])
  477:         ser = Series(np.random.default_rng(2).standard_normal(len(idx)), idx)
  478:         rs = repr(ser).split("\n")
  479:         line_len = len(rs[0])
  480:         for line in rs[1:]:
  481:             try:
  482:                 line = line.decode(get_option("display.encoding"))
  483:             except AttributeError:
  484:                 pass
  485:             if not line.startswith("dtype:"):
  486:                 assert len(line) == line_len
  487: 
  488:     def test_east_asian_unicode_false(self):
  489:         # not aligned properly because of east asian width
  490: 
  491:         # mid col
  492:         df = DataFrame(
  493:             {"a": ["гЃ‚", "гЃ„гЃ„гЃ„", "гЃ†", "гЃ€гЃ€гЃ€гЃ€гЃ€гЃ€"], "b": [1, 222, 33333, 4]},
  494:             index=["a", "bb", "c", "ddd"],
  495:         )
  496:         expected = (
  497:             "          a      b\na         гЃ‚      1\n"
  498:             "bb      гЃ„гЃ„гЃ„    222\nc         гЃ†  33333\n"
  499:             "ddd  гЃ€гЃ€гЃ€гЃ€гЃ€гЃ€      4"
  500:         )
  501:         assert repr(df) == expected
  502: 
  503:         # last col
  504:         df = DataFrame(
  505:             {"a": [1, 222, 33333, 4], "b": ["гЃ‚", "гЃ„гЃ„гЃ„", "гЃ†", "гЃ€гЃ€гЃ€гЃ€гЃ€гЃ€"]},
  506:             index=["a", "bb", "c", "ddd"],
  507:         )
  508:         expected = (
  509:             "         a       b\na        1       гЃ‚\n"
  510:             "bb     222     гЃ„гЃ„гЃ„\nc    33333       гЃ†\n"
  511:             "ddd      4  гЃ€гЃ€гЃ€гЃ€гЃ€гЃ€"
  512:         )
  513:         assert repr(df) == expected
  514: 
  515:         # all col
  516:         df = DataFrame(
  517:             {
  518:                 "a": ["гЃ‚гЃ‚гЃ‚гЃ‚гЃ‚", "гЃ„", "гЃ†", "гЃ€гЃ€гЃ€"],
  519:                 "b": ["гЃ‚", "гЃ„гЃ„гЃ„", "гЃ†", "гЃ€гЃ€гЃ€гЃ€гЃ€гЃ€"],
  520:             },
  521:             index=["a", "bb", "c", "ddd"],
  522:         )
  523:         expected = (
  524:             "         a       b\na    гЃ‚гЃ‚гЃ‚гЃ‚гЃ‚       гЃ‚\n"
  525:             "bb       гЃ„     гЃ„гЃ„гЃ„\nc        гЃ†       гЃ†\n"
  526:             "ddd    гЃ€гЃ€гЃ€  гЃ€гЃ€гЃ€гЃ€гЃ€гЃ€"
  527:         )
  528:         assert repr(df) == expected
  529: 
  530:         # column name
  531:         df = DataFrame(
  532:             {
  533:                 "b": ["гЃ‚", "гЃ„гЃ„гЃ„", "гЃ†", "гЃ€гЃ€гЃ€гЃ€гЃ€гЃ€"],
  534:                 "гЃ‚гЃ‚гЃ‚гЃ‚гЃ‚": [1, 222, 33333, 4],
  535:             },
  536:             index=["a", "bb", "c", "ddd"],
  537:         )
  538:         expected = (
  539:             "          b  гЃ‚гЃ‚гЃ‚гЃ‚гЃ‚\na         гЃ‚      1\n"
  540:             "bb      гЃ„гЃ„гЃ„    222\nc         гЃ†  33333\n"
  541:             "ddd  гЃ€гЃ€гЃ€гЃ€гЃ€гЃ€      4"
  542:         )
  543:         assert repr(df) == expected
  544: 
  545:         # index
  546:         df = DataFrame(
  547:             {
  548:                 "a": ["гЃ‚гЃ‚гЃ‚гЃ‚гЃ‚", "гЃ„", "гЃ†", "гЃ€гЃ€гЃ€"],
  549:                 "b": ["гЃ‚", "гЃ„гЃ„гЃ„", "гЃ†", "гЃ€гЃ€гЃ€гЃ€гЃ€гЃ€"],
  550:             },
  551:             index=["гЃ‚гЃ‚гЃ‚", "гЃ„гЃ„гЃ„гЃ„гЃ„гЃ„", "гЃ†гЃ†", "гЃ€"],
  552:         )
  553:         expected = (
  554:             "            a       b\nгЃ‚гЃ‚гЃ‚     гЃ‚гЃ‚гЃ‚гЃ‚гЃ‚       гЃ‚\n"
  555:             "гЃ„гЃ„гЃ„гЃ„гЃ„гЃ„      гЃ„     гЃ„гЃ„гЃ„\nгЃ†гЃ†          гЃ†       гЃ†\n"
  556:             "гЃ€         гЃ€гЃ€гЃ€  гЃ€гЃ€гЃ€гЃ€гЃ€гЃ€"
  557:         )
  558:         assert repr(df) == expected
  559: 
  560:         # index name
  561:         df = DataFrame(
  562:             {
  563:                 "a": ["гЃ‚гЃ‚гЃ‚гЃ‚гЃ‚", "гЃ„", "гЃ†", "гЃ€гЃ€гЃ€"],
  564:                 "b": ["гЃ‚", "гЃ„гЃ„гЃ„", "гЃ†", "гЃ€гЃ€гЃ€гЃ€гЃ€гЃ€"],
  565:             },
  566:             index=Index(["гЃ‚", "гЃ„", "гЃ†гЃ†", "гЃ€"], name="гЃЉгЃЉгЃЉгЃЉ"),
  567:         )
  568:         expected = (
  569:             "          a       b\n"
  570:             "гЃЉгЃЉгЃЉгЃЉ               \n"
  571:             "гЃ‚     гЃ‚гЃ‚гЃ‚гЃ‚гЃ‚       гЃ‚\n"
  572:             "гЃ„         гЃ„     гЃ„гЃ„гЃ„\n"
  573:             "гЃ†гЃ†        гЃ†       гЃ†\n"
  574:             "гЃ€       гЃ€гЃ€гЃ€  гЃ€гЃ€гЃ€гЃ€гЃ€гЃ€"
  575:         )
  576:         assert repr(df) == expected
  577: 
  578:         # all
  579:         df = DataFrame(
  580:             {
  581:                 "гЃ‚гЃ‚гЃ‚": ["гЃ‚гЃ‚гЃ‚", "гЃ„", "гЃ†", "гЃ€гЃ€гЃ€гЃ€гЃ€"],
  582:                 "гЃ„гЃ„гЃ„гЃ„гЃ„": ["гЃ‚", "гЃ„гЃ„гЃ„", "гЃ†", "гЃ€гЃ€"],
  583:             },
  584:             index=Index(["гЃ‚", "гЃ„гЃ„гЃ„", "гЃ†гЃ†", "гЃ€"], name="гЃЉ"),
  585:         )
  586:         expected = (
  587:             "       гЃ‚гЃ‚гЃ‚ гЃ„гЃ„гЃ„гЃ„гЃ„\n"
  588:             "гЃЉ               \n"
  589:             "гЃ‚      гЃ‚гЃ‚гЃ‚     гЃ‚\n"
  590:             "гЃ„гЃ„гЃ„      гЃ„   гЃ„гЃ„гЃ„\n"
  591:             "гЃ†гЃ†       гЃ†     гЃ†\n"
  592:             "гЃ€    гЃ€гЃ€гЃ€гЃ€гЃ€    гЃ€гЃ€"
  593:         )
  594:         assert repr(df) == expected
  595: 
  596:         # MultiIndex
  597:         idx = MultiIndex.from_tuples(
  598:             [("гЃ‚", "гЃ„гЃ„"), ("гЃ†", "гЃ€"), ("гЃЉгЃЉгЃЉ", "гЃ‹гЃ‹гЃ‹гЃ‹"), ("гЃЌ", "гЃЏгЃЏ")]
  599:         )
  600:         df = DataFrame(
  601:             {
  602:                 "a": ["гЃ‚гЃ‚гЃ‚гЃ‚гЃ‚", "гЃ„", "гЃ†", "гЃ€гЃ€гЃ€"],
  603:                 "b": ["гЃ‚", "гЃ„гЃ„гЃ„", "гЃ†", "гЃ€гЃ€гЃ€гЃ€гЃ€гЃ€"],
  604:             },
  605:             index=idx,
  606:         )
  607:         expected = (
  608:             "              a       b\n"
  609:             "гЃ‚   гЃ„гЃ„    гЃ‚гЃ‚гЃ‚гЃ‚гЃ‚       гЃ‚\n"
  610:             "гЃ†   гЃ€         гЃ„     гЃ„гЃ„гЃ„\n"
  611:             "гЃЉгЃЉгЃЉ гЃ‹гЃ‹гЃ‹гЃ‹      гЃ†       гЃ†\n"
  612:             "гЃЌ   гЃЏгЃЏ      гЃ€гЃ€гЃ€  гЃ€гЃ€гЃ€гЃ€гЃ€гЃ€"
  613:         )
  614:         assert repr(df) == expected
  615: 
  616:         # truncate
  617:         with option_context("display.max_rows", 3, "display.max_columns", 3):
  618:             df = DataFrame(
  619:                 {
  620:                     "a": ["гЃ‚гЃ‚гЃ‚гЃ‚гЃ‚", "гЃ„", "гЃ†", "гЃ€гЃ€гЃ€"],
  621:                     "b": ["гЃ‚", "гЃ„гЃ„гЃ„", "гЃ†", "гЃ€гЃ€гЃ€гЃ€гЃ€гЃ€"],
  622:                     "c": ["гЃЉ", "гЃ‹", "гЃЌгЃЌгЃЌ", "гЃЏгЃЏгЃЏгЃЏгЃЏгЃЏ"],
  623:                     "гЃ‚гЃ‚гЃ‚гЃ‚": ["гЃ•", "гЃ—", "гЃ™", "гЃ›"],
  624:                 },
  625:                 columns=["a", "b", "c", "гЃ‚гЃ‚гЃ‚гЃ‚"],
  626:             )
  627: 
  628:             expected = (
  629:                 "        a  ... гЃ‚гЃ‚гЃ‚гЃ‚\n0   гЃ‚гЃ‚гЃ‚гЃ‚гЃ‚  ...    гЃ•\n"
  630:                 "..    ...  ...  ...\n3     гЃ€гЃ€гЃ€  ...    гЃ›\n"
  631:                 "\n[4 rows x 4 columns]"
  632:             )
  633:             assert repr(df) == expected
  634: 
  635:             df.index = ["гЃ‚гЃ‚гЃ‚", "гЃ„гЃ„гЃ„гЃ„", "гЃ†", "aaa"]
  636:             expected = (
  637:                 "         a  ... гЃ‚гЃ‚гЃ‚гЃ‚\nгЃ‚гЃ‚гЃ‚  гЃ‚гЃ‚гЃ‚гЃ‚гЃ‚  ...    гЃ•\n"
  638:                 "..     ...  ...  ...\naaa    гЃ€гЃ€гЃ€  ...    гЃ›\n"
  639:                 "\n[4 rows x 4 columns]"
  640:             )
  641:             assert repr(df) == expected
  642: 
  643:     def test_east_asian_unicode_true(self):
  644:         # Enable Unicode option -----------------------------------------
  645:         with option_context("display.unicode.east_asian_width", True):
  646:             # mid col
  647:             df = DataFrame(
  648:                 {"a": ["гЃ‚", "гЃ„гЃ„гЃ„", "гЃ†", "гЃ€гЃ€гЃ€гЃ€гЃ€гЃ€"], "b": [1, 222, 33333, 4]},
  649:                 index=["a", "bb", "c", "ddd"],
  650:             )
  651:             expected = (
  652:                 "                a      b\na              гЃ‚      1\n"
  653:                 "bb         гЃ„гЃ„гЃ„    222\nc              гЃ†  33333\n"
  654:                 "ddd  гЃ€гЃ€гЃ€гЃ€гЃ€гЃ€      4"
  655:             )
  656:             assert repr(df) == expected
  657: 
  658:             # last col
  659:             df = DataFrame(
  660:                 {"a": [1, 222, 33333, 4], "b": ["гЃ‚", "гЃ„гЃ„гЃ„", "гЃ†", "гЃ€гЃ€гЃ€гЃ€гЃ€гЃ€"]},
  661:                 index=["a", "bb", "c", "ddd"],
  662:             )
  663:             expected = (
  664:                 "         a             b\na        1            гЃ‚\n"
  665:                 "bb     222        гЃ„гЃ„гЃ„\nc    33333            гЃ†\n"
  666:                 "ddd      4  гЃ€гЃ€гЃ€гЃ€гЃ€гЃ€"
  667:             )
  668:             assert repr(df) == expected
  669: 
  670:             # all col
  671:             df = DataFrame(
  672:                 {
  673:                     "a": ["гЃ‚гЃ‚гЃ‚гЃ‚гЃ‚", "гЃ„", "гЃ†", "гЃ€гЃ€гЃ€"],
  674:                     "b": ["гЃ‚", "гЃ„гЃ„гЃ„", "гЃ†", "гЃ€гЃ€гЃ€гЃ€гЃ€гЃ€"],
  675:                 },
  676:                 index=["a", "bb", "c", "ddd"],
  677:             )
  678:             expected = (
  679:                 "              a             b\n"
  680:                 "a    гЃ‚гЃ‚гЃ‚гЃ‚гЃ‚            гЃ‚\n"
  681:                 "bb           гЃ„        гЃ„гЃ„гЃ„\n"
  682:                 "c            гЃ†            гЃ†\n"
  683:                 "ddd      гЃ€гЃ€гЃ€  гЃ€гЃ€гЃ€гЃ€гЃ€гЃ€"
  684:             )
  685:             assert repr(df) == expected
  686: 
  687:             # column name
  688:             df = DataFrame(
  689:                 {
  690:                     "b": ["гЃ‚", "гЃ„гЃ„гЃ„", "гЃ†", "гЃ€гЃ€гЃ€гЃ€гЃ€гЃ€"],
  691:                     "гЃ‚гЃ‚гЃ‚гЃ‚гЃ‚": [1, 222, 33333, 4],
  692:                 },
  693:                 index=["a", "bb", "c", "ddd"],
  694:             )
  695:             expected = (
  696:                 "                b  гЃ‚гЃ‚гЃ‚гЃ‚гЃ‚\n"
  697:                 "a              гЃ‚           1\n"
  698:                 "bb         гЃ„гЃ„гЃ„         222\n"
  699:                 "c              гЃ†       33333\n"
  700:                 "ddd  гЃ€гЃ€гЃ€гЃ€гЃ€гЃ€           4"
  701:             )
  702:             assert repr(df) == expected
  703: 
  704:             # index
  705:             df = DataFrame(
  706:                 {
  707:                     "a": ["гЃ‚гЃ‚гЃ‚гЃ‚гЃ‚", "гЃ„", "гЃ†", "гЃ€гЃ€гЃ€"],
  708:                     "b": ["гЃ‚", "гЃ„гЃ„гЃ„", "гЃ†", "гЃ€гЃ€гЃ€гЃ€гЃ€гЃ€"],
  709:                 },
  710:                 index=["гЃ‚гЃ‚гЃ‚", "гЃ„гЃ„гЃ„гЃ„гЃ„гЃ„", "гЃ†гЃ†", "гЃ€"],
  711:             )
  712:             expected = (
  713:                 "                       a             b\n"
  714:                 "гЃ‚гЃ‚гЃ‚        гЃ‚гЃ‚гЃ‚гЃ‚гЃ‚            гЃ‚\n"
  715:                 "гЃ„гЃ„гЃ„гЃ„гЃ„гЃ„          гЃ„        гЃ„гЃ„гЃ„\n"
  716:                 "гЃ†гЃ†                  гЃ†            гЃ†\n"
  717:                 "гЃ€                гЃ€гЃ€гЃ€  гЃ€гЃ€гЃ€гЃ€гЃ€гЃ€"
  718:             )
  719:             assert repr(df) == expected
  720: 
  721:             # index name
  722:             df = DataFrame(
  723:                 {
  724:                     "a": ["гЃ‚гЃ‚гЃ‚гЃ‚гЃ‚", "гЃ„", "гЃ†", "гЃ€гЃ€гЃ€"],
  725:                     "b": ["гЃ‚", "гЃ„гЃ„гЃ„", "гЃ†", "гЃ€гЃ€гЃ€гЃ€гЃ€гЃ€"],
  726:                 },
  727:                 index=Index(["гЃ‚", "гЃ„", "гЃ†гЃ†", "гЃ€"], name="гЃЉгЃЉгЃЉгЃЉ"),
  728:             )
  729:             expected = (
  730:                 "                   a             b\n"
  731:                 "гЃЉгЃЉгЃЉгЃЉ                          \n"
  732:                 "гЃ‚        гЃ‚гЃ‚гЃ‚гЃ‚гЃ‚            гЃ‚\n"
  733:                 "гЃ„                гЃ„        гЃ„гЃ„гЃ„\n"
  734:                 "гЃ†гЃ†              гЃ†            гЃ†\n"
  735:                 "гЃ€            гЃ€гЃ€гЃ€  гЃ€гЃ€гЃ€гЃ€гЃ€гЃ€"
  736:             )
  737:             assert repr(df) == expected
  738: 
  739:             # all
  740:             df = DataFrame(
  741:                 {
  742:                     "гЃ‚гЃ‚гЃ‚": ["гЃ‚гЃ‚гЃ‚", "гЃ„", "гЃ†", "гЃ€гЃ€гЃ€гЃ€гЃ€"],
  743:                     "гЃ„гЃ„гЃ„гЃ„гЃ„": ["гЃ‚", "гЃ„гЃ„гЃ„", "гЃ†", "гЃ€гЃ€"],
  744:                 },
  745:                 index=Index(["гЃ‚", "гЃ„гЃ„гЃ„", "гЃ†гЃ†", "гЃ€"], name="гЃЉ"),
  746:             )
  747:             expected = (
  748:                 "            гЃ‚гЃ‚гЃ‚ гЃ„гЃ„гЃ„гЃ„гЃ„\n"
  749:                 "гЃЉ                           \n"
  750:                 "гЃ‚          гЃ‚гЃ‚гЃ‚         гЃ‚\n"
  751:                 "гЃ„гЃ„гЃ„          гЃ„     гЃ„гЃ„гЃ„\n"
  752:                 "гЃ†гЃ†            гЃ†         гЃ†\n"
  753:                 "гЃ€      гЃ€гЃ€гЃ€гЃ€гЃ€       гЃ€гЃ€"
  754:             )
  755:             assert repr(df) == expected
  756: 
  757:             # MultiIndex
  758:             idx = MultiIndex.from_tuples(
  759:                 [("гЃ‚", "гЃ„гЃ„"), ("гЃ†", "гЃ€"), ("гЃЉгЃЉгЃЉ", "гЃ‹гЃ‹гЃ‹гЃ‹"), ("гЃЌ", "гЃЏгЃЏ")]
  760:             )
  761:             df = DataFrame(
  762:                 {
  763:                     "a": ["гЃ‚гЃ‚гЃ‚гЃ‚гЃ‚", "гЃ„", "гЃ†", "гЃ€гЃ€гЃ€"],
  764:                     "b": ["гЃ‚", "гЃ„гЃ„гЃ„", "гЃ†", "гЃ€гЃ€гЃ€гЃ€гЃ€гЃ€"],
  765:                 },
  766:                 index=idx,
  767:             )
  768:             expected = (
  769:                 "                          a             b\n"
  770:                 "гЃ‚     гЃ„гЃ„      гЃ‚гЃ‚гЃ‚гЃ‚гЃ‚            гЃ‚\n"
  771:                 "гЃ†     гЃ€                гЃ„        гЃ„гЃ„гЃ„\n"
  772:                 "гЃЉгЃЉгЃЉ гЃ‹гЃ‹гЃ‹гЃ‹          гЃ†            гЃ†\n"
  773:                 "гЃЌ     гЃЏгЃЏ          гЃ€гЃ€гЃ€  гЃ€гЃ€гЃ€гЃ€гЃ€гЃ€"
  774:             )
  775:             assert repr(df) == expected
  776: 
  777:             # truncate
  778:             with option_context("display.max_rows", 3, "display.max_columns", 3):
  779:                 df = DataFrame(
  780:                     {
  781:                         "a": ["гЃ‚гЃ‚гЃ‚гЃ‚гЃ‚", "гЃ„", "гЃ†", "гЃ€гЃ€гЃ€"],
  782:                         "b": ["гЃ‚", "гЃ„гЃ„гЃ„", "гЃ†", "гЃ€гЃ€гЃ€гЃ€гЃ€гЃ€"],
  783:                         "c": ["гЃЉ", "гЃ‹", "гЃЌгЃЌгЃЌ", "гЃЏгЃЏгЃЏгЃЏгЃЏгЃЏ"],
  784:                         "гЃ‚гЃ‚гЃ‚гЃ‚": ["гЃ•", "гЃ—", "гЃ™", "гЃ›"],
  785:                     },
  786:                     columns=["a", "b", "c", "гЃ‚гЃ‚гЃ‚гЃ‚"],
  787:                 )
  788: 
  789:                 expected = (
  790:                     "             a  ... гЃ‚гЃ‚гЃ‚гЃ‚\n"
  791:                     "0   гЃ‚гЃ‚гЃ‚гЃ‚гЃ‚  ...       гЃ•\n"
  792:                     "..         ...  ...      ...\n"
  793:                     "3       гЃ€гЃ€гЃ€  ...       гЃ›\n"
  794:                     "\n[4 rows x 4 columns]"
  795:                 )
  796:                 assert repr(df) == expected
  797: 
  798:                 df.index = ["гЃ‚гЃ‚гЃ‚", "гЃ„гЃ„гЃ„гЃ„", "гЃ†", "aaa"]
  799:                 expected = (
  800:                     "                 a  ... гЃ‚гЃ‚гЃ‚гЃ‚\n"
  801:                     "гЃ‚гЃ‚гЃ‚  гЃ‚гЃ‚гЃ‚гЃ‚гЃ‚  ...       гЃ•\n"
  802:                     "...            ...  ...      ...\n"
  803:                     "aaa         гЃ€гЃ€гЃ€  ...       гЃ›\n"
  804:                     "\n[4 rows x 4 columns]"
  805:                 )
  806:                 assert repr(df) == expected
  807: 
  808:             # ambiguous unicode
  809:             df = DataFrame(
  810:                 {
  811:                     "b": ["гЃ‚", "гЃ„гЃ„гЃ„", "ВЎВЎ", "гЃ€гЃ€гЃ€гЃ€гЃ€гЃ€"],
  812:                     "гЃ‚гЃ‚гЃ‚гЃ‚гЃ‚": [1, 222, 33333, 4],
  813:                 },
  814:                 index=["a", "bb", "c", "ВЎВЎВЎ"],
  815:             )
  816:             expected = (
  817:                 "                b  гЃ‚гЃ‚гЃ‚гЃ‚гЃ‚\n"
  818:                 "a              гЃ‚           1\n"
  819:                 "bb         гЃ„гЃ„гЃ„         222\n"
  820:                 "c              ВЎВЎ       33333\n"
  821:                 "ВЎВЎВЎ  гЃ€гЃ€гЃ€гЃ€гЃ€гЃ€           4"
  822:             )
  823:             assert repr(df) == expected
  824: 
  825:     def test_to_string_buffer_all_unicode(self):
  826:         buf = StringIO()
  827: 
  828:         empty = DataFrame({"c/\u03c3": Series(dtype=object)})
  829:         nonempty = DataFrame({"c/\u03c3": Series([1, 2, 3])})
  830: 
  831:         print(empty, file=buf)
  832:         print(nonempty, file=buf)
  833: 
  834:         # this should work
  835:         buf.getvalue()
  836: 
  837:     @pytest.mark.parametrize(
  838:         "index_scalar",
  839:         [
  840:             "a" * 10,
  841:             1,
  842:             Timestamp(2020, 1, 1),
  843:             pd.Period("2020-01-01"),
  844:         ],
  845:     )
  846:     @pytest.mark.parametrize("h", [10, 20])
  847:     @pytest.mark.parametrize("w", [10, 20])
  848:     def test_to_string_truncate_indices(self, index_scalar, h, w):
  849:         with option_context("display.expand_frame_repr", False):
  850:             df = DataFrame(
  851:                 index=[index_scalar] * h, columns=[str(i) * 10 for i in range(w)]
  852:             )
  853:             with option_context("display.max_rows", 15):
  854:                 if h == 20:
  855:                     assert has_vertically_truncated_repr(df)
  856:                 else:
  857:                     assert not has_vertically_truncated_repr(df)
  858:             with option_context("display.max_columns", 15):
  859:                 if w == 20:
  860:                     assert has_horizontally_truncated_repr(df)
  861:                 else:
  862:                     assert not has_horizontally_truncated_repr(df)
  863:             with option_context("display.max_rows", 15, "display.max_columns", 15):
  864:                 if h == 20 and w == 20:
  865:                     assert has_doubly_truncated_repr(df)
  866:                 else:
  867:                     assert not has_doubly_truncated_repr(df)
  868: 
  869:     def test_to_string_truncate_multilevel(self):
  870:         arrays = [
  871:             ["bar", "bar", "baz", "baz", "foo", "foo", "qux", "qux"],
  872:             ["one", "two", "one", "two", "one", "two", "one", "two"],
  873:         ]
  874:         df = DataFrame(index=arrays, columns=arrays)
  875:         with option_context("display.max_rows", 7, "display.max_columns", 7):
  876:             assert has_doubly_truncated_repr(df)
  877: 
  878:     @pytest.mark.parametrize("dtype", ["object", "datetime64[us]"])
  879:     def test_truncate_with_different_dtypes(self, dtype):
  880:         # 11594, 12045
  881:         # when truncated the dtypes of the splits can differ
  882: 
  883:         # 11594
  884:         ser = Series(
  885:             [datetime(2012, 1, 1)] * 10
  886:             + [datetime(1012, 1, 2)]
  887:             + [datetime(2012, 1, 3)] * 10,
  888:             dtype=dtype,
  889:         )
  890: 
  891:         with option_context("display.max_rows", 8):
  892:             result = str(ser)
  893:         assert dtype in result
  894: 
  895:     def test_truncate_with_different_dtypes2(self):
  896:         # 12045
  897:         df = DataFrame({"text": ["some words"] + [None] * 9}, dtype=object)
  898: 
  899:         with option_context("display.max_rows", 8, "display.max_columns", 3):
  900:             result = str(df)
  901:             assert "None" in result
  902:             assert "NaN" not in result
  903: 
  904:     def test_truncate_with_different_dtypes_multiindex(self):
  905:         # GH#13000
  906:         df = DataFrame({"Vals": range(100)})
  907:         frame = pd.concat([df], keys=["Sweep"], names=["Sweep", "Index"])
  908:         result = repr(frame)
  909: 
  910:         result2 = repr(frame.iloc[:5])
  911:         assert result.startswith(result2)
  912: 
  913:     def test_datetimelike_frame(self):
  914:         # GH 12211
  915:         df = DataFrame({"date": [Timestamp("20130101").tz_localize("UTC")] + [NaT] * 5})
  916: 
  917:         with option_context("display.max_rows", 5):
  918:             result = str(df)
  919:             assert "2013-01-01 00:00:00+00:00" in result
  920:             assert "NaT" in result
  921:             assert "..." in result
  922:             assert "[6 rows x 1 columns]" in result
  923: 
  924:         dts = [Timestamp("2011-01-01", tz="US/Eastern")] * 5 + [NaT] * 5
  925:         df = DataFrame({"dt": dts, "x": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]})
  926:         with option_context("display.max_rows", 5):
  927:             expected = (
  928:                 "                          dt   x\n"
  929:                 "0  2011-01-01 00:00:00-05:00   1\n"
  930:                 "1  2011-01-01 00:00:00-05:00   2\n"
  931:                 "..                       ...  ..\n"
  932:                 "8                        NaT   9\n"
  933:                 "9                        NaT  10\n\n"
  934:                 "[10 rows x 2 columns]"
  935:             )
  936:             assert repr(df) == expected
  937: 
  938:         dts = [NaT] * 5 + [Timestamp("2011-01-01", tz="US/Eastern")] * 5
  939:         df = DataFrame({"dt": dts, "x": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]})
  940:         with option_context("display.max_rows", 5):
  941:             expected = (
  942:                 "                          dt   x\n"
  943:                 "0                        NaT   1\n"
  944:                 "1                        NaT   2\n"
  945:                 "..                       ...  ..\n"
  946:                 "8  2011-01-01 00:00:00-05:00   9\n"
  947:                 "9  2011-01-01 00:00:00-05:00  10\n\n"
  948:                 "[10 rows x 2 columns]"
  949:             )
  950:             assert repr(df) == expected
  951: 
  952:         dts = [Timestamp("2011-01-01", tz="Asia/Tokyo")] * 5 + [
  953:             Timestamp("2011-01-01", tz="US/Eastern")
  954:         ] * 5
  955:         df = DataFrame({"dt": dts, "x": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]})
  956:         with option_context("display.max_rows", 5):
  957:             expected = (
  958:                 "                           dt   x\n"
  959:                 "0   2011-01-01 00:00:00+09:00   1\n"
  960:                 "1   2011-01-01 00:00:00+09:00   2\n"
  961:                 "..                        ...  ..\n"
  962:                 "8   2011-01-01 00:00:00-05:00   9\n"
  963:                 "9   2011-01-01 00:00:00-05:00  10\n\n"
  964:                 "[10 rows x 2 columns]"
  965:             )
  966:             assert repr(df) == expected
  967: 
  968:     @pytest.mark.parametrize(
  969:         "start_date",
  970:         [
  971:             "2017-01-01 23:59:59.999999999",
  972:             "2017-01-01 23:59:59.99999999",
  973:             "2017-01-01 23:59:59.9999999",
  974:             "2017-01-01 23:59:59.999999",
  975:             "2017-01-01 23:59:59.99999",
  976:             "2017-01-01 23:59:59.9999",
  977:         ],
  978:     )
  979:     def test_datetimeindex_highprecision(self, start_date):
  980:         # GH19030
  981:         # Check that high-precision time values for the end of day are
  982:         # included in repr for DatetimeIndex
  983:         df = DataFrame({"A": date_range(start=start_date, freq="D", periods=5)})
  984:         result = str(df)
  985:         assert start_date in result
  986: 
  987:         dti = date_range(start=start_date, freq="D", periods=5)
  988:         df = DataFrame({"A": range(5)}, index=dti)
  989:         result = str(df.index)
  990:         assert start_date in result
  991: 
  992:     def test_string_repr_encoding(self, datapath):
  993:         filepath = datapath("io", "parser", "data", "unicode_series.csv")
  994:         df = read_csv(filepath, header=None, encoding="latin1")
  995:         repr(df)
  996:         repr(df[1])
  997: 
  998:     def test_repr_corner(self):
  999:         # representing infs poses no problems
 1000:         df = DataFrame({"foo": [-np.inf, np.inf]})
 1001:         repr(df)
 1002: 
 1003:     def test_frame_info_encoding(self):
 1004:         index = ["'Til There Was You (1997)", "ldum klaka (Cold Fever) (1994)"]
 1005:         with option_context("display.max_rows", 1):
 1006:             df = DataFrame(columns=["a", "b", "c"], index=index)
 1007:             repr(df)
 1008:             repr(df.T)
 1009: 
 1010:     def test_wide_repr(self):
 1011:         with option_context(
 1012:             "mode.sim_interactive",
 1013:             True,
 1014:             "display.show_dimensions",
 1015:             True,
 1016:             "display.max_columns",
 1017:             20,
 1018:         ):
 1019:             max_cols = get_option("display.max_columns")
 1020:             df = DataFrame([["a" * 25] * (max_cols - 1)] * 10)
 1021:             with option_context("display.expand_frame_repr", False):
 1022:                 rep_str = repr(df)
 1023: 
 1024:             assert f"10 rows x {max_cols - 1} columns" in rep_str
 1025:             with option_context("display.expand_frame_repr", True):
 1026:                 wide_repr = repr(df)
 1027:             assert rep_str != wide_repr
 1028: 
 1029:             with option_context("display.width", 120):
 1030:                 wider_repr = repr(df)
 1031:                 assert len(wider_repr) < len(wide_repr)
 1032: 
 1033:     def test_wide_repr_wide_columns(self):
 1034:         with option_context("mode.sim_interactive", True, "display.max_columns", 20):
 1035:             df = DataFrame(
 1036:                 np.random.default_rng(2).standard_normal((5, 3)),
 1037:                 columns=["a" * 90, "b" * 90, "c" * 90],
 1038:             )
 1039:             rep_str = repr(df)
 1040: 
 1041:             assert len(rep_str.splitlines()) == 20
 1042: 
 1043:     def test_wide_repr_named(self):
 1044:         with option_context("mode.sim_interactive", True, "display.max_columns", 20):
 1045:             max_cols = get_option("display.max_columns")
 1046:             df = DataFrame([["a" * 25] * (max_cols - 1)] * 10)
 1047:             df.index.name = "DataFrame Index"
 1048:             with option_context("display.expand_frame_repr", False):
 1049:                 rep_str = repr(df)
 1050:             with option_context("display.expand_frame_repr", True):
 1051:                 wide_repr = repr(df)
 1052:             assert rep_str != wide_repr
 1053: 
 1054:             with option_context("display.width", 150):
 1055:                 wider_repr = repr(df)
 1056:                 assert len(wider_repr) < len(wide_repr)
 1057: 
 1058:             for line in wide_repr.splitlines()[1::13]:
 1059:                 assert "DataFrame Index" in line
 1060: 
 1061:     def test_wide_repr_multiindex(self):
 1062:         with option_context("mode.sim_interactive", True, "display.max_columns", 20):
 1063:             midx = MultiIndex.from_arrays([["a" * 5] * 10] * 2)
 1064:             max_cols = get_option("display.max_columns")
 1065:             df = DataFrame([["a" * 25] * (max_cols - 1)] * 10, index=midx)
 1066:             df.index.names = ["Level 0", "Level 1"]
 1067:             with option_context("display.expand_frame_repr", False):
 1068:                 rep_str = repr(df)
 1069:             with option_context("display.expand_frame_repr", True):
 1070:                 wide_repr = repr(df)
 1071:             assert rep_str != wide_repr
 1072: 
 1073:             with option_context("display.width", 150):
 1074:                 wider_repr = repr(df)
 1075:                 assert len(wider_repr) < len(wide_repr)
 1076: 
 1077:             for line in wide_repr.splitlines()[1::13]:
 1078:                 assert "Level 0 Level 1" in line
 1079: 
 1080:     def test_wide_repr_multiindex_cols(self):
 1081:         with option_context("mode.sim_interactive", True, "display.max_columns", 20):
 1082:             max_cols = get_option("display.max_columns")
 1083:             midx = MultiIndex.from_arrays([["a" * 5] * 10] * 2)
 1084:             mcols = MultiIndex.from_arrays([["b" * 3] * (max_cols - 1)] * 2)
 1085:             df = DataFrame(
 1086:                 [["c" * 25] * (max_cols - 1)] * 10, index=midx, columns=mcols
 1087:             )
 1088:             df.index.names = ["Level 0", "Level 1"]
 1089:             with option_context("display.expand_frame_repr", False):
 1090:                 rep_str = repr(df)
 1091:             with option_context("display.expand_frame_repr", True):
 1092:                 wide_repr = repr(df)
 1093:             assert rep_str != wide_repr
 1094: 
 1095:         with option_context("display.width", 150, "display.max_columns", 20):
 1096:             wider_repr = repr(df)
 1097:             assert len(wider_repr) < len(wide_repr)
 1098: 
 1099:     def test_wide_repr_unicode(self):
 1100:         with option_context("mode.sim_interactive", True, "display.max_columns", 20):
 1101:             max_cols = 20
 1102:             df = DataFrame([["a" * 25] * 10] * (max_cols - 1))
 1103:             with option_context("display.expand_frame_repr", False):
 1104:                 rep_str = repr(df)
 1105:             with option_context("display.expand_frame_repr", True):
 1106:                 wide_repr = repr(df)
 1107:             assert rep_str != wide_repr
 1108: 
 1109:             with option_context("display.width", 150):
 1110:                 wider_repr = repr(df)
 1111:                 assert len(wider_repr) < len(wide_repr)
 1112: 
 1113:     def test_wide_repr_wide_long_columns(self):
 1114:         with option_context("mode.sim_interactive", True):
 1115:             df = DataFrame({"a": ["a" * 30, "b" * 30], "b": ["c" * 70, "d" * 80]})
 1116: 
 1117:             result = repr(df)
 1118:             assert "ccccc" in result
 1119:             assert "ddddd" in result
 1120: 
 1121:     def test_long_series(self):
 1122:         n = 1000
 1123:         s = Series(
 1124:             np.random.default_rng(2).integers(-50, 50, n),
 1125:             index=[f"s{x:04d}" for x in range(n)],
 1126:             dtype="int64",
 1127:         )
 1128: 
 1129:         str_rep = str(s)
 1130:         nmatches = len(re.findall("dtype", str_rep))
 1131:         assert nmatches == 1
 1132: 
 1133:     def test_to_string_ascii_error(self):
 1134:         data = [
 1135:             (
 1136:                 "0  ",
 1137:                 "                        .gitignore ",
 1138:                 "     5 ",
 1139:                 " \xe2\x80\xa2\xe2\x80\xa2\xe2\x80\xa2\xe2\x80\xa2\xe2\x80\xa2",
 1140:             )
 1141:         ]
 1142:         df = DataFrame(data)
 1143: 
 1144:         # it works!
 1145:         repr(df)
 1146: 
 1147:     def test_show_dimensions(self):
 1148:         df = DataFrame(123, index=range(10, 15), columns=range(30))
 1149: 
 1150:         with option_context(
 1151:             "display.max_rows",
 1152:             10,
 1153:             "display.max_columns",
 1154:             40,
 1155:             "display.width",
 1156:             500,
 1157:             "display.expand_frame_repr",
 1158:             "info",
 1159:             "display.show_dimensions",
 1160:             True,
 1161:         ):
 1162:             assert "5 rows" in str(df)
 1163:             assert "5 rows" in df._repr_html_()
 1164:         with option_context(
 1165:             "display.max_rows",
 1166:             10,
 1167:             "display.max_columns",
 1168:             40,
 1169:             "display.width",
 1170:             500,
 1171:             "display.expand_frame_repr",
 1172:             "info",
 1173:             "display.show_dimensions",
 1174:             False,
 1175:         ):
 1176:             assert "5 rows" not in str(df)
 1177:             assert "5 rows" not in df._repr_html_()
 1178:         with option_context(
 1179:             "display.max_rows",
 1180:             2,
 1181:             "display.max_columns",
 1182:             2,
 1183:             "display.width",
 1184:             500,
 1185:             "display.expand_frame_repr",
 1186:             "info",
 1187:             "display.show_dimensions",
 1188:             "truncate",
 1189:         ):
 1190:             assert "5 rows" in str(df)
 1191:             assert "5 rows" in df._repr_html_()
 1192:         with option_context(
 1193:             "display.max_rows",
 1194:             10,
 1195:             "display.max_columns",
 1196:             40,
 1197:             "display.width",
 1198:             500,
 1199:             "display.expand_frame_repr",
 1200:             "info",
 1201:             "display.show_dimensions",
 1202:             "truncate",
 1203:         ):
 1204:             assert "5 rows" not in str(df)
 1205:             assert "5 rows" not in df._repr_html_()
 1206: 
 1207:     def test_info_repr(self):
 1208:         # GH#21746 For tests inside a terminal (i.e. not CI) we need to detect
 1209:         # the terminal size to ensure that we try to print something "too big"
 1210:         term_width, term_height = get_terminal_size()
 1211: 
 1212:         max_rows = 60
 1213:         max_cols = 20 + (max(term_width, 80) - 80) // 4
 1214:         # Long
 1215:         h, w = max_rows + 1, max_cols - 1
 1216:         df = DataFrame({k: np.arange(1, 1 + h) for k in np.arange(w)})
 1217:         assert has_vertically_truncated_repr(df)
 1218:         with option_context("display.large_repr", "info"):
 1219:             assert has_info_repr(df)
 1220: 
 1221:         # Wide
 1222:         h, w = max_rows - 1, max_cols + 1
 1223:         df = DataFrame({k: np.arange(1, 1 + h) for k in np.arange(w)})
 1224:         assert has_horizontally_truncated_repr(df)
 1225:         with option_context(
 1226:             "display.large_repr", "info", "display.max_columns", max_cols
 1227:         ):
 1228:             assert has_info_repr(df)
 1229: 
 1230:     def test_info_repr_max_cols(self):
 1231:         # GH #6939
 1232:         df = DataFrame(np.random.default_rng(2).standard_normal((10, 5)))
 1233:         with option_context(
 1234:             "display.large_repr",
 1235:             "info",
 1236:             "display.max_columns",
 1237:             1,
 1238:             "display.max_info_columns",
 1239:             4,
 1240:         ):
 1241:             assert has_non_verbose_info_repr(df)
 1242: 
 1243:         with option_context(
 1244:             "display.large_repr",
 1245:             "info",
 1246:             "display.max_columns",
 1247:             1,
 1248:             "display.max_info_columns",
 1249:             5,
 1250:         ):
 1251:             assert not has_non_verbose_info_repr(df)
 1252: 
 1253:         # FIXME: don't leave commented-out
 1254:         # test verbose overrides
 1255:         # set_option('display.max_info_columns', 4)  # exceeded
 1256: 
 1257:     def test_pprint_pathological_object(self):
 1258:         """
 1259:         If the test fails, it at least won't hang.
 1260:         """
 1261: 
 1262:         class A:
 1263:             def __getitem__(self, key):
 1264:                 return 3  # obviously simplified
 1265: 
 1266:         df = DataFrame([A()])
 1267:         repr(df)  # just don't die
 1268: 
 1269:     def test_float_trim_zeros(self):
 1270:         vals = [
 1271:             2.08430917305e10,
 1272:             3.52205017305e10,
 1273:             2.30674817305e10,
 1274:             2.03954217305e10,
 1275:             5.59897817305e10,
 1276:         ]
 1277:         skip = True
 1278:         for line in repr(DataFrame({"A": vals})).split("\n")[:-2]:
 1279:             if line.startswith("dtype:"):
 1280:                 continue
 1281:             if _three_digit_exp():
 1282:                 assert ("+010" in line) or skip
 1283:             else:
 1284:                 assert ("+10" in line) or skip
 1285:             skip = False
 1286: 
 1287:     @pytest.mark.parametrize(
 1288:         "data, expected",
 1289:         [
 1290:             (["3.50"], "0    3.50\ndtype: object"),
 1291:             ([1.20, "1.00"], "0     1.2\n1    1.00\ndtype: object"),
 1292:             ([np.nan], "0   NaN\ndtype: float64"),
 1293:             ([None], "0    None\ndtype: object"),
 1294:             (["3.50", np.nan], "0    3.50\n1     NaN\ndtype: object"),
 1295:             ([3.50, np.nan], "0    3.5\n1    NaN\ndtype: float64"),
 1296:             ([3.50, np.nan, "3.50"], "0     3.5\n1     NaN\n2    3.50\ndtype: object"),
 1297:             ([3.50, None, "3.50"], "0     3.5\n1    None\n2    3.50\ndtype: object"),
 1298:         ],
 1299:     )
 1300:     def test_repr_str_float_truncation(self, data, expected, using_infer_string):
 1301:         # GH#38708
 1302:         series = Series(data, dtype=object if "3.50" in data else None)
 1303:         result = repr(series)
 1304:         assert result == expected
 1305: 
 1306:     @pytest.mark.parametrize(
 1307:         "float_format,expected",
 1308:         [
 1309:             ("{:,.0f}".format, "0   1,000\n1    test\ndtype: object"),
 1310:             ("{:.4f}".format, "0   1000.0000\n1        test\ndtype: object"),
 1311:         ],
 1312:     )
 1313:     def test_repr_float_format_in_object_col(self, float_format, expected):
 1314:         # GH#40024
 1315:         df = Series([1000.0, "test"])
 1316:         with option_context("display.float_format", float_format):
 1317:             result = repr(df)
 1318: 
 1319:         assert result == expected
 1320: 
 1321:     def test_period(self):
 1322:         # GH 12615
 1323:         df = DataFrame(
 1324:             {
 1325:                 "A": pd.period_range("2013-01", periods=4, freq="M"),
 1326:                 "B": [
 1327:                     pd.Period("2011-01", freq="M"),
 1328:                     pd.Period("2011-02-01", freq="D"),
 1329:                     pd.Period("2011-03-01 09:00", freq="h"),
 1330:                     pd.Period("2011-04", freq="M"),
 1331:                 ],
 1332:                 "C": list("abcd"),
 1333:             }
 1334:         )
 1335:         exp = (
 1336:             "         A                 B  C\n"
 1337:             "0  2013-01           2011-01  a\n"
 1338:             "1  2013-02        2011-02-01  b\n"
 1339:             "2  2013-03  2011-03-01 09:00  c\n"
 1340:             "3  2013-04           2011-04  d"
 1341:         )
 1342:         assert str(df) == exp
 1343: 
 1344:     @pytest.mark.parametrize(
 1345:         "length, max_rows, min_rows, expected",
 1346:         [
 1347:             (10, 10, 10, 10),
 1348:             (10, 10, None, 10),
 1349:             (10, 8, None, 8),
 1350:             (20, 30, 10, 30),  # max_rows > len(frame), hence max_rows
 1351:             (50, 30, 10, 10),  # max_rows < len(frame), hence min_rows
 1352:             (100, 60, 10, 10),  # same
 1353:             (60, 60, 10, 60),  # edge case
 1354:             (61, 60, 10, 10),  # edge case
 1355:         ],
 1356:     )
 1357:     def test_max_rows_fitted(self, length, min_rows, max_rows, expected):
 1358:         """Check that display logic is correct.
 1359: 
 1360:         GH #37359
 1361: 
 1362:         See description here:
 1363:         https://pandas.pydata.org/docs/dev/user_guide/options.html#frequently-used-options
 1364:         """
 1365:         formatter = fmt.DataFrameFormatter(
 1366:             DataFrame(np.random.default_rng(2).random((length, 3))),
 1367:             max_rows=max_rows,
 1368:             min_rows=min_rows,
 1369:         )
 1370:         result = formatter.max_rows_fitted
 1371:         assert result == expected
 1372: 
 1373: 
 1374: def gen_series_formatting():
 1375:     s1 = Series(["a"] * 100)
 1376:     s2 = Series(["ab"] * 100)
 1377:     s3 = Series(["a", "ab", "abc", "abcd", "abcde", "abcdef"])
 1378:     s4 = s3[::-1]
 1379:     test_sers = {"onel": s1, "twol": s2, "asc": s3, "desc": s4}
 1380:     return test_sers
 1381: 
 1382: 
 1383: class TestSeriesFormatting:
 1384:     def test_freq_name_separation(self):
 1385:         s = Series(
 1386:             np.random.default_rng(2).standard_normal(10),
 1387:             index=date_range("1/1/2000", periods=10),
 1388:             name=0,
 1389:         )
 1390: 
 1391:         result = repr(s)
 1392:         assert "Freq: D, Name: 0" in result
 1393: 
 1394:     def test_unicode_name_in_footer(self):
 1395:         s = Series([1, 2], name="\u05e2\u05d1\u05e8\u05d9\u05ea")
 1396:         sf = fmt.SeriesFormatter(s, name="\u05e2\u05d1\u05e8\u05d9\u05ea")
 1397:         sf._get_footer()  # should not raise exception
 1398: 
 1399:     @pytest.mark.xfail(
 1400:         using_pyarrow_string_dtype(), reason="Fixup when arrow is default"
 1401:     )
 1402:     def test_east_asian_unicode_series(self):
 1403:         # not aligned properly because of east asian width
 1404: 
 1405:         # unicode index
 1406:         s = Series(["a", "bb", "CCC", "D"], index=["гЃ‚", "гЃ„гЃ„", "гЃ†гЃ†гЃ†", "гЃ€гЃ€гЃ€гЃ€"])
 1407:         expected = "".join(
 1408:             [
 1409:                 "гЃ‚         a\n",
 1410:                 "гЃ„гЃ„       bb\n",
 1411:                 "гЃ†гЃ†гЃ†     CCC\n",
 1412:                 "гЃ€гЃ€гЃ€гЃ€      D\ndtype: object",
 1413:             ]
 1414:         )
 1415:         assert repr(s) == expected
 1416: 
 1417:         # unicode values
 1418:         s = Series(["гЃ‚", "гЃ„гЃ„", "гЃ†гЃ†гЃ†", "гЃ€гЃ€гЃ€гЃ€"], index=["a", "bb", "c", "ddd"])
 1419:         expected = "".join(
 1420:             [
 1421:                 "a         гЃ‚\n",
 1422:                 "bb       гЃ„гЃ„\n",
 1423:                 "c       гЃ†гЃ†гЃ†\n",
 1424:                 "ddd    гЃ€гЃ€гЃ€гЃ€\n",
 1425:                 "dtype: object",
 1426:             ]
 1427:         )
 1428: 
 1429:         assert repr(s) == expected
 1430: 
 1431:         # both
 1432:         s = Series(
 1433:             ["гЃ‚", "гЃ„гЃ„", "гЃ†гЃ†гЃ†", "гЃ€гЃ€гЃ€гЃ€"],
 1434:             index=["гЃ‚гЃ‚", "гЃ„гЃ„гЃ„гЃ„", "гЃ†", "гЃ€гЃ€гЃ€"],
 1435:         )
 1436:         expected = "".join(
 1437:             [
 1438:                 "гЃ‚гЃ‚         гЃ‚\n",
 1439:                 "гЃ„гЃ„гЃ„гЃ„      гЃ„гЃ„\n",
 1440:                 "гЃ†        гЃ†гЃ†гЃ†\n",
 1441:                 "гЃ€гЃ€гЃ€     гЃ€гЃ€гЃ€гЃ€\n",
 1442:                 "dtype: object",
 1443:             ]
 1444:         )
 1445: 
 1446:         assert repr(s) == expected
 1447: 
 1448:         # unicode footer
 1449:         s = Series(
 1450:             ["гЃ‚", "гЃ„гЃ„", "гЃ†гЃ†гЃ†", "гЃ€гЃ€гЃ€гЃ€"],
 1451:             index=["гЃ‚гЃ‚", "гЃ„гЃ„гЃ„гЃ„", "гЃ†", "гЃ€гЃ€гЃ€"],
 1452:             name="гЃЉгЃЉгЃЉгЃЉгЃЉгЃЉгЃЉ",
 1453:         )
 1454:         expected = (
 1455:             "гЃ‚гЃ‚         гЃ‚\nгЃ„гЃ„гЃ„гЃ„      гЃ„гЃ„\nгЃ†        гЃ†гЃ†гЃ†\n"
 1456:             "гЃ€гЃ€гЃ€     гЃ€гЃ€гЃ€гЃ€\nName: гЃЉгЃЉгЃЉгЃЉгЃЉгЃЉгЃЉ, dtype: object"
 1457:         )
 1458:         assert repr(s) == expected
 1459: 
 1460:         # MultiIndex
 1461:         idx = MultiIndex.from_tuples(
 1462:             [("гЃ‚", "гЃ„гЃ„"), ("гЃ†", "гЃ€"), ("гЃЉгЃЉгЃЉ", "гЃ‹гЃ‹гЃ‹гЃ‹"), ("гЃЌ", "гЃЏгЃЏ")]
 1463:         )
 1464:         s = Series([1, 22, 3333, 44444], index=idx)
 1465:         expected = (
 1466:             "гЃ‚    гЃ„гЃ„          1\n"
 1467:             "гЃ†    гЃ€          22\n"
 1468:             "гЃЉгЃЉгЃЉ  гЃ‹гЃ‹гЃ‹гЃ‹     3333\n"
 1469:             "гЃЌ    гЃЏгЃЏ      44444\ndtype: int64"
 1470:         )
 1471:         assert repr(s) == expected
 1472: 
 1473:         # object dtype, shorter than unicode repr
 1474:         s = Series([1, 22, 3333, 44444], index=[1, "AB", np.nan, "гЃ‚гЃ‚гЃ‚"])
 1475:         expected = (
 1476:             "1          1\nAB        22\nNaN     3333\nгЃ‚гЃ‚гЃ‚    44444\ndtype: int64"
 1477:         )
 1478:         assert repr(s) == expected
 1479: 
 1480:         # object dtype, longer than unicode repr
 1481:         s = Series(
 1482:             [1, 22, 3333, 44444], index=[1, "AB", Timestamp("2011-01-01"), "гЃ‚гЃ‚гЃ‚"]
 1483:         )
 1484:         expected = (
 1485:             "1                          1\n"
 1486:             "AB                        22\n"
 1487:             "2011-01-01 00:00:00     3333\n"
 1488:             "гЃ‚гЃ‚гЃ‚                    44444\ndtype: int64"
 1489:         )
 1490:         assert repr(s) == expected
 1491: 
 1492:         # truncate
 1493:         with option_context("display.max_rows", 3):
 1494:             s = Series(["гЃ‚", "гЃ„гЃ„", "гЃ†гЃ†гЃ†", "гЃ€гЃ€гЃ€гЃ€"], name="гЃЉгЃЉгЃЉгЃЉгЃЉгЃЉгЃЉ")
 1495: 
 1496:             expected = (
 1497:                 "0       гЃ‚\n     ... \n"
 1498:                 "3    гЃ€гЃ€гЃ€гЃ€\n"
 1499:                 "Name: гЃЉгЃЉгЃЉгЃЉгЃЉгЃЉгЃЉ, Length: 4, dtype: object"
 1500:             )
 1501:             assert repr(s) == expected
 1502: 
 1503:             s.index = ["гЃ‚гЃ‚", "гЃ„гЃ„гЃ„гЃ„", "гЃ†", "гЃ€гЃ€гЃ€"]
 1504:             expected = (
 1505:                 "гЃ‚гЃ‚        гЃ‚\n       ... \n"
 1506:                 "гЃ€гЃ€гЃ€    гЃ€гЃ€гЃ€гЃ€\n"
 1507:                 "Name: гЃЉгЃЉгЃЉгЃЉгЃЉгЃЉгЃЉ, Length: 4, dtype: object"
 1508:             )
 1509:             assert repr(s) == expected
 1510: 
 1511:         # Enable Unicode option -----------------------------------------
 1512:         with option_context("display.unicode.east_asian_width", True):
 1513:             # unicode index
 1514:             s = Series(
 1515:                 ["a", "bb", "CCC", "D"],
 1516:                 index=["гЃ‚", "гЃ„гЃ„", "гЃ†гЃ†гЃ†", "гЃ€гЃ€гЃ€гЃ€"],
 1517:             )
 1518:             expected = (
 1519:                 "гЃ‚            a\nгЃ„гЃ„         bb\nгЃ†гЃ†гЃ†      CCC\n"
 1520:                 "гЃ€гЃ€гЃ€гЃ€      D\ndtype: object"
 1521:             )
 1522:             assert repr(s) == expected
 1523: 
 1524:             # unicode values
 1525:             s = Series(
 1526:                 ["гЃ‚", "гЃ„гЃ„", "гЃ†гЃ†гЃ†", "гЃ€гЃ€гЃ€гЃ€"],
 1527:                 index=["a", "bb", "c", "ddd"],
 1528:             )
 1529:             expected = (
 1530:                 "a            гЃ‚\nbb         гЃ„гЃ„\nc        гЃ†гЃ†гЃ†\n"
 1531:                 "ddd    гЃ€гЃ€гЃ€гЃ€\ndtype: object"
 1532:             )
 1533:             assert repr(s) == expected
 1534:             # both
 1535:             s = Series(
 1536:                 ["гЃ‚", "гЃ„гЃ„", "гЃ†гЃ†гЃ†", "гЃ€гЃ€гЃ€гЃ€"],
 1537:                 index=["гЃ‚гЃ‚", "гЃ„гЃ„гЃ„гЃ„", "гЃ†", "гЃ€гЃ€гЃ€"],
 1538:             )
 1539:             expected = (
 1540:                 "гЃ‚гЃ‚              гЃ‚\n"
 1541:                 "гЃ„гЃ„гЃ„гЃ„        гЃ„гЃ„\n"
 1542:                 "гЃ†            гЃ†гЃ†гЃ†\n"
 1543:                 "гЃ€гЃ€гЃ€      гЃ€гЃ€гЃ€гЃ€\ndtype: object"
 1544:             )
 1545:             assert repr(s) == expected
 1546: 
 1547:             # unicode footer
 1548:             s = Series(
 1549:                 ["гЃ‚", "гЃ„гЃ„", "гЃ†гЃ†гЃ†", "гЃ€гЃ€гЃ€гЃ€"],
 1550:                 index=["гЃ‚гЃ‚", "гЃ„гЃ„гЃ„гЃ„", "гЃ†", "гЃ€гЃ€гЃ€"],
 1551:                 name="гЃЉгЃЉгЃЉгЃЉгЃЉгЃЉгЃЉ",
 1552:             )
 1553:             expected = (
 1554:                 "гЃ‚гЃ‚              гЃ‚\n"
 1555:                 "гЃ„гЃ„гЃ„гЃ„        гЃ„гЃ„\n"
 1556:                 "гЃ†            гЃ†гЃ†гЃ†\n"
 1557:                 "гЃ€гЃ€гЃ€      гЃ€гЃ€гЃ€гЃ€\n"
 1558:                 "Name: гЃЉгЃЉгЃЉгЃЉгЃЉгЃЉгЃЉ, dtype: object"
 1559:             )
 1560:             assert repr(s) == expected
 1561: 
 1562:             # MultiIndex
 1563:             idx = MultiIndex.from_tuples(
 1564:                 [("гЃ‚", "гЃ„гЃ„"), ("гЃ†", "гЃ€"), ("гЃЉгЃЉгЃЉ", "гЃ‹гЃ‹гЃ‹гЃ‹"), ("гЃЌ", "гЃЏгЃЏ")]
 1565:             )
 1566:             s = Series([1, 22, 3333, 44444], index=idx)
 1567:             expected = (
 1568:                 "гЃ‚      гЃ„гЃ„            1\n"
 1569:                 "гЃ†      гЃ€             22\n"
 1570:                 "гЃЉгЃЉгЃЉ  гЃ‹гЃ‹гЃ‹гЃ‹     3333\n"
 1571:                 "гЃЌ      гЃЏгЃЏ        44444\n"
 1572:                 "dtype: int64"
 1573:             )
 1574:             assert repr(s) == expected
 1575: 
 1576:             # object dtype, shorter than unicode repr
 1577:             s = Series([1, 22, 3333, 44444], index=[1, "AB", np.nan, "гЃ‚гЃ‚гЃ‚"])
 1578:             expected = (
 1579:                 "1             1\nAB           22\nNaN        3333\n"
 1580:                 "гЃ‚гЃ‚гЃ‚    44444\ndtype: int64"
 1581:             )
 1582:             assert repr(s) == expected
 1583: 
 1584:             # object dtype, longer than unicode repr
 1585:             s = Series(
 1586:                 [1, 22, 3333, 44444],
 1587:                 index=[1, "AB", Timestamp("2011-01-01"), "гЃ‚гЃ‚гЃ‚"],
 1588:             )
 1589:             expected = (
 1590:                 "1                          1\n"
 1591:                 "AB                        22\n"
 1592:                 "2011-01-01 00:00:00     3333\n"
 1593:                 "гЃ‚гЃ‚гЃ‚                 44444\ndtype: int64"
 1594:             )
 1595:             assert repr(s) == expected
 1596: 
 1597:             # truncate
 1598:             with option_context("display.max_rows", 3):
 1599:                 s = Series(["гЃ‚", "гЃ„гЃ„", "гЃ†гЃ†гЃ†", "гЃ€гЃ€гЃ€гЃ€"], name="гЃЉгЃЉгЃЉгЃЉгЃЉгЃЉгЃЉ")
 1600:                 expected = (
 1601:                     "0          гЃ‚\n       ...   \n"
 1602:                     "3    гЃ€гЃ€гЃ€гЃ€\n"
 1603:                     "Name: гЃЉгЃЉгЃЉгЃЉгЃЉгЃЉгЃЉ, Length: 4, dtype: object"
 1604:                 )
 1605:                 assert repr(s) == expected
 1606: 
 1607:                 s.index = ["гЃ‚гЃ‚", "гЃ„гЃ„гЃ„гЃ„", "гЃ†", "гЃ€гЃ€гЃ€"]
 1608:                 expected = (
 1609:                     "гЃ‚гЃ‚            гЃ‚\n"
 1610:                     "            ...   \n"
 1611:                     "гЃ€гЃ€гЃ€    гЃ€гЃ€гЃ€гЃ€\n"
 1612:                     "Name: гЃЉгЃЉгЃЉгЃЉгЃЉгЃЉгЃЉ, Length: 4, dtype: object"
 1613:                 )
 1614:                 assert repr(s) == expected
 1615: 
 1616:             # ambiguous unicode
 1617:             s = Series(
 1618:                 ["ВЎВЎ", "гЃ„ВЎВЎ", "гЃ†гЃ†гЃ†", "гЃ€гЃ€гЃ€гЃ€"],
 1619:                 index=["гЃ‚гЃ‚", "ВЎВЎВЎВЎгЃ„гЃ„", "ВЎВЎ", "гЃ€гЃ€гЃ€"],
 1620:             )
 1621:             expected = (
 1622:                 "гЃ‚гЃ‚              ВЎВЎ\n"
 1623:                 "ВЎВЎВЎВЎгЃ„гЃ„        гЃ„ВЎВЎ\n"
 1624:                 "ВЎВЎ            гЃ†гЃ†гЃ†\n"
 1625:                 "гЃ€гЃ€гЃ€      гЃ€гЃ€гЃ€гЃ€\ndtype: object"
 1626:             )
 1627:             assert repr(s) == expected
 1628: 
 1629:     def test_float_trim_zeros(self):
 1630:         vals = [
 1631:             2.08430917305e10,
 1632:             3.52205017305e10,
 1633:             2.30674817305e10,
 1634:             2.03954217305e10,
 1635:             5.59897817305e10,
 1636:         ]
 1637:         for line in repr(Series(vals)).split("\n"):
 1638:             if line.startswith("dtype:"):
 1639:                 continue
 1640:             if _three_digit_exp():
 1641:                 assert "+010" in line
 1642:             else:
 1643:                 assert "+10" in line
 1644: 
 1645:     @pytest.mark.parametrize(
 1646:         "start_date",
 1647:         [
 1648:             "2017-01-01 23:59:59.999999999",
 1649:             "2017-01-01 23:59:59.99999999",
 1650:             "2017-01-01 23:59:59.9999999",
 1651:             "2017-01-01 23:59:59.999999",
 1652:             "2017-01-01 23:59:59.99999",
 1653:             "2017-01-01 23:59:59.9999",
 1654:         ],
 1655:     )
 1656:     def test_datetimeindex_highprecision(self, start_date):
 1657:         # GH19030
 1658:         # Check that high-precision time values for the end of day are
 1659:         # included in repr for DatetimeIndex
 1660:         s1 = Series(date_range(start=start_date, freq="D", periods=5))
 1661:         result = str(s1)
 1662:         assert start_date in result
 1663: 
 1664:         dti = date_range(start=start_date, freq="D", periods=5)
 1665:         s2 = Series(3, index=dti)
 1666:         result = str(s2.index)
 1667:         assert start_date in result
 1668: 
 1669:     def test_mixed_datetime64(self):
 1670:         df = DataFrame({"A": [1, 2], "B": ["2012-01-01", "2012-01-02"]})
 1671:         df["B"] = pd.to_datetime(df.B)
 1672: 
 1673:         result = repr(df.loc[0])
 1674:         assert "2012-01-01" in result
 1675: 
 1676:     def test_period(self):
 1677:         # GH 12615
 1678:         index = pd.period_range("2013-01", periods=6, freq="M")
 1679:         s = Series(np.arange(6, dtype="int64"), index=index)
 1680:         exp = (
 1681:             "2013-01    0\n"
 1682:             "2013-02    1\n"
 1683:             "2013-03    2\n"
 1684:             "2013-04    3\n"
 1685:             "2013-05    4\n"
 1686:             "2013-06    5\n"
 1687:             "Freq: M, dtype: int64"
 1688:         )
 1689:         assert str(s) == exp
 1690: 
 1691:         s = Series(index)
 1692:         exp = (
 1693:             "0    2013-01\n"
 1694:             "1    2013-02\n"
 1695:             "2    2013-03\n"
 1696:             "3    2013-04\n"
 1697:             "4    2013-05\n"
 1698:             "5    2013-06\n"
 1699:             "dtype: period[M]"
 1700:         )
 1701:         assert str(s) == exp
 1702: 
 1703:         # periods with mixed freq
 1704:         s = Series(
 1705:             [
 1706:                 pd.Period("2011-01", freq="M"),
 1707:                 pd.Period("2011-02-01", freq="D"),
 1708:                 pd.Period("2011-03-01 09:00", freq="h"),
 1709:             ]
 1710:         )
 1711:         exp = (
 1712:             "0             2011-01\n1          2011-02-01\n"
 1713:             "2    2011-03-01 09:00\ndtype: object"
 1714:         )
 1715:         assert str(s) == exp
 1716: 
 1717:     def test_max_multi_index_display(self):
 1718:         # GH 7101
 1719: 
 1720:         # doc example (indexing.rst)
 1721: 
 1722:         # multi-index
 1723:         arrays = [
 1724:             ["bar", "bar", "baz", "baz", "foo", "foo", "qux", "qux"],
 1725:             ["one", "two", "one", "two", "one", "two", "one", "two"],
 1726:         ]
 1727:         tuples = list(zip(*arrays))
 1728:         index = MultiIndex.from_tuples(tuples, names=["first", "second"])
 1729:         s = Series(np.random.default_rng(2).standard_normal(8), index=index)
 1730: 
 1731:         with option_context("display.max_rows", 10):
 1732:             assert len(str(s).split("\n")) == 10
 1733:         with option_context("display.max_rows", 3):
 1734:             assert len(str(s).split("\n")) == 5
 1735:         with option_context("display.max_rows", 2):
 1736:             assert len(str(s).split("\n")) == 5
 1737:         with option_context("display.max_rows", 1):
 1738:             assert len(str(s).split("\n")) == 4
 1739:         with option_context("display.max_rows", 0):
 1740:             assert len(str(s).split("\n")) == 10
 1741: 
 1742:         # index
 1743:         s = Series(np.random.default_rng(2).standard_normal(8), None)
 1744: 
 1745:         with option_context("display.max_rows", 10):
 1746:             assert len(str(s).split("\n")) == 9
 1747:         with option_context("display.max_rows", 3):
 1748:             assert len(str(s).split("\n")) == 4
 1749:         with option_context("display.max_rows", 2):
 1750:             assert len(str(s).split("\n")) == 4
 1751:         with option_context("display.max_rows", 1):
 1752:             assert len(str(s).split("\n")) == 3
 1753:         with option_context("display.max_rows", 0):
 1754:             assert len(str(s).split("\n")) == 9
 1755: 
 1756:     # Make sure #8532 is fixed
 1757:     def test_consistent_format(self):
 1758:         s = Series([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0.9999, 1, 1] * 10)
 1759:         with option_context("display.max_rows", 10, "display.show_dimensions", False):
 1760:             res = repr(s)
 1761:         exp = (
 1762:             "0      1.0000\n1      1.0000\n2      1.0000\n3      "
 1763:             "1.0000\n4      1.0000\n        ...  \n125    "
 1764:             "1.0000\n126    1.0000\n127    0.9999\n128    "
 1765:             "1.0000\n129    1.0000\ndtype: float64"
 1766:         )
 1767:         assert res == exp
 1768: 
 1769:     def chck_ncols(self, s):
 1770:         lines = [
 1771:             line for line in repr(s).split("\n") if not re.match(r"[^\.]*\.+", line)
 1772:         ][:-1]
 1773:         ncolsizes = len({len(line.strip()) for line in lines})
 1774:         assert ncolsizes == 1
 1775: 
 1776:     @pytest.mark.xfail(
 1777:         using_pyarrow_string_dtype(), reason="change when arrow is default"
 1778:     )
 1779:     def test_format_explicit(self):
 1780:         test_sers = gen_series_formatting()
 1781:         with option_context("display.max_rows", 4, "display.show_dimensions", False):
 1782:             res = repr(test_sers["onel"])
 1783:             exp = "0     a\n1     a\n     ..\n98    a\n99    a\ndtype: object"
 1784:             assert exp == res
 1785:             res = repr(test_sers["twol"])
 1786:             exp = "0     ab\n1     ab\n      ..\n98    ab\n99    ab\ndtype: object"
 1787:             assert exp == res
 1788:             res = repr(test_sers["asc"])
 1789:             exp = (
 1790:                 "0         a\n1        ab\n      ...  \n4     abcde\n5    "
 1791:                 "abcdef\ndtype: object"
 1792:             )
 1793:             assert exp == res
 1794:             res = repr(test_sers["desc"])
 1795:             exp = (
 1796:                 "5    abcdef\n4     abcde\n      ...  \n1        ab\n0         "
 1797:                 "a\ndtype: object"
 1798:             )
 1799:             assert exp == res
 1800: 
 1801:     def test_ncols(self):
 1802:         test_sers = gen_series_formatting()
 1803:         for s in test_sers.values():
 1804:             self.chck_ncols(s)
 1805: 
 1806:     def test_max_rows_eq_one(self):
 1807:         s = Series(range(10), dtype="int64")
 1808:         with option_context("display.max_rows", 1):
 1809:             strrepr = repr(s).split("\n")
 1810:         exp1 = ["0", "0"]
 1811:         res1 = strrepr[0].split()
 1812:         assert exp1 == res1
 1813:         exp2 = [".."]
 1814:         res2 = strrepr[1].split()
 1815:         assert exp2 == res2
 1816: 
 1817:     def test_truncate_ndots(self):
 1818:         def getndots(s):
 1819:             return len(re.match(r"[^\.]*(\.*)", s).groups()[0])
 1820: 
 1821:         s = Series([0, 2, 3, 6])
 1822:         with option_context("display.max_rows", 2):
 1823:             strrepr = repr(s).replace("\n", "")
 1824:         assert getndots(strrepr) == 2
 1825: 
 1826:         s = Series([0, 100, 200, 400])
 1827:         with option_context("display.max_rows", 2):
 1828:             strrepr = repr(s).replace("\n", "")
 1829:         assert getndots(strrepr) == 3
 1830: 
 1831:     def test_show_dimensions(self):
 1832:         # gh-7117
 1833:         s = Series(range(5))
 1834: 
 1835:         assert "Length" not in repr(s)
 1836: 
 1837:         with option_context("display.max_rows", 4):
 1838:             assert "Length" in repr(s)
 1839: 
 1840:         with option_context("display.show_dimensions", True):
 1841:             assert "Length" in repr(s)
 1842: 
 1843:         with option_context("display.max_rows", 4, "display.show_dimensions", False):
 1844:             assert "Length" not in repr(s)
 1845: 
 1846:     def test_repr_min_rows(self):
 1847:         s = Series(range(20))
 1848: 
 1849:         # default setting no truncation even if above min_rows
 1850:         assert ".." not in repr(s)
 1851: 
 1852:         s = Series(range(61))
 1853: 
 1854:         # default of max_rows 60 triggers truncation if above
 1855:         assert ".." in repr(s)
 1856: 
 1857:         with option_context("display.max_rows", 10, "display.min_rows", 4):
 1858:             # truncated after first two rows
 1859:             assert ".." in repr(s)
 1860:             assert "2  " not in repr(s)
 1861: 
 1862:         with option_context("display.max_rows", 12, "display.min_rows", None):
 1863:             # when set to None, follow value of max_rows
 1864:             assert "5      5" in repr(s)
 1865: 
 1866:         with option_context("display.max_rows", 10, "display.min_rows", 12):
 1867:             # when set value higher as max_rows, use the minimum
 1868:             assert "5      5" not in repr(s)
 1869: 
 1870:         with option_context("display.max_rows", None, "display.min_rows", 12):
 1871:             # max_rows of None -> never truncate
 1872:             assert ".." not in repr(s)
 1873: 
 1874: 
 1875: class TestGenericArrayFormatter:
 1876:     def test_1d_array(self):
 1877:         # _GenericArrayFormatter is used on types for which there isn't a dedicated
 1878:         # formatter. np.bool_ is one of those types.
 1879:         obj = fmt._GenericArrayFormatter(np.array([True, False]))
 1880:         res = obj.get_result()
 1881:         assert len(res) == 2
 1882:         # Results should be right-justified.
 1883:         assert res[0] == "  True"
 1884:         assert res[1] == " False"
 1885: 
 1886:     def test_2d_array(self):
 1887:         obj = fmt._GenericArrayFormatter(np.array([[True, False], [False, True]]))
 1888:         res = obj.get_result()
 1889:         assert len(res) == 2
 1890:         assert res[0] == " [True, False]"
 1891:         assert res[1] == " [False, True]"
 1892: 
 1893:     def test_3d_array(self):
 1894:         obj = fmt._GenericArrayFormatter(
 1895:             np.array([[[True, True], [False, False]], [[False, True], [True, False]]])
 1896:         )
 1897:         res = obj.get_result()
 1898:         assert len(res) == 2
 1899:         assert res[0] == " [[True, True], [False, False]]"
 1900:         assert res[1] == " [[False, True], [True, False]]"
 1901: 
 1902:     def test_2d_extension_type(self):
 1903:         # GH 33770
 1904: 
 1905:         # Define a stub extension type with just enough code to run Series.__repr__()
 1906:         class DtypeStub(pd.api.extensions.ExtensionDtype):
 1907:             @property
 1908:             def type(self):
 1909:                 return np.ndarray
 1910: 
 1911:             @property
 1912:             def name(self):
 1913:                 return "DtypeStub"
 1914: 
 1915:         class ExtTypeStub(pd.api.extensions.ExtensionArray):
 1916:             def __len__(self) -> int:
 1917:                 return 2
 1918: 
 1919:             def __getitem__(self, ix):
 1920:                 return [ix == 1, ix == 0]
 1921: 
 1922:             @property
 1923:             def dtype(self):
 1924:                 return DtypeStub()
 1925: 
 1926:         series = Series(ExtTypeStub(), copy=False)
 1927:         res = repr(series)  # This line crashed before #33770 was fixed.
 1928:         expected = "\n".join(
 1929:             ["0    [False True]", "1    [True False]", "dtype: DtypeStub"]
 1930:         )
 1931:         assert res == expected
 1932: 
 1933: 
 1934: def _three_digit_exp():
 1935:     return f"{1.7e8:.4g}" == "1.7e+008"
 1936: 
 1937: 
 1938: class TestFloatArrayFormatter:
 1939:     def test_misc(self):
 1940:         obj = fmt.FloatArrayFormatter(np.array([], dtype=np.float64))
 1941:         result = obj.get_result()
 1942:         assert len(result) == 0
 1943: 
 1944:     def test_format(self):
 1945:         obj = fmt.FloatArrayFormatter(np.array([12, 0], dtype=np.float64))
 1946:         result = obj.get_result()
 1947:         assert result[0] == " 12.0"
 1948:         assert result[1] == "  0.0"
 1949: 
 1950:     def test_output_display_precision_trailing_zeroes(self):
 1951:         # Issue #20359: trimming zeros while there is no decimal point
 1952: 
 1953:         # Happens when display precision is set to zero
 1954:         with option_context("display.precision", 0):
 1955:             s = Series([840.0, 4200.0])
 1956:             expected_output = "0     840\n1    4200\ndtype: float64"
 1957:             assert str(s) == expected_output
 1958: 
 1959:     @pytest.mark.parametrize(
 1960:         "value,expected",
 1961:         [
 1962:             ([9.4444], "   0\n0  9"),
 1963:             ([0.49], "       0\n0  5e-01"),
 1964:             ([10.9999], "    0\n0  11"),
 1965:             ([9.5444, 9.6], "    0\n0  10\n1  10"),
 1966:             ([0.46, 0.78, -9.9999], "       0\n0  5e-01\n1  8e-01\n2 -1e+01"),
 1967:         ],
 1968:     )
 1969:     def test_set_option_precision(self, value, expected):
 1970:         # Issue #30122
 1971:         # Precision was incorrectly shown
 1972: 
 1973:         with option_context("display.precision", 0):
 1974:             df_value = DataFrame(value)
 1975:             assert str(df_value) == expected
 1976: 
 1977:     def test_output_significant_digits(self):
 1978:         # Issue #9764
 1979: 
 1980:         # In case default display precision changes:
 1981:         with option_context("display.precision", 6):
 1982:             # DataFrame example from issue #9764
 1983:             d = DataFrame(
 1984:                 {
 1985:                     "col1": [
 1986:                         9.999e-8,
 1987:                         1e-7,
 1988:                         1.0001e-7,
 1989:                         2e-7,
 1990:                         4.999e-7,
 1991:                         5e-7,
 1992:                         5.0001e-7,
 1993:                         6e-7,
 1994:                         9.999e-7,
 1995:                         1e-6,
 1996:                         1.0001e-6,
 1997:                         2e-6,
 1998:                         4.999e-6,
 1999:                         5e-6,
 2000:                         5.0001e-6,
 2001:                         6e-6,
 2002:                     ]
 2003:                 }
 2004:             )
 2005: 
 2006:             expected_output = {
 2007:                 (0, 6): "           col1\n"
 2008:                 "0  9.999000e-08\n"
 2009:                 "1  1.000000e-07\n"
 2010:                 "2  1.000100e-07\n"
 2011:                 "3  2.000000e-07\n"
 2012:                 "4  4.999000e-07\n"
 2013:                 "5  5.000000e-07",
 2014:                 (1, 6): "           col1\n"
 2015:                 "1  1.000000e-07\n"
 2016:                 "2  1.000100e-07\n"
 2017:                 "3  2.000000e-07\n"
 2018:                 "4  4.999000e-07\n"
 2019:                 "5  5.000000e-07",
 2020:                 (1, 8): "           col1\n"
 2021:                 "1  1.000000e-07\n"
 2022:                 "2  1.000100e-07\n"
 2023:                 "3  2.000000e-07\n"
 2024:                 "4  4.999000e-07\n"
 2025:                 "5  5.000000e-07\n"
 2026:                 "6  5.000100e-07\n"
 2027:                 "7  6.000000e-07",
 2028:                 (8, 16): "            col1\n"
 2029:                 "8   9.999000e-07\n"
 2030:                 "9   1.000000e-06\n"
 2031:                 "10  1.000100e-06\n"
 2032:                 "11  2.000000e-06\n"
 2033:                 "12  4.999000e-06\n"
 2034:                 "13  5.000000e-06\n"
 2035:                 "14  5.000100e-06\n"
 2036:                 "15  6.000000e-06",
 2037:                 (9, 16): "        col1\n"
 2038:                 "9   0.000001\n"
 2039:                 "10  0.000001\n"
 2040:                 "11  0.000002\n"
 2041:                 "12  0.000005\n"
 2042:                 "13  0.000005\n"
 2043:                 "14  0.000005\n"
 2044:                 "15  0.000006",
 2045:             }
 2046: 
 2047:             for (start, stop), v in expected_output.items():
 2048:                 assert str(d[start:stop]) == v
 2049: 
 2050:     def test_too_long(self):
 2051:         # GH 10451
 2052:         with option_context("display.precision", 4):
 2053:             # need both a number > 1e6 and something that normally formats to
 2054:             # having length > display.precision + 6
 2055:             df = DataFrame({"x": [12345.6789]})
 2056:             assert str(df) == "            x\n0  12345.6789"
 2057:             df = DataFrame({"x": [2e6]})
 2058:             assert str(df) == "           x\n0  2000000.0"
 2059:             df = DataFrame({"x": [12345.6789, 2e6]})
 2060:             assert str(df) == "            x\n0  1.2346e+04\n1  2.0000e+06"
 2061: 
 2062: 
 2063: class TestTimedelta64Formatter:
 2064:     def test_days(self):
 2065:         x = pd.to_timedelta(list(range(5)) + [NaT], unit="D")._values
 2066:         result = fmt._Timedelta64Formatter(x).get_result()
 2067:         assert result[0].strip() == "0 days"
 2068:         assert result[1].strip() == "1 days"
 2069: 
 2070:         result = fmt._Timedelta64Formatter(x[1:2]).get_result()
 2071:         assert result[0].strip() == "1 days"
 2072: 
 2073:         result = fmt._Timedelta64Formatter(x).get_result()
 2074:         assert result[0].strip() == "0 days"
 2075:         assert result[1].strip() == "1 days"
 2076: 
 2077:         result = fmt._Timedelta64Formatter(x[1:2]).get_result()
 2078:         assert result[0].strip() == "1 days"
 2079: 
 2080:     def test_days_neg(self):
 2081:         x = pd.to_timedelta(list(range(5)) + [NaT], unit="D")._values
 2082:         result = fmt._Timedelta64Formatter(-x).get_result()
 2083:         assert result[0].strip() == "0 days"
 2084:         assert result[1].strip() == "-1 days"
 2085: 
 2086:     def test_subdays(self):
 2087:         y = pd.to_timedelta(list(range(5)) + [NaT], unit="s")._values
 2088:         result = fmt._Timedelta64Formatter(y).get_result()
 2089:         assert result[0].strip() == "0 days 00:00:00"
 2090:         assert result[1].strip() == "0 days 00:00:01"
 2091: 
 2092:     def test_subdays_neg(self):
 2093:         y = pd.to_timedelta(list(range(5)) + [NaT], unit="s")._values
 2094:         result = fmt._Timedelta64Formatter(-y).get_result()
 2095:         assert result[0].strip() == "0 days 00:00:00"
 2096:         assert result[1].strip() == "-1 days +23:59:59"
 2097: 
 2098:     def test_zero(self):
 2099:         x = pd.to_timedelta(list(range(1)) + [NaT], unit="D")._values
 2100:         result = fmt._Timedelta64Formatter(x).get_result()
 2101:         assert result[0].strip() == "0 days"
 2102: 
 2103:         x = pd.to_timedelta(list(range(1)), unit="D")._values
 2104:         result = fmt._Timedelta64Formatter(x).get_result()
 2105:         assert result[0].strip() == "0 days"
 2106: 
 2107: 
 2108: class TestDatetime64Formatter:
 2109:     def test_mixed(self):
 2110:         x = Series([datetime(2013, 1, 1), datetime(2013, 1, 1, 12), NaT])._values
 2111:         result = fmt._Datetime64Formatter(x).get_result()
 2112:         assert result[0].strip() == "2013-01-01 00:00:00"
 2113:         assert result[1].strip() == "2013-01-01 12:00:00"
 2114: 
 2115:     def test_dates(self):
 2116:         x = Series([datetime(2013, 1, 1), datetime(2013, 1, 2), NaT])._values
 2117:         result = fmt._Datetime64Formatter(x).get_result()
 2118:         assert result[0].strip() == "2013-01-01"
 2119:         assert result[1].strip() == "2013-01-02"
 2120: 
 2121:     def test_date_nanos(self):
 2122:         x = Series([Timestamp(200)])._values
 2123:         result = fmt._Datetime64Formatter(x).get_result()
 2124:         assert result[0].strip() == "1970-01-01 00:00:00.000000200"
 2125: 
 2126:     def test_dates_display(self):
 2127:         # 10170
 2128:         # make sure that we are consistently display date formatting
 2129:         x = Series(date_range("20130101 09:00:00", periods=5, freq="D"))
 2130:         x.iloc[1] = np.nan
 2131:         result = fmt._Datetime64Formatter(x._values).get_result()
 2132:         assert result[0].strip() == "2013-01-01 09:00:00"
 2133:         assert result[1].strip() == "NaT"
 2134:         assert result[4].strip() == "2013-01-05 09:00:00"
 2135: 
 2136:         x = Series(date_range("20130101 09:00:00", periods=5, freq="s"))
 2137:         x.iloc[1] = np.nan
 2138:         result = fmt._Datetime64Formatter(x._values).get_result()
 2139:         assert result[0].strip() == "2013-01-01 09:00:00"
 2140:         assert result[1].strip() == "NaT"
 2141:         assert result[4].strip() == "2013-01-01 09:00:04"
 2142: 
 2143:         x = Series(date_range("20130101 09:00:00", periods=5, freq="ms"))
 2144:         x.iloc[1] = np.nan
 2145:         result = fmt._Datetime64Formatter(x._values).get_result()
 2146:         assert result[0].strip() == "2013-01-01 09:00:00.000"
 2147:         assert result[1].strip() == "NaT"
 2148:         assert result[4].strip() == "2013-01-01 09:00:00.004"
 2149: 
 2150:         x = Series(date_range("20130101 09:00:00", periods=5, freq="us"))
 2151:         x.iloc[1] = np.nan
 2152:         result = fmt._Datetime64Formatter(x._values).get_result()
 2153:         assert result[0].strip() == "2013-01-01 09:00:00.000000"
 2154:         assert result[1].strip() == "NaT"
 2155:         assert result[4].strip() == "2013-01-01 09:00:00.000004"
 2156: 
 2157:         x = Series(date_range("20130101 09:00:00", periods=5, freq="ns"))
 2158:         x.iloc[1] = np.nan
 2159:         result = fmt._Datetime64Formatter(x._values).get_result()
 2160:         assert result[0].strip() == "2013-01-01 09:00:00.000000000"
 2161:         assert result[1].strip() == "NaT"
 2162:         assert result[4].strip() == "2013-01-01 09:00:00.000000004"
 2163: 
 2164:     def test_datetime64formatter_yearmonth(self):
 2165:         x = Series([datetime(2016, 1, 1), datetime(2016, 2, 2)])._values
 2166: 
 2167:         def format_func(x):
 2168:             return x.strftime("%Y-%m")
 2169: 
 2170:         formatter = fmt._Datetime64Formatter(x, formatter=format_func)
 2171:         result = formatter.get_result()
 2172:         assert result == ["2016-01", "2016-02"]
 2173: 
 2174:     def test_datetime64formatter_hoursecond(self):
 2175:         x = Series(
 2176:             pd.to_datetime(["10:10:10.100", "12:12:12.120"], format="%H:%M:%S.%f")
 2177:         )._values
 2178: 
 2179:         def format_func(x):
 2180:             return x.strftime("%H:%M")
 2181: 
 2182:         formatter = fmt._Datetime64Formatter(x, formatter=format_func)
 2183:         result = formatter.get_result()
 2184:         assert result == ["10:10", "12:12"]
 2185: 
 2186:     def test_datetime64formatter_tz_ms(self):
 2187:         x = (
 2188:             Series(
 2189:                 np.array(["2999-01-01", "2999-01-02", "NaT"], dtype="datetime64[ms]")
 2190:             )
 2191:             .dt.tz_localize("US/Pacific")
 2192:             ._values
 2193:         )
 2194:         result = fmt._Datetime64TZFormatter(x).get_result()
 2195:         assert result[0].strip() == "2999-01-01 00:00:00-08:00"
 2196:         assert result[1].strip() == "2999-01-02 00:00:00-08:00"
 2197: 
 2198: 
 2199: class TestFormatPercentiles:
 2200:     @pytest.mark.parametrize(
 2201:         "percentiles, expected",
 2202:         [
 2203:             (
 2204:                 [0.01999, 0.02001, 0.5, 0.666666, 0.9999],
 2205:                 ["1.999%", "2.001%", "50%", "66.667%", "99.99%"],
 2206:             ),
 2207:             (
 2208:                 [0, 0.5, 0.02001, 0.5, 0.666666, 0.9999],
 2209:                 ["0%", "50%", "2.0%", "50%", "66.67%", "99.99%"],
 2210:             ),
 2211:             ([0.281, 0.29, 0.57, 0.58], ["28.1%", "29%", "57%", "58%"]),
 2212:             ([0.28, 0.29, 0.57, 0.58], ["28%", "29%", "57%", "58%"]),
 2213:             (
 2214:                 [0.9, 0.99, 0.999, 0.9999, 0.99999],
 2215:                 ["90%", "99%", "99.9%", "99.99%", "99.999%"],
 2216:             ),
 2217:         ],
 2218:     )
 2219:     def test_format_percentiles(self, percentiles, expected):
 2220:         result = fmt.format_percentiles(percentiles)
 2221:         assert result == expected
 2222: 
 2223:     @pytest.mark.parametrize(
 2224:         "percentiles",
 2225:         [
 2226:             ([0.1, np.nan, 0.5]),
 2227:             ([-0.001, 0.1, 0.5]),
 2228:             ([2, 0.1, 0.5]),
 2229:             ([0.1, 0.5, "a"]),
 2230:         ],
 2231:     )
 2232:     def test_error_format_percentiles(self, percentiles):
 2233:         msg = r"percentiles should all be in the interval \[0,1\]"
 2234:         with pytest.raises(ValueError, match=msg):
 2235:             fmt.format_percentiles(percentiles)
 2236: 
 2237:     def test_format_percentiles_integer_idx(self):
 2238:         # Issue #26660
 2239:         result = fmt.format_percentiles(np.linspace(0, 1, 10 + 1))
 2240:         expected = [
 2241:             "0%",
 2242:             "10%",
 2243:             "20%",
 2244:             "30%",
 2245:             "40%",
 2246:             "50%",
 2247:             "60%",
 2248:             "70%",
 2249:             "80%",
 2250:             "90%",
 2251:             "100%",
 2252:         ]
 2253:         assert result == expected
 2254: 
 2255: 
 2256: @pytest.mark.parametrize("method", ["to_string", "to_html", "to_latex"])
 2257: @pytest.mark.parametrize(
 2258:     "encoding, data",
 2259:     [(None, "abc"), ("utf-8", "abc"), ("gbk", "йЂ ж€ђиѕ“е‡єдё­ж–‡жѕз¤єд№±з Ѓ"), ("foo", "abc")],
 2260: )
 2261: def test_filepath_or_buffer_arg(
 2262:     method,
 2263:     filepath_or_buffer,
 2264:     assert_filepath_or_buffer_equals,
 2265:     encoding,
 2266:     data,
 2267:     filepath_or_buffer_id,
 2268: ):
 2269:     df = DataFrame([data])
 2270:     if method in ["to_latex"]:  # uses styler implementation
 2271:         pytest.importorskip("jinja2")
 2272: 
 2273:     if filepath_or_buffer_id not in ["string", "pathlike"] and encoding is not None:
 2274:         with pytest.raises(
 2275:             ValueError, match="buf is not a file name and encoding is specified."
 2276:         ):
 2277:             getattr(df, method)(buf=filepath_or_buffer, encoding=encoding)
 2278:     elif encoding == "foo":
 2279:         with pytest.raises(LookupError, match="unknown encoding"):
 2280:             getattr(df, method)(buf=filepath_or_buffer, encoding=encoding)
 2281:     else:
 2282:         expected = getattr(df, method)()
 2283:         getattr(df, method)(buf=filepath_or_buffer, encoding=encoding)
 2284:         assert_filepath_or_buffer_equals(expected)
 2285: 
 2286: 
 2287: @pytest.mark.parametrize("method", ["to_string", "to_html", "to_latex"])
 2288: def test_filepath_or_buffer_bad_arg_raises(float_frame, method):
 2289:     if method in ["to_latex"]:  # uses styler implementation
 2290:         pytest.importorskip("jinja2")
 2291:     msg = "buf is not a file name and it has no write method"
 2292:     with pytest.raises(TypeError, match=msg):
 2293:         getattr(float_frame, method)(buf=object())
