    1: import gzip
    2: import io
    3: import os
    4: from pathlib import Path
    5: import subprocess
    6: import sys
    7: import tarfile
    8: import textwrap
    9: import time
   10: import zipfile
   11: 
   12: import numpy as np
   13: import pytest
   14: 
   15: from pandas.compat import is_platform_windows
   16: 
   17: import pandas as pd
   18: import pandas._testing as tm
   19: 
   20: import pandas.io.common as icom
   21: 
   22: 
   23: @pytest.mark.parametrize(
   24:     "obj",
   25:     [
   26:         pd.DataFrame(
   27:             100 * [[0.123456, 0.234567, 0.567567], [12.32112, 123123.2, 321321.2]],
   28:             columns=["X", "Y", "Z"],
   29:         ),
   30:         pd.Series(100 * [0.123456, 0.234567, 0.567567], name="X"),
   31:     ],
   32: )
   33: @pytest.mark.parametrize("method", ["to_pickle", "to_json", "to_csv"])
   34: def test_compression_size(obj, method, compression_only):
   35:     if compression_only == "tar":
   36:         compression_only = {"method": "tar", "mode": "w:gz"}
   37: 
   38:     with tm.ensure_clean() as path:
   39:         getattr(obj, method)(path, compression=compression_only)
   40:         compressed_size = os.path.getsize(path)
   41:         getattr(obj, method)(path, compression=None)
   42:         uncompressed_size = os.path.getsize(path)
   43:         assert uncompressed_size > compressed_size
   44: 
   45: 
   46: @pytest.mark.parametrize(
   47:     "obj",
   48:     [
   49:         pd.DataFrame(
   50:             100 * [[0.123456, 0.234567, 0.567567], [12.32112, 123123.2, 321321.2]],
   51:             columns=["X", "Y", "Z"],
   52:         ),
   53:         pd.Series(100 * [0.123456, 0.234567, 0.567567], name="X"),
   54:     ],
   55: )
   56: @pytest.mark.parametrize("method", ["to_csv", "to_json"])
   57: def test_compression_size_fh(obj, method, compression_only):
   58:     with tm.ensure_clean() as path:
   59:         with icom.get_handle(
   60:             path,
   61:             "w:gz" if compression_only == "tar" else "w",
   62:             compression=compression_only,
   63:         ) as handles:
   64:             getattr(obj, method)(handles.handle)
   65:             assert not handles.handle.closed
   66:         compressed_size = os.path.getsize(path)
   67:     with tm.ensure_clean() as path:
   68:         with icom.get_handle(path, "w", compression=None) as handles:
   69:             getattr(obj, method)(handles.handle)
   70:             assert not handles.handle.closed
   71:         uncompressed_size = os.path.getsize(path)
   72:         assert uncompressed_size > compressed_size
   73: 
   74: 
   75: @pytest.mark.parametrize(
   76:     "write_method, write_kwargs, read_method",
   77:     [
   78:         ("to_csv", {"index": False}, pd.read_csv),
   79:         ("to_json", {}, pd.read_json),
   80:         ("to_pickle", {}, pd.read_pickle),
   81:     ],
   82: )
   83: def test_dataframe_compression_defaults_to_infer(
   84:     write_method, write_kwargs, read_method, compression_only, compression_to_extension
   85: ):
   86:     # GH22004
   87:     input = pd.DataFrame([[1.0, 0, -4], [3.4, 5, 2]], columns=["X", "Y", "Z"])
   88:     extension = compression_to_extension[compression_only]
   89:     with tm.ensure_clean("compressed" + extension) as path:
   90:         getattr(input, write_method)(path, **write_kwargs)
   91:         output = read_method(path, compression=compression_only)
   92:     tm.assert_frame_equal(output, input)
   93: 
   94: 
   95: @pytest.mark.parametrize(
   96:     "write_method,write_kwargs,read_method,read_kwargs",
   97:     [
   98:         ("to_csv", {"index": False, "header": True}, pd.read_csv, {"squeeze": True}),
   99:         ("to_json", {}, pd.read_json, {"typ": "series"}),
  100:         ("to_pickle", {}, pd.read_pickle, {}),
  101:     ],
  102: )
  103: def test_series_compression_defaults_to_infer(
  104:     write_method,
  105:     write_kwargs,
  106:     read_method,
  107:     read_kwargs,
  108:     compression_only,
  109:     compression_to_extension,
  110: ):
  111:     # GH22004
  112:     input = pd.Series([0, 5, -2, 10], name="X")
  113:     extension = compression_to_extension[compression_only]
  114:     with tm.ensure_clean("compressed" + extension) as path:
  115:         getattr(input, write_method)(path, **write_kwargs)
  116:         if "squeeze" in read_kwargs:
  117:             kwargs = read_kwargs.copy()
  118:             del kwargs["squeeze"]
  119:             output = read_method(path, compression=compression_only, **kwargs).squeeze(
  120:                 "columns"
  121:             )
  122:         else:
  123:             output = read_method(path, compression=compression_only, **read_kwargs)
  124:     tm.assert_series_equal(output, input, check_names=False)
  125: 
  126: 
  127: def test_compression_warning(compression_only):
  128:     # Assert that passing a file object to to_csv while explicitly specifying a
  129:     # compression protocol triggers a RuntimeWarning, as per GH21227.
  130:     df = pd.DataFrame(
  131:         100 * [[0.123456, 0.234567, 0.567567], [12.32112, 123123.2, 321321.2]],
  132:         columns=["X", "Y", "Z"],
  133:     )
  134:     with tm.ensure_clean() as path:
  135:         with icom.get_handle(path, "w", compression=compression_only) as handles:
  136:             with tm.assert_produces_warning(RuntimeWarning):
  137:                 df.to_csv(handles.handle, compression=compression_only)
  138: 
  139: 
  140: def test_compression_binary(compression_only):
  141:     """
  142:     Binary file handles support compression.
  143: 
  144:     GH22555
  145:     """
  146:     df = pd.DataFrame(
  147:         1.1 * np.arange(120).reshape((30, 4)),
  148:         columns=pd.Index(list("ABCD"), dtype=object),
  149:         index=pd.Index([f"i-{i}" for i in range(30)], dtype=object),
  150:     )
  151: 
  152:     # with a file
  153:     with tm.ensure_clean() as path:
  154:         with open(path, mode="wb") as file:
  155:             df.to_csv(file, mode="wb", compression=compression_only)
  156:             file.seek(0)  # file shouldn't be closed
  157:         tm.assert_frame_equal(
  158:             df, pd.read_csv(path, index_col=0, compression=compression_only)
  159:         )
  160: 
  161:     # with BytesIO
  162:     file = io.BytesIO()
  163:     df.to_csv(file, mode="wb", compression=compression_only)
  164:     file.seek(0)  # file shouldn't be closed
  165:     tm.assert_frame_equal(
  166:         df, pd.read_csv(file, index_col=0, compression=compression_only)
  167:     )
  168: 
  169: 
  170: def test_gzip_reproducibility_file_name():
  171:     """
  172:     Gzip should create reproducible archives with mtime.
  173: 
  174:     Note: Archives created with different filenames will still be different!
  175: 
  176:     GH 28103
  177:     """
  178:     df = pd.DataFrame(
  179:         1.1 * np.arange(120).reshape((30, 4)),
  180:         columns=pd.Index(list("ABCD"), dtype=object),
  181:         index=pd.Index([f"i-{i}" for i in range(30)], dtype=object),
  182:     )
  183:     compression_options = {"method": "gzip", "mtime": 1}
  184: 
  185:     # test for filename
  186:     with tm.ensure_clean() as path:
  187:         path = Path(path)
  188:         df.to_csv(path, compression=compression_options)
  189:         time.sleep(0.1)
  190:         output = path.read_bytes()
  191:         df.to_csv(path, compression=compression_options)
  192:         assert output == path.read_bytes()
  193: 
  194: 
  195: def test_gzip_reproducibility_file_object():
  196:     """
  197:     Gzip should create reproducible archives with mtime.
  198: 
  199:     GH 28103
  200:     """
  201:     df = pd.DataFrame(
  202:         1.1 * np.arange(120).reshape((30, 4)),
  203:         columns=pd.Index(list("ABCD"), dtype=object),
  204:         index=pd.Index([f"i-{i}" for i in range(30)], dtype=object),
  205:     )
  206:     compression_options = {"method": "gzip", "mtime": 1}
  207: 
  208:     # test for file object
  209:     buffer = io.BytesIO()
  210:     df.to_csv(buffer, compression=compression_options, mode="wb")
  211:     output = buffer.getvalue()
  212:     time.sleep(0.1)
  213:     buffer = io.BytesIO()
  214:     df.to_csv(buffer, compression=compression_options, mode="wb")
  215:     assert output == buffer.getvalue()
  216: 
  217: 
  218: @pytest.mark.single_cpu
  219: def test_with_missing_lzma():
  220:     """Tests if import pandas works when lzma is not present."""
  221:     # https://github.com/pandas-dev/pandas/issues/27575
  222:     code = textwrap.dedent(
  223:         """\
  224:         import sys
  225:         sys.modules['lzma'] = None
  226:         import pandas
  227:         """
  228:     )
  229:     subprocess.check_output([sys.executable, "-c", code], stderr=subprocess.PIPE)
  230: 
  231: 
  232: @pytest.mark.single_cpu
  233: def test_with_missing_lzma_runtime():
  234:     """Tests if RuntimeError is hit when calling lzma without
  235:     having the module available.
  236:     """
  237:     code = textwrap.dedent(
  238:         """
  239:         import sys
  240:         import pytest
  241:         sys.modules['lzma'] = None
  242:         import pandas as pd
  243:         df = pd.DataFrame()
  244:         with pytest.raises(RuntimeError, match='lzma module'):
  245:             df.to_csv('foo.csv', compression='xz')
  246:         """
  247:     )
  248:     subprocess.check_output([sys.executable, "-c", code], stderr=subprocess.PIPE)
  249: 
  250: 
  251: @pytest.mark.parametrize(
  252:     "obj",
  253:     [
  254:         pd.DataFrame(
  255:             100 * [[0.123456, 0.234567, 0.567567], [12.32112, 123123.2, 321321.2]],
  256:             columns=["X", "Y", "Z"],
  257:         ),
  258:         pd.Series(100 * [0.123456, 0.234567, 0.567567], name="X"),
  259:     ],
  260: )
  261: @pytest.mark.parametrize("method", ["to_pickle", "to_json", "to_csv"])
  262: def test_gzip_compression_level(obj, method):
  263:     # GH33196
  264:     with tm.ensure_clean() as path:
  265:         getattr(obj, method)(path, compression="gzip")
  266:         compressed_size_default = os.path.getsize(path)
  267:         getattr(obj, method)(path, compression={"method": "gzip", "compresslevel": 1})
  268:         compressed_size_fast = os.path.getsize(path)
  269:         assert compressed_size_default < compressed_size_fast
  270: 
  271: 
  272: @pytest.mark.parametrize(
  273:     "obj",
  274:     [
  275:         pd.DataFrame(
  276:             100 * [[0.123456, 0.234567, 0.567567], [12.32112, 123123.2, 321321.2]],
  277:             columns=["X", "Y", "Z"],
  278:         ),
  279:         pd.Series(100 * [0.123456, 0.234567, 0.567567], name="X"),
  280:     ],
  281: )
  282: @pytest.mark.parametrize("method", ["to_pickle", "to_json", "to_csv"])
  283: def test_xz_compression_level_read(obj, method):
  284:     with tm.ensure_clean() as path:
  285:         getattr(obj, method)(path, compression="xz")
  286:         compressed_size_default = os.path.getsize(path)
  287:         getattr(obj, method)(path, compression={"method": "xz", "preset": 1})
  288:         compressed_size_fast = os.path.getsize(path)
  289:         assert compressed_size_default < compressed_size_fast
  290:         if method == "to_csv":
  291:             pd.read_csv(path, compression="xz")
  292: 
  293: 
  294: @pytest.mark.parametrize(
  295:     "obj",
  296:     [
  297:         pd.DataFrame(
  298:             100 * [[0.123456, 0.234567, 0.567567], [12.32112, 123123.2, 321321.2]],
  299:             columns=["X", "Y", "Z"],
  300:         ),
  301:         pd.Series(100 * [0.123456, 0.234567, 0.567567], name="X"),
  302:     ],
  303: )
  304: @pytest.mark.parametrize("method", ["to_pickle", "to_json", "to_csv"])
  305: def test_bzip_compression_level(obj, method):
  306:     """GH33196 bzip needs file size > 100k to show a size difference between
  307:     compression levels, so here we just check if the call works when
  308:     compression is passed as a dict.
  309:     """
  310:     with tm.ensure_clean() as path:
  311:         getattr(obj, method)(path, compression={"method": "bz2", "compresslevel": 1})
  312: 
  313: 
  314: @pytest.mark.parametrize(
  315:     "suffix,archive",
  316:     [
  317:         (".zip", zipfile.ZipFile),
  318:         (".tar", tarfile.TarFile),
  319:     ],
  320: )
  321: def test_empty_archive_zip(suffix, archive):
  322:     with tm.ensure_clean(filename=suffix) as path:
  323:         with archive(path, "w"):
  324:             pass
  325:         with pytest.raises(ValueError, match="Zero files found"):
  326:             pd.read_csv(path)
  327: 
  328: 
  329: def test_ambiguous_archive_zip():
  330:     with tm.ensure_clean(filename=".zip") as path:
  331:         with zipfile.ZipFile(path, "w") as file:
  332:             file.writestr("a.csv", "foo,bar")
  333:             file.writestr("b.csv", "foo,bar")
  334:         with pytest.raises(ValueError, match="Multiple files found in ZIP file"):
  335:             pd.read_csv(path)
  336: 
  337: 
  338: def test_ambiguous_archive_tar(tmp_path):
  339:     csvAPath = tmp_path / "a.csv"
  340:     with open(csvAPath, "w", encoding="utf-8") as a:
  341:         a.write("foo,bar\n")
  342:     csvBPath = tmp_path / "b.csv"
  343:     with open(csvBPath, "w", encoding="utf-8") as b:
  344:         b.write("foo,bar\n")
  345: 
  346:     tarpath = tmp_path / "archive.tar"
  347:     with tarfile.TarFile(tarpath, "w") as tar:
  348:         tar.add(csvAPath, "a.csv")
  349:         tar.add(csvBPath, "b.csv")
  350: 
  351:     with pytest.raises(ValueError, match="Multiple files found in TAR archive"):
  352:         pd.read_csv(tarpath)
  353: 
  354: 
  355: def test_tar_gz_to_different_filename():
  356:     with tm.ensure_clean(filename=".foo") as file:
  357:         pd.DataFrame(
  358:             [["1", "2"]],
  359:             columns=["foo", "bar"],
  360:         ).to_csv(file, compression={"method": "tar", "mode": "w:gz"}, index=False)
  361:         with gzip.open(file) as uncompressed:
  362:             with tarfile.TarFile(fileobj=uncompressed) as archive:
  363:                 members = archive.getmembers()
  364:                 assert len(members) == 1
  365:                 content = archive.extractfile(members[0]).read().decode("utf8")
  366: 
  367:                 if is_platform_windows():
  368:                     expected = "foo,bar\r\n1,2\r\n"
  369:                 else:
  370:                     expected = "foo,bar\n1,2\n"
  371: 
  372:                 assert content == expected
  373: 
  374: 
  375: def test_tar_no_error_on_close():
  376:     with io.BytesIO() as buffer:
  377:         with icom._BytesTarFile(fileobj=buffer, mode="w"):
  378:             pass
