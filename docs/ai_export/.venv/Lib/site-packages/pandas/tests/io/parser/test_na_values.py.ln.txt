    1: """
    2: Tests that NA values are properly handled during
    3: parsing for all of the parsers defined in parsers.py
    4: """
    5: from io import StringIO
    6: 
    7: import numpy as np
    8: import pytest
    9: 
   10: from pandas._libs.parsers import STR_NA_VALUES
   11: 
   12: from pandas import (
   13:     DataFrame,
   14:     Index,
   15:     MultiIndex,
   16: )
   17: import pandas._testing as tm
   18: 
   19: pytestmark = pytest.mark.filterwarnings(
   20:     "ignore:Passing a BlockManager to DataFrame:DeprecationWarning"
   21: )
   22: 
   23: xfail_pyarrow = pytest.mark.usefixtures("pyarrow_xfail")
   24: skip_pyarrow = pytest.mark.usefixtures("pyarrow_skip")
   25: 
   26: 
   27: def test_string_nas(all_parsers):
   28:     parser = all_parsers
   29:     data = """A,B,C
   30: a,b,c
   31: d,,f
   32: ,g,h
   33: """
   34:     result = parser.read_csv(StringIO(data))
   35:     expected = DataFrame(
   36:         [["a", "b", "c"], ["d", np.nan, "f"], [np.nan, "g", "h"]],
   37:         columns=["A", "B", "C"],
   38:     )
   39:     if parser.engine == "pyarrow":
   40:         expected.loc[2, "A"] = None
   41:         expected.loc[1, "B"] = None
   42:     tm.assert_frame_equal(result, expected)
   43: 
   44: 
   45: def test_detect_string_na(all_parsers):
   46:     parser = all_parsers
   47:     data = """A,B
   48: foo,bar
   49: NA,baz
   50: NaN,nan
   51: """
   52:     expected = DataFrame(
   53:         [["foo", "bar"], [np.nan, "baz"], [np.nan, np.nan]], columns=["A", "B"]
   54:     )
   55:     if parser.engine == "pyarrow":
   56:         expected.loc[[1, 2], "A"] = None
   57:         expected.loc[2, "B"] = None
   58:     result = parser.read_csv(StringIO(data))
   59:     tm.assert_frame_equal(result, expected)
   60: 
   61: 
   62: @pytest.mark.parametrize(
   63:     "na_values",
   64:     [
   65:         ["-999.0", "-999"],
   66:         [-999, -999.0],
   67:         [-999.0, -999],
   68:         ["-999.0"],
   69:         ["-999"],
   70:         [-999.0],
   71:         [-999],
   72:     ],
   73: )
   74: @pytest.mark.parametrize(
   75:     "data",
   76:     [
   77:         """A,B
   78: -999,1.2
   79: 2,-999
   80: 3,4.5
   81: """,
   82:         """A,B
   83: -999,1.200
   84: 2,-999.000
   85: 3,4.500
   86: """,
   87:     ],
   88: )
   89: def test_non_string_na_values(all_parsers, data, na_values, request):
   90:     # see gh-3611: with an odd float format, we can't match
   91:     # the string "999.0" exactly but still need float matching
   92:     parser = all_parsers
   93:     expected = DataFrame([[np.nan, 1.2], [2.0, np.nan], [3.0, 4.5]], columns=["A", "B"])
   94: 
   95:     if parser.engine == "pyarrow" and not all(isinstance(x, str) for x in na_values):
   96:         msg = "The 'pyarrow' engine requires all na_values to be strings"
   97:         with pytest.raises(TypeError, match=msg):
   98:             parser.read_csv(StringIO(data), na_values=na_values)
   99:         return
  100:     elif parser.engine == "pyarrow" and "-999.000" in data:
  101:         # bc the pyarrow engine does not include the float-ified version
  102:         #  of "-999" -> -999, it does not match the entry with the trailing
  103:         #  zeros, so "-999.000" is not treated as null.
  104:         mark = pytest.mark.xfail(
  105:             reason="pyarrow engined does not recognize equivalent floats"
  106:         )
  107:         request.applymarker(mark)
  108: 
  109:     result = parser.read_csv(StringIO(data), na_values=na_values)
  110:     tm.assert_frame_equal(result, expected)
  111: 
  112: 
  113: def test_default_na_values(all_parsers):
  114:     _NA_VALUES = {
  115:         "-1.#IND",
  116:         "1.#QNAN",
  117:         "1.#IND",
  118:         "-1.#QNAN",
  119:         "#N/A",
  120:         "N/A",
  121:         "n/a",
  122:         "NA",
  123:         "<NA>",
  124:         "#NA",
  125:         "NULL",
  126:         "null",
  127:         "NaN",
  128:         "nan",
  129:         "-NaN",
  130:         "-nan",
  131:         "#N/A N/A",
  132:         "",
  133:         "None",
  134:     }
  135:     assert _NA_VALUES == STR_NA_VALUES
  136: 
  137:     parser = all_parsers
  138:     nv = len(_NA_VALUES)
  139: 
  140:     def f(i, v):
  141:         if i == 0:
  142:             buf = ""
  143:         elif i > 0:
  144:             buf = "".join([","] * i)
  145: 
  146:         buf = f"{buf}{v}"
  147: 
  148:         if i < nv - 1:
  149:             joined = "".join([","] * (nv - i - 1))
  150:             buf = f"{buf}{joined}"
  151: 
  152:         return buf
  153: 
  154:     data = StringIO("\n".join([f(i, v) for i, v in enumerate(_NA_VALUES)]))
  155:     expected = DataFrame(np.nan, columns=range(nv), index=range(nv))
  156: 
  157:     result = parser.read_csv(data, header=None)
  158:     tm.assert_frame_equal(result, expected)
  159: 
  160: 
  161: @pytest.mark.parametrize("na_values", ["baz", ["baz"]])
  162: def test_custom_na_values(all_parsers, na_values):
  163:     parser = all_parsers
  164:     data = """A,B,C
  165: ignore,this,row
  166: 1,NA,3
  167: -1.#IND,5,baz
  168: 7,8,NaN
  169: """
  170:     expected = DataFrame(
  171:         [[1.0, np.nan, 3], [np.nan, 5, np.nan], [7, 8, np.nan]], columns=["A", "B", "C"]
  172:     )
  173:     if parser.engine == "pyarrow":
  174:         msg = "skiprows argument must be an integer when using engine='pyarrow'"
  175:         with pytest.raises(ValueError, match=msg):
  176:             parser.read_csv(StringIO(data), na_values=na_values, skiprows=[1])
  177:         return
  178: 
  179:     result = parser.read_csv(StringIO(data), na_values=na_values, skiprows=[1])
  180:     tm.assert_frame_equal(result, expected)
  181: 
  182: 
  183: def test_bool_na_values(all_parsers):
  184:     data = """A,B,C
  185: True,False,True
  186: NA,True,False
  187: False,NA,True"""
  188:     parser = all_parsers
  189:     result = parser.read_csv(StringIO(data))
  190:     expected = DataFrame(
  191:         {
  192:             "A": np.array([True, np.nan, False], dtype=object),
  193:             "B": np.array([False, True, np.nan], dtype=object),
  194:             "C": [True, False, True],
  195:         }
  196:     )
  197:     if parser.engine == "pyarrow":
  198:         expected.loc[1, "A"] = None
  199:         expected.loc[2, "B"] = None
  200:     tm.assert_frame_equal(result, expected)
  201: 
  202: 
  203: def test_na_value_dict(all_parsers):
  204:     data = """A,B,C
  205: foo,bar,NA
  206: bar,foo,foo
  207: foo,bar,NA
  208: bar,foo,foo"""
  209:     parser = all_parsers
  210: 
  211:     if parser.engine == "pyarrow":
  212:         msg = "pyarrow engine doesn't support passing a dict for na_values"
  213:         with pytest.raises(ValueError, match=msg):
  214:             parser.read_csv(StringIO(data), na_values={"A": ["foo"], "B": ["bar"]})
  215:         return
  216: 
  217:     df = parser.read_csv(StringIO(data), na_values={"A": ["foo"], "B": ["bar"]})
  218:     expected = DataFrame(
  219:         {
  220:             "A": [np.nan, "bar", np.nan, "bar"],
  221:             "B": [np.nan, "foo", np.nan, "foo"],
  222:             "C": [np.nan, "foo", np.nan, "foo"],
  223:         }
  224:     )
  225:     tm.assert_frame_equal(df, expected)
  226: 
  227: 
  228: @pytest.mark.parametrize(
  229:     "index_col,expected",
  230:     [
  231:         (
  232:             [0],
  233:             DataFrame({"b": [np.nan], "c": [1], "d": [5]}, index=Index([0], name="a")),
  234:         ),
  235:         (
  236:             [0, 2],
  237:             DataFrame(
  238:                 {"b": [np.nan], "d": [5]},
  239:                 index=MultiIndex.from_tuples([(0, 1)], names=["a", "c"]),
  240:             ),
  241:         ),
  242:         (
  243:             ["a", "c"],
  244:             DataFrame(
  245:                 {"b": [np.nan], "d": [5]},
  246:                 index=MultiIndex.from_tuples([(0, 1)], names=["a", "c"]),
  247:             ),
  248:         ),
  249:     ],
  250: )
  251: def test_na_value_dict_multi_index(all_parsers, index_col, expected):
  252:     data = """\
  253: a,b,c,d
  254: 0,NA,1,5
  255: """
  256:     parser = all_parsers
  257:     result = parser.read_csv(StringIO(data), na_values=set(), index_col=index_col)
  258:     tm.assert_frame_equal(result, expected)
  259: 
  260: 
  261: @pytest.mark.parametrize(
  262:     "kwargs,expected",
  263:     [
  264:         (
  265:             {},
  266:             DataFrame(
  267:                 {
  268:                     "A": ["a", "b", np.nan, "d", "e", np.nan, "g"],
  269:                     "B": [1, 2, 3, 4, 5, 6, 7],
  270:                     "C": ["one", "two", "three", np.nan, "five", np.nan, "seven"],
  271:                 }
  272:             ),
  273:         ),
  274:         (
  275:             {"na_values": {"A": [], "C": []}, "keep_default_na": False},
  276:             DataFrame(
  277:                 {
  278:                     "A": ["a", "b", "", "d", "e", "nan", "g"],
  279:                     "B": [1, 2, 3, 4, 5, 6, 7],
  280:                     "C": ["one", "two", "three", "nan", "five", "", "seven"],
  281:                 }
  282:             ),
  283:         ),
  284:         (
  285:             {"na_values": ["a"], "keep_default_na": False},
  286:             DataFrame(
  287:                 {
  288:                     "A": [np.nan, "b", "", "d", "e", "nan", "g"],
  289:                     "B": [1, 2, 3, 4, 5, 6, 7],
  290:                     "C": ["one", "two", "three", "nan", "five", "", "seven"],
  291:                 }
  292:             ),
  293:         ),
  294:         (
  295:             {"na_values": {"A": [], "C": []}},
  296:             DataFrame(
  297:                 {
  298:                     "A": ["a", "b", np.nan, "d", "e", np.nan, "g"],
  299:                     "B": [1, 2, 3, 4, 5, 6, 7],
  300:                     "C": ["one", "two", "three", np.nan, "five", np.nan, "seven"],
  301:                 }
  302:             ),
  303:         ),
  304:     ],
  305: )
  306: def test_na_values_keep_default(all_parsers, kwargs, expected, request):
  307:     data = """\
  308: A,B,C
  309: a,1,one
  310: b,2,two
  311: ,3,three
  312: d,4,nan
  313: e,5,five
  314: nan,6,
  315: g,7,seven
  316: """
  317:     parser = all_parsers
  318:     if parser.engine == "pyarrow":
  319:         if "na_values" in kwargs and isinstance(kwargs["na_values"], dict):
  320:             msg = "The pyarrow engine doesn't support passing a dict for na_values"
  321:             with pytest.raises(ValueError, match=msg):
  322:                 parser.read_csv(StringIO(data), **kwargs)
  323:             return
  324:         mark = pytest.mark.xfail()
  325:         request.applymarker(mark)
  326: 
  327:     result = parser.read_csv(StringIO(data), **kwargs)
  328:     tm.assert_frame_equal(result, expected)
  329: 
  330: 
  331: def test_no_na_values_no_keep_default(all_parsers):
  332:     # see gh-4318: passing na_values=None and
  333:     # keep_default_na=False yields 'None" as a na_value
  334:     data = """\
  335: A,B,C
  336: a,1,None
  337: b,2,two
  338: ,3,None
  339: d,4,nan
  340: e,5,five
  341: nan,6,
  342: g,7,seven
  343: """
  344:     parser = all_parsers
  345:     result = parser.read_csv(StringIO(data), keep_default_na=False)
  346: 
  347:     expected = DataFrame(
  348:         {
  349:             "A": ["a", "b", "", "d", "e", "nan", "g"],
  350:             "B": [1, 2, 3, 4, 5, 6, 7],
  351:             "C": ["None", "two", "None", "nan", "five", "", "seven"],
  352:         }
  353:     )
  354:     tm.assert_frame_equal(result, expected)
  355: 
  356: 
  357: def test_no_keep_default_na_dict_na_values(all_parsers):
  358:     # see gh-19227
  359:     data = "a,b\n,2"
  360:     parser = all_parsers
  361: 
  362:     if parser.engine == "pyarrow":
  363:         msg = "The pyarrow engine doesn't support passing a dict for na_values"
  364:         with pytest.raises(ValueError, match=msg):
  365:             parser.read_csv(
  366:                 StringIO(data), na_values={"b": ["2"]}, keep_default_na=False
  367:             )
  368:         return
  369: 
  370:     result = parser.read_csv(
  371:         StringIO(data), na_values={"b": ["2"]}, keep_default_na=False
  372:     )
  373:     expected = DataFrame({"a": [""], "b": [np.nan]})
  374:     tm.assert_frame_equal(result, expected)
  375: 
  376: 
  377: def test_no_keep_default_na_dict_na_scalar_values(all_parsers):
  378:     # see gh-19227
  379:     #
  380:     # Scalar values shouldn't cause the parsing to crash or fail.
  381:     data = "a,b\n1,2"
  382:     parser = all_parsers
  383: 
  384:     if parser.engine == "pyarrow":
  385:         msg = "The pyarrow engine doesn't support passing a dict for na_values"
  386:         with pytest.raises(ValueError, match=msg):
  387:             parser.read_csv(StringIO(data), na_values={"b": 2}, keep_default_na=False)
  388:         return
  389: 
  390:     df = parser.read_csv(StringIO(data), na_values={"b": 2}, keep_default_na=False)
  391:     expected = DataFrame({"a": [1], "b": [np.nan]})
  392:     tm.assert_frame_equal(df, expected)
  393: 
  394: 
  395: @pytest.mark.parametrize("col_zero_na_values", [113125, "113125"])
  396: def test_no_keep_default_na_dict_na_values_diff_reprs(all_parsers, col_zero_na_values):
  397:     # see gh-19227
  398:     data = """\
  399: 113125,"blah","/blaha",kjsdkj,412.166,225.874,214.008
  400: 729639,"qwer","",asdfkj,466.681,,252.373
  401: """
  402:     parser = all_parsers
  403:     expected = DataFrame(
  404:         {
  405:             0: [np.nan, 729639.0],
  406:             1: [np.nan, "qwer"],
  407:             2: ["/blaha", np.nan],
  408:             3: ["kjsdkj", "asdfkj"],
  409:             4: [412.166, 466.681],
  410:             5: ["225.874", ""],
  411:             6: [np.nan, 252.373],
  412:         }
  413:     )
  414: 
  415:     if parser.engine == "pyarrow":
  416:         msg = "The pyarrow engine doesn't support passing a dict for na_values"
  417:         with pytest.raises(ValueError, match=msg):
  418:             parser.read_csv(
  419:                 StringIO(data),
  420:                 header=None,
  421:                 keep_default_na=False,
  422:                 na_values={2: "", 6: "214.008", 1: "blah", 0: col_zero_na_values},
  423:             )
  424:         return
  425: 
  426:     result = parser.read_csv(
  427:         StringIO(data),
  428:         header=None,
  429:         keep_default_na=False,
  430:         na_values={2: "", 6: "214.008", 1: "blah", 0: col_zero_na_values},
  431:     )
  432:     tm.assert_frame_equal(result, expected)
  433: 
  434: 
  435: @xfail_pyarrow  # mismatched dtypes in both cases, FutureWarning in the True case
  436: @pytest.mark.parametrize(
  437:     "na_filter,row_data",
  438:     [
  439:         (True, [[1, "A"], [np.nan, np.nan], [3, "C"]]),
  440:         (False, [["1", "A"], ["nan", "B"], ["3", "C"]]),
  441:     ],
  442: )
  443: def test_na_values_na_filter_override(all_parsers, na_filter, row_data):
  444:     data = """\
  445: A,B
  446: 1,A
  447: nan,B
  448: 3,C
  449: """
  450:     parser = all_parsers
  451:     result = parser.read_csv(StringIO(data), na_values=["B"], na_filter=na_filter)
  452: 
  453:     expected = DataFrame(row_data, columns=["A", "B"])
  454:     tm.assert_frame_equal(result, expected)
  455: 
  456: 
  457: @skip_pyarrow  # CSV parse error: Expected 8 columns, got 5:
  458: def test_na_trailing_columns(all_parsers):
  459:     parser = all_parsers
  460:     data = """Date,Currency,Symbol,Type,Units,UnitPrice,Cost,Tax
  461: 2012-03-14,USD,AAPL,BUY,1000
  462: 2012-05-12,USD,SBUX,SELL,500"""
  463: 
  464:     # Trailing columns should be all NaN.
  465:     result = parser.read_csv(StringIO(data))
  466:     expected = DataFrame(
  467:         [
  468:             ["2012-03-14", "USD", "AAPL", "BUY", 1000, np.nan, np.nan, np.nan],
  469:             ["2012-05-12", "USD", "SBUX", "SELL", 500, np.nan, np.nan, np.nan],
  470:         ],
  471:         columns=[
  472:             "Date",
  473:             "Currency",
  474:             "Symbol",
  475:             "Type",
  476:             "Units",
  477:             "UnitPrice",
  478:             "Cost",
  479:             "Tax",
  480:         ],
  481:     )
  482:     tm.assert_frame_equal(result, expected)
  483: 
  484: 
  485: @pytest.mark.parametrize(
  486:     "na_values,row_data",
  487:     [
  488:         (1, [[np.nan, 2.0], [2.0, np.nan]]),
  489:         ({"a": 2, "b": 1}, [[1.0, 2.0], [np.nan, np.nan]]),
  490:     ],
  491: )
  492: def test_na_values_scalar(all_parsers, na_values, row_data):
  493:     # see gh-12224
  494:     parser = all_parsers
  495:     names = ["a", "b"]
  496:     data = "1,2\n2,1"
  497: 
  498:     if parser.engine == "pyarrow" and isinstance(na_values, dict):
  499:         if isinstance(na_values, dict):
  500:             err = ValueError
  501:             msg = "The pyarrow engine doesn't support passing a dict for na_values"
  502:         else:
  503:             err = TypeError
  504:             msg = "The 'pyarrow' engine requires all na_values to be strings"
  505:         with pytest.raises(err, match=msg):
  506:             parser.read_csv(StringIO(data), names=names, na_values=na_values)
  507:         return
  508:     elif parser.engine == "pyarrow":
  509:         msg = "The 'pyarrow' engine requires all na_values to be strings"
  510:         with pytest.raises(TypeError, match=msg):
  511:             parser.read_csv(StringIO(data), names=names, na_values=na_values)
  512:         return
  513: 
  514:     result = parser.read_csv(StringIO(data), names=names, na_values=na_values)
  515:     expected = DataFrame(row_data, columns=names)
  516:     tm.assert_frame_equal(result, expected)
  517: 
  518: 
  519: def test_na_values_dict_aliasing(all_parsers):
  520:     parser = all_parsers
  521:     na_values = {"a": 2, "b": 1}
  522:     na_values_copy = na_values.copy()
  523: 
  524:     names = ["a", "b"]
  525:     data = "1,2\n2,1"
  526: 
  527:     expected = DataFrame([[1.0, 2.0], [np.nan, np.nan]], columns=names)
  528: 
  529:     if parser.engine == "pyarrow":
  530:         msg = "The pyarrow engine doesn't support passing a dict for na_values"
  531:         with pytest.raises(ValueError, match=msg):
  532:             parser.read_csv(StringIO(data), names=names, na_values=na_values)
  533:         return
  534: 
  535:     result = parser.read_csv(StringIO(data), names=names, na_values=na_values)
  536: 
  537:     tm.assert_frame_equal(result, expected)
  538:     tm.assert_dict_equal(na_values, na_values_copy)
  539: 
  540: 
  541: def test_na_values_dict_col_index(all_parsers):
  542:     # see gh-14203
  543:     data = "a\nfoo\n1"
  544:     parser = all_parsers
  545:     na_values = {0: "foo"}
  546: 
  547:     if parser.engine == "pyarrow":
  548:         msg = "The pyarrow engine doesn't support passing a dict for na_values"
  549:         with pytest.raises(ValueError, match=msg):
  550:             parser.read_csv(StringIO(data), na_values=na_values)
  551:         return
  552: 
  553:     result = parser.read_csv(StringIO(data), na_values=na_values)
  554:     expected = DataFrame({"a": [np.nan, 1]})
  555:     tm.assert_frame_equal(result, expected)
  556: 
  557: 
  558: @pytest.mark.parametrize(
  559:     "data,kwargs,expected",
  560:     [
  561:         (
  562:             str(2**63) + "\n" + str(2**63 + 1),
  563:             {"na_values": [2**63]},
  564:             DataFrame([str(2**63), str(2**63 + 1)]),
  565:         ),
  566:         (str(2**63) + ",1" + "\n,2", {}, DataFrame([[str(2**63), 1], ["", 2]])),
  567:         (str(2**63) + "\n1", {"na_values": [2**63]}, DataFrame([np.nan, 1])),
  568:     ],
  569: )
  570: def test_na_values_uint64(all_parsers, data, kwargs, expected, request):
  571:     # see gh-14983
  572:     parser = all_parsers
  573: 
  574:     if parser.engine == "pyarrow" and "na_values" in kwargs:
  575:         msg = "The 'pyarrow' engine requires all na_values to be strings"
  576:         with pytest.raises(TypeError, match=msg):
  577:             parser.read_csv(StringIO(data), header=None, **kwargs)
  578:         return
  579:     elif parser.engine == "pyarrow":
  580:         mark = pytest.mark.xfail(reason="Returns float64 instead of object")
  581:         request.applymarker(mark)
  582: 
  583:     result = parser.read_csv(StringIO(data), header=None, **kwargs)
  584:     tm.assert_frame_equal(result, expected)
  585: 
  586: 
  587: def test_empty_na_values_no_default_with_index(all_parsers):
  588:     # see gh-15835
  589:     data = "a,1\nb,2"
  590:     parser = all_parsers
  591:     expected = DataFrame({"1": [2]}, index=Index(["b"], name="a"))
  592: 
  593:     result = parser.read_csv(StringIO(data), index_col=0, keep_default_na=False)
  594:     tm.assert_frame_equal(result, expected)
  595: 
  596: 
  597: @pytest.mark.parametrize(
  598:     "na_filter,index_data", [(False, ["", "5"]), (True, [np.nan, 5.0])]
  599: )
  600: def test_no_na_filter_on_index(all_parsers, na_filter, index_data, request):
  601:     # see gh-5239
  602:     #
  603:     # Don't parse NA-values in index unless na_filter=True
  604:     parser = all_parsers
  605:     data = "a,b,c\n1,,3\n4,5,6"
  606: 
  607:     if parser.engine == "pyarrow" and na_filter is False:
  608:         mark = pytest.mark.xfail(reason="mismatched index result")
  609:         request.applymarker(mark)
  610: 
  611:     expected = DataFrame({"a": [1, 4], "c": [3, 6]}, index=Index(index_data, name="b"))
  612:     result = parser.read_csv(StringIO(data), index_col=[1], na_filter=na_filter)
  613:     tm.assert_frame_equal(result, expected)
  614: 
  615: 
  616: def test_inf_na_values_with_int_index(all_parsers):
  617:     # see gh-17128
  618:     parser = all_parsers
  619:     data = "idx,col1,col2\n1,3,4\n2,inf,-inf"
  620: 
  621:     # Don't fail with OverflowError with inf's and integer index column.
  622:     out = parser.read_csv(StringIO(data), index_col=[0], na_values=["inf", "-inf"])
  623:     expected = DataFrame(
  624:         {"col1": [3, np.nan], "col2": [4, np.nan]}, index=Index([1, 2], name="idx")
  625:     )
  626:     tm.assert_frame_equal(out, expected)
  627: 
  628: 
  629: @xfail_pyarrow  # mismatched shape
  630: @pytest.mark.parametrize("na_filter", [True, False])
  631: def test_na_values_with_dtype_str_and_na_filter(all_parsers, na_filter):
  632:     # see gh-20377
  633:     parser = all_parsers
  634:     data = "a,b,c\n1,,3\n4,5,6"
  635: 
  636:     # na_filter=True --> missing value becomes NaN.
  637:     # na_filter=False --> missing value remains empty string.
  638:     empty = np.nan if na_filter else ""
  639:     expected = DataFrame({"a": ["1", "4"], "b": [empty, "5"], "c": ["3", "6"]})
  640: 
  641:     result = parser.read_csv(StringIO(data), na_filter=na_filter, dtype=str)
  642:     tm.assert_frame_equal(result, expected)
  643: 
  644: 
  645: @xfail_pyarrow  # mismatched exception message
  646: @pytest.mark.parametrize(
  647:     "data, na_values",
  648:     [
  649:         ("false,1\n,1\ntrue", None),
  650:         ("false,1\nnull,1\ntrue", None),
  651:         ("false,1\nnan,1\ntrue", None),
  652:         ("false,1\nfoo,1\ntrue", "foo"),
  653:         ("false,1\nfoo,1\ntrue", ["foo"]),
  654:         ("false,1\nfoo,1\ntrue", {"a": "foo"}),
  655:     ],
  656: )
  657: def test_cast_NA_to_bool_raises_error(all_parsers, data, na_values):
  658:     parser = all_parsers
  659:     msg = "|".join(
  660:         [
  661:             "Bool column has NA values in column [0a]",
  662:             "cannot safely convert passed user dtype of "
  663:             "bool for object dtyped data in column 0",
  664:         ]
  665:     )
  666: 
  667:     with pytest.raises(ValueError, match=msg):
  668:         parser.read_csv(
  669:             StringIO(data),
  670:             header=None,
  671:             names=["a", "b"],
  672:             dtype={"a": "bool"},
  673:             na_values=na_values,
  674:         )
  675: 
  676: 
  677: # TODO: this test isn't about the na_values keyword, it is about the empty entries
  678: #  being returned with NaN entries, whereas the pyarrow engine returns "nan"
  679: @xfail_pyarrow  # mismatched shapes
  680: def test_str_nan_dropped(all_parsers):
  681:     # see gh-21131
  682:     parser = all_parsers
  683: 
  684:     data = """File: small.csv,,
  685: 10010010233,0123,654
  686: foo,,bar
  687: 01001000155,4530,898"""
  688: 
  689:     result = parser.read_csv(
  690:         StringIO(data),
  691:         header=None,
  692:         names=["col1", "col2", "col3"],
  693:         dtype={"col1": str, "col2": str, "col3": str},
  694:     ).dropna()
  695: 
  696:     expected = DataFrame(
  697:         {
  698:             "col1": ["10010010233", "01001000155"],
  699:             "col2": ["0123", "4530"],
  700:             "col3": ["654", "898"],
  701:         },
  702:         index=[1, 3],
  703:     )
  704: 
  705:     tm.assert_frame_equal(result, expected)
  706: 
  707: 
  708: def test_nan_multi_index(all_parsers):
  709:     # GH 42446
  710:     parser = all_parsers
  711:     data = "A,B,B\nX,Y,Z\n1,2,inf"
  712: 
  713:     if parser.engine == "pyarrow":
  714:         msg = "The pyarrow engine doesn't support passing a dict for na_values"
  715:         with pytest.raises(ValueError, match=msg):
  716:             parser.read_csv(
  717:                 StringIO(data), header=list(range(2)), na_values={("B", "Z"): "inf"}
  718:             )
  719:         return
  720: 
  721:     result = parser.read_csv(
  722:         StringIO(data), header=list(range(2)), na_values={("B", "Z"): "inf"}
  723:     )
  724: 
  725:     expected = DataFrame(
  726:         {
  727:             ("A", "X"): [1],
  728:             ("B", "Y"): [2],
  729:             ("B", "Z"): [np.nan],
  730:         }
  731:     )
  732: 
  733:     tm.assert_frame_equal(result, expected)
  734: 
  735: 
  736: @xfail_pyarrow  # Failed: DID NOT RAISE <class 'ValueError'>; it casts the NaN to False
  737: def test_bool_and_nan_to_bool(all_parsers):
  738:     # GH#42808
  739:     parser = all_parsers
  740:     data = """0
  741: NaN
  742: True
  743: False
  744: """
  745:     with pytest.raises(ValueError, match="NA values"):
  746:         parser.read_csv(StringIO(data), dtype="bool")
  747: 
  748: 
  749: def test_bool_and_nan_to_int(all_parsers):
  750:     # GH#42808
  751:     parser = all_parsers
  752:     data = """0
  753: NaN
  754: True
  755: False
  756: """
  757:     with pytest.raises(ValueError, match="convert|NoneType"):
  758:         parser.read_csv(StringIO(data), dtype="int")
  759: 
  760: 
  761: def test_bool_and_nan_to_float(all_parsers):
  762:     # GH#42808
  763:     parser = all_parsers
  764:     data = """0
  765: NaN
  766: True
  767: False
  768: """
  769:     result = parser.read_csv(StringIO(data), dtype="float")
  770:     expected = DataFrame.from_dict({"0": [np.nan, 1.0, 0.0]})
  771:     tm.assert_frame_equal(result, expected)
