    1: import bz2
    2: import datetime as dt
    3: from datetime import datetime
    4: import gzip
    5: import io
    6: import os
    7: import struct
    8: import tarfile
    9: import zipfile
   10: 
   11: import numpy as np
   12: import pytest
   13: 
   14: import pandas.util._test_decorators as td
   15: 
   16: import pandas as pd
   17: from pandas import CategoricalDtype
   18: import pandas._testing as tm
   19: from pandas.core.frame import (
   20:     DataFrame,
   21:     Series,
   22: )
   23: 
   24: from pandas.io.parsers import read_csv
   25: from pandas.io.stata import (
   26:     CategoricalConversionWarning,
   27:     InvalidColumnName,
   28:     PossiblePrecisionLoss,
   29:     StataMissingValue,
   30:     StataReader,
   31:     StataWriter,
   32:     StataWriterUTF8,
   33:     ValueLabelTypeMismatch,
   34:     read_stata,
   35: )
   36: 
   37: 
   38: @pytest.fixture
   39: def mixed_frame():
   40:     return DataFrame(
   41:         {
   42:             "a": [1, 2, 3, 4],
   43:             "b": [1.0, 3.0, 27.0, 81.0],
   44:             "c": ["Atlanta", "Birmingham", "Cincinnati", "Detroit"],
   45:         }
   46:     )
   47: 
   48: 
   49: @pytest.fixture
   50: def parsed_114(datapath):
   51:     dta14_114 = datapath("io", "data", "stata", "stata5_114.dta")
   52:     parsed_114 = read_stata(dta14_114, convert_dates=True)
   53:     parsed_114.index.name = "index"
   54:     return parsed_114
   55: 
   56: 
   57: class TestStata:
   58:     def read_dta(self, file):
   59:         # Legacy default reader configuration
   60:         return read_stata(file, convert_dates=True)
   61: 
   62:     def read_csv(self, file):
   63:         return read_csv(file, parse_dates=True)
   64: 
   65:     @pytest.mark.parametrize("version", [114, 117, 118, 119, None])
   66:     def test_read_empty_dta(self, version):
   67:         empty_ds = DataFrame(columns=["unit"])
   68:         # GH 7369, make sure can read a 0-obs dta file
   69:         with tm.ensure_clean() as path:
   70:             empty_ds.to_stata(path, write_index=False, version=version)
   71:             empty_ds2 = read_stata(path)
   72:             tm.assert_frame_equal(empty_ds, empty_ds2)
   73: 
   74:     @pytest.mark.parametrize("version", [114, 117, 118, 119, None])
   75:     def test_read_empty_dta_with_dtypes(self, version):
   76:         # GH 46240
   77:         # Fixing above bug revealed that types are not correctly preserved when
   78:         # writing empty DataFrames
   79:         empty_df_typed = DataFrame(
   80:             {
   81:                 "i8": np.array([0], dtype=np.int8),
   82:                 "i16": np.array([0], dtype=np.int16),
   83:                 "i32": np.array([0], dtype=np.int32),
   84:                 "i64": np.array([0], dtype=np.int64),
   85:                 "u8": np.array([0], dtype=np.uint8),
   86:                 "u16": np.array([0], dtype=np.uint16),
   87:                 "u32": np.array([0], dtype=np.uint32),
   88:                 "u64": np.array([0], dtype=np.uint64),
   89:                 "f32": np.array([0], dtype=np.float32),
   90:                 "f64": np.array([0], dtype=np.float64),
   91:             }
   92:         )
   93:         expected = empty_df_typed.copy()
   94:         # No uint# support. Downcast since values in range for int#
   95:         expected["u8"] = expected["u8"].astype(np.int8)
   96:         expected["u16"] = expected["u16"].astype(np.int16)
   97:         expected["u32"] = expected["u32"].astype(np.int32)
   98:         # No int64 supported at all. Downcast since values in range for int32
   99:         expected["u64"] = expected["u64"].astype(np.int32)
  100:         expected["i64"] = expected["i64"].astype(np.int32)
  101: 
  102:         # GH 7369, make sure can read a 0-obs dta file
  103:         with tm.ensure_clean() as path:
  104:             empty_df_typed.to_stata(path, write_index=False, version=version)
  105:             empty_reread = read_stata(path)
  106:             tm.assert_frame_equal(expected, empty_reread)
  107:             tm.assert_series_equal(expected.dtypes, empty_reread.dtypes)
  108: 
  109:     @pytest.mark.parametrize("version", [114, 117, 118, 119, None])
  110:     def test_read_index_col_none(self, version):
  111:         df = DataFrame({"a": range(5), "b": ["b1", "b2", "b3", "b4", "b5"]})
  112:         # GH 7369, make sure can read a 0-obs dta file
  113:         with tm.ensure_clean() as path:
  114:             df.to_stata(path, write_index=False, version=version)
  115:             read_df = read_stata(path)
  116: 
  117:         assert isinstance(read_df.index, pd.RangeIndex)
  118:         expected = df.copy()
  119:         expected["a"] = expected["a"].astype(np.int32)
  120:         tm.assert_frame_equal(read_df, expected, check_index_type=True)
  121: 
  122:     @pytest.mark.parametrize("file", ["stata1_114", "stata1_117"])
  123:     def test_read_dta1(self, file, datapath):
  124:         file = datapath("io", "data", "stata", f"{file}.dta")
  125:         parsed = self.read_dta(file)
  126: 
  127:         # Pandas uses np.nan as missing value.
  128:         # Thus, all columns will be of type float, regardless of their name.
  129:         expected = DataFrame(
  130:             [(np.nan, np.nan, np.nan, np.nan, np.nan)],
  131:             columns=["float_miss", "double_miss", "byte_miss", "int_miss", "long_miss"],
  132:         )
  133: 
  134:         # this is an oddity as really the nan should be float64, but
  135:         # the casting doesn't fail so need to match stata here
  136:         expected["float_miss"] = expected["float_miss"].astype(np.float32)
  137: 
  138:         tm.assert_frame_equal(parsed, expected)
  139: 
  140:     def test_read_dta2(self, datapath):
  141:         expected = DataFrame.from_records(
  142:             [
  143:                 (
  144:                     datetime(2006, 11, 19, 23, 13, 20),
  145:                     1479596223000,
  146:                     datetime(2010, 1, 20),
  147:                     datetime(2010, 1, 8),
  148:                     datetime(2010, 1, 1),
  149:                     datetime(1974, 7, 1),
  150:                     datetime(2010, 1, 1),
  151:                     datetime(2010, 1, 1),
  152:                 ),
  153:                 (
  154:                     datetime(1959, 12, 31, 20, 3, 20),
  155:                     -1479590,
  156:                     datetime(1953, 10, 2),
  157:                     datetime(1948, 6, 10),
  158:                     datetime(1955, 1, 1),
  159:                     datetime(1955, 7, 1),
  160:                     datetime(1955, 1, 1),
  161:                     datetime(2, 1, 1),
  162:                 ),
  163:                 (pd.NaT, pd.NaT, pd.NaT, pd.NaT, pd.NaT, pd.NaT, pd.NaT, pd.NaT),
  164:             ],
  165:             columns=[
  166:                 "datetime_c",
  167:                 "datetime_big_c",
  168:                 "date",
  169:                 "weekly_date",
  170:                 "monthly_date",
  171:                 "quarterly_date",
  172:                 "half_yearly_date",
  173:                 "yearly_date",
  174:             ],
  175:         )
  176:         expected["yearly_date"] = expected["yearly_date"].astype("O")
  177: 
  178:         path1 = datapath("io", "data", "stata", "stata2_114.dta")
  179:         path2 = datapath("io", "data", "stata", "stata2_115.dta")
  180:         path3 = datapath("io", "data", "stata", "stata2_117.dta")
  181: 
  182:         with tm.assert_produces_warning(UserWarning):
  183:             parsed_114 = self.read_dta(path1)
  184:         with tm.assert_produces_warning(UserWarning):
  185:             parsed_115 = self.read_dta(path2)
  186:         with tm.assert_produces_warning(UserWarning):
  187:             parsed_117 = self.read_dta(path3)
  188:             # FIXME: don't leave commented-out
  189:             # 113 is buggy due to limits of date format support in Stata
  190:             # parsed_113 = self.read_dta(
  191:             # datapath("io", "data", "stata", "stata2_113.dta")
  192:             # )
  193: 
  194:         # FIXME: don't leave commented-out
  195:         # buggy test because of the NaT comparison on certain platforms
  196:         # Format 113 test fails since it does not support tc and tC formats
  197:         # tm.assert_frame_equal(parsed_113, expected)
  198:         tm.assert_frame_equal(parsed_114, expected, check_datetimelike_compat=True)
  199:         tm.assert_frame_equal(parsed_115, expected, check_datetimelike_compat=True)
  200:         tm.assert_frame_equal(parsed_117, expected, check_datetimelike_compat=True)
  201: 
  202:     @pytest.mark.parametrize(
  203:         "file", ["stata3_113", "stata3_114", "stata3_115", "stata3_117"]
  204:     )
  205:     def test_read_dta3(self, file, datapath):
  206:         file = datapath("io", "data", "stata", f"{file}.dta")
  207:         parsed = self.read_dta(file)
  208: 
  209:         # match stata here
  210:         expected = self.read_csv(datapath("io", "data", "stata", "stata3.csv"))
  211:         expected = expected.astype(np.float32)
  212:         expected["year"] = expected["year"].astype(np.int16)
  213:         expected["quarter"] = expected["quarter"].astype(np.int8)
  214: 
  215:         tm.assert_frame_equal(parsed, expected)
  216: 
  217:     @pytest.mark.parametrize(
  218:         "file", ["stata4_113", "stata4_114", "stata4_115", "stata4_117"]
  219:     )
  220:     def test_read_dta4(self, file, datapath):
  221:         file = datapath("io", "data", "stata", f"{file}.dta")
  222:         parsed = self.read_dta(file)
  223: 
  224:         expected = DataFrame.from_records(
  225:             [
  226:                 ["one", "ten", "one", "one", "one"],
  227:                 ["two", "nine", "two", "two", "two"],
  228:                 ["three", "eight", "three", "three", "three"],
  229:                 ["four", "seven", 4, "four", "four"],
  230:                 ["five", "six", 5, np.nan, "five"],
  231:                 ["six", "five", 6, np.nan, "six"],
  232:                 ["seven", "four", 7, np.nan, "seven"],
  233:                 ["eight", "three", 8, np.nan, "eight"],
  234:                 ["nine", "two", 9, np.nan, "nine"],
  235:                 ["ten", "one", "ten", np.nan, "ten"],
  236:             ],
  237:             columns=[
  238:                 "fully_labeled",
  239:                 "fully_labeled2",
  240:                 "incompletely_labeled",
  241:                 "labeled_with_missings",
  242:                 "float_labelled",
  243:             ],
  244:         )
  245: 
  246:         # these are all categoricals
  247:         for col in expected:
  248:             orig = expected[col].copy()
  249: 
  250:             categories = np.asarray(expected["fully_labeled"][orig.notna()])
  251:             if col == "incompletely_labeled":
  252:                 categories = orig
  253: 
  254:             cat = orig.astype("category")._values
  255:             cat = cat.set_categories(categories, ordered=True)
  256:             cat.categories.rename(None, inplace=True)
  257: 
  258:             expected[col] = cat
  259: 
  260:         # stata doesn't save .category metadata
  261:         tm.assert_frame_equal(parsed, expected)
  262: 
  263:     # File containing strls
  264:     def test_read_dta12(self, datapath):
  265:         parsed_117 = self.read_dta(datapath("io", "data", "stata", "stata12_117.dta"))
  266:         expected = DataFrame.from_records(
  267:             [
  268:                 [1, "abc", "abcdefghi"],
  269:                 [3, "cba", "qwertywertyqwerty"],
  270:                 [93, "", "strl"],
  271:             ],
  272:             columns=["x", "y", "z"],
  273:         )
  274: 
  275:         tm.assert_frame_equal(parsed_117, expected, check_dtype=False)
  276: 
  277:     def test_read_dta18(self, datapath):
  278:         parsed_118 = self.read_dta(datapath("io", "data", "stata", "stata14_118.dta"))
  279:         parsed_118["Bytes"] = parsed_118["Bytes"].astype("O")
  280:         expected = DataFrame.from_records(
  281:             [
  282:                 ["Cat", "Bogota", "BogotГЎ", 1, 1.0, "option b Гњnicode", 1.0],
  283:                 ["Dog", "Boston", "UzunkГ¶prГј", np.nan, np.nan, np.nan, np.nan],
  284:                 ["Plane", "Rome", "TromsГё", 0, 0.0, "option a", 0.0],
  285:                 ["Potato", "Tokyo", "ElГўzД±Дџ", -4, 4.0, 4, 4],  # noqa: RUF001
  286:                 ["", "", "", 0, 0.3332999, "option a", 1 / 3.0],
  287:             ],
  288:             columns=[
  289:                 "Things",
  290:                 "Cities",
  291:                 "Unicode_Cities_Strl",
  292:                 "Ints",
  293:                 "Floats",
  294:                 "Bytes",
  295:                 "Longs",
  296:             ],
  297:         )
  298:         expected["Floats"] = expected["Floats"].astype(np.float32)
  299:         for col in parsed_118.columns:
  300:             tm.assert_almost_equal(parsed_118[col], expected[col])
  301: 
  302:         with StataReader(datapath("io", "data", "stata", "stata14_118.dta")) as rdr:
  303:             vl = rdr.variable_labels()
  304:             vl_expected = {
  305:                 "Unicode_Cities_Strl": "Here are some strls with Гњnicode chars",
  306:                 "Longs": "long data",
  307:                 "Things": "Here are some things",
  308:                 "Bytes": "byte data",
  309:                 "Ints": "int data",
  310:                 "Cities": "Here are some cities",
  311:                 "Floats": "float data",
  312:             }
  313:             tm.assert_dict_equal(vl, vl_expected)
  314: 
  315:             assert rdr.data_label == "This is a  Гњnicode data label"
  316: 
  317:     def test_read_write_dta5(self):
  318:         original = DataFrame(
  319:             [(np.nan, np.nan, np.nan, np.nan, np.nan)],
  320:             columns=["float_miss", "double_miss", "byte_miss", "int_miss", "long_miss"],
  321:         )
  322:         original.index.name = "index"
  323: 
  324:         with tm.ensure_clean() as path:
  325:             original.to_stata(path, convert_dates=None)
  326:             written_and_read_again = self.read_dta(path)
  327: 
  328:         expected = original.copy()
  329:         expected.index = expected.index.astype(np.int32)
  330:         tm.assert_frame_equal(written_and_read_again.set_index("index"), expected)
  331: 
  332:     def test_write_dta6(self, datapath):
  333:         original = self.read_csv(datapath("io", "data", "stata", "stata3.csv"))
  334:         original.index.name = "index"
  335:         original.index = original.index.astype(np.int32)
  336:         original["year"] = original["year"].astype(np.int32)
  337:         original["quarter"] = original["quarter"].astype(np.int32)
  338: 
  339:         with tm.ensure_clean() as path:
  340:             original.to_stata(path, convert_dates=None)
  341:             written_and_read_again = self.read_dta(path)
  342:             tm.assert_frame_equal(
  343:                 written_and_read_again.set_index("index"),
  344:                 original,
  345:                 check_index_type=False,
  346:             )
  347: 
  348:     @pytest.mark.parametrize("version", [114, 117, 118, 119, None])
  349:     def test_read_write_dta10(self, version):
  350:         original = DataFrame(
  351:             data=[["string", "object", 1, 1.1, np.datetime64("2003-12-25")]],
  352:             columns=["string", "object", "integer", "floating", "datetime"],
  353:         )
  354:         original["object"] = Series(original["object"], dtype=object)
  355:         original.index.name = "index"
  356:         original.index = original.index.astype(np.int32)
  357:         original["integer"] = original["integer"].astype(np.int32)
  358: 
  359:         with tm.ensure_clean() as path:
  360:             original.to_stata(path, convert_dates={"datetime": "tc"}, version=version)
  361:             written_and_read_again = self.read_dta(path)
  362:             # original.index is np.int32, read index is np.int64
  363:             tm.assert_frame_equal(
  364:                 written_and_read_again.set_index("index"),
  365:                 original,
  366:                 check_index_type=False,
  367:             )
  368: 
  369:     def test_stata_doc_examples(self):
  370:         with tm.ensure_clean() as path:
  371:             df = DataFrame(
  372:                 np.random.default_rng(2).standard_normal((10, 2)), columns=list("AB")
  373:             )
  374:             df.to_stata(path)
  375: 
  376:     def test_write_preserves_original(self):
  377:         # 9795
  378: 
  379:         df = DataFrame(
  380:             np.random.default_rng(2).standard_normal((5, 4)), columns=list("abcd")
  381:         )
  382:         df.loc[2, "a":"c"] = np.nan
  383:         df_copy = df.copy()
  384:         with tm.ensure_clean() as path:
  385:             df.to_stata(path, write_index=False)
  386:         tm.assert_frame_equal(df, df_copy)
  387: 
  388:     @pytest.mark.parametrize("version", [114, 117, 118, 119, None])
  389:     def test_encoding(self, version, datapath):
  390:         # GH 4626, proper encoding handling
  391:         raw = read_stata(datapath("io", "data", "stata", "stata1_encoding.dta"))
  392:         encoded = read_stata(datapath("io", "data", "stata", "stata1_encoding.dta"))
  393:         result = encoded.kreis1849[0]
  394: 
  395:         expected = raw.kreis1849[0]
  396:         assert result == expected
  397:         assert isinstance(result, str)
  398: 
  399:         with tm.ensure_clean() as path:
  400:             encoded.to_stata(path, write_index=False, version=version)
  401:             reread_encoded = read_stata(path)
  402:             tm.assert_frame_equal(encoded, reread_encoded)
  403: 
  404:     def test_read_write_dta11(self):
  405:         original = DataFrame(
  406:             [(1, 2, 3, 4)],
  407:             columns=[
  408:                 "good",
  409:                 "b\u00E4d",
  410:                 "8number",
  411:                 "astringwithmorethan32characters______",
  412:             ],
  413:         )
  414:         formatted = DataFrame(
  415:             [(1, 2, 3, 4)],
  416:             columns=["good", "b_d", "_8number", "astringwithmorethan32characters_"],
  417:         )
  418:         formatted.index.name = "index"
  419:         formatted = formatted.astype(np.int32)
  420: 
  421:         with tm.ensure_clean() as path:
  422:             with tm.assert_produces_warning(InvalidColumnName):
  423:                 original.to_stata(path, convert_dates=None)
  424: 
  425:             written_and_read_again = self.read_dta(path)
  426: 
  427:         expected = formatted.copy()
  428:         expected.index = expected.index.astype(np.int32)
  429:         tm.assert_frame_equal(written_and_read_again.set_index("index"), expected)
  430: 
  431:     @pytest.mark.parametrize("version", [114, 117, 118, 119, None])
  432:     def test_read_write_dta12(self, version):
  433:         original = DataFrame(
  434:             [(1, 2, 3, 4, 5, 6)],
  435:             columns=[
  436:                 "astringwithmorethan32characters_1",
  437:                 "astringwithmorethan32characters_2",
  438:                 "+",
  439:                 "-",
  440:                 "short",
  441:                 "delete",
  442:             ],
  443:         )
  444:         formatted = DataFrame(
  445:             [(1, 2, 3, 4, 5, 6)],
  446:             columns=[
  447:                 "astringwithmorethan32characters_",
  448:                 "_0astringwithmorethan32character",
  449:                 "_",
  450:                 "_1_",
  451:                 "_short",
  452:                 "_delete",
  453:             ],
  454:         )
  455:         formatted.index.name = "index"
  456:         formatted = formatted.astype(np.int32)
  457: 
  458:         with tm.ensure_clean() as path:
  459:             with tm.assert_produces_warning(InvalidColumnName):
  460:                 original.to_stata(path, convert_dates=None, version=version)
  461:                 # should get a warning for that format.
  462: 
  463:             written_and_read_again = self.read_dta(path)
  464: 
  465:         expected = formatted.copy()
  466:         expected.index = expected.index.astype(np.int32)
  467:         tm.assert_frame_equal(written_and_read_again.set_index("index"), expected)
  468: 
  469:     def test_read_write_dta13(self):
  470:         s1 = Series(2**9, dtype=np.int16)
  471:         s2 = Series(2**17, dtype=np.int32)
  472:         s3 = Series(2**33, dtype=np.int64)
  473:         original = DataFrame({"int16": s1, "int32": s2, "int64": s3})
  474:         original.index.name = "index"
  475: 
  476:         formatted = original
  477:         formatted["int64"] = formatted["int64"].astype(np.float64)
  478: 
  479:         with tm.ensure_clean() as path:
  480:             original.to_stata(path)
  481:             written_and_read_again = self.read_dta(path)
  482: 
  483:         expected = formatted.copy()
  484:         expected.index = expected.index.astype(np.int32)
  485:         tm.assert_frame_equal(written_and_read_again.set_index("index"), expected)
  486: 
  487:     @pytest.mark.parametrize("version", [114, 117, 118, 119, None])
  488:     @pytest.mark.parametrize(
  489:         "file", ["stata5_113", "stata5_114", "stata5_115", "stata5_117"]
  490:     )
  491:     def test_read_write_reread_dta14(self, file, parsed_114, version, datapath):
  492:         file = datapath("io", "data", "stata", f"{file}.dta")
  493:         parsed = self.read_dta(file)
  494:         parsed.index.name = "index"
  495: 
  496:         tm.assert_frame_equal(parsed_114, parsed)
  497: 
  498:         with tm.ensure_clean() as path:
  499:             parsed_114.to_stata(path, convert_dates={"date_td": "td"}, version=version)
  500:             written_and_read_again = self.read_dta(path)
  501: 
  502:         expected = parsed_114.copy()
  503:         expected.index = expected.index.astype(np.int32)
  504:         tm.assert_frame_equal(written_and_read_again.set_index("index"), expected)
  505: 
  506:     @pytest.mark.parametrize(
  507:         "file", ["stata6_113", "stata6_114", "stata6_115", "stata6_117"]
  508:     )
  509:     def test_read_write_reread_dta15(self, file, datapath):
  510:         expected = self.read_csv(datapath("io", "data", "stata", "stata6.csv"))
  511:         expected["byte_"] = expected["byte_"].astype(np.int8)
  512:         expected["int_"] = expected["int_"].astype(np.int16)
  513:         expected["long_"] = expected["long_"].astype(np.int32)
  514:         expected["float_"] = expected["float_"].astype(np.float32)
  515:         expected["double_"] = expected["double_"].astype(np.float64)
  516:         expected["date_td"] = expected["date_td"].apply(
  517:             datetime.strptime, args=("%Y-%m-%d",)
  518:         )
  519: 
  520:         file = datapath("io", "data", "stata", f"{file}.dta")
  521:         parsed = self.read_dta(file)
  522: 
  523:         tm.assert_frame_equal(expected, parsed)
  524: 
  525:     @pytest.mark.parametrize("version", [114, 117, 118, 119, None])
  526:     def test_timestamp_and_label(self, version):
  527:         original = DataFrame([(1,)], columns=["variable"])
  528:         time_stamp = datetime(2000, 2, 29, 14, 21)
  529:         data_label = "This is a data file."
  530:         with tm.ensure_clean() as path:
  531:             original.to_stata(
  532:                 path, time_stamp=time_stamp, data_label=data_label, version=version
  533:             )
  534: 
  535:             with StataReader(path) as reader:
  536:                 assert reader.time_stamp == "29 Feb 2000 14:21"
  537:                 assert reader.data_label == data_label
  538: 
  539:     @pytest.mark.parametrize("version", [114, 117, 118, 119, None])
  540:     def test_invalid_timestamp(self, version):
  541:         original = DataFrame([(1,)], columns=["variable"])
  542:         time_stamp = "01 Jan 2000, 00:00:00"
  543:         with tm.ensure_clean() as path:
  544:             msg = "time_stamp should be datetime type"
  545:             with pytest.raises(ValueError, match=msg):
  546:                 original.to_stata(path, time_stamp=time_stamp, version=version)
  547:             assert not os.path.isfile(path)
  548: 
  549:     def test_numeric_column_names(self):
  550:         original = DataFrame(np.reshape(np.arange(25.0), (5, 5)))
  551:         original.index.name = "index"
  552:         with tm.ensure_clean() as path:
  553:             # should get a warning for that format.
  554:             with tm.assert_produces_warning(InvalidColumnName):
  555:                 original.to_stata(path)
  556: 
  557:             written_and_read_again = self.read_dta(path)
  558: 
  559:         written_and_read_again = written_and_read_again.set_index("index")
  560:         columns = list(written_and_read_again.columns)
  561:         convert_col_name = lambda x: int(x[1])
  562:         written_and_read_again.columns = map(convert_col_name, columns)
  563: 
  564:         expected = original.copy()
  565:         expected.index = expected.index.astype(np.int32)
  566:         tm.assert_frame_equal(expected, written_and_read_again)
  567: 
  568:     @pytest.mark.parametrize("version", [114, 117, 118, 119, None])
  569:     def test_nan_to_missing_value(self, version):
  570:         s1 = Series(np.arange(4.0), dtype=np.float32)
  571:         s2 = Series(np.arange(4.0), dtype=np.float64)
  572:         s1[::2] = np.nan
  573:         s2[1::2] = np.nan
  574:         original = DataFrame({"s1": s1, "s2": s2})
  575:         original.index.name = "index"
  576: 
  577:         with tm.ensure_clean() as path:
  578:             original.to_stata(path, version=version)
  579:             written_and_read_again = self.read_dta(path)
  580: 
  581:         written_and_read_again = written_and_read_again.set_index("index")
  582:         expected = original.copy()
  583:         expected.index = expected.index.astype(np.int32)
  584:         tm.assert_frame_equal(written_and_read_again, expected)
  585: 
  586:     def test_no_index(self):
  587:         columns = ["x", "y"]
  588:         original = DataFrame(np.reshape(np.arange(10.0), (5, 2)), columns=columns)
  589:         original.index.name = "index_not_written"
  590:         with tm.ensure_clean() as path:
  591:             original.to_stata(path, write_index=False)
  592:             written_and_read_again = self.read_dta(path)
  593:             with pytest.raises(KeyError, match=original.index.name):
  594:                 written_and_read_again["index_not_written"]
  595: 
  596:     def test_string_no_dates(self):
  597:         s1 = Series(["a", "A longer string"])
  598:         s2 = Series([1.0, 2.0], dtype=np.float64)
  599:         original = DataFrame({"s1": s1, "s2": s2})
  600:         original.index.name = "index"
  601:         with tm.ensure_clean() as path:
  602:             original.to_stata(path)
  603:             written_and_read_again = self.read_dta(path)
  604: 
  605:         expected = original.copy()
  606:         expected.index = expected.index.astype(np.int32)
  607:         tm.assert_frame_equal(written_and_read_again.set_index("index"), expected)
  608: 
  609:     def test_large_value_conversion(self):
  610:         s0 = Series([1, 99], dtype=np.int8)
  611:         s1 = Series([1, 127], dtype=np.int8)
  612:         s2 = Series([1, 2**15 - 1], dtype=np.int16)
  613:         s3 = Series([1, 2**63 - 1], dtype=np.int64)
  614:         original = DataFrame({"s0": s0, "s1": s1, "s2": s2, "s3": s3})
  615:         original.index.name = "index"
  616:         with tm.ensure_clean() as path:
  617:             with tm.assert_produces_warning(PossiblePrecisionLoss):
  618:                 original.to_stata(path)
  619: 
  620:             written_and_read_again = self.read_dta(path)
  621: 
  622:         modified = original.copy()
  623:         modified["s1"] = Series(modified["s1"], dtype=np.int16)
  624:         modified["s2"] = Series(modified["s2"], dtype=np.int32)
  625:         modified["s3"] = Series(modified["s3"], dtype=np.float64)
  626:         modified.index = original.index.astype(np.int32)
  627:         tm.assert_frame_equal(written_and_read_again.set_index("index"), modified)
  628: 
  629:     def test_dates_invalid_column(self):
  630:         original = DataFrame([datetime(2006, 11, 19, 23, 13, 20)])
  631:         original.index.name = "index"
  632:         with tm.ensure_clean() as path:
  633:             with tm.assert_produces_warning(InvalidColumnName):
  634:                 original.to_stata(path, convert_dates={0: "tc"})
  635: 
  636:             written_and_read_again = self.read_dta(path)
  637: 
  638:         modified = original.copy()
  639:         modified.columns = ["_0"]
  640:         modified.index = original.index.astype(np.int32)
  641:         tm.assert_frame_equal(written_and_read_again.set_index("index"), modified)
  642: 
  643:     def test_105(self, datapath):
  644:         # Data obtained from:
  645:         # http://go.worldbank.org/ZXY29PVJ21
  646:         dpath = datapath("io", "data", "stata", "S4_EDUC1.dta")
  647:         df = read_stata(dpath)
  648:         df0 = [[1, 1, 3, -2], [2, 1, 2, -2], [4, 1, 1, -2]]
  649:         df0 = DataFrame(df0)
  650:         df0.columns = ["clustnum", "pri_schl", "psch_num", "psch_dis"]
  651:         df0["clustnum"] = df0["clustnum"].astype(np.int16)
  652:         df0["pri_schl"] = df0["pri_schl"].astype(np.int8)
  653:         df0["psch_num"] = df0["psch_num"].astype(np.int8)
  654:         df0["psch_dis"] = df0["psch_dis"].astype(np.float32)
  655:         tm.assert_frame_equal(df.head(3), df0)
  656: 
  657:     def test_value_labels_old_format(self, datapath):
  658:         # GH 19417
  659:         #
  660:         # Test that value_labels() returns an empty dict if the file format
  661:         # predates supporting value labels.
  662:         dpath = datapath("io", "data", "stata", "S4_EDUC1.dta")
  663:         with StataReader(dpath) as reader:
  664:             assert reader.value_labels() == {}
  665: 
  666:     def test_date_export_formats(self):
  667:         columns = ["tc", "td", "tw", "tm", "tq", "th", "ty"]
  668:         conversions = {c: c for c in columns}
  669:         data = [datetime(2006, 11, 20, 23, 13, 20)] * len(columns)
  670:         original = DataFrame([data], columns=columns)
  671:         original.index.name = "index"
  672:         expected_values = [
  673:             datetime(2006, 11, 20, 23, 13, 20),  # Time
  674:             datetime(2006, 11, 20),  # Day
  675:             datetime(2006, 11, 19),  # Week
  676:             datetime(2006, 11, 1),  # Month
  677:             datetime(2006, 10, 1),  # Quarter year
  678:             datetime(2006, 7, 1),  # Half year
  679:             datetime(2006, 1, 1),
  680:         ]  # Year
  681: 
  682:         expected = DataFrame(
  683:             [expected_values],
  684:             index=pd.Index([0], dtype=np.int32, name="index"),
  685:             columns=columns,
  686:         )
  687: 
  688:         with tm.ensure_clean() as path:
  689:             original.to_stata(path, convert_dates=conversions)
  690:             written_and_read_again = self.read_dta(path)
  691: 
  692:         tm.assert_frame_equal(written_and_read_again.set_index("index"), expected)
  693: 
  694:     def test_write_missing_strings(self):
  695:         original = DataFrame([["1"], [None]], columns=["foo"])
  696: 
  697:         expected = DataFrame(
  698:             [["1"], [""]],
  699:             index=pd.Index([0, 1], dtype=np.int32, name="index"),
  700:             columns=["foo"],
  701:         )
  702: 
  703:         with tm.ensure_clean() as path:
  704:             original.to_stata(path)
  705:             written_and_read_again = self.read_dta(path)
  706: 
  707:         tm.assert_frame_equal(written_and_read_again.set_index("index"), expected)
  708: 
  709:     @pytest.mark.parametrize("version", [114, 117, 118, 119, None])
  710:     @pytest.mark.parametrize("byteorder", [">", "<"])
  711:     def test_bool_uint(self, byteorder, version):
  712:         s0 = Series([0, 1, True], dtype=np.bool_)
  713:         s1 = Series([0, 1, 100], dtype=np.uint8)
  714:         s2 = Series([0, 1, 255], dtype=np.uint8)
  715:         s3 = Series([0, 1, 2**15 - 100], dtype=np.uint16)
  716:         s4 = Series([0, 1, 2**16 - 1], dtype=np.uint16)
  717:         s5 = Series([0, 1, 2**31 - 100], dtype=np.uint32)
  718:         s6 = Series([0, 1, 2**32 - 1], dtype=np.uint32)
  719: 
  720:         original = DataFrame(
  721:             {"s0": s0, "s1": s1, "s2": s2, "s3": s3, "s4": s4, "s5": s5, "s6": s6}
  722:         )
  723:         original.index.name = "index"
  724:         expected = original.copy()
  725:         expected.index = original.index.astype(np.int32)
  726:         expected_types = (
  727:             np.int8,
  728:             np.int8,
  729:             np.int16,
  730:             np.int16,
  731:             np.int32,
  732:             np.int32,
  733:             np.float64,
  734:         )
  735:         for c, t in zip(expected.columns, expected_types):
  736:             expected[c] = expected[c].astype(t)
  737: 
  738:         with tm.ensure_clean() as path:
  739:             original.to_stata(path, byteorder=byteorder, version=version)
  740:             written_and_read_again = self.read_dta(path)
  741: 
  742:         written_and_read_again = written_and_read_again.set_index("index")
  743:         tm.assert_frame_equal(written_and_read_again, expected)
  744: 
  745:     def test_variable_labels(self, datapath):
  746:         with StataReader(datapath("io", "data", "stata", "stata7_115.dta")) as rdr:
  747:             sr_115 = rdr.variable_labels()
  748:         with StataReader(datapath("io", "data", "stata", "stata7_117.dta")) as rdr:
  749:             sr_117 = rdr.variable_labels()
  750:         keys = ("var1", "var2", "var3")
  751:         labels = ("label1", "label2", "label3")
  752:         for k, v in sr_115.items():
  753:             assert k in sr_117
  754:             assert v == sr_117[k]
  755:             assert k in keys
  756:             assert v in labels
  757: 
  758:     def test_minimal_size_col(self):
  759:         str_lens = (1, 100, 244)
  760:         s = {}
  761:         for str_len in str_lens:
  762:             s["s" + str(str_len)] = Series(
  763:                 ["a" * str_len, "b" * str_len, "c" * str_len]
  764:             )
  765:         original = DataFrame(s)
  766:         with tm.ensure_clean() as path:
  767:             original.to_stata(path, write_index=False)
  768: 
  769:             with StataReader(path) as sr:
  770:                 sr._ensure_open()  # The `_*list` variables are initialized here
  771:                 for variable, fmt, typ in zip(sr._varlist, sr._fmtlist, sr._typlist):
  772:                     assert int(variable[1:]) == int(fmt[1:-1])
  773:                     assert int(variable[1:]) == typ
  774: 
  775:     def test_excessively_long_string(self):
  776:         str_lens = (1, 244, 500)
  777:         s = {}
  778:         for str_len in str_lens:
  779:             s["s" + str(str_len)] = Series(
  780:                 ["a" * str_len, "b" * str_len, "c" * str_len]
  781:             )
  782:         original = DataFrame(s)
  783:         msg = (
  784:             r"Fixed width strings in Stata \.dta files are limited to 244 "
  785:             r"\(or fewer\)\ncharacters\.  Column 's500' does not satisfy "
  786:             r"this restriction\. Use the\n'version=117' parameter to write "
  787:             r"the newer \(Stata 13 and later\) format\."
  788:         )
  789:         with pytest.raises(ValueError, match=msg):
  790:             with tm.ensure_clean() as path:
  791:                 original.to_stata(path)
  792: 
  793:     def test_missing_value_generator(self):
  794:         types = ("b", "h", "l")
  795:         df = DataFrame([[0.0]], columns=["float_"])
  796:         with tm.ensure_clean() as path:
  797:             df.to_stata(path)
  798:             with StataReader(path) as rdr:
  799:                 valid_range = rdr.VALID_RANGE
  800:         expected_values = ["." + chr(97 + i) for i in range(26)]
  801:         expected_values.insert(0, ".")
  802:         for t in types:
  803:             offset = valid_range[t][1]
  804:             for i in range(27):
  805:                 val = StataMissingValue(offset + 1 + i)
  806:                 assert val.string == expected_values[i]
  807: 
  808:         # Test extremes for floats
  809:         val = StataMissingValue(struct.unpack("<f", b"\x00\x00\x00\x7f")[0])
  810:         assert val.string == "."
  811:         val = StataMissingValue(struct.unpack("<f", b"\x00\xd0\x00\x7f")[0])
  812:         assert val.string == ".z"
  813: 
  814:         # Test extremes for floats
  815:         val = StataMissingValue(
  816:             struct.unpack("<d", b"\x00\x00\x00\x00\x00\x00\xe0\x7f")[0]
  817:         )
  818:         assert val.string == "."
  819:         val = StataMissingValue(
  820:             struct.unpack("<d", b"\x00\x00\x00\x00\x00\x1a\xe0\x7f")[0]
  821:         )
  822:         assert val.string == ".z"
  823: 
  824:     @pytest.mark.parametrize("file", ["stata8_113", "stata8_115", "stata8_117"])
  825:     def test_missing_value_conversion(self, file, datapath):
  826:         columns = ["int8_", "int16_", "int32_", "float32_", "float64_"]
  827:         smv = StataMissingValue(101)
  828:         keys = sorted(smv.MISSING_VALUES.keys())
  829:         data = []
  830:         for i in range(27):
  831:             row = [StataMissingValue(keys[i + (j * 27)]) for j in range(5)]
  832:             data.append(row)
  833:         expected = DataFrame(data, columns=columns)
  834: 
  835:         parsed = read_stata(
  836:             datapath("io", "data", "stata", f"{file}.dta"), convert_missing=True
  837:         )
  838:         tm.assert_frame_equal(parsed, expected)
  839: 
  840:     def test_big_dates(self, datapath):
  841:         yr = [1960, 2000, 9999, 100, 2262, 1677]
  842:         mo = [1, 1, 12, 1, 4, 9]
  843:         dd = [1, 1, 31, 1, 22, 23]
  844:         hr = [0, 0, 23, 0, 0, 0]
  845:         mm = [0, 0, 59, 0, 0, 0]
  846:         ss = [0, 0, 59, 0, 0, 0]
  847:         expected = []
  848:         for year, month, day, hour, minute, second in zip(yr, mo, dd, hr, mm, ss):
  849:             row = []
  850:             for j in range(7):
  851:                 if j == 0:
  852:                     row.append(datetime(year, month, day, hour, minute, second))
  853:                 elif j == 6:
  854:                     row.append(datetime(year, 1, 1))
  855:                 else:
  856:                     row.append(datetime(year, month, day))
  857:             expected.append(row)
  858:         expected.append([pd.NaT] * 7)
  859:         columns = [
  860:             "date_tc",
  861:             "date_td",
  862:             "date_tw",
  863:             "date_tm",
  864:             "date_tq",
  865:             "date_th",
  866:             "date_ty",
  867:         ]
  868: 
  869:         # Fixes for weekly, quarterly,half,year
  870:         expected[2][2] = datetime(9999, 12, 24)
  871:         expected[2][3] = datetime(9999, 12, 1)
  872:         expected[2][4] = datetime(9999, 10, 1)
  873:         expected[2][5] = datetime(9999, 7, 1)
  874:         expected[4][2] = datetime(2262, 4, 16)
  875:         expected[4][3] = expected[4][4] = datetime(2262, 4, 1)
  876:         expected[4][5] = expected[4][6] = datetime(2262, 1, 1)
  877:         expected[5][2] = expected[5][3] = expected[5][4] = datetime(1677, 10, 1)
  878:         expected[5][5] = expected[5][6] = datetime(1678, 1, 1)
  879: 
  880:         expected = DataFrame(expected, columns=columns, dtype=object)
  881:         parsed_115 = read_stata(datapath("io", "data", "stata", "stata9_115.dta"))
  882:         parsed_117 = read_stata(datapath("io", "data", "stata", "stata9_117.dta"))
  883:         tm.assert_frame_equal(expected, parsed_115, check_datetimelike_compat=True)
  884:         tm.assert_frame_equal(expected, parsed_117, check_datetimelike_compat=True)
  885: 
  886:         date_conversion = {c: c[-2:] for c in columns}
  887:         # {c : c[-2:] for c in columns}
  888:         with tm.ensure_clean() as path:
  889:             expected.index.name = "index"
  890:             expected.to_stata(path, convert_dates=date_conversion)
  891:             written_and_read_again = self.read_dta(path)
  892: 
  893:         tm.assert_frame_equal(
  894:             written_and_read_again.set_index("index"),
  895:             expected.set_index(expected.index.astype(np.int32)),
  896:             check_datetimelike_compat=True,
  897:         )
  898: 
  899:     def test_dtype_conversion(self, datapath):
  900:         expected = self.read_csv(datapath("io", "data", "stata", "stata6.csv"))
  901:         expected["byte_"] = expected["byte_"].astype(np.int8)
  902:         expected["int_"] = expected["int_"].astype(np.int16)
  903:         expected["long_"] = expected["long_"].astype(np.int32)
  904:         expected["float_"] = expected["float_"].astype(np.float32)
  905:         expected["double_"] = expected["double_"].astype(np.float64)
  906:         expected["date_td"] = expected["date_td"].apply(
  907:             datetime.strptime, args=("%Y-%m-%d",)
  908:         )
  909: 
  910:         no_conversion = read_stata(
  911:             datapath("io", "data", "stata", "stata6_117.dta"), convert_dates=True
  912:         )
  913:         tm.assert_frame_equal(expected, no_conversion)
  914: 
  915:         conversion = read_stata(
  916:             datapath("io", "data", "stata", "stata6_117.dta"),
  917:             convert_dates=True,
  918:             preserve_dtypes=False,
  919:         )
  920: 
  921:         # read_csv types are the same
  922:         expected = self.read_csv(datapath("io", "data", "stata", "stata6.csv"))
  923:         expected["date_td"] = expected["date_td"].apply(
  924:             datetime.strptime, args=("%Y-%m-%d",)
  925:         )
  926: 
  927:         tm.assert_frame_equal(expected, conversion)
  928: 
  929:     def test_drop_column(self, datapath):
  930:         expected = self.read_csv(datapath("io", "data", "stata", "stata6.csv"))
  931:         expected["byte_"] = expected["byte_"].astype(np.int8)
  932:         expected["int_"] = expected["int_"].astype(np.int16)
  933:         expected["long_"] = expected["long_"].astype(np.int32)
  934:         expected["float_"] = expected["float_"].astype(np.float32)
  935:         expected["double_"] = expected["double_"].astype(np.float64)
  936:         expected["date_td"] = expected["date_td"].apply(
  937:             datetime.strptime, args=("%Y-%m-%d",)
  938:         )
  939: 
  940:         columns = ["byte_", "int_", "long_"]
  941:         expected = expected[columns]
  942:         dropped = read_stata(
  943:             datapath("io", "data", "stata", "stata6_117.dta"),
  944:             convert_dates=True,
  945:             columns=columns,
  946:         )
  947: 
  948:         tm.assert_frame_equal(expected, dropped)
  949: 
  950:         # See PR 10757
  951:         columns = ["int_", "long_", "byte_"]
  952:         expected = expected[columns]
  953:         reordered = read_stata(
  954:             datapath("io", "data", "stata", "stata6_117.dta"),
  955:             convert_dates=True,
  956:             columns=columns,
  957:         )
  958:         tm.assert_frame_equal(expected, reordered)
  959: 
  960:         msg = "columns contains duplicate entries"
  961:         with pytest.raises(ValueError, match=msg):
  962:             columns = ["byte_", "byte_"]
  963:             read_stata(
  964:                 datapath("io", "data", "stata", "stata6_117.dta"),
  965:                 convert_dates=True,
  966:                 columns=columns,
  967:             )
  968: 
  969:         msg = "The following columns were not found in the Stata data set: not_found"
  970:         with pytest.raises(ValueError, match=msg):
  971:             columns = ["byte_", "int_", "long_", "not_found"]
  972:             read_stata(
  973:                 datapath("io", "data", "stata", "stata6_117.dta"),
  974:                 convert_dates=True,
  975:                 columns=columns,
  976:             )
  977: 
  978:     @pytest.mark.parametrize("version", [114, 117, 118, 119, None])
  979:     @pytest.mark.filterwarnings(
  980:         "ignore:\\nStata value:pandas.io.stata.ValueLabelTypeMismatch"
  981:     )
  982:     def test_categorical_writing(self, version):
  983:         original = DataFrame.from_records(
  984:             [
  985:                 ["one", "ten", "one", "one", "one", 1],
  986:                 ["two", "nine", "two", "two", "two", 2],
  987:                 ["three", "eight", "three", "three", "three", 3],
  988:                 ["four", "seven", 4, "four", "four", 4],
  989:                 ["five", "six", 5, np.nan, "five", 5],
  990:                 ["six", "five", 6, np.nan, "six", 6],
  991:                 ["seven", "four", 7, np.nan, "seven", 7],
  992:                 ["eight", "three", 8, np.nan, "eight", 8],
  993:                 ["nine", "two", 9, np.nan, "nine", 9],
  994:                 ["ten", "one", "ten", np.nan, "ten", 10],
  995:             ],
  996:             columns=[
  997:                 "fully_labeled",
  998:                 "fully_labeled2",
  999:                 "incompletely_labeled",
 1000:                 "labeled_with_missings",
 1001:                 "float_labelled",
 1002:                 "unlabeled",
 1003:             ],
 1004:         )
 1005:         expected = original.copy()
 1006: 
 1007:         # these are all categoricals
 1008:         original = pd.concat(
 1009:             [original[col].astype("category") for col in original], axis=1
 1010:         )
 1011:         expected.index = expected.index.set_names("index").astype(np.int32)
 1012: 
 1013:         expected["incompletely_labeled"] = expected["incompletely_labeled"].apply(str)
 1014:         expected["unlabeled"] = expected["unlabeled"].apply(str)
 1015:         for col in expected:
 1016:             orig = expected[col].copy()
 1017: 
 1018:             cat = orig.astype("category")._values
 1019:             cat = cat.as_ordered()
 1020:             if col == "unlabeled":
 1021:                 cat = cat.set_categories(orig, ordered=True)
 1022: 
 1023:             cat.categories.rename(None, inplace=True)
 1024: 
 1025:             expected[col] = cat
 1026: 
 1027:         with tm.ensure_clean() as path:
 1028:             original.to_stata(path, version=version)
 1029:             written_and_read_again = self.read_dta(path)
 1030: 
 1031:         res = written_and_read_again.set_index("index")
 1032:         tm.assert_frame_equal(res, expected)
 1033: 
 1034:     def test_categorical_warnings_and_errors(self):
 1035:         # Warning for non-string labels
 1036:         # Error for labels too long
 1037:         original = DataFrame.from_records(
 1038:             [["a" * 10000], ["b" * 10000], ["c" * 10000], ["d" * 10000]],
 1039:             columns=["Too_long"],
 1040:         )
 1041: 
 1042:         original = pd.concat(
 1043:             [original[col].astype("category") for col in original], axis=1
 1044:         )
 1045:         with tm.ensure_clean() as path:
 1046:             msg = (
 1047:                 "Stata value labels for a single variable must have "
 1048:                 r"a combined length less than 32,000 characters\."
 1049:             )
 1050:             with pytest.raises(ValueError, match=msg):
 1051:                 original.to_stata(path)
 1052: 
 1053:         original = DataFrame.from_records(
 1054:             [["a"], ["b"], ["c"], ["d"], [1]], columns=["Too_long"]
 1055:         )
 1056:         original = pd.concat(
 1057:             [original[col].astype("category") for col in original], axis=1
 1058:         )
 1059: 
 1060:         with tm.assert_produces_warning(ValueLabelTypeMismatch):
 1061:             original.to_stata(path)
 1062:             # should get a warning for mixed content
 1063: 
 1064:     @pytest.mark.parametrize("version", [114, 117, 118, 119, None])
 1065:     def test_categorical_with_stata_missing_values(self, version):
 1066:         values = [["a" + str(i)] for i in range(120)]
 1067:         values.append([np.nan])
 1068:         original = DataFrame.from_records(values, columns=["many_labels"])
 1069:         original = pd.concat(
 1070:             [original[col].astype("category") for col in original], axis=1
 1071:         )
 1072:         original.index.name = "index"
 1073:         with tm.ensure_clean() as path:
 1074:             original.to_stata(path, version=version)
 1075:             written_and_read_again = self.read_dta(path)
 1076: 
 1077:         res = written_and_read_again.set_index("index")
 1078: 
 1079:         expected = original.copy()
 1080:         for col in expected:
 1081:             cat = expected[col]._values
 1082:             new_cats = cat.remove_unused_categories().categories
 1083:             cat = cat.set_categories(new_cats, ordered=True)
 1084:             expected[col] = cat
 1085:         expected.index = expected.index.astype(np.int32)
 1086:         tm.assert_frame_equal(res, expected)
 1087: 
 1088:     @pytest.mark.parametrize("file", ["stata10_115", "stata10_117"])
 1089:     def test_categorical_order(self, file, datapath):
 1090:         # Directly construct using expected codes
 1091:         # Format is is_cat, col_name, labels (in order), underlying data
 1092:         expected = [
 1093:             (True, "ordered", ["a", "b", "c", "d", "e"], np.arange(5)),
 1094:             (True, "reverse", ["a", "b", "c", "d", "e"], np.arange(5)[::-1]),
 1095:             (True, "noorder", ["a", "b", "c", "d", "e"], np.array([2, 1, 4, 0, 3])),
 1096:             (True, "floating", ["a", "b", "c", "d", "e"], np.arange(0, 5)),
 1097:             (True, "float_missing", ["a", "d", "e"], np.array([0, 1, 2, -1, -1])),
 1098:             (False, "nolabel", [1.0, 2.0, 3.0, 4.0, 5.0], np.arange(5)),
 1099:             (True, "int32_mixed", ["d", 2, "e", "b", "a"], np.arange(5)),
 1100:         ]
 1101:         cols = []
 1102:         for is_cat, col, labels, codes in expected:
 1103:             if is_cat:
 1104:                 cols.append(
 1105:                     (col, pd.Categorical.from_codes(codes, labels, ordered=True))
 1106:                 )
 1107:             else:
 1108:                 cols.append((col, Series(labels, dtype=np.float32)))
 1109:         expected = DataFrame.from_dict(dict(cols))
 1110: 
 1111:         # Read with and with out categoricals, ensure order is identical
 1112:         file = datapath("io", "data", "stata", f"{file}.dta")
 1113:         parsed = read_stata(file)
 1114:         tm.assert_frame_equal(expected, parsed)
 1115: 
 1116:         # Check identity of codes
 1117:         for col in expected:
 1118:             if isinstance(expected[col].dtype, CategoricalDtype):
 1119:                 tm.assert_series_equal(expected[col].cat.codes, parsed[col].cat.codes)
 1120:                 tm.assert_index_equal(
 1121:                     expected[col].cat.categories, parsed[col].cat.categories
 1122:                 )
 1123: 
 1124:     @pytest.mark.parametrize("file", ["stata11_115", "stata11_117"])
 1125:     def test_categorical_sorting(self, file, datapath):
 1126:         parsed = read_stata(datapath("io", "data", "stata", f"{file}.dta"))
 1127: 
 1128:         # Sort based on codes, not strings
 1129:         parsed = parsed.sort_values("srh", na_position="first")
 1130: 
 1131:         # Don't sort index
 1132:         parsed.index = pd.RangeIndex(len(parsed))
 1133:         codes = [-1, -1, 0, 1, 1, 1, 2, 2, 3, 4]
 1134:         categories = ["Poor", "Fair", "Good", "Very good", "Excellent"]
 1135:         cat = pd.Categorical.from_codes(
 1136:             codes=codes, categories=categories, ordered=True
 1137:         )
 1138:         expected = Series(cat, name="srh")
 1139:         tm.assert_series_equal(expected, parsed["srh"])
 1140: 
 1141:     @pytest.mark.parametrize("file", ["stata10_115", "stata10_117"])
 1142:     def test_categorical_ordering(self, file, datapath):
 1143:         file = datapath("io", "data", "stata", f"{file}.dta")
 1144:         parsed = read_stata(file)
 1145: 
 1146:         parsed_unordered = read_stata(file, order_categoricals=False)
 1147:         for col in parsed:
 1148:             if not isinstance(parsed[col].dtype, CategoricalDtype):
 1149:                 continue
 1150:             assert parsed[col].cat.ordered
 1151:             assert not parsed_unordered[col].cat.ordered
 1152: 
 1153:     @pytest.mark.filterwarnings("ignore::UserWarning")
 1154:     @pytest.mark.parametrize(
 1155:         "file",
 1156:         [
 1157:             "stata1_117",
 1158:             "stata2_117",
 1159:             "stata3_117",
 1160:             "stata4_117",
 1161:             "stata5_117",
 1162:             "stata6_117",
 1163:             "stata7_117",
 1164:             "stata8_117",
 1165:             "stata9_117",
 1166:             "stata10_117",
 1167:             "stata11_117",
 1168:         ],
 1169:     )
 1170:     @pytest.mark.parametrize("chunksize", [1, 2])
 1171:     @pytest.mark.parametrize("convert_categoricals", [False, True])
 1172:     @pytest.mark.parametrize("convert_dates", [False, True])
 1173:     def test_read_chunks_117(
 1174:         self, file, chunksize, convert_categoricals, convert_dates, datapath
 1175:     ):
 1176:         fname = datapath("io", "data", "stata", f"{file}.dta")
 1177: 
 1178:         parsed = read_stata(
 1179:             fname,
 1180:             convert_categoricals=convert_categoricals,
 1181:             convert_dates=convert_dates,
 1182:         )
 1183:         with read_stata(
 1184:             fname,
 1185:             iterator=True,
 1186:             convert_categoricals=convert_categoricals,
 1187:             convert_dates=convert_dates,
 1188:         ) as itr:
 1189:             pos = 0
 1190:             for j in range(5):
 1191:                 try:
 1192:                     chunk = itr.read(chunksize)
 1193:                 except StopIteration:
 1194:                     break
 1195:                 from_frame = parsed.iloc[pos : pos + chunksize, :].copy()
 1196:                 from_frame = self._convert_categorical(from_frame)
 1197:                 tm.assert_frame_equal(
 1198:                     from_frame, chunk, check_dtype=False, check_datetimelike_compat=True
 1199:                 )
 1200:                 pos += chunksize
 1201: 
 1202:     @staticmethod
 1203:     def _convert_categorical(from_frame: DataFrame) -> DataFrame:
 1204:         """
 1205:         Emulate the categorical casting behavior we expect from roundtripping.
 1206:         """
 1207:         for col in from_frame:
 1208:             ser = from_frame[col]
 1209:             if isinstance(ser.dtype, CategoricalDtype):
 1210:                 cat = ser._values.remove_unused_categories()
 1211:                 if cat.categories.dtype == object:
 1212:                     categories = pd.Index._with_infer(cat.categories._values)
 1213:                     cat = cat.set_categories(categories)
 1214:                 from_frame[col] = cat
 1215:         return from_frame
 1216: 
 1217:     def test_iterator(self, datapath):
 1218:         fname = datapath("io", "data", "stata", "stata3_117.dta")
 1219: 
 1220:         parsed = read_stata(fname)
 1221: 
 1222:         with read_stata(fname, iterator=True) as itr:
 1223:             chunk = itr.read(5)
 1224:             tm.assert_frame_equal(parsed.iloc[0:5, :], chunk)
 1225: 
 1226:         with read_stata(fname, chunksize=5) as itr:
 1227:             chunk = list(itr)
 1228:             tm.assert_frame_equal(parsed.iloc[0:5, :], chunk[0])
 1229: 
 1230:         with read_stata(fname, iterator=True) as itr:
 1231:             chunk = itr.get_chunk(5)
 1232:             tm.assert_frame_equal(parsed.iloc[0:5, :], chunk)
 1233: 
 1234:         with read_stata(fname, chunksize=5) as itr:
 1235:             chunk = itr.get_chunk()
 1236:             tm.assert_frame_equal(parsed.iloc[0:5, :], chunk)
 1237: 
 1238:         # GH12153
 1239:         with read_stata(fname, chunksize=4) as itr:
 1240:             from_chunks = pd.concat(itr)
 1241:         tm.assert_frame_equal(parsed, from_chunks)
 1242: 
 1243:     @pytest.mark.filterwarnings("ignore::UserWarning")
 1244:     @pytest.mark.parametrize(
 1245:         "file",
 1246:         [
 1247:             "stata2_115",
 1248:             "stata3_115",
 1249:             "stata4_115",
 1250:             "stata5_115",
 1251:             "stata6_115",
 1252:             "stata7_115",
 1253:             "stata8_115",
 1254:             "stata9_115",
 1255:             "stata10_115",
 1256:             "stata11_115",
 1257:         ],
 1258:     )
 1259:     @pytest.mark.parametrize("chunksize", [1, 2])
 1260:     @pytest.mark.parametrize("convert_categoricals", [False, True])
 1261:     @pytest.mark.parametrize("convert_dates", [False, True])
 1262:     def test_read_chunks_115(
 1263:         self, file, chunksize, convert_categoricals, convert_dates, datapath
 1264:     ):
 1265:         fname = datapath("io", "data", "stata", f"{file}.dta")
 1266: 
 1267:         # Read the whole file
 1268:         parsed = read_stata(
 1269:             fname,
 1270:             convert_categoricals=convert_categoricals,
 1271:             convert_dates=convert_dates,
 1272:         )
 1273: 
 1274:         # Compare to what we get when reading by chunk
 1275:         with read_stata(
 1276:             fname,
 1277:             iterator=True,
 1278:             convert_dates=convert_dates,
 1279:             convert_categoricals=convert_categoricals,
 1280:         ) as itr:
 1281:             pos = 0
 1282:             for j in range(5):
 1283:                 try:
 1284:                     chunk = itr.read(chunksize)
 1285:                 except StopIteration:
 1286:                     break
 1287:                 from_frame = parsed.iloc[pos : pos + chunksize, :].copy()
 1288:                 from_frame = self._convert_categorical(from_frame)
 1289:                 tm.assert_frame_equal(
 1290:                     from_frame, chunk, check_dtype=False, check_datetimelike_compat=True
 1291:                 )
 1292:                 pos += chunksize
 1293: 
 1294:     def test_read_chunks_columns(self, datapath):
 1295:         fname = datapath("io", "data", "stata", "stata3_117.dta")
 1296:         columns = ["quarter", "cpi", "m1"]
 1297:         chunksize = 2
 1298: 
 1299:         parsed = read_stata(fname, columns=columns)
 1300:         with read_stata(fname, iterator=True) as itr:
 1301:             pos = 0
 1302:             for j in range(5):
 1303:                 chunk = itr.read(chunksize, columns=columns)
 1304:                 if chunk is None:
 1305:                     break
 1306:                 from_frame = parsed.iloc[pos : pos + chunksize, :]
 1307:                 tm.assert_frame_equal(from_frame, chunk, check_dtype=False)
 1308:                 pos += chunksize
 1309: 
 1310:     @pytest.mark.parametrize("version", [114, 117, 118, 119, None])
 1311:     def test_write_variable_labels(self, version, mixed_frame):
 1312:         # GH 13631, add support for writing variable labels
 1313:         mixed_frame.index.name = "index"
 1314:         variable_labels = {"a": "City Rank", "b": "City Exponent", "c": "City"}
 1315:         with tm.ensure_clean() as path:
 1316:             mixed_frame.to_stata(path, variable_labels=variable_labels, version=version)
 1317:             with StataReader(path) as sr:
 1318:                 read_labels = sr.variable_labels()
 1319:             expected_labels = {
 1320:                 "index": "",
 1321:                 "a": "City Rank",
 1322:                 "b": "City Exponent",
 1323:                 "c": "City",
 1324:             }
 1325:             assert read_labels == expected_labels
 1326: 
 1327:         variable_labels["index"] = "The Index"
 1328:         with tm.ensure_clean() as path:
 1329:             mixed_frame.to_stata(path, variable_labels=variable_labels, version=version)
 1330:             with StataReader(path) as sr:
 1331:                 read_labels = sr.variable_labels()
 1332:             assert read_labels == variable_labels
 1333: 
 1334:     @pytest.mark.parametrize("version", [114, 117, 118, 119, None])
 1335:     def test_invalid_variable_labels(self, version, mixed_frame):
 1336:         mixed_frame.index.name = "index"
 1337:         variable_labels = {"a": "very long" * 10, "b": "City Exponent", "c": "City"}
 1338:         with tm.ensure_clean() as path:
 1339:             msg = "Variable labels must be 80 characters or fewer"
 1340:             with pytest.raises(ValueError, match=msg):
 1341:                 mixed_frame.to_stata(
 1342:                     path, variable_labels=variable_labels, version=version
 1343:                 )
 1344: 
 1345:     @pytest.mark.parametrize("version", [114, 117])
 1346:     def test_invalid_variable_label_encoding(self, version, mixed_frame):
 1347:         mixed_frame.index.name = "index"
 1348:         variable_labels = {"a": "very long" * 10, "b": "City Exponent", "c": "City"}
 1349:         variable_labels["a"] = "invalid character Е’"
 1350:         with tm.ensure_clean() as path:
 1351:             with pytest.raises(
 1352:                 ValueError, match="Variable labels must contain only characters"
 1353:             ):
 1354:                 mixed_frame.to_stata(
 1355:                     path, variable_labels=variable_labels, version=version
 1356:                 )
 1357: 
 1358:     def test_write_variable_label_errors(self, mixed_frame):
 1359:         values = ["\u03A1", "\u0391", "\u039D", "\u0394", "\u0391", "\u03A3"]
 1360: 
 1361:         variable_labels_utf8 = {
 1362:             "a": "City Rank",
 1363:             "b": "City Exponent",
 1364:             "c": "".join(values),
 1365:         }
 1366: 
 1367:         msg = (
 1368:             "Variable labels must contain only characters that can be "
 1369:             "encoded in Latin-1"
 1370:         )
 1371:         with pytest.raises(ValueError, match=msg):
 1372:             with tm.ensure_clean() as path:
 1373:                 mixed_frame.to_stata(path, variable_labels=variable_labels_utf8)
 1374: 
 1375:         variable_labels_long = {
 1376:             "a": "City Rank",
 1377:             "b": "City Exponent",
 1378:             "c": "A very, very, very long variable label "
 1379:             "that is too long for Stata which means "
 1380:             "that it has more than 80 characters",
 1381:         }
 1382: 
 1383:         msg = "Variable labels must be 80 characters or fewer"
 1384:         with pytest.raises(ValueError, match=msg):
 1385:             with tm.ensure_clean() as path:
 1386:                 mixed_frame.to_stata(path, variable_labels=variable_labels_long)
 1387: 
 1388:     def test_default_date_conversion(self):
 1389:         # GH 12259
 1390:         dates = [
 1391:             dt.datetime(1999, 12, 31, 12, 12, 12, 12000),
 1392:             dt.datetime(2012, 12, 21, 12, 21, 12, 21000),
 1393:             dt.datetime(1776, 7, 4, 7, 4, 7, 4000),
 1394:         ]
 1395:         original = DataFrame(
 1396:             {
 1397:                 "nums": [1.0, 2.0, 3.0],
 1398:                 "strs": ["apple", "banana", "cherry"],
 1399:                 "dates": dates,
 1400:             }
 1401:         )
 1402: 
 1403:         with tm.ensure_clean() as path:
 1404:             original.to_stata(path, write_index=False)
 1405:             reread = read_stata(path, convert_dates=True)
 1406:             tm.assert_frame_equal(original, reread)
 1407: 
 1408:             original.to_stata(path, write_index=False, convert_dates={"dates": "tc"})
 1409:             direct = read_stata(path, convert_dates=True)
 1410:             tm.assert_frame_equal(reread, direct)
 1411: 
 1412:             dates_idx = original.columns.tolist().index("dates")
 1413:             original.to_stata(path, write_index=False, convert_dates={dates_idx: "tc"})
 1414:             direct = read_stata(path, convert_dates=True)
 1415:             tm.assert_frame_equal(reread, direct)
 1416: 
 1417:     def test_unsupported_type(self):
 1418:         original = DataFrame({"a": [1 + 2j, 2 + 4j]})
 1419: 
 1420:         msg = "Data type complex128 not supported"
 1421:         with pytest.raises(NotImplementedError, match=msg):
 1422:             with tm.ensure_clean() as path:
 1423:                 original.to_stata(path)
 1424: 
 1425:     def test_unsupported_datetype(self):
 1426:         dates = [
 1427:             dt.datetime(1999, 12, 31, 12, 12, 12, 12000),
 1428:             dt.datetime(2012, 12, 21, 12, 21, 12, 21000),
 1429:             dt.datetime(1776, 7, 4, 7, 4, 7, 4000),
 1430:         ]
 1431:         original = DataFrame(
 1432:             {
 1433:                 "nums": [1.0, 2.0, 3.0],
 1434:                 "strs": ["apple", "banana", "cherry"],
 1435:                 "dates": dates,
 1436:             }
 1437:         )
 1438: 
 1439:         msg = "Format %tC not implemented"
 1440:         with pytest.raises(NotImplementedError, match=msg):
 1441:             with tm.ensure_clean() as path:
 1442:                 original.to_stata(path, convert_dates={"dates": "tC"})
 1443: 
 1444:         dates = pd.date_range("1-1-1990", periods=3, tz="Asia/Hong_Kong")
 1445:         original = DataFrame(
 1446:             {
 1447:                 "nums": [1.0, 2.0, 3.0],
 1448:                 "strs": ["apple", "banana", "cherry"],
 1449:                 "dates": dates,
 1450:             }
 1451:         )
 1452:         with pytest.raises(NotImplementedError, match="Data type datetime64"):
 1453:             with tm.ensure_clean() as path:
 1454:                 original.to_stata(path)
 1455: 
 1456:     def test_repeated_column_labels(self, datapath):
 1457:         # GH 13923, 25772
 1458:         msg = """
 1459: Value labels for column ethnicsn are not unique. These cannot be converted to
 1460: pandas categoricals.
 1461: 
 1462: Either read the file with `convert_categoricals` set to False or use the
 1463: low level interface in `StataReader` to separately read the values and the
 1464: value_labels.
 1465: 
 1466: The repeated labels are:\n-+\nwolof
 1467: """
 1468:         with pytest.raises(ValueError, match=msg):
 1469:             read_stata(
 1470:                 datapath("io", "data", "stata", "stata15.dta"),
 1471:                 convert_categoricals=True,
 1472:             )
 1473: 
 1474:     def test_stata_111(self, datapath):
 1475:         # 111 is an old version but still used by current versions of
 1476:         # SAS when exporting to Stata format. We do not know of any
 1477:         # on-line documentation for this version.
 1478:         df = read_stata(datapath("io", "data", "stata", "stata7_111.dta"))
 1479:         original = DataFrame(
 1480:             {
 1481:                 "y": [1, 1, 1, 1, 1, 0, 0, np.nan, 0, 0],
 1482:                 "x": [1, 2, 1, 3, np.nan, 4, 3, 5, 1, 6],
 1483:                 "w": [2, np.nan, 5, 2, 4, 4, 3, 1, 2, 3],
 1484:                 "z": ["a", "b", "c", "d", "e", "", "g", "h", "i", "j"],
 1485:             }
 1486:         )
 1487:         original = original[["y", "x", "w", "z"]]
 1488:         tm.assert_frame_equal(original, df)
 1489: 
 1490:     def test_out_of_range_double(self):
 1491:         # GH 14618
 1492:         df = DataFrame(
 1493:             {
 1494:                 "ColumnOk": [0.0, np.finfo(np.double).eps, 4.49423283715579e307],
 1495:                 "ColumnTooBig": [0.0, np.finfo(np.double).eps, np.finfo(np.double).max],
 1496:             }
 1497:         )
 1498:         msg = (
 1499:             r"Column ColumnTooBig has a maximum value \(.+\) outside the range "
 1500:             r"supported by Stata \(.+\)"
 1501:         )
 1502:         with pytest.raises(ValueError, match=msg):
 1503:             with tm.ensure_clean() as path:
 1504:                 df.to_stata(path)
 1505: 
 1506:     def test_out_of_range_float(self):
 1507:         original = DataFrame(
 1508:             {
 1509:                 "ColumnOk": [
 1510:                     0.0,
 1511:                     np.finfo(np.float32).eps,
 1512:                     np.finfo(np.float32).max / 10.0,
 1513:                 ],
 1514:                 "ColumnTooBig": [
 1515:                     0.0,
 1516:                     np.finfo(np.float32).eps,
 1517:                     np.finfo(np.float32).max,
 1518:                 ],
 1519:             }
 1520:         )
 1521:         original.index.name = "index"
 1522:         for col in original:
 1523:             original[col] = original[col].astype(np.float32)
 1524: 
 1525:         with tm.ensure_clean() as path:
 1526:             original.to_stata(path)
 1527:             reread = read_stata(path)
 1528: 
 1529:         original["ColumnTooBig"] = original["ColumnTooBig"].astype(np.float64)
 1530:         expected = original.copy()
 1531:         expected.index = expected.index.astype(np.int32)
 1532:         tm.assert_frame_equal(reread.set_index("index"), expected)
 1533: 
 1534:     @pytest.mark.parametrize("infval", [np.inf, -np.inf])
 1535:     def test_inf(self, infval):
 1536:         # GH 45350
 1537:         df = DataFrame({"WithoutInf": [0.0, 1.0], "WithInf": [2.0, infval]})
 1538:         msg = (
 1539:             "Column WithInf contains infinity or -infinity"
 1540:             "which is outside the range supported by Stata."
 1541:         )
 1542:         with pytest.raises(ValueError, match=msg):
 1543:             with tm.ensure_clean() as path:
 1544:                 df.to_stata(path)
 1545: 
 1546:     def test_path_pathlib(self):
 1547:         df = DataFrame(
 1548:             1.1 * np.arange(120).reshape((30, 4)),
 1549:             columns=pd.Index(list("ABCD"), dtype=object),
 1550:             index=pd.Index([f"i-{i}" for i in range(30)], dtype=object),
 1551:         )
 1552:         df.index.name = "index"
 1553:         reader = lambda x: read_stata(x).set_index("index")
 1554:         result = tm.round_trip_pathlib(df.to_stata, reader)
 1555:         tm.assert_frame_equal(df, result)
 1556: 
 1557:     def test_pickle_path_localpath(self):
 1558:         df = DataFrame(
 1559:             1.1 * np.arange(120).reshape((30, 4)),
 1560:             columns=pd.Index(list("ABCD"), dtype=object),
 1561:             index=pd.Index([f"i-{i}" for i in range(30)], dtype=object),
 1562:         )
 1563:         df.index.name = "index"
 1564:         reader = lambda x: read_stata(x).set_index("index")
 1565:         result = tm.round_trip_localpath(df.to_stata, reader)
 1566:         tm.assert_frame_equal(df, result)
 1567: 
 1568:     @pytest.mark.parametrize("write_index", [True, False])
 1569:     def test_value_labels_iterator(self, write_index):
 1570:         # GH 16923
 1571:         d = {"A": ["B", "E", "C", "A", "E"]}
 1572:         df = DataFrame(data=d)
 1573:         df["A"] = df["A"].astype("category")
 1574:         with tm.ensure_clean() as path:
 1575:             df.to_stata(path, write_index=write_index)
 1576: 
 1577:             with read_stata(path, iterator=True) as dta_iter:
 1578:                 value_labels = dta_iter.value_labels()
 1579:         assert value_labels == {"A": {0: "A", 1: "B", 2: "C", 3: "E"}}
 1580: 
 1581:     def test_set_index(self):
 1582:         # GH 17328
 1583:         df = DataFrame(
 1584:             1.1 * np.arange(120).reshape((30, 4)),
 1585:             columns=pd.Index(list("ABCD"), dtype=object),
 1586:             index=pd.Index([f"i-{i}" for i in range(30)], dtype=object),
 1587:         )
 1588:         df.index.name = "index"
 1589:         with tm.ensure_clean() as path:
 1590:             df.to_stata(path)
 1591:             reread = read_stata(path, index_col="index")
 1592:         tm.assert_frame_equal(df, reread)
 1593: 
 1594:     @pytest.mark.parametrize(
 1595:         "column", ["ms", "day", "week", "month", "qtr", "half", "yr"]
 1596:     )
 1597:     def test_date_parsing_ignores_format_details(self, column, datapath):
 1598:         # GH 17797
 1599:         #
 1600:         # Test that display formats are ignored when determining if a numeric
 1601:         # column is a date value.
 1602:         #
 1603:         # All date types are stored as numbers and format associated with the
 1604:         # column denotes both the type of the date and the display format.
 1605:         #
 1606:         # STATA supports 9 date types which each have distinct units. We test 7
 1607:         # of the 9 types, ignoring %tC and %tb. %tC is a variant of %tc that
 1608:         # accounts for leap seconds and %tb relies on STATAs business calendar.
 1609:         df = read_stata(datapath("io", "data", "stata", "stata13_dates.dta"))
 1610:         unformatted = df.loc[0, column]
 1611:         formatted = df.loc[0, column + "_fmt"]
 1612:         assert unformatted == formatted
 1613: 
 1614:     def test_writer_117(self):
 1615:         original = DataFrame(
 1616:             data=[
 1617:                 [
 1618:                     "string",
 1619:                     "object",
 1620:                     1,
 1621:                     1,
 1622:                     1,
 1623:                     1.1,
 1624:                     1.1,
 1625:                     np.datetime64("2003-12-25"),
 1626:                     "a",
 1627:                     "a" * 2045,
 1628:                     "a" * 5000,
 1629:                     "a",
 1630:                 ],
 1631:                 [
 1632:                     "string-1",
 1633:                     "object-1",
 1634:                     1,
 1635:                     1,
 1636:                     1,
 1637:                     1.1,
 1638:                     1.1,
 1639:                     np.datetime64("2003-12-26"),
 1640:                     "b",
 1641:                     "b" * 2045,
 1642:                     "",
 1643:                     "",
 1644:                 ],
 1645:             ],
 1646:             columns=[
 1647:                 "string",
 1648:                 "object",
 1649:                 "int8",
 1650:                 "int16",
 1651:                 "int32",
 1652:                 "float32",
 1653:                 "float64",
 1654:                 "datetime",
 1655:                 "s1",
 1656:                 "s2045",
 1657:                 "srtl",
 1658:                 "forced_strl",
 1659:             ],
 1660:         )
 1661:         original["object"] = Series(original["object"], dtype=object)
 1662:         original["int8"] = Series(original["int8"], dtype=np.int8)
 1663:         original["int16"] = Series(original["int16"], dtype=np.int16)
 1664:         original["int32"] = original["int32"].astype(np.int32)
 1665:         original["float32"] = Series(original["float32"], dtype=np.float32)
 1666:         original.index.name = "index"
 1667:         original.index = original.index.astype(np.int32)
 1668:         copy = original.copy()
 1669:         with tm.ensure_clean() as path:
 1670:             original.to_stata(
 1671:                 path,
 1672:                 convert_dates={"datetime": "tc"},
 1673:                 convert_strl=["forced_strl"],
 1674:                 version=117,
 1675:             )
 1676:             written_and_read_again = self.read_dta(path)
 1677:             # original.index is np.int32, read index is np.int64
 1678:             tm.assert_frame_equal(
 1679:                 written_and_read_again.set_index("index"),
 1680:                 original,
 1681:                 check_index_type=False,
 1682:             )
 1683:             tm.assert_frame_equal(original, copy)
 1684: 
 1685:     def test_convert_strl_name_swap(self):
 1686:         original = DataFrame(
 1687:             [["a" * 3000, "A", "apple"], ["b" * 1000, "B", "banana"]],
 1688:             columns=["long1" * 10, "long", 1],
 1689:         )
 1690:         original.index.name = "index"
 1691: 
 1692:         with tm.assert_produces_warning(InvalidColumnName):
 1693:             with tm.ensure_clean() as path:
 1694:                 original.to_stata(path, convert_strl=["long", 1], version=117)
 1695:                 reread = self.read_dta(path)
 1696:                 reread = reread.set_index("index")
 1697:                 reread.columns = original.columns
 1698:                 tm.assert_frame_equal(reread, original, check_index_type=False)
 1699: 
 1700:     def test_invalid_date_conversion(self):
 1701:         # GH 12259
 1702:         dates = [
 1703:             dt.datetime(1999, 12, 31, 12, 12, 12, 12000),
 1704:             dt.datetime(2012, 12, 21, 12, 21, 12, 21000),
 1705:             dt.datetime(1776, 7, 4, 7, 4, 7, 4000),
 1706:         ]
 1707:         original = DataFrame(
 1708:             {
 1709:                 "nums": [1.0, 2.0, 3.0],
 1710:                 "strs": ["apple", "banana", "cherry"],
 1711:                 "dates": dates,
 1712:             }
 1713:         )
 1714: 
 1715:         with tm.ensure_clean() as path:
 1716:             msg = "convert_dates key must be a column or an integer"
 1717:             with pytest.raises(ValueError, match=msg):
 1718:                 original.to_stata(path, convert_dates={"wrong_name": "tc"})
 1719: 
 1720:     @pytest.mark.parametrize("version", [114, 117, 118, 119, None])
 1721:     def test_nonfile_writing(self, version):
 1722:         # GH 21041
 1723:         bio = io.BytesIO()
 1724:         df = DataFrame(
 1725:             1.1 * np.arange(120).reshape((30, 4)),
 1726:             columns=pd.Index(list("ABCD"), dtype=object),
 1727:             index=pd.Index([f"i-{i}" for i in range(30)], dtype=object),
 1728:         )
 1729:         df.index.name = "index"
 1730:         with tm.ensure_clean() as path:
 1731:             df.to_stata(bio, version=version)
 1732:             bio.seek(0)
 1733:             with open(path, "wb") as dta:
 1734:                 dta.write(bio.read())
 1735:             reread = read_stata(path, index_col="index")
 1736:         tm.assert_frame_equal(df, reread)
 1737: 
 1738:     def test_gzip_writing(self):
 1739:         # writing version 117 requires seek and cannot be used with gzip
 1740:         df = DataFrame(
 1741:             1.1 * np.arange(120).reshape((30, 4)),
 1742:             columns=pd.Index(list("ABCD"), dtype=object),
 1743:             index=pd.Index([f"i-{i}" for i in range(30)], dtype=object),
 1744:         )
 1745:         df.index.name = "index"
 1746:         with tm.ensure_clean() as path:
 1747:             with gzip.GzipFile(path, "wb") as gz:
 1748:                 df.to_stata(gz, version=114)
 1749:             with gzip.GzipFile(path, "rb") as gz:
 1750:                 reread = read_stata(gz, index_col="index")
 1751:         tm.assert_frame_equal(df, reread)
 1752: 
 1753:     def test_unicode_dta_118(self, datapath):
 1754:         unicode_df = self.read_dta(datapath("io", "data", "stata", "stata16_118.dta"))
 1755: 
 1756:         columns = ["utf8", "latin1", "ascii", "utf8_strl", "ascii_strl"]
 1757:         values = [
 1758:             ["ПЃО±О·ОґО±П‚", "PГ„NDГ„S", "p", "ПЃО±О·ОґО±П‚", "p"],
 1759:             ["Ж¤ДЂЕ„ДђД…Ењ", "Г–", "a", "Ж¤ДЂЕ„ДђД…Ењ", "a"],
 1760:             ["бґбґЂбґЋбґ…бґЂS", "Гњ", "n", "бґбґЂбґЋбґ…бґЂS", "n"],
 1761:             ["      ", "      ", "d", "      ", "d"],
 1762:             [" ", "", "a", " ", "a"],
 1763:             ["", "", "s", "", "s"],
 1764:             ["", "", " ", "", " "],
 1765:         ]
 1766:         expected = DataFrame(values, columns=columns)
 1767: 
 1768:         tm.assert_frame_equal(unicode_df, expected)
 1769: 
 1770:     def test_mixed_string_strl(self):
 1771:         # GH 23633
 1772:         output = [{"mixed": "string" * 500, "number": 0}, {"mixed": None, "number": 1}]
 1773:         output = DataFrame(output)
 1774:         output.number = output.number.astype("int32")
 1775: 
 1776:         with tm.ensure_clean() as path:
 1777:             output.to_stata(path, write_index=False, version=117)
 1778:             reread = read_stata(path)
 1779:             expected = output.fillna("")
 1780:             tm.assert_frame_equal(reread, expected)
 1781: 
 1782:             # Check strl supports all None (null)
 1783:             output["mixed"] = None
 1784:             output.to_stata(
 1785:                 path, write_index=False, convert_strl=["mixed"], version=117
 1786:             )
 1787:             reread = read_stata(path)
 1788:             expected = output.fillna("")
 1789:             tm.assert_frame_equal(reread, expected)
 1790: 
 1791:     @pytest.mark.parametrize("version", [114, 117, 118, 119, None])
 1792:     def test_all_none_exception(self, version):
 1793:         output = [{"none": "none", "number": 0}, {"none": None, "number": 1}]
 1794:         output = DataFrame(output)
 1795:         output["none"] = None
 1796:         with tm.ensure_clean() as path:
 1797:             with pytest.raises(ValueError, match="Column `none` cannot be exported"):
 1798:                 output.to_stata(path, version=version)
 1799: 
 1800:     @pytest.mark.parametrize("version", [114, 117, 118, 119, None])
 1801:     def test_invalid_file_not_written(self, version):
 1802:         content = "Here is one __пїЅ__ Another one __В·__ Another one __ВЅ__"
 1803:         df = DataFrame([content], columns=["invalid"])
 1804:         with tm.ensure_clean() as path:
 1805:             msg1 = (
 1806:                 r"'latin-1' codec can't encode character '\\ufffd' "
 1807:                 r"in position 14: ordinal not in range\(256\)"
 1808:             )
 1809:             msg2 = (
 1810:                 "'ascii' codec can't decode byte 0xef in position 14: "
 1811:                 r"ordinal not in range\(128\)"
 1812:             )
 1813:             with pytest.raises(UnicodeEncodeError, match=f"{msg1}|{msg2}"):
 1814:                 df.to_stata(path)
 1815: 
 1816:     def test_strl_latin1(self):
 1817:         # GH 23573, correct GSO data to reflect correct size
 1818:         output = DataFrame(
 1819:             [["pandas"] * 2, ["ГѕГўГ‘ГђГ…В§"] * 2], columns=["var_str", "var_strl"]
 1820:         )
 1821: 
 1822:         with tm.ensure_clean() as path:
 1823:             output.to_stata(path, version=117, convert_strl=["var_strl"])
 1824:             with open(path, "rb") as reread:
 1825:                 content = reread.read()
 1826:                 expected = "ГѕГўГ‘ГђГ…В§"
 1827:                 assert expected.encode("latin-1") in content
 1828:                 assert expected.encode("utf-8") in content
 1829:                 gsos = content.split(b"strls")[1][1:-2]
 1830:                 for gso in gsos.split(b"GSO")[1:]:
 1831:                     val = gso.split(b"\x00")[-2]
 1832:                     size = gso[gso.find(b"\x82") + 1]
 1833:                     assert len(val) == size - 1
 1834: 
 1835:     def test_encoding_latin1_118(self, datapath):
 1836:         # GH 25960
 1837:         msg = """
 1838: One or more strings in the dta file could not be decoded using utf-8, and
 1839: so the fallback encoding of latin-1 is being used.  This can happen when a file
 1840: has been incorrectly encoded by Stata or some other software. You should verify
 1841: the string values returned are correct."""
 1842:         # Move path outside of read_stata, or else assert_produces_warning
 1843:         # will block pytests skip mechanism from triggering (failing the test)
 1844:         # if the path is not present
 1845:         path = datapath("io", "data", "stata", "stata1_encoding_118.dta")
 1846:         with tm.assert_produces_warning(UnicodeWarning, filter_level="once") as w:
 1847:             encoded = read_stata(path)
 1848:             # with filter_level="always", produces 151 warnings which can be slow
 1849:             assert len(w) == 1
 1850:             assert w[0].message.args[0] == msg
 1851: 
 1852:         expected = DataFrame([["DГјsseldorf"]] * 151, columns=["kreis1849"])
 1853:         tm.assert_frame_equal(encoded, expected)
 1854: 
 1855:     @pytest.mark.slow
 1856:     def test_stata_119(self, datapath):
 1857:         # Gzipped since contains 32,999 variables and uncompressed is 20MiB
 1858:         # Just validate that the reader reports correct number of variables
 1859:         # to avoid high peak memory
 1860:         with gzip.open(
 1861:             datapath("io", "data", "stata", "stata1_119.dta.gz"), "rb"
 1862:         ) as gz:
 1863:             with StataReader(gz) as reader:
 1864:                 reader._ensure_open()
 1865:                 assert reader._nvar == 32999
 1866: 
 1867:     @pytest.mark.parametrize("version", [118, 119, None])
 1868:     def test_utf8_writer(self, version):
 1869:         cat = pd.Categorical(["a", "ОІ", "Д‰"], ordered=True)
 1870:         data = DataFrame(
 1871:             [
 1872:                 [1.0, 1, "бґ¬", "бґЂ relatively long Еќtring"],
 1873:                 [2.0, 2, "бґ®", ""],
 1874:                 [3.0, 3, "бґ°", None],
 1875:             ],
 1876:             columns=["Г…", "ОІ", "Д‰", "strls"],
 1877:         )
 1878:         data["бґђбґ¬бµЂ"] = cat
 1879:         variable_labels = {
 1880:             "Г…": "apple",
 1881:             "ОІ": "бµ€бµ‰бµЉ",
 1882:             "Д‰": "бґЋбѓўбѓ„б‚Іб‚іб‚ґб‚¶б‚є",
 1883:             "strls": "Long Strings",
 1884:             "бґђбґ¬бµЂ": "",
 1885:         }
 1886:         data_label = "бґ…aбµЂa-label"
 1887:         value_labels = {"ОІ": {1: "label", 2: "Г¦ГёГҐ", 3: "Е‹ot valid latin-1"}}
 1888:         data["ОІ"] = data["ОІ"].astype(np.int32)
 1889:         with tm.ensure_clean() as path:
 1890:             writer = StataWriterUTF8(
 1891:                 path,
 1892:                 data,
 1893:                 data_label=data_label,
 1894:                 convert_strl=["strls"],
 1895:                 variable_labels=variable_labels,
 1896:                 write_index=False,
 1897:                 version=version,
 1898:                 value_labels=value_labels,
 1899:             )
 1900:             writer.write_file()
 1901:             reread_encoded = read_stata(path)
 1902:             # Missing is intentionally converted to empty strl
 1903:             data["strls"] = data["strls"].fillna("")
 1904:             # Variable with value labels is reread as categorical
 1905:             data["ОІ"] = (
 1906:                 data["ОІ"].replace(value_labels["ОІ"]).astype("category").cat.as_ordered()
 1907:             )
 1908:             tm.assert_frame_equal(data, reread_encoded)
 1909:             with StataReader(path) as reader:
 1910:                 assert reader.data_label == data_label
 1911:                 assert reader.variable_labels() == variable_labels
 1912: 
 1913:             data.to_stata(path, version=version, write_index=False)
 1914:             reread_to_stata = read_stata(path)
 1915:             tm.assert_frame_equal(data, reread_to_stata)
 1916: 
 1917:     def test_writer_118_exceptions(self):
 1918:         df = DataFrame(np.zeros((1, 33000), dtype=np.int8))
 1919:         with tm.ensure_clean() as path:
 1920:             with pytest.raises(ValueError, match="version must be either 118 or 119."):
 1921:                 StataWriterUTF8(path, df, version=117)
 1922:         with tm.ensure_clean() as path:
 1923:             with pytest.raises(ValueError, match="You must use version 119"):
 1924:                 StataWriterUTF8(path, df, version=118)
 1925: 
 1926:     @pytest.mark.parametrize(
 1927:         "dtype_backend",
 1928:         ["numpy_nullable", pytest.param("pyarrow", marks=td.skip_if_no("pyarrow"))],
 1929:     )
 1930:     def test_read_write_ea_dtypes(self, dtype_backend):
 1931:         df = DataFrame(
 1932:             {
 1933:                 "a": [1, 2, None],
 1934:                 "b": ["a", "b", "c"],
 1935:                 "c": [True, False, None],
 1936:                 "d": [1.5, 2.5, 3.5],
 1937:                 "e": pd.date_range("2020-12-31", periods=3, freq="D"),
 1938:             },
 1939:             index=pd.Index([0, 1, 2], name="index"),
 1940:         )
 1941:         df = df.convert_dtypes(dtype_backend=dtype_backend)
 1942:         df.to_stata("test_stata.dta", version=118)
 1943: 
 1944:         with tm.ensure_clean() as path:
 1945:             df.to_stata(path)
 1946:             written_and_read_again = self.read_dta(path)
 1947: 
 1948:         expected = DataFrame(
 1949:             {
 1950:                 "a": [1, 2, np.nan],
 1951:                 "b": ["a", "b", "c"],
 1952:                 "c": [1.0, 0, np.nan],
 1953:                 "d": [1.5, 2.5, 3.5],
 1954:                 "e": pd.date_range("2020-12-31", periods=3, freq="D"),
 1955:             },
 1956:             index=pd.Index([0, 1, 2], name="index", dtype=np.int32),
 1957:         )
 1958: 
 1959:         tm.assert_frame_equal(written_and_read_again.set_index("index"), expected)
 1960: 
 1961: 
 1962: @pytest.mark.parametrize("version", [105, 108, 111, 113, 114])
 1963: def test_backward_compat(version, datapath):
 1964:     data_base = datapath("io", "data", "stata")
 1965:     ref = os.path.join(data_base, "stata-compat-118.dta")
 1966:     old = os.path.join(data_base, f"stata-compat-{version}.dta")
 1967:     expected = read_stata(ref)
 1968:     old_dta = read_stata(old)
 1969:     tm.assert_frame_equal(old_dta, expected, check_dtype=False)
 1970: 
 1971: 
 1972: def test_direct_read(datapath, monkeypatch):
 1973:     file_path = datapath("io", "data", "stata", "stata-compat-118.dta")
 1974: 
 1975:     # Test that opening a file path doesn't buffer the file.
 1976:     with StataReader(file_path) as reader:
 1977:         # Must not have been buffered to memory
 1978:         assert not reader.read().empty
 1979:         assert not isinstance(reader._path_or_buf, io.BytesIO)
 1980: 
 1981:     # Test that we use a given fp exactly, if possible.
 1982:     with open(file_path, "rb") as fp:
 1983:         with StataReader(fp) as reader:
 1984:             assert not reader.read().empty
 1985:             assert reader._path_or_buf is fp
 1986: 
 1987:     # Test that we use a given BytesIO exactly, if possible.
 1988:     with open(file_path, "rb") as fp:
 1989:         with io.BytesIO(fp.read()) as bio:
 1990:             with StataReader(bio) as reader:
 1991:                 assert not reader.read().empty
 1992:                 assert reader._path_or_buf is bio
 1993: 
 1994: 
 1995: def test_statareader_warns_when_used_without_context(datapath):
 1996:     file_path = datapath("io", "data", "stata", "stata-compat-118.dta")
 1997:     with tm.assert_produces_warning(
 1998:         ResourceWarning,
 1999:         match="without using a context manager",
 2000:     ):
 2001:         sr = StataReader(file_path)
 2002:         sr.read()
 2003:     with tm.assert_produces_warning(
 2004:         FutureWarning,
 2005:         match="is not part of the public API",
 2006:     ):
 2007:         sr.close()
 2008: 
 2009: 
 2010: @pytest.mark.parametrize("version", [114, 117, 118, 119, None])
 2011: @pytest.mark.parametrize("use_dict", [True, False])
 2012: @pytest.mark.parametrize("infer", [True, False])
 2013: def test_compression(compression, version, use_dict, infer, compression_to_extension):
 2014:     file_name = "dta_inferred_compression.dta"
 2015:     if compression:
 2016:         if use_dict:
 2017:             file_ext = compression
 2018:         else:
 2019:             file_ext = compression_to_extension[compression]
 2020:         file_name += f".{file_ext}"
 2021:     compression_arg = compression
 2022:     if infer:
 2023:         compression_arg = "infer"
 2024:     if use_dict:
 2025:         compression_arg = {"method": compression}
 2026: 
 2027:     df = DataFrame(
 2028:         np.random.default_rng(2).standard_normal((10, 2)), columns=list("AB")
 2029:     )
 2030:     df.index.name = "index"
 2031:     with tm.ensure_clean(file_name) as path:
 2032:         df.to_stata(path, version=version, compression=compression_arg)
 2033:         if compression == "gzip":
 2034:             with gzip.open(path, "rb") as comp:
 2035:                 fp = io.BytesIO(comp.read())
 2036:         elif compression == "zip":
 2037:             with zipfile.ZipFile(path, "r") as comp:
 2038:                 fp = io.BytesIO(comp.read(comp.filelist[0]))
 2039:         elif compression == "tar":
 2040:             with tarfile.open(path) as tar:
 2041:                 fp = io.BytesIO(tar.extractfile(tar.getnames()[0]).read())
 2042:         elif compression == "bz2":
 2043:             with bz2.open(path, "rb") as comp:
 2044:                 fp = io.BytesIO(comp.read())
 2045:         elif compression == "zstd":
 2046:             zstd = pytest.importorskip("zstandard")
 2047:             with zstd.open(path, "rb") as comp:
 2048:                 fp = io.BytesIO(comp.read())
 2049:         elif compression == "xz":
 2050:             lzma = pytest.importorskip("lzma")
 2051:             with lzma.open(path, "rb") as comp:
 2052:                 fp = io.BytesIO(comp.read())
 2053:         elif compression is None:
 2054:             fp = path
 2055:         reread = read_stata(fp, index_col="index")
 2056: 
 2057:     expected = df.copy()
 2058:     expected.index = expected.index.astype(np.int32)
 2059:     tm.assert_frame_equal(reread, expected)
 2060: 
 2061: 
 2062: @pytest.mark.parametrize("method", ["zip", "infer"])
 2063: @pytest.mark.parametrize("file_ext", [None, "dta", "zip"])
 2064: def test_compression_dict(method, file_ext):
 2065:     file_name = f"test.{file_ext}"
 2066:     archive_name = "test.dta"
 2067:     df = DataFrame(
 2068:         np.random.default_rng(2).standard_normal((10, 2)), columns=list("AB")
 2069:     )
 2070:     df.index.name = "index"
 2071:     with tm.ensure_clean(file_name) as path:
 2072:         compression = {"method": method, "archive_name": archive_name}
 2073:         df.to_stata(path, compression=compression)
 2074:         if method == "zip" or file_ext == "zip":
 2075:             with zipfile.ZipFile(path, "r") as zp:
 2076:                 assert len(zp.filelist) == 1
 2077:                 assert zp.filelist[0].filename == archive_name
 2078:                 fp = io.BytesIO(zp.read(zp.filelist[0]))
 2079:         else:
 2080:             fp = path
 2081:         reread = read_stata(fp, index_col="index")
 2082: 
 2083:     expected = df.copy()
 2084:     expected.index = expected.index.astype(np.int32)
 2085:     tm.assert_frame_equal(reread, expected)
 2086: 
 2087: 
 2088: @pytest.mark.parametrize("version", [114, 117, 118, 119, None])
 2089: def test_chunked_categorical(version):
 2090:     df = DataFrame({"cats": Series(["a", "b", "a", "b", "c"], dtype="category")})
 2091:     df.index.name = "index"
 2092: 
 2093:     expected = df.copy()
 2094:     expected.index = expected.index.astype(np.int32)
 2095: 
 2096:     with tm.ensure_clean() as path:
 2097:         df.to_stata(path, version=version)
 2098:         with StataReader(path, chunksize=2, order_categoricals=False) as reader:
 2099:             for i, block in enumerate(reader):
 2100:                 block = block.set_index("index")
 2101:                 assert "cats" in block
 2102:                 tm.assert_series_equal(
 2103:                     block.cats, expected.cats.iloc[2 * i : 2 * (i + 1)]
 2104:                 )
 2105: 
 2106: 
 2107: def test_chunked_categorical_partial(datapath):
 2108:     dta_file = datapath("io", "data", "stata", "stata-dta-partially-labeled.dta")
 2109:     values = ["a", "b", "a", "b", 3.0]
 2110:     with StataReader(dta_file, chunksize=2) as reader:
 2111:         with tm.assert_produces_warning(CategoricalConversionWarning):
 2112:             for i, block in enumerate(reader):
 2113:                 assert list(block.cats) == values[2 * i : 2 * (i + 1)]
 2114:                 if i < 2:
 2115:                     idx = pd.Index(["a", "b"])
 2116:                 else:
 2117:                     idx = pd.Index([3.0], dtype="float64")
 2118:                 tm.assert_index_equal(block.cats.cat.categories, idx)
 2119:     with tm.assert_produces_warning(CategoricalConversionWarning):
 2120:         with StataReader(dta_file, chunksize=5) as reader:
 2121:             large_chunk = reader.__next__()
 2122:     direct = read_stata(dta_file)
 2123:     tm.assert_frame_equal(direct, large_chunk)
 2124: 
 2125: 
 2126: @pytest.mark.parametrize("chunksize", (-1, 0, "apple"))
 2127: def test_iterator_errors(datapath, chunksize):
 2128:     dta_file = datapath("io", "data", "stata", "stata-dta-partially-labeled.dta")
 2129:     with pytest.raises(ValueError, match="chunksize must be a positive"):
 2130:         with StataReader(dta_file, chunksize=chunksize):
 2131:             pass
 2132: 
 2133: 
 2134: def test_iterator_value_labels():
 2135:     # GH 31544
 2136:     values = ["c_label", "b_label"] + ["a_label"] * 500
 2137:     df = DataFrame({f"col{k}": pd.Categorical(values, ordered=True) for k in range(2)})
 2138:     with tm.ensure_clean() as path:
 2139:         df.to_stata(path, write_index=False)
 2140:         expected = pd.Index(["a_label", "b_label", "c_label"], dtype="object")
 2141:         with read_stata(path, chunksize=100) as reader:
 2142:             for j, chunk in enumerate(reader):
 2143:                 for i in range(2):
 2144:                     tm.assert_index_equal(chunk.dtypes.iloc[i].categories, expected)
 2145:                 tm.assert_frame_equal(chunk, df.iloc[j * 100 : (j + 1) * 100])
 2146: 
 2147: 
 2148: def test_precision_loss():
 2149:     df = DataFrame(
 2150:         [[sum(2**i for i in range(60)), sum(2**i for i in range(52))]],
 2151:         columns=["big", "little"],
 2152:     )
 2153:     with tm.ensure_clean() as path:
 2154:         with tm.assert_produces_warning(
 2155:             PossiblePrecisionLoss, match="Column converted from int64 to float64"
 2156:         ):
 2157:             df.to_stata(path, write_index=False)
 2158:         reread = read_stata(path)
 2159:         expected_dt = Series([np.float64, np.float64], index=["big", "little"])
 2160:         tm.assert_series_equal(reread.dtypes, expected_dt)
 2161:         assert reread.loc[0, "little"] == df.loc[0, "little"]
 2162:         assert reread.loc[0, "big"] == float(df.loc[0, "big"])
 2163: 
 2164: 
 2165: def test_compression_roundtrip(compression):
 2166:     df = DataFrame(
 2167:         [[0.123456, 0.234567, 0.567567], [12.32112, 123123.2, 321321.2]],
 2168:         index=["A", "B"],
 2169:         columns=["X", "Y", "Z"],
 2170:     )
 2171:     df.index.name = "index"
 2172: 
 2173:     with tm.ensure_clean() as path:
 2174:         df.to_stata(path, compression=compression)
 2175:         reread = read_stata(path, compression=compression, index_col="index")
 2176:         tm.assert_frame_equal(df, reread)
 2177: 
 2178:         # explicitly ensure file was compressed.
 2179:         with tm.decompress_file(path, compression) as fh:
 2180:             contents = io.BytesIO(fh.read())
 2181:         reread = read_stata(contents, index_col="index")
 2182:         tm.assert_frame_equal(df, reread)
 2183: 
 2184: 
 2185: @pytest.mark.parametrize("to_infer", [True, False])
 2186: @pytest.mark.parametrize("read_infer", [True, False])
 2187: def test_stata_compression(
 2188:     compression_only, read_infer, to_infer, compression_to_extension
 2189: ):
 2190:     compression = compression_only
 2191: 
 2192:     ext = compression_to_extension[compression]
 2193:     filename = f"test.{ext}"
 2194: 
 2195:     df = DataFrame(
 2196:         [[0.123456, 0.234567, 0.567567], [12.32112, 123123.2, 321321.2]],
 2197:         index=["A", "B"],
 2198:         columns=["X", "Y", "Z"],
 2199:     )
 2200:     df.index.name = "index"
 2201: 
 2202:     to_compression = "infer" if to_infer else compression
 2203:     read_compression = "infer" if read_infer else compression
 2204: 
 2205:     with tm.ensure_clean(filename) as path:
 2206:         df.to_stata(path, compression=to_compression)
 2207:         result = read_stata(path, compression=read_compression, index_col="index")
 2208:         tm.assert_frame_equal(result, df)
 2209: 
 2210: 
 2211: def test_non_categorical_value_labels():
 2212:     data = DataFrame(
 2213:         {
 2214:             "fully_labelled": [1, 2, 3, 3, 1],
 2215:             "partially_labelled": [1.0, 2.0, np.nan, 9.0, np.nan],
 2216:             "Y": [7, 7, 9, 8, 10],
 2217:             "Z": pd.Categorical(["j", "k", "l", "k", "j"]),
 2218:         }
 2219:     )
 2220: 
 2221:     with tm.ensure_clean() as path:
 2222:         value_labels = {
 2223:             "fully_labelled": {1: "one", 2: "two", 3: "three"},
 2224:             "partially_labelled": {1.0: "one", 2.0: "two"},
 2225:         }
 2226:         expected = {**value_labels, "Z": {0: "j", 1: "k", 2: "l"}}
 2227: 
 2228:         writer = StataWriter(path, data, value_labels=value_labels)
 2229:         writer.write_file()
 2230: 
 2231:         with StataReader(path) as reader:
 2232:             reader_value_labels = reader.value_labels()
 2233:             assert reader_value_labels == expected
 2234: 
 2235:         msg = "Can't create value labels for notY, it wasn't found in the dataset."
 2236:         with pytest.raises(KeyError, match=msg):
 2237:             value_labels = {"notY": {7: "label1", 8: "label2"}}
 2238:             StataWriter(path, data, value_labels=value_labels)
 2239: 
 2240:         msg = (
 2241:             "Can't create value labels for Z, value labels "
 2242:             "can only be applied to numeric columns."
 2243:         )
 2244:         with pytest.raises(ValueError, match=msg):
 2245:             value_labels = {"Z": {1: "a", 2: "k", 3: "j", 4: "i"}}
 2246:             StataWriter(path, data, value_labels=value_labels)
 2247: 
 2248: 
 2249: def test_non_categorical_value_label_name_conversion():
 2250:     # Check conversion of invalid variable names
 2251:     data = DataFrame(
 2252:         {
 2253:             "invalid~!": [1, 1, 2, 3, 5, 8],  # Only alphanumeric and _
 2254:             "6_invalid": [1, 1, 2, 3, 5, 8],  # Must start with letter or _
 2255:             "invalid_name_longer_than_32_characters": [8, 8, 9, 9, 8, 8],  # Too long
 2256:             "aggregate": [2, 5, 5, 6, 6, 9],  # Reserved words
 2257:             (1, 2): [1, 2, 3, 4, 5, 6],  # Hashable non-string
 2258:         }
 2259:     )
 2260: 
 2261:     value_labels = {
 2262:         "invalid~!": {1: "label1", 2: "label2"},
 2263:         "6_invalid": {1: "label1", 2: "label2"},
 2264:         "invalid_name_longer_than_32_characters": {8: "eight", 9: "nine"},
 2265:         "aggregate": {5: "five"},
 2266:         (1, 2): {3: "three"},
 2267:     }
 2268: 
 2269:     expected = {
 2270:         "invalid__": {1: "label1", 2: "label2"},
 2271:         "_6_invalid": {1: "label1", 2: "label2"},
 2272:         "invalid_name_longer_than_32_char": {8: "eight", 9: "nine"},
 2273:         "_aggregate": {5: "five"},
 2274:         "_1__2_": {3: "three"},
 2275:     }
 2276: 
 2277:     with tm.ensure_clean() as path:
 2278:         with tm.assert_produces_warning(InvalidColumnName):
 2279:             data.to_stata(path, value_labels=value_labels)
 2280: 
 2281:         with StataReader(path) as reader:
 2282:             reader_value_labels = reader.value_labels()
 2283:             assert reader_value_labels == expected
 2284: 
 2285: 
 2286: def test_non_categorical_value_label_convert_categoricals_error():
 2287:     # Mapping more than one value to the same label is valid for Stata
 2288:     # labels, but can't be read with convert_categoricals=True
 2289:     value_labels = {
 2290:         "repeated_labels": {10: "Ten", 20: "More than ten", 40: "More than ten"}
 2291:     }
 2292: 
 2293:     data = DataFrame(
 2294:         {
 2295:             "repeated_labels": [10, 10, 20, 20, 40, 40],
 2296:         }
 2297:     )
 2298: 
 2299:     with tm.ensure_clean() as path:
 2300:         data.to_stata(path, value_labels=value_labels)
 2301: 
 2302:         with StataReader(path, convert_categoricals=False) as reader:
 2303:             reader_value_labels = reader.value_labels()
 2304:         assert reader_value_labels == value_labels
 2305: 
 2306:         col = "repeated_labels"
 2307:         repeats = "-" * 80 + "\n" + "\n".join(["More than ten"])
 2308: 
 2309:         msg = f"""
 2310: Value labels for column {col} are not unique. These cannot be converted to
 2311: pandas categoricals.
 2312: 
 2313: Either read the file with `convert_categoricals` set to False or use the
 2314: low level interface in `StataReader` to separately read the values and the
 2315: value_labels.
 2316: 
 2317: The repeated labels are:
 2318: {repeats}
 2319: """
 2320:         with pytest.raises(ValueError, match=msg):
 2321:             read_stata(path, convert_categoricals=True)
 2322: 
 2323: 
 2324: @pytest.mark.parametrize("version", [114, 117, 118, 119, None])
 2325: @pytest.mark.parametrize(
 2326:     "dtype",
 2327:     [
 2328:         pd.BooleanDtype,
 2329:         pd.Int8Dtype,
 2330:         pd.Int16Dtype,
 2331:         pd.Int32Dtype,
 2332:         pd.Int64Dtype,
 2333:         pd.UInt8Dtype,
 2334:         pd.UInt16Dtype,
 2335:         pd.UInt32Dtype,
 2336:         pd.UInt64Dtype,
 2337:     ],
 2338: )
 2339: def test_nullable_support(dtype, version):
 2340:     df = DataFrame(
 2341:         {
 2342:             "a": Series([1.0, 2.0, 3.0]),
 2343:             "b": Series([1, pd.NA, pd.NA], dtype=dtype.name),
 2344:             "c": Series(["a", "b", None]),
 2345:         }
 2346:     )
 2347:     dtype_name = df.b.dtype.numpy_dtype.name
 2348:     # Only use supported names: no uint, bool or int64
 2349:     dtype_name = dtype_name.replace("u", "")
 2350:     if dtype_name == "int64":
 2351:         dtype_name = "int32"
 2352:     elif dtype_name == "bool":
 2353:         dtype_name = "int8"
 2354:     value = StataMissingValue.BASE_MISSING_VALUES[dtype_name]
 2355:     smv = StataMissingValue(value)
 2356:     expected_b = Series([1, smv, smv], dtype=object, name="b")
 2357:     expected_c = Series(["a", "b", ""], name="c")
 2358:     with tm.ensure_clean() as path:
 2359:         df.to_stata(path, write_index=False, version=version)
 2360:         reread = read_stata(path, convert_missing=True)
 2361:         tm.assert_series_equal(df.a, reread.a)
 2362:         tm.assert_series_equal(reread.b, expected_b)
 2363:         tm.assert_series_equal(reread.c, expected_c)
 2364: 
 2365: 
 2366: def test_empty_frame():
 2367:     # GH 46240
 2368:     # create an empty DataFrame with int64 and float64 dtypes
 2369:     df = DataFrame(data={"a": range(3), "b": [1.0, 2.0, 3.0]}).head(0)
 2370:     with tm.ensure_clean() as path:
 2371:         df.to_stata(path, write_index=False, version=117)
 2372:         # Read entire dataframe
 2373:         df2 = read_stata(path)
 2374:         assert "b" in df2
 2375:         # Dtypes don't match since no support for int32
 2376:         dtypes = Series({"a": np.dtype("int32"), "b": np.dtype("float64")})
 2377:         tm.assert_series_equal(df2.dtypes, dtypes)
 2378:         # read one column of empty .dta file
 2379:         df3 = read_stata(path, columns=["a"])
 2380:         assert "b" not in df3
 2381:         tm.assert_series_equal(df3.dtypes, dtypes.loc[["a"]])
