    1: from contextlib import closing
    2: from pathlib import Path
    3: import re
    4: 
    5: import numpy as np
    6: import pytest
    7: 
    8: from pandas._libs.tslibs import Timestamp
    9: from pandas.compat import is_platform_windows
   10: 
   11: import pandas as pd
   12: from pandas import (
   13:     DataFrame,
   14:     HDFStore,
   15:     Index,
   16:     Series,
   17:     _testing as tm,
   18:     date_range,
   19:     read_hdf,
   20: )
   21: from pandas.tests.io.pytables.common import (
   22:     _maybe_remove,
   23:     ensure_clean_store,
   24: )
   25: from pandas.util import _test_decorators as td
   26: 
   27: from pandas.io.pytables import TableIterator
   28: 
   29: pytestmark = pytest.mark.single_cpu
   30: 
   31: 
   32: def test_read_missing_key_close_store(tmp_path, setup_path):
   33:     # GH 25766
   34:     path = tmp_path / setup_path
   35:     df = DataFrame({"a": range(2), "b": range(2)})
   36:     df.to_hdf(path, key="k1")
   37: 
   38:     with pytest.raises(KeyError, match="'No object named k2 in the file'"):
   39:         read_hdf(path, "k2")
   40: 
   41:     # smoke test to test that file is properly closed after
   42:     # read with KeyError before another write
   43:     df.to_hdf(path, key="k2")
   44: 
   45: 
   46: def test_read_index_error_close_store(tmp_path, setup_path):
   47:     # GH 25766
   48:     path = tmp_path / setup_path
   49:     df = DataFrame({"A": [], "B": []}, index=[])
   50:     df.to_hdf(path, key="k1")
   51: 
   52:     with pytest.raises(IndexError, match=r"list index out of range"):
   53:         read_hdf(path, "k1", stop=0)
   54: 
   55:     # smoke test to test that file is properly closed after
   56:     # read with IndexError before another write
   57:     df.to_hdf(path, key="k1")
   58: 
   59: 
   60: def test_read_missing_key_opened_store(tmp_path, setup_path):
   61:     # GH 28699
   62:     path = tmp_path / setup_path
   63:     df = DataFrame({"a": range(2), "b": range(2)})
   64:     df.to_hdf(path, key="k1")
   65: 
   66:     with HDFStore(path, "r") as store:
   67:         with pytest.raises(KeyError, match="'No object named k2 in the file'"):
   68:             read_hdf(store, "k2")
   69: 
   70:         # Test that the file is still open after a KeyError and that we can
   71:         # still read from it.
   72:         read_hdf(store, "k1")
   73: 
   74: 
   75: def test_read_column(setup_path):
   76:     df = DataFrame(
   77:         np.random.default_rng(2).standard_normal((10, 4)),
   78:         columns=Index(list("ABCD"), dtype=object),
   79:         index=date_range("2000-01-01", periods=10, freq="B"),
   80:     )
   81: 
   82:     with ensure_clean_store(setup_path) as store:
   83:         _maybe_remove(store, "df")
   84: 
   85:         # GH 17912
   86:         # HDFStore.select_column should raise a KeyError
   87:         # exception if the key is not a valid store
   88:         with pytest.raises(KeyError, match="No object named df in the file"):
   89:             store.select_column("df", "index")
   90: 
   91:         store.append("df", df)
   92:         # error
   93:         with pytest.raises(
   94:             KeyError, match=re.escape("'column [foo] not found in the table'")
   95:         ):
   96:             store.select_column("df", "foo")
   97: 
   98:         msg = re.escape("select_column() got an unexpected keyword argument 'where'")
   99:         with pytest.raises(TypeError, match=msg):
  100:             store.select_column("df", "index", where=["index>5"])
  101: 
  102:         # valid
  103:         result = store.select_column("df", "index")
  104:         tm.assert_almost_equal(result.values, Series(df.index).values)
  105:         assert isinstance(result, Series)
  106: 
  107:         # not a data indexable column
  108:         msg = re.escape(
  109:             "column [values_block_0] can not be extracted individually; "
  110:             "it is not data indexable"
  111:         )
  112:         with pytest.raises(ValueError, match=msg):
  113:             store.select_column("df", "values_block_0")
  114: 
  115:         # a data column
  116:         df2 = df.copy()
  117:         df2["string"] = "foo"
  118:         store.append("df2", df2, data_columns=["string"])
  119:         result = store.select_column("df2", "string")
  120:         tm.assert_almost_equal(result.values, df2["string"].values)
  121: 
  122:         # a data column with NaNs, result excludes the NaNs
  123:         df3 = df.copy()
  124:         df3["string"] = "foo"
  125:         df3.loc[df3.index[4:6], "string"] = np.nan
  126:         store.append("df3", df3, data_columns=["string"])
  127:         result = store.select_column("df3", "string")
  128:         tm.assert_almost_equal(result.values, df3["string"].values)
  129: 
  130:         # start/stop
  131:         result = store.select_column("df3", "string", start=2)
  132:         tm.assert_almost_equal(result.values, df3["string"].values[2:])
  133: 
  134:         result = store.select_column("df3", "string", start=-2)
  135:         tm.assert_almost_equal(result.values, df3["string"].values[-2:])
  136: 
  137:         result = store.select_column("df3", "string", stop=2)
  138:         tm.assert_almost_equal(result.values, df3["string"].values[:2])
  139: 
  140:         result = store.select_column("df3", "string", stop=-2)
  141:         tm.assert_almost_equal(result.values, df3["string"].values[:-2])
  142: 
  143:         result = store.select_column("df3", "string", start=2, stop=-2)
  144:         tm.assert_almost_equal(result.values, df3["string"].values[2:-2])
  145: 
  146:         result = store.select_column("df3", "string", start=-2, stop=2)
  147:         tm.assert_almost_equal(result.values, df3["string"].values[-2:2])
  148: 
  149:         # GH 10392 - make sure column name is preserved
  150:         df4 = DataFrame({"A": np.random.default_rng(2).standard_normal(10), "B": "foo"})
  151:         store.append("df4", df4, data_columns=True)
  152:         expected = df4["B"]
  153:         result = store.select_column("df4", "B")
  154:         tm.assert_series_equal(result, expected)
  155: 
  156: 
  157: def test_pytables_native_read(datapath):
  158:     with ensure_clean_store(
  159:         datapath("io", "data", "legacy_hdf/pytables_native.h5"), mode="r"
  160:     ) as store:
  161:         d2 = store["detector/readout"]
  162:     assert isinstance(d2, DataFrame)
  163: 
  164: 
  165: @pytest.mark.skipif(is_platform_windows(), reason="native2 read fails oddly on windows")
  166: def test_pytables_native2_read(datapath):
  167:     with ensure_clean_store(
  168:         datapath("io", "data", "legacy_hdf", "pytables_native2.h5"), mode="r"
  169:     ) as store:
  170:         str(store)
  171:         d1 = store["detector"]
  172:     assert isinstance(d1, DataFrame)
  173: 
  174: 
  175: def test_legacy_table_fixed_format_read_py2(datapath):
  176:     # GH 24510
  177:     # legacy table with fixed format written in Python 2
  178:     with ensure_clean_store(
  179:         datapath("io", "data", "legacy_hdf", "legacy_table_fixed_py2.h5"), mode="r"
  180:     ) as store:
  181:         result = store.select("df")
  182:     expected = DataFrame(
  183:         [[1, 2, 3, "D"]],
  184:         columns=["A", "B", "C", "D"],
  185:         index=Index(["ABC"], name="INDEX_NAME"),
  186:     )
  187:     tm.assert_frame_equal(expected, result)
  188: 
  189: 
  190: def test_legacy_table_fixed_format_read_datetime_py2(datapath):
  191:     # GH 31750
  192:     # legacy table with fixed format and datetime64 column written in Python 2
  193:     expected = DataFrame(
  194:         [[Timestamp("2020-02-06T18:00")]],
  195:         columns=["A"],
  196:         index=Index(["date"]),
  197:         dtype="M8[ns]",
  198:     )
  199:     with ensure_clean_store(
  200:         datapath("io", "data", "legacy_hdf", "legacy_table_fixed_datetime_py2.h5"),
  201:         mode="r",
  202:     ) as store:
  203:         result = store.select("df")
  204:     tm.assert_frame_equal(expected, result)
  205: 
  206: 
  207: def test_legacy_table_read_py2(datapath):
  208:     # issue: 24925
  209:     # legacy table written in Python 2
  210:     with ensure_clean_store(
  211:         datapath("io", "data", "legacy_hdf", "legacy_table_py2.h5"), mode="r"
  212:     ) as store:
  213:         result = store.select("table")
  214: 
  215:     expected = DataFrame({"a": ["a", "b"], "b": [2, 3]})
  216:     tm.assert_frame_equal(expected, result)
  217: 
  218: 
  219: def test_read_hdf_open_store(tmp_path, setup_path):
  220:     # GH10330
  221:     # No check for non-string path_or-buf, and no test of open store
  222:     df = DataFrame(
  223:         np.random.default_rng(2).random((4, 5)),
  224:         index=list("abcd"),
  225:         columns=list("ABCDE"),
  226:     )
  227:     df.index.name = "letters"
  228:     df = df.set_index(keys="E", append=True)
  229: 
  230:     path = tmp_path / setup_path
  231:     df.to_hdf(path, key="df", mode="w")
  232:     direct = read_hdf(path, "df")
  233:     with HDFStore(path, mode="r") as store:
  234:         indirect = read_hdf(store, "df")
  235:         tm.assert_frame_equal(direct, indirect)
  236:         assert store.is_open
  237: 
  238: 
  239: def test_read_hdf_index_not_view(tmp_path, setup_path):
  240:     # GH 37441
  241:     # Ensure that the index of the DataFrame is not a view
  242:     # into the original recarray that pytables reads in
  243:     df = DataFrame(
  244:         np.random.default_rng(2).random((4, 5)),
  245:         index=[0, 1, 2, 3],
  246:         columns=list("ABCDE"),
  247:     )
  248: 
  249:     path = tmp_path / setup_path
  250:     df.to_hdf(path, key="df", mode="w", format="table")
  251: 
  252:     df2 = read_hdf(path, "df")
  253:     assert df2.index._data.base is None
  254:     tm.assert_frame_equal(df, df2)
  255: 
  256: 
  257: def test_read_hdf_iterator(tmp_path, setup_path):
  258:     df = DataFrame(
  259:         np.random.default_rng(2).random((4, 5)),
  260:         index=list("abcd"),
  261:         columns=list("ABCDE"),
  262:     )
  263:     df.index.name = "letters"
  264:     df = df.set_index(keys="E", append=True)
  265: 
  266:     path = tmp_path / setup_path
  267:     df.to_hdf(path, key="df", mode="w", format="t")
  268:     direct = read_hdf(path, "df")
  269:     iterator = read_hdf(path, "df", iterator=True)
  270:     with closing(iterator.store):
  271:         assert isinstance(iterator, TableIterator)
  272:         indirect = next(iterator.__iter__())
  273:     tm.assert_frame_equal(direct, indirect)
  274: 
  275: 
  276: def test_read_nokey(tmp_path, setup_path):
  277:     # GH10443
  278:     df = DataFrame(
  279:         np.random.default_rng(2).random((4, 5)),
  280:         index=list("abcd"),
  281:         columns=list("ABCDE"),
  282:     )
  283: 
  284:     # Categorical dtype not supported for "fixed" format. So no need
  285:     # to test with that dtype in the dataframe here.
  286:     path = tmp_path / setup_path
  287:     df.to_hdf(path, key="df", mode="a")
  288:     reread = read_hdf(path)
  289:     tm.assert_frame_equal(df, reread)
  290:     df.to_hdf(path, key="df2", mode="a")
  291: 
  292:     msg = "key must be provided when HDF5 file contains multiple datasets."
  293:     with pytest.raises(ValueError, match=msg):
  294:         read_hdf(path)
  295: 
  296: 
  297: def test_read_nokey_table(tmp_path, setup_path):
  298:     # GH13231
  299:     df = DataFrame({"i": range(5), "c": Series(list("abacd"), dtype="category")})
  300: 
  301:     path = tmp_path / setup_path
  302:     df.to_hdf(path, key="df", mode="a", format="table")
  303:     reread = read_hdf(path)
  304:     tm.assert_frame_equal(df, reread)
  305:     df.to_hdf(path, key="df2", mode="a", format="table")
  306: 
  307:     msg = "key must be provided when HDF5 file contains multiple datasets."
  308:     with pytest.raises(ValueError, match=msg):
  309:         read_hdf(path)
  310: 
  311: 
  312: def test_read_nokey_empty(tmp_path, setup_path):
  313:     path = tmp_path / setup_path
  314:     store = HDFStore(path)
  315:     store.close()
  316:     msg = re.escape(
  317:         "Dataset(s) incompatible with Pandas data types, not table, or no "
  318:         "datasets found in HDF5 file."
  319:     )
  320:     with pytest.raises(ValueError, match=msg):
  321:         read_hdf(path)
  322: 
  323: 
  324: def test_read_from_pathlib_path(tmp_path, setup_path):
  325:     # GH11773
  326:     expected = DataFrame(
  327:         np.random.default_rng(2).random((4, 5)),
  328:         index=list("abcd"),
  329:         columns=list("ABCDE"),
  330:     )
  331:     filename = tmp_path / setup_path
  332:     path_obj = Path(filename)
  333: 
  334:     expected.to_hdf(path_obj, key="df", mode="a")
  335:     actual = read_hdf(path_obj, key="df")
  336: 
  337:     tm.assert_frame_equal(expected, actual)
  338: 
  339: 
  340: @td.skip_if_no("py.path")
  341: def test_read_from_py_localpath(tmp_path, setup_path):
  342:     # GH11773
  343:     from py.path import local as LocalPath
  344: 
  345:     expected = DataFrame(
  346:         np.random.default_rng(2).random((4, 5)),
  347:         index=list("abcd"),
  348:         columns=list("ABCDE"),
  349:     )
  350:     filename = tmp_path / setup_path
  351:     path_obj = LocalPath(filename)
  352: 
  353:     expected.to_hdf(path_obj, key="df", mode="a")
  354:     actual = read_hdf(path_obj, key="df")
  355: 
  356:     tm.assert_frame_equal(expected, actual)
  357: 
  358: 
  359: @pytest.mark.parametrize("format", ["fixed", "table"])
  360: def test_read_hdf_series_mode_r(tmp_path, format, setup_path):
  361:     # GH 16583
  362:     # Tests that reading a Series saved to an HDF file
  363:     # still works if a mode='r' argument is supplied
  364:     series = Series(range(10), dtype=np.float64)
  365:     path = tmp_path / setup_path
  366:     series.to_hdf(path, key="data", format=format)
  367:     result = read_hdf(path, key="data", mode="r")
  368:     tm.assert_series_equal(result, series)
  369: 
  370: 
  371: @pytest.mark.filterwarnings(r"ignore:Period with BDay freq is deprecated:FutureWarning")
  372: @pytest.mark.filterwarnings(r"ignore:PeriodDtype\[B\] is deprecated:FutureWarning")
  373: def test_read_py2_hdf_file_in_py3(datapath):
  374:     # GH 16781
  375: 
  376:     # tests reading a PeriodIndex DataFrame written in Python2 in Python3
  377: 
  378:     # the file was generated in Python 2.7 like so:
  379:     #
  380:     # df = DataFrame([1.,2,3], index=pd.PeriodIndex(
  381:     #              ['2015-01-01', '2015-01-02', '2015-01-05'], freq='B'))
  382:     # df.to_hdf('periodindex_0.20.1_x86_64_darwin_2.7.13.h5', 'p')
  383: 
  384:     expected = DataFrame(
  385:         [1.0, 2, 3],
  386:         index=pd.PeriodIndex(["2015-01-01", "2015-01-02", "2015-01-05"], freq="B"),
  387:     )
  388: 
  389:     with ensure_clean_store(
  390:         datapath(
  391:             "io", "data", "legacy_hdf", "periodindex_0.20.1_x86_64_darwin_2.7.13.h5"
  392:         ),
  393:         mode="r",
  394:     ) as store:
  395:         result = store["p"]
  396:     tm.assert_frame_equal(result, expected)
  397: 
  398: 
  399: def test_read_infer_string(tmp_path, setup_path):
  400:     # GH#54431
  401:     pytest.importorskip("pyarrow")
  402:     df = DataFrame({"a": ["a", "b", None]})
  403:     path = tmp_path / setup_path
  404:     df.to_hdf(path, key="data", format="table")
  405:     with pd.option_context("future.infer_string", True):
  406:         result = read_hdf(path, key="data", mode="r")
  407:     expected = DataFrame(
  408:         {"a": ["a", "b", None]},
  409:         dtype="string[pyarrow_numpy]",
  410:         columns=Index(["a"], dtype="string[pyarrow_numpy]"),
  411:     )
  412:     tm.assert_frame_equal(result, expected)
