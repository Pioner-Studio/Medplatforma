    1: import io
    2: import os
    3: import sys
    4: from zipfile import ZipFile
    5: 
    6: from _csv import Error
    7: import numpy as np
    8: import pytest
    9: 
   10: import pandas as pd
   11: from pandas import (
   12:     DataFrame,
   13:     Index,
   14:     compat,
   15: )
   16: import pandas._testing as tm
   17: 
   18: 
   19: class TestToCSV:
   20:     def test_to_csv_with_single_column(self):
   21:         # see gh-18676, https://bugs.python.org/issue32255
   22:         #
   23:         # Python's CSV library adds an extraneous '""'
   24:         # before the newline when the NaN-value is in
   25:         # the first row. Otherwise, only the newline
   26:         # character is added. This behavior is inconsistent
   27:         # and was patched in https://bugs.python.org/pull_request4672.
   28:         df1 = DataFrame([None, 1])
   29:         expected1 = """\
   30: ""
   31: 1.0
   32: """
   33:         with tm.ensure_clean("test.csv") as path:
   34:             df1.to_csv(path, header=None, index=None)
   35:             with open(path, encoding="utf-8") as f:
   36:                 assert f.read() == expected1
   37: 
   38:         df2 = DataFrame([1, None])
   39:         expected2 = """\
   40: 1.0
   41: ""
   42: """
   43:         with tm.ensure_clean("test.csv") as path:
   44:             df2.to_csv(path, header=None, index=None)
   45:             with open(path, encoding="utf-8") as f:
   46:                 assert f.read() == expected2
   47: 
   48:     def test_to_csv_default_encoding(self):
   49:         # GH17097
   50:         df = DataFrame({"col": ["AAAAA", "Г„Г„Г„Г„Г„", "ГџГџГџГџГџ", "иЃћиЃћиЃћиЃћиЃћ"]})
   51: 
   52:         with tm.ensure_clean("test.csv") as path:
   53:             # the default to_csv encoding is uft-8.
   54:             df.to_csv(path)
   55:             tm.assert_frame_equal(pd.read_csv(path, index_col=0), df)
   56: 
   57:     def test_to_csv_quotechar(self):
   58:         df = DataFrame({"col": [1, 2]})
   59:         expected = """\
   60: "","col"
   61: "0","1"
   62: "1","2"
   63: """
   64: 
   65:         with tm.ensure_clean("test.csv") as path:
   66:             df.to_csv(path, quoting=1)  # 1=QUOTE_ALL
   67:             with open(path, encoding="utf-8") as f:
   68:                 assert f.read() == expected
   69: 
   70:         expected = """\
   71: $$,$col$
   72: $0$,$1$
   73: $1$,$2$
   74: """
   75: 
   76:         with tm.ensure_clean("test.csv") as path:
   77:             df.to_csv(path, quoting=1, quotechar="$")
   78:             with open(path, encoding="utf-8") as f:
   79:                 assert f.read() == expected
   80: 
   81:         with tm.ensure_clean("test.csv") as path:
   82:             with pytest.raises(TypeError, match="quotechar"):
   83:                 df.to_csv(path, quoting=1, quotechar=None)
   84: 
   85:     def test_to_csv_doublequote(self):
   86:         df = DataFrame({"col": ['a"a', '"bb"']})
   87:         expected = '''\
   88: "","col"
   89: "0","a""a"
   90: "1","""bb"""
   91: '''
   92: 
   93:         with tm.ensure_clean("test.csv") as path:
   94:             df.to_csv(path, quoting=1, doublequote=True)  # QUOTE_ALL
   95:             with open(path, encoding="utf-8") as f:
   96:                 assert f.read() == expected
   97: 
   98:         with tm.ensure_clean("test.csv") as path:
   99:             with pytest.raises(Error, match="escapechar"):
  100:                 df.to_csv(path, doublequote=False)  # no escapechar set
  101: 
  102:     def test_to_csv_escapechar(self):
  103:         df = DataFrame({"col": ['a"a', '"bb"']})
  104:         expected = """\
  105: "","col"
  106: "0","a\\"a"
  107: "1","\\"bb\\""
  108: """
  109: 
  110:         with tm.ensure_clean("test.csv") as path:  # QUOTE_ALL
  111:             df.to_csv(path, quoting=1, doublequote=False, escapechar="\\")
  112:             with open(path, encoding="utf-8") as f:
  113:                 assert f.read() == expected
  114: 
  115:         df = DataFrame({"col": ["a,a", ",bb,"]})
  116:         expected = """\
  117: ,col
  118: 0,a\\,a
  119: 1,\\,bb\\,
  120: """
  121: 
  122:         with tm.ensure_clean("test.csv") as path:
  123:             df.to_csv(path, quoting=3, escapechar="\\")  # QUOTE_NONE
  124:             with open(path, encoding="utf-8") as f:
  125:                 assert f.read() == expected
  126: 
  127:     def test_csv_to_string(self):
  128:         df = DataFrame({"col": [1, 2]})
  129:         expected_rows = [",col", "0,1", "1,2"]
  130:         expected = tm.convert_rows_list_to_csv_str(expected_rows)
  131:         assert df.to_csv() == expected
  132: 
  133:     def test_to_csv_decimal(self):
  134:         # see gh-781
  135:         df = DataFrame({"col1": [1], "col2": ["a"], "col3": [10.1]})
  136: 
  137:         expected_rows = [",col1,col2,col3", "0,1,a,10.1"]
  138:         expected_default = tm.convert_rows_list_to_csv_str(expected_rows)
  139:         assert df.to_csv() == expected_default
  140: 
  141:         expected_rows = [";col1;col2;col3", "0;1;a;10,1"]
  142:         expected_european_excel = tm.convert_rows_list_to_csv_str(expected_rows)
  143:         assert df.to_csv(decimal=",", sep=";") == expected_european_excel
  144: 
  145:         expected_rows = [",col1,col2,col3", "0,1,a,10.10"]
  146:         expected_float_format_default = tm.convert_rows_list_to_csv_str(expected_rows)
  147:         assert df.to_csv(float_format="%.2f") == expected_float_format_default
  148: 
  149:         expected_rows = [";col1;col2;col3", "0;1;a;10,10"]
  150:         expected_float_format = tm.convert_rows_list_to_csv_str(expected_rows)
  151:         assert (
  152:             df.to_csv(decimal=",", sep=";", float_format="%.2f")
  153:             == expected_float_format
  154:         )
  155: 
  156:         # see gh-11553: testing if decimal is taken into account for '0.0'
  157:         df = DataFrame({"a": [0, 1.1], "b": [2.2, 3.3], "c": 1})
  158: 
  159:         expected_rows = ["a,b,c", "0^0,2^2,1", "1^1,3^3,1"]
  160:         expected = tm.convert_rows_list_to_csv_str(expected_rows)
  161:         assert df.to_csv(index=False, decimal="^") == expected
  162: 
  163:         # same but for an index
  164:         assert df.set_index("a").to_csv(decimal="^") == expected
  165: 
  166:         # same for a multi-index
  167:         assert df.set_index(["a", "b"]).to_csv(decimal="^") == expected
  168: 
  169:     def test_to_csv_float_format(self):
  170:         # testing if float_format is taken into account for the index
  171:         # GH 11553
  172:         df = DataFrame({"a": [0, 1], "b": [2.2, 3.3], "c": 1})
  173: 
  174:         expected_rows = ["a,b,c", "0,2.20,1", "1,3.30,1"]
  175:         expected = tm.convert_rows_list_to_csv_str(expected_rows)
  176:         assert df.set_index("a").to_csv(float_format="%.2f") == expected
  177: 
  178:         # same for a multi-index
  179:         assert df.set_index(["a", "b"]).to_csv(float_format="%.2f") == expected
  180: 
  181:     def test_to_csv_na_rep(self):
  182:         # see gh-11553
  183:         #
  184:         # Testing if NaN values are correctly represented in the index.
  185:         df = DataFrame({"a": [0, np.nan], "b": [0, 1], "c": [2, 3]})
  186:         expected_rows = ["a,b,c", "0.0,0,2", "_,1,3"]
  187:         expected = tm.convert_rows_list_to_csv_str(expected_rows)
  188: 
  189:         assert df.set_index("a").to_csv(na_rep="_") == expected
  190:         assert df.set_index(["a", "b"]).to_csv(na_rep="_") == expected
  191: 
  192:         # now with an index containing only NaNs
  193:         df = DataFrame({"a": np.nan, "b": [0, 1], "c": [2, 3]})
  194:         expected_rows = ["a,b,c", "_,0,2", "_,1,3"]
  195:         expected = tm.convert_rows_list_to_csv_str(expected_rows)
  196: 
  197:         assert df.set_index("a").to_csv(na_rep="_") == expected
  198:         assert df.set_index(["a", "b"]).to_csv(na_rep="_") == expected
  199: 
  200:         # check if na_rep parameter does not break anything when no NaN
  201:         df = DataFrame({"a": 0, "b": [0, 1], "c": [2, 3]})
  202:         expected_rows = ["a,b,c", "0,0,2", "0,1,3"]
  203:         expected = tm.convert_rows_list_to_csv_str(expected_rows)
  204: 
  205:         assert df.set_index("a").to_csv(na_rep="_") == expected
  206:         assert df.set_index(["a", "b"]).to_csv(na_rep="_") == expected
  207: 
  208:         csv = pd.Series(["a", pd.NA, "c"]).to_csv(na_rep="ZZZZZ")
  209:         expected = tm.convert_rows_list_to_csv_str([",0", "0,a", "1,ZZZZZ", "2,c"])
  210:         assert expected == csv
  211: 
  212:     def test_to_csv_na_rep_nullable_string(self, nullable_string_dtype):
  213:         # GH 29975
  214:         # Make sure full na_rep shows up when a dtype is provided
  215:         expected = tm.convert_rows_list_to_csv_str([",0", "0,a", "1,ZZZZZ", "2,c"])
  216:         csv = pd.Series(["a", pd.NA, "c"], dtype=nullable_string_dtype).to_csv(
  217:             na_rep="ZZZZZ"
  218:         )
  219:         assert expected == csv
  220: 
  221:     def test_to_csv_date_format(self):
  222:         # GH 10209
  223:         df_sec = DataFrame({"A": pd.date_range("20130101", periods=5, freq="s")})
  224:         df_day = DataFrame({"A": pd.date_range("20130101", periods=5, freq="d")})
  225: 
  226:         expected_rows = [
  227:             ",A",
  228:             "0,2013-01-01 00:00:00",
  229:             "1,2013-01-01 00:00:01",
  230:             "2,2013-01-01 00:00:02",
  231:             "3,2013-01-01 00:00:03",
  232:             "4,2013-01-01 00:00:04",
  233:         ]
  234:         expected_default_sec = tm.convert_rows_list_to_csv_str(expected_rows)
  235:         assert df_sec.to_csv() == expected_default_sec
  236: 
  237:         expected_rows = [
  238:             ",A",
  239:             "0,2013-01-01 00:00:00",
  240:             "1,2013-01-02 00:00:00",
  241:             "2,2013-01-03 00:00:00",
  242:             "3,2013-01-04 00:00:00",
  243:             "4,2013-01-05 00:00:00",
  244:         ]
  245:         expected_ymdhms_day = tm.convert_rows_list_to_csv_str(expected_rows)
  246:         assert df_day.to_csv(date_format="%Y-%m-%d %H:%M:%S") == expected_ymdhms_day
  247: 
  248:         expected_rows = [
  249:             ",A",
  250:             "0,2013-01-01",
  251:             "1,2013-01-01",
  252:             "2,2013-01-01",
  253:             "3,2013-01-01",
  254:             "4,2013-01-01",
  255:         ]
  256:         expected_ymd_sec = tm.convert_rows_list_to_csv_str(expected_rows)
  257:         assert df_sec.to_csv(date_format="%Y-%m-%d") == expected_ymd_sec
  258: 
  259:         expected_rows = [
  260:             ",A",
  261:             "0,2013-01-01",
  262:             "1,2013-01-02",
  263:             "2,2013-01-03",
  264:             "3,2013-01-04",
  265:             "4,2013-01-05",
  266:         ]
  267:         expected_default_day = tm.convert_rows_list_to_csv_str(expected_rows)
  268:         assert df_day.to_csv() == expected_default_day
  269:         assert df_day.to_csv(date_format="%Y-%m-%d") == expected_default_day
  270: 
  271:         # see gh-7791
  272:         #
  273:         # Testing if date_format parameter is taken into account
  274:         # for multi-indexed DataFrames.
  275:         df_sec["B"] = 0
  276:         df_sec["C"] = 1
  277: 
  278:         expected_rows = ["A,B,C", "2013-01-01,0,1.0"]
  279:         expected_ymd_sec = tm.convert_rows_list_to_csv_str(expected_rows)
  280: 
  281:         df_sec_grouped = df_sec.groupby([pd.Grouper(key="A", freq="1h"), "B"])
  282:         assert df_sec_grouped.mean().to_csv(date_format="%Y-%m-%d") == expected_ymd_sec
  283: 
  284:     def test_to_csv_different_datetime_formats(self):
  285:         # GH#21734
  286:         df = DataFrame(
  287:             {
  288:                 "date": pd.to_datetime("1970-01-01"),
  289:                 "datetime": pd.date_range("1970-01-01", periods=2, freq="h"),
  290:             }
  291:         )
  292:         expected_rows = [
  293:             "date,datetime",
  294:             "1970-01-01,1970-01-01 00:00:00",
  295:             "1970-01-01,1970-01-01 01:00:00",
  296:         ]
  297:         expected = tm.convert_rows_list_to_csv_str(expected_rows)
  298:         assert df.to_csv(index=False) == expected
  299: 
  300:     def test_to_csv_date_format_in_categorical(self):
  301:         # GH#40754
  302:         ser = pd.Series(pd.to_datetime(["2021-03-27", pd.NaT], format="%Y-%m-%d"))
  303:         ser = ser.astype("category")
  304:         expected = tm.convert_rows_list_to_csv_str(["0", "2021-03-27", '""'])
  305:         assert ser.to_csv(index=False) == expected
  306: 
  307:         ser = pd.Series(
  308:             pd.date_range(
  309:                 start="2021-03-27", freq="D", periods=1, tz="Europe/Berlin"
  310:             ).append(pd.DatetimeIndex([pd.NaT]))
  311:         )
  312:         ser = ser.astype("category")
  313:         assert ser.to_csv(index=False, date_format="%Y-%m-%d") == expected
  314: 
  315:     def test_to_csv_float_ea_float_format(self):
  316:         # GH#45991
  317:         df = DataFrame({"a": [1.1, 2.02, pd.NA, 6.000006], "b": "c"})
  318:         df["a"] = df["a"].astype("Float64")
  319:         result = df.to_csv(index=False, float_format="%.5f")
  320:         expected = tm.convert_rows_list_to_csv_str(
  321:             ["a,b", "1.10000,c", "2.02000,c", ",c", "6.00001,c"]
  322:         )
  323:         assert result == expected
  324: 
  325:     def test_to_csv_float_ea_no_float_format(self):
  326:         # GH#45991
  327:         df = DataFrame({"a": [1.1, 2.02, pd.NA, 6.000006], "b": "c"})
  328:         df["a"] = df["a"].astype("Float64")
  329:         result = df.to_csv(index=False)
  330:         expected = tm.convert_rows_list_to_csv_str(
  331:             ["a,b", "1.1,c", "2.02,c", ",c", "6.000006,c"]
  332:         )
  333:         assert result == expected
  334: 
  335:     def test_to_csv_multi_index(self):
  336:         # see gh-6618
  337:         df = DataFrame([1], columns=pd.MultiIndex.from_arrays([[1], [2]]))
  338: 
  339:         exp_rows = [",1", ",2", "0,1"]
  340:         exp = tm.convert_rows_list_to_csv_str(exp_rows)
  341:         assert df.to_csv() == exp
  342: 
  343:         exp_rows = ["1", "2", "1"]
  344:         exp = tm.convert_rows_list_to_csv_str(exp_rows)
  345:         assert df.to_csv(index=False) == exp
  346: 
  347:         df = DataFrame(
  348:             [1],
  349:             columns=pd.MultiIndex.from_arrays([[1], [2]]),
  350:             index=pd.MultiIndex.from_arrays([[1], [2]]),
  351:         )
  352: 
  353:         exp_rows = [",,1", ",,2", "1,2,1"]
  354:         exp = tm.convert_rows_list_to_csv_str(exp_rows)
  355:         assert df.to_csv() == exp
  356: 
  357:         exp_rows = ["1", "2", "1"]
  358:         exp = tm.convert_rows_list_to_csv_str(exp_rows)
  359:         assert df.to_csv(index=False) == exp
  360: 
  361:         df = DataFrame([1], columns=pd.MultiIndex.from_arrays([["foo"], ["bar"]]))
  362: 
  363:         exp_rows = [",foo", ",bar", "0,1"]
  364:         exp = tm.convert_rows_list_to_csv_str(exp_rows)
  365:         assert df.to_csv() == exp
  366: 
  367:         exp_rows = ["foo", "bar", "1"]
  368:         exp = tm.convert_rows_list_to_csv_str(exp_rows)
  369:         assert df.to_csv(index=False) == exp
  370: 
  371:     @pytest.mark.parametrize(
  372:         "ind,expected",
  373:         [
  374:             (
  375:                 pd.MultiIndex(levels=[[1.0]], codes=[[0]], names=["x"]),
  376:                 "x,data\n1.0,1\n",
  377:             ),
  378:             (
  379:                 pd.MultiIndex(
  380:                     levels=[[1.0], [2.0]], codes=[[0], [0]], names=["x", "y"]
  381:                 ),
  382:                 "x,y,data\n1.0,2.0,1\n",
  383:             ),
  384:         ],
  385:     )
  386:     def test_to_csv_single_level_multi_index(self, ind, expected, frame_or_series):
  387:         # see gh-19589
  388:         obj = frame_or_series(pd.Series([1], ind, name="data"))
  389: 
  390:         result = obj.to_csv(lineterminator="\n", header=True)
  391:         assert result == expected
  392: 
  393:     def test_to_csv_string_array_ascii(self):
  394:         # GH 10813
  395:         str_array = [{"names": ["foo", "bar"]}, {"names": ["baz", "qux"]}]
  396:         df = DataFrame(str_array)
  397:         expected_ascii = """\
  398: ,names
  399: 0,"['foo', 'bar']"
  400: 1,"['baz', 'qux']"
  401: """
  402:         with tm.ensure_clean("str_test.csv") as path:
  403:             df.to_csv(path, encoding="ascii")
  404:             with open(path, encoding="utf-8") as f:
  405:                 assert f.read() == expected_ascii
  406: 
  407:     def test_to_csv_string_array_utf8(self):
  408:         # GH 10813
  409:         str_array = [{"names": ["foo", "bar"]}, {"names": ["baz", "qux"]}]
  410:         df = DataFrame(str_array)
  411:         expected_utf8 = """\
  412: ,names
  413: 0,"['foo', 'bar']"
  414: 1,"['baz', 'qux']"
  415: """
  416:         with tm.ensure_clean("unicode_test.csv") as path:
  417:             df.to_csv(path, encoding="utf-8")
  418:             with open(path, encoding="utf-8") as f:
  419:                 assert f.read() == expected_utf8
  420: 
  421:     def test_to_csv_string_with_lf(self):
  422:         # GH 20353
  423:         data = {"int": [1, 2, 3], "str_lf": ["abc", "d\nef", "g\nh\n\ni"]}
  424:         df = DataFrame(data)
  425:         with tm.ensure_clean("lf_test.csv") as path:
  426:             # case 1: The default line terminator(=os.linesep)(PR 21406)
  427:             os_linesep = os.linesep.encode("utf-8")
  428:             expected_noarg = (
  429:                 b"int,str_lf"
  430:                 + os_linesep
  431:                 + b"1,abc"
  432:                 + os_linesep
  433:                 + b'2,"d\nef"'
  434:                 + os_linesep
  435:                 + b'3,"g\nh\n\ni"'
  436:                 + os_linesep
  437:             )
  438:             df.to_csv(path, index=False)
  439:             with open(path, "rb") as f:
  440:                 assert f.read() == expected_noarg
  441:         with tm.ensure_clean("lf_test.csv") as path:
  442:             # case 2: LF as line terminator
  443:             expected_lf = b'int,str_lf\n1,abc\n2,"d\nef"\n3,"g\nh\n\ni"\n'
  444:             df.to_csv(path, lineterminator="\n", index=False)
  445:             with open(path, "rb") as f:
  446:                 assert f.read() == expected_lf
  447:         with tm.ensure_clean("lf_test.csv") as path:
  448:             # case 3: CRLF as line terminator
  449:             # 'lineterminator' should not change inner element
  450:             expected_crlf = b'int,str_lf\r\n1,abc\r\n2,"d\nef"\r\n3,"g\nh\n\ni"\r\n'
  451:             df.to_csv(path, lineterminator="\r\n", index=False)
  452:             with open(path, "rb") as f:
  453:                 assert f.read() == expected_crlf
  454: 
  455:     def test_to_csv_string_with_crlf(self):
  456:         # GH 20353
  457:         data = {"int": [1, 2, 3], "str_crlf": ["abc", "d\r\nef", "g\r\nh\r\n\r\ni"]}
  458:         df = DataFrame(data)
  459:         with tm.ensure_clean("crlf_test.csv") as path:
  460:             # case 1: The default line terminator(=os.linesep)(PR 21406)
  461:             os_linesep = os.linesep.encode("utf-8")
  462:             expected_noarg = (
  463:                 b"int,str_crlf"
  464:                 + os_linesep
  465:                 + b"1,abc"
  466:                 + os_linesep
  467:                 + b'2,"d\r\nef"'
  468:                 + os_linesep
  469:                 + b'3,"g\r\nh\r\n\r\ni"'
  470:                 + os_linesep
  471:             )
  472:             df.to_csv(path, index=False)
  473:             with open(path, "rb") as f:
  474:                 assert f.read() == expected_noarg
  475:         with tm.ensure_clean("crlf_test.csv") as path:
  476:             # case 2: LF as line terminator
  477:             expected_lf = b'int,str_crlf\n1,abc\n2,"d\r\nef"\n3,"g\r\nh\r\n\r\ni"\n'
  478:             df.to_csv(path, lineterminator="\n", index=False)
  479:             with open(path, "rb") as f:
  480:                 assert f.read() == expected_lf
  481:         with tm.ensure_clean("crlf_test.csv") as path:
  482:             # case 3: CRLF as line terminator
  483:             # 'lineterminator' should not change inner element
  484:             expected_crlf = (
  485:                 b"int,str_crlf\r\n"
  486:                 b"1,abc\r\n"
  487:                 b'2,"d\r\nef"\r\n'
  488:                 b'3,"g\r\nh\r\n\r\ni"\r\n'
  489:             )
  490:             df.to_csv(path, lineterminator="\r\n", index=False)
  491:             with open(path, "rb") as f:
  492:                 assert f.read() == expected_crlf
  493: 
  494:     def test_to_csv_stdout_file(self, capsys):
  495:         # GH 21561
  496:         df = DataFrame([["foo", "bar"], ["baz", "qux"]], columns=["name_1", "name_2"])
  497:         expected_rows = [",name_1,name_2", "0,foo,bar", "1,baz,qux"]
  498:         expected_ascii = tm.convert_rows_list_to_csv_str(expected_rows)
  499: 
  500:         df.to_csv(sys.stdout, encoding="ascii")
  501:         captured = capsys.readouterr()
  502: 
  503:         assert captured.out == expected_ascii
  504:         assert not sys.stdout.closed
  505: 
  506:     @pytest.mark.xfail(
  507:         compat.is_platform_windows(),
  508:         reason=(
  509:             "Especially in Windows, file stream should not be passed"
  510:             "to csv writer without newline='' option."
  511:             "(https://docs.python.org/3/library/csv.html#csv.writer)"
  512:         ),
  513:     )
  514:     def test_to_csv_write_to_open_file(self):
  515:         # GH 21696
  516:         df = DataFrame({"a": ["x", "y", "z"]})
  517:         expected = """\
  518: manual header
  519: x
  520: y
  521: z
  522: """
  523:         with tm.ensure_clean("test.txt") as path:
  524:             with open(path, "w", encoding="utf-8") as f:
  525:                 f.write("manual header\n")
  526:                 df.to_csv(f, header=None, index=None)
  527:             with open(path, encoding="utf-8") as f:
  528:                 assert f.read() == expected
  529: 
  530:     def test_to_csv_write_to_open_file_with_newline_py3(self):
  531:         # see gh-21696
  532:         # see gh-20353
  533:         df = DataFrame({"a": ["x", "y", "z"]})
  534:         expected_rows = ["x", "y", "z"]
  535:         expected = "manual header\n" + tm.convert_rows_list_to_csv_str(expected_rows)
  536:         with tm.ensure_clean("test.txt") as path:
  537:             with open(path, "w", newline="", encoding="utf-8") as f:
  538:                 f.write("manual header\n")
  539:                 df.to_csv(f, header=None, index=None)
  540: 
  541:             with open(path, "rb") as f:
  542:                 assert f.read() == bytes(expected, "utf-8")
  543: 
  544:     @pytest.mark.parametrize("to_infer", [True, False])
  545:     @pytest.mark.parametrize("read_infer", [True, False])
  546:     def test_to_csv_compression(
  547:         self, compression_only, read_infer, to_infer, compression_to_extension
  548:     ):
  549:         # see gh-15008
  550:         compression = compression_only
  551: 
  552:         # We'll complete file extension subsequently.
  553:         filename = "test."
  554:         filename += compression_to_extension[compression]
  555: 
  556:         df = DataFrame({"A": [1]})
  557: 
  558:         to_compression = "infer" if to_infer else compression
  559:         read_compression = "infer" if read_infer else compression
  560: 
  561:         with tm.ensure_clean(filename) as path:
  562:             df.to_csv(path, compression=to_compression)
  563:             result = pd.read_csv(path, index_col=0, compression=read_compression)
  564:             tm.assert_frame_equal(result, df)
  565: 
  566:     def test_to_csv_compression_dict(self, compression_only):
  567:         # GH 26023
  568:         method = compression_only
  569:         df = DataFrame({"ABC": [1]})
  570:         filename = "to_csv_compress_as_dict."
  571:         extension = {
  572:             "gzip": "gz",
  573:             "zstd": "zst",
  574:         }.get(method, method)
  575:         filename += extension
  576:         with tm.ensure_clean(filename) as path:
  577:             df.to_csv(path, compression={"method": method})
  578:             read_df = pd.read_csv(path, index_col=0)
  579:             tm.assert_frame_equal(read_df, df)
  580: 
  581:     def test_to_csv_compression_dict_no_method_raises(self):
  582:         # GH 26023
  583:         df = DataFrame({"ABC": [1]})
  584:         compression = {"some_option": True}
  585:         msg = "must have key 'method'"
  586: 
  587:         with tm.ensure_clean("out.zip") as path:
  588:             with pytest.raises(ValueError, match=msg):
  589:                 df.to_csv(path, compression=compression)
  590: 
  591:     @pytest.mark.parametrize("compression", ["zip", "infer"])
  592:     @pytest.mark.parametrize("archive_name", ["test_to_csv.csv", "test_to_csv.zip"])
  593:     def test_to_csv_zip_arguments(self, compression, archive_name):
  594:         # GH 26023
  595:         df = DataFrame({"ABC": [1]})
  596:         with tm.ensure_clean("to_csv_archive_name.zip") as path:
  597:             df.to_csv(
  598:                 path, compression={"method": compression, "archive_name": archive_name}
  599:             )
  600:             with ZipFile(path) as zp:
  601:                 assert len(zp.filelist) == 1
  602:                 archived_file = zp.filelist[0].filename
  603:                 assert archived_file == archive_name
  604: 
  605:     @pytest.mark.parametrize(
  606:         "filename,expected_arcname",
  607:         [
  608:             ("archive.csv", "archive.csv"),
  609:             ("archive.tsv", "archive.tsv"),
  610:             ("archive.csv.zip", "archive.csv"),
  611:             ("archive.tsv.zip", "archive.tsv"),
  612:             ("archive.zip", "archive"),
  613:         ],
  614:     )
  615:     def test_to_csv_zip_infer_name(self, tmp_path, filename, expected_arcname):
  616:         # GH 39465
  617:         df = DataFrame({"ABC": [1]})
  618:         path = tmp_path / filename
  619:         df.to_csv(path, compression="zip")
  620:         with ZipFile(path) as zp:
  621:             assert len(zp.filelist) == 1
  622:             archived_file = zp.filelist[0].filename
  623:             assert archived_file == expected_arcname
  624: 
  625:     @pytest.mark.parametrize("df_new_type", ["Int64"])
  626:     def test_to_csv_na_rep_long_string(self, df_new_type):
  627:         # see gh-25099
  628:         df = DataFrame({"c": [float("nan")] * 3})
  629:         df = df.astype(df_new_type)
  630:         expected_rows = ["c", "mynull", "mynull", "mynull"]
  631:         expected = tm.convert_rows_list_to_csv_str(expected_rows)
  632: 
  633:         result = df.to_csv(index=False, na_rep="mynull", encoding="ascii")
  634: 
  635:         assert expected == result
  636: 
  637:     def test_to_csv_timedelta_precision(self):
  638:         # GH 6783
  639:         s = pd.Series([1, 1]).astype("timedelta64[ns]")
  640:         buf = io.StringIO()
  641:         s.to_csv(buf)
  642:         result = buf.getvalue()
  643:         expected_rows = [
  644:             ",0",
  645:             "0,0 days 00:00:00.000000001",
  646:             "1,0 days 00:00:00.000000001",
  647:         ]
  648:         expected = tm.convert_rows_list_to_csv_str(expected_rows)
  649:         assert result == expected
  650: 
  651:     def test_na_rep_truncated(self):
  652:         # https://github.com/pandas-dev/pandas/issues/31447
  653:         result = pd.Series(range(8, 12)).to_csv(na_rep="-")
  654:         expected = tm.convert_rows_list_to_csv_str([",0", "0,8", "1,9", "2,10", "3,11"])
  655:         assert result == expected
  656: 
  657:         result = pd.Series([True, False]).to_csv(na_rep="nan")
  658:         expected = tm.convert_rows_list_to_csv_str([",0", "0,True", "1,False"])
  659:         assert result == expected
  660: 
  661:         result = pd.Series([1.1, 2.2]).to_csv(na_rep=".")
  662:         expected = tm.convert_rows_list_to_csv_str([",0", "0,1.1", "1,2.2"])
  663:         assert result == expected
  664: 
  665:     @pytest.mark.parametrize("errors", ["surrogatepass", "ignore", "replace"])
  666:     def test_to_csv_errors(self, errors):
  667:         # GH 22610
  668:         data = ["\ud800foo"]
  669:         ser = pd.Series(data, index=Index(data, dtype=object), dtype=object)
  670:         with tm.ensure_clean("test.csv") as path:
  671:             ser.to_csv(path, errors=errors)
  672:         # No use in reading back the data as it is not the same anymore
  673:         # due to the error handling
  674: 
  675:     @pytest.mark.parametrize("mode", ["wb", "w"])
  676:     def test_to_csv_binary_handle(self, mode):
  677:         """
  678:         Binary file objects should work (if 'mode' contains a 'b') or even without
  679:         it in most cases.
  680: 
  681:         GH 35058 and GH 19827
  682:         """
  683:         df = DataFrame(
  684:             1.1 * np.arange(120).reshape((30, 4)),
  685:             columns=Index(list("ABCD")),
  686:             index=Index([f"i-{i}" for i in range(30)]),
  687:         )
  688:         with tm.ensure_clean() as path:
  689:             with open(path, mode="w+b") as handle:
  690:                 df.to_csv(handle, mode=mode)
  691:             tm.assert_frame_equal(df, pd.read_csv(path, index_col=0))
  692: 
  693:     @pytest.mark.parametrize("mode", ["wb", "w"])
  694:     def test_to_csv_encoding_binary_handle(self, mode):
  695:         """
  696:         Binary file objects should honor a specified encoding.
  697: 
  698:         GH 23854 and GH 13068 with binary handles
  699:         """
  700:         # example from GH 23854
  701:         content = "a, b, рџђџ".encode("utf-8-sig")
  702:         buffer = io.BytesIO(content)
  703:         df = pd.read_csv(buffer, encoding="utf-8-sig")
  704: 
  705:         buffer = io.BytesIO()
  706:         df.to_csv(buffer, mode=mode, encoding="utf-8-sig", index=False)
  707:         buffer.seek(0)  # tests whether file handle wasn't closed
  708:         assert buffer.getvalue().startswith(content)
  709: 
  710:         # example from GH 13068
  711:         with tm.ensure_clean() as path:
  712:             with open(path, "w+b") as handle:
  713:                 DataFrame().to_csv(handle, mode=mode, encoding="utf-8-sig")
  714: 
  715:                 handle.seek(0)
  716:                 assert handle.read().startswith(b'\xef\xbb\xbf""')
  717: 
  718: 
  719: def test_to_csv_iterative_compression_name(compression):
  720:     # GH 38714
  721:     df = DataFrame(
  722:         1.1 * np.arange(120).reshape((30, 4)),
  723:         columns=Index(list("ABCD")),
  724:         index=Index([f"i-{i}" for i in range(30)]),
  725:     )
  726:     with tm.ensure_clean() as path:
  727:         df.to_csv(path, compression=compression, chunksize=1)
  728:         tm.assert_frame_equal(
  729:             pd.read_csv(path, compression=compression, index_col=0), df
  730:         )
  731: 
  732: 
  733: def test_to_csv_iterative_compression_buffer(compression):
  734:     # GH 38714
  735:     df = DataFrame(
  736:         1.1 * np.arange(120).reshape((30, 4)),
  737:         columns=Index(list("ABCD")),
  738:         index=Index([f"i-{i}" for i in range(30)]),
  739:     )
  740:     with io.BytesIO() as buffer:
  741:         df.to_csv(buffer, compression=compression, chunksize=1)
  742:         buffer.seek(0)
  743:         tm.assert_frame_equal(
  744:             pd.read_csv(buffer, compression=compression, index_col=0), df
  745:         )
  746:         assert not buffer.closed
  747: 
  748: 
  749: def test_to_csv_pos_args_deprecation():
  750:     # GH-54229
  751:     df = DataFrame({"a": [1, 2, 3]})
  752:     msg = (
  753:         r"Starting with pandas version 3.0 all arguments of to_csv except for the "
  754:         r"argument 'path_or_buf' will be keyword-only."
  755:     )
  756:     with tm.assert_produces_warning(FutureWarning, match=msg):
  757:         buffer = io.BytesIO()
  758:         df.to_csv(buffer, ";")
