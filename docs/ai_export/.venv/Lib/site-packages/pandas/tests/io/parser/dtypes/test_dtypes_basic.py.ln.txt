    1: """
    2: Tests dtype specification during parsing
    3: for all of the parsers defined in parsers.py
    4: """
    5: from collections import defaultdict
    6: from io import StringIO
    7: 
    8: import numpy as np
    9: import pytest
   10: 
   11: from pandas.errors import ParserWarning
   12: 
   13: import pandas as pd
   14: from pandas import (
   15:     DataFrame,
   16:     Timestamp,
   17: )
   18: import pandas._testing as tm
   19: from pandas.core.arrays import (
   20:     ArrowStringArray,
   21:     IntegerArray,
   22:     StringArray,
   23: )
   24: 
   25: pytestmark = pytest.mark.filterwarnings(
   26:     "ignore:Passing a BlockManager to DataFrame:DeprecationWarning"
   27: )
   28: 
   29: 
   30: @pytest.mark.parametrize("dtype", [str, object])
   31: @pytest.mark.parametrize("check_orig", [True, False])
   32: @pytest.mark.usefixtures("pyarrow_xfail")
   33: def test_dtype_all_columns(all_parsers, dtype, check_orig):
   34:     # see gh-3795, gh-6607
   35:     parser = all_parsers
   36: 
   37:     df = DataFrame(
   38:         np.random.default_rng(2).random((5, 2)).round(4),
   39:         columns=list("AB"),
   40:         index=["1A", "1B", "1C", "1D", "1E"],
   41:     )
   42: 
   43:     with tm.ensure_clean("__passing_str_as_dtype__.csv") as path:
   44:         df.to_csv(path)
   45: 
   46:         result = parser.read_csv(path, dtype=dtype, index_col=0)
   47: 
   48:         if check_orig:
   49:             expected = df.copy()
   50:             result = result.astype(float)
   51:         else:
   52:             expected = df.astype(str)
   53: 
   54:         tm.assert_frame_equal(result, expected)
   55: 
   56: 
   57: @pytest.mark.usefixtures("pyarrow_xfail")
   58: def test_dtype_per_column(all_parsers):
   59:     parser = all_parsers
   60:     data = """\
   61: one,two
   62: 1,2.5
   63: 2,3.5
   64: 3,4.5
   65: 4,5.5"""
   66:     expected = DataFrame(
   67:         [[1, "2.5"], [2, "3.5"], [3, "4.5"], [4, "5.5"]], columns=["one", "two"]
   68:     )
   69:     expected["one"] = expected["one"].astype(np.float64)
   70:     expected["two"] = expected["two"].astype(object)
   71: 
   72:     result = parser.read_csv(StringIO(data), dtype={"one": np.float64, 1: str})
   73:     tm.assert_frame_equal(result, expected)
   74: 
   75: 
   76: def test_invalid_dtype_per_column(all_parsers):
   77:     parser = all_parsers
   78:     data = """\
   79: one,two
   80: 1,2.5
   81: 2,3.5
   82: 3,4.5
   83: 4,5.5"""
   84: 
   85:     with pytest.raises(TypeError, match="data type [\"']foo[\"'] not understood"):
   86:         parser.read_csv(StringIO(data), dtype={"one": "foo", 1: "int"})
   87: 
   88: 
   89: def test_raise_on_passed_int_dtype_with_nas(all_parsers):
   90:     # see gh-2631
   91:     parser = all_parsers
   92:     data = """YEAR, DOY, a
   93: 2001,106380451,10
   94: 2001,,11
   95: 2001,106380451,67"""
   96: 
   97:     if parser.engine == "c":
   98:         msg = "Integer column has NA values"
   99:     elif parser.engine == "pyarrow":
  100:         msg = "The 'skipinitialspace' option is not supported with the 'pyarrow' engine"
  101:     else:
  102:         msg = "Unable to convert column DOY"
  103: 
  104:     with pytest.raises(ValueError, match=msg):
  105:         parser.read_csv(StringIO(data), dtype={"DOY": np.int64}, skipinitialspace=True)
  106: 
  107: 
  108: def test_dtype_with_converters(all_parsers):
  109:     parser = all_parsers
  110:     data = """a,b
  111: 1.1,2.2
  112: 1.2,2.3"""
  113: 
  114:     if parser.engine == "pyarrow":
  115:         msg = "The 'converters' option is not supported with the 'pyarrow' engine"
  116:         with pytest.raises(ValueError, match=msg):
  117:             parser.read_csv(
  118:                 StringIO(data), dtype={"a": "i8"}, converters={"a": lambda x: str(x)}
  119:             )
  120:         return
  121: 
  122:     # Dtype spec ignored if converted specified.
  123:     result = parser.read_csv_check_warnings(
  124:         ParserWarning,
  125:         "Both a converter and dtype were specified for column a "
  126:         "- only the converter will be used.",
  127:         StringIO(data),
  128:         dtype={"a": "i8"},
  129:         converters={"a": lambda x: str(x)},
  130:     )
  131:     expected = DataFrame({"a": ["1.1", "1.2"], "b": [2.2, 2.3]})
  132:     tm.assert_frame_equal(result, expected)
  133: 
  134: 
  135: @pytest.mark.parametrize(
  136:     "dtype", list(np.typecodes["AllInteger"] + np.typecodes["Float"])
  137: )
  138: def test_numeric_dtype(all_parsers, dtype):
  139:     data = "0\n1"
  140:     parser = all_parsers
  141:     expected = DataFrame([0, 1], dtype=dtype)
  142: 
  143:     result = parser.read_csv(StringIO(data), header=None, dtype=dtype)
  144:     tm.assert_frame_equal(expected, result)
  145: 
  146: 
  147: @pytest.mark.usefixtures("pyarrow_xfail")
  148: def test_boolean_dtype(all_parsers):
  149:     parser = all_parsers
  150:     data = "\n".join(
  151:         [
  152:             "a",
  153:             "True",
  154:             "TRUE",
  155:             "true",
  156:             "1",
  157:             "1.0",
  158:             "False",
  159:             "FALSE",
  160:             "false",
  161:             "0",
  162:             "0.0",
  163:             "NaN",
  164:             "nan",
  165:             "NA",
  166:             "null",
  167:             "NULL",
  168:         ]
  169:     )
  170: 
  171:     result = parser.read_csv(StringIO(data), dtype="boolean")
  172:     expected = DataFrame(
  173:         {
  174:             "a": pd.array(
  175:                 [
  176:                     True,
  177:                     True,
  178:                     True,
  179:                     True,
  180:                     True,
  181:                     False,
  182:                     False,
  183:                     False,
  184:                     False,
  185:                     False,
  186:                     None,
  187:                     None,
  188:                     None,
  189:                     None,
  190:                     None,
  191:                 ],
  192:                 dtype="boolean",
  193:             )
  194:         }
  195:     )
  196: 
  197:     tm.assert_frame_equal(result, expected)
  198: 
  199: 
  200: @pytest.mark.usefixtures("pyarrow_xfail")
  201: def test_delimiter_with_usecols_and_parse_dates(all_parsers):
  202:     # GH#35873
  203:     result = all_parsers.read_csv(
  204:         StringIO('"dump","-9,1","-9,1",20101010'),
  205:         engine="python",
  206:         names=["col", "col1", "col2", "col3"],
  207:         usecols=["col1", "col2", "col3"],
  208:         parse_dates=["col3"],
  209:         decimal=",",
  210:     )
  211:     expected = DataFrame(
  212:         {"col1": [-9.1], "col2": [-9.1], "col3": [Timestamp("2010-10-10")]}
  213:     )
  214:     tm.assert_frame_equal(result, expected)
  215: 
  216: 
  217: @pytest.mark.parametrize("thousands", ["_", None])
  218: def test_decimal_and_exponential(
  219:     request, python_parser_only, numeric_decimal, thousands
  220: ):
  221:     # GH#31920
  222:     decimal_number_check(request, python_parser_only, numeric_decimal, thousands, None)
  223: 
  224: 
  225: @pytest.mark.parametrize("thousands", ["_", None])
  226: @pytest.mark.parametrize("float_precision", [None, "legacy", "high", "round_trip"])
  227: def test_1000_sep_decimal_float_precision(
  228:     request, c_parser_only, numeric_decimal, float_precision, thousands
  229: ):
  230:     # test decimal and thousand sep handling in across 'float_precision'
  231:     # parsers
  232:     decimal_number_check(
  233:         request, c_parser_only, numeric_decimal, thousands, float_precision
  234:     )
  235:     text, value = numeric_decimal
  236:     text = " " + text + " "
  237:     if isinstance(value, str):  # the negative cases (parse as text)
  238:         value = " " + value + " "
  239:     decimal_number_check(
  240:         request, c_parser_only, (text, value), thousands, float_precision
  241:     )
  242: 
  243: 
  244: def decimal_number_check(request, parser, numeric_decimal, thousands, float_precision):
  245:     # GH#31920
  246:     value = numeric_decimal[0]
  247:     if thousands is None and value in ("1_,", "1_234,56", "1_234,56e0"):
  248:         request.applymarker(
  249:             pytest.mark.xfail(reason=f"thousands={thousands} and sep is in {value}")
  250:         )
  251:     df = parser.read_csv(
  252:         StringIO(value),
  253:         float_precision=float_precision,
  254:         sep="|",
  255:         thousands=thousands,
  256:         decimal=",",
  257:         header=None,
  258:     )
  259:     val = df.iloc[0, 0]
  260:     assert val == numeric_decimal[1]
  261: 
  262: 
  263: @pytest.mark.parametrize("float_precision", [None, "legacy", "high", "round_trip"])
  264: def test_skip_whitespace(c_parser_only, float_precision):
  265:     DATA = """id\tnum\t
  266: 1\t1.2 \t
  267: 1\t 2.1\t
  268: 2\t 1\t
  269: 2\t 1.2 \t
  270: """
  271:     df = c_parser_only.read_csv(
  272:         StringIO(DATA),
  273:         float_precision=float_precision,
  274:         sep="\t",
  275:         header=0,
  276:         dtype={1: np.float64},
  277:     )
  278:     tm.assert_series_equal(df.iloc[:, 1], pd.Series([1.2, 2.1, 1.0, 1.2], name="num"))
  279: 
  280: 
  281: @pytest.mark.usefixtures("pyarrow_xfail")
  282: def test_true_values_cast_to_bool(all_parsers):
  283:     # GH#34655
  284:     text = """a,b
  285: yes,xxx
  286: no,yyy
  287: 1,zzz
  288: 0,aaa
  289:     """
  290:     parser = all_parsers
  291:     result = parser.read_csv(
  292:         StringIO(text),
  293:         true_values=["yes"],
  294:         false_values=["no"],
  295:         dtype={"a": "boolean"},
  296:     )
  297:     expected = DataFrame(
  298:         {"a": [True, False, True, False], "b": ["xxx", "yyy", "zzz", "aaa"]}
  299:     )
  300:     expected["a"] = expected["a"].astype("boolean")
  301:     tm.assert_frame_equal(result, expected)
  302: 
  303: 
  304: @pytest.mark.usefixtures("pyarrow_xfail")
  305: @pytest.mark.parametrize("dtypes, exp_value", [({}, "1"), ({"a.1": "int64"}, 1)])
  306: def test_dtype_mangle_dup_cols(all_parsers, dtypes, exp_value):
  307:     # GH#35211
  308:     parser = all_parsers
  309:     data = """a,a\n1,1"""
  310:     dtype_dict = {"a": str, **dtypes}
  311:     # GH#42462
  312:     dtype_dict_copy = dtype_dict.copy()
  313:     result = parser.read_csv(StringIO(data), dtype=dtype_dict)
  314:     expected = DataFrame({"a": ["1"], "a.1": [exp_value]})
  315:     assert dtype_dict == dtype_dict_copy, "dtype dict changed"
  316:     tm.assert_frame_equal(result, expected)
  317: 
  318: 
  319: @pytest.mark.usefixtures("pyarrow_xfail")
  320: def test_dtype_mangle_dup_cols_single_dtype(all_parsers):
  321:     # GH#42022
  322:     parser = all_parsers
  323:     data = """a,a\n1,1"""
  324:     result = parser.read_csv(StringIO(data), dtype=str)
  325:     expected = DataFrame({"a": ["1"], "a.1": ["1"]})
  326:     tm.assert_frame_equal(result, expected)
  327: 
  328: 
  329: @pytest.mark.usefixtures("pyarrow_xfail")
  330: def test_dtype_multi_index(all_parsers):
  331:     # GH 42446
  332:     parser = all_parsers
  333:     data = "A,B,B\nX,Y,Z\n1,2,3"
  334: 
  335:     result = parser.read_csv(
  336:         StringIO(data),
  337:         header=list(range(2)),
  338:         dtype={
  339:             ("A", "X"): np.int32,
  340:             ("B", "Y"): np.int32,
  341:             ("B", "Z"): np.float32,
  342:         },
  343:     )
  344: 
  345:     expected = DataFrame(
  346:         {
  347:             ("A", "X"): np.int32([1]),
  348:             ("B", "Y"): np.int32([2]),
  349:             ("B", "Z"): np.float32([3]),
  350:         }
  351:     )
  352: 
  353:     tm.assert_frame_equal(result, expected)
  354: 
  355: 
  356: def test_nullable_int_dtype(all_parsers, any_int_ea_dtype):
  357:     # GH 25472
  358:     parser = all_parsers
  359:     dtype = any_int_ea_dtype
  360: 
  361:     data = """a,b,c
  362: ,3,5
  363: 1,,6
  364: 2,4,"""
  365:     expected = DataFrame(
  366:         {
  367:             "a": pd.array([pd.NA, 1, 2], dtype=dtype),
  368:             "b": pd.array([3, pd.NA, 4], dtype=dtype),
  369:             "c": pd.array([5, 6, pd.NA], dtype=dtype),
  370:         }
  371:     )
  372:     actual = parser.read_csv(StringIO(data), dtype=dtype)
  373:     tm.assert_frame_equal(actual, expected)
  374: 
  375: 
  376: @pytest.mark.usefixtures("pyarrow_xfail")
  377: @pytest.mark.parametrize("default", ["float", "float64"])
  378: def test_dtypes_defaultdict(all_parsers, default):
  379:     # GH#41574
  380:     data = """a,b
  381: 1,2
  382: """
  383:     dtype = defaultdict(lambda: default, a="int64")
  384:     parser = all_parsers
  385:     result = parser.read_csv(StringIO(data), dtype=dtype)
  386:     expected = DataFrame({"a": [1], "b": 2.0})
  387:     tm.assert_frame_equal(result, expected)
  388: 
  389: 
  390: @pytest.mark.usefixtures("pyarrow_xfail")
  391: def test_dtypes_defaultdict_mangle_dup_cols(all_parsers):
  392:     # GH#41574
  393:     data = """a,b,a,b,b.1
  394: 1,2,3,4,5
  395: """
  396:     dtype = defaultdict(lambda: "float64", a="int64")
  397:     dtype["b.1"] = "int64"
  398:     parser = all_parsers
  399:     result = parser.read_csv(StringIO(data), dtype=dtype)
  400:     expected = DataFrame({"a": [1], "b": [2.0], "a.1": [3], "b.2": [4.0], "b.1": [5]})
  401:     tm.assert_frame_equal(result, expected)
  402: 
  403: 
  404: @pytest.mark.usefixtures("pyarrow_xfail")
  405: def test_dtypes_defaultdict_invalid(all_parsers):
  406:     # GH#41574
  407:     data = """a,b
  408: 1,2
  409: """
  410:     dtype = defaultdict(lambda: "invalid_dtype", a="int64")
  411:     parser = all_parsers
  412:     with pytest.raises(TypeError, match="not understood"):
  413:         parser.read_csv(StringIO(data), dtype=dtype)
  414: 
  415: 
  416: def test_dtype_backend(all_parsers):
  417:     # GH#36712
  418: 
  419:     parser = all_parsers
  420: 
  421:     data = """a,b,c,d,e,f,g,h,i,j
  422: 1,2.5,True,a,,,,,12-31-2019,
  423: 3,4.5,False,b,6,7.5,True,a,12-31-2019,
  424: """
  425:     result = parser.read_csv(
  426:         StringIO(data), dtype_backend="numpy_nullable", parse_dates=["i"]
  427:     )
  428:     expected = DataFrame(
  429:         {
  430:             "a": pd.Series([1, 3], dtype="Int64"),
  431:             "b": pd.Series([2.5, 4.5], dtype="Float64"),
  432:             "c": pd.Series([True, False], dtype="boolean"),
  433:             "d": pd.Series(["a", "b"], dtype="string"),
  434:             "e": pd.Series([pd.NA, 6], dtype="Int64"),
  435:             "f": pd.Series([pd.NA, 7.5], dtype="Float64"),
  436:             "g": pd.Series([pd.NA, True], dtype="boolean"),
  437:             "h": pd.Series([pd.NA, "a"], dtype="string"),
  438:             "i": pd.Series([Timestamp("2019-12-31")] * 2),
  439:             "j": pd.Series([pd.NA, pd.NA], dtype="Int64"),
  440:         }
  441:     )
  442:     tm.assert_frame_equal(result, expected)
  443: 
  444: 
  445: def test_dtype_backend_and_dtype(all_parsers):
  446:     # GH#36712
  447: 
  448:     parser = all_parsers
  449: 
  450:     data = """a,b
  451: 1,2.5
  452: ,
  453: """
  454:     result = parser.read_csv(
  455:         StringIO(data), dtype_backend="numpy_nullable", dtype="float64"
  456:     )
  457:     expected = DataFrame({"a": [1.0, np.nan], "b": [2.5, np.nan]})
  458:     tm.assert_frame_equal(result, expected)
  459: 
  460: 
  461: def test_dtype_backend_string(all_parsers, string_storage):
  462:     # GH#36712
  463:     pa = pytest.importorskip("pyarrow")
  464: 
  465:     with pd.option_context("mode.string_storage", string_storage):
  466:         parser = all_parsers
  467: 
  468:         data = """a,b
  469: a,x
  470: b,
  471: """
  472:         result = parser.read_csv(StringIO(data), dtype_backend="numpy_nullable")
  473: 
  474:         if string_storage == "python":
  475:             expected = DataFrame(
  476:                 {
  477:                     "a": StringArray(np.array(["a", "b"], dtype=np.object_)),
  478:                     "b": StringArray(np.array(["x", pd.NA], dtype=np.object_)),
  479:                 }
  480:             )
  481:         else:
  482:             expected = DataFrame(
  483:                 {
  484:                     "a": ArrowStringArray(pa.array(["a", "b"])),
  485:                     "b": ArrowStringArray(pa.array(["x", None])),
  486:                 }
  487:             )
  488:         tm.assert_frame_equal(result, expected)
  489: 
  490: 
  491: def test_dtype_backend_ea_dtype_specified(all_parsers):
  492:     # GH#491496
  493:     data = """a,b
  494: 1,2
  495: """
  496:     parser = all_parsers
  497:     result = parser.read_csv(
  498:         StringIO(data), dtype="Int64", dtype_backend="numpy_nullable"
  499:     )
  500:     expected = DataFrame({"a": [1], "b": 2}, dtype="Int64")
  501:     tm.assert_frame_equal(result, expected)
  502: 
  503: 
  504: def test_dtype_backend_pyarrow(all_parsers, request):
  505:     # GH#36712
  506:     pa = pytest.importorskip("pyarrow")
  507:     parser = all_parsers
  508: 
  509:     data = """a,b,c,d,e,f,g,h,i,j
  510: 1,2.5,True,a,,,,,12-31-2019,
  511: 3,4.5,False,b,6,7.5,True,a,12-31-2019,
  512: """
  513:     result = parser.read_csv(StringIO(data), dtype_backend="pyarrow", parse_dates=["i"])
  514:     expected = DataFrame(
  515:         {
  516:             "a": pd.Series([1, 3], dtype="int64[pyarrow]"),
  517:             "b": pd.Series([2.5, 4.5], dtype="float64[pyarrow]"),
  518:             "c": pd.Series([True, False], dtype="bool[pyarrow]"),
  519:             "d": pd.Series(["a", "b"], dtype=pd.ArrowDtype(pa.string())),
  520:             "e": pd.Series([pd.NA, 6], dtype="int64[pyarrow]"),
  521:             "f": pd.Series([pd.NA, 7.5], dtype="float64[pyarrow]"),
  522:             "g": pd.Series([pd.NA, True], dtype="bool[pyarrow]"),
  523:             "h": pd.Series(
  524:                 [pd.NA, "a"],
  525:                 dtype=pd.ArrowDtype(pa.string()),
  526:             ),
  527:             "i": pd.Series([Timestamp("2019-12-31")] * 2),
  528:             "j": pd.Series([pd.NA, pd.NA], dtype="null[pyarrow]"),
  529:         }
  530:     )
  531:     tm.assert_frame_equal(result, expected)
  532: 
  533: 
  534: # pyarrow engine failing:
  535: # https://github.com/pandas-dev/pandas/issues/56136
  536: @pytest.mark.usefixtures("pyarrow_xfail")
  537: def test_ea_int_avoid_overflow(all_parsers):
  538:     # GH#32134
  539:     parser = all_parsers
  540:     data = """a,b
  541: 1,1
  542: ,1
  543: 1582218195625938945,1
  544: """
  545:     result = parser.read_csv(StringIO(data), dtype={"a": "Int64"})
  546:     expected = DataFrame(
  547:         {
  548:             "a": IntegerArray(
  549:                 np.array([1, 1, 1582218195625938945]), np.array([False, True, False])
  550:             ),
  551:             "b": 1,
  552:         }
  553:     )
  554:     tm.assert_frame_equal(result, expected)
  555: 
  556: 
  557: def test_string_inference(all_parsers):
  558:     # GH#54430
  559:     pytest.importorskip("pyarrow")
  560:     dtype = "string[pyarrow_numpy]"
  561: 
  562:     data = """a,b
  563: x,1
  564: y,2
  565: ,3"""
  566:     parser = all_parsers
  567:     with pd.option_context("future.infer_string", True):
  568:         result = parser.read_csv(StringIO(data))
  569: 
  570:     expected = DataFrame(
  571:         {"a": pd.Series(["x", "y", None], dtype=dtype), "b": [1, 2, 3]},
  572:         columns=pd.Index(["a", "b"], dtype=dtype),
  573:     )
  574:     tm.assert_frame_equal(result, expected)
  575: 
  576: 
  577: @pytest.mark.parametrize("dtype", ["O", object, "object", np.object_, str, np.str_])
  578: def test_string_inference_object_dtype(all_parsers, dtype):
  579:     # GH#56047
  580:     pytest.importorskip("pyarrow")
  581: 
  582:     data = """a,b
  583: x,a
  584: y,a
  585: z,a"""
  586:     parser = all_parsers
  587:     with pd.option_context("future.infer_string", True):
  588:         result = parser.read_csv(StringIO(data), dtype=dtype)
  589: 
  590:     expected = DataFrame(
  591:         {
  592:             "a": pd.Series(["x", "y", "z"], dtype=object),
  593:             "b": pd.Series(["a", "a", "a"], dtype=object),
  594:         },
  595:         columns=pd.Index(["a", "b"], dtype="string[pyarrow_numpy]"),
  596:     )
  597:     tm.assert_frame_equal(result, expected)
  598: 
  599:     with pd.option_context("future.infer_string", True):
  600:         result = parser.read_csv(StringIO(data), dtype={"a": dtype})
  601: 
  602:     expected = DataFrame(
  603:         {
  604:             "a": pd.Series(["x", "y", "z"], dtype=object),
  605:             "b": pd.Series(["a", "a", "a"], dtype="string[pyarrow_numpy]"),
  606:         },
  607:         columns=pd.Index(["a", "b"], dtype="string[pyarrow_numpy]"),
  608:     )
  609:     tm.assert_frame_equal(result, expected)
  610: 
  611: 
  612: def test_accurate_parsing_of_large_integers(all_parsers):
  613:     # GH#52505
  614:     data = """SYMBOL,MOMENT,ID,ID_DEAL
  615: AAPL,20230301181139587,1925036343869802844,
  616: AAPL,20230301181139587,2023552585717889863,2023552585717263358
  617: NVDA,20230301181139587,2023552585717889863,2023552585717263359
  618: AMC,20230301181139587,2023552585717889863,2023552585717263360
  619: AMZN,20230301181139587,2023552585717889759,2023552585717263360
  620: MSFT,20230301181139587,2023552585717889863,2023552585717263361
  621: NVDA,20230301181139587,2023552585717889827,2023552585717263361"""
  622:     orders = pd.read_csv(StringIO(data), dtype={"ID_DEAL": pd.Int64Dtype()})
  623:     assert len(orders.loc[orders["ID_DEAL"] == 2023552585717263358, "ID_DEAL"]) == 1
  624:     assert len(orders.loc[orders["ID_DEAL"] == 2023552585717263359, "ID_DEAL"]) == 1
  625:     assert len(orders.loc[orders["ID_DEAL"] == 2023552585717263360, "ID_DEAL"]) == 2
  626:     assert len(orders.loc[orders["ID_DEAL"] == 2023552585717263361, "ID_DEAL"]) == 2
  627: 
  628: 
  629: def test_dtypes_with_usecols(all_parsers):
  630:     # GH#54868
  631: 
  632:     parser = all_parsers
  633:     data = """a,b,c
  634: 1,2,3
  635: 4,5,6"""
  636: 
  637:     result = parser.read_csv(StringIO(data), usecols=["a", "c"], dtype={"a": object})
  638:     if parser.engine == "pyarrow":
  639:         values = [1, 4]
  640:     else:
  641:         values = ["1", "4"]
  642:     expected = DataFrame({"a": pd.Series(values, dtype=object), "c": [3, 6]})
  643:     tm.assert_frame_equal(result, expected)
