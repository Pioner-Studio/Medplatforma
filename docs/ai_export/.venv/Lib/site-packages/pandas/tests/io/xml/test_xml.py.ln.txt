    1: from __future__ import annotations
    2: 
    3: from io import (
    4:     BytesIO,
    5:     StringIO,
    6: )
    7: from lzma import LZMAError
    8: import os
    9: from tarfile import ReadError
   10: from urllib.error import HTTPError
   11: from xml.etree.ElementTree import ParseError
   12: from zipfile import BadZipFile
   13: 
   14: import numpy as np
   15: import pytest
   16: 
   17: from pandas.compat._optional import import_optional_dependency
   18: from pandas.errors import (
   19:     EmptyDataError,
   20:     ParserError,
   21: )
   22: import pandas.util._test_decorators as td
   23: 
   24: import pandas as pd
   25: from pandas import (
   26:     NA,
   27:     DataFrame,
   28:     Series,
   29: )
   30: import pandas._testing as tm
   31: from pandas.core.arrays import (
   32:     ArrowStringArray,
   33:     StringArray,
   34: )
   35: from pandas.core.arrays.string_arrow import ArrowStringArrayNumpySemantics
   36: 
   37: from pandas.io.common import get_handle
   38: from pandas.io.xml import read_xml
   39: 
   40: # CHECK LIST
   41: 
   42: # [x] - ValueError: "Values for parser can only be lxml or etree."
   43: 
   44: # etree
   45: # [X] - ImportError: "lxml not found, please install or use the etree parser."
   46: # [X] - TypeError: "expected str, bytes or os.PathLike object, not NoneType"
   47: # [X] - ValueError: "Either element or attributes can be parsed not both."
   48: # [X] - ValueError: "xpath does not return any nodes..."
   49: # [X] - SyntaxError: "You have used an incorrect or unsupported XPath"
   50: # [X] - ValueError: "names does not match length of child elements in xpath."
   51: # [X] - TypeError: "...is not a valid type for names"
   52: # [X] - ValueError: "To use stylesheet, you need lxml installed..."
   53: # []  - URLError: (GENERAL ERROR WITH HTTPError AS SUBCLASS)
   54: # [X] - HTTPError: "HTTP Error 404: Not Found"
   55: # []  - OSError: (GENERAL ERROR WITH FileNotFoundError AS SUBCLASS)
   56: # [X] - FileNotFoundError: "No such file or directory"
   57: # []  - ParseError    (FAILSAFE CATCH ALL FOR VERY COMPLEX XML)
   58: # [X] - UnicodeDecodeError: "'utf-8' codec can't decode byte 0xe9..."
   59: # [X] - UnicodeError: "UTF-16 stream does not start with BOM"
   60: # [X] - BadZipFile: "File is not a zip file"
   61: # [X] - OSError: "Invalid data stream"
   62: # [X] - LZMAError: "Input format not supported by decoder"
   63: # [X] - ValueError: "Unrecognized compression type"
   64: # [X] - PermissionError: "Forbidden"
   65: 
   66: # lxml
   67: # [X] - ValueError: "Either element or attributes can be parsed not both."
   68: # [X] - AttributeError: "__enter__"
   69: # [X] - XSLTApplyError: "Cannot resolve URI"
   70: # [X] - XSLTParseError: "document is not a stylesheet"
   71: # [X] - ValueError: "xpath does not return any nodes."
   72: # [X] - XPathEvalError: "Invalid expression"
   73: # []  - XPathSyntaxError: (OLD VERSION IN lxml FOR XPATH ERRORS)
   74: # [X] - TypeError: "empty namespace prefix is not supported in XPath"
   75: # [X] - ValueError: "names does not match length of child elements in xpath."
   76: # [X] - TypeError: "...is not a valid type for names"
   77: # [X] - LookupError: "unknown encoding"
   78: # []  - URLError: (USUALLY DUE TO NETWORKING)
   79: # [X  - HTTPError: "HTTP Error 404: Not Found"
   80: # [X] - OSError: "failed to load external entity"
   81: # [X] - XMLSyntaxError: "Start tag expected, '<' not found"
   82: # []  - ParserError: (FAILSAFE CATCH ALL FOR VERY COMPLEX XML
   83: # [X] - ValueError: "Values for parser can only be lxml or etree."
   84: # [X] - UnicodeDecodeError: "'utf-8' codec can't decode byte 0xe9..."
   85: # [X] - UnicodeError: "UTF-16 stream does not start with BOM"
   86: # [X] - BadZipFile: "File is not a zip file"
   87: # [X] - OSError: "Invalid data stream"
   88: # [X] - LZMAError: "Input format not supported by decoder"
   89: # [X] - ValueError: "Unrecognized compression type"
   90: # [X] - PermissionError: "Forbidden"
   91: 
   92: geom_df = DataFrame(
   93:     {
   94:         "shape": ["square", "circle", "triangle"],
   95:         "degrees": [360, 360, 180],
   96:         "sides": [4, np.nan, 3],
   97:     }
   98: )
   99: 
  100: xml_default_nmsp = """\
  101: <?xml version='1.0' encoding='utf-8'?>
  102: <data xmlns="http://example.com">
  103:   <row>
  104:     <shape>square</shape>
  105:     <degrees>360</degrees>
  106:     <sides>4</sides>
  107:   </row>
  108:   <row>
  109:     <shape>circle</shape>
  110:     <degrees>360</degrees>
  111:     <sides/>
  112:   </row>
  113:   <row>
  114:     <shape>triangle</shape>
  115:     <degrees>180</degrees>
  116:     <sides>3</sides>
  117:   </row>
  118: </data>"""
  119: 
  120: xml_prefix_nmsp = """\
  121: <?xml version='1.0' encoding='utf-8'?>
  122: <doc:data xmlns:doc="http://example.com">
  123:   <doc:row>
  124:     <doc:shape>square</doc:shape>
  125:     <doc:degrees>360</doc:degrees>
  126:     <doc:sides>4.0</doc:sides>
  127:   </doc:row>
  128:   <doc:row>
  129:     <doc:shape>circle</doc:shape>
  130:     <doc:degrees>360</doc:degrees>
  131:     <doc:sides/>
  132:   </doc:row>
  133:   <doc:row>
  134:     <doc:shape>triangle</doc:shape>
  135:     <doc:degrees>180</doc:degrees>
  136:     <doc:sides>3.0</doc:sides>
  137:   </doc:row>
  138: </doc:data>"""
  139: 
  140: 
  141: df_kml = DataFrame(
  142:     {
  143:         "id": {
  144:             0: "ID_00001",
  145:             1: "ID_00002",
  146:             2: "ID_00003",
  147:             3: "ID_00004",
  148:             4: "ID_00005",
  149:         },
  150:         "name": {
  151:             0: "Blue Line (Forest Park)",
  152:             1: "Red, Purple Line",
  153:             2: "Red, Purple Line",
  154:             3: "Red, Purple Line",
  155:             4: "Red, Purple Line",
  156:         },
  157:         "styleUrl": {
  158:             0: "#LineStyle01",
  159:             1: "#LineStyle01",
  160:             2: "#LineStyle01",
  161:             3: "#LineStyle01",
  162:             4: "#LineStyle01",
  163:         },
  164:         "extrude": {0: 0, 1: 0, 2: 0, 3: 0, 4: 0},
  165:         "altitudeMode": {
  166:             0: "clampedToGround",
  167:             1: "clampedToGround",
  168:             2: "clampedToGround",
  169:             3: "clampedToGround",
  170:             4: "clampedToGround",
  171:         },
  172:         "coordinates": {
  173:             0: (
  174:                 "-87.77678526964958,41.8708863930319,0 "
  175:                 "-87.77826234150609,41.87097820122218,0 "
  176:                 "-87.78251583439344,41.87130129991005,0 "
  177:                 "-87.78418294588424,41.87145055520308,0 "
  178:                 "-87.7872369165933,41.8717239119163,0 "
  179:                 "-87.79160214925886,41.87210797280065,0"
  180:             ),
  181:             1: (
  182:                 "-87.65758750947528,41.96427269188822,0 "
  183:                 "-87.65802133507393,41.96581929055245,0 "
  184:                 "-87.65819033925305,41.96621846093642,0 "
  185:                 "-87.6583189819129,41.96650362897086,0 "
  186:                 "-87.65835858701473,41.96669002089185,0 "
  187:                 "-87.65838428411853,41.96688150295095,0 "
  188:                 "-87.65842208882658,41.96745896091846,0 "
  189:                 "-87.65846556843937,41.9683761425439,0 "
  190:                 "-87.65849296214573,41.96913893870342,0"
  191:             ),
  192:             2: (
  193:                 "-87.65492939166126,41.95377494531437,0 "
  194:                 "-87.65557043199591,41.95376544118533,0 "
  195:                 "-87.65606302030132,41.95376391658746,0 "
  196:                 "-87.65623502146268,41.95377379126367,0 "
  197:                 "-87.65634748981634,41.95380103566435,0 "
  198:                 "-87.65646537904269,41.95387703994676,0 "
  199:                 "-87.65656532461145,41.95396622645799,0 "
  200:                 "-87.65664760856414,41.95404201996044,0 "
  201:                 "-87.65671750555913,41.95416647054043,0 "
  202:                 "-87.65673983607117,41.95429949810849,0 "
  203:                 "-87.65673866475777,41.95441024240925,0 "
  204:                 "-87.6567690255541,41.95490657227902,0 "
  205:                 "-87.65683672482363,41.95692259283837,0 "
  206:                 "-87.6568900886376,41.95861070983142,0 "
  207:                 "-87.65699865558875,41.96181418669004,0 "
  208:                 "-87.65756347177603,41.96397045777844,0 "
  209:                 "-87.65758750947528,41.96427269188822,0"
  210:             ),
  211:             3: (
  212:                 "-87.65362593118043,41.94742799535678,0 "
  213:                 "-87.65363554415794,41.94819886386848,0 "
  214:                 "-87.6536456393239,41.95059994675451,0 "
  215:                 "-87.65365831235026,41.95108288489359,0 "
  216:                 "-87.6536604873874,41.9519954657554,0 "
  217:                 "-87.65362592053201,41.95245597302328,0 "
  218:                 "-87.65367158496069,41.95311153649393,0 "
  219:                 "-87.65368468595476,41.9533202828916,0 "
  220:                 "-87.65369271253692,41.95343095587119,0 "
  221:                 "-87.65373335834569,41.95351536301472,0 "
  222:                 "-87.65378605844126,41.95358212680591,0 "
  223:                 "-87.65385067928185,41.95364452823767,0 "
  224:                 "-87.6539390793817,41.95370263886964,0 "
  225:                 "-87.6540786298351,41.95373403675265,0 "
  226:                 "-87.65430648647626,41.9537535411832,0 "
  227:                 "-87.65492939166126,41.95377494531437,0"
  228:             ),
  229:             4: (
  230:                 "-87.65345391792157,41.94217681262115,0 "
  231:                 "-87.65342448305786,41.94237224420864,0 "
  232:                 "-87.65339745703922,41.94268217746244,0 "
  233:                 "-87.65337753982941,41.94288140770284,0 "
  234:                 "-87.65336256753105,41.94317369618263,0 "
  235:                 "-87.65338799707138,41.94357253961736,0 "
  236:                 "-87.65340240886648,41.94389158188269,0 "
  237:                 "-87.65341837392448,41.94406444407721,0 "
  238:                 "-87.65342275247338,41.94421065714904,0 "
  239:                 "-87.65347469646018,41.94434829382345,0 "
  240:                 "-87.65351486483024,41.94447699917548,0 "
  241:                 "-87.65353483605053,41.9453896864472,0 "
  242:                 "-87.65361975532807,41.94689193720703,0 "
  243:                 "-87.65362593118043,41.94742799535678,0"
  244:             ),
  245:         },
  246:     }
  247: )
  248: 
  249: 
  250: def test_literal_xml_deprecation():
  251:     # GH 53809
  252:     pytest.importorskip("lxml")
  253:     msg = (
  254:         "Passing literal xml to 'read_xml' is deprecated and "
  255:         "will be removed in a future version. To read from a "
  256:         "literal string, wrap it in a 'StringIO' object."
  257:     )
  258: 
  259:     with tm.assert_produces_warning(FutureWarning, match=msg):
  260:         read_xml(xml_default_nmsp)
  261: 
  262: 
  263: @pytest.fixture(params=["rb", "r"])
  264: def mode(request):
  265:     return request.param
  266: 
  267: 
  268: @pytest.fixture(params=[pytest.param("lxml", marks=td.skip_if_no("lxml")), "etree"])
  269: def parser(request):
  270:     return request.param
  271: 
  272: 
  273: def read_xml_iterparse(data, **kwargs):
  274:     with tm.ensure_clean() as path:
  275:         with open(path, "w", encoding="utf-8") as f:
  276:             f.write(data)
  277:         return read_xml(path, **kwargs)
  278: 
  279: 
  280: def read_xml_iterparse_comp(comp_path, compression_only, **kwargs):
  281:     with get_handle(comp_path, "r", compression=compression_only) as handles:
  282:         with tm.ensure_clean() as path:
  283:             with open(path, "w", encoding="utf-8") as f:
  284:                 f.write(handles.handle.read())
  285:             return read_xml(path, **kwargs)
  286: 
  287: 
  288: # FILE / URL
  289: 
  290: 
  291: def test_parser_consistency_file(xml_books):
  292:     pytest.importorskip("lxml")
  293:     df_file_lxml = read_xml(xml_books, parser="lxml")
  294:     df_file_etree = read_xml(xml_books, parser="etree")
  295: 
  296:     df_iter_lxml = read_xml(
  297:         xml_books,
  298:         parser="lxml",
  299:         iterparse={"book": ["category", "title", "year", "author", "price"]},
  300:     )
  301:     df_iter_etree = read_xml(
  302:         xml_books,
  303:         parser="etree",
  304:         iterparse={"book": ["category", "title", "year", "author", "price"]},
  305:     )
  306: 
  307:     tm.assert_frame_equal(df_file_lxml, df_file_etree)
  308:     tm.assert_frame_equal(df_file_lxml, df_iter_lxml)
  309:     tm.assert_frame_equal(df_iter_lxml, df_iter_etree)
  310: 
  311: 
  312: @pytest.mark.network
  313: @pytest.mark.single_cpu
  314: def test_parser_consistency_url(parser, httpserver):
  315:     httpserver.serve_content(content=xml_default_nmsp)
  316: 
  317:     df_xpath = read_xml(StringIO(xml_default_nmsp), parser=parser)
  318:     df_iter = read_xml(
  319:         BytesIO(xml_default_nmsp.encode()),
  320:         parser=parser,
  321:         iterparse={"row": ["shape", "degrees", "sides"]},
  322:     )
  323: 
  324:     tm.assert_frame_equal(df_xpath, df_iter)
  325: 
  326: 
  327: def test_file_like(xml_books, parser, mode):
  328:     with open(xml_books, mode, encoding="utf-8" if mode == "r" else None) as f:
  329:         df_file = read_xml(f, parser=parser)
  330: 
  331:     df_expected = DataFrame(
  332:         {
  333:             "category": ["cooking", "children", "web"],
  334:             "title": ["Everyday Italian", "Harry Potter", "Learning XML"],
  335:             "author": ["Giada De Laurentiis", "J K. Rowling", "Erik T. Ray"],
  336:             "year": [2005, 2005, 2003],
  337:             "price": [30.00, 29.99, 39.95],
  338:         }
  339:     )
  340: 
  341:     tm.assert_frame_equal(df_file, df_expected)
  342: 
  343: 
  344: def test_file_io(xml_books, parser, mode):
  345:     with open(xml_books, mode, encoding="utf-8" if mode == "r" else None) as f:
  346:         xml_obj = f.read()
  347: 
  348:     df_io = read_xml(
  349:         (BytesIO(xml_obj) if isinstance(xml_obj, bytes) else StringIO(xml_obj)),
  350:         parser=parser,
  351:     )
  352: 
  353:     df_expected = DataFrame(
  354:         {
  355:             "category": ["cooking", "children", "web"],
  356:             "title": ["Everyday Italian", "Harry Potter", "Learning XML"],
  357:             "author": ["Giada De Laurentiis", "J K. Rowling", "Erik T. Ray"],
  358:             "year": [2005, 2005, 2003],
  359:             "price": [30.00, 29.99, 39.95],
  360:         }
  361:     )
  362: 
  363:     tm.assert_frame_equal(df_io, df_expected)
  364: 
  365: 
  366: def test_file_buffered_reader_string(xml_books, parser, mode):
  367:     with open(xml_books, mode, encoding="utf-8" if mode == "r" else None) as f:
  368:         xml_obj = f.read()
  369: 
  370:     if mode == "rb":
  371:         xml_obj = StringIO(xml_obj.decode())
  372:     elif mode == "r":
  373:         xml_obj = StringIO(xml_obj)
  374: 
  375:     df_str = read_xml(xml_obj, parser=parser)
  376: 
  377:     df_expected = DataFrame(
  378:         {
  379:             "category": ["cooking", "children", "web"],
  380:             "title": ["Everyday Italian", "Harry Potter", "Learning XML"],
  381:             "author": ["Giada De Laurentiis", "J K. Rowling", "Erik T. Ray"],
  382:             "year": [2005, 2005, 2003],
  383:             "price": [30.00, 29.99, 39.95],
  384:         }
  385:     )
  386: 
  387:     tm.assert_frame_equal(df_str, df_expected)
  388: 
  389: 
  390: def test_file_buffered_reader_no_xml_declaration(xml_books, parser, mode):
  391:     with open(xml_books, mode, encoding="utf-8" if mode == "r" else None) as f:
  392:         next(f)
  393:         xml_obj = f.read()
  394: 
  395:     if mode == "rb":
  396:         xml_obj = StringIO(xml_obj.decode())
  397:     elif mode == "r":
  398:         xml_obj = StringIO(xml_obj)
  399: 
  400:     df_str = read_xml(xml_obj, parser=parser)
  401: 
  402:     df_expected = DataFrame(
  403:         {
  404:             "category": ["cooking", "children", "web"],
  405:             "title": ["Everyday Italian", "Harry Potter", "Learning XML"],
  406:             "author": ["Giada De Laurentiis", "J K. Rowling", "Erik T. Ray"],
  407:             "year": [2005, 2005, 2003],
  408:             "price": [30.00, 29.99, 39.95],
  409:         }
  410:     )
  411: 
  412:     tm.assert_frame_equal(df_str, df_expected)
  413: 
  414: 
  415: def test_string_charset(parser):
  416:     txt = "<дё­ж–‡жЁ™з±¤><row><c1>1</c1><c2>2</c2></row></дё­ж–‡жЁ™з±¤>"
  417: 
  418:     df_str = read_xml(StringIO(txt), parser=parser)
  419: 
  420:     df_expected = DataFrame({"c1": 1, "c2": 2}, index=[0])
  421: 
  422:     tm.assert_frame_equal(df_str, df_expected)
  423: 
  424: 
  425: def test_file_charset(xml_doc_ch_utf, parser):
  426:     df_file = read_xml(xml_doc_ch_utf, parser=parser)
  427: 
  428:     df_expected = DataFrame(
  429:         {
  430:             "е•Џ": [
  431:                 "е•Џ  и‹Ґз®‡жЇй‚ЄиЂЊиЁЂз ґй‚Є дЅ•иЂ…жЇж­ЈиЂЊйЃ“(Sorry, this is Big5 only)з”іж­Ј",
  432:                 "е•Џ ж—ўз ґжњ‰еѕ—з”із„Ўеѕ— дє¦ж‡‰дЅ†з ґжЂ§еџ·з”іеЃ‡еђЌд»ҐдёЌ",
  433:                 "е•Џ ж—ўз ґжЂ§з”іеЃ‡ дє¦ж‡‰дЅ†з ґжњ‰з”із„Ў и‹Ґжњ‰з„Ўе…©жґ— дє¦ж‡‰жЂ§еЃ‡й›™з ґиЂ¶",
  434:             ],
  435:             "з­”": [
  436:                 "".join(
  437:                     [
  438:                         "з­”  й‚Єж—ўз„Ўй‡Џ ж­Јдє¦е¤љйЂ”  е¤§з•Ґз‚єиЁЂдёЌе‡єдєЊзЁ® и¬‚",
  439:                         "жњ‰еѕ—и€‡з„Ўеѕ— жњ‰еѕ—жЇй‚Єй €з ґ з„Ўеѕ—жЇж­Јй €з”і\n\t\tж•…",
  440:                     ]
  441:                 ),
  442:                 None,
  443:                 "з­”  дёЌдѕ‹  жњ‰з„Ўзљ†жЇжЂ§ ж‰Ђд»Ґй €й›™з ґ ж—ўе€†жЂ§еЃ‡з•° ж•…жњ‰з ґдёЌз ґ",
  444:             ],
  445:             "a": [
  446:                 None,
  447:                 "з­” жЂ§еџ·жЇжњ‰еѕ— еЃ‡еђЌжЇз„Ўеѕ—  д»Љз ґжњ‰еѕ—з”із„Ўеѕ— еЌіжЇз ґжЂ§еџ·з”іеЃ‡еђЌд№џ",
  448:                 None,
  449:             ],
  450:         }
  451:     )
  452: 
  453:     tm.assert_frame_equal(df_file, df_expected)
  454: 
  455: 
  456: def test_file_handle_close(xml_books, parser):
  457:     with open(xml_books, "rb") as f:
  458:         read_xml(BytesIO(f.read()), parser=parser)
  459: 
  460:         assert not f.closed
  461: 
  462: 
  463: @pytest.mark.parametrize("val", ["", b""])
  464: def test_empty_string_lxml(val):
  465:     lxml_etree = pytest.importorskip("lxml.etree")
  466: 
  467:     msg = "|".join(
  468:         [
  469:             "Document is empty",
  470:             # Seen on Mac with lxml 4.91
  471:             r"None \(line 0\)",
  472:         ]
  473:     )
  474:     with pytest.raises(lxml_etree.XMLSyntaxError, match=msg):
  475:         if isinstance(val, str):
  476:             read_xml(StringIO(val), parser="lxml")
  477:         else:
  478:             read_xml(BytesIO(val), parser="lxml")
  479: 
  480: 
  481: @pytest.mark.parametrize("val", ["", b""])
  482: def test_empty_string_etree(val):
  483:     with pytest.raises(ParseError, match="no element found"):
  484:         if isinstance(val, str):
  485:             read_xml(StringIO(val), parser="etree")
  486:         else:
  487:             read_xml(BytesIO(val), parser="etree")
  488: 
  489: 
  490: def test_wrong_file_path(parser):
  491:     msg = (
  492:         "Passing literal xml to 'read_xml' is deprecated and "
  493:         "will be removed in a future version. To read from a "
  494:         "literal string, wrap it in a 'StringIO' object."
  495:     )
  496:     filename = os.path.join("data", "html", "books.xml")
  497: 
  498:     with pytest.raises(
  499:         FutureWarning,
  500:         match=msg,
  501:     ):
  502:         read_xml(filename, parser=parser)
  503: 
  504: 
  505: @pytest.mark.network
  506: @pytest.mark.single_cpu
  507: def test_url(httpserver, xml_file):
  508:     pytest.importorskip("lxml")
  509:     with open(xml_file, encoding="utf-8") as f:
  510:         httpserver.serve_content(content=f.read())
  511:         df_url = read_xml(httpserver.url, xpath=".//book[count(*)=4]")
  512: 
  513:     df_expected = DataFrame(
  514:         {
  515:             "category": ["cooking", "children", "web"],
  516:             "title": ["Everyday Italian", "Harry Potter", "Learning XML"],
  517:             "author": ["Giada De Laurentiis", "J K. Rowling", "Erik T. Ray"],
  518:             "year": [2005, 2005, 2003],
  519:             "price": [30.00, 29.99, 39.95],
  520:         }
  521:     )
  522: 
  523:     tm.assert_frame_equal(df_url, df_expected)
  524: 
  525: 
  526: @pytest.mark.network
  527: @pytest.mark.single_cpu
  528: def test_wrong_url(parser, httpserver):
  529:     httpserver.serve_content("NOT FOUND", code=404)
  530:     with pytest.raises(HTTPError, match=("HTTP Error 404: NOT FOUND")):
  531:         read_xml(httpserver.url, xpath=".//book[count(*)=4]", parser=parser)
  532: 
  533: 
  534: # CONTENT
  535: 
  536: 
  537: def test_whitespace(parser):
  538:     xml = """
  539:       <data>
  540:         <row sides=" 4 ">
  541:           <shape>
  542:               square
  543:           </shape>
  544:           <degrees>&#009;360&#009;</degrees>
  545:         </row>
  546:         <row sides=" 0 ">
  547:           <shape>
  548:               circle
  549:           </shape>
  550:           <degrees>&#009;360&#009;</degrees>
  551:         </row>
  552:         <row sides=" 3 ">
  553:           <shape>
  554:               triangle
  555:           </shape>
  556:           <degrees>&#009;180&#009;</degrees>
  557:         </row>
  558:       </data>"""
  559: 
  560:     df_xpath = read_xml(StringIO(xml), parser=parser, dtype="string")
  561: 
  562:     df_iter = read_xml_iterparse(
  563:         xml,
  564:         parser=parser,
  565:         iterparse={"row": ["sides", "shape", "degrees"]},
  566:         dtype="string",
  567:     )
  568: 
  569:     df_expected = DataFrame(
  570:         {
  571:             "sides": [" 4 ", " 0 ", " 3 "],
  572:             "shape": [
  573:                 "\n              square\n          ",
  574:                 "\n              circle\n          ",
  575:                 "\n              triangle\n          ",
  576:             ],
  577:             "degrees": ["\t360\t", "\t360\t", "\t180\t"],
  578:         },
  579:         dtype="string",
  580:     )
  581: 
  582:     tm.assert_frame_equal(df_xpath, df_expected)
  583:     tm.assert_frame_equal(df_iter, df_expected)
  584: 
  585: 
  586: # XPATH
  587: 
  588: 
  589: def test_empty_xpath_lxml(xml_books):
  590:     pytest.importorskip("lxml")
  591:     with pytest.raises(ValueError, match=("xpath does not return any nodes")):
  592:         read_xml(xml_books, xpath=".//python", parser="lxml")
  593: 
  594: 
  595: def test_bad_xpath_etree(xml_books):
  596:     with pytest.raises(
  597:         SyntaxError, match=("You have used an incorrect or unsupported XPath")
  598:     ):
  599:         read_xml(xml_books, xpath=".//[book]", parser="etree")
  600: 
  601: 
  602: def test_bad_xpath_lxml(xml_books):
  603:     lxml_etree = pytest.importorskip("lxml.etree")
  604: 
  605:     with pytest.raises(lxml_etree.XPathEvalError, match=("Invalid expression")):
  606:         read_xml(xml_books, xpath=".//[book]", parser="lxml")
  607: 
  608: 
  609: # NAMESPACE
  610: 
  611: 
  612: def test_default_namespace(parser):
  613:     df_nmsp = read_xml(
  614:         StringIO(xml_default_nmsp),
  615:         xpath=".//ns:row",
  616:         namespaces={"ns": "http://example.com"},
  617:         parser=parser,
  618:     )
  619: 
  620:     df_iter = read_xml_iterparse(
  621:         xml_default_nmsp,
  622:         parser=parser,
  623:         iterparse={"row": ["shape", "degrees", "sides"]},
  624:     )
  625: 
  626:     df_expected = DataFrame(
  627:         {
  628:             "shape": ["square", "circle", "triangle"],
  629:             "degrees": [360, 360, 180],
  630:             "sides": [4.0, float("nan"), 3.0],
  631:         }
  632:     )
  633: 
  634:     tm.assert_frame_equal(df_nmsp, df_expected)
  635:     tm.assert_frame_equal(df_iter, df_expected)
  636: 
  637: 
  638: def test_prefix_namespace(parser):
  639:     df_nmsp = read_xml(
  640:         StringIO(xml_prefix_nmsp),
  641:         xpath=".//doc:row",
  642:         namespaces={"doc": "http://example.com"},
  643:         parser=parser,
  644:     )
  645:     df_iter = read_xml_iterparse(
  646:         xml_prefix_nmsp, parser=parser, iterparse={"row": ["shape", "degrees", "sides"]}
  647:     )
  648: 
  649:     df_expected = DataFrame(
  650:         {
  651:             "shape": ["square", "circle", "triangle"],
  652:             "degrees": [360, 360, 180],
  653:             "sides": [4.0, float("nan"), 3.0],
  654:         }
  655:     )
  656: 
  657:     tm.assert_frame_equal(df_nmsp, df_expected)
  658:     tm.assert_frame_equal(df_iter, df_expected)
  659: 
  660: 
  661: def test_consistency_default_namespace():
  662:     pytest.importorskip("lxml")
  663:     df_lxml = read_xml(
  664:         StringIO(xml_default_nmsp),
  665:         xpath=".//ns:row",
  666:         namespaces={"ns": "http://example.com"},
  667:         parser="lxml",
  668:     )
  669: 
  670:     df_etree = read_xml(
  671:         StringIO(xml_default_nmsp),
  672:         xpath=".//doc:row",
  673:         namespaces={"doc": "http://example.com"},
  674:         parser="etree",
  675:     )
  676: 
  677:     tm.assert_frame_equal(df_lxml, df_etree)
  678: 
  679: 
  680: def test_consistency_prefix_namespace():
  681:     pytest.importorskip("lxml")
  682:     df_lxml = read_xml(
  683:         StringIO(xml_prefix_nmsp),
  684:         xpath=".//doc:row",
  685:         namespaces={"doc": "http://example.com"},
  686:         parser="lxml",
  687:     )
  688: 
  689:     df_etree = read_xml(
  690:         StringIO(xml_prefix_nmsp),
  691:         xpath=".//doc:row",
  692:         namespaces={"doc": "http://example.com"},
  693:         parser="etree",
  694:     )
  695: 
  696:     tm.assert_frame_equal(df_lxml, df_etree)
  697: 
  698: 
  699: # PREFIX
  700: 
  701: 
  702: def test_missing_prefix_with_default_namespace(xml_books, parser):
  703:     with pytest.raises(ValueError, match=("xpath does not return any nodes")):
  704:         read_xml(xml_books, xpath=".//Placemark", parser=parser)
  705: 
  706: 
  707: def test_missing_prefix_definition_etree(kml_cta_rail_lines):
  708:     with pytest.raises(SyntaxError, match=("you used an undeclared namespace prefix")):
  709:         read_xml(kml_cta_rail_lines, xpath=".//kml:Placemark", parser="etree")
  710: 
  711: 
  712: def test_missing_prefix_definition_lxml(kml_cta_rail_lines):
  713:     lxml_etree = pytest.importorskip("lxml.etree")
  714: 
  715:     with pytest.raises(lxml_etree.XPathEvalError, match=("Undefined namespace prefix")):
  716:         read_xml(kml_cta_rail_lines, xpath=".//kml:Placemark", parser="lxml")
  717: 
  718: 
  719: @pytest.mark.parametrize("key", ["", None])
  720: def test_none_namespace_prefix(key):
  721:     pytest.importorskip("lxml")
  722:     with pytest.raises(
  723:         TypeError, match=("empty namespace prefix is not supported in XPath")
  724:     ):
  725:         read_xml(
  726:             StringIO(xml_default_nmsp),
  727:             xpath=".//kml:Placemark",
  728:             namespaces={key: "http://www.opengis.net/kml/2.2"},
  729:             parser="lxml",
  730:         )
  731: 
  732: 
  733: # ELEMS AND ATTRS
  734: 
  735: 
  736: def test_file_elems_and_attrs(xml_books, parser):
  737:     df_file = read_xml(xml_books, parser=parser)
  738:     df_iter = read_xml(
  739:         xml_books,
  740:         parser=parser,
  741:         iterparse={"book": ["category", "title", "author", "year", "price"]},
  742:     )
  743:     df_expected = DataFrame(
  744:         {
  745:             "category": ["cooking", "children", "web"],
  746:             "title": ["Everyday Italian", "Harry Potter", "Learning XML"],
  747:             "author": ["Giada De Laurentiis", "J K. Rowling", "Erik T. Ray"],
  748:             "year": [2005, 2005, 2003],
  749:             "price": [30.00, 29.99, 39.95],
  750:         }
  751:     )
  752: 
  753:     tm.assert_frame_equal(df_file, df_expected)
  754:     tm.assert_frame_equal(df_iter, df_expected)
  755: 
  756: 
  757: def test_file_only_attrs(xml_books, parser):
  758:     df_file = read_xml(xml_books, attrs_only=True, parser=parser)
  759:     df_iter = read_xml(xml_books, parser=parser, iterparse={"book": ["category"]})
  760:     df_expected = DataFrame({"category": ["cooking", "children", "web"]})
  761: 
  762:     tm.assert_frame_equal(df_file, df_expected)
  763:     tm.assert_frame_equal(df_iter, df_expected)
  764: 
  765: 
  766: def test_file_only_elems(xml_books, parser):
  767:     df_file = read_xml(xml_books, elems_only=True, parser=parser)
  768:     df_iter = read_xml(
  769:         xml_books,
  770:         parser=parser,
  771:         iterparse={"book": ["title", "author", "year", "price"]},
  772:     )
  773:     df_expected = DataFrame(
  774:         {
  775:             "title": ["Everyday Italian", "Harry Potter", "Learning XML"],
  776:             "author": ["Giada De Laurentiis", "J K. Rowling", "Erik T. Ray"],
  777:             "year": [2005, 2005, 2003],
  778:             "price": [30.00, 29.99, 39.95],
  779:         }
  780:     )
  781: 
  782:     tm.assert_frame_equal(df_file, df_expected)
  783:     tm.assert_frame_equal(df_iter, df_expected)
  784: 
  785: 
  786: def test_elem_and_attrs_only(kml_cta_rail_lines, parser):
  787:     with pytest.raises(
  788:         ValueError,
  789:         match=("Either element or attributes can be parsed not both"),
  790:     ):
  791:         read_xml(kml_cta_rail_lines, elems_only=True, attrs_only=True, parser=parser)
  792: 
  793: 
  794: def test_empty_attrs_only(parser):
  795:     xml = """
  796:       <data>
  797:         <row>
  798:           <shape sides="4">square</shape>
  799:           <degrees>360</degrees>
  800:         </row>
  801:         <row>
  802:           <shape sides="0">circle</shape>
  803:           <degrees>360</degrees>
  804:         </row>
  805:         <row>
  806:           <shape sides="3">triangle</shape>
  807:           <degrees>180</degrees>
  808:         </row>
  809:       </data>"""
  810: 
  811:     with pytest.raises(
  812:         ValueError,
  813:         match=("xpath does not return any nodes or attributes"),
  814:     ):
  815:         read_xml(StringIO(xml), xpath="./row", attrs_only=True, parser=parser)
  816: 
  817: 
  818: def test_empty_elems_only(parser):
  819:     xml = """
  820:       <data>
  821:         <row sides="4" shape="square" degrees="360"/>
  822:         <row sides="0" shape="circle" degrees="360"/>
  823:         <row sides="3" shape="triangle" degrees="180"/>
  824:       </data>"""
  825: 
  826:     with pytest.raises(
  827:         ValueError,
  828:         match=("xpath does not return any nodes or attributes"),
  829:     ):
  830:         read_xml(StringIO(xml), xpath="./row", elems_only=True, parser=parser)
  831: 
  832: 
  833: def test_attribute_centric_xml():
  834:     pytest.importorskip("lxml")
  835:     xml = """\
  836: <?xml version="1.0" encoding="UTF-8"?>
  837: <TrainSchedule>
  838:       <Stations>
  839:          <station Name="Manhattan" coords="31,460,195,498"/>
  840:          <station Name="Laraway Road" coords="63,409,194,455"/>
  841:          <station Name="179th St (Orland Park)" coords="0,364,110,395"/>
  842:          <station Name="153rd St (Orland Park)" coords="7,333,113,362"/>
  843:          <station Name="143rd St (Orland Park)" coords="17,297,115,330"/>
  844:          <station Name="Palos Park" coords="128,281,239,303"/>
  845:          <station Name="Palos Heights" coords="148,257,283,279"/>
  846:          <station Name="Worth" coords="170,230,248,255"/>
  847:          <station Name="Chicago Ridge" coords="70,187,208,214"/>
  848:          <station Name="Oak Lawn" coords="166,159,266,185"/>
  849:          <station Name="Ashburn" coords="197,133,336,157"/>
  850:          <station Name="Wrightwood" coords="219,106,340,133"/>
  851:          <station Name="Chicago Union Sta" coords="220,0,360,43"/>
  852:       </Stations>
  853: </TrainSchedule>"""
  854: 
  855:     df_lxml = read_xml(StringIO(xml), xpath=".//station")
  856:     df_etree = read_xml(StringIO(xml), xpath=".//station", parser="etree")
  857: 
  858:     df_iter_lx = read_xml_iterparse(xml, iterparse={"station": ["Name", "coords"]})
  859:     df_iter_et = read_xml_iterparse(
  860:         xml, parser="etree", iterparse={"station": ["Name", "coords"]}
  861:     )
  862: 
  863:     tm.assert_frame_equal(df_lxml, df_etree)
  864:     tm.assert_frame_equal(df_iter_lx, df_iter_et)
  865: 
  866: 
  867: # NAMES
  868: 
  869: 
  870: def test_names_option_output(xml_books, parser):
  871:     df_file = read_xml(
  872:         xml_books, names=["Col1", "Col2", "Col3", "Col4", "Col5"], parser=parser
  873:     )
  874:     df_iter = read_xml(
  875:         xml_books,
  876:         parser=parser,
  877:         names=["Col1", "Col2", "Col3", "Col4", "Col5"],
  878:         iterparse={"book": ["category", "title", "author", "year", "price"]},
  879:     )
  880: 
  881:     df_expected = DataFrame(
  882:         {
  883:             "Col1": ["cooking", "children", "web"],
  884:             "Col2": ["Everyday Italian", "Harry Potter", "Learning XML"],
  885:             "Col3": ["Giada De Laurentiis", "J K. Rowling", "Erik T. Ray"],
  886:             "Col4": [2005, 2005, 2003],
  887:             "Col5": [30.00, 29.99, 39.95],
  888:         }
  889:     )
  890: 
  891:     tm.assert_frame_equal(df_file, df_expected)
  892:     tm.assert_frame_equal(df_iter, df_expected)
  893: 
  894: 
  895: def test_repeat_names(parser):
  896:     xml = """\
  897: <shapes>
  898:   <shape type="2D">
  899:     <name>circle</name>
  900:     <type>curved</type>
  901:   </shape>
  902:   <shape type="3D">
  903:     <name>sphere</name>
  904:     <type>curved</type>
  905:   </shape>
  906: </shapes>"""
  907:     df_xpath = read_xml(
  908:         StringIO(xml),
  909:         xpath=".//shape",
  910:         parser=parser,
  911:         names=["type_dim", "shape", "type_edge"],
  912:     )
  913: 
  914:     df_iter = read_xml_iterparse(
  915:         xml,
  916:         parser=parser,
  917:         iterparse={"shape": ["type", "name", "type"]},
  918:         names=["type_dim", "shape", "type_edge"],
  919:     )
  920: 
  921:     df_expected = DataFrame(
  922:         {
  923:             "type_dim": ["2D", "3D"],
  924:             "shape": ["circle", "sphere"],
  925:             "type_edge": ["curved", "curved"],
  926:         }
  927:     )
  928: 
  929:     tm.assert_frame_equal(df_xpath, df_expected)
  930:     tm.assert_frame_equal(df_iter, df_expected)
  931: 
  932: 
  933: def test_repeat_values_new_names(parser):
  934:     xml = """\
  935: <shapes>
  936:   <shape>
  937:     <name>rectangle</name>
  938:     <family>rectangle</family>
  939:   </shape>
  940:   <shape>
  941:     <name>square</name>
  942:     <family>rectangle</family>
  943:   </shape>
  944:   <shape>
  945:     <name>ellipse</name>
  946:     <family>ellipse</family>
  947:   </shape>
  948:   <shape>
  949:     <name>circle</name>
  950:     <family>ellipse</family>
  951:   </shape>
  952: </shapes>"""
  953:     df_xpath = read_xml(
  954:         StringIO(xml), xpath=".//shape", parser=parser, names=["name", "group"]
  955:     )
  956: 
  957:     df_iter = read_xml_iterparse(
  958:         xml,
  959:         parser=parser,
  960:         iterparse={"shape": ["name", "family"]},
  961:         names=["name", "group"],
  962:     )
  963: 
  964:     df_expected = DataFrame(
  965:         {
  966:             "name": ["rectangle", "square", "ellipse", "circle"],
  967:             "group": ["rectangle", "rectangle", "ellipse", "ellipse"],
  968:         }
  969:     )
  970: 
  971:     tm.assert_frame_equal(df_xpath, df_expected)
  972:     tm.assert_frame_equal(df_iter, df_expected)
  973: 
  974: 
  975: def test_repeat_elements(parser):
  976:     xml = """\
  977: <shapes>
  978:   <shape>
  979:     <value item="name">circle</value>
  980:     <value item="family">ellipse</value>
  981:     <value item="degrees">360</value>
  982:     <value item="sides">0</value>
  983:   </shape>
  984:   <shape>
  985:     <value item="name">triangle</value>
  986:     <value item="family">polygon</value>
  987:     <value item="degrees">180</value>
  988:     <value item="sides">3</value>
  989:   </shape>
  990:   <shape>
  991:     <value item="name">square</value>
  992:     <value item="family">polygon</value>
  993:     <value item="degrees">360</value>
  994:     <value item="sides">4</value>
  995:   </shape>
  996: </shapes>"""
  997:     df_xpath = read_xml(
  998:         StringIO(xml),
  999:         xpath=".//shape",
 1000:         parser=parser,
 1001:         names=["name", "family", "degrees", "sides"],
 1002:     )
 1003: 
 1004:     df_iter = read_xml_iterparse(
 1005:         xml,
 1006:         parser=parser,
 1007:         iterparse={"shape": ["value", "value", "value", "value"]},
 1008:         names=["name", "family", "degrees", "sides"],
 1009:     )
 1010: 
 1011:     df_expected = DataFrame(
 1012:         {
 1013:             "name": ["circle", "triangle", "square"],
 1014:             "family": ["ellipse", "polygon", "polygon"],
 1015:             "degrees": [360, 180, 360],
 1016:             "sides": [0, 3, 4],
 1017:         }
 1018:     )
 1019: 
 1020:     tm.assert_frame_equal(df_xpath, df_expected)
 1021:     tm.assert_frame_equal(df_iter, df_expected)
 1022: 
 1023: 
 1024: def test_names_option_wrong_length(xml_books, parser):
 1025:     with pytest.raises(ValueError, match=("names does not match length")):
 1026:         read_xml(xml_books, names=["Col1", "Col2", "Col3"], parser=parser)
 1027: 
 1028: 
 1029: def test_names_option_wrong_type(xml_books, parser):
 1030:     with pytest.raises(TypeError, match=("is not a valid type for names")):
 1031:         read_xml(xml_books, names="Col1, Col2, Col3", parser=parser)
 1032: 
 1033: 
 1034: # ENCODING
 1035: 
 1036: 
 1037: def test_wrong_encoding(xml_baby_names, parser):
 1038:     with pytest.raises(UnicodeDecodeError, match=("'utf-8' codec can't decode")):
 1039:         read_xml(xml_baby_names, parser=parser)
 1040: 
 1041: 
 1042: def test_utf16_encoding(xml_baby_names, parser):
 1043:     with pytest.raises(
 1044:         UnicodeError,
 1045:         match=(
 1046:             "UTF-16 stream does not start with BOM|"
 1047:             "'utf-16-le' codec can't decode byte"
 1048:         ),
 1049:     ):
 1050:         read_xml(xml_baby_names, encoding="UTF-16", parser=parser)
 1051: 
 1052: 
 1053: def test_unknown_encoding(xml_baby_names, parser):
 1054:     with pytest.raises(LookupError, match=("unknown encoding: UFT-8")):
 1055:         read_xml(xml_baby_names, encoding="UFT-8", parser=parser)
 1056: 
 1057: 
 1058: def test_ascii_encoding(xml_baby_names, parser):
 1059:     with pytest.raises(UnicodeDecodeError, match=("'ascii' codec can't decode byte")):
 1060:         read_xml(xml_baby_names, encoding="ascii", parser=parser)
 1061: 
 1062: 
 1063: def test_parser_consistency_with_encoding(xml_baby_names):
 1064:     pytest.importorskip("lxml")
 1065:     df_xpath_lxml = read_xml(xml_baby_names, parser="lxml", encoding="ISO-8859-1")
 1066:     df_xpath_etree = read_xml(xml_baby_names, parser="etree", encoding="iso-8859-1")
 1067: 
 1068:     df_iter_lxml = read_xml(
 1069:         xml_baby_names,
 1070:         parser="lxml",
 1071:         encoding="ISO-8859-1",
 1072:         iterparse={"row": ["rank", "malename", "femalename"]},
 1073:     )
 1074:     df_iter_etree = read_xml(
 1075:         xml_baby_names,
 1076:         parser="etree",
 1077:         encoding="ISO-8859-1",
 1078:         iterparse={"row": ["rank", "malename", "femalename"]},
 1079:     )
 1080: 
 1081:     tm.assert_frame_equal(df_xpath_lxml, df_xpath_etree)
 1082:     tm.assert_frame_equal(df_xpath_etree, df_iter_etree)
 1083:     tm.assert_frame_equal(df_iter_lxml, df_iter_etree)
 1084: 
 1085: 
 1086: def test_wrong_encoding_for_lxml():
 1087:     pytest.importorskip("lxml")
 1088:     # GH#45133
 1089:     data = """<data>
 1090:   <row>
 1091:     <a>c</a>
 1092:   </row>
 1093: </data>
 1094: """
 1095:     with pytest.raises(TypeError, match="encoding None"):
 1096:         read_xml(StringIO(data), parser="lxml", encoding=None)
 1097: 
 1098: 
 1099: def test_none_encoding_etree():
 1100:     # GH#45133
 1101:     data = """<data>
 1102:   <row>
 1103:     <a>c</a>
 1104:   </row>
 1105: </data>
 1106: """
 1107:     result = read_xml(StringIO(data), parser="etree", encoding=None)
 1108:     expected = DataFrame({"a": ["c"]})
 1109:     tm.assert_frame_equal(result, expected)
 1110: 
 1111: 
 1112: # PARSER
 1113: 
 1114: 
 1115: @td.skip_if_installed("lxml")
 1116: def test_default_parser_no_lxml(xml_books):
 1117:     with pytest.raises(
 1118:         ImportError, match=("lxml not found, please install or use the etree parser.")
 1119:     ):
 1120:         read_xml(xml_books)
 1121: 
 1122: 
 1123: def test_wrong_parser(xml_books):
 1124:     with pytest.raises(
 1125:         ValueError, match=("Values for parser can only be lxml or etree.")
 1126:     ):
 1127:         read_xml(xml_books, parser="bs4")
 1128: 
 1129: 
 1130: # STYLESHEET
 1131: 
 1132: 
 1133: def test_stylesheet_file(kml_cta_rail_lines, xsl_flatten_doc):
 1134:     pytest.importorskip("lxml")
 1135:     df_style = read_xml(
 1136:         kml_cta_rail_lines,
 1137:         xpath=".//k:Placemark",
 1138:         namespaces={"k": "http://www.opengis.net/kml/2.2"},
 1139:         stylesheet=xsl_flatten_doc,
 1140:     )
 1141: 
 1142:     df_iter = read_xml(
 1143:         kml_cta_rail_lines,
 1144:         iterparse={
 1145:             "Placemark": [
 1146:                 "id",
 1147:                 "name",
 1148:                 "styleUrl",
 1149:                 "extrude",
 1150:                 "altitudeMode",
 1151:                 "coordinates",
 1152:             ]
 1153:         },
 1154:     )
 1155: 
 1156:     tm.assert_frame_equal(df_kml, df_style)
 1157:     tm.assert_frame_equal(df_kml, df_iter)
 1158: 
 1159: 
 1160: def test_stylesheet_file_like(kml_cta_rail_lines, xsl_flatten_doc, mode):
 1161:     pytest.importorskip("lxml")
 1162:     with open(xsl_flatten_doc, mode, encoding="utf-8" if mode == "r" else None) as f:
 1163:         df_style = read_xml(
 1164:             kml_cta_rail_lines,
 1165:             xpath=".//k:Placemark",
 1166:             namespaces={"k": "http://www.opengis.net/kml/2.2"},
 1167:             stylesheet=f,
 1168:         )
 1169: 
 1170:     tm.assert_frame_equal(df_kml, df_style)
 1171: 
 1172: 
 1173: def test_stylesheet_io(kml_cta_rail_lines, xsl_flatten_doc, mode):
 1174:     # note: By default the bodies of untyped functions are not checked,
 1175:     # consider using --check-untyped-defs
 1176:     pytest.importorskip("lxml")
 1177:     xsl_obj: BytesIO | StringIO  # type: ignore[annotation-unchecked]
 1178: 
 1179:     with open(xsl_flatten_doc, mode, encoding="utf-8" if mode == "r" else None) as f:
 1180:         if mode == "rb":
 1181:             xsl_obj = BytesIO(f.read())
 1182:         else:
 1183:             xsl_obj = StringIO(f.read())
 1184: 
 1185:     df_style = read_xml(
 1186:         kml_cta_rail_lines,
 1187:         xpath=".//k:Placemark",
 1188:         namespaces={"k": "http://www.opengis.net/kml/2.2"},
 1189:         stylesheet=xsl_obj,
 1190:     )
 1191: 
 1192:     tm.assert_frame_equal(df_kml, df_style)
 1193: 
 1194: 
 1195: def test_stylesheet_buffered_reader(kml_cta_rail_lines, xsl_flatten_doc, mode):
 1196:     pytest.importorskip("lxml")
 1197:     with open(xsl_flatten_doc, mode, encoding="utf-8" if mode == "r" else None) as f:
 1198:         xsl_obj = f.read()
 1199: 
 1200:     df_style = read_xml(
 1201:         kml_cta_rail_lines,
 1202:         xpath=".//k:Placemark",
 1203:         namespaces={"k": "http://www.opengis.net/kml/2.2"},
 1204:         stylesheet=xsl_obj,
 1205:     )
 1206: 
 1207:     tm.assert_frame_equal(df_kml, df_style)
 1208: 
 1209: 
 1210: def test_style_charset():
 1211:     pytest.importorskip("lxml")
 1212:     xml = "<дё­ж–‡жЁ™з±¤><row><c1>1</c1><c2>2</c2></row></дё­ж–‡жЁ™з±¤>"
 1213: 
 1214:     xsl = """\
 1215: <xsl:stylesheet version="1.0" xmlns:xsl="http://www.w3.org/1999/XSL/Transform">
 1216:  <xsl:output omit-xml-declaration="yes" indent="yes"/>
 1217:  <xsl:strip-space elements="*"/>
 1218: 
 1219:  <xsl:template match="node()|@*">
 1220:      <xsl:copy>
 1221:        <xsl:apply-templates select="node()|@*"/>
 1222:      </xsl:copy>
 1223:  </xsl:template>
 1224: 
 1225:  <xsl:template match="дё­ж–‡жЁ™з±¤">
 1226:      <ж №>
 1227:        <xsl:apply-templates />
 1228:      </ж №>
 1229:  </xsl:template>
 1230: 
 1231: </xsl:stylesheet>"""
 1232: 
 1233:     df_orig = read_xml(StringIO(xml))
 1234:     df_style = read_xml(StringIO(xml), stylesheet=xsl)
 1235: 
 1236:     tm.assert_frame_equal(df_orig, df_style)
 1237: 
 1238: 
 1239: def test_not_stylesheet(kml_cta_rail_lines, xml_books):
 1240:     lxml_etree = pytest.importorskip("lxml.etree")
 1241: 
 1242:     with pytest.raises(
 1243:         lxml_etree.XSLTParseError, match=("document is not a stylesheet")
 1244:     ):
 1245:         read_xml(kml_cta_rail_lines, stylesheet=xml_books)
 1246: 
 1247: 
 1248: def test_incorrect_xsl_syntax(kml_cta_rail_lines):
 1249:     lxml_etree = pytest.importorskip("lxml.etree")
 1250: 
 1251:     xsl = """\
 1252: <xsl:stylesheet version="1.0" xmlns:xsl="http://www.w3.org/1999/XSL/Transform"
 1253:                               xmlns:k="http://www.opengis.net/kml/2.2"/>
 1254:     <xsl:output method="xml" omit-xml-declaration="yes"
 1255:                 cdata-section-elements="k:description" indent="yes"/>
 1256:     <xsl:strip-space elements="*"/>
 1257: 
 1258:     <xsl:template match="node()|@*">
 1259:      <xsl:copy>
 1260:        <xsl:apply-templates select="node()|@*"/>
 1261:      </xsl:copy>
 1262:     </xsl:template>
 1263: 
 1264:     <xsl:template match="k:MultiGeometry|k:LineString">
 1265:         <xsl:apply-templates select='*'/>
 1266:     </xsl:template>
 1267: 
 1268:     <xsl:template match="k:description|k:Snippet|k:Style"/>
 1269: </xsl:stylesheet>"""
 1270: 
 1271:     with pytest.raises(
 1272:         lxml_etree.XMLSyntaxError, match=("Extra content at the end of the document")
 1273:     ):
 1274:         read_xml(kml_cta_rail_lines, stylesheet=xsl)
 1275: 
 1276: 
 1277: def test_incorrect_xsl_eval(kml_cta_rail_lines):
 1278:     lxml_etree = pytest.importorskip("lxml.etree")
 1279: 
 1280:     xsl = """\
 1281: <xsl:stylesheet version="1.0" xmlns:xsl="http://www.w3.org/1999/XSL/Transform"
 1282:                               xmlns:k="http://www.opengis.net/kml/2.2">
 1283:     <xsl:output method="xml" omit-xml-declaration="yes"
 1284:                 cdata-section-elements="k:description" indent="yes"/>
 1285:     <xsl:strip-space elements="*"/>
 1286: 
 1287:     <xsl:template match="node(*)|@*">
 1288:      <xsl:copy>
 1289:        <xsl:apply-templates select="node()|@*"/>
 1290:      </xsl:copy>
 1291:     </xsl:template>
 1292: 
 1293:     <xsl:template match="k:MultiGeometry|k:LineString">
 1294:         <xsl:apply-templates select='*'/>
 1295:     </xsl:template>
 1296: 
 1297:     <xsl:template match="k:description|k:Snippet|k:Style"/>
 1298: </xsl:stylesheet>"""
 1299: 
 1300:     with pytest.raises(lxml_etree.XSLTParseError, match=("failed to compile")):
 1301:         read_xml(kml_cta_rail_lines, stylesheet=xsl)
 1302: 
 1303: 
 1304: def test_incorrect_xsl_apply(kml_cta_rail_lines):
 1305:     lxml_etree = pytest.importorskip("lxml.etree")
 1306: 
 1307:     xsl = """\
 1308: <xsl:stylesheet version="1.0" xmlns:xsl="http://www.w3.org/1999/XSL/Transform">
 1309:     <xsl:output method="xml" encoding="utf-8" indent="yes" />
 1310:     <xsl:strip-space elements="*"/>
 1311: 
 1312:     <xsl:template match="@*|node()">
 1313:         <xsl:copy>
 1314:             <xsl:copy-of select="document('non_existent.xml')/*"/>
 1315:         </xsl:copy>
 1316:     </xsl:template>
 1317: </xsl:stylesheet>"""
 1318: 
 1319:     with pytest.raises(lxml_etree.XSLTApplyError, match=("Cannot resolve URI")):
 1320:         read_xml(kml_cta_rail_lines, stylesheet=xsl)
 1321: 
 1322: 
 1323: def test_wrong_stylesheet(kml_cta_rail_lines, xml_data_path):
 1324:     xml_etree = pytest.importorskip("lxml.etree")
 1325: 
 1326:     xsl = xml_data_path / "flatten.xsl"
 1327: 
 1328:     with pytest.raises(
 1329:         xml_etree.XMLSyntaxError,
 1330:         match=("Start tag expected, '<' not found"),
 1331:     ):
 1332:         read_xml(kml_cta_rail_lines, stylesheet=xsl)
 1333: 
 1334: 
 1335: def test_stylesheet_file_close(kml_cta_rail_lines, xsl_flatten_doc, mode):
 1336:     # note: By default the bodies of untyped functions are not checked,
 1337:     # consider using --check-untyped-defs
 1338:     pytest.importorskip("lxml")
 1339:     xsl_obj: BytesIO | StringIO  # type: ignore[annotation-unchecked]
 1340: 
 1341:     with open(xsl_flatten_doc, mode, encoding="utf-8" if mode == "r" else None) as f:
 1342:         if mode == "rb":
 1343:             xsl_obj = BytesIO(f.read())
 1344:         else:
 1345:             xsl_obj = StringIO(f.read())
 1346: 
 1347:         read_xml(kml_cta_rail_lines, stylesheet=xsl_obj)
 1348: 
 1349:         assert not f.closed
 1350: 
 1351: 
 1352: def test_stylesheet_with_etree(kml_cta_rail_lines, xsl_flatten_doc):
 1353:     pytest.importorskip("lxml")
 1354:     with pytest.raises(
 1355:         ValueError, match=("To use stylesheet, you need lxml installed")
 1356:     ):
 1357:         read_xml(kml_cta_rail_lines, parser="etree", stylesheet=xsl_flatten_doc)
 1358: 
 1359: 
 1360: @pytest.mark.parametrize("val", ["", b""])
 1361: def test_empty_stylesheet(val):
 1362:     pytest.importorskip("lxml")
 1363:     msg = (
 1364:         "Passing literal xml to 'read_xml' is deprecated and "
 1365:         "will be removed in a future version. To read from a "
 1366:         "literal string, wrap it in a 'StringIO' object."
 1367:     )
 1368:     kml = os.path.join("data", "xml", "cta_rail_lines.kml")
 1369: 
 1370:     with pytest.raises(FutureWarning, match=msg):
 1371:         read_xml(kml, stylesheet=val)
 1372: 
 1373: 
 1374: # ITERPARSE
 1375: def test_file_like_iterparse(xml_books, parser, mode):
 1376:     with open(xml_books, mode, encoding="utf-8" if mode == "r" else None) as f:
 1377:         if mode == "r" and parser == "lxml":
 1378:             with pytest.raises(
 1379:                 TypeError, match=("reading file objects must return bytes objects")
 1380:             ):
 1381:                 read_xml(
 1382:                     f,
 1383:                     parser=parser,
 1384:                     iterparse={
 1385:                         "book": ["category", "title", "year", "author", "price"]
 1386:                     },
 1387:                 )
 1388:             return None
 1389:         else:
 1390:             df_filelike = read_xml(
 1391:                 f,
 1392:                 parser=parser,
 1393:                 iterparse={"book": ["category", "title", "year", "author", "price"]},
 1394:             )
 1395: 
 1396:     df_expected = DataFrame(
 1397:         {
 1398:             "category": ["cooking", "children", "web"],
 1399:             "title": ["Everyday Italian", "Harry Potter", "Learning XML"],
 1400:             "author": ["Giada De Laurentiis", "J K. Rowling", "Erik T. Ray"],
 1401:             "year": [2005, 2005, 2003],
 1402:             "price": [30.00, 29.99, 39.95],
 1403:         }
 1404:     )
 1405: 
 1406:     tm.assert_frame_equal(df_filelike, df_expected)
 1407: 
 1408: 
 1409: def test_file_io_iterparse(xml_books, parser, mode):
 1410:     funcIO = StringIO if mode == "r" else BytesIO
 1411:     with open(
 1412:         xml_books,
 1413:         mode,
 1414:         encoding="utf-8" if mode == "r" else None,
 1415:     ) as f:
 1416:         with funcIO(f.read()) as b:
 1417:             if mode == "r" and parser == "lxml":
 1418:                 with pytest.raises(
 1419:                     TypeError, match=("reading file objects must return bytes objects")
 1420:                 ):
 1421:                     read_xml(
 1422:                         b,
 1423:                         parser=parser,
 1424:                         iterparse={
 1425:                             "book": ["category", "title", "year", "author", "price"]
 1426:                         },
 1427:                     )
 1428:                 return None
 1429:             else:
 1430:                 df_fileio = read_xml(
 1431:                     b,
 1432:                     parser=parser,
 1433:                     iterparse={
 1434:                         "book": ["category", "title", "year", "author", "price"]
 1435:                     },
 1436:                 )
 1437: 
 1438:     df_expected = DataFrame(
 1439:         {
 1440:             "category": ["cooking", "children", "web"],
 1441:             "title": ["Everyday Italian", "Harry Potter", "Learning XML"],
 1442:             "author": ["Giada De Laurentiis", "J K. Rowling", "Erik T. Ray"],
 1443:             "year": [2005, 2005, 2003],
 1444:             "price": [30.00, 29.99, 39.95],
 1445:         }
 1446:     )
 1447: 
 1448:     tm.assert_frame_equal(df_fileio, df_expected)
 1449: 
 1450: 
 1451: @pytest.mark.network
 1452: @pytest.mark.single_cpu
 1453: def test_url_path_error(parser, httpserver, xml_file):
 1454:     with open(xml_file, encoding="utf-8") as f:
 1455:         httpserver.serve_content(content=f.read())
 1456:         with pytest.raises(
 1457:             ParserError, match=("iterparse is designed for large XML files")
 1458:         ):
 1459:             read_xml(
 1460:                 httpserver.url,
 1461:                 parser=parser,
 1462:                 iterparse={"row": ["shape", "degrees", "sides", "date"]},
 1463:             )
 1464: 
 1465: 
 1466: def test_compression_error(parser, compression_only):
 1467:     with tm.ensure_clean(filename="geom_xml.zip") as path:
 1468:         geom_df.to_xml(path, parser=parser, compression=compression_only)
 1469: 
 1470:         with pytest.raises(
 1471:             ParserError, match=("iterparse is designed for large XML files")
 1472:         ):
 1473:             read_xml(
 1474:                 path,
 1475:                 parser=parser,
 1476:                 iterparse={"row": ["shape", "degrees", "sides", "date"]},
 1477:                 compression=compression_only,
 1478:             )
 1479: 
 1480: 
 1481: def test_wrong_dict_type(xml_books, parser):
 1482:     with pytest.raises(TypeError, match="list is not a valid type for iterparse"):
 1483:         read_xml(
 1484:             xml_books,
 1485:             parser=parser,
 1486:             iterparse=["category", "title", "year", "author", "price"],
 1487:         )
 1488: 
 1489: 
 1490: def test_wrong_dict_value(xml_books, parser):
 1491:     with pytest.raises(
 1492:         TypeError, match="<class 'str'> is not a valid type for value in iterparse"
 1493:     ):
 1494:         read_xml(xml_books, parser=parser, iterparse={"book": "category"})
 1495: 
 1496: 
 1497: def test_bad_xml(parser):
 1498:     bad_xml = """\
 1499: <?xml version='1.0' encoding='utf-8'?>
 1500:   <row>
 1501:     <shape>square</shape>
 1502:     <degrees>00360</degrees>
 1503:     <sides>4.0</sides>
 1504:     <date>2020-01-01</date>
 1505:    </row>
 1506:   <row>
 1507:     <shape>circle</shape>
 1508:     <degrees>00360</degrees>
 1509:     <sides/>
 1510:     <date>2021-01-01</date>
 1511:   </row>
 1512:   <row>
 1513:     <shape>triangle</shape>
 1514:     <degrees>00180</degrees>
 1515:     <sides>3.0</sides>
 1516:     <date>2022-01-01</date>
 1517:   </row>
 1518: """
 1519:     with tm.ensure_clean(filename="bad.xml") as path:
 1520:         with open(path, "w", encoding="utf-8") as f:
 1521:             f.write(bad_xml)
 1522: 
 1523:         with pytest.raises(
 1524:             SyntaxError,
 1525:             match=(
 1526:                 "Extra content at the end of the document|"
 1527:                 "junk after document element"
 1528:             ),
 1529:         ):
 1530:             read_xml(
 1531:                 path,
 1532:                 parser=parser,
 1533:                 parse_dates=["date"],
 1534:                 iterparse={"row": ["shape", "degrees", "sides", "date"]},
 1535:             )
 1536: 
 1537: 
 1538: def test_comment(parser):
 1539:     xml = """\
 1540: <!-- comment before root -->
 1541: <shapes>
 1542:   <!-- comment within root -->
 1543:   <shape>
 1544:     <name>circle</name>
 1545:     <type>2D</type>
 1546:   </shape>
 1547:   <shape>
 1548:     <name>sphere</name>
 1549:     <type>3D</type>
 1550:     <!-- comment within child -->
 1551:   </shape>
 1552:   <!-- comment within root -->
 1553: </shapes>
 1554: <!-- comment after root -->"""
 1555: 
 1556:     df_xpath = read_xml(StringIO(xml), xpath=".//shape", parser=parser)
 1557: 
 1558:     df_iter = read_xml_iterparse(
 1559:         xml, parser=parser, iterparse={"shape": ["name", "type"]}
 1560:     )
 1561: 
 1562:     df_expected = DataFrame(
 1563:         {
 1564:             "name": ["circle", "sphere"],
 1565:             "type": ["2D", "3D"],
 1566:         }
 1567:     )
 1568: 
 1569:     tm.assert_frame_equal(df_xpath, df_expected)
 1570:     tm.assert_frame_equal(df_iter, df_expected)
 1571: 
 1572: 
 1573: def test_dtd(parser):
 1574:     xml = """\
 1575: <?xml version="1.0" encoding="UTF-8"?>
 1576: <!DOCTYPE non-profits [
 1577:     <!ELEMENT shapes (shape*) >
 1578:     <!ELEMENT shape ( name, type )>
 1579:     <!ELEMENT name (#PCDATA)>
 1580: ]>
 1581: <shapes>
 1582:   <shape>
 1583:     <name>circle</name>
 1584:     <type>2D</type>
 1585:   </shape>
 1586:   <shape>
 1587:     <name>sphere</name>
 1588:     <type>3D</type>
 1589:   </shape>
 1590: </shapes>"""
 1591: 
 1592:     df_xpath = read_xml(StringIO(xml), xpath=".//shape", parser=parser)
 1593: 
 1594:     df_iter = read_xml_iterparse(
 1595:         xml, parser=parser, iterparse={"shape": ["name", "type"]}
 1596:     )
 1597: 
 1598:     df_expected = DataFrame(
 1599:         {
 1600:             "name": ["circle", "sphere"],
 1601:             "type": ["2D", "3D"],
 1602:         }
 1603:     )
 1604: 
 1605:     tm.assert_frame_equal(df_xpath, df_expected)
 1606:     tm.assert_frame_equal(df_iter, df_expected)
 1607: 
 1608: 
 1609: def test_processing_instruction(parser):
 1610:     xml = """\
 1611: <?xml version="1.0" encoding="UTF-8"?>
 1612: <?xml-stylesheet type="text/xsl" href="style.xsl"?>
 1613: <?display table-view?>
 1614: <?sort alpha-ascending?>
 1615: <?textinfo whitespace is allowed ?>
 1616: <?elementnames <shape>, <name>, <type> ?>
 1617: <shapes>
 1618:   <shape>
 1619:     <name>circle</name>
 1620:     <type>2D</type>
 1621:   </shape>
 1622:   <shape>
 1623:     <name>sphere</name>
 1624:     <type>3D</type>
 1625:   </shape>
 1626: </shapes>"""
 1627: 
 1628:     df_xpath = read_xml(StringIO(xml), xpath=".//shape", parser=parser)
 1629: 
 1630:     df_iter = read_xml_iterparse(
 1631:         xml, parser=parser, iterparse={"shape": ["name", "type"]}
 1632:     )
 1633: 
 1634:     df_expected = DataFrame(
 1635:         {
 1636:             "name": ["circle", "sphere"],
 1637:             "type": ["2D", "3D"],
 1638:         }
 1639:     )
 1640: 
 1641:     tm.assert_frame_equal(df_xpath, df_expected)
 1642:     tm.assert_frame_equal(df_iter, df_expected)
 1643: 
 1644: 
 1645: def test_no_result(xml_books, parser):
 1646:     with pytest.raises(
 1647:         ParserError, match="No result from selected items in iterparse."
 1648:     ):
 1649:         read_xml(
 1650:             xml_books,
 1651:             parser=parser,
 1652:             iterparse={"node": ["attr1", "elem1", "elem2", "elem3"]},
 1653:         )
 1654: 
 1655: 
 1656: def test_empty_data(xml_books, parser):
 1657:     with pytest.raises(EmptyDataError, match="No columns to parse from file"):
 1658:         read_xml(
 1659:             xml_books,
 1660:             parser=parser,
 1661:             iterparse={"book": ["attr1", "elem1", "elem2", "elem3"]},
 1662:         )
 1663: 
 1664: 
 1665: def test_online_stylesheet():
 1666:     pytest.importorskip("lxml")
 1667:     xml = """\
 1668: <?xml version="1.0" encoding="UTF-8"?>
 1669: <catalog>
 1670:   <cd>
 1671:     <title>Empire Burlesque</title>
 1672:     <artist>Bob Dylan</artist>
 1673:     <country>USA</country>
 1674:     <company>Columbia</company>
 1675:     <price>10.90</price>
 1676:     <year>1985</year>
 1677:   </cd>
 1678:   <cd>
 1679:     <title>Hide your heart</title>
 1680:     <artist>Bonnie Tyler</artist>
 1681:     <country>UK</country>
 1682:     <company>CBS Records</company>
 1683:     <price>9.90</price>
 1684:     <year>1988</year>
 1685:   </cd>
 1686:   <cd>
 1687:     <title>Greatest Hits</title>
 1688:     <artist>Dolly Parton</artist>
 1689:     <country>USA</country>
 1690:     <company>RCA</company>
 1691:     <price>9.90</price>
 1692:     <year>1982</year>
 1693:   </cd>
 1694:   <cd>
 1695:     <title>Still got the blues</title>
 1696:     <artist>Gary Moore</artist>
 1697:     <country>UK</country>
 1698:     <company>Virgin records</company>
 1699:     <price>10.20</price>
 1700:     <year>1990</year>
 1701:   </cd>
 1702:   <cd>
 1703:     <title>Eros</title>
 1704:     <artist>Eros Ramazzotti</artist>
 1705:     <country>EU</country>
 1706:     <company>BMG</company>
 1707:     <price>9.90</price>
 1708:     <year>1997</year>
 1709:   </cd>
 1710:   <cd>
 1711:     <title>One night only</title>
 1712:     <artist>Bee Gees</artist>
 1713:     <country>UK</country>
 1714:     <company>Polydor</company>
 1715:     <price>10.90</price>
 1716:     <year>1998</year>
 1717:   </cd>
 1718:   <cd>
 1719:     <title>Sylvias Mother</title>
 1720:     <artist>Dr.Hook</artist>
 1721:     <country>UK</country>
 1722:     <company>CBS</company>
 1723:     <price>8.10</price>
 1724:     <year>1973</year>
 1725:   </cd>
 1726:   <cd>
 1727:     <title>Maggie May</title>
 1728:     <artist>Rod Stewart</artist>
 1729:     <country>UK</country>
 1730:     <company>Pickwick</company>
 1731:     <price>8.50</price>
 1732:     <year>1990</year>
 1733:   </cd>
 1734:   <cd>
 1735:     <title>Romanza</title>
 1736:     <artist>Andrea Bocelli</artist>
 1737:     <country>EU</country>
 1738:     <company>Polydor</company>
 1739:     <price>10.80</price>
 1740:     <year>1996</year>
 1741:   </cd>
 1742:   <cd>
 1743:     <title>When a man loves a woman</title>
 1744:     <artist>Percy Sledge</artist>
 1745:     <country>USA</country>
 1746:     <company>Atlantic</company>
 1747:     <price>8.70</price>
 1748:     <year>1987</year>
 1749:   </cd>
 1750:   <cd>
 1751:     <title>Black angel</title>
 1752:     <artist>Savage Rose</artist>
 1753:     <country>EU</country>
 1754:     <company>Mega</company>
 1755:     <price>10.90</price>
 1756:     <year>1995</year>
 1757:   </cd>
 1758:   <cd>
 1759:     <title>1999 Grammy Nominees</title>
 1760:     <artist>Many</artist>
 1761:     <country>USA</country>
 1762:     <company>Grammy</company>
 1763:     <price>10.20</price>
 1764:     <year>1999</year>
 1765:   </cd>
 1766:   <cd>
 1767:     <title>For the good times</title>
 1768:     <artist>Kenny Rogers</artist>
 1769:     <country>UK</country>
 1770:     <company>Mucik Master</company>
 1771:     <price>8.70</price>
 1772:     <year>1995</year>
 1773:   </cd>
 1774:   <cd>
 1775:     <title>Big Willie style</title>
 1776:     <artist>Will Smith</artist>
 1777:     <country>USA</country>
 1778:     <company>Columbia</company>
 1779:     <price>9.90</price>
 1780:     <year>1997</year>
 1781:   </cd>
 1782:   <cd>
 1783:     <title>Tupelo Honey</title>
 1784:     <artist>Van Morrison</artist>
 1785:     <country>UK</country>
 1786:     <company>Polydor</company>
 1787:     <price>8.20</price>
 1788:     <year>1971</year>
 1789:   </cd>
 1790:   <cd>
 1791:     <title>Soulsville</title>
 1792:     <artist>Jorn Hoel</artist>
 1793:     <country>Norway</country>
 1794:     <company>WEA</company>
 1795:     <price>7.90</price>
 1796:     <year>1996</year>
 1797:   </cd>
 1798:   <cd>
 1799:     <title>The very best of</title>
 1800:     <artist>Cat Stevens</artist>
 1801:     <country>UK</country>
 1802:     <company>Island</company>
 1803:     <price>8.90</price>
 1804:     <year>1990</year>
 1805:   </cd>
 1806:   <cd>
 1807:     <title>Stop</title>
 1808:     <artist>Sam Brown</artist>
 1809:     <country>UK</country>
 1810:     <company>A and M</company>
 1811:     <price>8.90</price>
 1812:     <year>1988</year>
 1813:   </cd>
 1814:   <cd>
 1815:     <title>Bridge of Spies</title>
 1816:     <artist>T`Pau</artist>
 1817:     <country>UK</country>
 1818:     <company>Siren</company>
 1819:     <price>7.90</price>
 1820:     <year>1987</year>
 1821:   </cd>
 1822:   <cd>
 1823:     <title>Private Dancer</title>
 1824:     <artist>Tina Turner</artist>
 1825:     <country>UK</country>
 1826:     <company>Capitol</company>
 1827:     <price>8.90</price>
 1828:     <year>1983</year>
 1829:   </cd>
 1830:   <cd>
 1831:     <title>Midt om natten</title>
 1832:     <artist>Kim Larsen</artist>
 1833:     <country>EU</country>
 1834:     <company>Medley</company>
 1835:     <price>7.80</price>
 1836:     <year>1983</year>
 1837:   </cd>
 1838:   <cd>
 1839:     <title>Pavarotti Gala Concert</title>
 1840:     <artist>Luciano Pavarotti</artist>
 1841:     <country>UK</country>
 1842:     <company>DECCA</company>
 1843:     <price>9.90</price>
 1844:     <year>1991</year>
 1845:   </cd>
 1846:   <cd>
 1847:     <title>The dock of the bay</title>
 1848:     <artist>Otis Redding</artist>
 1849:     <country>USA</country>
 1850:     <COMPANY>Stax Records</COMPANY>
 1851:     <PRICE>7.90</PRICE>
 1852:     <YEAR>1968</YEAR>
 1853:   </cd>
 1854:   <cd>
 1855:     <title>Picture book</title>
 1856:     <artist>Simply Red</artist>
 1857:     <country>EU</country>
 1858:     <company>Elektra</company>
 1859:     <price>7.20</price>
 1860:     <year>1985</year>
 1861:   </cd>
 1862:   <cd>
 1863:     <title>Red</title>
 1864:     <artist>The Communards</artist>
 1865:     <country>UK</country>
 1866:     <company>London</company>
 1867:     <price>7.80</price>
 1868:     <year>1987</year>
 1869:   </cd>
 1870:   <cd>
 1871:     <title>Unchain my heart</title>
 1872:     <artist>Joe Cocker</artist>
 1873:     <country>USA</country>
 1874:     <company>EMI</company>
 1875:     <price>8.20</price>
 1876:     <year>1987</year>
 1877:   </cd>
 1878: </catalog>
 1879: """
 1880:     xsl = """\
 1881: <?xml version="1.0" encoding="UTF-8"?>
 1882: <xsl:stylesheet version="1.0" xmlns:xsl="http://www.w3.org/1999/XSL/Transform">
 1883: <xsl:template match="/">
 1884: <html>
 1885: <body>
 1886:   <h2>My CD Collection</h2>
 1887:   <table border="1">
 1888:     <tr bgcolor="#9acd32">
 1889:       <th style="text-align:left">Title</th>
 1890:       <th style="text-align:left">Artist</th>
 1891:     </tr>
 1892:     <xsl:for-each select="catalog/cd">
 1893:     <tr>
 1894:       <td><xsl:value-of select="title"/></td>
 1895:       <td><xsl:value-of select="artist"/></td>
 1896:     </tr>
 1897:     </xsl:for-each>
 1898:   </table>
 1899: </body>
 1900: </html>
 1901: </xsl:template>
 1902: </xsl:stylesheet>
 1903: """
 1904: 
 1905:     df_xsl = read_xml(
 1906:         StringIO(xml),
 1907:         xpath=".//tr[td and position() <= 6]",
 1908:         names=["title", "artist"],
 1909:         stylesheet=xsl,
 1910:     )
 1911: 
 1912:     df_expected = DataFrame(
 1913:         {
 1914:             "title": {
 1915:                 0: "Empire Burlesque",
 1916:                 1: "Hide your heart",
 1917:                 2: "Greatest Hits",
 1918:                 3: "Still got the blues",
 1919:                 4: "Eros",
 1920:             },
 1921:             "artist": {
 1922:                 0: "Bob Dylan",
 1923:                 1: "Bonnie Tyler",
 1924:                 2: "Dolly Parton",
 1925:                 3: "Gary Moore",
 1926:                 4: "Eros Ramazzotti",
 1927:             },
 1928:         }
 1929:     )
 1930: 
 1931:     tm.assert_frame_equal(df_expected, df_xsl)
 1932: 
 1933: 
 1934: # COMPRESSION
 1935: 
 1936: 
 1937: def test_compression_read(parser, compression_only):
 1938:     with tm.ensure_clean() as comp_path:
 1939:         geom_df.to_xml(
 1940:             comp_path, index=False, parser=parser, compression=compression_only
 1941:         )
 1942: 
 1943:         df_xpath = read_xml(comp_path, parser=parser, compression=compression_only)
 1944: 
 1945:         df_iter = read_xml_iterparse_comp(
 1946:             comp_path,
 1947:             compression_only,
 1948:             parser=parser,
 1949:             iterparse={"row": ["shape", "degrees", "sides"]},
 1950:             compression=compression_only,
 1951:         )
 1952: 
 1953:     tm.assert_frame_equal(df_xpath, geom_df)
 1954:     tm.assert_frame_equal(df_iter, geom_df)
 1955: 
 1956: 
 1957: def test_wrong_compression(parser, compression, compression_only):
 1958:     actual_compression = compression
 1959:     attempted_compression = compression_only
 1960: 
 1961:     if actual_compression == attempted_compression:
 1962:         pytest.skip(f"{actual_compression} == {attempted_compression}")
 1963: 
 1964:     errors = {
 1965:         "bz2": (OSError, "Invalid data stream"),
 1966:         "gzip": (OSError, "Not a gzipped file"),
 1967:         "zip": (BadZipFile, "File is not a zip file"),
 1968:         "tar": (ReadError, "file could not be opened successfully"),
 1969:     }
 1970:     zstd = import_optional_dependency("zstandard", errors="ignore")
 1971:     if zstd is not None:
 1972:         errors["zstd"] = (zstd.ZstdError, "Unknown frame descriptor")
 1973:     lzma = import_optional_dependency("lzma", errors="ignore")
 1974:     if lzma is not None:
 1975:         errors["xz"] = (LZMAError, "Input format not supported by decoder")
 1976:     error_cls, error_str = errors[attempted_compression]
 1977: 
 1978:     with tm.ensure_clean() as path:
 1979:         geom_df.to_xml(path, parser=parser, compression=actual_compression)
 1980: 
 1981:         with pytest.raises(error_cls, match=error_str):
 1982:             read_xml(path, parser=parser, compression=attempted_compression)
 1983: 
 1984: 
 1985: def test_unsuported_compression(parser):
 1986:     with pytest.raises(ValueError, match="Unrecognized compression type"):
 1987:         with tm.ensure_clean() as path:
 1988:             read_xml(path, parser=parser, compression="7z")
 1989: 
 1990: 
 1991: # STORAGE OPTIONS
 1992: 
 1993: 
 1994: @pytest.mark.network
 1995: @pytest.mark.single_cpu
 1996: def test_s3_parser_consistency(s3_public_bucket_with_data, s3so):
 1997:     pytest.importorskip("s3fs")
 1998:     pytest.importorskip("lxml")
 1999:     s3 = f"s3://{s3_public_bucket_with_data.name}/books.xml"
 2000: 
 2001:     df_lxml = read_xml(s3, parser="lxml", storage_options=s3so)
 2002: 
 2003:     df_etree = read_xml(s3, parser="etree", storage_options=s3so)
 2004: 
 2005:     tm.assert_frame_equal(df_lxml, df_etree)
 2006: 
 2007: 
 2008: def test_read_xml_nullable_dtypes(
 2009:     parser, string_storage, dtype_backend, using_infer_string
 2010: ):
 2011:     # GH#50500
 2012:     data = """<?xml version='1.0' encoding='utf-8'?>
 2013: <data xmlns="http://example.com">
 2014: <row>
 2015:   <a>x</a>
 2016:   <b>1</b>
 2017:   <c>4.0</c>
 2018:   <d>x</d>
 2019:   <e>2</e>
 2020:   <f>4.0</f>
 2021:   <g></g>
 2022:   <h>True</h>
 2023:   <i>False</i>
 2024: </row>
 2025: <row>
 2026:   <a>y</a>
 2027:   <b>2</b>
 2028:   <c>5.0</c>
 2029:   <d></d>
 2030:   <e></e>
 2031:   <f></f>
 2032:   <g></g>
 2033:   <h>False</h>
 2034:   <i></i>
 2035: </row>
 2036: </data>"""
 2037: 
 2038:     if using_infer_string:
 2039:         pa = pytest.importorskip("pyarrow")
 2040:         string_array = ArrowStringArrayNumpySemantics(pa.array(["x", "y"]))
 2041:         string_array_na = ArrowStringArrayNumpySemantics(pa.array(["x", None]))
 2042: 
 2043:     elif string_storage == "python":
 2044:         string_array = StringArray(np.array(["x", "y"], dtype=np.object_))
 2045:         string_array_na = StringArray(np.array(["x", NA], dtype=np.object_))
 2046: 
 2047:     elif dtype_backend == "pyarrow":
 2048:         pa = pytest.importorskip("pyarrow")
 2049:         from pandas.arrays import ArrowExtensionArray
 2050: 
 2051:         string_array = ArrowExtensionArray(pa.array(["x", "y"]))
 2052:         string_array_na = ArrowExtensionArray(pa.array(["x", None]))
 2053: 
 2054:     else:
 2055:         pa = pytest.importorskip("pyarrow")
 2056:         string_array = ArrowStringArray(pa.array(["x", "y"]))
 2057:         string_array_na = ArrowStringArray(pa.array(["x", None]))
 2058: 
 2059:     with pd.option_context("mode.string_storage", string_storage):
 2060:         result = read_xml(StringIO(data), parser=parser, dtype_backend=dtype_backend)
 2061: 
 2062:     expected = DataFrame(
 2063:         {
 2064:             "a": string_array,
 2065:             "b": Series([1, 2], dtype="Int64"),
 2066:             "c": Series([4.0, 5.0], dtype="Float64"),
 2067:             "d": string_array_na,
 2068:             "e": Series([2, NA], dtype="Int64"),
 2069:             "f": Series([4.0, NA], dtype="Float64"),
 2070:             "g": Series([NA, NA], dtype="Int64"),
 2071:             "h": Series([True, False], dtype="boolean"),
 2072:             "i": Series([False, NA], dtype="boolean"),
 2073:         }
 2074:     )
 2075: 
 2076:     if dtype_backend == "pyarrow":
 2077:         pa = pytest.importorskip("pyarrow")
 2078:         from pandas.arrays import ArrowExtensionArray
 2079: 
 2080:         expected = DataFrame(
 2081:             {
 2082:                 col: ArrowExtensionArray(pa.array(expected[col], from_pandas=True))
 2083:                 for col in expected.columns
 2084:             }
 2085:         )
 2086:         expected["g"] = ArrowExtensionArray(pa.array([None, None]))
 2087: 
 2088:     tm.assert_frame_equal(result, expected)
 2089: 
 2090: 
 2091: def test_invalid_dtype_backend():
 2092:     msg = (
 2093:         "dtype_backend numpy is invalid, only 'numpy_nullable' and "
 2094:         "'pyarrow' are allowed."
 2095:     )
 2096:     with pytest.raises(ValueError, match=msg):
 2097:         read_xml("test", dtype_backend="numpy")
