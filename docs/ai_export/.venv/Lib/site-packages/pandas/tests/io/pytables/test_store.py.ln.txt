    1: import contextlib
    2: import datetime as dt
    3: import hashlib
    4: import tempfile
    5: import time
    6: 
    7: import numpy as np
    8: import pytest
    9: 
   10: import pandas as pd
   11: from pandas import (
   12:     DataFrame,
   13:     DatetimeIndex,
   14:     Index,
   15:     MultiIndex,
   16:     Series,
   17:     Timestamp,
   18:     concat,
   19:     date_range,
   20:     period_range,
   21:     timedelta_range,
   22: )
   23: import pandas._testing as tm
   24: from pandas.tests.io.pytables.common import (
   25:     _maybe_remove,
   26:     ensure_clean_store,
   27: )
   28: 
   29: from pandas.io.pytables import (
   30:     HDFStore,
   31:     read_hdf,
   32: )
   33: 
   34: pytestmark = pytest.mark.single_cpu
   35: 
   36: tables = pytest.importorskip("tables")
   37: 
   38: 
   39: def test_context(setup_path):
   40:     with tm.ensure_clean(setup_path) as path:
   41:         try:
   42:             with HDFStore(path) as tbl:
   43:                 raise ValueError("blah")
   44:         except ValueError:
   45:             pass
   46:     with tm.ensure_clean(setup_path) as path:
   47:         with HDFStore(path) as tbl:
   48:             tbl["a"] = DataFrame(
   49:                 1.1 * np.arange(120).reshape((30, 4)),
   50:                 columns=Index(list("ABCD"), dtype=object),
   51:                 index=Index([f"i-{i}" for i in range(30)], dtype=object),
   52:             )
   53:             assert len(tbl) == 1
   54:             assert type(tbl["a"]) == DataFrame
   55: 
   56: 
   57: def test_no_track_times(tmp_path, setup_path):
   58:     # GH 32682
   59:     # enables to set track_times (see `pytables` `create_table` documentation)
   60: 
   61:     def checksum(filename, hash_factory=hashlib.md5, chunk_num_blocks=128):
   62:         h = hash_factory()
   63:         with open(filename, "rb") as f:
   64:             for chunk in iter(lambda: f.read(chunk_num_blocks * h.block_size), b""):
   65:                 h.update(chunk)
   66:         return h.digest()
   67: 
   68:     def create_h5_and_return_checksum(tmp_path, track_times):
   69:         path = tmp_path / setup_path
   70:         df = DataFrame({"a": [1]})
   71: 
   72:         with HDFStore(path, mode="w") as hdf:
   73:             hdf.put(
   74:                 "table",
   75:                 df,
   76:                 format="table",
   77:                 data_columns=True,
   78:                 index=None,
   79:                 track_times=track_times,
   80:             )
   81: 
   82:         return checksum(path)
   83: 
   84:     checksum_0_tt_false = create_h5_and_return_checksum(tmp_path, track_times=False)
   85:     checksum_0_tt_true = create_h5_and_return_checksum(tmp_path, track_times=True)
   86: 
   87:     # sleep is necessary to create h5 with different creation time
   88:     time.sleep(1)
   89: 
   90:     checksum_1_tt_false = create_h5_and_return_checksum(tmp_path, track_times=False)
   91:     checksum_1_tt_true = create_h5_and_return_checksum(tmp_path, track_times=True)
   92: 
   93:     # checksums are the same if track_time = False
   94:     assert checksum_0_tt_false == checksum_1_tt_false
   95: 
   96:     # checksums are NOT same if track_time = True
   97:     assert checksum_0_tt_true != checksum_1_tt_true
   98: 
   99: 
  100: def test_iter_empty(setup_path):
  101:     with ensure_clean_store(setup_path) as store:
  102:         # GH 12221
  103:         assert list(store) == []
  104: 
  105: 
  106: def test_repr(setup_path):
  107:     with ensure_clean_store(setup_path) as store:
  108:         repr(store)
  109:         store.info()
  110:         store["a"] = Series(
  111:             np.arange(10, dtype=np.float64), index=date_range("2020-01-01", periods=10)
  112:         )
  113:         store["b"] = Series(
  114:             range(10), dtype="float64", index=[f"i_{i}" for i in range(10)]
  115:         )
  116:         store["c"] = DataFrame(
  117:             1.1 * np.arange(120).reshape((30, 4)),
  118:             columns=Index(list("ABCD"), dtype=object),
  119:             index=Index([f"i-{i}" for i in range(30)], dtype=object),
  120:         )
  121: 
  122:         df = DataFrame(
  123:             1.1 * np.arange(120).reshape((30, 4)),
  124:             columns=Index(list("ABCD"), dtype=object),
  125:             index=Index([f"i-{i}" for i in range(30)], dtype=object),
  126:         )
  127:         df["obj1"] = "foo"
  128:         df["obj2"] = "bar"
  129:         df["bool1"] = df["A"] > 0
  130:         df["bool2"] = df["B"] > 0
  131:         df["bool3"] = True
  132:         df["int1"] = 1
  133:         df["int2"] = 2
  134:         df["timestamp1"] = Timestamp("20010102")
  135:         df["timestamp2"] = Timestamp("20010103")
  136:         df["datetime1"] = dt.datetime(2001, 1, 2, 0, 0)
  137:         df["datetime2"] = dt.datetime(2001, 1, 3, 0, 0)
  138:         df.loc[df.index[3:6], ["obj1"]] = np.nan
  139:         df = df._consolidate()
  140: 
  141:         with tm.assert_produces_warning(pd.errors.PerformanceWarning):
  142:             store["df"] = df
  143: 
  144:         # make a random group in hdf space
  145:         store._handle.create_group(store._handle.root, "bah")
  146: 
  147:         assert store.filename in repr(store)
  148:         assert store.filename in str(store)
  149:         store.info()
  150: 
  151:     # storers
  152:     with ensure_clean_store(setup_path) as store:
  153:         df = DataFrame(
  154:             1.1 * np.arange(120).reshape((30, 4)),
  155:             columns=Index(list("ABCD"), dtype=object),
  156:             index=Index([f"i-{i}" for i in range(30)], dtype=object),
  157:         )
  158:         store.append("df", df)
  159: 
  160:         s = store.get_storer("df")
  161:         repr(s)
  162:         str(s)
  163: 
  164: 
  165: def test_contains(setup_path):
  166:     with ensure_clean_store(setup_path) as store:
  167:         store["a"] = Series(
  168:             np.arange(10, dtype=np.float64), index=date_range("2020-01-01", periods=10)
  169:         )
  170:         store["b"] = DataFrame(
  171:             1.1 * np.arange(120).reshape((30, 4)),
  172:             columns=Index(list("ABCD"), dtype=object),
  173:             index=Index([f"i-{i}" for i in range(30)], dtype=object),
  174:         )
  175:         store["foo/bar"] = DataFrame(
  176:             1.1 * np.arange(120).reshape((30, 4)),
  177:             columns=Index(list("ABCD"), dtype=object),
  178:             index=Index([f"i-{i}" for i in range(30)], dtype=object),
  179:         )
  180:         assert "a" in store
  181:         assert "b" in store
  182:         assert "c" not in store
  183:         assert "foo/bar" in store
  184:         assert "/foo/bar" in store
  185:         assert "/foo/b" not in store
  186:         assert "bar" not in store
  187: 
  188:         # gh-2694: tables.NaturalNameWarning
  189:         with tm.assert_produces_warning(
  190:             tables.NaturalNameWarning, check_stacklevel=False
  191:         ):
  192:             store["node())"] = DataFrame(
  193:                 1.1 * np.arange(120).reshape((30, 4)),
  194:                 columns=Index(list("ABCD"), dtype=object),
  195:                 index=Index([f"i-{i}" for i in range(30)], dtype=object),
  196:             )
  197:         assert "node())" in store
  198: 
  199: 
  200: def test_versioning(setup_path):
  201:     with ensure_clean_store(setup_path) as store:
  202:         store["a"] = Series(
  203:             np.arange(10, dtype=np.float64), index=date_range("2020-01-01", periods=10)
  204:         )
  205:         store["b"] = DataFrame(
  206:             1.1 * np.arange(120).reshape((30, 4)),
  207:             columns=Index(list("ABCD"), dtype=object),
  208:             index=Index([f"i-{i}" for i in range(30)], dtype=object),
  209:         )
  210:         df = DataFrame(
  211:             np.random.default_rng(2).standard_normal((20, 4)),
  212:             columns=Index(list("ABCD"), dtype=object),
  213:             index=date_range("2000-01-01", periods=20, freq="B"),
  214:         )
  215:         _maybe_remove(store, "df1")
  216:         store.append("df1", df[:10])
  217:         store.append("df1", df[10:])
  218:         assert store.root.a._v_attrs.pandas_version == "0.15.2"
  219:         assert store.root.b._v_attrs.pandas_version == "0.15.2"
  220:         assert store.root.df1._v_attrs.pandas_version == "0.15.2"
  221: 
  222:         # write a file and wipe its versioning
  223:         _maybe_remove(store, "df2")
  224:         store.append("df2", df)
  225: 
  226:         # this is an error because its table_type is appendable, but no
  227:         # version info
  228:         store.get_node("df2")._v_attrs.pandas_version = None
  229: 
  230:         msg = "'NoneType' object has no attribute 'startswith'"
  231: 
  232:         with pytest.raises(Exception, match=msg):
  233:             store.select("df2")
  234: 
  235: 
  236: @pytest.mark.parametrize(
  237:     "where, expected",
  238:     [
  239:         (
  240:             "/",
  241:             {
  242:                 "": ({"first_group", "second_group"}, set()),
  243:                 "/first_group": (set(), {"df1", "df2"}),
  244:                 "/second_group": ({"third_group"}, {"df3", "s1"}),
  245:                 "/second_group/third_group": (set(), {"df4"}),
  246:             },
  247:         ),
  248:         (
  249:             "/second_group",
  250:             {
  251:                 "/second_group": ({"third_group"}, {"df3", "s1"}),
  252:                 "/second_group/third_group": (set(), {"df4"}),
  253:             },
  254:         ),
  255:     ],
  256: )
  257: def test_walk(where, expected):
  258:     # GH10143
  259:     objs = {
  260:         "df1": DataFrame([1, 2, 3]),
  261:         "df2": DataFrame([4, 5, 6]),
  262:         "df3": DataFrame([6, 7, 8]),
  263:         "df4": DataFrame([9, 10, 11]),
  264:         "s1": Series([10, 9, 8]),
  265:         # Next 3 items aren't pandas objects and should be ignored
  266:         "a1": np.array([[1, 2, 3], [4, 5, 6]]),
  267:         "tb1": np.array([(1, 2, 3), (4, 5, 6)], dtype="i,i,i"),
  268:         "tb2": np.array([(7, 8, 9), (10, 11, 12)], dtype="i,i,i"),
  269:     }
  270: 
  271:     with ensure_clean_store("walk_groups.hdf", mode="w") as store:
  272:         store.put("/first_group/df1", objs["df1"])
  273:         store.put("/first_group/df2", objs["df2"])
  274:         store.put("/second_group/df3", objs["df3"])
  275:         store.put("/second_group/s1", objs["s1"])
  276:         store.put("/second_group/third_group/df4", objs["df4"])
  277:         # Create non-pandas objects
  278:         store._handle.create_array("/first_group", "a1", objs["a1"])
  279:         store._handle.create_table("/first_group", "tb1", obj=objs["tb1"])
  280:         store._handle.create_table("/second_group", "tb2", obj=objs["tb2"])
  281: 
  282:         assert len(list(store.walk(where=where))) == len(expected)
  283:         for path, groups, leaves in store.walk(where=where):
  284:             assert path in expected
  285:             expected_groups, expected_frames = expected[path]
  286:             assert expected_groups == set(groups)
  287:             assert expected_frames == set(leaves)
  288:             for leaf in leaves:
  289:                 frame_path = "/".join([path, leaf])
  290:                 obj = store.get(frame_path)
  291:                 if "df" in leaf:
  292:                     tm.assert_frame_equal(obj, objs[leaf])
  293:                 else:
  294:                     tm.assert_series_equal(obj, objs[leaf])
  295: 
  296: 
  297: def test_getattr(setup_path):
  298:     with ensure_clean_store(setup_path) as store:
  299:         s = Series(
  300:             np.arange(10, dtype=np.float64), index=date_range("2020-01-01", periods=10)
  301:         )
  302:         store["a"] = s
  303: 
  304:         # test attribute access
  305:         result = store.a
  306:         tm.assert_series_equal(result, s)
  307:         result = getattr(store, "a")
  308:         tm.assert_series_equal(result, s)
  309: 
  310:         df = DataFrame(
  311:             np.random.default_rng(2).standard_normal((10, 4)),
  312:             columns=Index(list("ABCD"), dtype=object),
  313:             index=date_range("2000-01-01", periods=10, freq="B"),
  314:         )
  315:         store["df"] = df
  316:         result = store.df
  317:         tm.assert_frame_equal(result, df)
  318: 
  319:         # errors
  320:         for x in ["d", "mode", "path", "handle", "complib"]:
  321:             msg = f"'HDFStore' object has no attribute '{x}'"
  322:             with pytest.raises(AttributeError, match=msg):
  323:                 getattr(store, x)
  324: 
  325:         # not stores
  326:         for x in ["mode", "path", "handle", "complib"]:
  327:             getattr(store, f"_{x}")
  328: 
  329: 
  330: def test_store_dropna(tmp_path, setup_path):
  331:     df_with_missing = DataFrame(
  332:         {"col1": [0.0, np.nan, 2.0], "col2": [1.0, np.nan, np.nan]},
  333:         index=list("abc"),
  334:     )
  335:     df_without_missing = DataFrame(
  336:         {"col1": [0.0, 2.0], "col2": [1.0, np.nan]}, index=list("ac")
  337:     )
  338: 
  339:     # # Test to make sure defaults are to not drop.
  340:     # # Corresponding to Issue 9382
  341:     path = tmp_path / setup_path
  342:     df_with_missing.to_hdf(path, key="df", format="table")
  343:     reloaded = read_hdf(path, "df")
  344:     tm.assert_frame_equal(df_with_missing, reloaded)
  345: 
  346:     path = tmp_path / setup_path
  347:     df_with_missing.to_hdf(path, key="df", format="table", dropna=False)
  348:     reloaded = read_hdf(path, "df")
  349:     tm.assert_frame_equal(df_with_missing, reloaded)
  350: 
  351:     path = tmp_path / setup_path
  352:     df_with_missing.to_hdf(path, key="df", format="table", dropna=True)
  353:     reloaded = read_hdf(path, "df")
  354:     tm.assert_frame_equal(df_without_missing, reloaded)
  355: 
  356: 
  357: def test_keyword_deprecation(tmp_path, setup_path):
  358:     # GH 54229
  359:     path = tmp_path / setup_path
  360: 
  361:     msg = (
  362:         "Starting with pandas version 3.0 all arguments of to_hdf except for the "
  363:         "argument 'path_or_buf' will be keyword-only."
  364:     )
  365:     df = DataFrame([{"A": 1, "B": 2, "C": 3}, {"A": 1, "B": 2, "C": 3}])
  366: 
  367:     with tm.assert_produces_warning(FutureWarning, match=msg):
  368:         df.to_hdf(path, "key")
  369: 
  370: 
  371: def test_to_hdf_with_min_itemsize(tmp_path, setup_path):
  372:     path = tmp_path / setup_path
  373: 
  374:     # min_itemsize in index with to_hdf (GH 10381)
  375:     df = DataFrame(
  376:         {
  377:             "A": [0.0, 1.0, 2.0, 3.0, 4.0],
  378:             "B": [0.0, 1.0, 0.0, 1.0, 0.0],
  379:             "C": Index(["foo1", "foo2", "foo3", "foo4", "foo5"], dtype=object),
  380:             "D": date_range("20130101", periods=5),
  381:         }
  382:     ).set_index("C")
  383:     df.to_hdf(path, key="ss3", format="table", min_itemsize={"index": 6})
  384:     # just make sure there is a longer string:
  385:     df2 = df.copy().reset_index().assign(C="longer").set_index("C")
  386:     df2.to_hdf(path, key="ss3", append=True, format="table")
  387:     tm.assert_frame_equal(read_hdf(path, "ss3"), concat([df, df2]))
  388: 
  389:     # same as above, with a Series
  390:     df["B"].to_hdf(path, key="ss4", format="table", min_itemsize={"index": 6})
  391:     df2["B"].to_hdf(path, key="ss4", append=True, format="table")
  392:     tm.assert_series_equal(read_hdf(path, "ss4"), concat([df["B"], df2["B"]]))
  393: 
  394: 
  395: @pytest.mark.parametrize("format", ["fixed", "table"])
  396: def test_to_hdf_errors(tmp_path, format, setup_path):
  397:     data = ["\ud800foo"]
  398:     ser = Series(data, index=Index(data))
  399:     path = tmp_path / setup_path
  400:     # GH 20835
  401:     ser.to_hdf(path, key="table", format=format, errors="surrogatepass")
  402: 
  403:     result = read_hdf(path, "table", errors="surrogatepass")
  404:     tm.assert_series_equal(result, ser)
  405: 
  406: 
  407: def test_create_table_index(setup_path):
  408:     with ensure_clean_store(setup_path) as store:
  409: 
  410:         def col(t, column):
  411:             return getattr(store.get_storer(t).table.cols, column)
  412: 
  413:         # data columns
  414:         df = DataFrame(
  415:             np.random.default_rng(2).standard_normal((10, 4)),
  416:             columns=Index(list("ABCD"), dtype=object),
  417:             index=date_range("2000-01-01", periods=10, freq="B"),
  418:         )
  419:         df["string"] = "foo"
  420:         df["string2"] = "bar"
  421:         store.append("f", df, data_columns=["string", "string2"])
  422:         assert col("f", "index").is_indexed is True
  423:         assert col("f", "string").is_indexed is True
  424:         assert col("f", "string2").is_indexed is True
  425: 
  426:         # specify index=columns
  427:         store.append("f2", df, index=["string"], data_columns=["string", "string2"])
  428:         assert col("f2", "index").is_indexed is False
  429:         assert col("f2", "string").is_indexed is True
  430:         assert col("f2", "string2").is_indexed is False
  431: 
  432:         # try to index a non-table
  433:         _maybe_remove(store, "f2")
  434:         store.put("f2", df)
  435:         msg = "cannot create table index on a Fixed format store"
  436:         with pytest.raises(TypeError, match=msg):
  437:             store.create_table_index("f2")
  438: 
  439: 
  440: def test_create_table_index_data_columns_argument(setup_path):
  441:     # GH 28156
  442: 
  443:     with ensure_clean_store(setup_path) as store:
  444: 
  445:         def col(t, column):
  446:             return getattr(store.get_storer(t).table.cols, column)
  447: 
  448:         # data columns
  449:         df = DataFrame(
  450:             np.random.default_rng(2).standard_normal((10, 4)),
  451:             columns=Index(list("ABCD"), dtype=object),
  452:             index=date_range("2000-01-01", periods=10, freq="B"),
  453:         )
  454:         df["string"] = "foo"
  455:         df["string2"] = "bar"
  456:         store.append("f", df, data_columns=["string"])
  457:         assert col("f", "index").is_indexed is True
  458:         assert col("f", "string").is_indexed is True
  459: 
  460:         msg = "'Cols' object has no attribute 'string2'"
  461:         with pytest.raises(AttributeError, match=msg):
  462:             col("f", "string2").is_indexed
  463: 
  464:         # try to index a col which isn't a data_column
  465:         msg = (
  466:             "column string2 is not a data_column.\n"
  467:             "In order to read column string2 you must reload the dataframe \n"
  468:             "into HDFStore and include string2 with the data_columns argument."
  469:         )
  470:         with pytest.raises(AttributeError, match=msg):
  471:             store.create_table_index("f", columns=["string2"])
  472: 
  473: 
  474: def test_mi_data_columns(setup_path):
  475:     # GH 14435
  476:     idx = MultiIndex.from_arrays(
  477:         [date_range("2000-01-01", periods=5), range(5)], names=["date", "id"]
  478:     )
  479:     df = DataFrame({"a": [1.1, 1.2, 1.3, 1.4, 1.5]}, index=idx)
  480: 
  481:     with ensure_clean_store(setup_path) as store:
  482:         store.append("df", df, data_columns=True)
  483: 
  484:         actual = store.select("df", where="id == 1")
  485:         expected = df.iloc[[1], :]
  486:         tm.assert_frame_equal(actual, expected)
  487: 
  488: 
  489: def test_table_mixed_dtypes(setup_path):
  490:     # frame
  491:     df = DataFrame(
  492:         1.1 * np.arange(120).reshape((30, 4)),
  493:         columns=Index(list("ABCD"), dtype=object),
  494:         index=Index([f"i-{i}" for i in range(30)], dtype=object),
  495:     )
  496:     df["obj1"] = "foo"
  497:     df["obj2"] = "bar"
  498:     df["bool1"] = df["A"] > 0
  499:     df["bool2"] = df["B"] > 0
  500:     df["bool3"] = True
  501:     df["int1"] = 1
  502:     df["int2"] = 2
  503:     df["timestamp1"] = Timestamp("20010102").as_unit("ns")
  504:     df["timestamp2"] = Timestamp("20010103").as_unit("ns")
  505:     df["datetime1"] = Timestamp("20010102").as_unit("ns")
  506:     df["datetime2"] = Timestamp("20010103").as_unit("ns")
  507:     df.loc[df.index[3:6], ["obj1"]] = np.nan
  508:     df = df._consolidate()
  509: 
  510:     with ensure_clean_store(setup_path) as store:
  511:         store.append("df1_mixed", df)
  512:         tm.assert_frame_equal(store.select("df1_mixed"), df)
  513: 
  514: 
  515: def test_calendar_roundtrip_issue(setup_path):
  516:     # 8591
  517:     # doc example from tseries holiday section
  518:     weekmask_egypt = "Sun Mon Tue Wed Thu"
  519:     holidays = [
  520:         "2012-05-01",
  521:         dt.datetime(2013, 5, 1),
  522:         np.datetime64("2014-05-01"),
  523:     ]
  524:     bday_egypt = pd.offsets.CustomBusinessDay(
  525:         holidays=holidays, weekmask=weekmask_egypt
  526:     )
  527:     mydt = dt.datetime(2013, 4, 30)
  528:     dts = date_range(mydt, periods=5, freq=bday_egypt)
  529: 
  530:     s = Series(dts.weekday, dts).map(Series("Mon Tue Wed Thu Fri Sat Sun".split()))
  531: 
  532:     with ensure_clean_store(setup_path) as store:
  533:         store.put("fixed", s)
  534:         result = store.select("fixed")
  535:         tm.assert_series_equal(result, s)
  536: 
  537:         store.append("table", s)
  538:         result = store.select("table")
  539:         tm.assert_series_equal(result, s)
  540: 
  541: 
  542: def test_remove(setup_path):
  543:     with ensure_clean_store(setup_path) as store:
  544:         ts = Series(
  545:             np.arange(10, dtype=np.float64), index=date_range("2020-01-01", periods=10)
  546:         )
  547:         df = DataFrame(
  548:             1.1 * np.arange(120).reshape((30, 4)),
  549:             columns=Index(list("ABCD"), dtype=object),
  550:             index=Index([f"i-{i}" for i in range(30)], dtype=object),
  551:         )
  552:         store["a"] = ts
  553:         store["b"] = df
  554:         _maybe_remove(store, "a")
  555:         assert len(store) == 1
  556:         tm.assert_frame_equal(df, store["b"])
  557: 
  558:         _maybe_remove(store, "b")
  559:         assert len(store) == 0
  560: 
  561:         # nonexistence
  562:         with pytest.raises(
  563:             KeyError, match="'No object named a_nonexistent_store in the file'"
  564:         ):
  565:             store.remove("a_nonexistent_store")
  566: 
  567:         # pathing
  568:         store["a"] = ts
  569:         store["b/foo"] = df
  570:         _maybe_remove(store, "foo")
  571:         _maybe_remove(store, "b/foo")
  572:         assert len(store) == 1
  573: 
  574:         store["a"] = ts
  575:         store["b/foo"] = df
  576:         _maybe_remove(store, "b")
  577:         assert len(store) == 1
  578: 
  579:         # __delitem__
  580:         store["a"] = ts
  581:         store["b"] = df
  582:         del store["a"]
  583:         del store["b"]
  584:         assert len(store) == 0
  585: 
  586: 
  587: def test_same_name_scoping(setup_path):
  588:     with ensure_clean_store(setup_path) as store:
  589:         df = DataFrame(
  590:             np.random.default_rng(2).standard_normal((20, 2)),
  591:             index=date_range("20130101", periods=20),
  592:         )
  593:         store.put("df", df, format="table")
  594:         expected = df[df.index > Timestamp("20130105")]
  595: 
  596:         result = store.select("df", "index>datetime.datetime(2013,1,5)")
  597:         tm.assert_frame_equal(result, expected)
  598: 
  599:         # changes what 'datetime' points to in the namespace where
  600:         #  'select' does the lookup
  601: 
  602:         # technically an error, but allow it
  603:         result = store.select("df", "index>datetime.datetime(2013,1,5)")
  604:         tm.assert_frame_equal(result, expected)
  605: 
  606:         result = store.select("df", "index>datetime(2013,1,5)")
  607:         tm.assert_frame_equal(result, expected)
  608: 
  609: 
  610: def test_store_index_name(setup_path):
  611:     df = DataFrame(
  612:         1.1 * np.arange(120).reshape((30, 4)),
  613:         columns=Index(list("ABCD"), dtype=object),
  614:         index=Index([f"i-{i}" for i in range(30)], dtype=object),
  615:     )
  616:     df.index.name = "foo"
  617: 
  618:     with ensure_clean_store(setup_path) as store:
  619:         store["frame"] = df
  620:         recons = store["frame"]
  621:         tm.assert_frame_equal(recons, df)
  622: 
  623: 
  624: @pytest.mark.parametrize("tz", [None, "US/Pacific"])
  625: @pytest.mark.parametrize("table_format", ["table", "fixed"])
  626: def test_store_index_name_numpy_str(tmp_path, table_format, setup_path, unit, tz):
  627:     # GH #13492
  628:     idx = DatetimeIndex(
  629:         [dt.date(2000, 1, 1), dt.date(2000, 1, 2)],
  630:         name="cols\u05d2",
  631:     ).tz_localize(tz)
  632:     idx1 = (
  633:         DatetimeIndex(
  634:             [dt.date(2010, 1, 1), dt.date(2010, 1, 2)],
  635:             name="rows\u05d0",
  636:         )
  637:         .as_unit(unit)
  638:         .tz_localize(tz)
  639:     )
  640:     df = DataFrame(np.arange(4).reshape(2, 2), columns=idx, index=idx1)
  641: 
  642:     # This used to fail, returning numpy strings instead of python strings.
  643:     path = tmp_path / setup_path
  644:     df.to_hdf(path, key="df", format=table_format)
  645:     df2 = read_hdf(path, "df")
  646: 
  647:     tm.assert_frame_equal(df, df2, check_names=True)
  648: 
  649:     assert isinstance(df2.index.name, str)
  650:     assert isinstance(df2.columns.name, str)
  651: 
  652: 
  653: def test_store_series_name(setup_path):
  654:     df = DataFrame(
  655:         1.1 * np.arange(120).reshape((30, 4)),
  656:         columns=Index(list("ABCD"), dtype=object),
  657:         index=Index([f"i-{i}" for i in range(30)], dtype=object),
  658:     )
  659:     series = df["A"]
  660: 
  661:     with ensure_clean_store(setup_path) as store:
  662:         store["series"] = series
  663:         recons = store["series"]
  664:         tm.assert_series_equal(recons, series)
  665: 
  666: 
  667: def test_overwrite_node(setup_path):
  668:     with ensure_clean_store(setup_path) as store:
  669:         store["a"] = DataFrame(
  670:             np.random.default_rng(2).standard_normal((10, 4)),
  671:             columns=Index(list("ABCD"), dtype=object),
  672:             index=date_range("2000-01-01", periods=10, freq="B"),
  673:         )
  674:         ts = Series(
  675:             np.arange(10, dtype=np.float64), index=date_range("2020-01-01", periods=10)
  676:         )
  677:         store["a"] = ts
  678: 
  679:         tm.assert_series_equal(store["a"], ts)
  680: 
  681: 
  682: def test_coordinates(setup_path):
  683:     df = DataFrame(
  684:         np.random.default_rng(2).standard_normal((10, 4)),
  685:         columns=Index(list("ABCD"), dtype=object),
  686:         index=date_range("2000-01-01", periods=10, freq="B"),
  687:     )
  688: 
  689:     with ensure_clean_store(setup_path) as store:
  690:         _maybe_remove(store, "df")
  691:         store.append("df", df)
  692: 
  693:         # all
  694:         c = store.select_as_coordinates("df")
  695:         assert (c.values == np.arange(len(df.index))).all()
  696: 
  697:         # get coordinates back & test vs frame
  698:         _maybe_remove(store, "df")
  699: 
  700:         df = DataFrame({"A": range(5), "B": range(5)})
  701:         store.append("df", df)
  702:         c = store.select_as_coordinates("df", ["index<3"])
  703:         assert (c.values == np.arange(3)).all()
  704:         result = store.select("df", where=c)
  705:         expected = df.loc[0:2, :]
  706:         tm.assert_frame_equal(result, expected)
  707: 
  708:         c = store.select_as_coordinates("df", ["index>=3", "index<=4"])
  709:         assert (c.values == np.arange(2) + 3).all()
  710:         result = store.select("df", where=c)
  711:         expected = df.loc[3:4, :]
  712:         tm.assert_frame_equal(result, expected)
  713:         assert isinstance(c, Index)
  714: 
  715:         # multiple tables
  716:         _maybe_remove(store, "df1")
  717:         _maybe_remove(store, "df2")
  718:         df1 = DataFrame(
  719:             np.random.default_rng(2).standard_normal((10, 4)),
  720:             columns=Index(list("ABCD"), dtype=object),
  721:             index=date_range("2000-01-01", periods=10, freq="B"),
  722:         )
  723:         df2 = df1.copy().rename(columns="{}_2".format)
  724:         store.append("df1", df1, data_columns=["A", "B"])
  725:         store.append("df2", df2)
  726: 
  727:         c = store.select_as_coordinates("df1", ["A>0", "B>0"])
  728:         df1_result = store.select("df1", c)
  729:         df2_result = store.select("df2", c)
  730:         result = concat([df1_result, df2_result], axis=1)
  731: 
  732:         expected = concat([df1, df2], axis=1)
  733:         expected = expected[(expected.A > 0) & (expected.B > 0)]
  734:         tm.assert_frame_equal(result, expected, check_freq=False)
  735:         # FIXME: 2021-01-18 on some (mostly windows) builds we get freq=None
  736:         #  but expect freq="18B"
  737: 
  738:     # pass array/mask as the coordinates
  739:     with ensure_clean_store(setup_path) as store:
  740:         df = DataFrame(
  741:             np.random.default_rng(2).standard_normal((1000, 2)),
  742:             index=date_range("20000101", periods=1000),
  743:         )
  744:         store.append("df", df)
  745:         c = store.select_column("df", "index")
  746:         where = c[DatetimeIndex(c).month == 5].index
  747:         expected = df.iloc[where]
  748: 
  749:         # locations
  750:         result = store.select("df", where=where)
  751:         tm.assert_frame_equal(result, expected)
  752: 
  753:         # boolean
  754:         result = store.select("df", where=where)
  755:         tm.assert_frame_equal(result, expected)
  756: 
  757:         # invalid
  758:         msg = (
  759:             "where must be passed as a string, PyTablesExpr, "
  760:             "or list-like of PyTablesExpr"
  761:         )
  762:         with pytest.raises(TypeError, match=msg):
  763:             store.select("df", where=np.arange(len(df), dtype="float64"))
  764: 
  765:         with pytest.raises(TypeError, match=msg):
  766:             store.select("df", where=np.arange(len(df) + 1))
  767: 
  768:         with pytest.raises(TypeError, match=msg):
  769:             store.select("df", where=np.arange(len(df)), start=5)
  770: 
  771:         with pytest.raises(TypeError, match=msg):
  772:             store.select("df", where=np.arange(len(df)), start=5, stop=10)
  773: 
  774:         # selection with filter
  775:         selection = date_range("20000101", periods=500)
  776:         result = store.select("df", where="index in selection")
  777:         expected = df[df.index.isin(selection)]
  778:         tm.assert_frame_equal(result, expected)
  779: 
  780:         # list
  781:         df = DataFrame(np.random.default_rng(2).standard_normal((10, 2)))
  782:         store.append("df2", df)
  783:         result = store.select("df2", where=[0, 3, 5])
  784:         expected = df.iloc[[0, 3, 5]]
  785:         tm.assert_frame_equal(result, expected)
  786: 
  787:         # boolean
  788:         where = [True] * 10
  789:         where[-2] = False
  790:         result = store.select("df2", where=where)
  791:         expected = df.loc[where]
  792:         tm.assert_frame_equal(result, expected)
  793: 
  794:         # start/stop
  795:         result = store.select("df2", start=5, stop=10)
  796:         expected = df[5:10]
  797:         tm.assert_frame_equal(result, expected)
  798: 
  799: 
  800: def test_start_stop_table(setup_path):
  801:     with ensure_clean_store(setup_path) as store:
  802:         # table
  803:         df = DataFrame(
  804:             {
  805:                 "A": np.random.default_rng(2).random(20),
  806:                 "B": np.random.default_rng(2).random(20),
  807:             }
  808:         )
  809:         store.append("df", df)
  810: 
  811:         result = store.select("df", "columns=['A']", start=0, stop=5)
  812:         expected = df.loc[0:4, ["A"]]
  813:         tm.assert_frame_equal(result, expected)
  814: 
  815:         # out of range
  816:         result = store.select("df", "columns=['A']", start=30, stop=40)
  817:         assert len(result) == 0
  818:         expected = df.loc[30:40, ["A"]]
  819:         tm.assert_frame_equal(result, expected)
  820: 
  821: 
  822: def test_start_stop_multiple(setup_path):
  823:     # GH 16209
  824:     with ensure_clean_store(setup_path) as store:
  825:         df = DataFrame({"foo": [1, 2], "bar": [1, 2]})
  826: 
  827:         store.append_to_multiple(
  828:             {"selector": ["foo"], "data": None}, df, selector="selector"
  829:         )
  830:         result = store.select_as_multiple(
  831:             ["selector", "data"], selector="selector", start=0, stop=1
  832:         )
  833:         expected = df.loc[[0], ["foo", "bar"]]
  834:         tm.assert_frame_equal(result, expected)
  835: 
  836: 
  837: def test_start_stop_fixed(setup_path):
  838:     with ensure_clean_store(setup_path) as store:
  839:         # fixed, GH 8287
  840:         df = DataFrame(
  841:             {
  842:                 "A": np.random.default_rng(2).random(20),
  843:                 "B": np.random.default_rng(2).random(20),
  844:             },
  845:             index=date_range("20130101", periods=20),
  846:         )
  847:         store.put("df", df)
  848: 
  849:         result = store.select("df", start=0, stop=5)
  850:         expected = df.iloc[0:5, :]
  851:         tm.assert_frame_equal(result, expected)
  852: 
  853:         result = store.select("df", start=5, stop=10)
  854:         expected = df.iloc[5:10, :]
  855:         tm.assert_frame_equal(result, expected)
  856: 
  857:         # out of range
  858:         result = store.select("df", start=30, stop=40)
  859:         expected = df.iloc[30:40, :]
  860:         tm.assert_frame_equal(result, expected)
  861: 
  862:         # series
  863:         s = df.A
  864:         store.put("s", s)
  865:         result = store.select("s", start=0, stop=5)
  866:         expected = s.iloc[0:5]
  867:         tm.assert_series_equal(result, expected)
  868: 
  869:         result = store.select("s", start=5, stop=10)
  870:         expected = s.iloc[5:10]
  871:         tm.assert_series_equal(result, expected)
  872: 
  873:         # sparse; not implemented
  874:         df = DataFrame(
  875:             1.1 * np.arange(120).reshape((30, 4)),
  876:             columns=Index(list("ABCD"), dtype=object),
  877:             index=Index([f"i-{i}" for i in range(30)], dtype=object),
  878:         )
  879:         df.iloc[3:5, 1:3] = np.nan
  880:         df.iloc[8:10, -2] = np.nan
  881: 
  882: 
  883: def test_select_filter_corner(setup_path):
  884:     df = DataFrame(np.random.default_rng(2).standard_normal((50, 100)))
  885:     df.index = [f"{c:3d}" for c in df.index]
  886:     df.columns = [f"{c:3d}" for c in df.columns]
  887: 
  888:     with ensure_clean_store(setup_path) as store:
  889:         store.put("frame", df, format="table")
  890: 
  891:         crit = "columns=df.columns[:75]"
  892:         result = store.select("frame", [crit])
  893:         tm.assert_frame_equal(result, df.loc[:, df.columns[:75]])
  894: 
  895:         crit = "columns=df.columns[:75:2]"
  896:         result = store.select("frame", [crit])
  897:         tm.assert_frame_equal(result, df.loc[:, df.columns[:75:2]])
  898: 
  899: 
  900: def test_path_pathlib():
  901:     df = DataFrame(
  902:         1.1 * np.arange(120).reshape((30, 4)),
  903:         columns=Index(list("ABCD"), dtype=object),
  904:         index=Index([f"i-{i}" for i in range(30)], dtype=object),
  905:     )
  906: 
  907:     result = tm.round_trip_pathlib(
  908:         lambda p: df.to_hdf(p, key="df"), lambda p: read_hdf(p, "df")
  909:     )
  910:     tm.assert_frame_equal(df, result)
  911: 
  912: 
  913: @pytest.mark.parametrize("start, stop", [(0, 2), (1, 2), (None, None)])
  914: def test_contiguous_mixed_data_table(start, stop, setup_path):
  915:     # GH 17021
  916:     df = DataFrame(
  917:         {
  918:             "a": Series([20111010, 20111011, 20111012]),
  919:             "b": Series(["ab", "cd", "ab"]),
  920:         }
  921:     )
  922: 
  923:     with ensure_clean_store(setup_path) as store:
  924:         store.append("test_dataset", df)
  925: 
  926:         result = store.select("test_dataset", start=start, stop=stop)
  927:         tm.assert_frame_equal(df[start:stop], result)
  928: 
  929: 
  930: def test_path_pathlib_hdfstore():
  931:     df = DataFrame(
  932:         1.1 * np.arange(120).reshape((30, 4)),
  933:         columns=Index(list("ABCD"), dtype=object),
  934:         index=Index([f"i-{i}" for i in range(30)], dtype=object),
  935:     )
  936: 
  937:     def writer(path):
  938:         with HDFStore(path) as store:
  939:             df.to_hdf(store, key="df")
  940: 
  941:     def reader(path):
  942:         with HDFStore(path) as store:
  943:             return read_hdf(store, "df")
  944: 
  945:     result = tm.round_trip_pathlib(writer, reader)
  946:     tm.assert_frame_equal(df, result)
  947: 
  948: 
  949: def test_pickle_path_localpath():
  950:     df = DataFrame(
  951:         1.1 * np.arange(120).reshape((30, 4)),
  952:         columns=Index(list("ABCD"), dtype=object),
  953:         index=Index([f"i-{i}" for i in range(30)], dtype=object),
  954:     )
  955:     result = tm.round_trip_pathlib(
  956:         lambda p: df.to_hdf(p, key="df"), lambda p: read_hdf(p, "df")
  957:     )
  958:     tm.assert_frame_equal(df, result)
  959: 
  960: 
  961: def test_path_localpath_hdfstore():
  962:     df = DataFrame(
  963:         1.1 * np.arange(120).reshape((30, 4)),
  964:         columns=Index(list("ABCD"), dtype=object),
  965:         index=Index([f"i-{i}" for i in range(30)], dtype=object),
  966:     )
  967: 
  968:     def writer(path):
  969:         with HDFStore(path) as store:
  970:             df.to_hdf(store, key="df")
  971: 
  972:     def reader(path):
  973:         with HDFStore(path) as store:
  974:             return read_hdf(store, "df")
  975: 
  976:     result = tm.round_trip_localpath(writer, reader)
  977:     tm.assert_frame_equal(df, result)
  978: 
  979: 
  980: @pytest.mark.parametrize("propindexes", [True, False])
  981: def test_copy(propindexes):
  982:     df = DataFrame(
  983:         1.1 * np.arange(120).reshape((30, 4)),
  984:         columns=Index(list("ABCD"), dtype=object),
  985:         index=Index([f"i-{i}" for i in range(30)], dtype=object),
  986:     )
  987: 
  988:     with tm.ensure_clean() as path:
  989:         with HDFStore(path) as st:
  990:             st.append("df", df, data_columns=["A"])
  991:         with tempfile.NamedTemporaryFile() as new_f:
  992:             with HDFStore(path) as store:
  993:                 with contextlib.closing(
  994:                     store.copy(new_f.name, keys=None, propindexes=propindexes)
  995:                 ) as tstore:
  996:                     # check keys
  997:                     keys = store.keys()
  998:                     assert set(keys) == set(tstore.keys())
  999:                     # check indices & nrows
 1000:                     for k in tstore.keys():
 1001:                         if tstore.get_storer(k).is_table:
 1002:                             new_t = tstore.get_storer(k)
 1003:                             orig_t = store.get_storer(k)
 1004: 
 1005:                             assert orig_t.nrows == new_t.nrows
 1006: 
 1007:                             # check propindixes
 1008:                             if propindexes:
 1009:                                 for a in orig_t.axes:
 1010:                                     if a.is_indexed:
 1011:                                         assert new_t[a.name].is_indexed
 1012: 
 1013: 
 1014: def test_duplicate_column_name(tmp_path, setup_path):
 1015:     df = DataFrame(columns=["a", "a"], data=[[0, 0]])
 1016: 
 1017:     path = tmp_path / setup_path
 1018:     msg = "Columns index has to be unique for fixed format"
 1019:     with pytest.raises(ValueError, match=msg):
 1020:         df.to_hdf(path, key="df", format="fixed")
 1021: 
 1022:     df.to_hdf(path, key="df", format="table")
 1023:     other = read_hdf(path, "df")
 1024: 
 1025:     tm.assert_frame_equal(df, other)
 1026:     assert df.equals(other)
 1027:     assert other.equals(df)
 1028: 
 1029: 
 1030: def test_preserve_timedeltaindex_type(setup_path):
 1031:     # GH9635
 1032:     df = DataFrame(np.random.default_rng(2).normal(size=(10, 5)))
 1033:     df.index = timedelta_range(start="0s", periods=10, freq="1s", name="example")
 1034: 
 1035:     with ensure_clean_store(setup_path) as store:
 1036:         store["df"] = df
 1037:         tm.assert_frame_equal(store["df"], df)
 1038: 
 1039: 
 1040: def test_columns_multiindex_modified(tmp_path, setup_path):
 1041:     # BUG: 7212
 1042: 
 1043:     df = DataFrame(
 1044:         np.random.default_rng(2).random((4, 5)),
 1045:         index=list("abcd"),
 1046:         columns=list("ABCDE"),
 1047:     )
 1048:     df.index.name = "letters"
 1049:     df = df.set_index(keys="E", append=True)
 1050: 
 1051:     data_columns = df.index.names + df.columns.tolist()
 1052:     path = tmp_path / setup_path
 1053:     df.to_hdf(
 1054:         path,
 1055:         key="df",
 1056:         mode="a",
 1057:         append=True,
 1058:         data_columns=data_columns,
 1059:         index=False,
 1060:     )
 1061:     cols2load = list("BCD")
 1062:     cols2load_original = list(cols2load)
 1063:     # GH#10055 make sure read_hdf call does not alter cols2load inplace
 1064:     read_hdf(path, "df", columns=cols2load)
 1065:     assert cols2load_original == cols2load
 1066: 
 1067: 
 1068: @pytest.mark.filterwarnings(r"ignore:PeriodDtype\[B\] is deprecated:FutureWarning")
 1069: @pytest.mark.parametrize(
 1070:     "columns",
 1071:     [
 1072:         Index([0, 1], dtype=np.int64),
 1073:         Index([0.0, 1.0], dtype=np.float64),
 1074:         date_range("2020-01-01", periods=2),
 1075:         timedelta_range("1 day", periods=2),
 1076:         period_range("2020-01-01", periods=2, freq="D"),
 1077:     ],
 1078: )
 1079: def test_to_hdf_with_object_column_names_should_fail(tmp_path, setup_path, columns):
 1080:     # GH9057
 1081:     df = DataFrame(np.random.default_rng(2).standard_normal((10, 2)), columns=columns)
 1082:     path = tmp_path / setup_path
 1083:     msg = "cannot have non-object label DataIndexableCol"
 1084:     with pytest.raises(ValueError, match=msg):
 1085:         df.to_hdf(path, key="df", format="table", data_columns=True)
 1086: 
 1087: 
 1088: @pytest.mark.parametrize("dtype", [None, "category"])
 1089: def test_to_hdf_with_object_column_names_should_run(tmp_path, setup_path, dtype):
 1090:     # GH9057
 1091:     df = DataFrame(
 1092:         np.random.default_rng(2).standard_normal((10, 2)),
 1093:         columns=Index(["a", "b"], dtype=dtype),
 1094:     )
 1095:     path = tmp_path / setup_path
 1096:     df.to_hdf(path, key="df", format="table", data_columns=True)
 1097:     result = read_hdf(path, "df", where=f"index = [{df.index[0]}]")
 1098:     assert len(result)
 1099: 
 1100: 
 1101: def test_hdfstore_strides(setup_path):
 1102:     # GH22073
 1103:     df = DataFrame({"a": [1, 2, 3, 4], "b": [5, 6, 7, 8]})
 1104:     with ensure_clean_store(setup_path) as store:
 1105:         store.put("df", df)
 1106:         assert df["a"].values.strides == store["df"]["a"].values.strides
 1107: 
 1108: 
 1109: def test_store_bool_index(tmp_path, setup_path):
 1110:     # GH#48667
 1111:     df = DataFrame([[1]], columns=[True], index=Index([False], dtype="bool"))
 1112:     expected = df.copy()
 1113: 
 1114:     # # Test to make sure defaults are to not drop.
 1115:     # # Corresponding to Issue 9382
 1116:     path = tmp_path / setup_path
 1117:     df.to_hdf(path, key="a")
 1118:     result = read_hdf(path, "a")
 1119:     tm.assert_frame_equal(expected, result)
