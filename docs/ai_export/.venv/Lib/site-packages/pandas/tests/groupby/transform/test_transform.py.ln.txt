    1: """ test with the .transform """
    2: import numpy as np
    3: import pytest
    4: 
    5: from pandas._libs import lib
    6: 
    7: from pandas.core.dtypes.common import ensure_platform_int
    8: 
    9: import pandas as pd
   10: from pandas import (
   11:     Categorical,
   12:     DataFrame,
   13:     Index,
   14:     MultiIndex,
   15:     Series,
   16:     Timestamp,
   17:     concat,
   18:     date_range,
   19: )
   20: import pandas._testing as tm
   21: from pandas.tests.groupby import get_groupby_method_args
   22: 
   23: 
   24: def assert_fp_equal(a, b):
   25:     assert (np.abs(a - b) < 1e-12).all()
   26: 
   27: 
   28: def test_transform():
   29:     data = Series(np.arange(9) // 3, index=np.arange(9))
   30: 
   31:     index = np.arange(9)
   32:     np.random.default_rng(2).shuffle(index)
   33:     data = data.reindex(index)
   34: 
   35:     grouped = data.groupby(lambda x: x // 3)
   36: 
   37:     transformed = grouped.transform(lambda x: x * x.sum())
   38:     assert transformed[7] == 12
   39: 
   40:     # GH 8046
   41:     # make sure that we preserve the input order
   42: 
   43:     df = DataFrame(
   44:         np.arange(6, dtype="int64").reshape(3, 2), columns=["a", "b"], index=[0, 2, 1]
   45:     )
   46:     key = [0, 0, 1]
   47:     expected = (
   48:         df.sort_index()
   49:         .groupby(key)
   50:         .transform(lambda x: x - x.mean())
   51:         .groupby(key)
   52:         .mean()
   53:     )
   54:     result = df.groupby(key).transform(lambda x: x - x.mean()).groupby(key).mean()
   55:     tm.assert_frame_equal(result, expected)
   56: 
   57:     def demean(arr):
   58:         return arr - arr.mean(axis=0)
   59: 
   60:     people = DataFrame(
   61:         np.random.default_rng(2).standard_normal((5, 5)),
   62:         columns=["a", "b", "c", "d", "e"],
   63:         index=["Joe", "Steve", "Wes", "Jim", "Travis"],
   64:     )
   65:     key = ["one", "two", "one", "two", "one"]
   66:     result = people.groupby(key).transform(demean).groupby(key).mean()
   67:     expected = people.groupby(key, group_keys=False).apply(demean).groupby(key).mean()
   68:     tm.assert_frame_equal(result, expected)
   69: 
   70:     # GH 8430
   71:     df = DataFrame(
   72:         np.random.default_rng(2).standard_normal((50, 4)),
   73:         columns=Index(list("ABCD"), dtype=object),
   74:         index=date_range("2000-01-01", periods=50, freq="B"),
   75:     )
   76:     g = df.groupby(pd.Grouper(freq="ME"))
   77:     g.transform(lambda x: x - 1)
   78: 
   79:     # GH 9700
   80:     df = DataFrame({"a": range(5, 10), "b": range(5)})
   81:     msg = "using DataFrameGroupBy.max"
   82:     with tm.assert_produces_warning(FutureWarning, match=msg):
   83:         result = df.groupby("a").transform(max)
   84:     expected = DataFrame({"b": range(5)})
   85:     tm.assert_frame_equal(result, expected)
   86: 
   87: 
   88: def test_transform_fast():
   89:     df = DataFrame(
   90:         {
   91:             "id": np.arange(100000) / 3,
   92:             "val": np.random.default_rng(2).standard_normal(100000),
   93:         }
   94:     )
   95: 
   96:     grp = df.groupby("id")["val"]
   97: 
   98:     values = np.repeat(grp.mean().values, ensure_platform_int(grp.count().values))
   99:     expected = Series(values, index=df.index, name="val")
  100: 
  101:     msg = "using SeriesGroupBy.mean"
  102:     with tm.assert_produces_warning(FutureWarning, match=msg):
  103:         result = grp.transform(np.mean)
  104:     tm.assert_series_equal(result, expected)
  105: 
  106:     result = grp.transform("mean")
  107:     tm.assert_series_equal(result, expected)
  108: 
  109: 
  110: def test_transform_fast2():
  111:     # GH 12737
  112:     df = DataFrame(
  113:         {
  114:             "grouping": [0, 1, 1, 3],
  115:             "f": [1.1, 2.1, 3.1, 4.5],
  116:             "d": date_range("2014-1-1", "2014-1-4"),
  117:             "i": [1, 2, 3, 4],
  118:         },
  119:         columns=["grouping", "f", "i", "d"],
  120:     )
  121:     result = df.groupby("grouping").transform("first")
  122: 
  123:     dates = Index(
  124:         [
  125:             Timestamp("2014-1-1"),
  126:             Timestamp("2014-1-2"),
  127:             Timestamp("2014-1-2"),
  128:             Timestamp("2014-1-4"),
  129:         ],
  130:         dtype="M8[ns]",
  131:     )
  132:     expected = DataFrame(
  133:         {"f": [1.1, 2.1, 2.1, 4.5], "d": dates, "i": [1, 2, 2, 4]},
  134:         columns=["f", "i", "d"],
  135:     )
  136:     tm.assert_frame_equal(result, expected)
  137: 
  138:     # selection
  139:     result = df.groupby("grouping")[["f", "i"]].transform("first")
  140:     expected = expected[["f", "i"]]
  141:     tm.assert_frame_equal(result, expected)
  142: 
  143: 
  144: def test_transform_fast3():
  145:     # dup columns
  146:     df = DataFrame([[1, 2, 3], [4, 5, 6]], columns=["g", "a", "a"])
  147:     result = df.groupby("g").transform("first")
  148:     expected = df.drop("g", axis=1)
  149:     tm.assert_frame_equal(result, expected)
  150: 
  151: 
  152: def test_transform_broadcast(tsframe, ts):
  153:     grouped = ts.groupby(lambda x: x.month)
  154:     msg = "using SeriesGroupBy.mean"
  155:     with tm.assert_produces_warning(FutureWarning, match=msg):
  156:         result = grouped.transform(np.mean)
  157: 
  158:     tm.assert_index_equal(result.index, ts.index)
  159:     for _, gp in grouped:
  160:         assert_fp_equal(result.reindex(gp.index), gp.mean())
  161: 
  162:     grouped = tsframe.groupby(lambda x: x.month)
  163:     msg = "using DataFrameGroupBy.mean"
  164:     with tm.assert_produces_warning(FutureWarning, match=msg):
  165:         result = grouped.transform(np.mean)
  166:     tm.assert_index_equal(result.index, tsframe.index)
  167:     for _, gp in grouped:
  168:         agged = gp.mean(axis=0)
  169:         res = result.reindex(gp.index)
  170:         for col in tsframe:
  171:             assert_fp_equal(res[col], agged[col])
  172: 
  173:     # group columns
  174:     msg = "DataFrame.groupby with axis=1 is deprecated"
  175:     with tm.assert_produces_warning(FutureWarning, match=msg):
  176:         grouped = tsframe.groupby({"A": 0, "B": 0, "C": 1, "D": 1}, axis=1)
  177:     msg = "using DataFrameGroupBy.mean"
  178:     with tm.assert_produces_warning(FutureWarning, match=msg):
  179:         result = grouped.transform(np.mean)
  180:     tm.assert_index_equal(result.index, tsframe.index)
  181:     tm.assert_index_equal(result.columns, tsframe.columns)
  182:     for _, gp in grouped:
  183:         agged = gp.mean(1)
  184:         res = result.reindex(columns=gp.columns)
  185:         for idx in gp.index:
  186:             assert_fp_equal(res.xs(idx), agged[idx])
  187: 
  188: 
  189: def test_transform_axis_1(request, transformation_func):
  190:     # GH 36308
  191: 
  192:     df = DataFrame({"a": [1, 2], "b": [3, 4], "c": [5, 6]}, index=["x", "y"])
  193:     args = get_groupby_method_args(transformation_func, df)
  194:     msg = "DataFrame.groupby with axis=1 is deprecated"
  195:     with tm.assert_produces_warning(FutureWarning, match=msg):
  196:         gb = df.groupby([0, 0, 1], axis=1)
  197:     warn = FutureWarning if transformation_func == "fillna" else None
  198:     msg = "DataFrameGroupBy.fillna is deprecated"
  199:     with tm.assert_produces_warning(warn, match=msg):
  200:         result = gb.transform(transformation_func, *args)
  201:     msg = "DataFrameGroupBy.fillna is deprecated"
  202:     with tm.assert_produces_warning(warn, match=msg):
  203:         expected = df.T.groupby([0, 0, 1]).transform(transformation_func, *args).T
  204: 
  205:     if transformation_func in ["diff", "shift"]:
  206:         # Result contains nans, so transpose coerces to float
  207:         expected["b"] = expected["b"].astype("int64")
  208: 
  209:     # cumcount returns Series; the rest are DataFrame
  210:     tm.assert_equal(result, expected)
  211: 
  212: 
  213: def test_transform_axis_1_reducer(request, reduction_func):
  214:     # GH#45715
  215:     if reduction_func in (
  216:         "corrwith",
  217:         "ngroup",
  218:         "nth",
  219:     ):
  220:         marker = pytest.mark.xfail(reason="transform incorrectly fails - GH#45986")
  221:         request.applymarker(marker)
  222: 
  223:     df = DataFrame({"a": [1, 2], "b": [3, 4], "c": [5, 6]}, index=["x", "y"])
  224:     msg = "DataFrame.groupby with axis=1 is deprecated"
  225:     with tm.assert_produces_warning(FutureWarning, match=msg):
  226:         gb = df.groupby([0, 0, 1], axis=1)
  227: 
  228:     result = gb.transform(reduction_func)
  229:     expected = df.T.groupby([0, 0, 1]).transform(reduction_func).T
  230:     tm.assert_equal(result, expected)
  231: 
  232: 
  233: def test_transform_axis_ts(tsframe):
  234:     # make sure that we are setting the axes
  235:     # correctly when on axis=0 or 1
  236:     # in the presence of a non-monotonic indexer
  237:     # GH12713
  238: 
  239:     base = tsframe.iloc[0:5]
  240:     r = len(base.index)
  241:     c = len(base.columns)
  242:     tso = DataFrame(
  243:         np.random.default_rng(2).standard_normal((r, c)),
  244:         index=base.index,
  245:         columns=base.columns,
  246:         dtype="float64",
  247:     )
  248:     # monotonic
  249:     ts = tso
  250:     grouped = ts.groupby(lambda x: x.weekday(), group_keys=False)
  251:     result = ts - grouped.transform("mean")
  252:     expected = grouped.apply(lambda x: x - x.mean(axis=0))
  253:     tm.assert_frame_equal(result, expected)
  254: 
  255:     ts = ts.T
  256:     msg = "DataFrame.groupby with axis=1 is deprecated"
  257:     with tm.assert_produces_warning(FutureWarning, match=msg):
  258:         grouped = ts.groupby(lambda x: x.weekday(), axis=1, group_keys=False)
  259:     result = ts - grouped.transform("mean")
  260:     expected = grouped.apply(lambda x: (x.T - x.mean(1)).T)
  261:     tm.assert_frame_equal(result, expected)
  262: 
  263:     # non-monotonic
  264:     ts = tso.iloc[[1, 0] + list(range(2, len(base)))]
  265:     grouped = ts.groupby(lambda x: x.weekday(), group_keys=False)
  266:     result = ts - grouped.transform("mean")
  267:     expected = grouped.apply(lambda x: x - x.mean(axis=0))
  268:     tm.assert_frame_equal(result, expected)
  269: 
  270:     ts = ts.T
  271:     msg = "DataFrame.groupby with axis=1 is deprecated"
  272:     with tm.assert_produces_warning(FutureWarning, match=msg):
  273:         grouped = ts.groupby(lambda x: x.weekday(), axis=1, group_keys=False)
  274:     result = ts - grouped.transform("mean")
  275:     expected = grouped.apply(lambda x: (x.T - x.mean(1)).T)
  276:     tm.assert_frame_equal(result, expected)
  277: 
  278: 
  279: def test_transform_dtype():
  280:     # GH 9807
  281:     # Check transform dtype output is preserved
  282:     df = DataFrame([[1, 3], [2, 3]])
  283:     result = df.groupby(1).transform("mean")
  284:     expected = DataFrame([[1.5], [1.5]])
  285:     tm.assert_frame_equal(result, expected)
  286: 
  287: 
  288: def test_transform_bug():
  289:     # GH 5712
  290:     # transforming on a datetime column
  291:     df = DataFrame({"A": Timestamp("20130101"), "B": np.arange(5)})
  292:     result = df.groupby("A")["B"].transform(lambda x: x.rank(ascending=False))
  293:     expected = Series(np.arange(5, 0, step=-1), name="B", dtype="float64")
  294:     tm.assert_series_equal(result, expected)
  295: 
  296: 
  297: def test_transform_numeric_to_boolean():
  298:     # GH 16875
  299:     # inconsistency in transforming boolean values
  300:     expected = Series([True, True], name="A")
  301: 
  302:     df = DataFrame({"A": [1.1, 2.2], "B": [1, 2]})
  303:     result = df.groupby("B").A.transform(lambda x: True)
  304:     tm.assert_series_equal(result, expected)
  305: 
  306:     df = DataFrame({"A": [1, 2], "B": [1, 2]})
  307:     result = df.groupby("B").A.transform(lambda x: True)
  308:     tm.assert_series_equal(result, expected)
  309: 
  310: 
  311: def test_transform_datetime_to_timedelta():
  312:     # GH 15429
  313:     # transforming a datetime to timedelta
  314:     df = DataFrame({"A": Timestamp("20130101"), "B": np.arange(5)})
  315:     expected = Series(
  316:         Timestamp("20130101") - Timestamp("20130101"), index=range(5), name="A"
  317:     )
  318: 
  319:     # this does date math without changing result type in transform
  320:     base_time = df["A"][0]
  321:     result = (
  322:         df.groupby("A")["A"].transform(lambda x: x.max() - x.min() + base_time)
  323:         - base_time
  324:     )
  325:     tm.assert_series_equal(result, expected)
  326: 
  327:     # this does date math and causes the transform to return timedelta
  328:     result = df.groupby("A")["A"].transform(lambda x: x.max() - x.min())
  329:     tm.assert_series_equal(result, expected)
  330: 
  331: 
  332: def test_transform_datetime_to_numeric():
  333:     # GH 10972
  334:     # convert dt to float
  335:     df = DataFrame({"a": 1, "b": date_range("2015-01-01", periods=2, freq="D")})
  336:     result = df.groupby("a").b.transform(
  337:         lambda x: x.dt.dayofweek - x.dt.dayofweek.mean()
  338:     )
  339: 
  340:     expected = Series([-0.5, 0.5], name="b")
  341:     tm.assert_series_equal(result, expected)
  342: 
  343:     # convert dt to int
  344:     df = DataFrame({"a": 1, "b": date_range("2015-01-01", periods=2, freq="D")})
  345:     result = df.groupby("a").b.transform(
  346:         lambda x: x.dt.dayofweek - x.dt.dayofweek.min()
  347:     )
  348: 
  349:     expected = Series([0, 1], dtype=np.int32, name="b")
  350:     tm.assert_series_equal(result, expected)
  351: 
  352: 
  353: def test_transform_casting():
  354:     # 13046
  355:     times = [
  356:         "13:43:27",
  357:         "14:26:19",
  358:         "14:29:01",
  359:         "18:39:34",
  360:         "18:40:18",
  361:         "18:44:30",
  362:         "18:46:00",
  363:         "18:52:15",
  364:         "18:59:59",
  365:         "19:17:48",
  366:         "19:21:38",
  367:     ]
  368:     df = DataFrame(
  369:         {
  370:             "A": [f"B-{i}" for i in range(11)],
  371:             "ID3": np.take(
  372:                 ["a", "b", "c", "d", "e"], [0, 1, 2, 1, 3, 1, 1, 1, 4, 1, 1]
  373:             ),
  374:             "DATETIME": pd.to_datetime([f"2014-10-08 {time}" for time in times]),
  375:         },
  376:         index=pd.RangeIndex(11, name="idx"),
  377:     )
  378: 
  379:     result = df.groupby("ID3")["DATETIME"].transform(lambda x: x.diff())
  380:     assert lib.is_np_dtype(result.dtype, "m")
  381: 
  382:     result = df[["ID3", "DATETIME"]].groupby("ID3").transform(lambda x: x.diff())
  383:     assert lib.is_np_dtype(result.DATETIME.dtype, "m")
  384: 
  385: 
  386: def test_transform_multiple(ts):
  387:     grouped = ts.groupby([lambda x: x.year, lambda x: x.month])
  388: 
  389:     grouped.transform(lambda x: x * 2)
  390: 
  391:     msg = "using SeriesGroupBy.mean"
  392:     with tm.assert_produces_warning(FutureWarning, match=msg):
  393:         grouped.transform(np.mean)
  394: 
  395: 
  396: def test_dispatch_transform(tsframe):
  397:     df = tsframe[::5].reindex(tsframe.index)
  398: 
  399:     grouped = df.groupby(lambda x: x.month)
  400: 
  401:     msg = "DataFrameGroupBy.fillna is deprecated"
  402:     with tm.assert_produces_warning(FutureWarning, match=msg):
  403:         filled = grouped.fillna(method="pad")
  404:     msg = "Series.fillna with 'method' is deprecated"
  405:     fillit = lambda x: x.fillna(method="pad")
  406:     with tm.assert_produces_warning(FutureWarning, match=msg):
  407:         expected = df.groupby(lambda x: x.month).transform(fillit)
  408:     tm.assert_frame_equal(filled, expected)
  409: 
  410: 
  411: def test_transform_fillna_null():
  412:     df = DataFrame(
  413:         {
  414:             "price": [10, 10, 20, 20, 30, 30],
  415:             "color": [10, 10, 20, 20, 30, 30],
  416:             "cost": (100, 200, 300, 400, 500, 600),
  417:         }
  418:     )
  419:     msg = "DataFrameGroupBy.fillna is deprecated"
  420:     with tm.assert_produces_warning(FutureWarning, match=msg):
  421:         with pytest.raises(ValueError, match="Must specify a fill 'value' or 'method'"):
  422:             df.groupby(["price"]).transform("fillna")
  423:     with tm.assert_produces_warning(FutureWarning, match=msg):
  424:         with pytest.raises(ValueError, match="Must specify a fill 'value' or 'method'"):
  425:             df.groupby(["price"]).fillna()
  426: 
  427: 
  428: def test_transform_transformation_func(transformation_func):
  429:     # GH 30918
  430:     df = DataFrame(
  431:         {
  432:             "A": ["foo", "foo", "foo", "foo", "bar", "bar", "baz"],
  433:             "B": [1, 2, np.nan, 3, 3, np.nan, 4],
  434:         },
  435:         index=date_range("2020-01-01", "2020-01-07"),
  436:     )
  437:     if transformation_func == "cumcount":
  438:         test_op = lambda x: x.transform("cumcount")
  439:         mock_op = lambda x: Series(range(len(x)), x.index)
  440:     elif transformation_func == "fillna":
  441:         test_op = lambda x: x.transform("fillna", value=0)
  442:         mock_op = lambda x: x.fillna(value=0)
  443:     elif transformation_func == "ngroup":
  444:         test_op = lambda x: x.transform("ngroup")
  445:         counter = -1
  446: 
  447:         def mock_op(x):
  448:             nonlocal counter
  449:             counter += 1
  450:             return Series(counter, index=x.index)
  451: 
  452:     else:
  453:         test_op = lambda x: x.transform(transformation_func)
  454:         mock_op = lambda x: getattr(x, transformation_func)()
  455: 
  456:     if transformation_func == "pct_change":
  457:         msg = "The default fill_method='pad' in DataFrame.pct_change is deprecated"
  458:         groupby_msg = (
  459:             "The default fill_method='ffill' in DataFrameGroupBy.pct_change "
  460:             "is deprecated"
  461:         )
  462:         warn = FutureWarning
  463:         groupby_warn = FutureWarning
  464:     elif transformation_func == "fillna":
  465:         msg = ""
  466:         groupby_msg = "DataFrameGroupBy.fillna is deprecated"
  467:         warn = None
  468:         groupby_warn = FutureWarning
  469:     else:
  470:         msg = groupby_msg = ""
  471:         warn = groupby_warn = None
  472: 
  473:     with tm.assert_produces_warning(groupby_warn, match=groupby_msg):
  474:         result = test_op(df.groupby("A"))
  475: 
  476:     # pass the group in same order as iterating `for ... in df.groupby(...)`
  477:     # but reorder to match df's index since this is a transform
  478:     groups = [df[["B"]].iloc[4:6], df[["B"]].iloc[6:], df[["B"]].iloc[:4]]
  479:     with tm.assert_produces_warning(warn, match=msg):
  480:         expected = concat([mock_op(g) for g in groups]).sort_index()
  481:     # sort_index does not preserve the freq
  482:     expected = expected.set_axis(df.index)
  483: 
  484:     if transformation_func in ("cumcount", "ngroup"):
  485:         tm.assert_series_equal(result, expected)
  486:     else:
  487:         tm.assert_frame_equal(result, expected)
  488: 
  489: 
  490: def test_transform_select_columns(df):
  491:     f = lambda x: x.mean()
  492:     result = df.groupby("A")[["C", "D"]].transform(f)
  493: 
  494:     selection = df[["C", "D"]]
  495:     expected = selection.groupby(df["A"]).transform(f)
  496: 
  497:     tm.assert_frame_equal(result, expected)
  498: 
  499: 
  500: def test_transform_nuisance_raises(df):
  501:     # case that goes through _transform_item_by_item
  502: 
  503:     df.columns = ["A", "B", "B", "D"]
  504: 
  505:     # this also tests orderings in transform between
  506:     # series/frame to make sure it's consistent
  507:     grouped = df.groupby("A")
  508: 
  509:     gbc = grouped["B"]
  510:     with pytest.raises(TypeError, match="Could not convert"):
  511:         gbc.transform(lambda x: np.mean(x))
  512: 
  513:     with pytest.raises(TypeError, match="Could not convert"):
  514:         df.groupby("A").transform(lambda x: np.mean(x))
  515: 
  516: 
  517: def test_transform_function_aliases(df):
  518:     result = df.groupby("A").transform("mean", numeric_only=True)
  519:     msg = "using DataFrameGroupBy.mean"
  520:     with tm.assert_produces_warning(FutureWarning, match=msg):
  521:         expected = df.groupby("A")[["C", "D"]].transform(np.mean)
  522:     tm.assert_frame_equal(result, expected)
  523: 
  524:     result = df.groupby("A")["C"].transform("mean")
  525:     msg = "using SeriesGroupBy.mean"
  526:     with tm.assert_produces_warning(FutureWarning, match=msg):
  527:         expected = df.groupby("A")["C"].transform(np.mean)
  528:     tm.assert_series_equal(result, expected)
  529: 
  530: 
  531: def test_series_fast_transform_date():
  532:     # GH 13191
  533:     df = DataFrame(
  534:         {"grouping": [np.nan, 1, 1, 3], "d": date_range("2014-1-1", "2014-1-4")}
  535:     )
  536:     result = df.groupby("grouping")["d"].transform("first")
  537:     dates = [
  538:         pd.NaT,
  539:         Timestamp("2014-1-2"),
  540:         Timestamp("2014-1-2"),
  541:         Timestamp("2014-1-4"),
  542:     ]
  543:     expected = Series(dates, name="d", dtype="M8[ns]")
  544:     tm.assert_series_equal(result, expected)
  545: 
  546: 
  547: def test_transform_length():
  548:     # GH 9697
  549:     df = DataFrame({"col1": [1, 1, 2, 2], "col2": [1, 2, 3, np.nan]})
  550:     expected = Series([3.0] * 4)
  551: 
  552:     def nsum(x):
  553:         return np.nansum(x)
  554: 
  555:     msg = "using DataFrameGroupBy.sum"
  556:     with tm.assert_produces_warning(FutureWarning, match=msg):
  557:         results = [
  558:             df.groupby("col1").transform(sum)["col2"],
  559:             df.groupby("col1")["col2"].transform(sum),
  560:             df.groupby("col1").transform(nsum)["col2"],
  561:             df.groupby("col1")["col2"].transform(nsum),
  562:         ]
  563:     for result in results:
  564:         tm.assert_series_equal(result, expected, check_names=False)
  565: 
  566: 
  567: def test_transform_coercion():
  568:     # 14457
  569:     # when we are transforming be sure to not coerce
  570:     # via assignment
  571:     df = DataFrame({"A": ["a", "a", "b", "b"], "B": [0, 1, 3, 4]})
  572:     g = df.groupby("A")
  573: 
  574:     msg = "using DataFrameGroupBy.mean"
  575:     with tm.assert_produces_warning(FutureWarning, match=msg):
  576:         expected = g.transform(np.mean)
  577: 
  578:     result = g.transform(lambda x: np.mean(x, axis=0))
  579:     tm.assert_frame_equal(result, expected)
  580: 
  581: 
  582: def test_groupby_transform_with_int():
  583:     # GH 3740, make sure that we might upcast on item-by-item transform
  584: 
  585:     # floats
  586:     df = DataFrame(
  587:         {
  588:             "A": [1, 1, 1, 2, 2, 2],
  589:             "B": Series(1, dtype="float64"),
  590:             "C": Series([1, 2, 3, 1, 2, 3], dtype="float64"),
  591:             "D": "foo",
  592:         }
  593:     )
  594:     with np.errstate(all="ignore"):
  595:         result = df.groupby("A")[["B", "C"]].transform(
  596:             lambda x: (x - x.mean()) / x.std()
  597:         )
  598:     expected = DataFrame(
  599:         {"B": np.nan, "C": Series([-1, 0, 1, -1, 0, 1], dtype="float64")}
  600:     )
  601:     tm.assert_frame_equal(result, expected)
  602: 
  603:     # int case
  604:     df = DataFrame(
  605:         {
  606:             "A": [1, 1, 1, 2, 2, 2],
  607:             "B": 1,
  608:             "C": [1, 2, 3, 1, 2, 3],
  609:             "D": "foo",
  610:         }
  611:     )
  612:     with np.errstate(all="ignore"):
  613:         with pytest.raises(TypeError, match="Could not convert"):
  614:             df.groupby("A").transform(lambda x: (x - x.mean()) / x.std())
  615:         result = df.groupby("A")[["B", "C"]].transform(
  616:             lambda x: (x - x.mean()) / x.std()
  617:         )
  618:     expected = DataFrame({"B": np.nan, "C": [-1.0, 0.0, 1.0, -1.0, 0.0, 1.0]})
  619:     tm.assert_frame_equal(result, expected)
  620: 
  621:     # int that needs float conversion
  622:     s = Series([2, 3, 4, 10, 5, -1])
  623:     df = DataFrame({"A": [1, 1, 1, 2, 2, 2], "B": 1, "C": s, "D": "foo"})
  624:     with np.errstate(all="ignore"):
  625:         with pytest.raises(TypeError, match="Could not convert"):
  626:             df.groupby("A").transform(lambda x: (x - x.mean()) / x.std())
  627:         result = df.groupby("A")[["B", "C"]].transform(
  628:             lambda x: (x - x.mean()) / x.std()
  629:         )
  630: 
  631:     s1 = s.iloc[0:3]
  632:     s1 = (s1 - s1.mean()) / s1.std()
  633:     s2 = s.iloc[3:6]
  634:     s2 = (s2 - s2.mean()) / s2.std()
  635:     expected = DataFrame({"B": np.nan, "C": concat([s1, s2])})
  636:     tm.assert_frame_equal(result, expected)
  637: 
  638:     # int doesn't get downcasted
  639:     result = df.groupby("A")[["B", "C"]].transform(lambda x: x * 2 / 2)
  640:     expected = DataFrame({"B": 1.0, "C": [2.0, 3.0, 4.0, 10.0, 5.0, -1.0]})
  641:     tm.assert_frame_equal(result, expected)
  642: 
  643: 
  644: def test_groupby_transform_with_nan_group():
  645:     # GH 9941
  646:     df = DataFrame({"a": range(10), "b": [1, 1, 2, 3, np.nan, 4, 4, 5, 5, 5]})
  647:     msg = "using SeriesGroupBy.max"
  648:     with tm.assert_produces_warning(FutureWarning, match=msg):
  649:         result = df.groupby(df.b)["a"].transform(max)
  650:     expected = Series([1.0, 1.0, 2.0, 3.0, np.nan, 6.0, 6.0, 9.0, 9.0, 9.0], name="a")
  651:     tm.assert_series_equal(result, expected)
  652: 
  653: 
  654: def test_transform_mixed_type():
  655:     index = MultiIndex.from_arrays([[0, 0, 0, 1, 1, 1], [1, 2, 3, 1, 2, 3]])
  656:     df = DataFrame(
  657:         {
  658:             "d": [1.0, 1.0, 1.0, 2.0, 2.0, 2.0],
  659:             "c": np.tile(["a", "b", "c"], 2),
  660:             "v": np.arange(1.0, 7.0),
  661:         },
  662:         index=index,
  663:     )
  664: 
  665:     def f(group):
  666:         group["g"] = group["d"] * 2
  667:         return group[:1]
  668: 
  669:     grouped = df.groupby("c")
  670:     msg = "DataFrameGroupBy.apply operated on the grouping columns"
  671:     with tm.assert_produces_warning(DeprecationWarning, match=msg):
  672:         result = grouped.apply(f)
  673: 
  674:     assert result["d"].dtype == np.float64
  675: 
  676:     # this is by definition a mutating operation!
  677:     with pd.option_context("mode.chained_assignment", None):
  678:         for key, group in grouped:
  679:             res = f(group)
  680:             tm.assert_frame_equal(res, result.loc[key])
  681: 
  682: 
  683: @pytest.mark.parametrize(
  684:     "op, args, targop",
  685:     [
  686:         ("cumprod", (), lambda x: x.cumprod()),
  687:         ("cumsum", (), lambda x: x.cumsum()),
  688:         ("shift", (-1,), lambda x: x.shift(-1)),
  689:         ("shift", (1,), lambda x: x.shift()),
  690:     ],
  691: )
  692: def test_cython_transform_series(op, args, targop):
  693:     # GH 4095
  694:     s = Series(np.random.default_rng(2).standard_normal(1000))
  695:     s_missing = s.copy()
  696:     s_missing.iloc[2:10] = np.nan
  697:     labels = np.random.default_rng(2).integers(0, 50, size=1000).astype(float)
  698: 
  699:     # series
  700:     for data in [s, s_missing]:
  701:         # print(data.head())
  702:         expected = data.groupby(labels).transform(targop)
  703: 
  704:         tm.assert_series_equal(expected, data.groupby(labels).transform(op, *args))
  705:         tm.assert_series_equal(expected, getattr(data.groupby(labels), op)(*args))
  706: 
  707: 
  708: @pytest.mark.parametrize("op", ["cumprod", "cumsum"])
  709: @pytest.mark.parametrize("skipna", [False, True])
  710: @pytest.mark.parametrize(
  711:     "input, exp",
  712:     [
  713:         # When everything is NaN
  714:         ({"key": ["b"] * 10, "value": np.nan}, Series([np.nan] * 10, name="value")),
  715:         # When there is a single NaN
  716:         (
  717:             {"key": ["b"] * 10 + ["a"] * 2, "value": [3] * 3 + [np.nan] + [3] * 8},
  718:             {
  719:                 ("cumprod", False): [3.0, 9.0, 27.0] + [np.nan] * 7 + [3.0, 9.0],
  720:                 ("cumprod", True): [
  721:                     3.0,
  722:                     9.0,
  723:                     27.0,
  724:                     np.nan,
  725:                     81.0,
  726:                     243.0,
  727:                     729.0,
  728:                     2187.0,
  729:                     6561.0,
  730:                     19683.0,
  731:                     3.0,
  732:                     9.0,
  733:                 ],
  734:                 ("cumsum", False): [3.0, 6.0, 9.0] + [np.nan] * 7 + [3.0, 6.0],
  735:                 ("cumsum", True): [
  736:                     3.0,
  737:                     6.0,
  738:                     9.0,
  739:                     np.nan,
  740:                     12.0,
  741:                     15.0,
  742:                     18.0,
  743:                     21.0,
  744:                     24.0,
  745:                     27.0,
  746:                     3.0,
  747:                     6.0,
  748:                 ],
  749:             },
  750:         ),
  751:     ],
  752: )
  753: def test_groupby_cum_skipna(op, skipna, input, exp):
  754:     df = DataFrame(input)
  755:     result = df.groupby("key")["value"].transform(op, skipna=skipna)
  756:     if isinstance(exp, dict):
  757:         expected = exp[(op, skipna)]
  758:     else:
  759:         expected = exp
  760:     expected = Series(expected, name="value")
  761:     tm.assert_series_equal(expected, result)
  762: 
  763: 
  764: @pytest.fixture
  765: def frame():
  766:     floating = Series(np.random.default_rng(2).standard_normal(10))
  767:     floating_missing = floating.copy()
  768:     floating_missing.iloc[2:7] = np.nan
  769:     strings = list("abcde") * 2
  770:     strings_missing = strings[:]
  771:     strings_missing[5] = np.nan
  772: 
  773:     df = DataFrame(
  774:         {
  775:             "float": floating,
  776:             "float_missing": floating_missing,
  777:             "int": [1, 1, 1, 1, 2] * 2,
  778:             "datetime": date_range("1990-1-1", periods=10),
  779:             "timedelta": pd.timedelta_range(1, freq="s", periods=10),
  780:             "string": strings,
  781:             "string_missing": strings_missing,
  782:             "cat": Categorical(strings),
  783:         },
  784:     )
  785:     return df
  786: 
  787: 
  788: @pytest.fixture
  789: def frame_mi(frame):
  790:     frame.index = MultiIndex.from_product([range(5), range(2)])
  791:     return frame
  792: 
  793: 
  794: @pytest.mark.slow
  795: @pytest.mark.parametrize(
  796:     "op, args, targop",
  797:     [
  798:         ("cumprod", (), lambda x: x.cumprod()),
  799:         ("cumsum", (), lambda x: x.cumsum()),
  800:         ("shift", (-1,), lambda x: x.shift(-1)),
  801:         ("shift", (1,), lambda x: x.shift()),
  802:     ],
  803: )
  804: @pytest.mark.parametrize("df_fix", ["frame", "frame_mi"])
  805: @pytest.mark.parametrize(
  806:     "gb_target",
  807:     [
  808:         {"by": np.random.default_rng(2).integers(0, 50, size=10).astype(float)},
  809:         {"level": 0},
  810:         {"by": "string"},
  811:         pytest.param({"by": "string_missing"}, marks=pytest.mark.xfail),
  812:         {"by": ["int", "string"]},
  813:     ],
  814: )
  815: def test_cython_transform_frame(request, op, args, targop, df_fix, gb_target):
  816:     df = request.getfixturevalue(df_fix)
  817:     gb = df.groupby(group_keys=False, **gb_target)
  818: 
  819:     if op != "shift" and "int" not in gb_target:
  820:         # numeric apply fastpath promotes dtype so have
  821:         # to apply separately and concat
  822:         i = gb[["int"]].apply(targop)
  823:         f = gb[["float", "float_missing"]].apply(targop)
  824:         expected = concat([f, i], axis=1)
  825:     else:
  826:         if op != "shift" or not isinstance(gb_target.get("by"), (str, list)):
  827:             warn = None
  828:         else:
  829:             warn = DeprecationWarning
  830:         msg = "DataFrameGroupBy.apply operated on the grouping columns"
  831:         with tm.assert_produces_warning(warn, match=msg):
  832:             expected = gb.apply(targop)
  833: 
  834:     expected = expected.sort_index(axis=1)
  835:     if op == "shift":
  836:         depr_msg = "The 'downcast' keyword in fillna is deprecated"
  837:         with tm.assert_produces_warning(FutureWarning, match=depr_msg):
  838:             expected["string_missing"] = expected["string_missing"].fillna(
  839:                 np.nan, downcast=False
  840:             )
  841:             expected["string"] = expected["string"].fillna(np.nan, downcast=False)
  842: 
  843:     result = gb[expected.columns].transform(op, *args).sort_index(axis=1)
  844:     tm.assert_frame_equal(result, expected)
  845:     result = getattr(gb[expected.columns], op)(*args).sort_index(axis=1)
  846:     tm.assert_frame_equal(result, expected)
  847: 
  848: 
  849: @pytest.mark.slow
  850: @pytest.mark.parametrize(
  851:     "op, args, targop",
  852:     [
  853:         ("cumprod", (), lambda x: x.cumprod()),
  854:         ("cumsum", (), lambda x: x.cumsum()),
  855:         ("shift", (-1,), lambda x: x.shift(-1)),
  856:         ("shift", (1,), lambda x: x.shift()),
  857:     ],
  858: )
  859: @pytest.mark.parametrize("df_fix", ["frame", "frame_mi"])
  860: @pytest.mark.parametrize(
  861:     "gb_target",
  862:     [
  863:         {"by": np.random.default_rng(2).integers(0, 50, size=10).astype(float)},
  864:         {"level": 0},
  865:         {"by": "string"},
  866:         # TODO: create xfail condition given other params
  867:         # {"by": 'string_missing'},
  868:         {"by": ["int", "string"]},
  869:     ],
  870: )
  871: @pytest.mark.parametrize(
  872:     "column",
  873:     [
  874:         "float",
  875:         "float_missing",
  876:         "int",
  877:         "datetime",
  878:         "timedelta",
  879:         "string",
  880:         "string_missing",
  881:     ],
  882: )
  883: def test_cython_transform_frame_column(
  884:     request, op, args, targop, df_fix, gb_target, column
  885: ):
  886:     df = request.getfixturevalue(df_fix)
  887:     gb = df.groupby(group_keys=False, **gb_target)
  888:     c = column
  889:     if (
  890:         c not in ["float", "int", "float_missing"]
  891:         and op != "shift"
  892:         and not (c == "timedelta" and op == "cumsum")
  893:     ):
  894:         msg = "|".join(
  895:             [
  896:                 "does not support .* operations",
  897:                 ".* is not supported for object dtype",
  898:                 "is not implemented for this dtype",
  899:             ]
  900:         )
  901:         with pytest.raises(TypeError, match=msg):
  902:             gb[c].transform(op)
  903:         with pytest.raises(TypeError, match=msg):
  904:             getattr(gb[c], op)()
  905:     else:
  906:         expected = gb[c].apply(targop)
  907:         expected.name = c
  908:         if c in ["string_missing", "string"]:
  909:             depr_msg = "The 'downcast' keyword in fillna is deprecated"
  910:             with tm.assert_produces_warning(FutureWarning, match=depr_msg):
  911:                 expected = expected.fillna(np.nan, downcast=False)
  912: 
  913:         res = gb[c].transform(op, *args)
  914:         tm.assert_series_equal(expected, res)
  915:         res2 = getattr(gb[c], op)(*args)
  916:         tm.assert_series_equal(expected, res2)
  917: 
  918: 
  919: def test_transform_with_non_scalar_group():
  920:     # GH 10165
  921:     cols = MultiIndex.from_tuples(
  922:         [
  923:             ("syn", "A"),
  924:             ("foo", "A"),
  925:             ("non", "A"),
  926:             ("syn", "C"),
  927:             ("foo", "C"),
  928:             ("non", "C"),
  929:             ("syn", "T"),
  930:             ("foo", "T"),
  931:             ("non", "T"),
  932:             ("syn", "G"),
  933:             ("foo", "G"),
  934:             ("non", "G"),
  935:         ]
  936:     )
  937:     df = DataFrame(
  938:         np.random.default_rng(2).integers(1, 10, (4, 12)),
  939:         columns=cols,
  940:         index=["A", "C", "G", "T"],
  941:     )
  942: 
  943:     msg = "DataFrame.groupby with axis=1 is deprecated"
  944:     with tm.assert_produces_warning(FutureWarning, match=msg):
  945:         gb = df.groupby(axis=1, level=1)
  946:     msg = "transform must return a scalar value for each group.*"
  947:     with pytest.raises(ValueError, match=msg):
  948:         gb.transform(lambda z: z.div(z.sum(axis=1), axis=0))
  949: 
  950: 
  951: @pytest.mark.parametrize(
  952:     "cols,expected",
  953:     [
  954:         ("a", Series([1, 1, 1], name="a")),
  955:         (
  956:             ["a", "c"],
  957:             DataFrame({"a": [1, 1, 1], "c": [1, 1, 1]}),
  958:         ),
  959:     ],
  960: )
  961: @pytest.mark.parametrize("agg_func", ["count", "rank", "size"])
  962: def test_transform_numeric_ret(cols, expected, agg_func):
  963:     # GH#19200 and GH#27469
  964:     df = DataFrame(
  965:         {"a": date_range("2018-01-01", periods=3), "b": range(3), "c": range(7, 10)}
  966:     )
  967:     result = df.groupby("b")[cols].transform(agg_func)
  968: 
  969:     if agg_func == "rank":
  970:         expected = expected.astype("float")
  971:     elif agg_func == "size" and cols == ["a", "c"]:
  972:         # transform("size") returns a Series
  973:         expected = expected["a"].rename(None)
  974:     tm.assert_equal(result, expected)
  975: 
  976: 
  977: def test_transform_ffill():
  978:     # GH 24211
  979:     data = [["a", 0.0], ["a", float("nan")], ["b", 1.0], ["b", float("nan")]]
  980:     df = DataFrame(data, columns=["key", "values"])
  981:     result = df.groupby("key").transform("ffill")
  982:     expected = DataFrame({"values": [0.0, 0.0, 1.0, 1.0]})
  983:     tm.assert_frame_equal(result, expected)
  984:     result = df.groupby("key")["values"].transform("ffill")
  985:     expected = Series([0.0, 0.0, 1.0, 1.0], name="values")
  986:     tm.assert_series_equal(result, expected)
  987: 
  988: 
  989: @pytest.mark.parametrize("mix_groupings", [True, False])
  990: @pytest.mark.parametrize("as_series", [True, False])
  991: @pytest.mark.parametrize("val1,val2", [("foo", "bar"), (1, 2), (1.0, 2.0)])
  992: @pytest.mark.parametrize(
  993:     "fill_method,limit,exp_vals",
  994:     [
  995:         (
  996:             "ffill",
  997:             None,
  998:             [np.nan, np.nan, "val1", "val1", "val1", "val2", "val2", "val2"],
  999:         ),
 1000:         ("ffill", 1, [np.nan, np.nan, "val1", "val1", np.nan, "val2", "val2", np.nan]),
 1001:         (
 1002:             "bfill",
 1003:             None,
 1004:             ["val1", "val1", "val1", "val2", "val2", "val2", np.nan, np.nan],
 1005:         ),
 1006:         ("bfill", 1, [np.nan, "val1", "val1", np.nan, "val2", "val2", np.nan, np.nan]),
 1007:     ],
 1008: )
 1009: def test_group_fill_methods(
 1010:     mix_groupings, as_series, val1, val2, fill_method, limit, exp_vals
 1011: ):
 1012:     vals = [np.nan, np.nan, val1, np.nan, np.nan, val2, np.nan, np.nan]
 1013:     _exp_vals = list(exp_vals)
 1014:     # Overwrite placeholder values
 1015:     for index, exp_val in enumerate(_exp_vals):
 1016:         if exp_val == "val1":
 1017:             _exp_vals[index] = val1
 1018:         elif exp_val == "val2":
 1019:             _exp_vals[index] = val2
 1020: 
 1021:     # Need to modify values and expectations depending on the
 1022:     # Series / DataFrame that we ultimately want to generate
 1023:     if mix_groupings:  # ['a', 'b', 'a, 'b', ...]
 1024:         keys = ["a", "b"] * len(vals)
 1025: 
 1026:         def interweave(list_obj):
 1027:             temp = []
 1028:             for x in list_obj:
 1029:                 temp.extend([x, x])
 1030: 
 1031:             return temp
 1032: 
 1033:         _exp_vals = interweave(_exp_vals)
 1034:         vals = interweave(vals)
 1035:     else:  # ['a', 'a', 'a', ... 'b', 'b', 'b']
 1036:         keys = ["a"] * len(vals) + ["b"] * len(vals)
 1037:         _exp_vals = _exp_vals * 2
 1038:         vals = vals * 2
 1039: 
 1040:     df = DataFrame({"key": keys, "val": vals})
 1041:     if as_series:
 1042:         result = getattr(df.groupby("key")["val"], fill_method)(limit=limit)
 1043:         exp = Series(_exp_vals, name="val")
 1044:         tm.assert_series_equal(result, exp)
 1045:     else:
 1046:         result = getattr(df.groupby("key"), fill_method)(limit=limit)
 1047:         exp = DataFrame({"val": _exp_vals})
 1048:         tm.assert_frame_equal(result, exp)
 1049: 
 1050: 
 1051: @pytest.mark.parametrize("fill_method", ["ffill", "bfill"])
 1052: def test_pad_stable_sorting(fill_method):
 1053:     # GH 21207
 1054:     x = [0] * 20
 1055:     y = [np.nan] * 10 + [1] * 10
 1056: 
 1057:     if fill_method == "bfill":
 1058:         y = y[::-1]
 1059: 
 1060:     df = DataFrame({"x": x, "y": y})
 1061:     expected = df.drop("x", axis=1)
 1062: 
 1063:     result = getattr(df.groupby("x"), fill_method)()
 1064: 
 1065:     tm.assert_frame_equal(result, expected)
 1066: 
 1067: 
 1068: @pytest.mark.parametrize(
 1069:     "freq",
 1070:     [
 1071:         None,
 1072:         pytest.param(
 1073:             "D",
 1074:             marks=pytest.mark.xfail(
 1075:                 reason="GH#23918 before method uses freq in vectorized approach"
 1076:             ),
 1077:         ),
 1078:     ],
 1079: )
 1080: @pytest.mark.parametrize("periods", [1, -1])
 1081: @pytest.mark.parametrize("fill_method", ["ffill", "bfill", None])
 1082: @pytest.mark.parametrize("limit", [None, 1])
 1083: def test_pct_change(frame_or_series, freq, periods, fill_method, limit):
 1084:     # GH 21200, 21621, 30463
 1085:     vals = [3, np.nan, np.nan, np.nan, 1, 2, 4, 10, np.nan, 4]
 1086:     keys = ["a", "b"]
 1087:     key_v = np.repeat(keys, len(vals))
 1088:     df = DataFrame({"key": key_v, "vals": vals * 2})
 1089: 
 1090:     df_g = df
 1091:     if fill_method is not None:
 1092:         df_g = getattr(df.groupby("key"), fill_method)(limit=limit)
 1093:     grp = df_g.groupby(df.key)
 1094: 
 1095:     expected = grp["vals"].obj / grp["vals"].shift(periods) - 1
 1096: 
 1097:     gb = df.groupby("key")
 1098: 
 1099:     if frame_or_series is Series:
 1100:         gb = gb["vals"]
 1101:     else:
 1102:         expected = expected.to_frame("vals")
 1103: 
 1104:     msg = (
 1105:         "The 'fill_method' keyword being not None and the 'limit' keyword in "
 1106:         f"{type(gb).__name__}.pct_change are deprecated"
 1107:     )
 1108:     with tm.assert_produces_warning(FutureWarning, match=msg):
 1109:         result = gb.pct_change(
 1110:             periods=periods, fill_method=fill_method, limit=limit, freq=freq
 1111:         )
 1112:     tm.assert_equal(result, expected)
 1113: 
 1114: 
 1115: @pytest.mark.parametrize(
 1116:     "func, expected_status",
 1117:     [
 1118:         ("ffill", ["shrt", "shrt", "lng", np.nan, "shrt", "ntrl", "ntrl"]),
 1119:         ("bfill", ["shrt", "lng", "lng", "shrt", "shrt", "ntrl", np.nan]),
 1120:     ],
 1121: )
 1122: def test_ffill_bfill_non_unique_multilevel(func, expected_status):
 1123:     # GH 19437
 1124:     date = pd.to_datetime(
 1125:         [
 1126:             "2018-01-01",
 1127:             "2018-01-01",
 1128:             "2018-01-01",
 1129:             "2018-01-01",
 1130:             "2018-01-02",
 1131:             "2018-01-01",
 1132:             "2018-01-02",
 1133:         ]
 1134:     )
 1135:     symbol = ["MSFT", "MSFT", "MSFT", "AAPL", "AAPL", "TSLA", "TSLA"]
 1136:     status = ["shrt", np.nan, "lng", np.nan, "shrt", "ntrl", np.nan]
 1137: 
 1138:     df = DataFrame({"date": date, "symbol": symbol, "status": status})
 1139:     df = df.set_index(["date", "symbol"])
 1140:     result = getattr(df.groupby("symbol")["status"], func)()
 1141: 
 1142:     index = MultiIndex.from_tuples(
 1143:         tuples=list(zip(*[date, symbol])), names=["date", "symbol"]
 1144:     )
 1145:     expected = Series(expected_status, index=index, name="status")
 1146: 
 1147:     tm.assert_series_equal(result, expected)
 1148: 
 1149: 
 1150: @pytest.mark.parametrize("func", [np.any, np.all])
 1151: def test_any_all_np_func(func):
 1152:     # GH 20653
 1153:     df = DataFrame(
 1154:         [["foo", True], [np.nan, True], ["foo", True]], columns=["key", "val"]
 1155:     )
 1156: 
 1157:     exp = Series([True, np.nan, True], name="val")
 1158: 
 1159:     msg = "using SeriesGroupBy.[any|all]"
 1160:     with tm.assert_produces_warning(FutureWarning, match=msg):
 1161:         res = df.groupby("key")["val"].transform(func)
 1162:     tm.assert_series_equal(res, exp)
 1163: 
 1164: 
 1165: def test_groupby_transform_rename():
 1166:     # https://github.com/pandas-dev/pandas/issues/23461
 1167:     def demean_rename(x):
 1168:         result = x - x.mean()
 1169: 
 1170:         if isinstance(x, Series):
 1171:             return result
 1172: 
 1173:         result = result.rename(columns={c: f"{c}_demeaned" for c in result.columns})
 1174: 
 1175:         return result
 1176: 
 1177:     df = DataFrame({"group": list("ababa"), "value": [1, 1, 1, 2, 2]})
 1178:     expected = DataFrame({"value": [-1.0 / 3, -0.5, -1.0 / 3, 0.5, 2.0 / 3]})
 1179: 
 1180:     result = df.groupby("group").transform(demean_rename)
 1181:     tm.assert_frame_equal(result, expected)
 1182:     result_single = df.groupby("group").value.transform(demean_rename)
 1183:     tm.assert_series_equal(result_single, expected["value"])
 1184: 
 1185: 
 1186: @pytest.mark.parametrize("func", [min, max, np.min, np.max, "first", "last"])
 1187: def test_groupby_transform_timezone_column(func):
 1188:     # GH 24198
 1189:     ts = pd.to_datetime("now", utc=True).tz_convert("Asia/Singapore")
 1190:     result = DataFrame({"end_time": [ts], "id": [1]})
 1191:     warn = FutureWarning if not isinstance(func, str) else None
 1192:     msg = "using SeriesGroupBy.[min|max]"
 1193:     with tm.assert_produces_warning(warn, match=msg):
 1194:         result["max_end_time"] = result.groupby("id").end_time.transform(func)
 1195:     expected = DataFrame([[ts, 1, ts]], columns=["end_time", "id", "max_end_time"])
 1196:     tm.assert_frame_equal(result, expected)
 1197: 
 1198: 
 1199: @pytest.mark.parametrize(
 1200:     "func, values",
 1201:     [
 1202:         ("idxmin", ["1/1/2011"] * 2 + ["1/3/2011"] * 7 + ["1/10/2011"]),
 1203:         ("idxmax", ["1/2/2011"] * 2 + ["1/9/2011"] * 7 + ["1/10/2011"]),
 1204:     ],
 1205: )
 1206: def test_groupby_transform_with_datetimes(func, values):
 1207:     # GH 15306
 1208:     dates = date_range("1/1/2011", periods=10, freq="D")
 1209: 
 1210:     stocks = DataFrame({"price": np.arange(10.0)}, index=dates)
 1211:     stocks["week_id"] = dates.isocalendar().week
 1212: 
 1213:     result = stocks.groupby(stocks["week_id"])["price"].transform(func)
 1214: 
 1215:     expected = Series(
 1216:         data=pd.to_datetime(values).as_unit("ns"), index=dates, name="price"
 1217:     )
 1218: 
 1219:     tm.assert_series_equal(result, expected)
 1220: 
 1221: 
 1222: def test_groupby_transform_dtype():
 1223:     # GH 22243
 1224:     df = DataFrame({"a": [1], "val": [1.35]})
 1225: 
 1226:     result = df["val"].transform(lambda x: x.map(lambda y: f"+{y}"))
 1227:     expected1 = Series(["+1.35"], name="val", dtype="object")
 1228:     tm.assert_series_equal(result, expected1)
 1229: 
 1230:     result = df.groupby("a")["val"].transform(lambda x: x.map(lambda y: f"+{y}"))
 1231:     tm.assert_series_equal(result, expected1)
 1232: 
 1233:     result = df.groupby("a")["val"].transform(lambda x: x.map(lambda y: f"+({y})"))
 1234:     expected2 = Series(["+(1.35)"], name="val", dtype="object")
 1235:     tm.assert_series_equal(result, expected2)
 1236: 
 1237:     df["val"] = df["val"].astype(object)
 1238:     result = df.groupby("a")["val"].transform(lambda x: x.map(lambda y: f"+{y}"))
 1239:     tm.assert_series_equal(result, expected1)
 1240: 
 1241: 
 1242: @pytest.mark.parametrize("func", ["cumsum", "cumprod", "cummin", "cummax"])
 1243: def test_transform_absent_categories(func):
 1244:     # GH 16771
 1245:     # cython transforms with more groups than rows
 1246:     x_vals = [1]
 1247:     x_cats = range(2)
 1248:     y = [1]
 1249:     df = DataFrame({"x": Categorical(x_vals, x_cats), "y": y})
 1250:     result = getattr(df.y.groupby(df.x, observed=False), func)()
 1251:     expected = df.y
 1252:     tm.assert_series_equal(result, expected)
 1253: 
 1254: 
 1255: @pytest.mark.parametrize("func", ["ffill", "bfill", "shift"])
 1256: @pytest.mark.parametrize("key, val", [("level", 0), ("by", Series([0]))])
 1257: def test_ffill_not_in_axis(func, key, val):
 1258:     # GH 21521
 1259:     df = DataFrame([[np.nan]])
 1260:     result = getattr(df.groupby(**{key: val}), func)()
 1261:     expected = df
 1262: 
 1263:     tm.assert_frame_equal(result, expected)
 1264: 
 1265: 
 1266: def test_transform_invalid_name_raises():
 1267:     # GH#27486
 1268:     df = DataFrame({"a": [0, 1, 1, 2]})
 1269:     g = df.groupby(["a", "b", "b", "c"])
 1270:     with pytest.raises(ValueError, match="not a valid function name"):
 1271:         g.transform("some_arbitrary_name")
 1272: 
 1273:     # method exists on the object, but is not a valid transformation/agg
 1274:     assert hasattr(g, "aggregate")  # make sure the method exists
 1275:     with pytest.raises(ValueError, match="not a valid function name"):
 1276:         g.transform("aggregate")
 1277: 
 1278:     # Test SeriesGroupBy
 1279:     g = df["a"].groupby(["a", "b", "b", "c"])
 1280:     with pytest.raises(ValueError, match="not a valid function name"):
 1281:         g.transform("some_arbitrary_name")
 1282: 
 1283: 
 1284: def test_transform_agg_by_name(request, reduction_func, frame_or_series):
 1285:     func = reduction_func
 1286: 
 1287:     obj = DataFrame(
 1288:         {"a": [0, 0, 0, 1, 1, 1], "b": range(6)},
 1289:         index=["A", "B", "C", "D", "E", "F"],
 1290:     )
 1291:     if frame_or_series is Series:
 1292:         obj = obj["a"]
 1293: 
 1294:     g = obj.groupby(np.repeat([0, 1], 3))
 1295: 
 1296:     if func == "corrwith" and isinstance(obj, Series):  # GH#32293
 1297:         # TODO: implement SeriesGroupBy.corrwith
 1298:         assert not hasattr(g, func)
 1299:         return
 1300: 
 1301:     args = get_groupby_method_args(reduction_func, obj)
 1302:     result = g.transform(func, *args)
 1303: 
 1304:     # this is the *definition* of a transformation
 1305:     tm.assert_index_equal(result.index, obj.index)
 1306: 
 1307:     if func not in ("ngroup", "size") and obj.ndim == 2:
 1308:         # size/ngroup return a Series, unlike other transforms
 1309:         tm.assert_index_equal(result.columns, obj.columns)
 1310: 
 1311:     # verify that values were broadcasted across each group
 1312:     assert len(set(DataFrame(result).iloc[-3:, -1])) == 1
 1313: 
 1314: 
 1315: def test_transform_lambda_with_datetimetz():
 1316:     # GH 27496
 1317:     df = DataFrame(
 1318:         {
 1319:             "time": [
 1320:                 Timestamp("2010-07-15 03:14:45"),
 1321:                 Timestamp("2010-11-19 18:47:06"),
 1322:             ],
 1323:             "timezone": ["Etc/GMT+4", "US/Eastern"],
 1324:         }
 1325:     )
 1326:     result = df.groupby(["timezone"])["time"].transform(
 1327:         lambda x: x.dt.tz_localize(x.name)
 1328:     )
 1329:     expected = Series(
 1330:         [
 1331:             Timestamp("2010-07-15 03:14:45", tz="Etc/GMT+4"),
 1332:             Timestamp("2010-11-19 18:47:06", tz="US/Eastern"),
 1333:         ],
 1334:         name="time",
 1335:     )
 1336:     tm.assert_series_equal(result, expected)
 1337: 
 1338: 
 1339: def test_transform_fastpath_raises():
 1340:     # GH#29631 case where fastpath defined in groupby.generic _choose_path
 1341:     #  raises, but slow_path does not
 1342: 
 1343:     df = DataFrame({"A": [1, 1, 2, 2], "B": [1, -1, 1, 2]})
 1344:     gb = df.groupby("A")
 1345: 
 1346:     def func(grp):
 1347:         # we want a function such that func(frame) fails but func.apply(frame)
 1348:         #  works
 1349:         if grp.ndim == 2:
 1350:             # Ensure that fast_path fails
 1351:             raise NotImplementedError("Don't cross the streams")
 1352:         return grp * 2
 1353: 
 1354:     # Check that the fastpath raises, see _transform_general
 1355:     obj = gb._obj_with_exclusions
 1356:     gen = gb._grouper.get_iterator(obj, axis=gb.axis)
 1357:     fast_path, slow_path = gb._define_paths(func)
 1358:     _, group = next(gen)
 1359: 
 1360:     with pytest.raises(NotImplementedError, match="Don't cross the streams"):
 1361:         fast_path(group)
 1362: 
 1363:     result = gb.transform(func)
 1364: 
 1365:     expected = DataFrame([2, -2, 2, 4], columns=["B"])
 1366:     tm.assert_frame_equal(result, expected)
 1367: 
 1368: 
 1369: def test_transform_lambda_indexing():
 1370:     # GH 7883
 1371:     df = DataFrame(
 1372:         {
 1373:             "A": ["foo", "bar", "foo", "bar", "foo", "flux", "foo", "flux"],
 1374:             "B": ["one", "one", "two", "three", "two", "six", "five", "three"],
 1375:             "C": range(8),
 1376:             "D": range(8),
 1377:             "E": range(8),
 1378:         }
 1379:     )
 1380:     df = df.set_index(["A", "B"])
 1381:     df = df.sort_index()
 1382:     result = df.groupby(level="A").transform(lambda x: x.iloc[-1])
 1383:     expected = DataFrame(
 1384:         {
 1385:             "C": [3, 3, 7, 7, 4, 4, 4, 4],
 1386:             "D": [3, 3, 7, 7, 4, 4, 4, 4],
 1387:             "E": [3, 3, 7, 7, 4, 4, 4, 4],
 1388:         },
 1389:         index=MultiIndex.from_tuples(
 1390:             [
 1391:                 ("bar", "one"),
 1392:                 ("bar", "three"),
 1393:                 ("flux", "six"),
 1394:                 ("flux", "three"),
 1395:                 ("foo", "five"),
 1396:                 ("foo", "one"),
 1397:                 ("foo", "two"),
 1398:                 ("foo", "two"),
 1399:             ],
 1400:             names=["A", "B"],
 1401:         ),
 1402:     )
 1403:     tm.assert_frame_equal(result, expected)
 1404: 
 1405: 
 1406: def test_categorical_and_not_categorical_key(observed):
 1407:     # Checks that groupby-transform, when grouping by both a categorical
 1408:     # and a non-categorical key, doesn't try to expand the output to include
 1409:     # non-observed categories but instead matches the input shape.
 1410:     # GH 32494
 1411:     df_with_categorical = DataFrame(
 1412:         {
 1413:             "A": Categorical(["a", "b", "a"], categories=["a", "b", "c"]),
 1414:             "B": [1, 2, 3],
 1415:             "C": ["a", "b", "a"],
 1416:         }
 1417:     )
 1418:     df_without_categorical = DataFrame(
 1419:         {"A": ["a", "b", "a"], "B": [1, 2, 3], "C": ["a", "b", "a"]}
 1420:     )
 1421: 
 1422:     # DataFrame case
 1423:     result = df_with_categorical.groupby(["A", "C"], observed=observed).transform("sum")
 1424:     expected = df_without_categorical.groupby(["A", "C"]).transform("sum")
 1425:     tm.assert_frame_equal(result, expected)
 1426:     expected_explicit = DataFrame({"B": [4, 2, 4]})
 1427:     tm.assert_frame_equal(result, expected_explicit)
 1428: 
 1429:     # Series case
 1430:     result = df_with_categorical.groupby(["A", "C"], observed=observed)["B"].transform(
 1431:         "sum"
 1432:     )
 1433:     expected = df_without_categorical.groupby(["A", "C"])["B"].transform("sum")
 1434:     tm.assert_series_equal(result, expected)
 1435:     expected_explicit = Series([4, 2, 4], name="B")
 1436:     tm.assert_series_equal(result, expected_explicit)
 1437: 
 1438: 
 1439: def test_string_rank_grouping():
 1440:     # GH 19354
 1441:     df = DataFrame({"A": [1, 1, 2], "B": [1, 2, 3]})
 1442:     result = df.groupby("A").transform("rank")
 1443:     expected = DataFrame({"B": [1.0, 2.0, 1.0]})
 1444:     tm.assert_frame_equal(result, expected)
 1445: 
 1446: 
 1447: def test_transform_cumcount():
 1448:     # GH 27472
 1449:     df = DataFrame({"a": [0, 0, 0, 1, 1, 1], "b": range(6)})
 1450:     grp = df.groupby(np.repeat([0, 1], 3))
 1451: 
 1452:     result = grp.cumcount()
 1453:     expected = Series([0, 1, 2, 0, 1, 2])
 1454:     tm.assert_series_equal(result, expected)
 1455: 
 1456:     result = grp.transform("cumcount")
 1457:     tm.assert_series_equal(result, expected)
 1458: 
 1459: 
 1460: @pytest.mark.parametrize("keys", [["A1"], ["A1", "A2"]])
 1461: def test_null_group_lambda_self(sort, dropna, keys):
 1462:     # GH 17093
 1463:     size = 50
 1464:     nulls1 = np.random.default_rng(2).choice([False, True], size)
 1465:     nulls2 = np.random.default_rng(2).choice([False, True], size)
 1466:     # Whether a group contains a null value or not
 1467:     nulls_grouper = nulls1 if len(keys) == 1 else nulls1 | nulls2
 1468: 
 1469:     a1 = np.random.default_rng(2).integers(0, 5, size=size).astype(float)
 1470:     a1[nulls1] = np.nan
 1471:     a2 = np.random.default_rng(2).integers(0, 5, size=size).astype(float)
 1472:     a2[nulls2] = np.nan
 1473:     values = np.random.default_rng(2).integers(0, 5, size=a1.shape)
 1474:     df = DataFrame({"A1": a1, "A2": a2, "B": values})
 1475: 
 1476:     expected_values = values
 1477:     if dropna and nulls_grouper.any():
 1478:         expected_values = expected_values.astype(float)
 1479:         expected_values[nulls_grouper] = np.nan
 1480:     expected = DataFrame(expected_values, columns=["B"])
 1481: 
 1482:     gb = df.groupby(keys, dropna=dropna, sort=sort)
 1483:     result = gb[["B"]].transform(lambda x: x)
 1484:     tm.assert_frame_equal(result, expected)
 1485: 
 1486: 
 1487: def test_null_group_str_reducer(request, dropna, reduction_func):
 1488:     # GH 17093
 1489:     if reduction_func == "corrwith":
 1490:         msg = "incorrectly raises"
 1491:         request.applymarker(pytest.mark.xfail(reason=msg))
 1492: 
 1493:     index = [1, 2, 3, 4]  # test transform preserves non-standard index
 1494:     df = DataFrame({"A": [1, 1, np.nan, np.nan], "B": [1, 2, 2, 3]}, index=index)
 1495:     gb = df.groupby("A", dropna=dropna)
 1496: 
 1497:     args = get_groupby_method_args(reduction_func, df)
 1498: 
 1499:     # Manually handle reducers that don't fit the generic pattern
 1500:     # Set expected with dropna=False, then replace if necessary
 1501:     if reduction_func == "first":
 1502:         expected = DataFrame({"B": [1, 1, 2, 2]}, index=index)
 1503:     elif reduction_func == "last":
 1504:         expected = DataFrame({"B": [2, 2, 3, 3]}, index=index)
 1505:     elif reduction_func == "nth":
 1506:         expected = DataFrame({"B": [1, 1, 2, 2]}, index=index)
 1507:     elif reduction_func == "size":
 1508:         expected = Series([2, 2, 2, 2], index=index)
 1509:     elif reduction_func == "corrwith":
 1510:         expected = DataFrame({"B": [1.0, 1.0, 1.0, 1.0]}, index=index)
 1511:     else:
 1512:         expected_gb = df.groupby("A", dropna=False)
 1513:         buffer = []
 1514:         for idx, group in expected_gb:
 1515:             res = getattr(group["B"], reduction_func)()
 1516:             buffer.append(Series(res, index=group.index))
 1517:         expected = concat(buffer).to_frame("B")
 1518:     if dropna:
 1519:         dtype = object if reduction_func in ("any", "all") else float
 1520:         expected = expected.astype(dtype)
 1521:         if expected.ndim == 2:
 1522:             expected.iloc[[2, 3], 0] = np.nan
 1523:         else:
 1524:             expected.iloc[[2, 3]] = np.nan
 1525: 
 1526:     result = gb.transform(reduction_func, *args)
 1527:     tm.assert_equal(result, expected)
 1528: 
 1529: 
 1530: def test_null_group_str_transformer(request, dropna, transformation_func):
 1531:     # GH 17093
 1532:     df = DataFrame({"A": [1, 1, np.nan], "B": [1, 2, 2]}, index=[1, 2, 3])
 1533:     args = get_groupby_method_args(transformation_func, df)
 1534:     gb = df.groupby("A", dropna=dropna)
 1535: 
 1536:     buffer = []
 1537:     for k, (idx, group) in enumerate(gb):
 1538:         if transformation_func == "cumcount":
 1539:             # DataFrame has no cumcount method
 1540:             res = DataFrame({"B": range(len(group))}, index=group.index)
 1541:         elif transformation_func == "ngroup":
 1542:             res = DataFrame(len(group) * [k], index=group.index, columns=["B"])
 1543:         else:
 1544:             res = getattr(group[["B"]], transformation_func)(*args)
 1545:         buffer.append(res)
 1546:     if dropna:
 1547:         dtype = object if transformation_func in ("any", "all") else None
 1548:         buffer.append(DataFrame([[np.nan]], index=[3], dtype=dtype, columns=["B"]))
 1549:     expected = concat(buffer)
 1550: 
 1551:     if transformation_func in ("cumcount", "ngroup"):
 1552:         # ngroup/cumcount always returns a Series as it counts the groups, not values
 1553:         expected = expected["B"].rename(None)
 1554: 
 1555:     if transformation_func == "pct_change" and not dropna:
 1556:         warn = FutureWarning
 1557:         msg = (
 1558:             "The default fill_method='ffill' in DataFrameGroupBy.pct_change "
 1559:             "is deprecated"
 1560:         )
 1561:     elif transformation_func == "fillna":
 1562:         warn = FutureWarning
 1563:         msg = "DataFrameGroupBy.fillna is deprecated"
 1564:     else:
 1565:         warn = None
 1566:         msg = ""
 1567:     with tm.assert_produces_warning(warn, match=msg):
 1568:         result = gb.transform(transformation_func, *args)
 1569: 
 1570:     tm.assert_equal(result, expected)
 1571: 
 1572: 
 1573: def test_null_group_str_reducer_series(request, dropna, reduction_func):
 1574:     # GH 17093
 1575:     index = [1, 2, 3, 4]  # test transform preserves non-standard index
 1576:     ser = Series([1, 2, 2, 3], index=index)
 1577:     gb = ser.groupby([1, 1, np.nan, np.nan], dropna=dropna)
 1578: 
 1579:     if reduction_func == "corrwith":
 1580:         # corrwith not implemented for SeriesGroupBy
 1581:         assert not hasattr(gb, reduction_func)
 1582:         return
 1583: 
 1584:     args = get_groupby_method_args(reduction_func, ser)
 1585: 
 1586:     # Manually handle reducers that don't fit the generic pattern
 1587:     # Set expected with dropna=False, then replace if necessary
 1588:     if reduction_func == "first":
 1589:         expected = Series([1, 1, 2, 2], index=index)
 1590:     elif reduction_func == "last":
 1591:         expected = Series([2, 2, 3, 3], index=index)
 1592:     elif reduction_func == "nth":
 1593:         expected = Series([1, 1, 2, 2], index=index)
 1594:     elif reduction_func == "size":
 1595:         expected = Series([2, 2, 2, 2], index=index)
 1596:     elif reduction_func == "corrwith":
 1597:         expected = Series([1, 1, 2, 2], index=index)
 1598:     else:
 1599:         expected_gb = ser.groupby([1, 1, np.nan, np.nan], dropna=False)
 1600:         buffer = []
 1601:         for idx, group in expected_gb:
 1602:             res = getattr(group, reduction_func)()
 1603:             buffer.append(Series(res, index=group.index))
 1604:         expected = concat(buffer)
 1605:     if dropna:
 1606:         dtype = object if reduction_func in ("any", "all") else float
 1607:         expected = expected.astype(dtype)
 1608:         expected.iloc[[2, 3]] = np.nan
 1609: 
 1610:     result = gb.transform(reduction_func, *args)
 1611:     tm.assert_series_equal(result, expected)
 1612: 
 1613: 
 1614: def test_null_group_str_transformer_series(dropna, transformation_func):
 1615:     # GH 17093
 1616:     ser = Series([1, 2, 2], index=[1, 2, 3])
 1617:     args = get_groupby_method_args(transformation_func, ser)
 1618:     gb = ser.groupby([1, 1, np.nan], dropna=dropna)
 1619: 
 1620:     buffer = []
 1621:     for k, (idx, group) in enumerate(gb):
 1622:         if transformation_func == "cumcount":
 1623:             # Series has no cumcount method
 1624:             res = Series(range(len(group)), index=group.index)
 1625:         elif transformation_func == "ngroup":
 1626:             res = Series(k, index=group.index)
 1627:         else:
 1628:             res = getattr(group, transformation_func)(*args)
 1629:         buffer.append(res)
 1630:     if dropna:
 1631:         dtype = object if transformation_func in ("any", "all") else None
 1632:         buffer.append(Series([np.nan], index=[3], dtype=dtype))
 1633:     expected = concat(buffer)
 1634: 
 1635:     warn = FutureWarning if transformation_func == "fillna" else None
 1636:     msg = "SeriesGroupBy.fillna is deprecated"
 1637:     with tm.assert_produces_warning(warn, match=msg):
 1638:         result = gb.transform(transformation_func, *args)
 1639: 
 1640:     tm.assert_equal(result, expected)
 1641: 
 1642: 
 1643: @pytest.mark.parametrize(
 1644:     "func, expected_values",
 1645:     [
 1646:         (Series.sort_values, [5, 4, 3, 2, 1]),
 1647:         (lambda x: x.head(1), [5.0, np.nan, 3, 2, np.nan]),
 1648:     ],
 1649: )
 1650: @pytest.mark.parametrize("keys", [["a1"], ["a1", "a2"]])
 1651: @pytest.mark.parametrize("keys_in_index", [True, False])
 1652: def test_transform_aligns(func, frame_or_series, expected_values, keys, keys_in_index):
 1653:     # GH#45648 - transform should align with the input's index
 1654:     df = DataFrame({"a1": [1, 1, 3, 2, 2], "b": [5, 4, 3, 2, 1]})
 1655:     if "a2" in keys:
 1656:         df["a2"] = df["a1"]
 1657:     if keys_in_index:
 1658:         df = df.set_index(keys, append=True)
 1659: 
 1660:     gb = df.groupby(keys)
 1661:     if frame_or_series is Series:
 1662:         gb = gb["b"]
 1663: 
 1664:     result = gb.transform(func)
 1665:     expected = DataFrame({"b": expected_values}, index=df.index)
 1666:     if frame_or_series is Series:
 1667:         expected = expected["b"]
 1668:     tm.assert_equal(result, expected)
 1669: 
 1670: 
 1671: @pytest.mark.parametrize("keys", ["A", ["A", "B"]])
 1672: def test_as_index_no_change(keys, df, groupby_func):
 1673:     # GH#49834 - as_index should have no impact on DataFrameGroupBy.transform
 1674:     if keys == "A":
 1675:         # Column B is string dtype; will fail on some ops
 1676:         df = df.drop(columns="B")
 1677:     args = get_groupby_method_args(groupby_func, df)
 1678:     gb_as_index_true = df.groupby(keys, as_index=True)
 1679:     gb_as_index_false = df.groupby(keys, as_index=False)
 1680:     warn = FutureWarning if groupby_func == "fillna" else None
 1681:     msg = "DataFrameGroupBy.fillna is deprecated"
 1682:     with tm.assert_produces_warning(warn, match=msg):
 1683:         result = gb_as_index_true.transform(groupby_func, *args)
 1684:     with tm.assert_produces_warning(warn, match=msg):
 1685:         expected = gb_as_index_false.transform(groupby_func, *args)
 1686:     tm.assert_equal(result, expected)
 1687: 
 1688: 
 1689: @pytest.mark.parametrize("how", ["idxmax", "idxmin"])
 1690: @pytest.mark.parametrize("numeric_only", [True, False])
 1691: def test_idxmin_idxmax_transform_args(how, skipna, numeric_only):
 1692:     # GH#55268 - ensure *args are passed through when calling transform
 1693:     df = DataFrame({"a": [1, 1, 1, 2], "b": [3.0, 4.0, np.nan, 6.0], "c": list("abcd")})
 1694:     gb = df.groupby("a")
 1695:     msg = f"'axis' keyword in DataFrameGroupBy.{how} is deprecated"
 1696:     with tm.assert_produces_warning(FutureWarning, match=msg):
 1697:         result = gb.transform(how, 0, skipna, numeric_only)
 1698:     warn = None if skipna else FutureWarning
 1699:     msg = f"The behavior of DataFrameGroupBy.{how} with .* any-NA and skipna=False"
 1700:     with tm.assert_produces_warning(warn, match=msg):
 1701:         expected = gb.transform(how, skipna=skipna, numeric_only=numeric_only)
 1702:     tm.assert_frame_equal(result, expected)
