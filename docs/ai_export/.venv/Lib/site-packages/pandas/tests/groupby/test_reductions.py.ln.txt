    1: import builtins
    2: import datetime as dt
    3: from string import ascii_lowercase
    4: 
    5: import numpy as np
    6: import pytest
    7: 
    8: from pandas._libs.tslibs import iNaT
    9: 
   10: from pandas.core.dtypes.common import pandas_dtype
   11: from pandas.core.dtypes.missing import na_value_for_dtype
   12: 
   13: import pandas as pd
   14: from pandas import (
   15:     DataFrame,
   16:     MultiIndex,
   17:     Series,
   18:     Timestamp,
   19:     date_range,
   20:     isna,
   21: )
   22: import pandas._testing as tm
   23: from pandas.util import _test_decorators as td
   24: 
   25: 
   26: @pytest.mark.parametrize("agg_func", ["any", "all"])
   27: @pytest.mark.parametrize(
   28:     "vals",
   29:     [
   30:         ["foo", "bar", "baz"],
   31:         ["foo", "", ""],
   32:         ["", "", ""],
   33:         [1, 2, 3],
   34:         [1, 0, 0],
   35:         [0, 0, 0],
   36:         [1.0, 2.0, 3.0],
   37:         [1.0, 0.0, 0.0],
   38:         [0.0, 0.0, 0.0],
   39:         [True, True, True],
   40:         [True, False, False],
   41:         [False, False, False],
   42:         [np.nan, np.nan, np.nan],
   43:     ],
   44: )
   45: def test_groupby_bool_aggs(skipna, agg_func, vals):
   46:     df = DataFrame({"key": ["a"] * 3 + ["b"] * 3, "val": vals * 2})
   47: 
   48:     # Figure out expectation using Python builtin
   49:     exp = getattr(builtins, agg_func)(vals)
   50: 
   51:     # edge case for missing data with skipna and 'any'
   52:     if skipna and all(isna(vals)) and agg_func == "any":
   53:         exp = False
   54: 
   55:     expected = DataFrame(
   56:         [exp] * 2, columns=["val"], index=pd.Index(["a", "b"], name="key")
   57:     )
   58:     result = getattr(df.groupby("key"), agg_func)(skipna=skipna)
   59:     tm.assert_frame_equal(result, expected)
   60: 
   61: 
   62: def test_any():
   63:     df = DataFrame(
   64:         [[1, 2, "foo"], [1, np.nan, "bar"], [3, np.nan, "baz"]],
   65:         columns=["A", "B", "C"],
   66:     )
   67:     expected = DataFrame(
   68:         [[True, True], [False, True]], columns=["B", "C"], index=[1, 3]
   69:     )
   70:     expected.index.name = "A"
   71:     result = df.groupby("A").any()
   72:     tm.assert_frame_equal(result, expected)
   73: 
   74: 
   75: @pytest.mark.parametrize("bool_agg_func", ["any", "all"])
   76: def test_bool_aggs_dup_column_labels(bool_agg_func):
   77:     # GH#21668
   78:     df = DataFrame([[True, True]], columns=["a", "a"])
   79:     grp_by = df.groupby([0])
   80:     result = getattr(grp_by, bool_agg_func)()
   81: 
   82:     expected = df.set_axis(np.array([0]))
   83:     tm.assert_frame_equal(result, expected)
   84: 
   85: 
   86: @pytest.mark.parametrize("bool_agg_func", ["any", "all"])
   87: @pytest.mark.parametrize(
   88:     "data",
   89:     [
   90:         [False, False, False],
   91:         [True, True, True],
   92:         [pd.NA, pd.NA, pd.NA],
   93:         [False, pd.NA, False],
   94:         [True, pd.NA, True],
   95:         [True, pd.NA, False],
   96:     ],
   97: )
   98: def test_masked_kleene_logic(bool_agg_func, skipna, data):
   99:     # GH#37506
  100:     ser = Series(data, dtype="boolean")
  101: 
  102:     # The result should match aggregating on the whole series. Correctness
  103:     # there is verified in test_reductions.py::test_any_all_boolean_kleene_logic
  104:     expected_data = getattr(ser, bool_agg_func)(skipna=skipna)
  105:     expected = Series(expected_data, index=np.array([0]), dtype="boolean")
  106: 
  107:     result = ser.groupby([0, 0, 0]).agg(bool_agg_func, skipna=skipna)
  108:     tm.assert_series_equal(result, expected)
  109: 
  110: 
  111: @pytest.mark.parametrize(
  112:     "dtype1,dtype2,exp_col1,exp_col2",
  113:     [
  114:         (
  115:             "float",
  116:             "Float64",
  117:             np.array([True], dtype=bool),
  118:             pd.array([pd.NA], dtype="boolean"),
  119:         ),
  120:         (
  121:             "Int64",
  122:             "float",
  123:             pd.array([pd.NA], dtype="boolean"),
  124:             np.array([True], dtype=bool),
  125:         ),
  126:         (
  127:             "Int64",
  128:             "Int64",
  129:             pd.array([pd.NA], dtype="boolean"),
  130:             pd.array([pd.NA], dtype="boolean"),
  131:         ),
  132:         (
  133:             "Float64",
  134:             "boolean",
  135:             pd.array([pd.NA], dtype="boolean"),
  136:             pd.array([pd.NA], dtype="boolean"),
  137:         ),
  138:     ],
  139: )
  140: def test_masked_mixed_types(dtype1, dtype2, exp_col1, exp_col2):
  141:     # GH#37506
  142:     data = [1.0, np.nan]
  143:     df = DataFrame(
  144:         {"col1": pd.array(data, dtype=dtype1), "col2": pd.array(data, dtype=dtype2)}
  145:     )
  146:     result = df.groupby([1, 1]).agg("all", skipna=False)
  147: 
  148:     expected = DataFrame({"col1": exp_col1, "col2": exp_col2}, index=np.array([1]))
  149:     tm.assert_frame_equal(result, expected)
  150: 
  151: 
  152: @pytest.mark.parametrize("bool_agg_func", ["any", "all"])
  153: @pytest.mark.parametrize("dtype", ["Int64", "Float64", "boolean"])
  154: def test_masked_bool_aggs_skipna(bool_agg_func, dtype, skipna, frame_or_series):
  155:     # GH#40585
  156:     obj = frame_or_series([pd.NA, 1], dtype=dtype)
  157:     expected_res = True
  158:     if not skipna and bool_agg_func == "all":
  159:         expected_res = pd.NA
  160:     expected = frame_or_series([expected_res], index=np.array([1]), dtype="boolean")
  161: 
  162:     result = obj.groupby([1, 1]).agg(bool_agg_func, skipna=skipna)
  163:     tm.assert_equal(result, expected)
  164: 
  165: 
  166: @pytest.mark.parametrize(
  167:     "bool_agg_func,data,expected_res",
  168:     [
  169:         ("any", [pd.NA, np.nan], False),
  170:         ("any", [pd.NA, 1, np.nan], True),
  171:         ("all", [pd.NA, pd.NaT], True),
  172:         ("all", [pd.NA, False, pd.NaT], False),
  173:     ],
  174: )
  175: def test_object_type_missing_vals(bool_agg_func, data, expected_res, frame_or_series):
  176:     # GH#37501
  177:     obj = frame_or_series(data, dtype=object)
  178:     result = obj.groupby([1] * len(data)).agg(bool_agg_func)
  179:     expected = frame_or_series([expected_res], index=np.array([1]), dtype="bool")
  180:     tm.assert_equal(result, expected)
  181: 
  182: 
  183: @pytest.mark.parametrize("bool_agg_func", ["any", "all"])
  184: def test_object_NA_raises_with_skipna_false(bool_agg_func):
  185:     # GH#37501
  186:     ser = Series([pd.NA], dtype=object)
  187:     with pytest.raises(TypeError, match="boolean value of NA is ambiguous"):
  188:         ser.groupby([1]).agg(bool_agg_func, skipna=False)
  189: 
  190: 
  191: @pytest.mark.parametrize("bool_agg_func", ["any", "all"])
  192: def test_empty(frame_or_series, bool_agg_func):
  193:     # GH 45231
  194:     kwargs = {"columns": ["a"]} if frame_or_series is DataFrame else {"name": "a"}
  195:     obj = frame_or_series(**kwargs, dtype=object)
  196:     result = getattr(obj.groupby(obj.index), bool_agg_func)()
  197:     expected = frame_or_series(**kwargs, dtype=bool)
  198:     tm.assert_equal(result, expected)
  199: 
  200: 
  201: @pytest.mark.parametrize("how", ["idxmin", "idxmax"])
  202: def test_idxmin_idxmax_extremes(how, any_real_numpy_dtype):
  203:     # GH#57040
  204:     if any_real_numpy_dtype is int or any_real_numpy_dtype is float:
  205:         # No need to test
  206:         return
  207:     info = np.iinfo if "int" in any_real_numpy_dtype else np.finfo
  208:     min_value = info(any_real_numpy_dtype).min
  209:     max_value = info(any_real_numpy_dtype).max
  210:     df = DataFrame(
  211:         {"a": [2, 1, 1, 2], "b": [min_value, max_value, max_value, min_value]},
  212:         dtype=any_real_numpy_dtype,
  213:     )
  214:     gb = df.groupby("a")
  215:     result = getattr(gb, how)()
  216:     expected = DataFrame(
  217:         {"b": [1, 0]}, index=pd.Index([1, 2], name="a", dtype=any_real_numpy_dtype)
  218:     )
  219:     tm.assert_frame_equal(result, expected)
  220: 
  221: 
  222: @pytest.mark.parametrize("how", ["idxmin", "idxmax"])
  223: def test_idxmin_idxmax_extremes_skipna(skipna, how, float_numpy_dtype):
  224:     # GH#57040
  225:     min_value = np.finfo(float_numpy_dtype).min
  226:     max_value = np.finfo(float_numpy_dtype).max
  227:     df = DataFrame(
  228:         {
  229:             "a": Series(np.repeat(range(1, 6), repeats=2), dtype="intp"),
  230:             "b": Series(
  231:                 [
  232:                     np.nan,
  233:                     min_value,
  234:                     np.nan,
  235:                     max_value,
  236:                     min_value,
  237:                     np.nan,
  238:                     max_value,
  239:                     np.nan,
  240:                     np.nan,
  241:                     np.nan,
  242:                 ],
  243:                 dtype=float_numpy_dtype,
  244:             ),
  245:         },
  246:     )
  247:     gb = df.groupby("a")
  248: 
  249:     warn = None if skipna else FutureWarning
  250:     msg = f"The behavior of DataFrameGroupBy.{how} with all-NA values"
  251:     with tm.assert_produces_warning(warn, match=msg):
  252:         result = getattr(gb, how)(skipna=skipna)
  253:     if skipna:
  254:         values = [1, 3, 4, 6, np.nan]
  255:     else:
  256:         values = np.nan
  257:     expected = DataFrame(
  258:         {"b": values}, index=pd.Index(range(1, 6), name="a", dtype="intp")
  259:     )
  260:     tm.assert_frame_equal(result, expected)
  261: 
  262: 
  263: @pytest.mark.parametrize(
  264:     "func, values",
  265:     [
  266:         ("idxmin", {"c_int": [0, 2], "c_float": [1, 3], "c_date": [1, 2]}),
  267:         ("idxmax", {"c_int": [1, 3], "c_float": [0, 2], "c_date": [0, 3]}),
  268:     ],
  269: )
  270: @pytest.mark.parametrize("numeric_only", [True, False])
  271: def test_idxmin_idxmax_returns_int_types(func, values, numeric_only):
  272:     # GH 25444
  273:     df = DataFrame(
  274:         {
  275:             "name": ["A", "A", "B", "B"],
  276:             "c_int": [1, 2, 3, 4],
  277:             "c_float": [4.02, 3.03, 2.04, 1.05],
  278:             "c_date": ["2019", "2018", "2016", "2017"],
  279:         }
  280:     )
  281:     df["c_date"] = pd.to_datetime(df["c_date"])
  282:     df["c_date_tz"] = df["c_date"].dt.tz_localize("US/Pacific")
  283:     df["c_timedelta"] = df["c_date"] - df["c_date"].iloc[0]
  284:     df["c_period"] = df["c_date"].dt.to_period("W")
  285:     df["c_Integer"] = df["c_int"].astype("Int64")
  286:     df["c_Floating"] = df["c_float"].astype("Float64")
  287: 
  288:     result = getattr(df.groupby("name"), func)(numeric_only=numeric_only)
  289: 
  290:     expected = DataFrame(values, index=pd.Index(["A", "B"], name="name"))
  291:     if numeric_only:
  292:         expected = expected.drop(columns=["c_date"])
  293:     else:
  294:         expected["c_date_tz"] = expected["c_date"]
  295:         expected["c_timedelta"] = expected["c_date"]
  296:         expected["c_period"] = expected["c_date"]
  297:     expected["c_Integer"] = expected["c_int"]
  298:     expected["c_Floating"] = expected["c_float"]
  299: 
  300:     tm.assert_frame_equal(result, expected)
  301: 
  302: 
  303: @pytest.mark.parametrize(
  304:     "data",
  305:     [
  306:         (
  307:             Timestamp("2011-01-15 12:50:28.502376"),
  308:             Timestamp("2011-01-20 12:50:28.593448"),
  309:         ),
  310:         (24650000000000001, 24650000000000002),
  311:     ],
  312: )
  313: @pytest.mark.parametrize("method", ["count", "min", "max", "first", "last"])
  314: def test_groupby_non_arithmetic_agg_int_like_precision(method, data):
  315:     # GH#6620, GH#9311
  316:     df = DataFrame({"a": [1, 1], "b": data})
  317: 
  318:     grouped = df.groupby("a")
  319:     result = getattr(grouped, method)()
  320:     if method == "count":
  321:         expected_value = 2
  322:     elif method == "first":
  323:         expected_value = data[0]
  324:     elif method == "last":
  325:         expected_value = data[1]
  326:     else:
  327:         expected_value = getattr(df["b"], method)()
  328:     expected = DataFrame({"b": [expected_value]}, index=pd.Index([1], name="a"))
  329: 
  330:     tm.assert_frame_equal(result, expected)
  331: 
  332: 
  333: @pytest.mark.parametrize("how", ["first", "last"])
  334: def test_first_last_skipna(any_real_nullable_dtype, sort, skipna, how):
  335:     # GH#57019
  336:     na_value = na_value_for_dtype(pandas_dtype(any_real_nullable_dtype))
  337:     df = DataFrame(
  338:         {
  339:             "a": [2, 1, 1, 2, 3, 3],
  340:             "b": [na_value, 3.0, na_value, 4.0, np.nan, np.nan],
  341:             "c": [na_value, 3.0, na_value, 4.0, np.nan, np.nan],
  342:         },
  343:         dtype=any_real_nullable_dtype,
  344:     )
  345:     gb = df.groupby("a", sort=sort)
  346:     method = getattr(gb, how)
  347:     result = method(skipna=skipna)
  348: 
  349:     ilocs = {
  350:         ("first", True): [3, 1, 4],
  351:         ("first", False): [0, 1, 4],
  352:         ("last", True): [3, 1, 5],
  353:         ("last", False): [3, 2, 5],
  354:     }[how, skipna]
  355:     expected = df.iloc[ilocs].set_index("a")
  356:     if sort:
  357:         expected = expected.sort_index()
  358:     tm.assert_frame_equal(result, expected)
  359: 
  360: 
  361: def test_idxmin_idxmax_axis1():
  362:     df = DataFrame(
  363:         np.random.default_rng(2).standard_normal((10, 4)), columns=["A", "B", "C", "D"]
  364:     )
  365:     df["A"] = [1, 2, 3, 1, 2, 3, 1, 2, 3, 4]
  366: 
  367:     gb = df.groupby("A")
  368: 
  369:     warn_msg = "DataFrameGroupBy.idxmax with axis=1 is deprecated"
  370:     with tm.assert_produces_warning(FutureWarning, match=warn_msg):
  371:         res = gb.idxmax(axis=1)
  372: 
  373:     alt = df.iloc[:, 1:].idxmax(axis=1)
  374:     indexer = res.index.get_level_values(1)
  375: 
  376:     tm.assert_series_equal(alt[indexer], res.droplevel("A"))
  377: 
  378:     df["E"] = date_range("2016-01-01", periods=10)
  379:     gb2 = df.groupby("A")
  380: 
  381:     msg = "'>' not supported between instances of 'Timestamp' and 'float'"
  382:     with pytest.raises(TypeError, match=msg):
  383:         with tm.assert_produces_warning(FutureWarning, match=warn_msg):
  384:             gb2.idxmax(axis=1)
  385: 
  386: 
  387: def test_groupby_mean_no_overflow():
  388:     # Regression test for (#22487)
  389:     df = DataFrame(
  390:         {
  391:             "user": ["A", "A", "A", "A", "A"],
  392:             "connections": [4970, 4749, 4719, 4704, 18446744073699999744],
  393:         }
  394:     )
  395:     assert df.groupby("user")["connections"].mean()["A"] == 3689348814740003840
  396: 
  397: 
  398: def test_mean_on_timedelta():
  399:     # GH 17382
  400:     df = DataFrame({"time": pd.to_timedelta(range(10)), "cat": ["A", "B"] * 5})
  401:     result = df.groupby("cat")["time"].mean()
  402:     expected = Series(
  403:         pd.to_timedelta([4, 5]), name="time", index=pd.Index(["A", "B"], name="cat")
  404:     )
  405:     tm.assert_series_equal(result, expected)
  406: 
  407: 
  408: def test_cython_median():
  409:     arr = np.random.default_rng(2).standard_normal(1000)
  410:     arr[::2] = np.nan
  411:     df = DataFrame(arr)
  412: 
  413:     labels = np.random.default_rng(2).integers(0, 50, size=1000).astype(float)
  414:     labels[::17] = np.nan
  415: 
  416:     result = df.groupby(labels).median()
  417:     msg = "using DataFrameGroupBy.median"
  418:     with tm.assert_produces_warning(FutureWarning, match=msg):
  419:         exp = df.groupby(labels).agg(np.nanmedian)
  420:     tm.assert_frame_equal(result, exp)
  421: 
  422:     df = DataFrame(np.random.default_rng(2).standard_normal((1000, 5)))
  423:     msg = "using DataFrameGroupBy.median"
  424:     with tm.assert_produces_warning(FutureWarning, match=msg):
  425:         rs = df.groupby(labels).agg(np.median)
  426:     xp = df.groupby(labels).median()
  427:     tm.assert_frame_equal(rs, xp)
  428: 
  429: 
  430: def test_median_empty_bins(observed):
  431:     df = DataFrame(np.random.default_rng(2).integers(0, 44, 500))
  432: 
  433:     grps = range(0, 55, 5)
  434:     bins = pd.cut(df[0], grps)
  435: 
  436:     result = df.groupby(bins, observed=observed).median()
  437:     expected = df.groupby(bins, observed=observed).agg(lambda x: x.median())
  438:     tm.assert_frame_equal(result, expected)
  439: 
  440: 
  441: def test_max_min_non_numeric():
  442:     # #2700
  443:     aa = DataFrame({"nn": [11, 11, 22, 22], "ii": [1, 2, 3, 4], "ss": 4 * ["mama"]})
  444: 
  445:     result = aa.groupby("nn").max()
  446:     assert "ss" in result
  447: 
  448:     result = aa.groupby("nn").max(numeric_only=False)
  449:     assert "ss" in result
  450: 
  451:     result = aa.groupby("nn").min()
  452:     assert "ss" in result
  453: 
  454:     result = aa.groupby("nn").min(numeric_only=False)
  455:     assert "ss" in result
  456: 
  457: 
  458: def test_max_min_object_multiple_columns(using_array_manager):
  459:     # GH#41111 case where the aggregation is valid for some columns but not
  460:     # others; we split object blocks column-wise, consistent with
  461:     # DataFrame._reduce
  462: 
  463:     df = DataFrame(
  464:         {
  465:             "A": [1, 1, 2, 2, 3],
  466:             "B": [1, "foo", 2, "bar", False],
  467:             "C": ["a", "b", "c", "d", "e"],
  468:         }
  469:     )
  470:     df._consolidate_inplace()  # should already be consolidate, but double-check
  471:     if not using_array_manager:
  472:         assert len(df._mgr.blocks) == 2
  473: 
  474:     gb = df.groupby("A")
  475: 
  476:     result = gb[["C"]].max()
  477:     # "max" is valid for column "C" but not for "B"
  478:     ei = pd.Index([1, 2, 3], name="A")
  479:     expected = DataFrame({"C": ["b", "d", "e"]}, index=ei)
  480:     tm.assert_frame_equal(result, expected)
  481: 
  482:     result = gb[["C"]].min()
  483:     # "min" is valid for column "C" but not for "B"
  484:     ei = pd.Index([1, 2, 3], name="A")
  485:     expected = DataFrame({"C": ["a", "c", "e"]}, index=ei)
  486:     tm.assert_frame_equal(result, expected)
  487: 
  488: 
  489: def test_min_date_with_nans():
  490:     # GH26321
  491:     dates = pd.to_datetime(
  492:         Series(["2019-05-09", "2019-05-09", "2019-05-09"]), format="%Y-%m-%d"
  493:     ).dt.date
  494:     df = DataFrame({"a": [np.nan, "1", np.nan], "b": [0, 1, 1], "c": dates})
  495: 
  496:     result = df.groupby("b", as_index=False)["c"].min()["c"]
  497:     expected = pd.to_datetime(
  498:         Series(["2019-05-09", "2019-05-09"], name="c"), format="%Y-%m-%d"
  499:     ).dt.date
  500:     tm.assert_series_equal(result, expected)
  501: 
  502:     result = df.groupby("b")["c"].min()
  503:     expected.index.name = "b"
  504:     tm.assert_series_equal(result, expected)
  505: 
  506: 
  507: def test_max_inat():
  508:     # GH#40767 dont interpret iNaT as NaN
  509:     ser = Series([1, iNaT])
  510:     key = np.array([1, 1], dtype=np.int64)
  511:     gb = ser.groupby(key)
  512: 
  513:     result = gb.max(min_count=2)
  514:     expected = Series({1: 1}, dtype=np.int64)
  515:     tm.assert_series_equal(result, expected, check_exact=True)
  516: 
  517:     result = gb.min(min_count=2)
  518:     expected = Series({1: iNaT}, dtype=np.int64)
  519:     tm.assert_series_equal(result, expected, check_exact=True)
  520: 
  521:     # not enough entries -> gets masked to NaN
  522:     result = gb.min(min_count=3)
  523:     expected = Series({1: np.nan})
  524:     tm.assert_series_equal(result, expected, check_exact=True)
  525: 
  526: 
  527: def test_max_inat_not_all_na():
  528:     # GH#40767 dont interpret iNaT as NaN
  529: 
  530:     # make sure we dont round iNaT+1 to iNaT
  531:     ser = Series([1, iNaT, 2, iNaT + 1])
  532:     gb = ser.groupby([1, 2, 3, 3])
  533:     result = gb.min(min_count=2)
  534: 
  535:     # Note: in converting to float64, the iNaT + 1 maps to iNaT, i.e. is lossy
  536:     expected = Series({1: np.nan, 2: np.nan, 3: iNaT + 1})
  537:     expected.index = expected.index.astype(int)
  538:     tm.assert_series_equal(result, expected, check_exact=True)
  539: 
  540: 
  541: @pytest.mark.parametrize("func", ["min", "max"])
  542: def test_groupby_aggregate_period_column(func):
  543:     # GH 31471
  544:     groups = [1, 2]
  545:     periods = pd.period_range("2020", periods=2, freq="Y")
  546:     df = DataFrame({"a": groups, "b": periods})
  547: 
  548:     result = getattr(df.groupby("a")["b"], func)()
  549:     idx = pd.Index([1, 2], name="a")
  550:     expected = Series(periods, index=idx, name="b")
  551: 
  552:     tm.assert_series_equal(result, expected)
  553: 
  554: 
  555: @pytest.mark.parametrize("func", ["min", "max"])
  556: def test_groupby_aggregate_period_frame(func):
  557:     # GH 31471
  558:     groups = [1, 2]
  559:     periods = pd.period_range("2020", periods=2, freq="Y")
  560:     df = DataFrame({"a": groups, "b": periods})
  561: 
  562:     result = getattr(df.groupby("a"), func)()
  563:     idx = pd.Index([1, 2], name="a")
  564:     expected = DataFrame({"b": periods}, index=idx)
  565: 
  566:     tm.assert_frame_equal(result, expected)
  567: 
  568: 
  569: def test_aggregate_numeric_object_dtype():
  570:     # https://github.com/pandas-dev/pandas/issues/39329
  571:     # simplified case: multiple object columns where one is all-NaN
  572:     # -> gets split as the all-NaN is inferred as float
  573:     df = DataFrame(
  574:         {"key": ["A", "A", "B", "B"], "col1": list("abcd"), "col2": [np.nan] * 4},
  575:     ).astype(object)
  576:     result = df.groupby("key").min()
  577:     expected = (
  578:         DataFrame(
  579:             {"key": ["A", "B"], "col1": ["a", "c"], "col2": [np.nan, np.nan]},
  580:         )
  581:         .set_index("key")
  582:         .astype(object)
  583:     )
  584:     tm.assert_frame_equal(result, expected)
  585: 
  586:     # same but with numbers
  587:     df = DataFrame(
  588:         {"key": ["A", "A", "B", "B"], "col1": list("abcd"), "col2": range(4)},
  589:     ).astype(object)
  590:     result = df.groupby("key").min()
  591:     expected = (
  592:         DataFrame({"key": ["A", "B"], "col1": ["a", "c"], "col2": [0, 2]})
  593:         .set_index("key")
  594:         .astype(object)
  595:     )
  596:     tm.assert_frame_equal(result, expected)
  597: 
  598: 
  599: @pytest.mark.parametrize("func", ["min", "max"])
  600: def test_aggregate_categorical_lost_index(func: str):
  601:     # GH: 28641 groupby drops index, when grouping over categorical column with min/max
  602:     ds = Series(["b"], dtype="category").cat.as_ordered()
  603:     df = DataFrame({"A": [1997], "B": ds})
  604:     result = df.groupby("A").agg({"B": func})
  605:     expected = DataFrame({"B": ["b"]}, index=pd.Index([1997], name="A"))
  606: 
  607:     # ordered categorical dtype should be preserved
  608:     expected["B"] = expected["B"].astype(ds.dtype)
  609: 
  610:     tm.assert_frame_equal(result, expected)
  611: 
  612: 
  613: @pytest.mark.parametrize("dtype", ["Int64", "Int32", "Float64", "Float32", "boolean"])
  614: def test_groupby_min_max_nullable(dtype):
  615:     if dtype == "Int64":
  616:         # GH#41743 avoid precision loss
  617:         ts = 1618556707013635762
  618:     elif dtype == "boolean":
  619:         ts = 0
  620:     else:
  621:         ts = 4.0
  622: 
  623:     df = DataFrame({"id": [2, 2], "ts": [ts, ts + 1]})
  624:     df["ts"] = df["ts"].astype(dtype)
  625: 
  626:     gb = df.groupby("id")
  627: 
  628:     result = gb.min()
  629:     expected = df.iloc[:1].set_index("id")
  630:     tm.assert_frame_equal(result, expected)
  631: 
  632:     res_max = gb.max()
  633:     expected_max = df.iloc[1:].set_index("id")
  634:     tm.assert_frame_equal(res_max, expected_max)
  635: 
  636:     result2 = gb.min(min_count=3)
  637:     expected2 = DataFrame({"ts": [pd.NA]}, index=expected.index, dtype=dtype)
  638:     tm.assert_frame_equal(result2, expected2)
  639: 
  640:     res_max2 = gb.max(min_count=3)
  641:     tm.assert_frame_equal(res_max2, expected2)
  642: 
  643:     # Case with NA values
  644:     df2 = DataFrame({"id": [2, 2, 2], "ts": [ts, pd.NA, ts + 1]})
  645:     df2["ts"] = df2["ts"].astype(dtype)
  646:     gb2 = df2.groupby("id")
  647: 
  648:     result3 = gb2.min()
  649:     tm.assert_frame_equal(result3, expected)
  650: 
  651:     res_max3 = gb2.max()
  652:     tm.assert_frame_equal(res_max3, expected_max)
  653: 
  654:     result4 = gb2.min(min_count=100)
  655:     tm.assert_frame_equal(result4, expected2)
  656: 
  657:     res_max4 = gb2.max(min_count=100)
  658:     tm.assert_frame_equal(res_max4, expected2)
  659: 
  660: 
  661: def test_min_max_nullable_uint64_empty_group():
  662:     # don't raise NotImplementedError from libgroupby
  663:     cat = pd.Categorical([0] * 10, categories=[0, 1])
  664:     df = DataFrame({"A": cat, "B": pd.array(np.arange(10, dtype=np.uint64))})
  665:     gb = df.groupby("A", observed=False)
  666: 
  667:     res = gb.min()
  668: 
  669:     idx = pd.CategoricalIndex([0, 1], dtype=cat.dtype, name="A")
  670:     expected = DataFrame({"B": pd.array([0, pd.NA], dtype="UInt64")}, index=idx)
  671:     tm.assert_frame_equal(res, expected)
  672: 
  673:     res = gb.max()
  674:     expected.iloc[0, 0] = 9
  675:     tm.assert_frame_equal(res, expected)
  676: 
  677: 
  678: @pytest.mark.parametrize("func", ["first", "last", "min", "max"])
  679: def test_groupby_min_max_categorical(func):
  680:     # GH: 52151
  681:     df = DataFrame(
  682:         {
  683:             "col1": pd.Categorical(["A"], categories=list("AB"), ordered=True),
  684:             "col2": pd.Categorical([1], categories=[1, 2], ordered=True),
  685:             "value": 0.1,
  686:         }
  687:     )
  688:     result = getattr(df.groupby("col1", observed=False), func)()
  689: 
  690:     idx = pd.CategoricalIndex(data=["A", "B"], name="col1", ordered=True)
  691:     expected = DataFrame(
  692:         {
  693:             "col2": pd.Categorical([1, None], categories=[1, 2], ordered=True),
  694:             "value": [0.1, None],
  695:         },
  696:         index=idx,
  697:     )
  698:     tm.assert_frame_equal(result, expected)
  699: 
  700: 
  701: @pytest.mark.parametrize("func", ["min", "max"])
  702: def test_min_empty_string_dtype(func):
  703:     # GH#55619
  704:     pytest.importorskip("pyarrow")
  705:     dtype = "string[pyarrow_numpy]"
  706:     df = DataFrame({"a": ["a"], "b": "a", "c": "a"}, dtype=dtype).iloc[:0]
  707:     result = getattr(df.groupby("a"), func)()
  708:     expected = DataFrame(
  709:         columns=["b", "c"], dtype=dtype, index=pd.Index([], dtype=dtype, name="a")
  710:     )
  711:     tm.assert_frame_equal(result, expected)
  712: 
  713: 
  714: def test_max_nan_bug():
  715:     df = DataFrame(
  716:         {
  717:             "Unnamed: 0": ["-04-23", "-05-06", "-05-07"],
  718:             "Date": [
  719:                 "2013-04-23 00:00:00",
  720:                 "2013-05-06 00:00:00",
  721:                 "2013-05-07 00:00:00",
  722:             ],
  723:             "app": Series([np.nan, np.nan, "OE"]),
  724:             "File": ["log080001.log", "log.log", "xlsx"],
  725:         }
  726:     )
  727:     gb = df.groupby("Date")
  728:     r = gb[["File"]].max()
  729:     e = gb["File"].max().to_frame()
  730:     tm.assert_frame_equal(r, e)
  731:     assert not r["File"].isna().any()
  732: 
  733: 
  734: @pytest.mark.slow
  735: @pytest.mark.parametrize("sort", [False, True])
  736: @pytest.mark.parametrize("dropna", [False, True])
  737: @pytest.mark.parametrize("as_index", [True, False])
  738: @pytest.mark.parametrize("with_nan", [True, False])
  739: @pytest.mark.parametrize("keys", [["joe"], ["joe", "jim"]])
  740: def test_series_groupby_nunique(sort, dropna, as_index, with_nan, keys):
  741:     n = 100
  742:     m = 10
  743:     days = date_range("2015-08-23", periods=10)
  744:     df = DataFrame(
  745:         {
  746:             "jim": np.random.default_rng(2).choice(list(ascii_lowercase), n),
  747:             "joe": np.random.default_rng(2).choice(days, n),
  748:             "julie": np.random.default_rng(2).integers(0, m, n),
  749:         }
  750:     )
  751:     if with_nan:
  752:         df = df.astype({"julie": float})  # Explicit cast to avoid implicit cast below
  753:         df.loc[1::17, "jim"] = None
  754:         df.loc[3::37, "joe"] = None
  755:         df.loc[7::19, "julie"] = None
  756:         df.loc[8::19, "julie"] = None
  757:         df.loc[9::19, "julie"] = None
  758:     original_df = df.copy()
  759:     gr = df.groupby(keys, as_index=as_index, sort=sort)
  760:     left = gr["julie"].nunique(dropna=dropna)
  761: 
  762:     gr = df.groupby(keys, as_index=as_index, sort=sort)
  763:     right = gr["julie"].apply(Series.nunique, dropna=dropna)
  764:     if not as_index:
  765:         right = right.reset_index(drop=True)
  766: 
  767:     if as_index:
  768:         tm.assert_series_equal(left, right, check_names=False)
  769:     else:
  770:         tm.assert_frame_equal(left, right, check_names=False)
  771:     tm.assert_frame_equal(df, original_df)
  772: 
  773: 
  774: def test_nunique():
  775:     df = DataFrame({"A": list("abbacc"), "B": list("abxacc"), "C": list("abbacx")})
  776: 
  777:     expected = DataFrame({"A": list("abc"), "B": [1, 2, 1], "C": [1, 1, 2]})
  778:     result = df.groupby("A", as_index=False).nunique()
  779:     tm.assert_frame_equal(result, expected)
  780: 
  781:     # as_index
  782:     expected.index = list("abc")
  783:     expected.index.name = "A"
  784:     expected = expected.drop(columns="A")
  785:     result = df.groupby("A").nunique()
  786:     tm.assert_frame_equal(result, expected)
  787: 
  788:     # with na
  789:     result = df.replace({"x": None}).groupby("A").nunique(dropna=False)
  790:     tm.assert_frame_equal(result, expected)
  791: 
  792:     # dropna
  793:     expected = DataFrame({"B": [1] * 3, "C": [1] * 3}, index=list("abc"))
  794:     expected.index.name = "A"
  795:     result = df.replace({"x": None}).groupby("A").nunique()
  796:     tm.assert_frame_equal(result, expected)
  797: 
  798: 
  799: def test_nunique_with_object():
  800:     # GH 11077
  801:     data = DataFrame(
  802:         [
  803:             [100, 1, "Alice"],
  804:             [200, 2, "Bob"],
  805:             [300, 3, "Charlie"],
  806:             [-400, 4, "Dan"],
  807:             [500, 5, "Edith"],
  808:         ],
  809:         columns=["amount", "id", "name"],
  810:     )
  811: 
  812:     result = data.groupby(["id", "amount"])["name"].nunique()
  813:     index = MultiIndex.from_arrays([data.id, data.amount])
  814:     expected = Series([1] * 5, name="name", index=index)
  815:     tm.assert_series_equal(result, expected)
  816: 
  817: 
  818: def test_nunique_with_empty_series():
  819:     # GH 12553
  820:     data = Series(name="name", dtype=object)
  821:     result = data.groupby(level=0).nunique()
  822:     expected = Series(name="name", dtype="int64")
  823:     tm.assert_series_equal(result, expected)
  824: 
  825: 
  826: def test_nunique_with_timegrouper():
  827:     # GH 13453
  828:     test = DataFrame(
  829:         {
  830:             "time": [
  831:                 Timestamp("2016-06-28 09:35:35"),
  832:                 Timestamp("2016-06-28 16:09:30"),
  833:                 Timestamp("2016-06-28 16:46:28"),
  834:             ],
  835:             "data": ["1", "2", "3"],
  836:         }
  837:     ).set_index("time")
  838:     result = test.groupby(pd.Grouper(freq="h"))["data"].nunique()
  839:     expected = test.groupby(pd.Grouper(freq="h"))["data"].apply(Series.nunique)
  840:     tm.assert_series_equal(result, expected)
  841: 
  842: 
  843: @pytest.mark.parametrize(
  844:     "key, data, dropna, expected",
  845:     [
  846:         (
  847:             ["x", "x", "x"],
  848:             [Timestamp("2019-01-01"), pd.NaT, Timestamp("2019-01-01")],
  849:             True,
  850:             Series([1], index=pd.Index(["x"], name="key"), name="data"),
  851:         ),
  852:         (
  853:             ["x", "x", "x"],
  854:             [dt.date(2019, 1, 1), pd.NaT, dt.date(2019, 1, 1)],
  855:             True,
  856:             Series([1], index=pd.Index(["x"], name="key"), name="data"),
  857:         ),
  858:         (
  859:             ["x", "x", "x", "y", "y"],
  860:             [
  861:                 dt.date(2019, 1, 1),
  862:                 pd.NaT,
  863:                 dt.date(2019, 1, 1),
  864:                 pd.NaT,
  865:                 dt.date(2019, 1, 1),
  866:             ],
  867:             False,
  868:             Series([2, 2], index=pd.Index(["x", "y"], name="key"), name="data"),
  869:         ),
  870:         (
  871:             ["x", "x", "x", "x", "y"],
  872:             [
  873:                 dt.date(2019, 1, 1),
  874:                 pd.NaT,
  875:                 dt.date(2019, 1, 1),
  876:                 pd.NaT,
  877:                 dt.date(2019, 1, 1),
  878:             ],
  879:             False,
  880:             Series([2, 1], index=pd.Index(["x", "y"], name="key"), name="data"),
  881:         ),
  882:     ],
  883: )
  884: def test_nunique_with_NaT(key, data, dropna, expected):
  885:     # GH 27951
  886:     df = DataFrame({"key": key, "data": data})
  887:     result = df.groupby(["key"])["data"].nunique(dropna=dropna)
  888:     tm.assert_series_equal(result, expected)
  889: 
  890: 
  891: def test_nunique_preserves_column_level_names():
  892:     # GH 23222
  893:     test = DataFrame([1, 2, 2], columns=pd.Index(["A"], name="level_0"))
  894:     result = test.groupby([0, 0, 0]).nunique()
  895:     expected = DataFrame([2], index=np.array([0]), columns=test.columns)
  896:     tm.assert_frame_equal(result, expected)
  897: 
  898: 
  899: def test_nunique_transform_with_datetime():
  900:     # GH 35109 - transform with nunique on datetimes results in integers
  901:     df = DataFrame(date_range("2008-12-31", "2009-01-02"), columns=["date"])
  902:     result = df.groupby([0, 0, 1])["date"].transform("nunique")
  903:     expected = Series([2, 2, 1], name="date")
  904:     tm.assert_series_equal(result, expected)
  905: 
  906: 
  907: def test_empty_categorical(observed):
  908:     # GH#21334
  909:     cat = Series([1]).astype("category")
  910:     ser = cat[:0]
  911:     gb = ser.groupby(ser, observed=observed)
  912:     result = gb.nunique()
  913:     if observed:
  914:         expected = Series([], index=cat[:0], dtype="int64")
  915:     else:
  916:         expected = Series([0], index=cat, dtype="int64")
  917:     tm.assert_series_equal(result, expected)
  918: 
  919: 
  920: def test_intercept_builtin_sum():
  921:     s = Series([1.0, 2.0, np.nan, 3.0])
  922:     grouped = s.groupby([0, 1, 2, 2])
  923: 
  924:     msg = "using SeriesGroupBy.sum"
  925:     with tm.assert_produces_warning(FutureWarning, match=msg):
  926:         # GH#53425
  927:         result = grouped.agg(builtins.sum)
  928:     msg = "using np.sum"
  929:     with tm.assert_produces_warning(FutureWarning, match=msg):
  930:         # GH#53425
  931:         result2 = grouped.apply(builtins.sum)
  932:     expected = grouped.sum()
  933:     tm.assert_series_equal(result, expected)
  934:     tm.assert_series_equal(result2, expected)
  935: 
  936: 
  937: @pytest.mark.parametrize("min_count", [0, 10])
  938: def test_groupby_sum_mincount_boolean(min_count):
  939:     b = True
  940:     a = False
  941:     na = np.nan
  942:     dfg = pd.array([b, b, na, na, a, a, b], dtype="boolean")
  943: 
  944:     df = DataFrame({"A": [1, 1, 2, 2, 3, 3, 1], "B": dfg})
  945:     result = df.groupby("A").sum(min_count=min_count)
  946:     if min_count == 0:
  947:         expected = DataFrame(
  948:             {"B": pd.array([3, 0, 0], dtype="Int64")},
  949:             index=pd.Index([1, 2, 3], name="A"),
  950:         )
  951:         tm.assert_frame_equal(result, expected)
  952:     else:
  953:         expected = DataFrame(
  954:             {"B": pd.array([pd.NA] * 3, dtype="Int64")},
  955:             index=pd.Index([1, 2, 3], name="A"),
  956:         )
  957:         tm.assert_frame_equal(result, expected)
  958: 
  959: 
  960: def test_groupby_sum_below_mincount_nullable_integer():
  961:     # https://github.com/pandas-dev/pandas/issues/32861
  962:     df = DataFrame({"a": [0, 1, 2], "b": [0, 1, 2], "c": [0, 1, 2]}, dtype="Int64")
  963:     grouped = df.groupby("a")
  964:     idx = pd.Index([0, 1, 2], name="a", dtype="Int64")
  965: 
  966:     result = grouped["b"].sum(min_count=2)
  967:     expected = Series([pd.NA] * 3, dtype="Int64", index=idx, name="b")
  968:     tm.assert_series_equal(result, expected)
  969: 
  970:     result = grouped.sum(min_count=2)
  971:     expected = DataFrame({"b": [pd.NA] * 3, "c": [pd.NA] * 3}, dtype="Int64", index=idx)
  972:     tm.assert_frame_equal(result, expected)
  973: 
  974: 
  975: def test_groupby_sum_timedelta_with_nat():
  976:     # GH#42659
  977:     df = DataFrame(
  978:         {
  979:             "a": [1, 1, 2, 2],
  980:             "b": [pd.Timedelta("1d"), pd.Timedelta("2d"), pd.Timedelta("3d"), pd.NaT],
  981:         }
  982:     )
  983:     td3 = pd.Timedelta(days=3)
  984: 
  985:     gb = df.groupby("a")
  986: 
  987:     res = gb.sum()
  988:     expected = DataFrame({"b": [td3, td3]}, index=pd.Index([1, 2], name="a"))
  989:     tm.assert_frame_equal(res, expected)
  990: 
  991:     res = gb["b"].sum()
  992:     tm.assert_series_equal(res, expected["b"])
  993: 
  994:     res = gb["b"].sum(min_count=2)
  995:     expected = Series([td3, pd.NaT], dtype="m8[ns]", name="b", index=expected.index)
  996:     tm.assert_series_equal(res, expected)
  997: 
  998: 
  999: @pytest.mark.parametrize(
 1000:     "dtype", ["int8", "int16", "int32", "int64", "float32", "float64", "uint64"]
 1001: )
 1002: @pytest.mark.parametrize(
 1003:     "method,data",
 1004:     [
 1005:         ("first", {"df": [{"a": 1, "b": 1}, {"a": 2, "b": 3}]}),
 1006:         ("last", {"df": [{"a": 1, "b": 2}, {"a": 2, "b": 4}]}),
 1007:         ("min", {"df": [{"a": 1, "b": 1}, {"a": 2, "b": 3}]}),
 1008:         ("max", {"df": [{"a": 1, "b": 2}, {"a": 2, "b": 4}]}),
 1009:         ("count", {"df": [{"a": 1, "b": 2}, {"a": 2, "b": 2}], "out_type": "int64"}),
 1010:     ],
 1011: )
 1012: def test_groupby_non_arithmetic_agg_types(dtype, method, data):
 1013:     # GH9311, GH6620
 1014:     df = DataFrame(
 1015:         [{"a": 1, "b": 1}, {"a": 1, "b": 2}, {"a": 2, "b": 3}, {"a": 2, "b": 4}]
 1016:     )
 1017: 
 1018:     df["b"] = df.b.astype(dtype)
 1019: 
 1020:     if "args" not in data:
 1021:         data["args"] = []
 1022: 
 1023:     if "out_type" in data:
 1024:         out_type = data["out_type"]
 1025:     else:
 1026:         out_type = dtype
 1027: 
 1028:     exp = data["df"]
 1029:     df_out = DataFrame(exp)
 1030: 
 1031:     df_out["b"] = df_out.b.astype(out_type)
 1032:     df_out.set_index("a", inplace=True)
 1033: 
 1034:     grpd = df.groupby("a")
 1035:     t = getattr(grpd, method)(*data["args"])
 1036:     tm.assert_frame_equal(t, df_out)
 1037: 
 1038: 
 1039: def scipy_sem(*args, **kwargs):
 1040:     from scipy.stats import sem
 1041: 
 1042:     return sem(*args, ddof=1, **kwargs)
 1043: 
 1044: 
 1045: @pytest.mark.parametrize(
 1046:     "op,targop",
 1047:     [
 1048:         ("mean", np.mean),
 1049:         ("median", np.median),
 1050:         ("std", np.std),
 1051:         ("var", np.var),
 1052:         ("sum", np.sum),
 1053:         ("prod", np.prod),
 1054:         ("min", np.min),
 1055:         ("max", np.max),
 1056:         ("first", lambda x: x.iloc[0]),
 1057:         ("last", lambda x: x.iloc[-1]),
 1058:         ("count", np.size),
 1059:         pytest.param("sem", scipy_sem, marks=td.skip_if_no("scipy")),
 1060:     ],
 1061: )
 1062: def test_ops_general(op, targop):
 1063:     df = DataFrame(np.random.default_rng(2).standard_normal(1000))
 1064:     labels = np.random.default_rng(2).integers(0, 50, size=1000).astype(float)
 1065: 
 1066:     result = getattr(df.groupby(labels), op)()
 1067:     warn = None if op in ("first", "last", "count", "sem") else FutureWarning
 1068:     msg = f"using DataFrameGroupBy.{op}"
 1069:     with tm.assert_produces_warning(warn, match=msg):
 1070:         expected = df.groupby(labels).agg(targop)
 1071:     tm.assert_frame_equal(result, expected)
 1072: 
 1073: 
 1074: @pytest.mark.parametrize(
 1075:     "values",
 1076:     [
 1077:         {
 1078:             "a": [1, 1, 1, 2, 2, 2, 3, 3, 3],
 1079:             "b": [1, pd.NA, 2, 1, pd.NA, 2, 1, pd.NA, 2],
 1080:         },
 1081:         {"a": [1, 1, 2, 2, 3, 3], "b": [1, 2, 1, 2, 1, 2]},
 1082:     ],
 1083: )
 1084: @pytest.mark.parametrize("function", ["mean", "median", "var"])
 1085: def test_apply_to_nullable_integer_returns_float(values, function):
 1086:     # https://github.com/pandas-dev/pandas/issues/32219
 1087:     output = 0.5 if function == "var" else 1.5
 1088:     arr = np.array([output] * 3, dtype=float)
 1089:     idx = pd.Index([1, 2, 3], name="a", dtype="Int64")
 1090:     expected = DataFrame({"b": arr}, index=idx).astype("Float64")
 1091: 
 1092:     groups = DataFrame(values, dtype="Int64").groupby("a")
 1093: 
 1094:     result = getattr(groups, function)()
 1095:     tm.assert_frame_equal(result, expected)
 1096: 
 1097:     result = groups.agg(function)
 1098:     tm.assert_frame_equal(result, expected)
 1099: 
 1100:     result = groups.agg([function])
 1101:     expected.columns = MultiIndex.from_tuples([("b", function)])
 1102:     tm.assert_frame_equal(result, expected)
 1103: 
 1104: 
 1105: @pytest.mark.parametrize(
 1106:     "op",
 1107:     [
 1108:         "sum",
 1109:         "prod",
 1110:         "min",
 1111:         "max",
 1112:         "median",
 1113:         "mean",
 1114:         "skew",
 1115:         "std",
 1116:         "var",
 1117:         "sem",
 1118:     ],
 1119: )
 1120: @pytest.mark.parametrize("axis", [0, 1])
 1121: @pytest.mark.parametrize("skipna", [True, False])
 1122: @pytest.mark.parametrize("sort", [True, False])
 1123: def test_regression_allowlist_methods(op, axis, skipna, sort):
 1124:     # GH6944
 1125:     # GH 17537
 1126:     # explicitly test the allowlist methods
 1127:     raw_frame = DataFrame([0])
 1128:     if axis == 0:
 1129:         frame = raw_frame
 1130:         msg = "The 'axis' keyword in DataFrame.groupby is deprecated and will be"
 1131:     else:
 1132:         frame = raw_frame.T
 1133:         msg = "DataFrame.groupby with axis=1 is deprecated"
 1134: 
 1135:     with tm.assert_produces_warning(FutureWarning, match=msg):
 1136:         grouped = frame.groupby(level=0, axis=axis, sort=sort)
 1137: 
 1138:     if op == "skew":
 1139:         # skew has skipna
 1140:         result = getattr(grouped, op)(skipna=skipna)
 1141:         expected = frame.groupby(level=0).apply(
 1142:             lambda h: getattr(h, op)(axis=axis, skipna=skipna)
 1143:         )
 1144:         if sort:
 1145:             expected = expected.sort_index(axis=axis)
 1146:         tm.assert_frame_equal(result, expected)
 1147:     else:
 1148:         result = getattr(grouped, op)()
 1149:         expected = frame.groupby(level=0).apply(lambda h: getattr(h, op)(axis=axis))
 1150:         if sort:
 1151:             expected = expected.sort_index(axis=axis)
 1152:         tm.assert_frame_equal(result, expected)
 1153: 
 1154: 
 1155: def test_groupby_prod_with_int64_dtype():
 1156:     # GH#46573
 1157:     data = [
 1158:         [1, 11],
 1159:         [1, 41],
 1160:         [1, 17],
 1161:         [1, 37],
 1162:         [1, 7],
 1163:         [1, 29],
 1164:         [1, 31],
 1165:         [1, 2],
 1166:         [1, 3],
 1167:         [1, 43],
 1168:         [1, 5],
 1169:         [1, 47],
 1170:         [1, 19],
 1171:         [1, 88],
 1172:     ]
 1173:     df = DataFrame(data, columns=["A", "B"], dtype="int64")
 1174:     result = df.groupby(["A"]).prod().reset_index()
 1175:     expected = DataFrame({"A": [1], "B": [180970905912331920]}, dtype="int64")
 1176:     tm.assert_frame_equal(result, expected)
