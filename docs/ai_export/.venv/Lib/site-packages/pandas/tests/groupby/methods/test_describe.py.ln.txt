    1: import numpy as np
    2: import pytest
    3: 
    4: import pandas as pd
    5: from pandas import (
    6:     DataFrame,
    7:     Index,
    8:     MultiIndex,
    9:     Series,
   10:     Timestamp,
   11:     date_range,
   12: )
   13: import pandas._testing as tm
   14: 
   15: 
   16: def test_apply_describe_bug(multiindex_dataframe_random_data):
   17:     grouped = multiindex_dataframe_random_data.groupby(level="first")
   18:     grouped.describe()  # it works!
   19: 
   20: 
   21: def test_series_describe_multikey():
   22:     ts = Series(
   23:         np.arange(10, dtype=np.float64), index=date_range("2020-01-01", periods=10)
   24:     )
   25:     grouped = ts.groupby([lambda x: x.year, lambda x: x.month])
   26:     result = grouped.describe()
   27:     tm.assert_series_equal(result["mean"], grouped.mean(), check_names=False)
   28:     tm.assert_series_equal(result["std"], grouped.std(), check_names=False)
   29:     tm.assert_series_equal(result["min"], grouped.min(), check_names=False)
   30: 
   31: 
   32: def test_series_describe_single():
   33:     ts = Series(
   34:         np.arange(10, dtype=np.float64), index=date_range("2020-01-01", periods=10)
   35:     )
   36:     grouped = ts.groupby(lambda x: x.month)
   37:     result = grouped.apply(lambda x: x.describe())
   38:     expected = grouped.describe().stack(future_stack=True)
   39:     tm.assert_series_equal(result, expected)
   40: 
   41: 
   42: @pytest.mark.parametrize("keys", ["key1", ["key1", "key2"]])
   43: def test_series_describe_as_index(as_index, keys):
   44:     # GH#49256
   45:     df = DataFrame(
   46:         {
   47:             "key1": ["one", "two", "two", "three", "two"],
   48:             "key2": ["one", "two", "two", "three", "two"],
   49:             "foo2": [1, 2, 4, 4, 6],
   50:         }
   51:     )
   52:     gb = df.groupby(keys, as_index=as_index)["foo2"]
   53:     result = gb.describe()
   54:     expected = DataFrame(
   55:         {
   56:             "key1": ["one", "three", "two"],
   57:             "count": [1.0, 1.0, 3.0],
   58:             "mean": [1.0, 4.0, 4.0],
   59:             "std": [np.nan, np.nan, 2.0],
   60:             "min": [1.0, 4.0, 2.0],
   61:             "25%": [1.0, 4.0, 3.0],
   62:             "50%": [1.0, 4.0, 4.0],
   63:             "75%": [1.0, 4.0, 5.0],
   64:             "max": [1.0, 4.0, 6.0],
   65:         }
   66:     )
   67:     if len(keys) == 2:
   68:         expected.insert(1, "key2", expected["key1"])
   69:     if as_index:
   70:         expected = expected.set_index(keys)
   71:     tm.assert_frame_equal(result, expected)
   72: 
   73: 
   74: def test_frame_describe_multikey(tsframe):
   75:     grouped = tsframe.groupby([lambda x: x.year, lambda x: x.month])
   76:     result = grouped.describe()
   77:     desc_groups = []
   78:     for col in tsframe:
   79:         group = grouped[col].describe()
   80:         # GH 17464 - Remove duplicate MultiIndex levels
   81:         group_col = MultiIndex(
   82:             levels=[[col], group.columns],
   83:             codes=[[0] * len(group.columns), range(len(group.columns))],
   84:         )
   85:         group = DataFrame(group.values, columns=group_col, index=group.index)
   86:         desc_groups.append(group)
   87:     expected = pd.concat(desc_groups, axis=1)
   88:     tm.assert_frame_equal(result, expected)
   89: 
   90:     msg = "DataFrame.groupby with axis=1 is deprecated"
   91:     with tm.assert_produces_warning(FutureWarning, match=msg):
   92:         groupedT = tsframe.groupby({"A": 0, "B": 0, "C": 1, "D": 1}, axis=1)
   93:     result = groupedT.describe()
   94:     expected = tsframe.describe().T
   95:     # reverting the change from https://github.com/pandas-dev/pandas/pull/35441/
   96:     expected.index = MultiIndex(
   97:         levels=[[0, 1], expected.index],
   98:         codes=[[0, 0, 1, 1], range(len(expected.index))],
   99:     )
  100:     tm.assert_frame_equal(result, expected)
  101: 
  102: 
  103: def test_frame_describe_tupleindex():
  104:     # GH 14848 - regression from 0.19.0 to 0.19.1
  105:     df1 = DataFrame(
  106:         {
  107:             "x": [1, 2, 3, 4, 5] * 3,
  108:             "y": [10, 20, 30, 40, 50] * 3,
  109:             "z": [100, 200, 300, 400, 500] * 3,
  110:         }
  111:     )
  112:     df1["k"] = [(0, 0, 1), (0, 1, 0), (1, 0, 0)] * 5
  113:     df2 = df1.rename(columns={"k": "key"})
  114:     msg = "Names should be list-like for a MultiIndex"
  115:     with pytest.raises(ValueError, match=msg):
  116:         df1.groupby("k").describe()
  117:     with pytest.raises(ValueError, match=msg):
  118:         df2.groupby("key").describe()
  119: 
  120: 
  121: def test_frame_describe_unstacked_format():
  122:     # GH 4792
  123:     prices = {
  124:         Timestamp("2011-01-06 10:59:05", tz=None): 24990,
  125:         Timestamp("2011-01-06 12:43:33", tz=None): 25499,
  126:         Timestamp("2011-01-06 12:54:09", tz=None): 25499,
  127:     }
  128:     volumes = {
  129:         Timestamp("2011-01-06 10:59:05", tz=None): 1500000000,
  130:         Timestamp("2011-01-06 12:43:33", tz=None): 5000000000,
  131:         Timestamp("2011-01-06 12:54:09", tz=None): 100000000,
  132:     }
  133:     df = DataFrame({"PRICE": prices, "VOLUME": volumes})
  134:     result = df.groupby("PRICE").VOLUME.describe()
  135:     data = [
  136:         df[df.PRICE == 24990].VOLUME.describe().values.tolist(),
  137:         df[df.PRICE == 25499].VOLUME.describe().values.tolist(),
  138:     ]
  139:     expected = DataFrame(
  140:         data,
  141:         index=Index([24990, 25499], name="PRICE"),
  142:         columns=["count", "mean", "std", "min", "25%", "50%", "75%", "max"],
  143:     )
  144:     tm.assert_frame_equal(result, expected)
  145: 
  146: 
  147: @pytest.mark.filterwarnings(
  148:     "ignore:"
  149:     "indexing past lexsort depth may impact performance:"
  150:     "pandas.errors.PerformanceWarning"
  151: )
  152: @pytest.mark.parametrize("as_index", [True, False])
  153: @pytest.mark.parametrize("keys", [["a1"], ["a1", "a2"]])
  154: def test_describe_with_duplicate_output_column_names(as_index, keys):
  155:     # GH 35314
  156:     df = DataFrame(
  157:         {
  158:             "a1": [99, 99, 99, 88, 88, 88],
  159:             "a2": [99, 99, 99, 88, 88, 88],
  160:             "b": [1, 2, 3, 4, 5, 6],
  161:             "c": [10, 20, 30, 40, 50, 60],
  162:         },
  163:         columns=["a1", "a2", "b", "b"],
  164:         copy=False,
  165:     )
  166:     if keys == ["a1"]:
  167:         df = df.drop(columns="a2")
  168: 
  169:     expected = (
  170:         DataFrame.from_records(
  171:             [
  172:                 ("b", "count", 3.0, 3.0),
  173:                 ("b", "mean", 5.0, 2.0),
  174:                 ("b", "std", 1.0, 1.0),
  175:                 ("b", "min", 4.0, 1.0),
  176:                 ("b", "25%", 4.5, 1.5),
  177:                 ("b", "50%", 5.0, 2.0),
  178:                 ("b", "75%", 5.5, 2.5),
  179:                 ("b", "max", 6.0, 3.0),
  180:                 ("b", "count", 3.0, 3.0),
  181:                 ("b", "mean", 5.0, 2.0),
  182:                 ("b", "std", 1.0, 1.0),
  183:                 ("b", "min", 4.0, 1.0),
  184:                 ("b", "25%", 4.5, 1.5),
  185:                 ("b", "50%", 5.0, 2.0),
  186:                 ("b", "75%", 5.5, 2.5),
  187:                 ("b", "max", 6.0, 3.0),
  188:             ],
  189:         )
  190:         .set_index([0, 1])
  191:         .T
  192:     )
  193:     expected.columns.names = [None, None]
  194:     if len(keys) == 2:
  195:         expected.index = MultiIndex(
  196:             levels=[[88, 99], [88, 99]], codes=[[0, 1], [0, 1]], names=["a1", "a2"]
  197:         )
  198:     else:
  199:         expected.index = Index([88, 99], name="a1")
  200: 
  201:     if not as_index:
  202:         expected = expected.reset_index()
  203: 
  204:     result = df.groupby(keys, as_index=as_index).describe()
  205: 
  206:     tm.assert_frame_equal(result, expected)
  207: 
  208: 
  209: def test_describe_duplicate_columns():
  210:     # GH#50806
  211:     df = DataFrame([[0, 1, 2, 3]])
  212:     df.columns = [0, 1, 2, 0]
  213:     gb = df.groupby(df[1])
  214:     result = gb.describe(percentiles=[])
  215: 
  216:     columns = ["count", "mean", "std", "min", "50%", "max"]
  217:     frames = [
  218:         DataFrame([[1.0, val, np.nan, val, val, val]], index=[1], columns=columns)
  219:         for val in (0.0, 2.0, 3.0)
  220:     ]
  221:     expected = pd.concat(frames, axis=1)
  222:     expected.columns = MultiIndex(
  223:         levels=[[0, 2], columns],
  224:         codes=[6 * [0] + 6 * [1] + 6 * [0], 3 * list(range(6))],
  225:     )
  226:     expected.index.names = [1]
  227:     tm.assert_frame_equal(result, expected)
  228: 
  229: 
  230: class TestGroupByNonCythonPaths:
  231:     # GH#5610 non-cython calls should not include the grouper
  232:     # Tests for code not expected to go through cython paths.
  233: 
  234:     @pytest.fixture
  235:     def df(self):
  236:         df = DataFrame(
  237:             [[1, 2, "foo"], [1, np.nan, "bar"], [3, np.nan, "baz"]],
  238:             columns=["A", "B", "C"],
  239:         )
  240:         return df
  241: 
  242:     @pytest.fixture
  243:     def gb(self, df):
  244:         gb = df.groupby("A")
  245:         return gb
  246: 
  247:     @pytest.fixture
  248:     def gni(self, df):
  249:         gni = df.groupby("A", as_index=False)
  250:         return gni
  251: 
  252:     def test_describe(self, df, gb, gni):
  253:         # describe
  254:         expected_index = Index([1, 3], name="A")
  255:         expected_col = MultiIndex(
  256:             levels=[["B"], ["count", "mean", "std", "min", "25%", "50%", "75%", "max"]],
  257:             codes=[[0] * 8, list(range(8))],
  258:         )
  259:         expected = DataFrame(
  260:             [
  261:                 [1.0, 2.0, np.nan, 2.0, 2.0, 2.0, 2.0, 2.0],
  262:                 [0.0, np.nan, np.nan, np.nan, np.nan, np.nan, np.nan, np.nan],
  263:             ],
  264:             index=expected_index,
  265:             columns=expected_col,
  266:         )
  267:         result = gb.describe()
  268:         tm.assert_frame_equal(result, expected)
  269: 
  270:         expected = expected.reset_index()
  271:         result = gni.describe()
  272:         tm.assert_frame_equal(result, expected)
  273: 
  274: 
  275: @pytest.mark.parametrize("dtype", [int, float, object])
  276: @pytest.mark.parametrize(
  277:     "kwargs",
  278:     [
  279:         {"percentiles": [0.10, 0.20, 0.30], "include": "all", "exclude": None},
  280:         {"percentiles": [0.10, 0.20, 0.30], "include": None, "exclude": ["int"]},
  281:         {"percentiles": [0.10, 0.20, 0.30], "include": ["int"], "exclude": None},
  282:     ],
  283: )
  284: def test_groupby_empty_dataset(dtype, kwargs):
  285:     # GH#41575
  286:     df = DataFrame([[1, 2, 3]], columns=["A", "B", "C"], dtype=dtype)
  287:     df["B"] = df["B"].astype(int)
  288:     df["C"] = df["C"].astype(float)
  289: 
  290:     result = df.iloc[:0].groupby("A").describe(**kwargs)
  291:     expected = df.groupby("A").describe(**kwargs).reset_index(drop=True).iloc[:0]
  292:     tm.assert_frame_equal(result, expected)
  293: 
  294:     result = df.iloc[:0].groupby("A").B.describe(**kwargs)
  295:     expected = df.groupby("A").B.describe(**kwargs).reset_index(drop=True).iloc[:0]
  296:     expected.index = Index([])
  297:     tm.assert_frame_equal(result, expected)
