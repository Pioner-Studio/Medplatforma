    1: from datetime import datetime
    2: 
    3: import numpy as np
    4: import pytest
    5: 
    6: import pandas as pd
    7: from pandas import (
    8:     Categorical,
    9:     CategoricalIndex,
   10:     DataFrame,
   11:     Index,
   12:     MultiIndex,
   13:     Series,
   14:     qcut,
   15: )
   16: import pandas._testing as tm
   17: from pandas.api.typing import SeriesGroupBy
   18: from pandas.tests.groupby import get_groupby_method_args
   19: 
   20: 
   21: def cartesian_product_for_groupers(result, args, names, fill_value=np.nan):
   22:     """Reindex to a cartesian production for the groupers,
   23:     preserving the nature (Categorical) of each grouper
   24:     """
   25: 
   26:     def f(a):
   27:         if isinstance(a, (CategoricalIndex, Categorical)):
   28:             categories = a.categories
   29:             a = Categorical.from_codes(
   30:                 np.arange(len(categories)), categories=categories, ordered=a.ordered
   31:             )
   32:         return a
   33: 
   34:     index = MultiIndex.from_product(map(f, args), names=names)
   35:     return result.reindex(index, fill_value=fill_value).sort_index()
   36: 
   37: 
   38: _results_for_groupbys_with_missing_categories = {
   39:     # This maps the builtin groupby functions to their expected outputs for
   40:     # missing categories when they are called on a categorical grouper with
   41:     # observed=False. Some functions are expected to return NaN, some zero.
   42:     # These expected values can be used across several tests (i.e. they are
   43:     # the same for SeriesGroupBy and DataFrameGroupBy) but they should only be
   44:     # hardcoded in one place.
   45:     "all": np.nan,
   46:     "any": np.nan,
   47:     "count": 0,
   48:     "corrwith": np.nan,
   49:     "first": np.nan,
   50:     "idxmax": np.nan,
   51:     "idxmin": np.nan,
   52:     "last": np.nan,
   53:     "max": np.nan,
   54:     "mean": np.nan,
   55:     "median": np.nan,
   56:     "min": np.nan,
   57:     "nth": np.nan,
   58:     "nunique": 0,
   59:     "prod": np.nan,
   60:     "quantile": np.nan,
   61:     "sem": np.nan,
   62:     "size": 0,
   63:     "skew": np.nan,
   64:     "std": np.nan,
   65:     "sum": 0,
   66:     "var": np.nan,
   67: }
   68: 
   69: 
   70: def test_apply_use_categorical_name(df):
   71:     cats = qcut(df.C, 4)
   72: 
   73:     def get_stats(group):
   74:         return {
   75:             "min": group.min(),
   76:             "max": group.max(),
   77:             "count": group.count(),
   78:             "mean": group.mean(),
   79:         }
   80: 
   81:     result = df.groupby(cats, observed=False).D.apply(get_stats)
   82:     assert result.index.names[0] == "C"
   83: 
   84: 
   85: def test_basic(using_infer_string):  # TODO: split this test
   86:     cats = Categorical(
   87:         ["a", "a", "a", "b", "b", "b", "c", "c", "c"],
   88:         categories=["a", "b", "c", "d"],
   89:         ordered=True,
   90:     )
   91:     data = DataFrame({"a": [1, 1, 1, 2, 2, 2, 3, 4, 5], "b": cats})
   92: 
   93:     exp_index = CategoricalIndex(list("abcd"), name="b", ordered=True)
   94:     expected = DataFrame({"a": [1, 2, 4, np.nan]}, index=exp_index)
   95:     result = data.groupby("b", observed=False).mean()
   96:     tm.assert_frame_equal(result, expected)
   97: 
   98:     cat1 = Categorical(["a", "a", "b", "b"], categories=["a", "b", "z"], ordered=True)
   99:     cat2 = Categorical(["c", "d", "c", "d"], categories=["c", "d", "y"], ordered=True)
  100:     df = DataFrame({"A": cat1, "B": cat2, "values": [1, 2, 3, 4]})
  101: 
  102:     # single grouper
  103:     gb = df.groupby("A", observed=False)
  104:     exp_idx = CategoricalIndex(["a", "b", "z"], name="A", ordered=True)
  105:     expected = DataFrame({"values": Series([3, 7, 0], index=exp_idx)})
  106:     result = gb.sum(numeric_only=True)
  107:     tm.assert_frame_equal(result, expected)
  108: 
  109:     # GH 8623
  110:     x = DataFrame(
  111:         [[1, "John P. Doe"], [2, "Jane Dove"], [1, "John P. Doe"]],
  112:         columns=["person_id", "person_name"],
  113:     )
  114:     x["person_name"] = Categorical(x.person_name)
  115: 
  116:     g = x.groupby(["person_id"], observed=False)
  117:     result = g.transform(lambda x: x)
  118:     tm.assert_frame_equal(result, x[["person_name"]])
  119: 
  120:     result = x.drop_duplicates("person_name")
  121:     expected = x.iloc[[0, 1]]
  122:     tm.assert_frame_equal(result, expected)
  123: 
  124:     def f(x):
  125:         return x.drop_duplicates("person_name").iloc[0]
  126: 
  127:     msg = "DataFrameGroupBy.apply operated on the grouping columns"
  128:     with tm.assert_produces_warning(DeprecationWarning, match=msg):
  129:         result = g.apply(f)
  130:     expected = x.iloc[[0, 1]].copy()
  131:     expected.index = Index([1, 2], name="person_id")
  132:     dtype = "string[pyarrow_numpy]" if using_infer_string else object
  133:     expected["person_name"] = expected["person_name"].astype(dtype)
  134:     tm.assert_frame_equal(result, expected)
  135: 
  136:     # GH 9921
  137:     # Monotonic
  138:     df = DataFrame({"a": [5, 15, 25]})
  139:     c = pd.cut(df.a, bins=[0, 10, 20, 30, 40])
  140: 
  141:     msg = "using SeriesGroupBy.sum"
  142:     with tm.assert_produces_warning(FutureWarning, match=msg):
  143:         # GH#53425
  144:         result = df.a.groupby(c, observed=False).transform(sum)
  145:     tm.assert_series_equal(result, df["a"])
  146: 
  147:     tm.assert_series_equal(
  148:         df.a.groupby(c, observed=False).transform(lambda xs: np.sum(xs)), df["a"]
  149:     )
  150:     msg = "using DataFrameGroupBy.sum"
  151:     with tm.assert_produces_warning(FutureWarning, match=msg):
  152:         # GH#53425
  153:         result = df.groupby(c, observed=False).transform(sum)
  154:     expected = df[["a"]]
  155:     tm.assert_frame_equal(result, expected)
  156: 
  157:     gbc = df.groupby(c, observed=False)
  158:     result = gbc.transform(lambda xs: np.max(xs, axis=0))
  159:     tm.assert_frame_equal(result, df[["a"]])
  160: 
  161:     result2 = gbc.transform(lambda xs: np.max(xs, axis=0))
  162:     msg = "using DataFrameGroupBy.max"
  163:     with tm.assert_produces_warning(FutureWarning, match=msg):
  164:         # GH#53425
  165:         result3 = gbc.transform(max)
  166:     result4 = gbc.transform(np.maximum.reduce)
  167:     result5 = gbc.transform(lambda xs: np.maximum.reduce(xs))
  168:     tm.assert_frame_equal(result2, df[["a"]], check_dtype=False)
  169:     tm.assert_frame_equal(result3, df[["a"]], check_dtype=False)
  170:     tm.assert_frame_equal(result4, df[["a"]])
  171:     tm.assert_frame_equal(result5, df[["a"]])
  172: 
  173:     # Filter
  174:     tm.assert_series_equal(df.a.groupby(c, observed=False).filter(np.all), df["a"])
  175:     tm.assert_frame_equal(df.groupby(c, observed=False).filter(np.all), df)
  176: 
  177:     # Non-monotonic
  178:     df = DataFrame({"a": [5, 15, 25, -5]})
  179:     c = pd.cut(df.a, bins=[-10, 0, 10, 20, 30, 40])
  180: 
  181:     msg = "using SeriesGroupBy.sum"
  182:     with tm.assert_produces_warning(FutureWarning, match=msg):
  183:         # GH#53425
  184:         result = df.a.groupby(c, observed=False).transform(sum)
  185:     tm.assert_series_equal(result, df["a"])
  186: 
  187:     tm.assert_series_equal(
  188:         df.a.groupby(c, observed=False).transform(lambda xs: np.sum(xs)), df["a"]
  189:     )
  190:     msg = "using DataFrameGroupBy.sum"
  191:     with tm.assert_produces_warning(FutureWarning, match=msg):
  192:         # GH#53425
  193:         result = df.groupby(c, observed=False).transform(sum)
  194:     expected = df[["a"]]
  195:     tm.assert_frame_equal(result, expected)
  196: 
  197:     tm.assert_frame_equal(
  198:         df.groupby(c, observed=False).transform(lambda xs: np.sum(xs)), df[["a"]]
  199:     )
  200: 
  201:     # GH 9603
  202:     df = DataFrame({"a": [1, 0, 0, 0]})
  203:     c = pd.cut(df.a, [0, 1, 2, 3, 4], labels=Categorical(list("abcd")))
  204:     result = df.groupby(c, observed=False).apply(len)
  205: 
  206:     exp_index = CategoricalIndex(c.values.categories, ordered=c.values.ordered)
  207:     expected = Series([1, 0, 0, 0], index=exp_index)
  208:     expected.index.name = "a"
  209:     tm.assert_series_equal(result, expected)
  210: 
  211:     # more basic
  212:     levels = ["foo", "bar", "baz", "qux"]
  213:     codes = np.random.default_rng(2).integers(0, 4, size=100)
  214: 
  215:     cats = Categorical.from_codes(codes, levels, ordered=True)
  216: 
  217:     data = DataFrame(np.random.default_rng(2).standard_normal((100, 4)))
  218: 
  219:     result = data.groupby(cats, observed=False).mean()
  220: 
  221:     expected = data.groupby(np.asarray(cats), observed=False).mean()
  222:     exp_idx = CategoricalIndex(levels, categories=cats.categories, ordered=True)
  223:     expected = expected.reindex(exp_idx)
  224: 
  225:     tm.assert_frame_equal(result, expected)
  226: 
  227:     grouped = data.groupby(cats, observed=False)
  228:     desc_result = grouped.describe()
  229: 
  230:     idx = cats.codes.argsort()
  231:     ord_labels = np.asarray(cats).take(idx)
  232:     ord_data = data.take(idx)
  233: 
  234:     exp_cats = Categorical(
  235:         ord_labels, ordered=True, categories=["foo", "bar", "baz", "qux"]
  236:     )
  237:     expected = ord_data.groupby(exp_cats, sort=False, observed=False).describe()
  238:     tm.assert_frame_equal(desc_result, expected)
  239: 
  240:     # GH 10460
  241:     expc = Categorical.from_codes(np.arange(4).repeat(8), levels, ordered=True)
  242:     exp = CategoricalIndex(expc)
  243:     tm.assert_index_equal(
  244:         (desc_result.stack(future_stack=True).index.get_level_values(0)), exp
  245:     )
  246:     exp = Index(["count", "mean", "std", "min", "25%", "50%", "75%", "max"] * 4)
  247:     tm.assert_index_equal(
  248:         (desc_result.stack(future_stack=True).index.get_level_values(1)), exp
  249:     )
  250: 
  251: 
  252: def test_level_get_group(observed):
  253:     # GH15155
  254:     df = DataFrame(
  255:         data=np.arange(2, 22, 2),
  256:         index=MultiIndex(
  257:             levels=[CategoricalIndex(["a", "b"]), range(10)],
  258:             codes=[[0] * 5 + [1] * 5, range(10)],
  259:             names=["Index1", "Index2"],
  260:         ),
  261:     )
  262:     g = df.groupby(level=["Index1"], observed=observed)
  263: 
  264:     # expected should equal test.loc[["a"]]
  265:     # GH15166
  266:     expected = DataFrame(
  267:         data=np.arange(2, 12, 2),
  268:         index=MultiIndex(
  269:             levels=[CategoricalIndex(["a", "b"]), range(5)],
  270:             codes=[[0] * 5, range(5)],
  271:             names=["Index1", "Index2"],
  272:         ),
  273:     )
  274:     msg = "you will need to pass a length-1 tuple"
  275:     with tm.assert_produces_warning(FutureWarning, match=msg):
  276:         # GH#25971 - warn when not passing a length-1 tuple
  277:         result = g.get_group("a")
  278: 
  279:     tm.assert_frame_equal(result, expected)
  280: 
  281: 
  282: def test_sorting_with_different_categoricals():
  283:     # GH 24271
  284:     df = DataFrame(
  285:         {
  286:             "group": ["A"] * 6 + ["B"] * 6,
  287:             "dose": ["high", "med", "low"] * 4,
  288:             "outcomes": np.arange(12.0),
  289:         }
  290:     )
  291: 
  292:     df.dose = Categorical(df.dose, categories=["low", "med", "high"], ordered=True)
  293: 
  294:     result = df.groupby("group")["dose"].value_counts()
  295:     result = result.sort_index(level=0, sort_remaining=True)
  296:     index = ["low", "med", "high", "low", "med", "high"]
  297:     index = Categorical(index, categories=["low", "med", "high"], ordered=True)
  298:     index = [["A", "A", "A", "B", "B", "B"], CategoricalIndex(index)]
  299:     index = MultiIndex.from_arrays(index, names=["group", "dose"])
  300:     expected = Series([2] * 6, index=index, name="count")
  301:     tm.assert_series_equal(result, expected)
  302: 
  303: 
  304: @pytest.mark.parametrize("ordered", [True, False])
  305: def test_apply(ordered):
  306:     # GH 10138
  307: 
  308:     dense = Categorical(list("abc"), ordered=ordered)
  309: 
  310:     # 'b' is in the categories but not in the list
  311:     missing = Categorical(list("aaa"), categories=["a", "b"], ordered=ordered)
  312:     values = np.arange(len(dense))
  313:     df = DataFrame({"missing": missing, "dense": dense, "values": values})
  314:     grouped = df.groupby(["missing", "dense"], observed=True)
  315: 
  316:     # missing category 'b' should still exist in the output index
  317:     idx = MultiIndex.from_arrays([missing, dense], names=["missing", "dense"])
  318:     expected = DataFrame([0, 1, 2.0], index=idx, columns=["values"])
  319: 
  320:     result = grouped.apply(lambda x: np.mean(x, axis=0))
  321:     tm.assert_frame_equal(result, expected)
  322: 
  323:     result = grouped.mean()
  324:     tm.assert_frame_equal(result, expected)
  325: 
  326:     msg = "using DataFrameGroupBy.mean"
  327:     with tm.assert_produces_warning(FutureWarning, match=msg):
  328:         # GH#53425
  329:         result = grouped.agg(np.mean)
  330:     tm.assert_frame_equal(result, expected)
  331: 
  332:     # but for transform we should still get back the original index
  333:     idx = MultiIndex.from_arrays([missing, dense], names=["missing", "dense"])
  334:     expected = Series(1, index=idx)
  335:     msg = "DataFrameGroupBy.apply operated on the grouping columns"
  336:     with tm.assert_produces_warning(DeprecationWarning, match=msg):
  337:         result = grouped.apply(lambda x: 1)
  338:     tm.assert_series_equal(result, expected)
  339: 
  340: 
  341: def test_observed(observed):
  342:     # multiple groupers, don't re-expand the output space
  343:     # of the grouper
  344:     # gh-14942 (implement)
  345:     # gh-10132 (back-compat)
  346:     # gh-8138 (back-compat)
  347:     # gh-8869
  348: 
  349:     cat1 = Categorical(["a", "a", "b", "b"], categories=["a", "b", "z"], ordered=True)
  350:     cat2 = Categorical(["c", "d", "c", "d"], categories=["c", "d", "y"], ordered=True)
  351:     df = DataFrame({"A": cat1, "B": cat2, "values": [1, 2, 3, 4]})
  352:     df["C"] = ["foo", "bar"] * 2
  353: 
  354:     # multiple groupers with a non-cat
  355:     gb = df.groupby(["A", "B", "C"], observed=observed)
  356:     exp_index = MultiIndex.from_arrays(
  357:         [cat1, cat2, ["foo", "bar"] * 2], names=["A", "B", "C"]
  358:     )
  359:     expected = DataFrame({"values": Series([1, 2, 3, 4], index=exp_index)}).sort_index()
  360:     result = gb.sum()
  361:     if not observed:
  362:         expected = cartesian_product_for_groupers(
  363:             expected, [cat1, cat2, ["foo", "bar"]], list("ABC"), fill_value=0
  364:         )
  365: 
  366:     tm.assert_frame_equal(result, expected)
  367: 
  368:     gb = df.groupby(["A", "B"], observed=observed)
  369:     exp_index = MultiIndex.from_arrays([cat1, cat2], names=["A", "B"])
  370:     expected = DataFrame(
  371:         {"values": [1, 2, 3, 4], "C": ["foo", "bar", "foo", "bar"]}, index=exp_index
  372:     )
  373:     result = gb.sum()
  374:     if not observed:
  375:         expected = cartesian_product_for_groupers(
  376:             expected, [cat1, cat2], list("AB"), fill_value=0
  377:         )
  378: 
  379:     tm.assert_frame_equal(result, expected)
  380: 
  381:     # https://github.com/pandas-dev/pandas/issues/8138
  382:     d = {
  383:         "cat": Categorical(
  384:             ["a", "b", "a", "b"], categories=["a", "b", "c"], ordered=True
  385:         ),
  386:         "ints": [1, 1, 2, 2],
  387:         "val": [10, 20, 30, 40],
  388:     }
  389:     df = DataFrame(d)
  390: 
  391:     # Grouping on a single column
  392:     groups_single_key = df.groupby("cat", observed=observed)
  393:     result = groups_single_key.mean()
  394: 
  395:     exp_index = CategoricalIndex(
  396:         list("ab"), name="cat", categories=list("abc"), ordered=True
  397:     )
  398:     expected = DataFrame({"ints": [1.5, 1.5], "val": [20.0, 30]}, index=exp_index)
  399:     if not observed:
  400:         index = CategoricalIndex(
  401:             list("abc"), name="cat", categories=list("abc"), ordered=True
  402:         )
  403:         expected = expected.reindex(index)
  404: 
  405:     tm.assert_frame_equal(result, expected)
  406: 
  407:     # Grouping on two columns
  408:     groups_double_key = df.groupby(["cat", "ints"], observed=observed)
  409:     result = groups_double_key.agg("mean")
  410:     expected = DataFrame(
  411:         {
  412:             "val": [10.0, 30.0, 20.0, 40.0],
  413:             "cat": Categorical(
  414:                 ["a", "a", "b", "b"], categories=["a", "b", "c"], ordered=True
  415:             ),
  416:             "ints": [1, 2, 1, 2],
  417:         }
  418:     ).set_index(["cat", "ints"])
  419:     if not observed:
  420:         expected = cartesian_product_for_groupers(
  421:             expected, [df.cat.values, [1, 2]], ["cat", "ints"]
  422:         )
  423: 
  424:     tm.assert_frame_equal(result, expected)
  425: 
  426:     # GH 10132
  427:     for key in [("a", 1), ("b", 2), ("b", 1), ("a", 2)]:
  428:         c, i = key
  429:         result = groups_double_key.get_group(key)
  430:         expected = df[(df.cat == c) & (df.ints == i)]
  431:         tm.assert_frame_equal(result, expected)
  432: 
  433:     # gh-8869
  434:     # with as_index
  435:     d = {
  436:         "foo": [10, 8, 4, 8, 4, 1, 1],
  437:         "bar": [10, 20, 30, 40, 50, 60, 70],
  438:         "baz": ["d", "c", "e", "a", "a", "d", "c"],
  439:     }
  440:     df = DataFrame(d)
  441:     cat = pd.cut(df["foo"], np.linspace(0, 10, 3))
  442:     df["range"] = cat
  443:     groups = df.groupby(["range", "baz"], as_index=False, observed=observed)
  444:     result = groups.agg("mean")
  445: 
  446:     groups2 = df.groupby(["range", "baz"], as_index=True, observed=observed)
  447:     expected = groups2.agg("mean").reset_index()
  448:     tm.assert_frame_equal(result, expected)
  449: 
  450: 
  451: def test_observed_codes_remap(observed):
  452:     d = {"C1": [3, 3, 4, 5], "C2": [1, 2, 3, 4], "C3": [10, 100, 200, 34]}
  453:     df = DataFrame(d)
  454:     values = pd.cut(df["C1"], [1, 2, 3, 6])
  455:     values.name = "cat"
  456:     groups_double_key = df.groupby([values, "C2"], observed=observed)
  457: 
  458:     idx = MultiIndex.from_arrays([values, [1, 2, 3, 4]], names=["cat", "C2"])
  459:     expected = DataFrame(
  460:         {"C1": [3.0, 3.0, 4.0, 5.0], "C3": [10.0, 100.0, 200.0, 34.0]}, index=idx
  461:     )
  462:     if not observed:
  463:         expected = cartesian_product_for_groupers(
  464:             expected, [values.values, [1, 2, 3, 4]], ["cat", "C2"]
  465:         )
  466: 
  467:     result = groups_double_key.agg("mean")
  468:     tm.assert_frame_equal(result, expected)
  469: 
  470: 
  471: def test_observed_perf():
  472:     # we create a cartesian product, so this is
  473:     # non-performant if we don't use observed values
  474:     # gh-14942
  475:     df = DataFrame(
  476:         {
  477:             "cat": np.random.default_rng(2).integers(0, 255, size=30000),
  478:             "int_id": np.random.default_rng(2).integers(0, 255, size=30000),
  479:             "other_id": np.random.default_rng(2).integers(0, 10000, size=30000),
  480:             "foo": 0,
  481:         }
  482:     )
  483:     df["cat"] = df.cat.astype(str).astype("category")
  484: 
  485:     grouped = df.groupby(["cat", "int_id", "other_id"], observed=True)
  486:     result = grouped.count()
  487:     assert result.index.levels[0].nunique() == df.cat.nunique()
  488:     assert result.index.levels[1].nunique() == df.int_id.nunique()
  489:     assert result.index.levels[2].nunique() == df.other_id.nunique()
  490: 
  491: 
  492: def test_observed_groups(observed):
  493:     # gh-20583
  494:     # test that we have the appropriate groups
  495: 
  496:     cat = Categorical(["a", "c", "a"], categories=["a", "b", "c"])
  497:     df = DataFrame({"cat": cat, "vals": [1, 2, 3]})
  498:     g = df.groupby("cat", observed=observed)
  499: 
  500:     result = g.groups
  501:     if observed:
  502:         expected = {"a": Index([0, 2], dtype="int64"), "c": Index([1], dtype="int64")}
  503:     else:
  504:         expected = {
  505:             "a": Index([0, 2], dtype="int64"),
  506:             "b": Index([], dtype="int64"),
  507:             "c": Index([1], dtype="int64"),
  508:         }
  509: 
  510:     tm.assert_dict_equal(result, expected)
  511: 
  512: 
  513: @pytest.mark.parametrize(
  514:     "keys, expected_values, expected_index_levels",
  515:     [
  516:         ("a", [15, 9, 0], CategoricalIndex([1, 2, 3], name="a")),
  517:         (
  518:             ["a", "b"],
  519:             [7, 8, 0, 0, 0, 9, 0, 0, 0],
  520:             [CategoricalIndex([1, 2, 3], name="a"), Index([4, 5, 6])],
  521:         ),
  522:         (
  523:             ["a", "a2"],
  524:             [15, 0, 0, 0, 9, 0, 0, 0, 0],
  525:             [
  526:                 CategoricalIndex([1, 2, 3], name="a"),
  527:                 CategoricalIndex([1, 2, 3], name="a"),
  528:             ],
  529:         ),
  530:     ],
  531: )
  532: @pytest.mark.parametrize("test_series", [True, False])
  533: def test_unobserved_in_index(keys, expected_values, expected_index_levels, test_series):
  534:     # GH#49354 - ensure unobserved cats occur when grouping by index levels
  535:     df = DataFrame(
  536:         {
  537:             "a": Categorical([1, 1, 2], categories=[1, 2, 3]),
  538:             "a2": Categorical([1, 1, 2], categories=[1, 2, 3]),
  539:             "b": [4, 5, 6],
  540:             "c": [7, 8, 9],
  541:         }
  542:     ).set_index(["a", "a2"])
  543:     if "b" not in keys:
  544:         # Only keep b when it is used for grouping for consistent columns in the result
  545:         df = df.drop(columns="b")
  546: 
  547:     gb = df.groupby(keys, observed=False)
  548:     if test_series:
  549:         gb = gb["c"]
  550:     result = gb.sum()
  551: 
  552:     if len(keys) == 1:
  553:         index = expected_index_levels
  554:     else:
  555:         codes = [[0, 0, 0, 1, 1, 1, 2, 2, 2], 3 * [0, 1, 2]]
  556:         index = MultiIndex(
  557:             expected_index_levels,
  558:             codes=codes,
  559:             names=keys,
  560:         )
  561:     expected = DataFrame({"c": expected_values}, index=index)
  562:     if test_series:
  563:         expected = expected["c"]
  564:     tm.assert_equal(result, expected)
  565: 
  566: 
  567: def test_observed_groups_with_nan(observed):
  568:     # GH 24740
  569:     df = DataFrame(
  570:         {
  571:             "cat": Categorical(["a", np.nan, "a"], categories=["a", "b", "d"]),
  572:             "vals": [1, 2, 3],
  573:         }
  574:     )
  575:     g = df.groupby("cat", observed=observed)
  576:     result = g.groups
  577:     if observed:
  578:         expected = {"a": Index([0, 2], dtype="int64")}
  579:     else:
  580:         expected = {
  581:             "a": Index([0, 2], dtype="int64"),
  582:             "b": Index([], dtype="int64"),
  583:             "d": Index([], dtype="int64"),
  584:         }
  585:     tm.assert_dict_equal(result, expected)
  586: 
  587: 
  588: def test_observed_nth():
  589:     # GH 26385
  590:     cat = Categorical(["a", np.nan, np.nan], categories=["a", "b", "c"])
  591:     ser = Series([1, 2, 3])
  592:     df = DataFrame({"cat": cat, "ser": ser})
  593: 
  594:     result = df.groupby("cat", observed=False)["ser"].nth(0)
  595:     expected = df["ser"].iloc[[0]]
  596:     tm.assert_series_equal(result, expected)
  597: 
  598: 
  599: def test_dataframe_categorical_with_nan(observed):
  600:     # GH 21151
  601:     s1 = Categorical([np.nan, "a", np.nan, "a"], categories=["a", "b", "c"])
  602:     s2 = Series([1, 2, 3, 4])
  603:     df = DataFrame({"s1": s1, "s2": s2})
  604:     result = df.groupby("s1", observed=observed).first().reset_index()
  605:     if observed:
  606:         expected = DataFrame(
  607:             {"s1": Categorical(["a"], categories=["a", "b", "c"]), "s2": [2]}
  608:         )
  609:     else:
  610:         expected = DataFrame(
  611:             {
  612:                 "s1": Categorical(["a", "b", "c"], categories=["a", "b", "c"]),
  613:                 "s2": [2, np.nan, np.nan],
  614:             }
  615:         )
  616:     tm.assert_frame_equal(result, expected)
  617: 
  618: 
  619: @pytest.mark.parametrize("ordered", [True, False])
  620: @pytest.mark.parametrize("observed", [True, False])
  621: @pytest.mark.parametrize("sort", [True, False])
  622: def test_dataframe_categorical_ordered_observed_sort(ordered, observed, sort):
  623:     # GH 25871: Fix groupby sorting on ordered Categoricals
  624:     # GH 25167: Groupby with observed=True doesn't sort
  625: 
  626:     # Build a dataframe with cat having one unobserved category ('missing'),
  627:     # and a Series with identical values
  628:     label = Categorical(
  629:         ["d", "a", "b", "a", "d", "b"],
  630:         categories=["a", "b", "missing", "d"],
  631:         ordered=ordered,
  632:     )
  633:     val = Series(["d", "a", "b", "a", "d", "b"])
  634:     df = DataFrame({"label": label, "val": val})
  635: 
  636:     # aggregate on the Categorical
  637:     result = df.groupby("label", observed=observed, sort=sort)["val"].aggregate("first")
  638: 
  639:     # If ordering works, we expect index labels equal to aggregation results,
  640:     # except for 'observed=False': label 'missing' has aggregation None
  641:     label = Series(result.index.array, dtype="object")
  642:     aggr = Series(result.array)
  643:     if not observed:
  644:         aggr[aggr.isna()] = "missing"
  645:     if not all(label == aggr):
  646:         msg = (
  647:             "Labels and aggregation results not consistently sorted\n"
  648:             f"for (ordered={ordered}, observed={observed}, sort={sort})\n"
  649:             f"Result:\n{result}"
  650:         )
  651:         assert False, msg
  652: 
  653: 
  654: def test_datetime():
  655:     # GH9049: ensure backward compatibility
  656:     levels = pd.date_range("2014-01-01", periods=4)
  657:     codes = np.random.default_rng(2).integers(0, 4, size=100)
  658: 
  659:     cats = Categorical.from_codes(codes, levels, ordered=True)
  660: 
  661:     data = DataFrame(np.random.default_rng(2).standard_normal((100, 4)))
  662:     result = data.groupby(cats, observed=False).mean()
  663: 
  664:     expected = data.groupby(np.asarray(cats), observed=False).mean()
  665:     expected = expected.reindex(levels)
  666:     expected.index = CategoricalIndex(
  667:         expected.index, categories=expected.index, ordered=True
  668:     )
  669: 
  670:     tm.assert_frame_equal(result, expected)
  671: 
  672:     grouped = data.groupby(cats, observed=False)
  673:     desc_result = grouped.describe()
  674: 
  675:     idx = cats.codes.argsort()
  676:     ord_labels = cats.take(idx)
  677:     ord_data = data.take(idx)
  678:     expected = ord_data.groupby(ord_labels, observed=False).describe()
  679:     tm.assert_frame_equal(desc_result, expected)
  680:     tm.assert_index_equal(desc_result.index, expected.index)
  681:     tm.assert_index_equal(
  682:         desc_result.index.get_level_values(0), expected.index.get_level_values(0)
  683:     )
  684: 
  685:     # GH 10460
  686:     expc = Categorical.from_codes(np.arange(4).repeat(8), levels, ordered=True)
  687:     exp = CategoricalIndex(expc)
  688:     tm.assert_index_equal(
  689:         (desc_result.stack(future_stack=True).index.get_level_values(0)), exp
  690:     )
  691:     exp = Index(["count", "mean", "std", "min", "25%", "50%", "75%", "max"] * 4)
  692:     tm.assert_index_equal(
  693:         (desc_result.stack(future_stack=True).index.get_level_values(1)), exp
  694:     )
  695: 
  696: 
  697: def test_categorical_index():
  698:     s = np.random.default_rng(2)
  699:     levels = ["foo", "bar", "baz", "qux"]
  700:     codes = s.integers(0, 4, size=20)
  701:     cats = Categorical.from_codes(codes, levels, ordered=True)
  702:     df = DataFrame(np.repeat(np.arange(20), 4).reshape(-1, 4), columns=list("abcd"))
  703:     df["cats"] = cats
  704: 
  705:     # with a cat index
  706:     result = df.set_index("cats").groupby(level=0, observed=False).sum()
  707:     expected = df[list("abcd")].groupby(cats.codes, observed=False).sum()
  708:     expected.index = CategoricalIndex(
  709:         Categorical.from_codes([0, 1, 2, 3], levels, ordered=True), name="cats"
  710:     )
  711:     tm.assert_frame_equal(result, expected)
  712: 
  713:     # with a cat column, should produce a cat index
  714:     result = df.groupby("cats", observed=False).sum()
  715:     expected = df[list("abcd")].groupby(cats.codes, observed=False).sum()
  716:     expected.index = CategoricalIndex(
  717:         Categorical.from_codes([0, 1, 2, 3], levels, ordered=True), name="cats"
  718:     )
  719:     tm.assert_frame_equal(result, expected)
  720: 
  721: 
  722: def test_describe_categorical_columns():
  723:     # GH 11558
  724:     cats = CategoricalIndex(
  725:         ["qux", "foo", "baz", "bar"],
  726:         categories=["foo", "bar", "baz", "qux"],
  727:         ordered=True,
  728:     )
  729:     df = DataFrame(np.random.default_rng(2).standard_normal((20, 4)), columns=cats)
  730:     result = df.groupby([1, 2, 3, 4] * 5).describe()
  731: 
  732:     tm.assert_index_equal(result.stack(future_stack=True).columns, cats)
  733:     tm.assert_categorical_equal(
  734:         result.stack(future_stack=True).columns.values, cats.values
  735:     )
  736: 
  737: 
  738: def test_unstack_categorical():
  739:     # GH11558 (example is taken from the original issue)
  740:     df = DataFrame(
  741:         {"a": range(10), "medium": ["A", "B"] * 5, "artist": list("XYXXY") * 2}
  742:     )
  743:     df["medium"] = df["medium"].astype("category")
  744: 
  745:     gcat = df.groupby(["artist", "medium"], observed=False)["a"].count().unstack()
  746:     result = gcat.describe()
  747: 
  748:     exp_columns = CategoricalIndex(["A", "B"], ordered=False, name="medium")
  749:     tm.assert_index_equal(result.columns, exp_columns)
  750:     tm.assert_categorical_equal(result.columns.values, exp_columns.values)
  751: 
  752:     result = gcat["A"] + gcat["B"]
  753:     expected = Series([6, 4], index=Index(["X", "Y"], name="artist"))
  754:     tm.assert_series_equal(result, expected)
  755: 
  756: 
  757: def test_bins_unequal_len():
  758:     # GH3011
  759:     series = Series([np.nan, np.nan, 1, 1, 2, 2, 3, 3, 4, 4])
  760:     bins = pd.cut(series.dropna().values, 4)
  761: 
  762:     # len(bins) != len(series) here
  763:     with pytest.raises(ValueError, match="Grouper and axis must be same length"):
  764:         series.groupby(bins).mean()
  765: 
  766: 
  767: @pytest.mark.parametrize(
  768:     ["series", "data"],
  769:     [
  770:         # Group a series with length and index equal to those of the grouper.
  771:         (Series(range(4)), {"A": [0, 3], "B": [1, 2]}),
  772:         # Group a series with length equal to that of the grouper and index unequal to
  773:         # that of the grouper.
  774:         (Series(range(4)).rename(lambda idx: idx + 1), {"A": [2], "B": [0, 1]}),
  775:         # GH44179: Group a series with length unequal to that of the grouper.
  776:         (Series(range(7)), {"A": [0, 3], "B": [1, 2]}),
  777:     ],
  778: )
  779: def test_categorical_series(series, data):
  780:     # Group the given series by a series with categorical data type such that group A
  781:     # takes indices 0 and 3 and group B indices 1 and 2, obtaining the values mapped in
  782:     # the given data.
  783:     groupby = series.groupby(Series(list("ABBA"), dtype="category"), observed=False)
  784:     result = groupby.aggregate(list)
  785:     expected = Series(data, index=CategoricalIndex(data.keys()))
  786:     tm.assert_series_equal(result, expected)
  787: 
  788: 
  789: def test_as_index():
  790:     # GH13204
  791:     df = DataFrame(
  792:         {
  793:             "cat": Categorical([1, 2, 2], [1, 2, 3]),
  794:             "A": [10, 11, 11],
  795:             "B": [101, 102, 103],
  796:         }
  797:     )
  798:     result = df.groupby(["cat", "A"], as_index=False, observed=True).sum()
  799:     expected = DataFrame(
  800:         {
  801:             "cat": Categorical([1, 2], categories=df.cat.cat.categories),
  802:             "A": [10, 11],
  803:             "B": [101, 205],
  804:         },
  805:         columns=["cat", "A", "B"],
  806:     )
  807:     tm.assert_frame_equal(result, expected)
  808: 
  809:     # function grouper
  810:     f = lambda r: df.loc[r, "A"]
  811:     msg = "A grouping .* was excluded from the result"
  812:     with tm.assert_produces_warning(FutureWarning, match=msg):
  813:         result = df.groupby(["cat", f], as_index=False, observed=True).sum()
  814:     expected = DataFrame(
  815:         {
  816:             "cat": Categorical([1, 2], categories=df.cat.cat.categories),
  817:             "A": [10, 22],
  818:             "B": [101, 205],
  819:         },
  820:         columns=["cat", "A", "B"],
  821:     )
  822:     tm.assert_frame_equal(result, expected)
  823: 
  824:     # another not in-axis grouper (conflicting names in index)
  825:     s = Series(["a", "b", "b"], name="cat")
  826:     msg = "A grouping .* was excluded from the result"
  827:     with tm.assert_produces_warning(FutureWarning, match=msg):
  828:         result = df.groupby(["cat", s], as_index=False, observed=True).sum()
  829:     tm.assert_frame_equal(result, expected)
  830: 
  831:     # is original index dropped?
  832:     group_columns = ["cat", "A"]
  833:     expected = DataFrame(
  834:         {
  835:             "cat": Categorical([1, 2], categories=df.cat.cat.categories),
  836:             "A": [10, 11],
  837:             "B": [101, 205],
  838:         },
  839:         columns=["cat", "A", "B"],
  840:     )
  841: 
  842:     for name in [None, "X", "B"]:
  843:         df.index = Index(list("abc"), name=name)
  844:         result = df.groupby(group_columns, as_index=False, observed=True).sum()
  845: 
  846:         tm.assert_frame_equal(result, expected)
  847: 
  848: 
  849: def test_preserve_categories():
  850:     # GH-13179
  851:     categories = list("abc")
  852: 
  853:     # ordered=True
  854:     df = DataFrame({"A": Categorical(list("ba"), categories=categories, ordered=True)})
  855:     sort_index = CategoricalIndex(categories, categories, ordered=True, name="A")
  856:     nosort_index = CategoricalIndex(list("bac"), categories, ordered=True, name="A")
  857:     tm.assert_index_equal(
  858:         df.groupby("A", sort=True, observed=False).first().index, sort_index
  859:     )
  860:     # GH#42482 - don't sort result when sort=False, even when ordered=True
  861:     tm.assert_index_equal(
  862:         df.groupby("A", sort=False, observed=False).first().index, nosort_index
  863:     )
  864: 
  865:     # ordered=False
  866:     df = DataFrame({"A": Categorical(list("ba"), categories=categories, ordered=False)})
  867:     sort_index = CategoricalIndex(categories, categories, ordered=False, name="A")
  868:     # GH#48749 - don't change order of categories
  869:     # GH#42482 - don't sort result when sort=False, even when ordered=True
  870:     nosort_index = CategoricalIndex(list("bac"), list("abc"), ordered=False, name="A")
  871:     tm.assert_index_equal(
  872:         df.groupby("A", sort=True, observed=False).first().index, sort_index
  873:     )
  874:     tm.assert_index_equal(
  875:         df.groupby("A", sort=False, observed=False).first().index, nosort_index
  876:     )
  877: 
  878: 
  879: def test_preserve_categorical_dtype():
  880:     # GH13743, GH13854
  881:     df = DataFrame(
  882:         {
  883:             "A": [1, 2, 1, 1, 2],
  884:             "B": [10, 16, 22, 28, 34],
  885:             "C1": Categorical(list("abaab"), categories=list("bac"), ordered=False),
  886:             "C2": Categorical(list("abaab"), categories=list("bac"), ordered=True),
  887:         }
  888:     )
  889:     # single grouper
  890:     exp_full = DataFrame(
  891:         {
  892:             "A": [2.0, 1.0, np.nan],
  893:             "B": [25.0, 20.0, np.nan],
  894:             "C1": Categorical(list("bac"), categories=list("bac"), ordered=False),
  895:             "C2": Categorical(list("bac"), categories=list("bac"), ordered=True),
  896:         }
  897:     )
  898:     for col in ["C1", "C2"]:
  899:         result1 = df.groupby(by=col, as_index=False, observed=False).mean(
  900:             numeric_only=True
  901:         )
  902:         result2 = (
  903:             df.groupby(by=col, as_index=True, observed=False)
  904:             .mean(numeric_only=True)
  905:             .reset_index()
  906:         )
  907:         expected = exp_full.reindex(columns=result1.columns)
  908:         tm.assert_frame_equal(result1, expected)
  909:         tm.assert_frame_equal(result2, expected)
  910: 
  911: 
  912: @pytest.mark.parametrize(
  913:     "func, values",
  914:     [
  915:         ("first", ["second", "first"]),
  916:         ("last", ["fourth", "third"]),
  917:         ("min", ["fourth", "first"]),
  918:         ("max", ["second", "third"]),
  919:     ],
  920: )
  921: def test_preserve_on_ordered_ops(func, values):
  922:     # gh-18502
  923:     # preserve the categoricals on ops
  924:     c = Categorical(["first", "second", "third", "fourth"], ordered=True)
  925:     df = DataFrame({"payload": [-1, -2, -1, -2], "col": c})
  926:     g = df.groupby("payload")
  927:     result = getattr(g, func)()
  928:     expected = DataFrame(
  929:         {"payload": [-2, -1], "col": Series(values, dtype=c.dtype)}
  930:     ).set_index("payload")
  931:     tm.assert_frame_equal(result, expected)
  932: 
  933:     # we should also preserve categorical for SeriesGroupBy
  934:     sgb = df.groupby("payload")["col"]
  935:     result = getattr(sgb, func)()
  936:     expected = expected["col"]
  937:     tm.assert_series_equal(result, expected)
  938: 
  939: 
  940: def test_categorical_no_compress():
  941:     data = Series(np.random.default_rng(2).standard_normal(9))
  942: 
  943:     codes = np.array([0, 0, 0, 1, 1, 1, 2, 2, 2])
  944:     cats = Categorical.from_codes(codes, [0, 1, 2], ordered=True)
  945: 
  946:     result = data.groupby(cats, observed=False).mean()
  947:     exp = data.groupby(codes, observed=False).mean()
  948: 
  949:     exp.index = CategoricalIndex(
  950:         exp.index, categories=cats.categories, ordered=cats.ordered
  951:     )
  952:     tm.assert_series_equal(result, exp)
  953: 
  954:     codes = np.array([0, 0, 0, 1, 1, 1, 3, 3, 3])
  955:     cats = Categorical.from_codes(codes, [0, 1, 2, 3], ordered=True)
  956: 
  957:     result = data.groupby(cats, observed=False).mean()
  958:     exp = data.groupby(codes, observed=False).mean().reindex(cats.categories)
  959:     exp.index = CategoricalIndex(
  960:         exp.index, categories=cats.categories, ordered=cats.ordered
  961:     )
  962:     tm.assert_series_equal(result, exp)
  963: 
  964:     cats = Categorical(
  965:         ["a", "a", "a", "b", "b", "b", "c", "c", "c"],
  966:         categories=["a", "b", "c", "d"],
  967:         ordered=True,
  968:     )
  969:     data = DataFrame({"a": [1, 1, 1, 2, 2, 2, 3, 4, 5], "b": cats})
  970: 
  971:     result = data.groupby("b", observed=False).mean()
  972:     result = result["a"].values
  973:     exp = np.array([1, 2, 4, np.nan])
  974:     tm.assert_numpy_array_equal(result, exp)
  975: 
  976: 
  977: def test_groupby_empty_with_category():
  978:     # GH-9614
  979:     # test fix for when group by on None resulted in
  980:     # coercion of dtype categorical -> float
  981:     df = DataFrame({"A": [None] * 3, "B": Categorical(["train", "train", "test"])})
  982:     result = df.groupby("A").first()["B"]
  983:     expected = Series(
  984:         Categorical([], categories=["test", "train"]),
  985:         index=Series([], dtype="object", name="A"),
  986:         name="B",
  987:     )
  988:     tm.assert_series_equal(result, expected)
  989: 
  990: 
  991: def test_sort():
  992:     # https://stackoverflow.com/questions/23814368/sorting-pandas-
  993:     #        categorical-labels-after-groupby
  994:     # This should result in a properly sorted Series so that the plot
  995:     # has a sorted x axis
  996:     # self.cat.groupby(['value_group'])['value_group'].count().plot(kind='bar')
  997: 
  998:     df = DataFrame({"value": np.random.default_rng(2).integers(0, 10000, 100)})
  999:     labels = [f"{i} - {i+499}" for i in range(0, 10000, 500)]
 1000:     cat_labels = Categorical(labels, labels)
 1001: 
 1002:     df = df.sort_values(by=["value"], ascending=True)
 1003:     df["value_group"] = pd.cut(
 1004:         df.value, range(0, 10500, 500), right=False, labels=cat_labels
 1005:     )
 1006: 
 1007:     res = df.groupby(["value_group"], observed=False)["value_group"].count()
 1008:     exp = res[sorted(res.index, key=lambda x: float(x.split()[0]))]
 1009:     exp.index = CategoricalIndex(exp.index, name=exp.index.name)
 1010:     tm.assert_series_equal(res, exp)
 1011: 
 1012: 
 1013: @pytest.mark.parametrize("ordered", [True, False])
 1014: def test_sort2(sort, ordered):
 1015:     # dataframe groupby sort was being ignored # GH 8868
 1016:     # GH#48749 - don't change order of categories
 1017:     # GH#42482 - don't sort result when sort=False, even when ordered=True
 1018:     df = DataFrame(
 1019:         [
 1020:             ["(7.5, 10]", 10, 10],
 1021:             ["(7.5, 10]", 8, 20],
 1022:             ["(2.5, 5]", 5, 30],
 1023:             ["(5, 7.5]", 6, 40],
 1024:             ["(2.5, 5]", 4, 50],
 1025:             ["(0, 2.5]", 1, 60],
 1026:             ["(5, 7.5]", 7, 70],
 1027:         ],
 1028:         columns=["range", "foo", "bar"],
 1029:     )
 1030:     df["range"] = Categorical(df["range"], ordered=ordered)
 1031:     result = df.groupby("range", sort=sort, observed=False).first()
 1032: 
 1033:     if sort:
 1034:         data_values = [[1, 60], [5, 30], [6, 40], [10, 10]]
 1035:         index_values = ["(0, 2.5]", "(2.5, 5]", "(5, 7.5]", "(7.5, 10]"]
 1036:     else:
 1037:         data_values = [[10, 10], [5, 30], [6, 40], [1, 60]]
 1038:         index_values = ["(7.5, 10]", "(2.5, 5]", "(5, 7.5]", "(0, 2.5]"]
 1039:     expected = DataFrame(
 1040:         data_values,
 1041:         columns=["foo", "bar"],
 1042:         index=CategoricalIndex(index_values, name="range", ordered=ordered),
 1043:     )
 1044: 
 1045:     tm.assert_frame_equal(result, expected)
 1046: 
 1047: 
 1048: @pytest.mark.parametrize("ordered", [True, False])
 1049: def test_sort_datetimelike(sort, ordered):
 1050:     # GH10505
 1051:     # GH#42482 - don't sort result when sort=False, even when ordered=True
 1052: 
 1053:     # use same data as test_groupby_sort_categorical, which category is
 1054:     # corresponding to datetime.month
 1055:     df = DataFrame(
 1056:         {
 1057:             "dt": [
 1058:                 datetime(2011, 7, 1),
 1059:                 datetime(2011, 7, 1),
 1060:                 datetime(2011, 2, 1),
 1061:                 datetime(2011, 5, 1),
 1062:                 datetime(2011, 2, 1),
 1063:                 datetime(2011, 1, 1),
 1064:                 datetime(2011, 5, 1),
 1065:             ],
 1066:             "foo": [10, 8, 5, 6, 4, 1, 7],
 1067:             "bar": [10, 20, 30, 40, 50, 60, 70],
 1068:         },
 1069:         columns=["dt", "foo", "bar"],
 1070:     )
 1071: 
 1072:     # ordered=True
 1073:     df["dt"] = Categorical(df["dt"], ordered=ordered)
 1074:     if sort:
 1075:         data_values = [[1, 60], [5, 30], [6, 40], [10, 10]]
 1076:         index_values = [
 1077:             datetime(2011, 1, 1),
 1078:             datetime(2011, 2, 1),
 1079:             datetime(2011, 5, 1),
 1080:             datetime(2011, 7, 1),
 1081:         ]
 1082:     else:
 1083:         data_values = [[10, 10], [5, 30], [6, 40], [1, 60]]
 1084:         index_values = [
 1085:             datetime(2011, 7, 1),
 1086:             datetime(2011, 2, 1),
 1087:             datetime(2011, 5, 1),
 1088:             datetime(2011, 1, 1),
 1089:         ]
 1090:     expected = DataFrame(
 1091:         data_values,
 1092:         columns=["foo", "bar"],
 1093:         index=CategoricalIndex(index_values, name="dt", ordered=ordered),
 1094:     )
 1095:     result = df.groupby("dt", sort=sort, observed=False).first()
 1096:     tm.assert_frame_equal(result, expected)
 1097: 
 1098: 
 1099: def test_empty_sum():
 1100:     # https://github.com/pandas-dev/pandas/issues/18678
 1101:     df = DataFrame(
 1102:         {"A": Categorical(["a", "a", "b"], categories=["a", "b", "c"]), "B": [1, 2, 1]}
 1103:     )
 1104:     expected_idx = CategoricalIndex(["a", "b", "c"], name="A")
 1105: 
 1106:     # 0 by default
 1107:     result = df.groupby("A", observed=False).B.sum()
 1108:     expected = Series([3, 1, 0], expected_idx, name="B")
 1109:     tm.assert_series_equal(result, expected)
 1110: 
 1111:     # min_count=0
 1112:     result = df.groupby("A", observed=False).B.sum(min_count=0)
 1113:     expected = Series([3, 1, 0], expected_idx, name="B")
 1114:     tm.assert_series_equal(result, expected)
 1115: 
 1116:     # min_count=1
 1117:     result = df.groupby("A", observed=False).B.sum(min_count=1)
 1118:     expected = Series([3, 1, np.nan], expected_idx, name="B")
 1119:     tm.assert_series_equal(result, expected)
 1120: 
 1121:     # min_count>1
 1122:     result = df.groupby("A", observed=False).B.sum(min_count=2)
 1123:     expected = Series([3, np.nan, np.nan], expected_idx, name="B")
 1124:     tm.assert_series_equal(result, expected)
 1125: 
 1126: 
 1127: def test_empty_prod():
 1128:     # https://github.com/pandas-dev/pandas/issues/18678
 1129:     df = DataFrame(
 1130:         {"A": Categorical(["a", "a", "b"], categories=["a", "b", "c"]), "B": [1, 2, 1]}
 1131:     )
 1132: 
 1133:     expected_idx = CategoricalIndex(["a", "b", "c"], name="A")
 1134: 
 1135:     # 1 by default
 1136:     result = df.groupby("A", observed=False).B.prod()
 1137:     expected = Series([2, 1, 1], expected_idx, name="B")
 1138:     tm.assert_series_equal(result, expected)
 1139: 
 1140:     # min_count=0
 1141:     result = df.groupby("A", observed=False).B.prod(min_count=0)
 1142:     expected = Series([2, 1, 1], expected_idx, name="B")
 1143:     tm.assert_series_equal(result, expected)
 1144: 
 1145:     # min_count=1
 1146:     result = df.groupby("A", observed=False).B.prod(min_count=1)
 1147:     expected = Series([2, 1, np.nan], expected_idx, name="B")
 1148:     tm.assert_series_equal(result, expected)
 1149: 
 1150: 
 1151: def test_groupby_multiindex_categorical_datetime():
 1152:     # https://github.com/pandas-dev/pandas/issues/21390
 1153: 
 1154:     df = DataFrame(
 1155:         {
 1156:             "key1": Categorical(list("abcbabcba")),
 1157:             "key2": Categorical(
 1158:                 list(pd.date_range("2018-06-01 00", freq="1min", periods=3)) * 3
 1159:             ),
 1160:             "values": np.arange(9),
 1161:         }
 1162:     )
 1163:     result = df.groupby(["key1", "key2"], observed=False).mean()
 1164: 
 1165:     idx = MultiIndex.from_product(
 1166:         [
 1167:             Categorical(["a", "b", "c"]),
 1168:             Categorical(pd.date_range("2018-06-01 00", freq="1min", periods=3)),
 1169:         ],
 1170:         names=["key1", "key2"],
 1171:     )
 1172:     expected = DataFrame({"values": [0, 4, 8, 3, 4, 5, 6, np.nan, 2]}, index=idx)
 1173:     tm.assert_frame_equal(result, expected)
 1174: 
 1175: 
 1176: @pytest.mark.parametrize(
 1177:     "as_index, expected",
 1178:     [
 1179:         (
 1180:             True,
 1181:             Series(
 1182:                 index=MultiIndex.from_arrays(
 1183:                     [Series([1, 1, 2], dtype="category"), [1, 2, 2]], names=["a", "b"]
 1184:                 ),
 1185:                 data=[1, 2, 3],
 1186:                 name="x",
 1187:             ),
 1188:         ),
 1189:         (
 1190:             False,
 1191:             DataFrame(
 1192:                 {
 1193:                     "a": Series([1, 1, 2], dtype="category"),
 1194:                     "b": [1, 2, 2],
 1195:                     "x": [1, 2, 3],
 1196:                 }
 1197:             ),
 1198:         ),
 1199:     ],
 1200: )
 1201: def test_groupby_agg_observed_true_single_column(as_index, expected):
 1202:     # GH-23970
 1203:     df = DataFrame(
 1204:         {"a": Series([1, 1, 2], dtype="category"), "b": [1, 2, 2], "x": [1, 2, 3]}
 1205:     )
 1206: 
 1207:     result = df.groupby(["a", "b"], as_index=as_index, observed=True)["x"].sum()
 1208: 
 1209:     tm.assert_equal(result, expected)
 1210: 
 1211: 
 1212: @pytest.mark.parametrize("fill_value", [None, np.nan, pd.NaT])
 1213: def test_shift(fill_value):
 1214:     ct = Categorical(
 1215:         ["a", "b", "c", "d"], categories=["a", "b", "c", "d"], ordered=False
 1216:     )
 1217:     expected = Categorical(
 1218:         [None, "a", "b", "c"], categories=["a", "b", "c", "d"], ordered=False
 1219:     )
 1220:     res = ct.shift(1, fill_value=fill_value)
 1221:     tm.assert_equal(res, expected)
 1222: 
 1223: 
 1224: @pytest.fixture
 1225: def df_cat(df):
 1226:     """
 1227:     DataFrame with multiple categorical columns and a column of integers.
 1228:     Shortened so as not to contain all possible combinations of categories.
 1229:     Useful for testing `observed` kwarg functionality on GroupBy objects.
 1230: 
 1231:     Parameters
 1232:     ----------
 1233:     df: DataFrame
 1234:         Non-categorical, longer DataFrame from another fixture, used to derive
 1235:         this one
 1236: 
 1237:     Returns
 1238:     -------
 1239:     df_cat: DataFrame
 1240:     """
 1241:     df_cat = df.copy()[:4]  # leave out some groups
 1242:     df_cat["A"] = df_cat["A"].astype("category")
 1243:     df_cat["B"] = df_cat["B"].astype("category")
 1244:     df_cat["C"] = Series([1, 2, 3, 4])
 1245:     df_cat = df_cat.drop(["D"], axis=1)
 1246:     return df_cat
 1247: 
 1248: 
 1249: @pytest.mark.parametrize("operation", ["agg", "apply"])
 1250: def test_seriesgroupby_observed_true(df_cat, operation):
 1251:     # GH#24880
 1252:     # GH#49223 - order of results was wrong when grouping by index levels
 1253:     lev_a = Index(["bar", "bar", "foo", "foo"], dtype=df_cat["A"].dtype, name="A")
 1254:     lev_b = Index(["one", "three", "one", "two"], dtype=df_cat["B"].dtype, name="B")
 1255:     index = MultiIndex.from_arrays([lev_a, lev_b])
 1256:     expected = Series(data=[2, 4, 1, 3], index=index, name="C").sort_index()
 1257: 
 1258:     grouped = df_cat.groupby(["A", "B"], observed=True)["C"]
 1259:     msg = "using np.sum" if operation == "apply" else "using SeriesGroupBy.sum"
 1260:     with tm.assert_produces_warning(FutureWarning, match=msg):
 1261:         # GH#53425
 1262:         result = getattr(grouped, operation)(sum)
 1263:     tm.assert_series_equal(result, expected)
 1264: 
 1265: 
 1266: @pytest.mark.parametrize("operation", ["agg", "apply"])
 1267: @pytest.mark.parametrize("observed", [False, None])
 1268: def test_seriesgroupby_observed_false_or_none(df_cat, observed, operation):
 1269:     # GH 24880
 1270:     # GH#49223 - order of results was wrong when grouping by index levels
 1271:     index, _ = MultiIndex.from_product(
 1272:         [
 1273:             CategoricalIndex(["bar", "foo"], ordered=False),
 1274:             CategoricalIndex(["one", "three", "two"], ordered=False),
 1275:         ],
 1276:         names=["A", "B"],
 1277:     ).sortlevel()
 1278: 
 1279:     expected = Series(data=[2, 4, np.nan, 1, np.nan, 3], index=index, name="C")
 1280:     if operation == "agg":
 1281:         msg = "The 'downcast' keyword in fillna is deprecated"
 1282:         with tm.assert_produces_warning(FutureWarning, match=msg):
 1283:             expected = expected.fillna(0, downcast="infer")
 1284:     grouped = df_cat.groupby(["A", "B"], observed=observed)["C"]
 1285:     msg = "using SeriesGroupBy.sum" if operation == "agg" else "using np.sum"
 1286:     with tm.assert_produces_warning(FutureWarning, match=msg):
 1287:         # GH#53425
 1288:         result = getattr(grouped, operation)(sum)
 1289:     tm.assert_series_equal(result, expected)
 1290: 
 1291: 
 1292: @pytest.mark.parametrize(
 1293:     "observed, index, data",
 1294:     [
 1295:         (
 1296:             True,
 1297:             MultiIndex.from_arrays(
 1298:                 [
 1299:                     Index(["bar"] * 4 + ["foo"] * 4, dtype="category", name="A"),
 1300:                     Index(
 1301:                         ["one", "one", "three", "three", "one", "one", "two", "two"],
 1302:                         dtype="category",
 1303:                         name="B",
 1304:                     ),
 1305:                     Index(["min", "max"] * 4),
 1306:                 ]
 1307:             ),
 1308:             [2, 2, 4, 4, 1, 1, 3, 3],
 1309:         ),
 1310:         (
 1311:             False,
 1312:             MultiIndex.from_product(
 1313:                 [
 1314:                     CategoricalIndex(["bar", "foo"], ordered=False),
 1315:                     CategoricalIndex(["one", "three", "two"], ordered=False),
 1316:                     Index(["min", "max"]),
 1317:                 ],
 1318:                 names=["A", "B", None],
 1319:             ),
 1320:             [2, 2, 4, 4, np.nan, np.nan, 1, 1, np.nan, np.nan, 3, 3],
 1321:         ),
 1322:         (
 1323:             None,
 1324:             MultiIndex.from_product(
 1325:                 [
 1326:                     CategoricalIndex(["bar", "foo"], ordered=False),
 1327:                     CategoricalIndex(["one", "three", "two"], ordered=False),
 1328:                     Index(["min", "max"]),
 1329:                 ],
 1330:                 names=["A", "B", None],
 1331:             ),
 1332:             [2, 2, 4, 4, np.nan, np.nan, 1, 1, np.nan, np.nan, 3, 3],
 1333:         ),
 1334:     ],
 1335: )
 1336: def test_seriesgroupby_observed_apply_dict(df_cat, observed, index, data):
 1337:     # GH 24880
 1338:     expected = Series(data=data, index=index, name="C")
 1339:     result = df_cat.groupby(["A", "B"], observed=observed)["C"].apply(
 1340:         lambda x: {"min": x.min(), "max": x.max()}
 1341:     )
 1342:     tm.assert_series_equal(result, expected)
 1343: 
 1344: 
 1345: def test_groupby_categorical_series_dataframe_consistent(df_cat):
 1346:     # GH 20416
 1347:     expected = df_cat.groupby(["A", "B"], observed=False)["C"].mean()
 1348:     result = df_cat.groupby(["A", "B"], observed=False).mean()["C"]
 1349:     tm.assert_series_equal(result, expected)
 1350: 
 1351: 
 1352: @pytest.mark.parametrize("code", [([1, 0, 0]), ([0, 0, 0])])
 1353: def test_groupby_categorical_axis_1(code):
 1354:     # GH 13420
 1355:     df = DataFrame({"a": [1, 2, 3, 4], "b": [-1, -2, -3, -4], "c": [5, 6, 7, 8]})
 1356:     cat = Categorical.from_codes(code, categories=list("abc"))
 1357:     msg = "DataFrame.groupby with axis=1 is deprecated"
 1358:     with tm.assert_produces_warning(FutureWarning, match=msg):
 1359:         gb = df.groupby(cat, axis=1, observed=False)
 1360:     result = gb.mean()
 1361:     msg = "The 'axis' keyword in DataFrame.groupby is deprecated"
 1362:     with tm.assert_produces_warning(FutureWarning, match=msg):
 1363:         gb2 = df.T.groupby(cat, axis=0, observed=False)
 1364:     expected = gb2.mean().T
 1365:     tm.assert_frame_equal(result, expected)
 1366: 
 1367: 
 1368: def test_groupby_cat_preserves_structure(observed, ordered):
 1369:     # GH 28787
 1370:     df = DataFrame(
 1371:         {"Name": Categorical(["Bob", "Greg"], ordered=ordered), "Item": [1, 2]},
 1372:         columns=["Name", "Item"],
 1373:     )
 1374:     expected = df.copy()
 1375: 
 1376:     result = (
 1377:         df.groupby("Name", observed=observed)
 1378:         .agg(DataFrame.sum, skipna=True)
 1379:         .reset_index()
 1380:     )
 1381: 
 1382:     tm.assert_frame_equal(result, expected)
 1383: 
 1384: 
 1385: def test_get_nonexistent_category():
 1386:     # Accessing a Category that is not in the dataframe
 1387:     df = DataFrame({"var": ["a", "a", "b", "b"], "val": range(4)})
 1388:     with pytest.raises(KeyError, match="'vau'"):
 1389:         df.groupby("var").apply(
 1390:             lambda rows: DataFrame(
 1391:                 {"var": [rows.iloc[-1]["var"]], "val": [rows.iloc[-1]["vau"]]}
 1392:             )
 1393:         )
 1394: 
 1395: 
 1396: def test_series_groupby_on_2_categoricals_unobserved(reduction_func, observed):
 1397:     # GH 17605
 1398:     if reduction_func == "ngroup":
 1399:         pytest.skip("ngroup is not truly a reduction")
 1400: 
 1401:     df = DataFrame(
 1402:         {
 1403:             "cat_1": Categorical(list("AABB"), categories=list("ABCD")),
 1404:             "cat_2": Categorical(list("AB") * 2, categories=list("ABCD")),
 1405:             "value": [0.1] * 4,
 1406:         }
 1407:     )
 1408:     args = get_groupby_method_args(reduction_func, df)
 1409: 
 1410:     expected_length = 4 if observed else 16
 1411: 
 1412:     series_groupby = df.groupby(["cat_1", "cat_2"], observed=observed)["value"]
 1413: 
 1414:     if reduction_func == "corrwith":
 1415:         # TODO: implemented SeriesGroupBy.corrwith. See GH 32293
 1416:         assert not hasattr(series_groupby, reduction_func)
 1417:         return
 1418: 
 1419:     agg = getattr(series_groupby, reduction_func)
 1420: 
 1421:     if not observed and reduction_func in ["idxmin", "idxmax"]:
 1422:         # idxmin and idxmax are designed to fail on empty inputs
 1423:         with pytest.raises(
 1424:             ValueError, match="empty group due to unobserved categories"
 1425:         ):
 1426:             agg(*args)
 1427:         return
 1428: 
 1429:     result = agg(*args)
 1430: 
 1431:     assert len(result) == expected_length
 1432: 
 1433: 
 1434: def test_series_groupby_on_2_categoricals_unobserved_zeroes_or_nans(
 1435:     reduction_func, request
 1436: ):
 1437:     # GH 17605
 1438:     # Tests whether the unobserved categories in the result contain 0 or NaN
 1439: 
 1440:     if reduction_func == "ngroup":
 1441:         pytest.skip("ngroup is not truly a reduction")
 1442: 
 1443:     if reduction_func == "corrwith":  # GH 32293
 1444:         mark = pytest.mark.xfail(
 1445:             reason="TODO: implemented SeriesGroupBy.corrwith. See GH 32293"
 1446:         )
 1447:         request.applymarker(mark)
 1448: 
 1449:     df = DataFrame(
 1450:         {
 1451:             "cat_1": Categorical(list("AABB"), categories=list("ABC")),
 1452:             "cat_2": Categorical(list("AB") * 2, categories=list("ABC")),
 1453:             "value": [0.1] * 4,
 1454:         }
 1455:     )
 1456:     unobserved = [tuple("AC"), tuple("BC"), tuple("CA"), tuple("CB"), tuple("CC")]
 1457:     args = get_groupby_method_args(reduction_func, df)
 1458: 
 1459:     series_groupby = df.groupby(["cat_1", "cat_2"], observed=False)["value"]
 1460:     agg = getattr(series_groupby, reduction_func)
 1461: 
 1462:     if reduction_func in ["idxmin", "idxmax"]:
 1463:         # idxmin and idxmax are designed to fail on empty inputs
 1464:         with pytest.raises(
 1465:             ValueError, match="empty group due to unobserved categories"
 1466:         ):
 1467:             agg(*args)
 1468:         return
 1469: 
 1470:     result = agg(*args)
 1471: 
 1472:     zero_or_nan = _results_for_groupbys_with_missing_categories[reduction_func]
 1473: 
 1474:     for idx in unobserved:
 1475:         val = result.loc[idx]
 1476:         assert (pd.isna(zero_or_nan) and pd.isna(val)) or (val == zero_or_nan)
 1477: 
 1478:     # If we expect unobserved values to be zero, we also expect the dtype to be int.
 1479:     # Except for .sum(). If the observed categories sum to dtype=float (i.e. their
 1480:     # sums have decimals), then the zeros for the missing categories should also be
 1481:     # floats.
 1482:     if zero_or_nan == 0 and reduction_func != "sum":
 1483:         assert np.issubdtype(result.dtype, np.integer)
 1484: 
 1485: 
 1486: def test_dataframe_groupby_on_2_categoricals_when_observed_is_true(reduction_func):
 1487:     # GH 23865
 1488:     # GH 27075
 1489:     # Ensure that df.groupby, when 'by' is two Categorical variables,
 1490:     # does not return the categories that are not in df when observed=True
 1491:     if reduction_func == "ngroup":
 1492:         pytest.skip("ngroup does not return the Categories on the index")
 1493: 
 1494:     df = DataFrame(
 1495:         {
 1496:             "cat_1": Categorical(list("AABB"), categories=list("ABC")),
 1497:             "cat_2": Categorical(list("1111"), categories=list("12")),
 1498:             "value": [0.1, 0.1, 0.1, 0.1],
 1499:         }
 1500:     )
 1501:     unobserved_cats = [("A", "2"), ("B", "2"), ("C", "1"), ("C", "2")]
 1502: 
 1503:     df_grp = df.groupby(["cat_1", "cat_2"], observed=True)
 1504: 
 1505:     args = get_groupby_method_args(reduction_func, df)
 1506:     res = getattr(df_grp, reduction_func)(*args)
 1507: 
 1508:     for cat in unobserved_cats:
 1509:         assert cat not in res.index
 1510: 
 1511: 
 1512: @pytest.mark.parametrize("observed", [False, None])
 1513: def test_dataframe_groupby_on_2_categoricals_when_observed_is_false(
 1514:     reduction_func, observed
 1515: ):
 1516:     # GH 23865
 1517:     # GH 27075
 1518:     # Ensure that df.groupby, when 'by' is two Categorical variables,
 1519:     # returns the categories that are not in df when observed=False/None
 1520: 
 1521:     if reduction_func == "ngroup":
 1522:         pytest.skip("ngroup does not return the Categories on the index")
 1523: 
 1524:     df = DataFrame(
 1525:         {
 1526:             "cat_1": Categorical(list("AABB"), categories=list("ABC")),
 1527:             "cat_2": Categorical(list("1111"), categories=list("12")),
 1528:             "value": [0.1, 0.1, 0.1, 0.1],
 1529:         }
 1530:     )
 1531:     unobserved_cats = [("A", "2"), ("B", "2"), ("C", "1"), ("C", "2")]
 1532: 
 1533:     df_grp = df.groupby(["cat_1", "cat_2"], observed=observed)
 1534: 
 1535:     args = get_groupby_method_args(reduction_func, df)
 1536: 
 1537:     if not observed and reduction_func in ["idxmin", "idxmax"]:
 1538:         # idxmin and idxmax are designed to fail on empty inputs
 1539:         with pytest.raises(
 1540:             ValueError, match="empty group due to unobserved categories"
 1541:         ):
 1542:             getattr(df_grp, reduction_func)(*args)
 1543:         return
 1544: 
 1545:     res = getattr(df_grp, reduction_func)(*args)
 1546: 
 1547:     expected = _results_for_groupbys_with_missing_categories[reduction_func]
 1548: 
 1549:     if expected is np.nan:
 1550:         assert res.loc[unobserved_cats].isnull().all().all()
 1551:     else:
 1552:         assert (res.loc[unobserved_cats] == expected).all().all()
 1553: 
 1554: 
 1555: def test_series_groupby_categorical_aggregation_getitem():
 1556:     # GH 8870
 1557:     d = {"foo": [10, 8, 4, 1], "bar": [10, 20, 30, 40], "baz": ["d", "c", "d", "c"]}
 1558:     df = DataFrame(d)
 1559:     cat = pd.cut(df["foo"], np.linspace(0, 20, 5))
 1560:     df["range"] = cat
 1561:     groups = df.groupby(["range", "baz"], as_index=True, sort=True, observed=False)
 1562:     result = groups["foo"].agg("mean")
 1563:     expected = groups.agg("mean")["foo"]
 1564:     tm.assert_series_equal(result, expected)
 1565: 
 1566: 
 1567: @pytest.mark.parametrize(
 1568:     "func, expected_values",
 1569:     [(Series.nunique, [1, 1, 2]), (Series.count, [1, 2, 2])],
 1570: )
 1571: def test_groupby_agg_categorical_columns(func, expected_values):
 1572:     # 31256
 1573:     df = DataFrame(
 1574:         {
 1575:             "id": [0, 1, 2, 3, 4],
 1576:             "groups": [0, 1, 1, 2, 2],
 1577:             "value": Categorical([0, 0, 0, 0, 1]),
 1578:         }
 1579:     ).set_index("id")
 1580:     result = df.groupby("groups").agg(func)
 1581: 
 1582:     expected = DataFrame(
 1583:         {"value": expected_values}, index=Index([0, 1, 2], name="groups")
 1584:     )
 1585:     tm.assert_frame_equal(result, expected)
 1586: 
 1587: 
 1588: def test_groupby_agg_non_numeric():
 1589:     df = DataFrame({"A": Categorical(["a", "a", "b"], categories=["a", "b", "c"])})
 1590:     expected = DataFrame({"A": [2, 1]}, index=np.array([1, 2]))
 1591: 
 1592:     result = df.groupby([1, 2, 1]).agg(Series.nunique)
 1593:     tm.assert_frame_equal(result, expected)
 1594: 
 1595:     result = df.groupby([1, 2, 1]).nunique()
 1596:     tm.assert_frame_equal(result, expected)
 1597: 
 1598: 
 1599: @pytest.mark.parametrize("func", ["first", "last"])
 1600: def test_groupby_first_returned_categorical_instead_of_dataframe(func):
 1601:     # GH 28641: groupby drops index, when grouping over categorical column with
 1602:     # first/last. Renamed Categorical instead of DataFrame previously.
 1603:     df = DataFrame({"A": [1997], "B": Series(["b"], dtype="category").cat.as_ordered()})
 1604:     df_grouped = df.groupby("A")["B"]
 1605:     result = getattr(df_grouped, func)()
 1606: 
 1607:     # ordered categorical dtype should be preserved
 1608:     expected = Series(
 1609:         ["b"], index=Index([1997], name="A"), name="B", dtype=df["B"].dtype
 1610:     )
 1611:     tm.assert_series_equal(result, expected)
 1612: 
 1613: 
 1614: def test_read_only_category_no_sort():
 1615:     # GH33410
 1616:     cats = np.array([1, 2])
 1617:     cats.flags.writeable = False
 1618:     df = DataFrame(
 1619:         {"a": [1, 3, 5, 7], "b": Categorical([1, 1, 2, 2], categories=Index(cats))}
 1620:     )
 1621:     expected = DataFrame(data={"a": [2.0, 6.0]}, index=CategoricalIndex(cats, name="b"))
 1622:     result = df.groupby("b", sort=False, observed=False).mean()
 1623:     tm.assert_frame_equal(result, expected)
 1624: 
 1625: 
 1626: def test_sorted_missing_category_values():
 1627:     # GH 28597
 1628:     df = DataFrame(
 1629:         {
 1630:             "foo": [
 1631:                 "small",
 1632:                 "large",
 1633:                 "large",
 1634:                 "large",
 1635:                 "medium",
 1636:                 "large",
 1637:                 "large",
 1638:                 "medium",
 1639:             ],
 1640:             "bar": ["C", "A", "A", "C", "A", "C", "A", "C"],
 1641:         }
 1642:     )
 1643:     df["foo"] = (
 1644:         df["foo"]
 1645:         .astype("category")
 1646:         .cat.set_categories(["tiny", "small", "medium", "large"], ordered=True)
 1647:     )
 1648: 
 1649:     expected = DataFrame(
 1650:         {
 1651:             "tiny": {"A": 0, "C": 0},
 1652:             "small": {"A": 0, "C": 1},
 1653:             "medium": {"A": 1, "C": 1},
 1654:             "large": {"A": 3, "C": 2},
 1655:         }
 1656:     )
 1657:     expected = expected.rename_axis("bar", axis="index")
 1658:     expected.columns = CategoricalIndex(
 1659:         ["tiny", "small", "medium", "large"],
 1660:         categories=["tiny", "small", "medium", "large"],
 1661:         ordered=True,
 1662:         name="foo",
 1663:         dtype="category",
 1664:     )
 1665: 
 1666:     result = df.groupby(["bar", "foo"], observed=False).size().unstack()
 1667: 
 1668:     tm.assert_frame_equal(result, expected)
 1669: 
 1670: 
 1671: def test_agg_cython_category_not_implemented_fallback():
 1672:     # https://github.com/pandas-dev/pandas/issues/31450
 1673:     df = DataFrame({"col_num": [1, 1, 2, 3]})
 1674:     df["col_cat"] = df["col_num"].astype("category")
 1675: 
 1676:     result = df.groupby("col_num").col_cat.first()
 1677: 
 1678:     # ordered categorical dtype should definitely be preserved;
 1679:     #  this is unordered, so is less-clear case (if anything, it should raise)
 1680:     expected = Series(
 1681:         [1, 2, 3],
 1682:         index=Index([1, 2, 3], name="col_num"),
 1683:         name="col_cat",
 1684:         dtype=df["col_cat"].dtype,
 1685:     )
 1686:     tm.assert_series_equal(result, expected)
 1687: 
 1688:     result = df.groupby("col_num").agg({"col_cat": "first"})
 1689:     expected = expected.to_frame()
 1690:     tm.assert_frame_equal(result, expected)
 1691: 
 1692: 
 1693: def test_aggregate_categorical_with_isnan():
 1694:     # GH 29837
 1695:     df = DataFrame(
 1696:         {
 1697:             "A": [1, 1, 1, 1],
 1698:             "B": [1, 2, 1, 2],
 1699:             "numerical_col": [0.1, 0.2, np.nan, 0.3],
 1700:             "object_col": ["foo", "bar", "foo", "fee"],
 1701:             "categorical_col": ["foo", "bar", "foo", "fee"],
 1702:         }
 1703:     )
 1704: 
 1705:     df = df.astype({"categorical_col": "category"})
 1706: 
 1707:     result = df.groupby(["A", "B"]).agg(lambda df: df.isna().sum())
 1708:     index = MultiIndex.from_arrays([[1, 1], [1, 2]], names=("A", "B"))
 1709:     expected = DataFrame(
 1710:         data={
 1711:             "numerical_col": [1, 0],
 1712:             "object_col": [0, 0],
 1713:             "categorical_col": [0, 0],
 1714:         },
 1715:         index=index,
 1716:     )
 1717:     tm.assert_frame_equal(result, expected)
 1718: 
 1719: 
 1720: def test_categorical_transform():
 1721:     # GH 29037
 1722:     df = DataFrame(
 1723:         {
 1724:             "package_id": [1, 1, 1, 2, 2, 3],
 1725:             "status": [
 1726:                 "Waiting",
 1727:                 "OnTheWay",
 1728:                 "Delivered",
 1729:                 "Waiting",
 1730:                 "OnTheWay",
 1731:                 "Waiting",
 1732:             ],
 1733:         }
 1734:     )
 1735: 
 1736:     delivery_status_type = pd.CategoricalDtype(
 1737:         categories=["Waiting", "OnTheWay", "Delivered"], ordered=True
 1738:     )
 1739:     df["status"] = df["status"].astype(delivery_status_type)
 1740:     msg = "using SeriesGroupBy.max"
 1741:     with tm.assert_produces_warning(FutureWarning, match=msg):
 1742:         # GH#53425
 1743:         df["last_status"] = df.groupby("package_id")["status"].transform(max)
 1744:     result = df.copy()
 1745: 
 1746:     expected = DataFrame(
 1747:         {
 1748:             "package_id": [1, 1, 1, 2, 2, 3],
 1749:             "status": [
 1750:                 "Waiting",
 1751:                 "OnTheWay",
 1752:                 "Delivered",
 1753:                 "Waiting",
 1754:                 "OnTheWay",
 1755:                 "Waiting",
 1756:             ],
 1757:             "last_status": [
 1758:                 "Delivered",
 1759:                 "Delivered",
 1760:                 "Delivered",
 1761:                 "OnTheWay",
 1762:                 "OnTheWay",
 1763:                 "Waiting",
 1764:             ],
 1765:         }
 1766:     )
 1767: 
 1768:     expected["status"] = expected["status"].astype(delivery_status_type)
 1769: 
 1770:     # .transform(max) should preserve ordered categoricals
 1771:     expected["last_status"] = expected["last_status"].astype(delivery_status_type)
 1772: 
 1773:     tm.assert_frame_equal(result, expected)
 1774: 
 1775: 
 1776: @pytest.mark.parametrize("func", ["first", "last"])
 1777: def test_series_groupby_first_on_categorical_col_grouped_on_2_categoricals(
 1778:     func: str, observed: bool
 1779: ):
 1780:     # GH 34951
 1781:     cat = Categorical([0, 0, 1, 1])
 1782:     val = [0, 1, 1, 0]
 1783:     df = DataFrame({"a": cat, "b": cat, "c": val})
 1784: 
 1785:     cat2 = Categorical([0, 1])
 1786:     idx = MultiIndex.from_product([cat2, cat2], names=["a", "b"])
 1787:     expected_dict = {
 1788:         "first": Series([0, np.nan, np.nan, 1], idx, name="c"),
 1789:         "last": Series([1, np.nan, np.nan, 0], idx, name="c"),
 1790:     }
 1791: 
 1792:     expected = expected_dict[func]
 1793:     if observed:
 1794:         expected = expected.dropna().astype(np.int64)
 1795: 
 1796:     srs_grp = df.groupby(["a", "b"], observed=observed)["c"]
 1797:     result = getattr(srs_grp, func)()
 1798:     tm.assert_series_equal(result, expected)
 1799: 
 1800: 
 1801: @pytest.mark.parametrize("func", ["first", "last"])
 1802: def test_df_groupby_first_on_categorical_col_grouped_on_2_categoricals(
 1803:     func: str, observed: bool
 1804: ):
 1805:     # GH 34951
 1806:     cat = Categorical([0, 0, 1, 1])
 1807:     val = [0, 1, 1, 0]
 1808:     df = DataFrame({"a": cat, "b": cat, "c": val})
 1809: 
 1810:     cat2 = Categorical([0, 1])
 1811:     idx = MultiIndex.from_product([cat2, cat2], names=["a", "b"])
 1812:     expected_dict = {
 1813:         "first": Series([0, np.nan, np.nan, 1], idx, name="c"),
 1814:         "last": Series([1, np.nan, np.nan, 0], idx, name="c"),
 1815:     }
 1816: 
 1817:     expected = expected_dict[func].to_frame()
 1818:     if observed:
 1819:         expected = expected.dropna().astype(np.int64)
 1820: 
 1821:     df_grp = df.groupby(["a", "b"], observed=observed)
 1822:     result = getattr(df_grp, func)()
 1823:     tm.assert_frame_equal(result, expected)
 1824: 
 1825: 
 1826: def test_groupby_categorical_indices_unused_categories():
 1827:     # GH#38642
 1828:     df = DataFrame(
 1829:         {
 1830:             "key": Categorical(["b", "b", "a"], categories=["a", "b", "c"]),
 1831:             "col": range(3),
 1832:         }
 1833:     )
 1834:     grouped = df.groupby("key", sort=False, observed=False)
 1835:     result = grouped.indices
 1836:     expected = {
 1837:         "b": np.array([0, 1], dtype="intp"),
 1838:         "a": np.array([2], dtype="intp"),
 1839:         "c": np.array([], dtype="intp"),
 1840:     }
 1841:     assert result.keys() == expected.keys()
 1842:     for key in result.keys():
 1843:         tm.assert_numpy_array_equal(result[key], expected[key])
 1844: 
 1845: 
 1846: @pytest.mark.parametrize("func", ["first", "last"])
 1847: def test_groupby_last_first_preserve_categoricaldtype(func):
 1848:     # GH#33090
 1849:     df = DataFrame({"a": [1, 2, 3]})
 1850:     df["b"] = df["a"].astype("category")
 1851:     result = getattr(df.groupby("a")["b"], func)()
 1852:     expected = Series(
 1853:         Categorical([1, 2, 3]), name="b", index=Index([1, 2, 3], name="a")
 1854:     )
 1855:     tm.assert_series_equal(expected, result)
 1856: 
 1857: 
 1858: def test_groupby_categorical_observed_nunique():
 1859:     # GH#45128
 1860:     df = DataFrame({"a": [1, 2], "b": [1, 2], "c": [10, 11]})
 1861:     df = df.astype(dtype={"a": "category", "b": "category"})
 1862:     result = df.groupby(["a", "b"], observed=True).nunique()["c"]
 1863:     expected = Series(
 1864:         [1, 1],
 1865:         index=MultiIndex.from_arrays(
 1866:             [CategoricalIndex([1, 2], name="a"), CategoricalIndex([1, 2], name="b")]
 1867:         ),
 1868:         name="c",
 1869:     )
 1870:     tm.assert_series_equal(result, expected)
 1871: 
 1872: 
 1873: def test_groupby_categorical_aggregate_functions():
 1874:     # GH#37275
 1875:     dtype = pd.CategoricalDtype(categories=["small", "big"], ordered=True)
 1876:     df = DataFrame(
 1877:         [[1, "small"], [1, "big"], [2, "small"]], columns=["grp", "description"]
 1878:     ).astype({"description": dtype})
 1879: 
 1880:     result = df.groupby("grp")["description"].max()
 1881:     expected = Series(
 1882:         ["big", "small"],
 1883:         index=Index([1, 2], name="grp"),
 1884:         name="description",
 1885:         dtype=pd.CategoricalDtype(categories=["small", "big"], ordered=True),
 1886:     )
 1887: 
 1888:     tm.assert_series_equal(result, expected)
 1889: 
 1890: 
 1891: def test_groupby_categorical_dropna(observed, dropna):
 1892:     # GH#48645 - dropna should have no impact on the result when there are no NA values
 1893:     cat = Categorical([1, 2], categories=[1, 2, 3])
 1894:     df = DataFrame({"x": Categorical([1, 2], categories=[1, 2, 3]), "y": [3, 4]})
 1895:     gb = df.groupby("x", observed=observed, dropna=dropna)
 1896:     result = gb.sum()
 1897: 
 1898:     if observed:
 1899:         expected = DataFrame({"y": [3, 4]}, index=cat)
 1900:     else:
 1901:         index = CategoricalIndex([1, 2, 3], [1, 2, 3])
 1902:         expected = DataFrame({"y": [3, 4, 0]}, index=index)
 1903:     expected.index.name = "x"
 1904: 
 1905:     tm.assert_frame_equal(result, expected)
 1906: 
 1907: 
 1908: @pytest.mark.parametrize("index_kind", ["range", "single", "multi"])
 1909: @pytest.mark.parametrize("ordered", [True, False])
 1910: def test_category_order_reducer(
 1911:     request, as_index, sort, observed, reduction_func, index_kind, ordered
 1912: ):
 1913:     # GH#48749
 1914:     if reduction_func == "corrwith" and not as_index:
 1915:         msg = "GH#49950 - corrwith with as_index=False may not have grouping column"
 1916:         request.applymarker(pytest.mark.xfail(reason=msg))
 1917:     elif index_kind != "range" and not as_index:
 1918:         pytest.skip(reason="Result doesn't have categories, nothing to test")
 1919:     df = DataFrame(
 1920:         {
 1921:             "a": Categorical([2, 1, 2, 3], categories=[1, 4, 3, 2], ordered=ordered),
 1922:             "b": range(4),
 1923:         }
 1924:     )
 1925:     if index_kind == "range":
 1926:         keys = ["a"]
 1927:     elif index_kind == "single":
 1928:         keys = ["a"]
 1929:         df = df.set_index(keys)
 1930:     elif index_kind == "multi":
 1931:         keys = ["a", "a2"]
 1932:         df["a2"] = df["a"]
 1933:         df = df.set_index(keys)
 1934:     args = get_groupby_method_args(reduction_func, df)
 1935:     gb = df.groupby(keys, as_index=as_index, sort=sort, observed=observed)
 1936: 
 1937:     if not observed and reduction_func in ["idxmin", "idxmax"]:
 1938:         # idxmin and idxmax are designed to fail on empty inputs
 1939:         with pytest.raises(
 1940:             ValueError, match="empty group due to unobserved categories"
 1941:         ):
 1942:             getattr(gb, reduction_func)(*args)
 1943:         return
 1944: 
 1945:     op_result = getattr(gb, reduction_func)(*args)
 1946:     if as_index:
 1947:         result = op_result.index.get_level_values("a").categories
 1948:     else:
 1949:         result = op_result["a"].cat.categories
 1950:     expected = Index([1, 4, 3, 2])
 1951:     tm.assert_index_equal(result, expected)
 1952: 
 1953:     if index_kind == "multi":
 1954:         result = op_result.index.get_level_values("a2").categories
 1955:         tm.assert_index_equal(result, expected)
 1956: 
 1957: 
 1958: @pytest.mark.parametrize("index_kind", ["single", "multi"])
 1959: @pytest.mark.parametrize("ordered", [True, False])
 1960: def test_category_order_transformer(
 1961:     as_index, sort, observed, transformation_func, index_kind, ordered
 1962: ):
 1963:     # GH#48749
 1964:     df = DataFrame(
 1965:         {
 1966:             "a": Categorical([2, 1, 2, 3], categories=[1, 4, 3, 2], ordered=ordered),
 1967:             "b": range(4),
 1968:         }
 1969:     )
 1970:     if index_kind == "single":
 1971:         keys = ["a"]
 1972:         df = df.set_index(keys)
 1973:     elif index_kind == "multi":
 1974:         keys = ["a", "a2"]
 1975:         df["a2"] = df["a"]
 1976:         df = df.set_index(keys)
 1977:     args = get_groupby_method_args(transformation_func, df)
 1978:     gb = df.groupby(keys, as_index=as_index, sort=sort, observed=observed)
 1979:     warn = FutureWarning if transformation_func == "fillna" else None
 1980:     msg = "DataFrameGroupBy.fillna is deprecated"
 1981:     with tm.assert_produces_warning(warn, match=msg):
 1982:         op_result = getattr(gb, transformation_func)(*args)
 1983:     result = op_result.index.get_level_values("a").categories
 1984:     expected = Index([1, 4, 3, 2])
 1985:     tm.assert_index_equal(result, expected)
 1986: 
 1987:     if index_kind == "multi":
 1988:         result = op_result.index.get_level_values("a2").categories
 1989:         tm.assert_index_equal(result, expected)
 1990: 
 1991: 
 1992: @pytest.mark.parametrize("index_kind", ["range", "single", "multi"])
 1993: @pytest.mark.parametrize("method", ["head", "tail"])
 1994: @pytest.mark.parametrize("ordered", [True, False])
 1995: def test_category_order_head_tail(
 1996:     as_index, sort, observed, method, index_kind, ordered
 1997: ):
 1998:     # GH#48749
 1999:     df = DataFrame(
 2000:         {
 2001:             "a": Categorical([2, 1, 2, 3], categories=[1, 4, 3, 2], ordered=ordered),
 2002:             "b": range(4),
 2003:         }
 2004:     )
 2005:     if index_kind == "range":
 2006:         keys = ["a"]
 2007:     elif index_kind == "single":
 2008:         keys = ["a"]
 2009:         df = df.set_index(keys)
 2010:     elif index_kind == "multi":
 2011:         keys = ["a", "a2"]
 2012:         df["a2"] = df["a"]
 2013:         df = df.set_index(keys)
 2014:     gb = df.groupby(keys, as_index=as_index, sort=sort, observed=observed)
 2015:     op_result = getattr(gb, method)()
 2016:     if index_kind == "range":
 2017:         result = op_result["a"].cat.categories
 2018:     else:
 2019:         result = op_result.index.get_level_values("a").categories
 2020:     expected = Index([1, 4, 3, 2])
 2021:     tm.assert_index_equal(result, expected)
 2022: 
 2023:     if index_kind == "multi":
 2024:         result = op_result.index.get_level_values("a2").categories
 2025:         tm.assert_index_equal(result, expected)
 2026: 
 2027: 
 2028: @pytest.mark.parametrize("index_kind", ["range", "single", "multi"])
 2029: @pytest.mark.parametrize("method", ["apply", "agg", "transform"])
 2030: @pytest.mark.parametrize("ordered", [True, False])
 2031: def test_category_order_apply(as_index, sort, observed, method, index_kind, ordered):
 2032:     # GH#48749
 2033:     if (method == "transform" and index_kind == "range") or (
 2034:         not as_index and index_kind != "range"
 2035:     ):
 2036:         pytest.skip("No categories in result, nothing to test")
 2037:     df = DataFrame(
 2038:         {
 2039:             "a": Categorical([2, 1, 2, 3], categories=[1, 4, 3, 2], ordered=ordered),
 2040:             "b": range(4),
 2041:         }
 2042:     )
 2043:     if index_kind == "range":
 2044:         keys = ["a"]
 2045:     elif index_kind == "single":
 2046:         keys = ["a"]
 2047:         df = df.set_index(keys)
 2048:     elif index_kind == "multi":
 2049:         keys = ["a", "a2"]
 2050:         df["a2"] = df["a"]
 2051:         df = df.set_index(keys)
 2052:     gb = df.groupby(keys, as_index=as_index, sort=sort, observed=observed)
 2053:     warn = DeprecationWarning if method == "apply" and index_kind == "range" else None
 2054:     msg = "DataFrameGroupBy.apply operated on the grouping columns"
 2055:     with tm.assert_produces_warning(warn, match=msg):
 2056:         op_result = getattr(gb, method)(lambda x: x.sum(numeric_only=True))
 2057:     if (method == "transform" or not as_index) and index_kind == "range":
 2058:         result = op_result["a"].cat.categories
 2059:     else:
 2060:         result = op_result.index.get_level_values("a").categories
 2061:     expected = Index([1, 4, 3, 2])
 2062:     tm.assert_index_equal(result, expected)
 2063: 
 2064:     if index_kind == "multi":
 2065:         result = op_result.index.get_level_values("a2").categories
 2066:         tm.assert_index_equal(result, expected)
 2067: 
 2068: 
 2069: @pytest.mark.parametrize("index_kind", ["range", "single", "multi"])
 2070: def test_many_categories(as_index, sort, index_kind, ordered):
 2071:     # GH#48749 - Test when the grouper has many categories
 2072:     if index_kind != "range" and not as_index:
 2073:         pytest.skip(reason="Result doesn't have categories, nothing to test")
 2074:     categories = np.arange(9999, -1, -1)
 2075:     grouper = Categorical([2, 1, 2, 3], categories=categories, ordered=ordered)
 2076:     df = DataFrame({"a": grouper, "b": range(4)})
 2077:     if index_kind == "range":
 2078:         keys = ["a"]
 2079:     elif index_kind == "single":
 2080:         keys = ["a"]
 2081:         df = df.set_index(keys)
 2082:     elif index_kind == "multi":
 2083:         keys = ["a", "a2"]
 2084:         df["a2"] = df["a"]
 2085:         df = df.set_index(keys)
 2086:     gb = df.groupby(keys, as_index=as_index, sort=sort, observed=True)
 2087:     result = gb.sum()
 2088: 
 2089:     # Test is setup so that data and index are the same values
 2090:     data = [3, 2, 1] if sort else [2, 1, 3]
 2091: 
 2092:     index = CategoricalIndex(
 2093:         data, categories=grouper.categories, ordered=ordered, name="a"
 2094:     )
 2095:     if as_index:
 2096:         expected = DataFrame({"b": data})
 2097:         if index_kind == "multi":
 2098:             expected.index = MultiIndex.from_frame(DataFrame({"a": index, "a2": index}))
 2099:         else:
 2100:             expected.index = index
 2101:     elif index_kind == "multi":
 2102:         expected = DataFrame({"a": Series(index), "a2": Series(index), "b": data})
 2103:     else:
 2104:         expected = DataFrame({"a": Series(index), "b": data})
 2105: 
 2106:     tm.assert_frame_equal(result, expected)
 2107: 
 2108: 
 2109: @pytest.mark.parametrize("cat_columns", ["a", "b", ["a", "b"]])
 2110: @pytest.mark.parametrize("keys", ["a", "b", ["a", "b"]])
 2111: def test_groupby_default_depr(cat_columns, keys):
 2112:     # GH#43999
 2113:     df = DataFrame({"a": [1, 1, 2, 3], "b": [4, 5, 6, 7]})
 2114:     df[cat_columns] = df[cat_columns].astype("category")
 2115:     msg = "The default of observed=False is deprecated"
 2116:     klass = FutureWarning if set(cat_columns) & set(keys) else None
 2117:     with tm.assert_produces_warning(klass, match=msg):
 2118:         df.groupby(keys)
 2119: 
 2120: 
 2121: @pytest.mark.parametrize("test_series", [True, False])
 2122: @pytest.mark.parametrize("keys", [["a1"], ["a1", "a2"]])
 2123: def test_agg_list(request, as_index, observed, reduction_func, test_series, keys):
 2124:     # GH#52760
 2125:     if test_series and reduction_func == "corrwith":
 2126:         assert not hasattr(SeriesGroupBy, "corrwith")
 2127:         pytest.skip("corrwith not implemented for SeriesGroupBy")
 2128:     elif reduction_func == "corrwith":
 2129:         msg = "GH#32293: attempts to call SeriesGroupBy.corrwith"
 2130:         request.applymarker(pytest.mark.xfail(reason=msg))
 2131:     elif (
 2132:         reduction_func == "nunique"
 2133:         and not test_series
 2134:         and len(keys) != 1
 2135:         and not observed
 2136:         and not as_index
 2137:     ):
 2138:         msg = "GH#52848 - raises a ValueError"
 2139:         request.applymarker(pytest.mark.xfail(reason=msg))
 2140: 
 2141:     df = DataFrame({"a1": [0, 0, 1], "a2": [2, 3, 3], "b": [4, 5, 6]})
 2142:     df = df.astype({"a1": "category", "a2": "category"})
 2143:     if "a2" not in keys:
 2144:         df = df.drop(columns="a2")
 2145:     gb = df.groupby(by=keys, as_index=as_index, observed=observed)
 2146:     if test_series:
 2147:         gb = gb["b"]
 2148:     args = get_groupby_method_args(reduction_func, df)
 2149: 
 2150:     if not observed and reduction_func in ["idxmin", "idxmax"] and keys == ["a1", "a2"]:
 2151:         with pytest.raises(
 2152:             ValueError, match="empty group due to unobserved categories"
 2153:         ):
 2154:             gb.agg([reduction_func], *args)
 2155:         return
 2156: 
 2157:     result = gb.agg([reduction_func], *args)
 2158:     expected = getattr(gb, reduction_func)(*args)
 2159: 
 2160:     if as_index and (test_series or reduction_func == "size"):
 2161:         expected = expected.to_frame(reduction_func)
 2162:     if not test_series:
 2163:         expected.columns = MultiIndex.from_tuples(
 2164:             [(ind, "") for ind in expected.columns[:-1]] + [("b", reduction_func)]
 2165:         )
 2166:     elif not as_index:
 2167:         expected.columns = keys + [reduction_func]
 2168: 
 2169:     tm.assert_equal(result, expected)
