    1: """
    2: these are systematically testing all of the args to value_counts
    3: with different size combinations. This is to ensure stability of the sorting
    4: and proper parameter handling
    5: """
    6: 
    7: 
    8: import numpy as np
    9: import pytest
   10: 
   11: import pandas.util._test_decorators as td
   12: 
   13: from pandas import (
   14:     Categorical,
   15:     CategoricalIndex,
   16:     DataFrame,
   17:     Grouper,
   18:     Index,
   19:     MultiIndex,
   20:     Series,
   21:     date_range,
   22:     to_datetime,
   23: )
   24: import pandas._testing as tm
   25: from pandas.util.version import Version
   26: 
   27: 
   28: def tests_value_counts_index_names_category_column():
   29:     # GH44324 Missing name of index category column
   30:     df = DataFrame(
   31:         {
   32:             "gender": ["female"],
   33:             "country": ["US"],
   34:         }
   35:     )
   36:     df["gender"] = df["gender"].astype("category")
   37:     result = df.groupby("country")["gender"].value_counts()
   38: 
   39:     # Construct expected, very specific multiindex
   40:     df_mi_expected = DataFrame([["US", "female"]], columns=["country", "gender"])
   41:     df_mi_expected["gender"] = df_mi_expected["gender"].astype("category")
   42:     mi_expected = MultiIndex.from_frame(df_mi_expected)
   43:     expected = Series([1], index=mi_expected, name="count")
   44: 
   45:     tm.assert_series_equal(result, expected)
   46: 
   47: 
   48: def seed_df(seed_nans, n, m):
   49:     days = date_range("2015-08-24", periods=10)
   50: 
   51:     frame = DataFrame(
   52:         {
   53:             "1st": np.random.default_rng(2).choice(list("abcd"), n),
   54:             "2nd": np.random.default_rng(2).choice(days, n),
   55:             "3rd": np.random.default_rng(2).integers(1, m + 1, n),
   56:         }
   57:     )
   58: 
   59:     if seed_nans:
   60:         # Explicitly cast to float to avoid implicit cast when setting nan
   61:         frame["3rd"] = frame["3rd"].astype("float")
   62:         frame.loc[1::11, "1st"] = np.nan
   63:         frame.loc[3::17, "2nd"] = np.nan
   64:         frame.loc[7::19, "3rd"] = np.nan
   65:         frame.loc[8::19, "3rd"] = np.nan
   66:         frame.loc[9::19, "3rd"] = np.nan
   67: 
   68:     return frame
   69: 
   70: 
   71: @pytest.mark.slow
   72: @pytest.mark.parametrize("seed_nans", [True, False])
   73: @pytest.mark.parametrize("num_rows", [10, 50])
   74: @pytest.mark.parametrize("max_int", [5, 20])
   75: @pytest.mark.parametrize("keys", ["1st", "2nd", ["1st", "2nd"]], ids=repr)
   76: @pytest.mark.parametrize("bins", [None, [0, 5]], ids=repr)
   77: @pytest.mark.parametrize("isort", [True, False])
   78: @pytest.mark.parametrize("normalize, name", [(True, "proportion"), (False, "count")])
   79: @pytest.mark.parametrize("sort", [True, False])
   80: @pytest.mark.parametrize("ascending", [True, False])
   81: @pytest.mark.parametrize("dropna", [True, False])
   82: def test_series_groupby_value_counts(
   83:     seed_nans,
   84:     num_rows,
   85:     max_int,
   86:     keys,
   87:     bins,
   88:     isort,
   89:     normalize,
   90:     name,
   91:     sort,
   92:     ascending,
   93:     dropna,
   94: ):
   95:     df = seed_df(seed_nans, num_rows, max_int)
   96: 
   97:     def rebuild_index(df):
   98:         arr = list(map(df.index.get_level_values, range(df.index.nlevels)))
   99:         df.index = MultiIndex.from_arrays(arr, names=df.index.names)
  100:         return df
  101: 
  102:     kwargs = {
  103:         "normalize": normalize,
  104:         "sort": sort,
  105:         "ascending": ascending,
  106:         "dropna": dropna,
  107:         "bins": bins,
  108:     }
  109: 
  110:     gr = df.groupby(keys, sort=isort)
  111:     left = gr["3rd"].value_counts(**kwargs)
  112: 
  113:     gr = df.groupby(keys, sort=isort)
  114:     right = gr["3rd"].apply(Series.value_counts, **kwargs)
  115:     right.index.names = right.index.names[:-1] + ["3rd"]
  116:     # https://github.com/pandas-dev/pandas/issues/49909
  117:     right = right.rename(name)
  118: 
  119:     # have to sort on index because of unstable sort on values
  120:     left, right = map(rebuild_index, (left, right))  # xref GH9212
  121:     tm.assert_series_equal(left.sort_index(), right.sort_index())
  122: 
  123: 
  124: @pytest.mark.parametrize("utc", [True, False])
  125: def test_series_groupby_value_counts_with_grouper(utc):
  126:     # GH28479
  127:     df = DataFrame(
  128:         {
  129:             "Timestamp": [
  130:                 1565083561,
  131:                 1565083561 + 86400,
  132:                 1565083561 + 86500,
  133:                 1565083561 + 86400 * 2,
  134:                 1565083561 + 86400 * 3,
  135:                 1565083561 + 86500 * 3,
  136:                 1565083561 + 86400 * 4,
  137:             ],
  138:             "Food": ["apple", "apple", "banana", "banana", "orange", "orange", "pear"],
  139:         }
  140:     ).drop([3])
  141: 
  142:     df["Datetime"] = to_datetime(df["Timestamp"], utc=utc, unit="s")
  143:     dfg = df.groupby(Grouper(freq="1D", key="Datetime"))
  144: 
  145:     # have to sort on index because of unstable sort on values xref GH9212
  146:     result = dfg["Food"].value_counts().sort_index()
  147:     expected = dfg["Food"].apply(Series.value_counts).sort_index()
  148:     expected.index.names = result.index.names
  149:     # https://github.com/pandas-dev/pandas/issues/49909
  150:     expected = expected.rename("count")
  151: 
  152:     tm.assert_series_equal(result, expected)
  153: 
  154: 
  155: @pytest.mark.parametrize("columns", [["A", "B"], ["A", "B", "C"]])
  156: def test_series_groupby_value_counts_empty(columns):
  157:     # GH39172
  158:     df = DataFrame(columns=columns)
  159:     dfg = df.groupby(columns[:-1])
  160: 
  161:     result = dfg[columns[-1]].value_counts()
  162:     expected = Series([], dtype=result.dtype, name="count")
  163:     expected.index = MultiIndex.from_arrays([[]] * len(columns), names=columns)
  164: 
  165:     tm.assert_series_equal(result, expected)
  166: 
  167: 
  168: @pytest.mark.parametrize("columns", [["A", "B"], ["A", "B", "C"]])
  169: def test_series_groupby_value_counts_one_row(columns):
  170:     # GH42618
  171:     df = DataFrame(data=[range(len(columns))], columns=columns)
  172:     dfg = df.groupby(columns[:-1])
  173: 
  174:     result = dfg[columns[-1]].value_counts()
  175:     expected = df.value_counts()
  176: 
  177:     tm.assert_series_equal(result, expected)
  178: 
  179: 
  180: def test_series_groupby_value_counts_on_categorical():
  181:     # GH38672
  182: 
  183:     s = Series(Categorical(["a"], categories=["a", "b"]))
  184:     result = s.groupby([0]).value_counts()
  185: 
  186:     expected = Series(
  187:         data=[1, 0],
  188:         index=MultiIndex.from_arrays(
  189:             [
  190:                 np.array([0, 0]),
  191:                 CategoricalIndex(
  192:                     ["a", "b"], categories=["a", "b"], ordered=False, dtype="category"
  193:                 ),
  194:             ]
  195:         ),
  196:         name="count",
  197:     )
  198: 
  199:     # Expected:
  200:     # 0  a    1
  201:     #    b    0
  202:     # dtype: int64
  203: 
  204:     tm.assert_series_equal(result, expected)
  205: 
  206: 
  207: def test_series_groupby_value_counts_no_sort():
  208:     # GH#50482
  209:     df = DataFrame(
  210:         {
  211:             "gender": ["male", "male", "female", "male", "female", "male"],
  212:             "education": ["low", "medium", "high", "low", "high", "low"],
  213:             "country": ["US", "FR", "US", "FR", "FR", "FR"],
  214:         }
  215:     )
  216:     gb = df.groupby(["country", "gender"], sort=False)["education"]
  217:     result = gb.value_counts(sort=False)
  218:     index = MultiIndex(
  219:         levels=[["US", "FR"], ["male", "female"], ["low", "medium", "high"]],
  220:         codes=[[0, 1, 0, 1, 1], [0, 0, 1, 0, 1], [0, 1, 2, 0, 2]],
  221:         names=["country", "gender", "education"],
  222:     )
  223:     expected = Series([1, 1, 1, 2, 1], index=index, name="count")
  224:     tm.assert_series_equal(result, expected)
  225: 
  226: 
  227: @pytest.fixture
  228: def education_df():
  229:     return DataFrame(
  230:         {
  231:             "gender": ["male", "male", "female", "male", "female", "male"],
  232:             "education": ["low", "medium", "high", "low", "high", "low"],
  233:             "country": ["US", "FR", "US", "FR", "FR", "FR"],
  234:         }
  235:     )
  236: 
  237: 
  238: def test_axis(education_df):
  239:     msg = "DataFrame.groupby with axis=1 is deprecated"
  240:     with tm.assert_produces_warning(FutureWarning, match=msg):
  241:         gp = education_df.groupby("country", axis=1)
  242:     with pytest.raises(NotImplementedError, match="axis"):
  243:         gp.value_counts()
  244: 
  245: 
  246: def test_bad_subset(education_df):
  247:     gp = education_df.groupby("country")
  248:     with pytest.raises(ValueError, match="subset"):
  249:         gp.value_counts(subset=["country"])
  250: 
  251: 
  252: def test_basic(education_df, request):
  253:     # gh43564
  254:     if Version(np.__version__) >= Version("1.25"):
  255:         request.applymarker(
  256:             pytest.mark.xfail(
  257:                 reason=(
  258:                     "pandas default unstable sorting of duplicates"
  259:                     "issue with numpy>=1.25 with AVX instructions"
  260:                 ),
  261:                 strict=False,
  262:             )
  263:         )
  264:     result = education_df.groupby("country")[["gender", "education"]].value_counts(
  265:         normalize=True
  266:     )
  267:     expected = Series(
  268:         data=[0.5, 0.25, 0.25, 0.5, 0.5],
  269:         index=MultiIndex.from_tuples(
  270:             [
  271:                 ("FR", "male", "low"),
  272:                 ("FR", "female", "high"),
  273:                 ("FR", "male", "medium"),
  274:                 ("US", "female", "high"),
  275:                 ("US", "male", "low"),
  276:             ],
  277:             names=["country", "gender", "education"],
  278:         ),
  279:         name="proportion",
  280:     )
  281:     tm.assert_series_equal(result, expected)
  282: 
  283: 
  284: def _frame_value_counts(df, keys, normalize, sort, ascending):
  285:     return df[keys].value_counts(normalize=normalize, sort=sort, ascending=ascending)
  286: 
  287: 
  288: @pytest.mark.parametrize("groupby", ["column", "array", "function"])
  289: @pytest.mark.parametrize("normalize, name", [(True, "proportion"), (False, "count")])
  290: @pytest.mark.parametrize(
  291:     "sort, ascending",
  292:     [
  293:         (False, None),
  294:         (True, True),
  295:         (True, False),
  296:     ],
  297: )
  298: @pytest.mark.parametrize("as_index", [True, False])
  299: @pytest.mark.parametrize("frame", [True, False])
  300: def test_against_frame_and_seriesgroupby(
  301:     education_df, groupby, normalize, name, sort, ascending, as_index, frame, request
  302: ):
  303:     # test all parameters:
  304:     # - Use column, array or function as by= parameter
  305:     # - Whether or not to normalize
  306:     # - Whether or not to sort and how
  307:     # - Whether or not to use the groupby as an index
  308:     # - 3-way compare against:
  309:     #   - apply with :meth:`~DataFrame.value_counts`
  310:     #   - `~SeriesGroupBy.value_counts`
  311:     if Version(np.__version__) >= Version("1.25") and frame and sort and normalize:
  312:         request.applymarker(
  313:             pytest.mark.xfail(
  314:                 reason=(
  315:                     "pandas default unstable sorting of duplicates"
  316:                     "issue with numpy>=1.25 with AVX instructions"
  317:                 ),
  318:                 strict=False,
  319:             )
  320:         )
  321:     by = {
  322:         "column": "country",
  323:         "array": education_df["country"].values,
  324:         "function": lambda x: education_df["country"][x] == "US",
  325:     }[groupby]
  326: 
  327:     gp = education_df.groupby(by=by, as_index=as_index)
  328:     result = gp[["gender", "education"]].value_counts(
  329:         normalize=normalize, sort=sort, ascending=ascending
  330:     )
  331:     if frame:
  332:         # compare against apply with DataFrame value_counts
  333:         warn = DeprecationWarning if groupby == "column" else None
  334:         msg = "DataFrameGroupBy.apply operated on the grouping columns"
  335:         with tm.assert_produces_warning(warn, match=msg):
  336:             expected = gp.apply(
  337:                 _frame_value_counts, ["gender", "education"], normalize, sort, ascending
  338:             )
  339: 
  340:         if as_index:
  341:             tm.assert_series_equal(result, expected)
  342:         else:
  343:             name = "proportion" if normalize else "count"
  344:             expected = expected.reset_index().rename({0: name}, axis=1)
  345:             if groupby == "column":
  346:                 expected = expected.rename({"level_0": "country"}, axis=1)
  347:                 expected["country"] = np.where(expected["country"], "US", "FR")
  348:             elif groupby == "function":
  349:                 expected["level_0"] = expected["level_0"] == 1
  350:             else:
  351:                 expected["level_0"] = np.where(expected["level_0"], "US", "FR")
  352:             tm.assert_frame_equal(result, expected)
  353:     else:
  354:         # compare against SeriesGroupBy value_counts
  355:         education_df["both"] = education_df["gender"] + "-" + education_df["education"]
  356:         expected = gp["both"].value_counts(
  357:             normalize=normalize, sort=sort, ascending=ascending
  358:         )
  359:         expected.name = name
  360:         if as_index:
  361:             index_frame = expected.index.to_frame(index=False)
  362:             index_frame["gender"] = index_frame["both"].str.split("-").str.get(0)
  363:             index_frame["education"] = index_frame["both"].str.split("-").str.get(1)
  364:             del index_frame["both"]
  365:             index_frame = index_frame.rename({0: None}, axis=1)
  366:             expected.index = MultiIndex.from_frame(index_frame)
  367:             tm.assert_series_equal(result, expected)
  368:         else:
  369:             expected.insert(1, "gender", expected["both"].str.split("-").str.get(0))
  370:             expected.insert(2, "education", expected["both"].str.split("-").str.get(1))
  371:             del expected["both"]
  372:             tm.assert_frame_equal(result, expected)
  373: 
  374: 
  375: @pytest.mark.parametrize(
  376:     "dtype",
  377:     [
  378:         object,
  379:         pytest.param("string[pyarrow_numpy]", marks=td.skip_if_no("pyarrow")),
  380:         pytest.param("string[pyarrow]", marks=td.skip_if_no("pyarrow")),
  381:     ],
  382: )
  383: @pytest.mark.parametrize("normalize", [True, False])
  384: @pytest.mark.parametrize(
  385:     "sort, ascending, expected_rows, expected_count, expected_group_size",
  386:     [
  387:         (False, None, [0, 1, 2, 3, 4], [1, 1, 1, 2, 1], [1, 3, 1, 3, 1]),
  388:         (True, False, [3, 0, 1, 2, 4], [2, 1, 1, 1, 1], [3, 1, 3, 1, 1]),
  389:         (True, True, [0, 1, 2, 4, 3], [1, 1, 1, 1, 2], [1, 3, 1, 1, 3]),
  390:     ],
  391: )
  392: def test_compound(
  393:     education_df,
  394:     normalize,
  395:     sort,
  396:     ascending,
  397:     expected_rows,
  398:     expected_count,
  399:     expected_group_size,
  400:     dtype,
  401: ):
  402:     education_df = education_df.astype(dtype)
  403:     education_df.columns = education_df.columns.astype(dtype)
  404:     # Multiple groupby keys and as_index=False
  405:     gp = education_df.groupby(["country", "gender"], as_index=False, sort=False)
  406:     result = gp["education"].value_counts(
  407:         normalize=normalize, sort=sort, ascending=ascending
  408:     )
  409:     expected = DataFrame()
  410:     for column in ["country", "gender", "education"]:
  411:         expected[column] = [education_df[column][row] for row in expected_rows]
  412:         expected = expected.astype(dtype)
  413:         expected.columns = expected.columns.astype(dtype)
  414:     if normalize:
  415:         expected["proportion"] = expected_count
  416:         expected["proportion"] /= expected_group_size
  417:         if dtype == "string[pyarrow]":
  418:             expected["proportion"] = expected["proportion"].convert_dtypes()
  419:     else:
  420:         expected["count"] = expected_count
  421:         if dtype == "string[pyarrow]":
  422:             expected["count"] = expected["count"].convert_dtypes()
  423:     tm.assert_frame_equal(result, expected)
  424: 
  425: 
  426: @pytest.fixture
  427: def animals_df():
  428:     return DataFrame(
  429:         {"key": [1, 1, 1, 1], "num_legs": [2, 4, 4, 6], "num_wings": [2, 0, 0, 0]},
  430:         index=["falcon", "dog", "cat", "ant"],
  431:     )
  432: 
  433: 
  434: @pytest.mark.parametrize(
  435:     "sort, ascending, normalize, name, expected_data, expected_index",
  436:     [
  437:         (False, None, False, "count", [1, 2, 1], [(1, 1, 1), (2, 4, 6), (2, 0, 0)]),
  438:         (True, True, False, "count", [1, 1, 2], [(1, 1, 1), (2, 6, 4), (2, 0, 0)]),
  439:         (True, False, False, "count", [2, 1, 1], [(1, 1, 1), (4, 2, 6), (0, 2, 0)]),
  440:         (
  441:             True,
  442:             False,
  443:             True,
  444:             "proportion",
  445:             [0.5, 0.25, 0.25],
  446:             [(1, 1, 1), (4, 2, 6), (0, 2, 0)],
  447:         ),
  448:     ],
  449: )
  450: def test_data_frame_value_counts(
  451:     animals_df, sort, ascending, normalize, name, expected_data, expected_index
  452: ):
  453:     # 3-way compare with :meth:`~DataFrame.value_counts`
  454:     # Tests from frame/methods/test_value_counts.py
  455:     result_frame = animals_df.value_counts(
  456:         sort=sort, ascending=ascending, normalize=normalize
  457:     )
  458:     expected = Series(
  459:         data=expected_data,
  460:         index=MultiIndex.from_arrays(
  461:             expected_index, names=["key", "num_legs", "num_wings"]
  462:         ),
  463:         name=name,
  464:     )
  465:     tm.assert_series_equal(result_frame, expected)
  466: 
  467:     result_frame_groupby = animals_df.groupby("key").value_counts(
  468:         sort=sort, ascending=ascending, normalize=normalize
  469:     )
  470: 
  471:     tm.assert_series_equal(result_frame_groupby, expected)
  472: 
  473: 
  474: @pytest.fixture
  475: def nulls_df():
  476:     n = np.nan
  477:     return DataFrame(
  478:         {
  479:             "A": [1, 1, n, 4, n, 6, 6, 6, 6],
  480:             "B": [1, 1, 3, n, n, 6, 6, 6, 6],
  481:             "C": [1, 2, 3, 4, 5, 6, n, 8, n],
  482:             "D": [1, 2, 3, 4, 5, 6, 7, n, n],
  483:         }
  484:     )
  485: 
  486: 
  487: @pytest.mark.parametrize(
  488:     "group_dropna, count_dropna, expected_rows, expected_values",
  489:     [
  490:         (
  491:             False,
  492:             False,
  493:             [0, 1, 3, 5, 7, 6, 8, 2, 4],
  494:             [0.5, 0.5, 1.0, 0.25, 0.25, 0.25, 0.25, 1.0, 1.0],
  495:         ),
  496:         (False, True, [0, 1, 3, 5, 2, 4], [0.5, 0.5, 1.0, 1.0, 1.0, 1.0]),
  497:         (True, False, [0, 1, 5, 7, 6, 8], [0.5, 0.5, 0.25, 0.25, 0.25, 0.25]),
  498:         (True, True, [0, 1, 5], [0.5, 0.5, 1.0]),
  499:     ],
  500: )
  501: def test_dropna_combinations(
  502:     nulls_df, group_dropna, count_dropna, expected_rows, expected_values, request
  503: ):
  504:     if Version(np.__version__) >= Version("1.25") and not group_dropna:
  505:         request.applymarker(
  506:             pytest.mark.xfail(
  507:                 reason=(
  508:                     "pandas default unstable sorting of duplicates"
  509:                     "issue with numpy>=1.25 with AVX instructions"
  510:                 ),
  511:                 strict=False,
  512:             )
  513:         )
  514:     gp = nulls_df.groupby(["A", "B"], dropna=group_dropna)
  515:     result = gp.value_counts(normalize=True, sort=True, dropna=count_dropna)
  516:     columns = DataFrame()
  517:     for column in nulls_df.columns:
  518:         columns[column] = [nulls_df[column][row] for row in expected_rows]
  519:     index = MultiIndex.from_frame(columns)
  520:     expected = Series(data=expected_values, index=index, name="proportion")
  521:     tm.assert_series_equal(result, expected)
  522: 
  523: 
  524: @pytest.fixture
  525: def names_with_nulls_df(nulls_fixture):
  526:     return DataFrame(
  527:         {
  528:             "key": [1, 1, 1, 1],
  529:             "first_name": ["John", "Anne", "John", "Beth"],
  530:             "middle_name": ["Smith", nulls_fixture, nulls_fixture, "Louise"],
  531:         },
  532:     )
  533: 
  534: 
  535: @pytest.mark.parametrize(
  536:     "dropna, expected_data, expected_index",
  537:     [
  538:         (
  539:             True,
  540:             [1, 1],
  541:             MultiIndex.from_arrays(
  542:                 [(1, 1), ("Beth", "John"), ("Louise", "Smith")],
  543:                 names=["key", "first_name", "middle_name"],
  544:             ),
  545:         ),
  546:         (
  547:             False,
  548:             [1, 1, 1, 1],
  549:             MultiIndex(
  550:                 levels=[
  551:                     Index([1]),
  552:                     Index(["Anne", "Beth", "John"]),
  553:                     Index(["Louise", "Smith", np.nan]),
  554:                 ],
  555:                 codes=[[0, 0, 0, 0], [0, 1, 2, 2], [2, 0, 1, 2]],
  556:                 names=["key", "first_name", "middle_name"],
  557:             ),
  558:         ),
  559:     ],
  560: )
  561: @pytest.mark.parametrize("normalize, name", [(False, "count"), (True, "proportion")])
  562: def test_data_frame_value_counts_dropna(
  563:     names_with_nulls_df, dropna, normalize, name, expected_data, expected_index
  564: ):
  565:     # GH 41334
  566:     # 3-way compare with :meth:`~DataFrame.value_counts`
  567:     # Tests with nulls from frame/methods/test_value_counts.py
  568:     result_frame = names_with_nulls_df.value_counts(dropna=dropna, normalize=normalize)
  569:     expected = Series(
  570:         data=expected_data,
  571:         index=expected_index,
  572:         name=name,
  573:     )
  574:     if normalize:
  575:         expected /= float(len(expected_data))
  576: 
  577:     tm.assert_series_equal(result_frame, expected)
  578: 
  579:     result_frame_groupby = names_with_nulls_df.groupby("key").value_counts(
  580:         dropna=dropna, normalize=normalize
  581:     )
  582: 
  583:     tm.assert_series_equal(result_frame_groupby, expected)
  584: 
  585: 
  586: @pytest.mark.parametrize("as_index", [False, True])
  587: @pytest.mark.parametrize("observed", [False, True])
  588: @pytest.mark.parametrize(
  589:     "normalize, name, expected_data",
  590:     [
  591:         (
  592:             False,
  593:             "count",
  594:             np.array([2, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0], dtype=np.int64),
  595:         ),
  596:         (
  597:             True,
  598:             "proportion",
  599:             np.array([0.5, 0.25, 0.25, 0.0, 0.0, 0.0, 0.5, 0.5, 0.0, 0.0, 0.0, 0.0]),
  600:         ),
  601:     ],
  602: )
  603: def test_categorical_single_grouper_with_only_observed_categories(
  604:     education_df, as_index, observed, normalize, name, expected_data, request
  605: ):
  606:     # Test single categorical grouper with only observed grouping categories
  607:     # when non-groupers are also categorical
  608:     if Version(np.__version__) >= Version("1.25"):
  609:         request.applymarker(
  610:             pytest.mark.xfail(
  611:                 reason=(
  612:                     "pandas default unstable sorting of duplicates"
  613:                     "issue with numpy>=1.25 with AVX instructions"
  614:                 ),
  615:                 strict=False,
  616:             )
  617:         )
  618: 
  619:     gp = education_df.astype("category").groupby(
  620:         "country", as_index=as_index, observed=observed
  621:     )
  622:     result = gp.value_counts(normalize=normalize)
  623: 
  624:     expected_index = MultiIndex.from_tuples(
  625:         [
  626:             ("FR", "male", "low"),
  627:             ("FR", "female", "high"),
  628:             ("FR", "male", "medium"),
  629:             ("FR", "female", "low"),
  630:             ("FR", "female", "medium"),
  631:             ("FR", "male", "high"),
  632:             ("US", "female", "high"),
  633:             ("US", "male", "low"),
  634:             ("US", "female", "low"),
  635:             ("US", "female", "medium"),
  636:             ("US", "male", "high"),
  637:             ("US", "male", "medium"),
  638:         ],
  639:         names=["country", "gender", "education"],
  640:     )
  641: 
  642:     expected_series = Series(
  643:         data=expected_data,
  644:         index=expected_index,
  645:         name=name,
  646:     )
  647:     for i in range(3):
  648:         expected_series.index = expected_series.index.set_levels(
  649:             CategoricalIndex(expected_series.index.levels[i]), level=i
  650:         )
  651: 
  652:     if as_index:
  653:         tm.assert_series_equal(result, expected_series)
  654:     else:
  655:         expected = expected_series.reset_index(
  656:             name="proportion" if normalize else "count"
  657:         )
  658:         tm.assert_frame_equal(result, expected)
  659: 
  660: 
  661: def assert_categorical_single_grouper(
  662:     education_df, as_index, observed, expected_index, normalize, name, expected_data
  663: ):
  664:     # Test single categorical grouper when non-groupers are also categorical
  665:     education_df = education_df.copy().astype("category")
  666: 
  667:     # Add non-observed grouping categories
  668:     education_df["country"] = education_df["country"].cat.add_categories(["ASIA"])
  669: 
  670:     gp = education_df.groupby("country", as_index=as_index, observed=observed)
  671:     result = gp.value_counts(normalize=normalize)
  672: 
  673:     expected_series = Series(
  674:         data=expected_data,
  675:         index=MultiIndex.from_tuples(
  676:             expected_index,
  677:             names=["country", "gender", "education"],
  678:         ),
  679:         name=name,
  680:     )
  681:     for i in range(3):
  682:         index_level = CategoricalIndex(expected_series.index.levels[i])
  683:         if i == 0:
  684:             index_level = index_level.set_categories(
  685:                 education_df["country"].cat.categories
  686:             )
  687:         expected_series.index = expected_series.index.set_levels(index_level, level=i)
  688: 
  689:     if as_index:
  690:         tm.assert_series_equal(result, expected_series)
  691:     else:
  692:         expected = expected_series.reset_index(name=name)
  693:         tm.assert_frame_equal(result, expected)
  694: 
  695: 
  696: @pytest.mark.parametrize("as_index", [True, False])
  697: @pytest.mark.parametrize(
  698:     "normalize, name, expected_data",
  699:     [
  700:         (
  701:             False,
  702:             "count",
  703:             np.array([2, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0], dtype=np.int64),
  704:         ),
  705:         (
  706:             True,
  707:             "proportion",
  708:             np.array([0.5, 0.25, 0.25, 0.0, 0.0, 0.0, 0.5, 0.5, 0.0, 0.0, 0.0, 0.0]),
  709:         ),
  710:     ],
  711: )
  712: def test_categorical_single_grouper_observed_true(
  713:     education_df, as_index, normalize, name, expected_data, request
  714: ):
  715:     # GH#46357
  716: 
  717:     if Version(np.__version__) >= Version("1.25"):
  718:         request.applymarker(
  719:             pytest.mark.xfail(
  720:                 reason=(
  721:                     "pandas default unstable sorting of duplicates"
  722:                     "issue with numpy>=1.25 with AVX instructions"
  723:                 ),
  724:                 strict=False,
  725:             )
  726:         )
  727: 
  728:     expected_index = [
  729:         ("FR", "male", "low"),
  730:         ("FR", "female", "high"),
  731:         ("FR", "male", "medium"),
  732:         ("FR", "female", "low"),
  733:         ("FR", "female", "medium"),
  734:         ("FR", "male", "high"),
  735:         ("US", "female", "high"),
  736:         ("US", "male", "low"),
  737:         ("US", "female", "low"),
  738:         ("US", "female", "medium"),
  739:         ("US", "male", "high"),
  740:         ("US", "male", "medium"),
  741:     ]
  742: 
  743:     assert_categorical_single_grouper(
  744:         education_df=education_df,
  745:         as_index=as_index,
  746:         observed=True,
  747:         expected_index=expected_index,
  748:         normalize=normalize,
  749:         name=name,
  750:         expected_data=expected_data,
  751:     )
  752: 
  753: 
  754: @pytest.mark.parametrize("as_index", [True, False])
  755: @pytest.mark.parametrize(
  756:     "normalize, name, expected_data",
  757:     [
  758:         (
  759:             False,
  760:             "count",
  761:             np.array(
  762:                 [2, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=np.int64
  763:             ),
  764:         ),
  765:         (
  766:             True,
  767:             "proportion",
  768:             np.array(
  769:                 [
  770:                     0.5,
  771:                     0.25,
  772:                     0.25,
  773:                     0.0,
  774:                     0.0,
  775:                     0.0,
  776:                     0.5,
  777:                     0.5,
  778:                     0.0,
  779:                     0.0,
  780:                     0.0,
  781:                     0.0,
  782:                     0.0,
  783:                     0.0,
  784:                     0.0,
  785:                     0.0,
  786:                     0.0,
  787:                     0.0,
  788:                 ]
  789:             ),
  790:         ),
  791:     ],
  792: )
  793: def test_categorical_single_grouper_observed_false(
  794:     education_df, as_index, normalize, name, expected_data, request
  795: ):
  796:     # GH#46357
  797: 
  798:     if Version(np.__version__) >= Version("1.25"):
  799:         request.applymarker(
  800:             pytest.mark.xfail(
  801:                 reason=(
  802:                     "pandas default unstable sorting of duplicates"
  803:                     "issue with numpy>=1.25 with AVX instructions"
  804:                 ),
  805:                 strict=False,
  806:             )
  807:         )
  808: 
  809:     expected_index = [
  810:         ("FR", "male", "low"),
  811:         ("FR", "female", "high"),
  812:         ("FR", "male", "medium"),
  813:         ("FR", "female", "low"),
  814:         ("FR", "female", "medium"),
  815:         ("FR", "male", "high"),
  816:         ("US", "female", "high"),
  817:         ("US", "male", "low"),
  818:         ("US", "female", "low"),
  819:         ("US", "female", "medium"),
  820:         ("US", "male", "high"),
  821:         ("US", "male", "medium"),
  822:         ("ASIA", "female", "high"),
  823:         ("ASIA", "female", "low"),
  824:         ("ASIA", "female", "medium"),
  825:         ("ASIA", "male", "high"),
  826:         ("ASIA", "male", "low"),
  827:         ("ASIA", "male", "medium"),
  828:     ]
  829: 
  830:     assert_categorical_single_grouper(
  831:         education_df=education_df,
  832:         as_index=as_index,
  833:         observed=False,
  834:         expected_index=expected_index,
  835:         normalize=normalize,
  836:         name=name,
  837:         expected_data=expected_data,
  838:     )
  839: 
  840: 
  841: @pytest.mark.parametrize("as_index", [True, False])
  842: @pytest.mark.parametrize(
  843:     "observed, expected_index",
  844:     [
  845:         (
  846:             False,
  847:             [
  848:                 ("FR", "high", "female"),
  849:                 ("FR", "high", "male"),
  850:                 ("FR", "low", "male"),
  851:                 ("FR", "low", "female"),
  852:                 ("FR", "medium", "male"),
  853:                 ("FR", "medium", "female"),
  854:                 ("US", "high", "female"),
  855:                 ("US", "high", "male"),
  856:                 ("US", "low", "male"),
  857:                 ("US", "low", "female"),
  858:                 ("US", "medium", "female"),
  859:                 ("US", "medium", "male"),
  860:             ],
  861:         ),
  862:         (
  863:             True,
  864:             [
  865:                 ("FR", "high", "female"),
  866:                 ("FR", "low", "male"),
  867:                 ("FR", "medium", "male"),
  868:                 ("US", "high", "female"),
  869:                 ("US", "low", "male"),
  870:             ],
  871:         ),
  872:     ],
  873: )
  874: @pytest.mark.parametrize(
  875:     "normalize, name, expected_data",
  876:     [
  877:         (
  878:             False,
  879:             "count",
  880:             np.array([1, 0, 2, 0, 1, 0, 1, 0, 1, 0, 0, 0], dtype=np.int64),
  881:         ),
  882:         (
  883:             True,
  884:             "proportion",
  885:             # NaN values corresponds to non-observed groups
  886:             np.array([1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0]),
  887:         ),
  888:     ],
  889: )
  890: def test_categorical_multiple_groupers(
  891:     education_df, as_index, observed, expected_index, normalize, name, expected_data
  892: ):
  893:     # GH#46357
  894: 
  895:     # Test multiple categorical groupers when non-groupers are non-categorical
  896:     education_df = education_df.copy()
  897:     education_df["country"] = education_df["country"].astype("category")
  898:     education_df["education"] = education_df["education"].astype("category")
  899: 
  900:     gp = education_df.groupby(
  901:         ["country", "education"], as_index=as_index, observed=observed
  902:     )
  903:     result = gp.value_counts(normalize=normalize)
  904: 
  905:     expected_series = Series(
  906:         data=expected_data[expected_data > 0.0] if observed else expected_data,
  907:         index=MultiIndex.from_tuples(
  908:             expected_index,
  909:             names=["country", "education", "gender"],
  910:         ),
  911:         name=name,
  912:     )
  913:     for i in range(2):
  914:         expected_series.index = expected_series.index.set_levels(
  915:             CategoricalIndex(expected_series.index.levels[i]), level=i
  916:         )
  917: 
  918:     if as_index:
  919:         tm.assert_series_equal(result, expected_series)
  920:     else:
  921:         expected = expected_series.reset_index(
  922:             name="proportion" if normalize else "count"
  923:         )
  924:         tm.assert_frame_equal(result, expected)
  925: 
  926: 
  927: @pytest.mark.parametrize("as_index", [False, True])
  928: @pytest.mark.parametrize("observed", [False, True])
  929: @pytest.mark.parametrize(
  930:     "normalize, name, expected_data",
  931:     [
  932:         (
  933:             False,
  934:             "count",
  935:             np.array([2, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0], dtype=np.int64),
  936:         ),
  937:         (
  938:             True,
  939:             "proportion",
  940:             # NaN values corresponds to non-observed groups
  941:             np.array([0.5, 0.25, 0.25, 0.0, 0.0, 0.0, 0.5, 0.5, 0.0, 0.0, 0.0, 0.0]),
  942:         ),
  943:     ],
  944: )
  945: def test_categorical_non_groupers(
  946:     education_df, as_index, observed, normalize, name, expected_data, request
  947: ):
  948:     # GH#46357 Test non-observed categories are included in the result,
  949:     # regardless of `observed`
  950: 
  951:     if Version(np.__version__) >= Version("1.25"):
  952:         request.applymarker(
  953:             pytest.mark.xfail(
  954:                 reason=(
  955:                     "pandas default unstable sorting of duplicates"
  956:                     "issue with numpy>=1.25 with AVX instructions"
  957:                 ),
  958:                 strict=False,
  959:             )
  960:         )
  961: 
  962:     education_df = education_df.copy()
  963:     education_df["gender"] = education_df["gender"].astype("category")
  964:     education_df["education"] = education_df["education"].astype("category")
  965: 
  966:     gp = education_df.groupby("country", as_index=as_index, observed=observed)
  967:     result = gp.value_counts(normalize=normalize)
  968: 
  969:     expected_index = [
  970:         ("FR", "male", "low"),
  971:         ("FR", "female", "high"),
  972:         ("FR", "male", "medium"),
  973:         ("FR", "female", "low"),
  974:         ("FR", "female", "medium"),
  975:         ("FR", "male", "high"),
  976:         ("US", "female", "high"),
  977:         ("US", "male", "low"),
  978:         ("US", "female", "low"),
  979:         ("US", "female", "medium"),
  980:         ("US", "male", "high"),
  981:         ("US", "male", "medium"),
  982:     ]
  983:     expected_series = Series(
  984:         data=expected_data,
  985:         index=MultiIndex.from_tuples(
  986:             expected_index,
  987:             names=["country", "gender", "education"],
  988:         ),
  989:         name=name,
  990:     )
  991:     for i in range(1, 3):
  992:         expected_series.index = expected_series.index.set_levels(
  993:             CategoricalIndex(expected_series.index.levels[i]), level=i
  994:         )
  995: 
  996:     if as_index:
  997:         tm.assert_series_equal(result, expected_series)
  998:     else:
  999:         expected = expected_series.reset_index(
 1000:             name="proportion" if normalize else "count"
 1001:         )
 1002:         tm.assert_frame_equal(result, expected)
 1003: 
 1004: 
 1005: @pytest.mark.parametrize(
 1006:     "normalize, expected_label, expected_values",
 1007:     [
 1008:         (False, "count", [1, 1, 1]),
 1009:         (True, "proportion", [0.5, 0.5, 1.0]),
 1010:     ],
 1011: )
 1012: def test_mixed_groupings(normalize, expected_label, expected_values):
 1013:     # Test multiple groupings
 1014:     df = DataFrame({"A": [1, 2, 1], "B": [1, 2, 3]})
 1015:     gp = df.groupby([[4, 5, 4], "A", lambda i: 7 if i == 1 else 8], as_index=False)
 1016:     result = gp.value_counts(sort=True, normalize=normalize)
 1017:     expected = DataFrame(
 1018:         {
 1019:             "level_0": np.array([4, 4, 5], dtype=int),
 1020:             "A": [1, 1, 2],
 1021:             "level_2": [8, 8, 7],
 1022:             "B": [1, 3, 2],
 1023:             expected_label: expected_values,
 1024:         }
 1025:     )
 1026:     tm.assert_frame_equal(result, expected)
 1027: 
 1028: 
 1029: @pytest.mark.parametrize(
 1030:     "test, columns, expected_names",
 1031:     [
 1032:         ("repeat", list("abbde"), ["a", None, "d", "b", "b", "e"]),
 1033:         ("level", list("abcd") + ["level_1"], ["a", None, "d", "b", "c", "level_1"]),
 1034:     ],
 1035: )
 1036: @pytest.mark.parametrize("as_index", [False, True])
 1037: def test_column_label_duplicates(test, columns, expected_names, as_index):
 1038:     # GH 44992
 1039:     # Test for duplicate input column labels and generated duplicate labels
 1040:     df = DataFrame([[1, 3, 5, 7, 9], [2, 4, 6, 8, 10]], columns=columns)
 1041:     expected_data = [(1, 0, 7, 3, 5, 9), (2, 1, 8, 4, 6, 10)]
 1042:     keys = ["a", np.array([0, 1], dtype=np.int64), "d"]
 1043:     result = df.groupby(keys, as_index=as_index).value_counts()
 1044:     if as_index:
 1045:         expected = Series(
 1046:             data=(1, 1),
 1047:             index=MultiIndex.from_tuples(
 1048:                 expected_data,
 1049:                 names=expected_names,
 1050:             ),
 1051:             name="count",
 1052:         )
 1053:         tm.assert_series_equal(result, expected)
 1054:     else:
 1055:         expected_data = [list(row) + [1] for row in expected_data]
 1056:         expected_columns = list(expected_names)
 1057:         expected_columns[1] = "level_1"
 1058:         expected_columns.append("count")
 1059:         expected = DataFrame(expected_data, columns=expected_columns)
 1060:         tm.assert_frame_equal(result, expected)
 1061: 
 1062: 
 1063: @pytest.mark.parametrize(
 1064:     "normalize, expected_label",
 1065:     [
 1066:         (False, "count"),
 1067:         (True, "proportion"),
 1068:     ],
 1069: )
 1070: def test_result_label_duplicates(normalize, expected_label):
 1071:     # Test for result column label duplicating an input column label
 1072:     gb = DataFrame([[1, 2, 3]], columns=["a", "b", expected_label]).groupby(
 1073:         "a", as_index=False
 1074:     )
 1075:     msg = f"Column label '{expected_label}' is duplicate of result column"
 1076:     with pytest.raises(ValueError, match=msg):
 1077:         gb.value_counts(normalize=normalize)
 1078: 
 1079: 
 1080: def test_ambiguous_grouping():
 1081:     # Test that groupby is not confused by groupings length equal to row count
 1082:     df = DataFrame({"a": [1, 1]})
 1083:     gb = df.groupby(np.array([1, 1], dtype=np.int64))
 1084:     result = gb.value_counts()
 1085:     expected = Series(
 1086:         [2], index=MultiIndex.from_tuples([[1, 1]], names=[None, "a"]), name="count"
 1087:     )
 1088:     tm.assert_series_equal(result, expected)
 1089: 
 1090: 
 1091: def test_subset_overlaps_gb_key_raises():
 1092:     # GH 46383
 1093:     df = DataFrame({"c1": ["a", "b", "c"], "c2": ["x", "y", "y"]}, index=[0, 1, 1])
 1094:     msg = "Keys {'c1'} in subset cannot be in the groupby column keys."
 1095:     with pytest.raises(ValueError, match=msg):
 1096:         df.groupby("c1").value_counts(subset=["c1"])
 1097: 
 1098: 
 1099: def test_subset_doesnt_exist_in_frame():
 1100:     # GH 46383
 1101:     df = DataFrame({"c1": ["a", "b", "c"], "c2": ["x", "y", "y"]}, index=[0, 1, 1])
 1102:     msg = "Keys {'c3'} in subset do not exist in the DataFrame."
 1103:     with pytest.raises(ValueError, match=msg):
 1104:         df.groupby("c1").value_counts(subset=["c3"])
 1105: 
 1106: 
 1107: def test_subset():
 1108:     # GH 46383
 1109:     df = DataFrame({"c1": ["a", "b", "c"], "c2": ["x", "y", "y"]}, index=[0, 1, 1])
 1110:     result = df.groupby(level=0).value_counts(subset=["c2"])
 1111:     expected = Series(
 1112:         [1, 2],
 1113:         index=MultiIndex.from_arrays([[0, 1], ["x", "y"]], names=[None, "c2"]),
 1114:         name="count",
 1115:     )
 1116:     tm.assert_series_equal(result, expected)
 1117: 
 1118: 
 1119: def test_subset_duplicate_columns():
 1120:     # GH 46383
 1121:     df = DataFrame(
 1122:         [["a", "x", "x"], ["b", "y", "y"], ["b", "y", "y"]],
 1123:         index=[0, 1, 1],
 1124:         columns=["c1", "c2", "c2"],
 1125:     )
 1126:     result = df.groupby(level=0).value_counts(subset=["c2"])
 1127:     expected = Series(
 1128:         [1, 2],
 1129:         index=MultiIndex.from_arrays(
 1130:             [[0, 1], ["x", "y"], ["x", "y"]], names=[None, "c2", "c2"]
 1131:         ),
 1132:         name="count",
 1133:     )
 1134:     tm.assert_series_equal(result, expected)
 1135: 
 1136: 
 1137: @pytest.mark.parametrize("utc", [True, False])
 1138: def test_value_counts_time_grouper(utc, unit):
 1139:     # GH#50486
 1140:     df = DataFrame(
 1141:         {
 1142:             "Timestamp": [
 1143:                 1565083561,
 1144:                 1565083561 + 86400,
 1145:                 1565083561 + 86500,
 1146:                 1565083561 + 86400 * 2,
 1147:                 1565083561 + 86400 * 3,
 1148:                 1565083561 + 86500 * 3,
 1149:                 1565083561 + 86400 * 4,
 1150:             ],
 1151:             "Food": ["apple", "apple", "banana", "banana", "orange", "orange", "pear"],
 1152:         }
 1153:     ).drop([3])
 1154: 
 1155:     df["Datetime"] = to_datetime(df["Timestamp"], utc=utc, unit="s").dt.as_unit(unit)
 1156:     gb = df.groupby(Grouper(freq="1D", key="Datetime"))
 1157:     result = gb.value_counts()
 1158:     dates = to_datetime(
 1159:         ["2019-08-06", "2019-08-07", "2019-08-09", "2019-08-10"], utc=utc
 1160:     ).as_unit(unit)
 1161:     timestamps = df["Timestamp"].unique()
 1162:     index = MultiIndex(
 1163:         levels=[dates, timestamps, ["apple", "banana", "orange", "pear"]],
 1164:         codes=[[0, 1, 1, 2, 2, 3], range(6), [0, 0, 1, 2, 2, 3]],
 1165:         names=["Datetime", "Timestamp", "Food"],
 1166:     )
 1167:     expected = Series(1, index=index, name="count")
 1168:     tm.assert_series_equal(result, expected)
 1169: 
 1170: 
 1171: def test_value_counts_integer_columns():
 1172:     # GH#55627
 1173:     df = DataFrame({1: ["a", "a", "a"], 2: ["a", "a", "d"], 3: ["a", "b", "c"]})
 1174:     gp = df.groupby([1, 2], as_index=False, sort=False)
 1175:     result = gp[3].value_counts()
 1176:     expected = DataFrame(
 1177:         {1: ["a", "a", "a"], 2: ["a", "a", "d"], 3: ["a", "b", "c"], "count": 1}
 1178:     )
 1179:     tm.assert_frame_equal(result, expected)
 1180: 
 1181: 
 1182: @pytest.mark.parametrize("vc_sort", [True, False])
 1183: @pytest.mark.parametrize("normalize", [True, False])
 1184: def test_value_counts_sort(sort, vc_sort, normalize):
 1185:     # GH#55951
 1186:     df = DataFrame({"a": [2, 1, 1, 1], 0: [3, 4, 3, 3]})
 1187:     gb = df.groupby("a", sort=sort)
 1188:     result = gb.value_counts(sort=vc_sort, normalize=normalize)
 1189: 
 1190:     if normalize:
 1191:         values = [2 / 3, 1 / 3, 1.0]
 1192:     else:
 1193:         values = [2, 1, 1]
 1194:     index = MultiIndex(
 1195:         levels=[[1, 2], [3, 4]], codes=[[0, 0, 1], [0, 1, 0]], names=["a", 0]
 1196:     )
 1197:     expected = Series(values, index=index, name="proportion" if normalize else "count")
 1198:     if sort and vc_sort:
 1199:         taker = [0, 1, 2]
 1200:     elif sort and not vc_sort:
 1201:         taker = [0, 1, 2]
 1202:     elif not sort and vc_sort:
 1203:         taker = [0, 2, 1]
 1204:     else:
 1205:         taker = [2, 1, 0]
 1206:     expected = expected.take(taker)
 1207: 
 1208:     tm.assert_series_equal(result, expected)
 1209: 
 1210: 
 1211: @pytest.mark.parametrize("vc_sort", [True, False])
 1212: @pytest.mark.parametrize("normalize", [True, False])
 1213: def test_value_counts_sort_categorical(sort, vc_sort, normalize):
 1214:     # GH#55951
 1215:     df = DataFrame({"a": [2, 1, 1, 1], 0: [3, 4, 3, 3]}, dtype="category")
 1216:     gb = df.groupby("a", sort=sort, observed=True)
 1217:     result = gb.value_counts(sort=vc_sort, normalize=normalize)
 1218: 
 1219:     if normalize:
 1220:         values = [2 / 3, 1 / 3, 1.0, 0.0]
 1221:     else:
 1222:         values = [2, 1, 1, 0]
 1223:     name = "proportion" if normalize else "count"
 1224:     expected = DataFrame(
 1225:         {
 1226:             "a": Categorical([1, 1, 2, 2]),
 1227:             0: Categorical([3, 4, 3, 4]),
 1228:             name: values,
 1229:         }
 1230:     ).set_index(["a", 0])[name]
 1231:     if sort and vc_sort:
 1232:         taker = [0, 1, 2, 3]
 1233:     elif sort and not vc_sort:
 1234:         taker = [0, 1, 2, 3]
 1235:     elif not sort and vc_sort:
 1236:         taker = [0, 2, 1, 3]
 1237:     else:
 1238:         taker = [2, 3, 0, 1]
 1239:     expected = expected.take(taker)
 1240: 
 1241:     tm.assert_series_equal(result, expected)
