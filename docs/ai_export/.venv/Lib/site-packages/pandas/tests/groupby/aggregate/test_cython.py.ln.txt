    1: """
    2: test cython .agg behavior
    3: """
    4: 
    5: import numpy as np
    6: import pytest
    7: 
    8: from pandas.core.dtypes.common import (
    9:     is_float_dtype,
   10:     is_integer_dtype,
   11: )
   12: 
   13: import pandas as pd
   14: from pandas import (
   15:     DataFrame,
   16:     Index,
   17:     NaT,
   18:     Series,
   19:     Timedelta,
   20:     Timestamp,
   21:     bdate_range,
   22: )
   23: import pandas._testing as tm
   24: import pandas.core.common as com
   25: 
   26: 
   27: @pytest.mark.parametrize(
   28:     "op_name",
   29:     [
   30:         "count",
   31:         "sum",
   32:         "std",
   33:         "var",
   34:         "sem",
   35:         "mean",
   36:         pytest.param(
   37:             "median",
   38:             # ignore mean of empty slice
   39:             # and all-NaN
   40:             marks=[pytest.mark.filterwarnings("ignore::RuntimeWarning")],
   41:         ),
   42:         "prod",
   43:         "min",
   44:         "max",
   45:     ],
   46: )
   47: def test_cythonized_aggers(op_name):
   48:     data = {
   49:         "A": [0, 0, 0, 0, 1, 1, 1, 1, 1, 1.0, np.nan, np.nan],
   50:         "B": ["A", "B"] * 6,
   51:         "C": np.random.default_rng(2).standard_normal(12),
   52:     }
   53:     df = DataFrame(data)
   54:     df.loc[2:10:2, "C"] = np.nan
   55: 
   56:     op = lambda x: getattr(x, op_name)()
   57: 
   58:     # single column
   59:     grouped = df.drop(["B"], axis=1).groupby("A")
   60:     exp = {cat: op(group["C"]) for cat, group in grouped}
   61:     exp = DataFrame({"C": exp})
   62:     exp.index.name = "A"
   63:     result = op(grouped)
   64:     tm.assert_frame_equal(result, exp)
   65: 
   66:     # multiple columns
   67:     grouped = df.groupby(["A", "B"])
   68:     expd = {}
   69:     for (cat1, cat2), group in grouped:
   70:         expd.setdefault(cat1, {})[cat2] = op(group["C"])
   71:     exp = DataFrame(expd).T.stack(future_stack=True)
   72:     exp.index.names = ["A", "B"]
   73:     exp.name = "C"
   74: 
   75:     result = op(grouped)["C"]
   76:     if op_name in ["sum", "prod"]:
   77:         tm.assert_series_equal(result, exp)
   78: 
   79: 
   80: def test_cython_agg_boolean():
   81:     frame = DataFrame(
   82:         {
   83:             "a": np.random.default_rng(2).integers(0, 5, 50),
   84:             "b": np.random.default_rng(2).integers(0, 2, 50).astype("bool"),
   85:         }
   86:     )
   87:     result = frame.groupby("a")["b"].mean()
   88:     msg = "using SeriesGroupBy.mean"
   89:     with tm.assert_produces_warning(FutureWarning, match=msg):
   90:         # GH#53425
   91:         expected = frame.groupby("a")["b"].agg(np.mean)
   92: 
   93:     tm.assert_series_equal(result, expected)
   94: 
   95: 
   96: def test_cython_agg_nothing_to_agg():
   97:     frame = DataFrame(
   98:         {"a": np.random.default_rng(2).integers(0, 5, 50), "b": ["foo", "bar"] * 25}
   99:     )
  100: 
  101:     msg = "Cannot use numeric_only=True with SeriesGroupBy.mean and non-numeric dtypes"
  102:     with pytest.raises(TypeError, match=msg):
  103:         frame.groupby("a")["b"].mean(numeric_only=True)
  104: 
  105:     frame = DataFrame(
  106:         {"a": np.random.default_rng(2).integers(0, 5, 50), "b": ["foo", "bar"] * 25}
  107:     )
  108: 
  109:     result = frame[["b"]].groupby(frame["a"]).mean(numeric_only=True)
  110:     expected = DataFrame(
  111:         [], index=frame["a"].sort_values().drop_duplicates(), columns=[]
  112:     )
  113:     tm.assert_frame_equal(result, expected)
  114: 
  115: 
  116: def test_cython_agg_nothing_to_agg_with_dates():
  117:     frame = DataFrame(
  118:         {
  119:             "a": np.random.default_rng(2).integers(0, 5, 50),
  120:             "b": ["foo", "bar"] * 25,
  121:             "dates": pd.date_range("now", periods=50, freq="min"),
  122:         }
  123:     )
  124:     msg = "Cannot use numeric_only=True with SeriesGroupBy.mean and non-numeric dtypes"
  125:     with pytest.raises(TypeError, match=msg):
  126:         frame.groupby("b").dates.mean(numeric_only=True)
  127: 
  128: 
  129: def test_cython_agg_frame_columns():
  130:     # #2113
  131:     df = DataFrame({"x": [1, 2, 3], "y": [3, 4, 5]})
  132: 
  133:     msg = "DataFrame.groupby with axis=1 is deprecated"
  134:     with tm.assert_produces_warning(FutureWarning, match=msg):
  135:         df.groupby(level=0, axis="columns").mean()
  136:     with tm.assert_produces_warning(FutureWarning, match=msg):
  137:         df.groupby(level=0, axis="columns").mean()
  138:     with tm.assert_produces_warning(FutureWarning, match=msg):
  139:         df.groupby(level=0, axis="columns").mean()
  140:     with tm.assert_produces_warning(FutureWarning, match=msg):
  141:         df.groupby(level=0, axis="columns").mean()
  142: 
  143: 
  144: def test_cython_agg_return_dict():
  145:     # GH 16741
  146:     df = DataFrame(
  147:         {
  148:             "A": ["foo", "bar", "foo", "bar", "foo", "bar", "foo", "foo"],
  149:             "B": ["one", "one", "two", "three", "two", "two", "one", "three"],
  150:             "C": np.random.default_rng(2).standard_normal(8),
  151:             "D": np.random.default_rng(2).standard_normal(8),
  152:         }
  153:     )
  154: 
  155:     ts = df.groupby("A")["B"].agg(lambda x: x.value_counts().to_dict())
  156:     expected = Series(
  157:         [{"two": 1, "one": 1, "three": 1}, {"two": 2, "one": 2, "three": 1}],
  158:         index=Index(["bar", "foo"], name="A"),
  159:         name="B",
  160:     )
  161:     tm.assert_series_equal(ts, expected)
  162: 
  163: 
  164: def test_cython_fail_agg():
  165:     dr = bdate_range("1/1/2000", periods=50)
  166:     ts = Series(["A", "B", "C", "D", "E"] * 10, index=dr)
  167: 
  168:     grouped = ts.groupby(lambda x: x.month)
  169:     summed = grouped.sum()
  170:     msg = "using SeriesGroupBy.sum"
  171:     with tm.assert_produces_warning(FutureWarning, match=msg):
  172:         # GH#53425
  173:         expected = grouped.agg(np.sum)
  174:     tm.assert_series_equal(summed, expected)
  175: 
  176: 
  177: @pytest.mark.parametrize(
  178:     "op, targop",
  179:     [
  180:         ("mean", np.mean),
  181:         ("median", np.median),
  182:         ("var", np.var),
  183:         ("sum", np.sum),
  184:         ("prod", np.prod),
  185:         ("min", np.min),
  186:         ("max", np.max),
  187:         ("first", lambda x: x.iloc[0]),
  188:         ("last", lambda x: x.iloc[-1]),
  189:     ],
  190: )
  191: def test__cython_agg_general(op, targop):
  192:     df = DataFrame(np.random.default_rng(2).standard_normal(1000))
  193:     labels = np.random.default_rng(2).integers(0, 50, size=1000).astype(float)
  194: 
  195:     result = df.groupby(labels)._cython_agg_general(op, alt=None, numeric_only=True)
  196:     warn = FutureWarning if targop in com._cython_table else None
  197:     msg = f"using DataFrameGroupBy.{op}"
  198:     with tm.assert_produces_warning(warn, match=msg):
  199:         # GH#53425
  200:         expected = df.groupby(labels).agg(targop)
  201:     tm.assert_frame_equal(result, expected)
  202: 
  203: 
  204: @pytest.mark.parametrize(
  205:     "op, targop",
  206:     [
  207:         ("mean", np.mean),
  208:         ("median", lambda x: np.median(x) if len(x) > 0 else np.nan),
  209:         ("var", lambda x: np.var(x, ddof=1)),
  210:         ("min", np.min),
  211:         ("max", np.max),
  212:     ],
  213: )
  214: def test_cython_agg_empty_buckets(op, targop, observed):
  215:     df = DataFrame([11, 12, 13])
  216:     grps = range(0, 55, 5)
  217: 
  218:     # calling _cython_agg_general directly, instead of via the user API
  219:     # which sets different values for min_count, so do that here.
  220:     g = df.groupby(pd.cut(df[0], grps), observed=observed)
  221:     result = g._cython_agg_general(op, alt=None, numeric_only=True)
  222: 
  223:     g = df.groupby(pd.cut(df[0], grps), observed=observed)
  224:     expected = g.agg(lambda x: targop(x))
  225:     tm.assert_frame_equal(result, expected)
  226: 
  227: 
  228: def test_cython_agg_empty_buckets_nanops(observed):
  229:     # GH-18869 can't call nanops on empty groups, so hardcode expected
  230:     # for these
  231:     df = DataFrame([11, 12, 13], columns=["a"])
  232:     grps = np.arange(0, 25, 5, dtype=int)
  233:     # add / sum
  234:     result = df.groupby(pd.cut(df["a"], grps), observed=observed)._cython_agg_general(
  235:         "sum", alt=None, numeric_only=True
  236:     )
  237:     intervals = pd.interval_range(0, 20, freq=5)
  238:     expected = DataFrame(
  239:         {"a": [0, 0, 36, 0]},
  240:         index=pd.CategoricalIndex(intervals, name="a", ordered=True),
  241:     )
  242:     if observed:
  243:         expected = expected[expected.a != 0]
  244: 
  245:     tm.assert_frame_equal(result, expected)
  246: 
  247:     # prod
  248:     result = df.groupby(pd.cut(df["a"], grps), observed=observed)._cython_agg_general(
  249:         "prod", alt=None, numeric_only=True
  250:     )
  251:     expected = DataFrame(
  252:         {"a": [1, 1, 1716, 1]},
  253:         index=pd.CategoricalIndex(intervals, name="a", ordered=True),
  254:     )
  255:     if observed:
  256:         expected = expected[expected.a != 1]
  257: 
  258:     tm.assert_frame_equal(result, expected)
  259: 
  260: 
  261: @pytest.mark.parametrize("op", ["first", "last", "max", "min"])
  262: @pytest.mark.parametrize(
  263:     "data", [Timestamp("2016-10-14 21:00:44.557"), Timedelta("17088 days 21:00:44.557")]
  264: )
  265: def test_cython_with_timestamp_and_nat(op, data):
  266:     # https://github.com/pandas-dev/pandas/issues/19526
  267:     df = DataFrame({"a": [0, 1], "b": [data, NaT]})
  268:     index = Index([0, 1], name="a")
  269: 
  270:     # We will group by a and test the cython aggregations
  271:     expected = DataFrame({"b": [data, NaT]}, index=index)
  272: 
  273:     result = df.groupby("a").aggregate(op)
  274:     tm.assert_frame_equal(expected, result)
  275: 
  276: 
  277: @pytest.mark.parametrize(
  278:     "agg",
  279:     [
  280:         "min",
  281:         "max",
  282:         "count",
  283:         "sum",
  284:         "prod",
  285:         "var",
  286:         "mean",
  287:         "median",
  288:         "ohlc",
  289:         "cumprod",
  290:         "cumsum",
  291:         "shift",
  292:         "any",
  293:         "all",
  294:         "quantile",
  295:         "first",
  296:         "last",
  297:         "rank",
  298:         "cummin",
  299:         "cummax",
  300:     ],
  301: )
  302: def test_read_only_buffer_source_agg(agg):
  303:     # https://github.com/pandas-dev/pandas/issues/36014
  304:     df = DataFrame(
  305:         {
  306:             "sepal_length": [5.1, 4.9, 4.7, 4.6, 5.0],
  307:             "species": ["setosa", "setosa", "setosa", "setosa", "setosa"],
  308:         }
  309:     )
  310:     df._mgr.arrays[0].flags.writeable = False
  311: 
  312:     result = df.groupby(["species"]).agg({"sepal_length": agg})
  313:     expected = df.copy().groupby(["species"]).agg({"sepal_length": agg})
  314: 
  315:     tm.assert_equal(result, expected)
  316: 
  317: 
  318: @pytest.mark.parametrize(
  319:     "op_name",
  320:     [
  321:         "count",
  322:         "sum",
  323:         "std",
  324:         "var",
  325:         "sem",
  326:         "mean",
  327:         "median",
  328:         "prod",
  329:         "min",
  330:         "max",
  331:     ],
  332: )
  333: def test_cython_agg_nullable_int(op_name):
  334:     # ensure that the cython-based aggregations don't fail for nullable dtype
  335:     # (eg https://github.com/pandas-dev/pandas/issues/37415)
  336:     df = DataFrame(
  337:         {
  338:             "A": ["A", "B"] * 5,
  339:             "B": pd.array([1, 2, 3, 4, 5, 6, 7, 8, 9, pd.NA], dtype="Int64"),
  340:         }
  341:     )
  342:     result = getattr(df.groupby("A")["B"], op_name)()
  343:     df2 = df.assign(B=df["B"].astype("float64"))
  344:     expected = getattr(df2.groupby("A")["B"], op_name)()
  345:     if op_name in ("mean", "median"):
  346:         convert_integer = False
  347:     else:
  348:         convert_integer = True
  349:     expected = expected.convert_dtypes(convert_integer=convert_integer)
  350:     tm.assert_series_equal(result, expected)
  351: 
  352: 
  353: @pytest.mark.parametrize("dtype", ["Int64", "Float64", "boolean"])
  354: def test_count_masked_returns_masked_dtype(dtype):
  355:     df = DataFrame(
  356:         {
  357:             "A": [1, 1],
  358:             "B": pd.array([1, pd.NA], dtype=dtype),
  359:             "C": pd.array([1, 1], dtype=dtype),
  360:         }
  361:     )
  362:     result = df.groupby("A").count()
  363:     expected = DataFrame(
  364:         [[1, 2]], index=Index([1], name="A"), columns=["B", "C"], dtype="Int64"
  365:     )
  366:     tm.assert_frame_equal(result, expected)
  367: 
  368: 
  369: @pytest.mark.parametrize("with_na", [True, False])
  370: @pytest.mark.parametrize(
  371:     "op_name, action",
  372:     [
  373:         # ("count", "always_int"),
  374:         ("sum", "large_int"),
  375:         # ("std", "always_float"),
  376:         ("var", "always_float"),
  377:         # ("sem", "always_float"),
  378:         ("mean", "always_float"),
  379:         ("median", "always_float"),
  380:         ("prod", "large_int"),
  381:         ("min", "preserve"),
  382:         ("max", "preserve"),
  383:         ("first", "preserve"),
  384:         ("last", "preserve"),
  385:     ],
  386: )
  387: @pytest.mark.parametrize(
  388:     "data",
  389:     [
  390:         pd.array([1, 2, 3, 4], dtype="Int64"),
  391:         pd.array([1, 2, 3, 4], dtype="Int8"),
  392:         pd.array([0.1, 0.2, 0.3, 0.4], dtype="Float32"),
  393:         pd.array([0.1, 0.2, 0.3, 0.4], dtype="Float64"),
  394:         pd.array([True, True, False, False], dtype="boolean"),
  395:     ],
  396: )
  397: def test_cython_agg_EA_known_dtypes(data, op_name, action, with_na):
  398:     if with_na:
  399:         data[3] = pd.NA
  400: 
  401:     df = DataFrame({"key": ["a", "a", "b", "b"], "col": data})
  402:     grouped = df.groupby("key")
  403: 
  404:     if action == "always_int":
  405:         # always Int64
  406:         expected_dtype = pd.Int64Dtype()
  407:     elif action == "large_int":
  408:         # for any int/bool use Int64, for float preserve dtype
  409:         if is_float_dtype(data.dtype):
  410:             expected_dtype = data.dtype
  411:         elif is_integer_dtype(data.dtype):
  412:             # match the numpy dtype we'd get with the non-nullable analogue
  413:             expected_dtype = data.dtype
  414:         else:
  415:             expected_dtype = pd.Int64Dtype()
  416:     elif action == "always_float":
  417:         # for any int/bool use Float64, for float preserve dtype
  418:         if is_float_dtype(data.dtype):
  419:             expected_dtype = data.dtype
  420:         else:
  421:             expected_dtype = pd.Float64Dtype()
  422:     elif action == "preserve":
  423:         expected_dtype = data.dtype
  424: 
  425:     result = getattr(grouped, op_name)()
  426:     assert result["col"].dtype == expected_dtype
  427: 
  428:     result = grouped.aggregate(op_name)
  429:     assert result["col"].dtype == expected_dtype
  430: 
  431:     result = getattr(grouped["col"], op_name)()
  432:     assert result.dtype == expected_dtype
  433: 
  434:     result = grouped["col"].aggregate(op_name)
  435:     assert result.dtype == expected_dtype
