    1: """
    2: test all other .agg behavior
    3: """
    4: 
    5: import datetime as dt
    6: from functools import partial
    7: 
    8: import numpy as np
    9: import pytest
   10: 
   11: from pandas.errors import SpecificationError
   12: 
   13: import pandas as pd
   14: from pandas import (
   15:     DataFrame,
   16:     Index,
   17:     MultiIndex,
   18:     PeriodIndex,
   19:     Series,
   20:     date_range,
   21:     period_range,
   22: )
   23: import pandas._testing as tm
   24: 
   25: from pandas.io.formats.printing import pprint_thing
   26: 
   27: 
   28: def test_agg_partial_failure_raises():
   29:     # GH#43741
   30: 
   31:     df = DataFrame(
   32:         {
   33:             "data1": np.random.default_rng(2).standard_normal(5),
   34:             "data2": np.random.default_rng(2).standard_normal(5),
   35:             "key1": ["a", "a", "b", "b", "a"],
   36:             "key2": ["one", "two", "one", "two", "one"],
   37:         }
   38:     )
   39:     grouped = df.groupby("key1")
   40: 
   41:     def peak_to_peak(arr):
   42:         return arr.max() - arr.min()
   43: 
   44:     with pytest.raises(TypeError, match="unsupported operand type"):
   45:         grouped.agg([peak_to_peak])
   46: 
   47:     with pytest.raises(TypeError, match="unsupported operand type"):
   48:         grouped.agg(peak_to_peak)
   49: 
   50: 
   51: def test_agg_datetimes_mixed():
   52:     data = [[1, "2012-01-01", 1.0], [2, "2012-01-02", 2.0], [3, None, 3.0]]
   53: 
   54:     df1 = DataFrame(
   55:         {
   56:             "key": [x[0] for x in data],
   57:             "date": [x[1] for x in data],
   58:             "value": [x[2] for x in data],
   59:         }
   60:     )
   61: 
   62:     data = [
   63:         [
   64:             row[0],
   65:             (dt.datetime.strptime(row[1], "%Y-%m-%d").date() if row[1] else None),
   66:             row[2],
   67:         ]
   68:         for row in data
   69:     ]
   70: 
   71:     df2 = DataFrame(
   72:         {
   73:             "key": [x[0] for x in data],
   74:             "date": [x[1] for x in data],
   75:             "value": [x[2] for x in data],
   76:         }
   77:     )
   78: 
   79:     df1["weights"] = df1["value"] / df1["value"].sum()
   80:     gb1 = df1.groupby("date").aggregate("sum")
   81: 
   82:     df2["weights"] = df1["value"] / df1["value"].sum()
   83:     gb2 = df2.groupby("date").aggregate("sum")
   84: 
   85:     assert len(gb1) == len(gb2)
   86: 
   87: 
   88: def test_agg_period_index():
   89:     prng = period_range("2012-1-1", freq="M", periods=3)
   90:     df = DataFrame(np.random.default_rng(2).standard_normal((3, 2)), index=prng)
   91:     rs = df.groupby(level=0).sum()
   92:     assert isinstance(rs.index, PeriodIndex)
   93: 
   94:     # GH 3579
   95:     index = period_range(start="1999-01", periods=5, freq="M")
   96:     s1 = Series(np.random.default_rng(2).random(len(index)), index=index)
   97:     s2 = Series(np.random.default_rng(2).random(len(index)), index=index)
   98:     df = DataFrame.from_dict({"s1": s1, "s2": s2})
   99:     grouped = df.groupby(df.index.month)
  100:     list(grouped)
  101: 
  102: 
  103: def test_agg_dict_parameter_cast_result_dtypes():
  104:     # GH 12821
  105: 
  106:     df = DataFrame(
  107:         {
  108:             "class": ["A", "A", "B", "B", "C", "C", "D", "D"],
  109:             "time": date_range("1/1/2011", periods=8, freq="h"),
  110:         }
  111:     )
  112:     df.loc[[0, 1, 2, 5], "time"] = None
  113: 
  114:     # test for `first` function
  115:     exp = df.loc[[0, 3, 4, 6]].set_index("class")
  116:     grouped = df.groupby("class")
  117:     tm.assert_frame_equal(grouped.first(), exp)
  118:     tm.assert_frame_equal(grouped.agg("first"), exp)
  119:     tm.assert_frame_equal(grouped.agg({"time": "first"}), exp)
  120:     tm.assert_series_equal(grouped.time.first(), exp["time"])
  121:     tm.assert_series_equal(grouped.time.agg("first"), exp["time"])
  122: 
  123:     # test for `last` function
  124:     exp = df.loc[[0, 3, 4, 7]].set_index("class")
  125:     grouped = df.groupby("class")
  126:     tm.assert_frame_equal(grouped.last(), exp)
  127:     tm.assert_frame_equal(grouped.agg("last"), exp)
  128:     tm.assert_frame_equal(grouped.agg({"time": "last"}), exp)
  129:     tm.assert_series_equal(grouped.time.last(), exp["time"])
  130:     tm.assert_series_equal(grouped.time.agg("last"), exp["time"])
  131: 
  132:     # count
  133:     exp = Series([2, 2, 2, 2], index=Index(list("ABCD"), name="class"), name="time")
  134:     tm.assert_series_equal(grouped.time.agg(len), exp)
  135:     tm.assert_series_equal(grouped.time.size(), exp)
  136: 
  137:     exp = Series([0, 1, 1, 2], index=Index(list("ABCD"), name="class"), name="time")
  138:     tm.assert_series_equal(grouped.time.count(), exp)
  139: 
  140: 
  141: def test_agg_cast_results_dtypes():
  142:     # similar to GH12821
  143:     # xref #11444
  144:     u = [dt.datetime(2015, x + 1, 1) for x in range(12)]
  145:     v = list("aaabbbbbbccd")
  146:     df = DataFrame({"X": v, "Y": u})
  147: 
  148:     result = df.groupby("X")["Y"].agg(len)
  149:     expected = df.groupby("X")["Y"].count()
  150:     tm.assert_series_equal(result, expected)
  151: 
  152: 
  153: def test_aggregate_float64_no_int64():
  154:     # see gh-11199
  155:     df = DataFrame({"a": [1, 2, 3, 4, 5], "b": [1, 2, 2, 4, 5], "c": [1, 2, 3, 4, 5]})
  156: 
  157:     expected = DataFrame({"a": [1, 2.5, 4, 5]}, index=[1, 2, 4, 5])
  158:     expected.index.name = "b"
  159: 
  160:     result = df.groupby("b")[["a"]].mean()
  161:     tm.assert_frame_equal(result, expected)
  162: 
  163:     expected = DataFrame({"a": [1, 2.5, 4, 5], "c": [1, 2.5, 4, 5]}, index=[1, 2, 4, 5])
  164:     expected.index.name = "b"
  165: 
  166:     result = df.groupby("b")[["a", "c"]].mean()
  167:     tm.assert_frame_equal(result, expected)
  168: 
  169: 
  170: def test_aggregate_api_consistency():
  171:     # GH 9052
  172:     # make sure that the aggregates via dict
  173:     # are consistent
  174:     df = DataFrame(
  175:         {
  176:             "A": ["foo", "bar", "foo", "bar", "foo", "bar", "foo", "foo"],
  177:             "B": ["one", "one", "two", "two", "two", "two", "one", "two"],
  178:             "C": np.random.default_rng(2).standard_normal(8) + 1.0,
  179:             "D": np.arange(8),
  180:         }
  181:     )
  182: 
  183:     grouped = df.groupby(["A", "B"])
  184:     c_mean = grouped["C"].mean()
  185:     c_sum = grouped["C"].sum()
  186:     d_mean = grouped["D"].mean()
  187:     d_sum = grouped["D"].sum()
  188: 
  189:     result = grouped["D"].agg(["sum", "mean"])
  190:     expected = pd.concat([d_sum, d_mean], axis=1)
  191:     expected.columns = ["sum", "mean"]
  192:     tm.assert_frame_equal(result, expected, check_like=True)
  193: 
  194:     result = grouped.agg(["sum", "mean"])
  195:     expected = pd.concat([c_sum, c_mean, d_sum, d_mean], axis=1)
  196:     expected.columns = MultiIndex.from_product([["C", "D"], ["sum", "mean"]])
  197:     tm.assert_frame_equal(result, expected, check_like=True)
  198: 
  199:     result = grouped[["D", "C"]].agg(["sum", "mean"])
  200:     expected = pd.concat([d_sum, d_mean, c_sum, c_mean], axis=1)
  201:     expected.columns = MultiIndex.from_product([["D", "C"], ["sum", "mean"]])
  202:     tm.assert_frame_equal(result, expected, check_like=True)
  203: 
  204:     result = grouped.agg({"C": "mean", "D": "sum"})
  205:     expected = pd.concat([d_sum, c_mean], axis=1)
  206:     tm.assert_frame_equal(result, expected, check_like=True)
  207: 
  208:     result = grouped.agg({"C": ["mean", "sum"], "D": ["mean", "sum"]})
  209:     expected = pd.concat([c_mean, c_sum, d_mean, d_sum], axis=1)
  210:     expected.columns = MultiIndex.from_product([["C", "D"], ["mean", "sum"]])
  211: 
  212:     msg = r"Column\(s\) \['r', 'r2'\] do not exist"
  213:     with pytest.raises(KeyError, match=msg):
  214:         grouped[["D", "C"]].agg({"r": "sum", "r2": "mean"})
  215: 
  216: 
  217: def test_agg_dict_renaming_deprecation():
  218:     # 15931
  219:     df = DataFrame({"A": [1, 1, 1, 2, 2], "B": range(5), "C": range(5)})
  220: 
  221:     msg = r"nested renamer is not supported"
  222:     with pytest.raises(SpecificationError, match=msg):
  223:         df.groupby("A").agg(
  224:             {"B": {"foo": ["sum", "max"]}, "C": {"bar": ["count", "min"]}}
  225:         )
  226: 
  227:     msg = r"Column\(s\) \['ma'\] do not exist"
  228:     with pytest.raises(KeyError, match=msg):
  229:         df.groupby("A")[["B", "C"]].agg({"ma": "max"})
  230: 
  231:     msg = r"nested renamer is not supported"
  232:     with pytest.raises(SpecificationError, match=msg):
  233:         df.groupby("A").B.agg({"foo": "count"})
  234: 
  235: 
  236: def test_agg_compat():
  237:     # GH 12334
  238:     df = DataFrame(
  239:         {
  240:             "A": ["foo", "bar", "foo", "bar", "foo", "bar", "foo", "foo"],
  241:             "B": ["one", "one", "two", "two", "two", "two", "one", "two"],
  242:             "C": np.random.default_rng(2).standard_normal(8) + 1.0,
  243:             "D": np.arange(8),
  244:         }
  245:     )
  246: 
  247:     g = df.groupby(["A", "B"])
  248: 
  249:     msg = r"nested renamer is not supported"
  250:     with pytest.raises(SpecificationError, match=msg):
  251:         g["D"].agg({"C": ["sum", "std"]})
  252: 
  253:     with pytest.raises(SpecificationError, match=msg):
  254:         g["D"].agg({"C": "sum", "D": "std"})
  255: 
  256: 
  257: def test_agg_nested_dicts():
  258:     # API change for disallowing these types of nested dicts
  259:     df = DataFrame(
  260:         {
  261:             "A": ["foo", "bar", "foo", "bar", "foo", "bar", "foo", "foo"],
  262:             "B": ["one", "one", "two", "two", "two", "two", "one", "two"],
  263:             "C": np.random.default_rng(2).standard_normal(8) + 1.0,
  264:             "D": np.arange(8),
  265:         }
  266:     )
  267: 
  268:     g = df.groupby(["A", "B"])
  269: 
  270:     msg = r"nested renamer is not supported"
  271:     with pytest.raises(SpecificationError, match=msg):
  272:         g.aggregate({"r1": {"C": ["mean", "sum"]}, "r2": {"D": ["mean", "sum"]}})
  273: 
  274:     with pytest.raises(SpecificationError, match=msg):
  275:         g.agg({"C": {"ra": ["mean", "std"]}, "D": {"rb": ["mean", "std"]}})
  276: 
  277:     # same name as the original column
  278:     # GH9052
  279:     with pytest.raises(SpecificationError, match=msg):
  280:         g["D"].agg({"result1": np.sum, "result2": np.mean})
  281: 
  282:     with pytest.raises(SpecificationError, match=msg):
  283:         g["D"].agg({"D": np.sum, "result2": np.mean})
  284: 
  285: 
  286: def test_agg_item_by_item_raise_typeerror():
  287:     df = DataFrame(np.random.default_rng(2).integers(10, size=(20, 10)))
  288: 
  289:     def raiseException(df):
  290:         pprint_thing("----------------------------------------")
  291:         pprint_thing(df.to_string())
  292:         raise TypeError("test")
  293: 
  294:     with pytest.raises(TypeError, match="test"):
  295:         df.groupby(0).agg(raiseException)
  296: 
  297: 
  298: def test_series_agg_multikey():
  299:     ts = Series(
  300:         np.arange(10, dtype=np.float64), index=date_range("2020-01-01", periods=10)
  301:     )
  302:     grouped = ts.groupby([lambda x: x.year, lambda x: x.month])
  303: 
  304:     result = grouped.agg("sum")
  305:     expected = grouped.sum()
  306:     tm.assert_series_equal(result, expected)
  307: 
  308: 
  309: def test_series_agg_multi_pure_python():
  310:     data = DataFrame(
  311:         {
  312:             "A": [
  313:                 "foo",
  314:                 "foo",
  315:                 "foo",
  316:                 "foo",
  317:                 "bar",
  318:                 "bar",
  319:                 "bar",
  320:                 "bar",
  321:                 "foo",
  322:                 "foo",
  323:                 "foo",
  324:             ],
  325:             "B": [
  326:                 "one",
  327:                 "one",
  328:                 "one",
  329:                 "two",
  330:                 "one",
  331:                 "one",
  332:                 "one",
  333:                 "two",
  334:                 "two",
  335:                 "two",
  336:                 "one",
  337:             ],
  338:             "C": [
  339:                 "dull",
  340:                 "dull",
  341:                 "shiny",
  342:                 "dull",
  343:                 "dull",
  344:                 "shiny",
  345:                 "shiny",
  346:                 "dull",
  347:                 "shiny",
  348:                 "shiny",
  349:                 "shiny",
  350:             ],
  351:             "D": np.random.default_rng(2).standard_normal(11),
  352:             "E": np.random.default_rng(2).standard_normal(11),
  353:             "F": np.random.default_rng(2).standard_normal(11),
  354:         }
  355:     )
  356: 
  357:     def bad(x):
  358:         assert len(x.values.base) > 0
  359:         return "foo"
  360: 
  361:     result = data.groupby(["A", "B"]).agg(bad)
  362:     expected = data.groupby(["A", "B"]).agg(lambda x: "foo")
  363:     tm.assert_frame_equal(result, expected)
  364: 
  365: 
  366: def test_agg_consistency():
  367:     # agg with ([]) and () not consistent
  368:     # GH 6715
  369:     def P1(a):
  370:         return np.percentile(a.dropna(), q=1)
  371: 
  372:     df = DataFrame(
  373:         {
  374:             "col1": [1, 2, 3, 4],
  375:             "col2": [10, 25, 26, 31],
  376:             "date": [
  377:                 dt.date(2013, 2, 10),
  378:                 dt.date(2013, 2, 10),
  379:                 dt.date(2013, 2, 11),
  380:                 dt.date(2013, 2, 11),
  381:             ],
  382:         }
  383:     )
  384: 
  385:     g = df.groupby("date")
  386: 
  387:     expected = g.agg([P1])
  388:     expected.columns = expected.columns.levels[0]
  389: 
  390:     result = g.agg(P1)
  391:     tm.assert_frame_equal(result, expected)
  392: 
  393: 
  394: def test_agg_callables():
  395:     # GH 7929
  396:     df = DataFrame({"foo": [1, 2], "bar": [3, 4]}).astype(np.int64)
  397: 
  398:     class fn_class:
  399:         def __call__(self, x):
  400:             return sum(x)
  401: 
  402:     equiv_callables = [
  403:         sum,
  404:         np.sum,
  405:         lambda x: sum(x),
  406:         lambda x: x.sum(),
  407:         partial(sum),
  408:         fn_class(),
  409:     ]
  410: 
  411:     expected = df.groupby("foo").agg("sum")
  412:     for ecall in equiv_callables:
  413:         warn = FutureWarning if ecall is sum or ecall is np.sum else None
  414:         msg = "using DataFrameGroupBy.sum"
  415:         with tm.assert_produces_warning(warn, match=msg):
  416:             result = df.groupby("foo").agg(ecall)
  417:         tm.assert_frame_equal(result, expected)
  418: 
  419: 
  420: def test_agg_over_numpy_arrays():
  421:     # GH 3788
  422:     df = DataFrame(
  423:         [
  424:             [1, np.array([10, 20, 30])],
  425:             [1, np.array([40, 50, 60])],
  426:             [2, np.array([20, 30, 40])],
  427:         ],
  428:         columns=["category", "arraydata"],
  429:     )
  430:     gb = df.groupby("category")
  431: 
  432:     expected_data = [[np.array([50, 70, 90])], [np.array([20, 30, 40])]]
  433:     expected_index = Index([1, 2], name="category")
  434:     expected_column = ["arraydata"]
  435:     expected = DataFrame(expected_data, index=expected_index, columns=expected_column)
  436: 
  437:     alt = gb.sum(numeric_only=False)
  438:     tm.assert_frame_equal(alt, expected)
  439: 
  440:     result = gb.agg("sum", numeric_only=False)
  441:     tm.assert_frame_equal(result, expected)
  442: 
  443:     # FIXME: the original version of this test called `gb.agg(sum)`
  444:     #  and that raises TypeError if `numeric_only=False` is passed
  445: 
  446: 
  447: @pytest.mark.parametrize("as_period", [True, False])
  448: def test_agg_tzaware_non_datetime_result(as_period):
  449:     # discussed in GH#29589, fixed in GH#29641, operating on tzaware values
  450:     #  with function that is not dtype-preserving
  451:     dti = date_range("2012-01-01", periods=4, tz="UTC")
  452:     if as_period:
  453:         dti = dti.tz_localize(None).to_period("D")
  454: 
  455:     df = DataFrame({"a": [0, 0, 1, 1], "b": dti})
  456:     gb = df.groupby("a")
  457: 
  458:     # Case that _does_ preserve the dtype
  459:     result = gb["b"].agg(lambda x: x.iloc[0])
  460:     expected = Series(dti[::2], name="b")
  461:     expected.index.name = "a"
  462:     tm.assert_series_equal(result, expected)
  463: 
  464:     # Cases that do _not_ preserve the dtype
  465:     result = gb["b"].agg(lambda x: x.iloc[0].year)
  466:     expected = Series([2012, 2012], name="b")
  467:     expected.index.name = "a"
  468:     tm.assert_series_equal(result, expected)
  469: 
  470:     result = gb["b"].agg(lambda x: x.iloc[-1] - x.iloc[0])
  471:     expected = Series([pd.Timedelta(days=1), pd.Timedelta(days=1)], name="b")
  472:     expected.index.name = "a"
  473:     if as_period:
  474:         expected = Series([pd.offsets.Day(1), pd.offsets.Day(1)], name="b")
  475:         expected.index.name = "a"
  476:     tm.assert_series_equal(result, expected)
  477: 
  478: 
  479: def test_agg_timezone_round_trip():
  480:     # GH 15426
  481:     ts = pd.Timestamp("2016-01-01 12:00:00", tz="US/Pacific")
  482:     df = DataFrame({"a": 1, "b": [ts + dt.timedelta(minutes=nn) for nn in range(10)]})
  483: 
  484:     result1 = df.groupby("a")["b"].agg("min").iloc[0]
  485:     result2 = df.groupby("a")["b"].agg(lambda x: np.min(x)).iloc[0]
  486:     result3 = df.groupby("a")["b"].min().iloc[0]
  487: 
  488:     assert result1 == ts
  489:     assert result2 == ts
  490:     assert result3 == ts
  491: 
  492:     dates = [
  493:         pd.Timestamp(f"2016-01-0{i:d} 12:00:00", tz="US/Pacific") for i in range(1, 5)
  494:     ]
  495:     df = DataFrame({"A": ["a", "b"] * 2, "B": dates})
  496:     grouped = df.groupby("A")
  497: 
  498:     ts = df["B"].iloc[0]
  499:     assert ts == grouped.nth(0)["B"].iloc[0]
  500:     assert ts == grouped.head(1)["B"].iloc[0]
  501:     assert ts == grouped.first()["B"].iloc[0]
  502: 
  503:     # GH#27110 applying iloc should return a DataFrame
  504:     msg = "DataFrameGroupBy.apply operated on the grouping columns"
  505:     with tm.assert_produces_warning(DeprecationWarning, match=msg):
  506:         assert ts == grouped.apply(lambda x: x.iloc[0]).iloc[0, 1]
  507: 
  508:     ts = df["B"].iloc[2]
  509:     assert ts == grouped.last()["B"].iloc[0]
  510: 
  511:     # GH#27110 applying iloc should return a DataFrame
  512:     msg = "DataFrameGroupBy.apply operated on the grouping columns"
  513:     with tm.assert_produces_warning(DeprecationWarning, match=msg):
  514:         assert ts == grouped.apply(lambda x: x.iloc[-1]).iloc[0, 1]
  515: 
  516: 
  517: def test_sum_uint64_overflow():
  518:     # see gh-14758
  519:     # Convert to uint64 and don't overflow
  520:     df = DataFrame([[1, 2], [3, 4], [5, 6]], dtype=object)
  521:     df = df + 9223372036854775807
  522: 
  523:     index = Index(
  524:         [9223372036854775808, 9223372036854775810, 9223372036854775812], dtype=np.uint64
  525:     )
  526:     expected = DataFrame(
  527:         {1: [9223372036854775809, 9223372036854775811, 9223372036854775813]},
  528:         index=index,
  529:         dtype=object,
  530:     )
  531: 
  532:     expected.index.name = 0
  533:     result = df.groupby(0).sum(numeric_only=False)
  534:     tm.assert_frame_equal(result, expected)
  535: 
  536:     # out column is non-numeric, so with numeric_only=True it is dropped
  537:     result2 = df.groupby(0).sum(numeric_only=True)
  538:     expected2 = expected[[]]
  539:     tm.assert_frame_equal(result2, expected2)
  540: 
  541: 
  542: @pytest.mark.parametrize(
  543:     "structure, expected",
  544:     [
  545:         (tuple, DataFrame({"C": {(1, 1): (1, 1, 1), (3, 4): (3, 4, 4)}})),
  546:         (list, DataFrame({"C": {(1, 1): [1, 1, 1], (3, 4): [3, 4, 4]}})),
  547:         (
  548:             lambda x: tuple(x),
  549:             DataFrame({"C": {(1, 1): (1, 1, 1), (3, 4): (3, 4, 4)}}),
  550:         ),
  551:         (
  552:             lambda x: list(x),
  553:             DataFrame({"C": {(1, 1): [1, 1, 1], (3, 4): [3, 4, 4]}}),
  554:         ),
  555:     ],
  556: )
  557: def test_agg_structs_dataframe(structure, expected):
  558:     df = DataFrame(
  559:         {"A": [1, 1, 1, 3, 3, 3], "B": [1, 1, 1, 4, 4, 4], "C": [1, 1, 1, 3, 4, 4]}
  560:     )
  561: 
  562:     result = df.groupby(["A", "B"]).aggregate(structure)
  563:     expected.index.names = ["A", "B"]
  564:     tm.assert_frame_equal(result, expected)
  565: 
  566: 
  567: @pytest.mark.parametrize(
  568:     "structure, expected",
  569:     [
  570:         (tuple, Series([(1, 1, 1), (3, 4, 4)], index=[1, 3], name="C")),
  571:         (list, Series([[1, 1, 1], [3, 4, 4]], index=[1, 3], name="C")),
  572:         (lambda x: tuple(x), Series([(1, 1, 1), (3, 4, 4)], index=[1, 3], name="C")),
  573:         (lambda x: list(x), Series([[1, 1, 1], [3, 4, 4]], index=[1, 3], name="C")),
  574:     ],
  575: )
  576: def test_agg_structs_series(structure, expected):
  577:     # Issue #18079
  578:     df = DataFrame(
  579:         {"A": [1, 1, 1, 3, 3, 3], "B": [1, 1, 1, 4, 4, 4], "C": [1, 1, 1, 3, 4, 4]}
  580:     )
  581: 
  582:     result = df.groupby("A")["C"].aggregate(structure)
  583:     expected.index.name = "A"
  584:     tm.assert_series_equal(result, expected)
  585: 
  586: 
  587: def test_agg_category_nansum(observed):
  588:     categories = ["a", "b", "c"]
  589:     df = DataFrame(
  590:         {"A": pd.Categorical(["a", "a", "b"], categories=categories), "B": [1, 2, 3]}
  591:     )
  592:     msg = "using SeriesGroupBy.sum"
  593:     with tm.assert_produces_warning(FutureWarning, match=msg):
  594:         result = df.groupby("A", observed=observed).B.agg(np.nansum)
  595:     expected = Series(
  596:         [3, 3, 0],
  597:         index=pd.CategoricalIndex(["a", "b", "c"], categories=categories, name="A"),
  598:         name="B",
  599:     )
  600:     if observed:
  601:         expected = expected[expected != 0]
  602:     tm.assert_series_equal(result, expected)
  603: 
  604: 
  605: def test_agg_list_like_func():
  606:     # GH 18473
  607:     df = DataFrame({"A": [str(x) for x in range(3)], "B": [str(x) for x in range(3)]})
  608:     grouped = df.groupby("A", as_index=False, sort=False)
  609:     result = grouped.agg({"B": lambda x: list(x)})
  610:     expected = DataFrame(
  611:         {"A": [str(x) for x in range(3)], "B": [[str(x)] for x in range(3)]}
  612:     )
  613:     tm.assert_frame_equal(result, expected)
  614: 
  615: 
  616: def test_agg_lambda_with_timezone():
  617:     # GH 23683
  618:     df = DataFrame(
  619:         {
  620:             "tag": [1, 1],
  621:             "date": [
  622:                 pd.Timestamp("2018-01-01", tz="UTC"),
  623:                 pd.Timestamp("2018-01-02", tz="UTC"),
  624:             ],
  625:         }
  626:     )
  627:     result = df.groupby("tag").agg({"date": lambda e: e.head(1)})
  628:     expected = DataFrame(
  629:         [pd.Timestamp("2018-01-01", tz="UTC")],
  630:         index=Index([1], name="tag"),
  631:         columns=["date"],
  632:     )
  633:     tm.assert_frame_equal(result, expected)
  634: 
  635: 
  636: @pytest.mark.parametrize(
  637:     "err_cls",
  638:     [
  639:         NotImplementedError,
  640:         RuntimeError,
  641:         KeyError,
  642:         IndexError,
  643:         OSError,
  644:         ValueError,
  645:         ArithmeticError,
  646:         AttributeError,
  647:     ],
  648: )
  649: def test_groupby_agg_err_catching(err_cls):
  650:     # make sure we suppress anything other than TypeError or AssertionError
  651:     #  in _python_agg_general
  652: 
  653:     # Use a non-standard EA to make sure we don't go down ndarray paths
  654:     from pandas.tests.extension.decimal.array import (
  655:         DecimalArray,
  656:         make_data,
  657:         to_decimal,
  658:     )
  659: 
  660:     data = make_data()[:5]
  661:     df = DataFrame(
  662:         {"id1": [0, 0, 0, 1, 1], "id2": [0, 1, 0, 1, 1], "decimals": DecimalArray(data)}
  663:     )
  664: 
  665:     expected = Series(to_decimal([data[0], data[3]]))
  666: 
  667:     def weird_func(x):
  668:         # weird function that raise something other than TypeError or IndexError
  669:         #  in _python_agg_general
  670:         if len(x) == 0:
  671:             raise err_cls
  672:         return x.iloc[0]
  673: 
  674:     result = df["decimals"].groupby(df["id1"]).agg(weird_func)
  675:     tm.assert_series_equal(result, expected, check_names=False)
