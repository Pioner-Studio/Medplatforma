    1: from datetime import datetime
    2: import decimal
    3: from decimal import Decimal
    4: import re
    5: 
    6: import numpy as np
    7: import pytest
    8: 
    9: from pandas.errors import (
   10:     PerformanceWarning,
   11:     SpecificationError,
   12: )
   13: import pandas.util._test_decorators as td
   14: 
   15: from pandas.core.dtypes.common import is_string_dtype
   16: 
   17: import pandas as pd
   18: from pandas import (
   19:     Categorical,
   20:     DataFrame,
   21:     Grouper,
   22:     Index,
   23:     Interval,
   24:     MultiIndex,
   25:     RangeIndex,
   26:     Series,
   27:     Timedelta,
   28:     Timestamp,
   29:     date_range,
   30:     to_datetime,
   31: )
   32: import pandas._testing as tm
   33: from pandas.core.arrays import BooleanArray
   34: import pandas.core.common as com
   35: 
   36: pytestmark = pytest.mark.filterwarnings("ignore:Mean of empty slice:RuntimeWarning")
   37: 
   38: 
   39: def test_repr():
   40:     # GH18203
   41:     result = repr(Grouper(key="A", level="B"))
   42:     expected = "Grouper(key='A', level='B', axis=0, sort=False, dropna=True)"
   43:     assert result == expected
   44: 
   45: 
   46: def test_groupby_std_datetimelike(warn_copy_on_write):
   47:     # GH#48481
   48:     tdi = pd.timedelta_range("1 Day", periods=10000)
   49:     ser = Series(tdi)
   50:     ser[::5] *= 2  # get different std for different groups
   51: 
   52:     df = ser.to_frame("A").copy()
   53: 
   54:     df["B"] = ser + Timestamp(0)
   55:     df["C"] = ser + Timestamp(0, tz="UTC")
   56:     df.iloc[-1] = pd.NaT  # last group includes NaTs
   57: 
   58:     gb = df.groupby(list(range(5)) * 2000)
   59: 
   60:     result = gb.std()
   61: 
   62:     # Note: this does not _exactly_ match what we would get if we did
   63:     # [gb.get_group(i).std() for i in gb.groups]
   64:     #  but it _does_ match the floating point error we get doing the
   65:     #  same operation on int64 data xref GH#51332
   66:     td1 = Timedelta("2887 days 11:21:02.326710176")
   67:     td4 = Timedelta("2886 days 00:42:34.664668096")
   68:     exp_ser = Series([td1 * 2, td1, td1, td1, td4], index=np.arange(5))
   69:     expected = DataFrame({"A": exp_ser, "B": exp_ser, "C": exp_ser})
   70:     tm.assert_frame_equal(result, expected)
   71: 
   72: 
   73: @pytest.mark.parametrize("dtype", ["int64", "int32", "float64", "float32"])
   74: def test_basic_aggregations(dtype):
   75:     data = Series(np.arange(9) // 3, index=np.arange(9), dtype=dtype)
   76: 
   77:     index = np.arange(9)
   78:     np.random.default_rng(2).shuffle(index)
   79:     data = data.reindex(index)
   80: 
   81:     grouped = data.groupby(lambda x: x // 3, group_keys=False)
   82: 
   83:     for k, v in grouped:
   84:         assert len(v) == 3
   85: 
   86:     msg = "using SeriesGroupBy.mean"
   87:     with tm.assert_produces_warning(FutureWarning, match=msg):
   88:         agged = grouped.aggregate(np.mean)
   89:     assert agged[1] == 1
   90: 
   91:     msg = "using SeriesGroupBy.mean"
   92:     with tm.assert_produces_warning(FutureWarning, match=msg):
   93:         expected = grouped.agg(np.mean)
   94:     tm.assert_series_equal(agged, expected)  # shorthand
   95:     tm.assert_series_equal(agged, grouped.mean())
   96:     result = grouped.sum()
   97:     msg = "using SeriesGroupBy.sum"
   98:     with tm.assert_produces_warning(FutureWarning, match=msg):
   99:         expected = grouped.agg(np.sum)
  100:     tm.assert_series_equal(result, expected)
  101: 
  102:     expected = grouped.apply(lambda x: x * x.sum())
  103:     transformed = grouped.transform(lambda x: x * x.sum())
  104:     assert transformed[7] == 12
  105:     tm.assert_series_equal(transformed, expected)
  106: 
  107:     value_grouped = data.groupby(data)
  108:     msg = "using SeriesGroupBy.mean"
  109:     with tm.assert_produces_warning(FutureWarning, match=msg):
  110:         result = value_grouped.aggregate(np.mean)
  111:     tm.assert_series_equal(result, agged, check_index_type=False)
  112: 
  113:     # complex agg
  114:     msg = "using SeriesGroupBy.[mean|std]"
  115:     with tm.assert_produces_warning(FutureWarning, match=msg):
  116:         agged = grouped.aggregate([np.mean, np.std])
  117: 
  118:     msg = r"nested renamer is not supported"
  119:     with pytest.raises(SpecificationError, match=msg):
  120:         grouped.aggregate({"one": np.mean, "two": np.std})
  121: 
  122:     group_constants = {0: 10, 1: 20, 2: 30}
  123:     msg = (
  124:         "Pinning the groupby key to each group in SeriesGroupBy.agg is deprecated, "
  125:         "and cases that relied on it will raise in a future version"
  126:     )
  127:     with tm.assert_produces_warning(FutureWarning, match=msg):
  128:         # GH#41090
  129:         agged = grouped.agg(lambda x: group_constants[x.name] + x.mean())
  130:     assert agged[1] == 21
  131: 
  132:     # corner cases
  133:     msg = "Must produce aggregated value"
  134:     # exception raised is type Exception
  135:     with pytest.raises(Exception, match=msg):
  136:         grouped.aggregate(lambda x: x * 2)
  137: 
  138: 
  139: def test_groupby_nonobject_dtype(multiindex_dataframe_random_data):
  140:     key = multiindex_dataframe_random_data.index.codes[0]
  141:     grouped = multiindex_dataframe_random_data.groupby(key)
  142:     result = grouped.sum()
  143: 
  144:     expected = multiindex_dataframe_random_data.groupby(key.astype("O")).sum()
  145:     assert result.index.dtype == np.int8
  146:     assert expected.index.dtype == np.int64
  147:     tm.assert_frame_equal(result, expected, check_index_type=False)
  148: 
  149: 
  150: def test_groupby_nonobject_dtype_mixed():
  151:     # GH 3911, mixed frame non-conversion
  152:     df = DataFrame(
  153:         {
  154:             "A": ["foo", "bar", "foo", "bar", "foo", "bar", "foo", "foo"],
  155:             "B": ["one", "one", "two", "three", "two", "two", "one", "three"],
  156:             "C": np.random.default_rng(2).standard_normal(8),
  157:             "D": np.array(np.random.default_rng(2).standard_normal(8), dtype="float32"),
  158:         }
  159:     )
  160:     df["value"] = range(len(df))
  161: 
  162:     def max_value(group):
  163:         return group.loc[group["value"].idxmax()]
  164: 
  165:     msg = "DataFrameGroupBy.apply operated on the grouping columns"
  166:     with tm.assert_produces_warning(DeprecationWarning, match=msg):
  167:         applied = df.groupby("A").apply(max_value)
  168:     result = applied.dtypes
  169:     expected = df.dtypes
  170:     tm.assert_series_equal(result, expected)
  171: 
  172: 
  173: def test_inconsistent_return_type():
  174:     # GH5592
  175:     # inconsistent return type
  176:     df = DataFrame(
  177:         {
  178:             "A": ["Tiger", "Tiger", "Tiger", "Lamb", "Lamb", "Pony", "Pony"],
  179:             "B": Series(np.arange(7), dtype="int64"),
  180:             "C": date_range("20130101", periods=7),
  181:         }
  182:     )
  183: 
  184:     def f_0(grp):
  185:         return grp.iloc[0]
  186: 
  187:     expected = df.groupby("A").first()[["B"]]
  188:     msg = "DataFrameGroupBy.apply operated on the grouping columns"
  189:     with tm.assert_produces_warning(DeprecationWarning, match=msg):
  190:         result = df.groupby("A").apply(f_0)[["B"]]
  191:     tm.assert_frame_equal(result, expected)
  192: 
  193:     def f_1(grp):
  194:         if grp.name == "Tiger":
  195:             return None
  196:         return grp.iloc[0]
  197: 
  198:     msg = "DataFrameGroupBy.apply operated on the grouping columns"
  199:     with tm.assert_produces_warning(DeprecationWarning, match=msg):
  200:         result = df.groupby("A").apply(f_1)[["B"]]
  201:     e = expected.copy()
  202:     e.loc["Tiger"] = np.nan
  203:     tm.assert_frame_equal(result, e)
  204: 
  205:     def f_2(grp):
  206:         if grp.name == "Pony":
  207:             return None
  208:         return grp.iloc[0]
  209: 
  210:     msg = "DataFrameGroupBy.apply operated on the grouping columns"
  211:     with tm.assert_produces_warning(DeprecationWarning, match=msg):
  212:         result = df.groupby("A").apply(f_2)[["B"]]
  213:     e = expected.copy()
  214:     e.loc["Pony"] = np.nan
  215:     tm.assert_frame_equal(result, e)
  216: 
  217:     # 5592 revisited, with datetimes
  218:     def f_3(grp):
  219:         if grp.name == "Pony":
  220:             return None
  221:         return grp.iloc[0]
  222: 
  223:     msg = "DataFrameGroupBy.apply operated on the grouping columns"
  224:     with tm.assert_produces_warning(DeprecationWarning, match=msg):
  225:         result = df.groupby("A").apply(f_3)[["C"]]
  226:     e = df.groupby("A").first()[["C"]]
  227:     e.loc["Pony"] = pd.NaT
  228:     tm.assert_frame_equal(result, e)
  229: 
  230:     # scalar outputs
  231:     def f_4(grp):
  232:         if grp.name == "Pony":
  233:             return None
  234:         return grp.iloc[0].loc["C"]
  235: 
  236:     msg = "DataFrameGroupBy.apply operated on the grouping columns"
  237:     with tm.assert_produces_warning(DeprecationWarning, match=msg):
  238:         result = df.groupby("A").apply(f_4)
  239:     e = df.groupby("A").first()["C"].copy()
  240:     e.loc["Pony"] = np.nan
  241:     e.name = None
  242:     tm.assert_series_equal(result, e)
  243: 
  244: 
  245: def test_pass_args_kwargs(ts, tsframe):
  246:     def f(x, q=None, axis=0):
  247:         return np.percentile(x, q, axis=axis)
  248: 
  249:     g = lambda x: np.percentile(x, 80, axis=0)
  250: 
  251:     # Series
  252:     ts_grouped = ts.groupby(lambda x: x.month)
  253:     agg_result = ts_grouped.agg(np.percentile, 80, axis=0)
  254:     apply_result = ts_grouped.apply(np.percentile, 80, axis=0)
  255:     trans_result = ts_grouped.transform(np.percentile, 80, axis=0)
  256: 
  257:     agg_expected = ts_grouped.quantile(0.8)
  258:     trans_expected = ts_grouped.transform(g)
  259: 
  260:     tm.assert_series_equal(apply_result, agg_expected)
  261:     tm.assert_series_equal(agg_result, agg_expected)
  262:     tm.assert_series_equal(trans_result, trans_expected)
  263: 
  264:     agg_result = ts_grouped.agg(f, q=80)
  265:     apply_result = ts_grouped.apply(f, q=80)
  266:     trans_result = ts_grouped.transform(f, q=80)
  267:     tm.assert_series_equal(agg_result, agg_expected)
  268:     tm.assert_series_equal(apply_result, agg_expected)
  269:     tm.assert_series_equal(trans_result, trans_expected)
  270: 
  271:     # DataFrame
  272:     for as_index in [True, False]:
  273:         df_grouped = tsframe.groupby(lambda x: x.month, as_index=as_index)
  274:         warn = None if as_index else FutureWarning
  275:         msg = "A grouping .* was excluded from the result"
  276:         with tm.assert_produces_warning(warn, match=msg):
  277:             agg_result = df_grouped.agg(np.percentile, 80, axis=0)
  278:         with tm.assert_produces_warning(warn, match=msg):
  279:             apply_result = df_grouped.apply(DataFrame.quantile, 0.8)
  280:         with tm.assert_produces_warning(warn, match=msg):
  281:             expected = df_grouped.quantile(0.8)
  282:         tm.assert_frame_equal(apply_result, expected, check_names=False)
  283:         tm.assert_frame_equal(agg_result, expected)
  284: 
  285:         apply_result = df_grouped.apply(DataFrame.quantile, [0.4, 0.8])
  286:         with tm.assert_produces_warning(warn, match=msg):
  287:             expected_seq = df_grouped.quantile([0.4, 0.8])
  288:         tm.assert_frame_equal(apply_result, expected_seq, check_names=False)
  289: 
  290:         with tm.assert_produces_warning(warn, match=msg):
  291:             agg_result = df_grouped.agg(f, q=80)
  292:         with tm.assert_produces_warning(warn, match=msg):
  293:             apply_result = df_grouped.apply(DataFrame.quantile, q=0.8)
  294:         tm.assert_frame_equal(agg_result, expected)
  295:         tm.assert_frame_equal(apply_result, expected, check_names=False)
  296: 
  297: 
  298: @pytest.mark.parametrize("as_index", [True, False])
  299: def test_pass_args_kwargs_duplicate_columns(tsframe, as_index):
  300:     # go through _aggregate_frame with self.axis == 0 and duplicate columns
  301:     tsframe.columns = ["A", "B", "A", "C"]
  302:     gb = tsframe.groupby(lambda x: x.month, as_index=as_index)
  303: 
  304:     warn = None if as_index else FutureWarning
  305:     msg = "A grouping .* was excluded from the result"
  306:     with tm.assert_produces_warning(warn, match=msg):
  307:         res = gb.agg(np.percentile, 80, axis=0)
  308: 
  309:     ex_data = {
  310:         1: tsframe[tsframe.index.month == 1].quantile(0.8),
  311:         2: tsframe[tsframe.index.month == 2].quantile(0.8),
  312:     }
  313:     expected = DataFrame(ex_data).T
  314:     if not as_index:
  315:         # TODO: try to get this more consistent?
  316:         expected.index = Index(range(2))
  317: 
  318:     tm.assert_frame_equal(res, expected)
  319: 
  320: 
  321: def test_len():
  322:     df = DataFrame(
  323:         np.random.default_rng(2).standard_normal((10, 4)),
  324:         columns=Index(list("ABCD"), dtype=object),
  325:         index=date_range("2000-01-01", periods=10, freq="B"),
  326:     )
  327:     grouped = df.groupby([lambda x: x.year, lambda x: x.month, lambda x: x.day])
  328:     assert len(grouped) == len(df)
  329: 
  330:     grouped = df.groupby([lambda x: x.year, lambda x: x.month])
  331:     expected = len({(x.year, x.month) for x in df.index})
  332:     assert len(grouped) == expected
  333: 
  334: 
  335: def test_len_nan_group():
  336:     # issue 11016
  337:     df = DataFrame({"a": [np.nan] * 3, "b": [1, 2, 3]})
  338:     assert len(df.groupby("a")) == 0
  339:     assert len(df.groupby("b")) == 3
  340:     assert len(df.groupby(["a", "b"])) == 3
  341: 
  342: 
  343: def test_basic_regression():
  344:     # regression
  345:     result = Series([1.0 * x for x in list(range(1, 10)) * 10])
  346: 
  347:     data = np.random.default_rng(2).random(1100) * 10.0
  348:     groupings = Series(data)
  349: 
  350:     grouped = result.groupby(groupings)
  351:     grouped.mean()
  352: 
  353: 
  354: @pytest.mark.parametrize(
  355:     "dtype", ["float64", "float32", "int64", "int32", "int16", "int8"]
  356: )
  357: def test_with_na_groups(dtype):
  358:     index = Index(np.arange(10))
  359:     values = Series(np.ones(10), index, dtype=dtype)
  360:     labels = Series(
  361:         [np.nan, "foo", "bar", "bar", np.nan, np.nan, "bar", "bar", np.nan, "foo"],
  362:         index=index,
  363:     )
  364: 
  365:     # this SHOULD be an int
  366:     grouped = values.groupby(labels)
  367:     agged = grouped.agg(len)
  368:     expected = Series([4, 2], index=["bar", "foo"])
  369: 
  370:     tm.assert_series_equal(agged, expected, check_dtype=False)
  371: 
  372:     # assert issubclass(agged.dtype.type, np.integer)
  373: 
  374:     # explicitly return a float from my function
  375:     def f(x):
  376:         return float(len(x))
  377: 
  378:     agged = grouped.agg(f)
  379:     expected = Series([4.0, 2.0], index=["bar", "foo"])
  380: 
  381:     tm.assert_series_equal(agged, expected)
  382: 
  383: 
  384: def test_indices_concatenation_order():
  385:     # GH 2808
  386: 
  387:     def f1(x):
  388:         y = x[(x.b % 2) == 1] ** 2
  389:         if y.empty:
  390:             multiindex = MultiIndex(levels=[[]] * 2, codes=[[]] * 2, names=["b", "c"])
  391:             res = DataFrame(columns=["a"], index=multiindex)
  392:             return res
  393:         else:
  394:             y = y.set_index(["b", "c"])
  395:             return y
  396: 
  397:     def f2(x):
  398:         y = x[(x.b % 2) == 1] ** 2
  399:         if y.empty:
  400:             return DataFrame()
  401:         else:
  402:             y = y.set_index(["b", "c"])
  403:             return y
  404: 
  405:     def f3(x):
  406:         y = x[(x.b % 2) == 1] ** 2
  407:         if y.empty:
  408:             multiindex = MultiIndex(
  409:                 levels=[[]] * 2, codes=[[]] * 2, names=["foo", "bar"]
  410:             )
  411:             res = DataFrame(columns=["a", "b"], index=multiindex)
  412:             return res
  413:         else:
  414:             return y
  415: 
  416:     df = DataFrame({"a": [1, 2, 2, 2], "b": range(4), "c": range(5, 9)})
  417: 
  418:     df2 = DataFrame({"a": [3, 2, 2, 2], "b": range(4), "c": range(5, 9)})
  419: 
  420:     depr_msg = "The behavior of array concatenation with empty entries is deprecated"
  421: 
  422:     # correct result
  423:     msg = "DataFrameGroupBy.apply operated on the grouping columns"
  424:     with tm.assert_produces_warning(DeprecationWarning, match=msg):
  425:         result1 = df.groupby("a").apply(f1)
  426:     with tm.assert_produces_warning(DeprecationWarning, match=msg):
  427:         result2 = df2.groupby("a").apply(f1)
  428:     tm.assert_frame_equal(result1, result2)
  429: 
  430:     # should fail (not the same number of levels)
  431:     msg = "Cannot concat indices that do not have the same number of levels"
  432:     with pytest.raises(AssertionError, match=msg):
  433:         df.groupby("a").apply(f2)
  434:     with pytest.raises(AssertionError, match=msg):
  435:         df2.groupby("a").apply(f2)
  436: 
  437:     # should fail (incorrect shape)
  438:     with pytest.raises(AssertionError, match=msg):
  439:         df.groupby("a").apply(f3)
  440:     with pytest.raises(AssertionError, match=msg):
  441:         with tm.assert_produces_warning(FutureWarning, match=depr_msg):
  442:             df2.groupby("a").apply(f3)
  443: 
  444: 
  445: def test_attr_wrapper(ts):
  446:     grouped = ts.groupby(lambda x: x.weekday())
  447: 
  448:     result = grouped.std()
  449:     expected = grouped.agg(lambda x: np.std(x, ddof=1))
  450:     tm.assert_series_equal(result, expected)
  451: 
  452:     # this is pretty cool
  453:     result = grouped.describe()
  454:     expected = {name: gp.describe() for name, gp in grouped}
  455:     expected = DataFrame(expected).T
  456:     tm.assert_frame_equal(result, expected)
  457: 
  458:     # get attribute
  459:     result = grouped.dtype
  460:     expected = grouped.agg(lambda x: x.dtype)
  461:     tm.assert_series_equal(result, expected)
  462: 
  463:     # make sure raises error
  464:     msg = "'SeriesGroupBy' object has no attribute 'foo'"
  465:     with pytest.raises(AttributeError, match=msg):
  466:         getattr(grouped, "foo")
  467: 
  468: 
  469: def test_frame_groupby(tsframe):
  470:     grouped = tsframe.groupby(lambda x: x.weekday())
  471: 
  472:     # aggregate
  473:     aggregated = grouped.aggregate("mean")
  474:     assert len(aggregated) == 5
  475:     assert len(aggregated.columns) == 4
  476: 
  477:     # by string
  478:     tscopy = tsframe.copy()
  479:     tscopy["weekday"] = [x.weekday() for x in tscopy.index]
  480:     stragged = tscopy.groupby("weekday").aggregate("mean")
  481:     tm.assert_frame_equal(stragged, aggregated, check_names=False)
  482: 
  483:     # transform
  484:     grouped = tsframe.head(30).groupby(lambda x: x.weekday())
  485:     transformed = grouped.transform(lambda x: x - x.mean())
  486:     assert len(transformed) == 30
  487:     assert len(transformed.columns) == 4
  488: 
  489:     # transform propagate
  490:     transformed = grouped.transform(lambda x: x.mean())
  491:     for name, group in grouped:
  492:         mean = group.mean()
  493:         for idx in group.index:
  494:             tm.assert_series_equal(transformed.xs(idx), mean, check_names=False)
  495: 
  496:     # iterate
  497:     for weekday, group in grouped:
  498:         assert group.index[0].weekday() == weekday
  499: 
  500:     # groups / group_indices
  501:     groups = grouped.groups
  502:     indices = grouped.indices
  503: 
  504:     for k, v in groups.items():
  505:         samething = tsframe.index.take(indices[k])
  506:         assert (samething == v).all()
  507: 
  508: 
  509: def test_frame_groupby_columns(tsframe):
  510:     mapping = {"A": 0, "B": 0, "C": 1, "D": 1}
  511:     msg = "DataFrame.groupby with axis=1 is deprecated"
  512:     with tm.assert_produces_warning(FutureWarning, match=msg):
  513:         grouped = tsframe.groupby(mapping, axis=1)
  514: 
  515:     # aggregate
  516:     aggregated = grouped.aggregate("mean")
  517:     assert len(aggregated) == len(tsframe)
  518:     assert len(aggregated.columns) == 2
  519: 
  520:     # transform
  521:     tf = lambda x: x - x.mean()
  522:     msg = "The 'axis' keyword in DataFrame.groupby is deprecated"
  523:     with tm.assert_produces_warning(FutureWarning, match=msg):
  524:         groupedT = tsframe.T.groupby(mapping, axis=0)
  525:     tm.assert_frame_equal(groupedT.transform(tf).T, grouped.transform(tf))
  526: 
  527:     # iterate
  528:     for k, v in grouped:
  529:         assert len(v.columns) == 2
  530: 
  531: 
  532: def test_frame_set_name_single(df):
  533:     grouped = df.groupby("A")
  534: 
  535:     result = grouped.mean(numeric_only=True)
  536:     assert result.index.name == "A"
  537: 
  538:     result = df.groupby("A", as_index=False).mean(numeric_only=True)
  539:     assert result.index.name != "A"
  540: 
  541:     result = grouped[["C", "D"]].agg("mean")
  542:     assert result.index.name == "A"
  543: 
  544:     result = grouped.agg({"C": "mean", "D": "std"})
  545:     assert result.index.name == "A"
  546: 
  547:     result = grouped["C"].mean()
  548:     assert result.index.name == "A"
  549:     result = grouped["C"].agg("mean")
  550:     assert result.index.name == "A"
  551:     result = grouped["C"].agg(["mean", "std"])
  552:     assert result.index.name == "A"
  553: 
  554:     msg = r"nested renamer is not supported"
  555:     with pytest.raises(SpecificationError, match=msg):
  556:         grouped["C"].agg({"foo": "mean", "bar": "std"})
  557: 
  558: 
  559: def test_multi_func(df):
  560:     col1 = df["A"]
  561:     col2 = df["B"]
  562: 
  563:     grouped = df.groupby([col1.get, col2.get])
  564:     agged = grouped.mean(numeric_only=True)
  565:     expected = df.groupby(["A", "B"]).mean()
  566: 
  567:     # TODO groupby get drops names
  568:     tm.assert_frame_equal(
  569:         agged.loc[:, ["C", "D"]], expected.loc[:, ["C", "D"]], check_names=False
  570:     )
  571: 
  572:     # some "groups" with no data
  573:     df = DataFrame(
  574:         {
  575:             "v1": np.random.default_rng(2).standard_normal(6),
  576:             "v2": np.random.default_rng(2).standard_normal(6),
  577:             "k1": np.array(["b", "b", "b", "a", "a", "a"]),
  578:             "k2": np.array(["1", "1", "1", "2", "2", "2"]),
  579:         },
  580:         index=["one", "two", "three", "four", "five", "six"],
  581:     )
  582:     # only verify that it works for now
  583:     grouped = df.groupby(["k1", "k2"])
  584:     grouped.agg("sum")
  585: 
  586: 
  587: def test_multi_key_multiple_functions(df):
  588:     grouped = df.groupby(["A", "B"])["C"]
  589: 
  590:     agged = grouped.agg(["mean", "std"])
  591:     expected = DataFrame({"mean": grouped.agg("mean"), "std": grouped.agg("std")})
  592:     tm.assert_frame_equal(agged, expected)
  593: 
  594: 
  595: def test_frame_multi_key_function_list():
  596:     data = DataFrame(
  597:         {
  598:             "A": [
  599:                 "foo",
  600:                 "foo",
  601:                 "foo",
  602:                 "foo",
  603:                 "bar",
  604:                 "bar",
  605:                 "bar",
  606:                 "bar",
  607:                 "foo",
  608:                 "foo",
  609:                 "foo",
  610:             ],
  611:             "B": [
  612:                 "one",
  613:                 "one",
  614:                 "one",
  615:                 "two",
  616:                 "one",
  617:                 "one",
  618:                 "one",
  619:                 "two",
  620:                 "two",
  621:                 "two",
  622:                 "one",
  623:             ],
  624:             "D": np.random.default_rng(2).standard_normal(11),
  625:             "E": np.random.default_rng(2).standard_normal(11),
  626:             "F": np.random.default_rng(2).standard_normal(11),
  627:         }
  628:     )
  629: 
  630:     grouped = data.groupby(["A", "B"])
  631:     funcs = ["mean", "std"]
  632:     agged = grouped.agg(funcs)
  633:     expected = pd.concat(
  634:         [grouped["D"].agg(funcs), grouped["E"].agg(funcs), grouped["F"].agg(funcs)],
  635:         keys=["D", "E", "F"],
  636:         axis=1,
  637:     )
  638:     assert isinstance(agged.index, MultiIndex)
  639:     assert isinstance(expected.index, MultiIndex)
  640:     tm.assert_frame_equal(agged, expected)
  641: 
  642: 
  643: def test_frame_multi_key_function_list_partial_failure():
  644:     data = DataFrame(
  645:         {
  646:             "A": [
  647:                 "foo",
  648:                 "foo",
  649:                 "foo",
  650:                 "foo",
  651:                 "bar",
  652:                 "bar",
  653:                 "bar",
  654:                 "bar",
  655:                 "foo",
  656:                 "foo",
  657:                 "foo",
  658:             ],
  659:             "B": [
  660:                 "one",
  661:                 "one",
  662:                 "one",
  663:                 "two",
  664:                 "one",
  665:                 "one",
  666:                 "one",
  667:                 "two",
  668:                 "two",
  669:                 "two",
  670:                 "one",
  671:             ],
  672:             "C": [
  673:                 "dull",
  674:                 "dull",
  675:                 "shiny",
  676:                 "dull",
  677:                 "dull",
  678:                 "shiny",
  679:                 "shiny",
  680:                 "dull",
  681:                 "shiny",
  682:                 "shiny",
  683:                 "shiny",
  684:             ],
  685:             "D": np.random.default_rng(2).standard_normal(11),
  686:             "E": np.random.default_rng(2).standard_normal(11),
  687:             "F": np.random.default_rng(2).standard_normal(11),
  688:         }
  689:     )
  690: 
  691:     grouped = data.groupby(["A", "B"])
  692:     funcs = ["mean", "std"]
  693:     msg = re.escape("agg function failed [how->mean,dtype->")
  694:     with pytest.raises(TypeError, match=msg):
  695:         grouped.agg(funcs)
  696: 
  697: 
  698: @pytest.mark.parametrize("op", [lambda x: x.sum(), lambda x: x.mean()])
  699: def test_groupby_multiple_columns(df, op):
  700:     data = df
  701:     grouped = data.groupby(["A", "B"])
  702: 
  703:     result1 = op(grouped)
  704: 
  705:     keys = []
  706:     values = []
  707:     for n1, gp1 in data.groupby("A"):
  708:         for n2, gp2 in gp1.groupby("B"):
  709:             keys.append((n1, n2))
  710:             values.append(op(gp2.loc[:, ["C", "D"]]))
  711: 
  712:     mi = MultiIndex.from_tuples(keys, names=["A", "B"])
  713:     expected = pd.concat(values, axis=1).T
  714:     expected.index = mi
  715: 
  716:     # a little bit crude
  717:     for col in ["C", "D"]:
  718:         result_col = op(grouped[col])
  719:         pivoted = result1[col]
  720:         exp = expected[col]
  721:         tm.assert_series_equal(result_col, exp)
  722:         tm.assert_series_equal(pivoted, exp)
  723: 
  724:     # test single series works the same
  725:     result = data["C"].groupby([data["A"], data["B"]]).mean()
  726:     expected = data.groupby(["A", "B"]).mean()["C"]
  727: 
  728:     tm.assert_series_equal(result, expected)
  729: 
  730: 
  731: def test_as_index_select_column():
  732:     # GH 5764
  733:     df = DataFrame([[1, 2], [1, 4], [5, 6]], columns=["A", "B"])
  734:     result = df.groupby("A", as_index=False)["B"].get_group(1)
  735:     expected = Series([2, 4], name="B")
  736:     tm.assert_series_equal(result, expected)
  737: 
  738:     result = df.groupby("A", as_index=False, group_keys=True)["B"].apply(
  739:         lambda x: x.cumsum()
  740:     )
  741:     expected = Series(
  742:         [2, 6, 6], name="B", index=MultiIndex.from_tuples([(0, 0), (0, 1), (1, 2)])
  743:     )
  744:     tm.assert_series_equal(result, expected)
  745: 
  746: 
  747: def test_obj_arg_get_group_deprecated():
  748:     depr_msg = "obj is deprecated"
  749: 
  750:     df = DataFrame({"a": [1, 1, 2], "b": [3, 4, 5]})
  751:     expected = df.iloc[df.groupby("b").indices.get(4)]
  752:     with tm.assert_produces_warning(FutureWarning, match=depr_msg):
  753:         result = df.groupby("b").get_group(4, obj=df)
  754:         tm.assert_frame_equal(result, expected)
  755: 
  756: 
  757: def test_groupby_as_index_select_column_sum_empty_df():
  758:     # GH 35246
  759:     df = DataFrame(columns=Index(["A", "B", "C"], name="alpha"))
  760:     left = df.groupby(by="A", as_index=False)["B"].sum(numeric_only=False)
  761: 
  762:     expected = DataFrame(columns=df.columns[:2], index=range(0))
  763:     # GH#50744 - Columns after selection shouldn't retain names
  764:     expected.columns.names = [None]
  765:     tm.assert_frame_equal(left, expected)
  766: 
  767: 
  768: def test_groupby_as_index_agg(df):
  769:     grouped = df.groupby("A", as_index=False)
  770: 
  771:     # single-key
  772: 
  773:     result = grouped[["C", "D"]].agg("mean")
  774:     expected = grouped.mean(numeric_only=True)
  775:     tm.assert_frame_equal(result, expected)
  776: 
  777:     result2 = grouped.agg({"C": "mean", "D": "sum"})
  778:     expected2 = grouped.mean(numeric_only=True)
  779:     expected2["D"] = grouped.sum()["D"]
  780:     tm.assert_frame_equal(result2, expected2)
  781: 
  782:     grouped = df.groupby("A", as_index=True)
  783: 
  784:     msg = r"nested renamer is not supported"
  785:     with pytest.raises(SpecificationError, match=msg):
  786:         grouped["C"].agg({"Q": "sum"})
  787: 
  788:     # multi-key
  789: 
  790:     grouped = df.groupby(["A", "B"], as_index=False)
  791: 
  792:     result = grouped.agg("mean")
  793:     expected = grouped.mean()
  794:     tm.assert_frame_equal(result, expected)
  795: 
  796:     result2 = grouped.agg({"C": "mean", "D": "sum"})
  797:     expected2 = grouped.mean()
  798:     expected2["D"] = grouped.sum()["D"]
  799:     tm.assert_frame_equal(result2, expected2)
  800: 
  801:     expected3 = grouped["C"].sum()
  802:     expected3 = DataFrame(expected3).rename(columns={"C": "Q"})
  803:     msg = "Passing a dictionary to SeriesGroupBy.agg is deprecated"
  804:     with tm.assert_produces_warning(FutureWarning, match=msg):
  805:         result3 = grouped["C"].agg({"Q": "sum"})
  806:     tm.assert_frame_equal(result3, expected3)
  807: 
  808:     # GH7115 & GH8112 & GH8582
  809:     df = DataFrame(
  810:         np.random.default_rng(2).integers(0, 100, (50, 3)),
  811:         columns=["jim", "joe", "jolie"],
  812:     )
  813:     ts = Series(np.random.default_rng(2).integers(5, 10, 50), name="jim")
  814: 
  815:     gr = df.groupby(ts)
  816:     gr.nth(0)  # invokes set_selection_from_grouper internally
  817: 
  818:     msg = "The behavior of DataFrame.sum with axis=None is deprecated"
  819:     with tm.assert_produces_warning(FutureWarning, match=msg, check_stacklevel=False):
  820:         res = gr.apply(sum)
  821:     with tm.assert_produces_warning(FutureWarning, match=msg, check_stacklevel=False):
  822:         alt = df.groupby(ts).apply(sum)
  823:     tm.assert_frame_equal(res, alt)
  824: 
  825:     for attr in ["mean", "max", "count", "idxmax", "cumsum", "all"]:
  826:         gr = df.groupby(ts, as_index=False)
  827:         left = getattr(gr, attr)()
  828: 
  829:         gr = df.groupby(ts.values, as_index=True)
  830:         right = getattr(gr, attr)().reset_index(drop=True)
  831: 
  832:         tm.assert_frame_equal(left, right)
  833: 
  834: 
  835: def test_ops_not_as_index(reduction_func):
  836:     # GH 10355, 21090
  837:     # Using as_index=False should not modify grouped column
  838: 
  839:     if reduction_func in ("corrwith", "nth", "ngroup"):
  840:         pytest.skip(f"GH 5755: Test not applicable for {reduction_func}")
  841: 
  842:     df = DataFrame(
  843:         np.random.default_rng(2).integers(0, 5, size=(100, 2)), columns=["a", "b"]
  844:     )
  845:     expected = getattr(df.groupby("a"), reduction_func)()
  846:     if reduction_func == "size":
  847:         expected = expected.rename("size")
  848:     expected = expected.reset_index()
  849: 
  850:     if reduction_func != "size":
  851:         # 32 bit compat -> groupby preserves dtype whereas reset_index casts to int64
  852:         expected["a"] = expected["a"].astype(df["a"].dtype)
  853: 
  854:     g = df.groupby("a", as_index=False)
  855: 
  856:     result = getattr(g, reduction_func)()
  857:     tm.assert_frame_equal(result, expected)
  858: 
  859:     result = g.agg(reduction_func)
  860:     tm.assert_frame_equal(result, expected)
  861: 
  862:     result = getattr(g["b"], reduction_func)()
  863:     tm.assert_frame_equal(result, expected)
  864: 
  865:     result = g["b"].agg(reduction_func)
  866:     tm.assert_frame_equal(result, expected)
  867: 
  868: 
  869: def test_as_index_series_return_frame(df):
  870:     grouped = df.groupby("A", as_index=False)
  871:     grouped2 = df.groupby(["A", "B"], as_index=False)
  872: 
  873:     result = grouped["C"].agg("sum")
  874:     expected = grouped.agg("sum").loc[:, ["A", "C"]]
  875:     assert isinstance(result, DataFrame)
  876:     tm.assert_frame_equal(result, expected)
  877: 
  878:     result2 = grouped2["C"].agg("sum")
  879:     expected2 = grouped2.agg("sum").loc[:, ["A", "B", "C"]]
  880:     assert isinstance(result2, DataFrame)
  881:     tm.assert_frame_equal(result2, expected2)
  882: 
  883:     result = grouped["C"].sum()
  884:     expected = grouped.sum().loc[:, ["A", "C"]]
  885:     assert isinstance(result, DataFrame)
  886:     tm.assert_frame_equal(result, expected)
  887: 
  888:     result2 = grouped2["C"].sum()
  889:     expected2 = grouped2.sum().loc[:, ["A", "B", "C"]]
  890:     assert isinstance(result2, DataFrame)
  891:     tm.assert_frame_equal(result2, expected2)
  892: 
  893: 
  894: def test_as_index_series_column_slice_raises(df):
  895:     # GH15072
  896:     grouped = df.groupby("A", as_index=False)
  897:     msg = r"Column\(s\) C already selected"
  898: 
  899:     with pytest.raises(IndexError, match=msg):
  900:         grouped["C"].__getitem__("D")
  901: 
  902: 
  903: def test_groupby_as_index_cython(df):
  904:     data = df
  905: 
  906:     # single-key
  907:     grouped = data.groupby("A", as_index=False)
  908:     result = grouped.mean(numeric_only=True)
  909:     expected = data.groupby(["A"]).mean(numeric_only=True)
  910:     expected.insert(0, "A", expected.index)
  911:     expected.index = RangeIndex(len(expected))
  912:     tm.assert_frame_equal(result, expected)
  913: 
  914:     # multi-key
  915:     grouped = data.groupby(["A", "B"], as_index=False)
  916:     result = grouped.mean()
  917:     expected = data.groupby(["A", "B"]).mean()
  918: 
  919:     arrays = list(zip(*expected.index.values))
  920:     expected.insert(0, "A", arrays[0])
  921:     expected.insert(1, "B", arrays[1])
  922:     expected.index = RangeIndex(len(expected))
  923:     tm.assert_frame_equal(result, expected)
  924: 
  925: 
  926: def test_groupby_as_index_series_scalar(df):
  927:     grouped = df.groupby(["A", "B"], as_index=False)
  928: 
  929:     # GH #421
  930: 
  931:     result = grouped["C"].agg(len)
  932:     expected = grouped.agg(len).loc[:, ["A", "B", "C"]]
  933:     tm.assert_frame_equal(result, expected)
  934: 
  935: 
  936: def test_groupby_as_index_corner(df, ts):
  937:     msg = "as_index=False only valid with DataFrame"
  938:     with pytest.raises(TypeError, match=msg):
  939:         ts.groupby(lambda x: x.weekday(), as_index=False)
  940: 
  941:     msg = "as_index=False only valid for axis=0"
  942:     depr_msg = "DataFrame.groupby with axis=1 is deprecated"
  943:     with pytest.raises(ValueError, match=msg):
  944:         with tm.assert_produces_warning(FutureWarning, match=depr_msg):
  945:             df.groupby(lambda x: x.lower(), as_index=False, axis=1)
  946: 
  947: 
  948: def test_groupby_multiple_key():
  949:     df = DataFrame(
  950:         np.random.default_rng(2).standard_normal((10, 4)),
  951:         columns=Index(list("ABCD"), dtype=object),
  952:         index=date_range("2000-01-01", periods=10, freq="B"),
  953:     )
  954:     grouped = df.groupby([lambda x: x.year, lambda x: x.month, lambda x: x.day])
  955:     agged = grouped.sum()
  956:     tm.assert_almost_equal(df.values, agged.values)
  957: 
  958:     depr_msg = "DataFrame.groupby with axis=1 is deprecated"
  959:     with tm.assert_produces_warning(FutureWarning, match=depr_msg):
  960:         grouped = df.T.groupby(
  961:             [lambda x: x.year, lambda x: x.month, lambda x: x.day], axis=1
  962:         )
  963: 
  964:     agged = grouped.agg(lambda x: x.sum())
  965:     tm.assert_index_equal(agged.index, df.columns)
  966:     tm.assert_almost_equal(df.T.values, agged.values)
  967: 
  968:     agged = grouped.agg(lambda x: x.sum())
  969:     tm.assert_almost_equal(df.T.values, agged.values)
  970: 
  971: 
  972: def test_groupby_multi_corner(df):
  973:     # test that having an all-NA column doesn't mess you up
  974:     df = df.copy()
  975:     df["bad"] = np.nan
  976:     agged = df.groupby(["A", "B"]).mean()
  977: 
  978:     expected = df.groupby(["A", "B"]).mean()
  979:     expected["bad"] = np.nan
  980: 
  981:     tm.assert_frame_equal(agged, expected)
  982: 
  983: 
  984: def test_raises_on_nuisance(df):
  985:     grouped = df.groupby("A")
  986:     msg = re.escape("agg function failed [how->mean,dtype->")
  987:     with pytest.raises(TypeError, match=msg):
  988:         grouped.agg("mean")
  989:     with pytest.raises(TypeError, match=msg):
  990:         grouped.mean()
  991: 
  992:     df = df.loc[:, ["A", "C", "D"]]
  993:     df["E"] = datetime.now()
  994:     grouped = df.groupby("A")
  995:     msg = "datetime64 type does not support sum operations"
  996:     with pytest.raises(TypeError, match=msg):
  997:         grouped.agg("sum")
  998:     with pytest.raises(TypeError, match=msg):
  999:         grouped.sum()
 1000: 
 1001:     # won't work with axis = 1
 1002:     depr_msg = "DataFrame.groupby with axis=1 is deprecated"
 1003:     with tm.assert_produces_warning(FutureWarning, match=depr_msg):
 1004:         grouped = df.groupby({"A": 0, "C": 0, "D": 1, "E": 1}, axis=1)
 1005:     msg = "does not support reduction 'sum'"
 1006:     with pytest.raises(TypeError, match=msg):
 1007:         grouped.agg(lambda x: x.sum(0, numeric_only=False))
 1008: 
 1009: 
 1010: @pytest.mark.parametrize(
 1011:     "agg_function",
 1012:     ["max", "min"],
 1013: )
 1014: def test_keep_nuisance_agg(df, agg_function):
 1015:     # GH 38815
 1016:     grouped = df.groupby("A")
 1017:     result = getattr(grouped, agg_function)()
 1018:     expected = result.copy()
 1019:     expected.loc["bar", "B"] = getattr(df.loc[df["A"] == "bar", "B"], agg_function)()
 1020:     expected.loc["foo", "B"] = getattr(df.loc[df["A"] == "foo", "B"], agg_function)()
 1021:     tm.assert_frame_equal(result, expected)
 1022: 
 1023: 
 1024: @pytest.mark.parametrize(
 1025:     "agg_function",
 1026:     ["sum", "mean", "prod", "std", "var", "sem", "median"],
 1027: )
 1028: @pytest.mark.parametrize("numeric_only", [True, False])
 1029: def test_omit_nuisance_agg(df, agg_function, numeric_only):
 1030:     # GH 38774, GH 38815
 1031:     grouped = df.groupby("A")
 1032: 
 1033:     no_drop_nuisance = ("var", "std", "sem", "mean", "prod", "median")
 1034:     if agg_function in no_drop_nuisance and not numeric_only:
 1035:         # Added numeric_only as part of GH#46560; these do not drop nuisance
 1036:         # columns when numeric_only is False
 1037:         if agg_function in ("std", "sem"):
 1038:             klass = ValueError
 1039:             msg = "could not convert string to float: 'one'"
 1040:         else:
 1041:             klass = TypeError
 1042:             msg = re.escape(f"agg function failed [how->{agg_function},dtype->")
 1043:         with pytest.raises(klass, match=msg):
 1044:             getattr(grouped, agg_function)(numeric_only=numeric_only)
 1045:     else:
 1046:         result = getattr(grouped, agg_function)(numeric_only=numeric_only)
 1047:         if not numeric_only and agg_function == "sum":
 1048:             # sum is successful on column B
 1049:             columns = ["A", "B", "C", "D"]
 1050:         else:
 1051:             columns = ["A", "C", "D"]
 1052:         expected = getattr(df.loc[:, columns].groupby("A"), agg_function)(
 1053:             numeric_only=numeric_only
 1054:         )
 1055:         tm.assert_frame_equal(result, expected)
 1056: 
 1057: 
 1058: def test_raise_on_nuisance_python_single(df):
 1059:     # GH 38815
 1060:     grouped = df.groupby("A")
 1061:     with pytest.raises(ValueError, match="could not convert"):
 1062:         grouped.skew()
 1063: 
 1064: 
 1065: def test_raise_on_nuisance_python_multiple(three_group):
 1066:     grouped = three_group.groupby(["A", "B"])
 1067:     msg = re.escape("agg function failed [how->mean,dtype->")
 1068:     with pytest.raises(TypeError, match=msg):
 1069:         grouped.agg("mean")
 1070:     with pytest.raises(TypeError, match=msg):
 1071:         grouped.mean()
 1072: 
 1073: 
 1074: def test_empty_groups_corner(multiindex_dataframe_random_data):
 1075:     # handle empty groups
 1076:     df = DataFrame(
 1077:         {
 1078:             "k1": np.array(["b", "b", "b", "a", "a", "a"]),
 1079:             "k2": np.array(["1", "1", "1", "2", "2", "2"]),
 1080:             "k3": ["foo", "bar"] * 3,
 1081:             "v1": np.random.default_rng(2).standard_normal(6),
 1082:             "v2": np.random.default_rng(2).standard_normal(6),
 1083:         }
 1084:     )
 1085: 
 1086:     grouped = df.groupby(["k1", "k2"])
 1087:     result = grouped[["v1", "v2"]].agg("mean")
 1088:     expected = grouped.mean(numeric_only=True)
 1089:     tm.assert_frame_equal(result, expected)
 1090: 
 1091:     grouped = multiindex_dataframe_random_data[3:5].groupby(level=0)
 1092:     agged = grouped.apply(lambda x: x.mean())
 1093:     agged_A = grouped["A"].apply("mean")
 1094:     tm.assert_series_equal(agged["A"], agged_A)
 1095:     assert agged.index.name == "first"
 1096: 
 1097: 
 1098: def test_nonsense_func():
 1099:     df = DataFrame([0])
 1100:     msg = r"unsupported operand type\(s\) for \+: 'int' and 'str'"
 1101:     with pytest.raises(TypeError, match=msg):
 1102:         df.groupby(lambda x: x + "foo")
 1103: 
 1104: 
 1105: def test_wrap_aggregated_output_multindex(multiindex_dataframe_random_data):
 1106:     df = multiindex_dataframe_random_data.T
 1107:     df["baz", "two"] = "peekaboo"
 1108: 
 1109:     keys = [np.array([0, 0, 1]), np.array([0, 0, 1])]
 1110:     msg = re.escape("agg function failed [how->mean,dtype->")
 1111:     with pytest.raises(TypeError, match=msg):
 1112:         df.groupby(keys).agg("mean")
 1113:     agged = df.drop(columns=("baz", "two")).groupby(keys).agg("mean")
 1114:     assert isinstance(agged.columns, MultiIndex)
 1115: 
 1116:     def aggfun(ser):
 1117:         if ser.name == ("foo", "one"):
 1118:             raise TypeError("Test error message")
 1119:         return ser.sum()
 1120: 
 1121:     with pytest.raises(TypeError, match="Test error message"):
 1122:         df.groupby(keys).aggregate(aggfun)
 1123: 
 1124: 
 1125: def test_groupby_level_apply(multiindex_dataframe_random_data):
 1126:     result = multiindex_dataframe_random_data.groupby(level=0).count()
 1127:     assert result.index.name == "first"
 1128:     result = multiindex_dataframe_random_data.groupby(level=1).count()
 1129:     assert result.index.name == "second"
 1130: 
 1131:     result = multiindex_dataframe_random_data["A"].groupby(level=0).count()
 1132:     assert result.index.name == "first"
 1133: 
 1134: 
 1135: def test_groupby_level_mapper(multiindex_dataframe_random_data):
 1136:     deleveled = multiindex_dataframe_random_data.reset_index()
 1137: 
 1138:     mapper0 = {"foo": 0, "bar": 0, "baz": 1, "qux": 1}
 1139:     mapper1 = {"one": 0, "two": 0, "three": 1}
 1140: 
 1141:     result0 = multiindex_dataframe_random_data.groupby(mapper0, level=0).sum()
 1142:     result1 = multiindex_dataframe_random_data.groupby(mapper1, level=1).sum()
 1143: 
 1144:     mapped_level0 = np.array(
 1145:         [mapper0.get(x) for x in deleveled["first"]], dtype=np.int64
 1146:     )
 1147:     mapped_level1 = np.array(
 1148:         [mapper1.get(x) for x in deleveled["second"]], dtype=np.int64
 1149:     )
 1150:     expected0 = multiindex_dataframe_random_data.groupby(mapped_level0).sum()
 1151:     expected1 = multiindex_dataframe_random_data.groupby(mapped_level1).sum()
 1152:     expected0.index.name, expected1.index.name = "first", "second"
 1153: 
 1154:     tm.assert_frame_equal(result0, expected0)
 1155:     tm.assert_frame_equal(result1, expected1)
 1156: 
 1157: 
 1158: def test_groupby_level_nonmulti():
 1159:     # GH 1313, GH 13901
 1160:     s = Series([1, 2, 3, 10, 4, 5, 20, 6], Index([1, 2, 3, 1, 4, 5, 2, 6], name="foo"))
 1161:     expected = Series([11, 22, 3, 4, 5, 6], Index(range(1, 7), name="foo"))
 1162: 
 1163:     result = s.groupby(level=0).sum()
 1164:     tm.assert_series_equal(result, expected)
 1165:     result = s.groupby(level=[0]).sum()
 1166:     tm.assert_series_equal(result, expected)
 1167:     result = s.groupby(level=-1).sum()
 1168:     tm.assert_series_equal(result, expected)
 1169:     result = s.groupby(level=[-1]).sum()
 1170:     tm.assert_series_equal(result, expected)
 1171: 
 1172:     msg = "level > 0 or level < -1 only valid with MultiIndex"
 1173:     with pytest.raises(ValueError, match=msg):
 1174:         s.groupby(level=1)
 1175:     with pytest.raises(ValueError, match=msg):
 1176:         s.groupby(level=-2)
 1177:     msg = "No group keys passed!"
 1178:     with pytest.raises(ValueError, match=msg):
 1179:         s.groupby(level=[])
 1180:     msg = "multiple levels only valid with MultiIndex"
 1181:     with pytest.raises(ValueError, match=msg):
 1182:         s.groupby(level=[0, 0])
 1183:     with pytest.raises(ValueError, match=msg):
 1184:         s.groupby(level=[0, 1])
 1185:     msg = "level > 0 or level < -1 only valid with MultiIndex"
 1186:     with pytest.raises(ValueError, match=msg):
 1187:         s.groupby(level=[1])
 1188: 
 1189: 
 1190: def test_groupby_complex():
 1191:     # GH 12902
 1192:     a = Series(data=np.arange(4) * (1 + 2j), index=[0, 0, 1, 1])
 1193:     expected = Series((1 + 2j, 5 + 10j))
 1194: 
 1195:     result = a.groupby(level=0).sum()
 1196:     tm.assert_series_equal(result, expected)
 1197: 
 1198: 
 1199: def test_groupby_complex_mean():
 1200:     # GH 26475
 1201:     df = DataFrame(
 1202:         [
 1203:             {"a": 2, "b": 1 + 2j},
 1204:             {"a": 1, "b": 1 + 1j},
 1205:             {"a": 1, "b": 1 + 2j},
 1206:         ]
 1207:     )
 1208:     result = df.groupby("b").mean()
 1209:     expected = DataFrame(
 1210:         [[1.0], [1.5]],
 1211:         index=Index([(1 + 1j), (1 + 2j)], name="b"),
 1212:         columns=Index(["a"]),
 1213:     )
 1214:     tm.assert_frame_equal(result, expected)
 1215: 
 1216: 
 1217: def test_groupby_complex_numbers(using_infer_string):
 1218:     # GH 17927
 1219:     df = DataFrame(
 1220:         [
 1221:             {"a": 1, "b": 1 + 1j},
 1222:             {"a": 1, "b": 1 + 2j},
 1223:             {"a": 4, "b": 1},
 1224:         ]
 1225:     )
 1226:     dtype = "string[pyarrow_numpy]" if using_infer_string else object
 1227:     expected = DataFrame(
 1228:         np.array([1, 1, 1], dtype=np.int64),
 1229:         index=Index([(1 + 1j), (1 + 2j), (1 + 0j)], name="b"),
 1230:         columns=Index(["a"], dtype=dtype),
 1231:     )
 1232:     result = df.groupby("b", sort=False).count()
 1233:     tm.assert_frame_equal(result, expected)
 1234: 
 1235:     # Sorted by the magnitude of the complex numbers
 1236:     expected.index = Index([(1 + 0j), (1 + 1j), (1 + 2j)], name="b")
 1237:     result = df.groupby("b", sort=True).count()
 1238:     tm.assert_frame_equal(result, expected)
 1239: 
 1240: 
 1241: def test_groupby_series_indexed_differently():
 1242:     s1 = Series(
 1243:         [5.0, -9.0, 4.0, 100.0, -5.0, 55.0, 6.7],
 1244:         index=Index(["a", "b", "c", "d", "e", "f", "g"]),
 1245:     )
 1246:     s2 = Series(
 1247:         [1.0, 1.0, 4.0, 5.0, 5.0, 7.0], index=Index(["a", "b", "d", "f", "g", "h"])
 1248:     )
 1249: 
 1250:     grouped = s1.groupby(s2)
 1251:     agged = grouped.mean()
 1252:     exp = s1.groupby(s2.reindex(s1.index).get).mean()
 1253:     tm.assert_series_equal(agged, exp)
 1254: 
 1255: 
 1256: def test_groupby_with_hier_columns():
 1257:     tuples = list(
 1258:         zip(
 1259:             *[
 1260:                 ["bar", "bar", "baz", "baz", "foo", "foo", "qux", "qux"],
 1261:                 ["one", "two", "one", "two", "one", "two", "one", "two"],
 1262:             ]
 1263:         )
 1264:     )
 1265:     index = MultiIndex.from_tuples(tuples)
 1266:     columns = MultiIndex.from_tuples(
 1267:         [("A", "cat"), ("B", "dog"), ("B", "cat"), ("A", "dog")]
 1268:     )
 1269:     df = DataFrame(
 1270:         np.random.default_rng(2).standard_normal((8, 4)), index=index, columns=columns
 1271:     )
 1272: 
 1273:     result = df.groupby(level=0).mean()
 1274:     tm.assert_index_equal(result.columns, columns)
 1275: 
 1276:     depr_msg = "DataFrame.groupby with axis=1 is deprecated"
 1277:     with tm.assert_produces_warning(FutureWarning, match=depr_msg):
 1278:         gb = df.groupby(level=0, axis=1)
 1279:     result = gb.mean()
 1280:     tm.assert_index_equal(result.index, df.index)
 1281: 
 1282:     result = df.groupby(level=0).agg("mean")
 1283:     tm.assert_index_equal(result.columns, columns)
 1284: 
 1285:     result = df.groupby(level=0).apply(lambda x: x.mean())
 1286:     tm.assert_index_equal(result.columns, columns)
 1287: 
 1288:     with tm.assert_produces_warning(FutureWarning, match=depr_msg):
 1289:         gb = df.groupby(level=0, axis=1)
 1290:     result = gb.agg(lambda x: x.mean(1))
 1291:     tm.assert_index_equal(result.columns, Index(["A", "B"]))
 1292:     tm.assert_index_equal(result.index, df.index)
 1293: 
 1294:     # add a nuisance column
 1295:     sorted_columns, _ = columns.sortlevel(0)
 1296:     df["A", "foo"] = "bar"
 1297:     result = df.groupby(level=0).mean(numeric_only=True)
 1298:     tm.assert_index_equal(result.columns, df.columns[:-1])
 1299: 
 1300: 
 1301: def test_grouping_ndarray(df):
 1302:     grouped = df.groupby(df["A"].values)
 1303:     result = grouped.sum()
 1304:     expected = df.groupby(df["A"].rename(None)).sum()
 1305:     tm.assert_frame_equal(result, expected)
 1306: 
 1307: 
 1308: def test_groupby_wrong_multi_labels():
 1309:     index = Index([0, 1, 2, 3, 4], name="index")
 1310:     data = DataFrame(
 1311:         {
 1312:             "foo": ["foo1", "foo1", "foo2", "foo1", "foo3"],
 1313:             "bar": ["bar1", "bar2", "bar2", "bar1", "bar1"],
 1314:             "baz": ["baz1", "baz1", "baz1", "baz2", "baz2"],
 1315:             "spam": ["spam2", "spam3", "spam2", "spam1", "spam1"],
 1316:             "data": [20, 30, 40, 50, 60],
 1317:         },
 1318:         index=index,
 1319:     )
 1320: 
 1321:     grouped = data.groupby(["foo", "bar", "baz", "spam"])
 1322: 
 1323:     result = grouped.agg("mean")
 1324:     expected = grouped.mean()
 1325:     tm.assert_frame_equal(result, expected)
 1326: 
 1327: 
 1328: def test_groupby_series_with_name(df):
 1329:     result = df.groupby(df["A"]).mean(numeric_only=True)
 1330:     result2 = df.groupby(df["A"], as_index=False).mean(numeric_only=True)
 1331:     assert result.index.name == "A"
 1332:     assert "A" in result2
 1333: 
 1334:     result = df.groupby([df["A"], df["B"]]).mean()
 1335:     result2 = df.groupby([df["A"], df["B"]], as_index=False).mean()
 1336:     assert result.index.names == ("A", "B")
 1337:     assert "A" in result2
 1338:     assert "B" in result2
 1339: 
 1340: 
 1341: def test_seriesgroupby_name_attr(df):
 1342:     # GH 6265
 1343:     result = df.groupby("A")["C"]
 1344:     assert result.count().name == "C"
 1345:     assert result.mean().name == "C"
 1346: 
 1347:     testFunc = lambda x: np.sum(x) * 2
 1348:     assert result.agg(testFunc).name == "C"
 1349: 
 1350: 
 1351: def test_consistency_name():
 1352:     # GH 12363
 1353: 
 1354:     df = DataFrame(
 1355:         {
 1356:             "A": ["foo", "bar", "foo", "bar", "foo", "bar", "foo", "foo"],
 1357:             "B": ["one", "one", "two", "two", "two", "two", "one", "two"],
 1358:             "C": np.random.default_rng(2).standard_normal(8) + 1.0,
 1359:             "D": np.arange(8),
 1360:         }
 1361:     )
 1362: 
 1363:     expected = df.groupby(["A"]).B.count()
 1364:     result = df.B.groupby(df.A).count()
 1365:     tm.assert_series_equal(result, expected)
 1366: 
 1367: 
 1368: def test_groupby_name_propagation(df):
 1369:     # GH 6124
 1370:     def summarize(df, name=None):
 1371:         return Series({"count": 1, "mean": 2, "omissions": 3}, name=name)
 1372: 
 1373:     def summarize_random_name(df):
 1374:         # Provide a different name for each Series.  In this case, groupby
 1375:         # should not attempt to propagate the Series name since they are
 1376:         # inconsistent.
 1377:         return Series({"count": 1, "mean": 2, "omissions": 3}, name=df.iloc[0]["A"])
 1378: 
 1379:     msg = "DataFrameGroupBy.apply operated on the grouping columns"
 1380:     with tm.assert_produces_warning(DeprecationWarning, match=msg):
 1381:         metrics = df.groupby("A").apply(summarize)
 1382:     assert metrics.columns.name is None
 1383:     with tm.assert_produces_warning(DeprecationWarning, match=msg):
 1384:         metrics = df.groupby("A").apply(summarize, "metrics")
 1385:     assert metrics.columns.name == "metrics"
 1386:     with tm.assert_produces_warning(DeprecationWarning, match=msg):
 1387:         metrics = df.groupby("A").apply(summarize_random_name)
 1388:     assert metrics.columns.name is None
 1389: 
 1390: 
 1391: def test_groupby_nonstring_columns():
 1392:     df = DataFrame([np.arange(10) for x in range(10)])
 1393:     grouped = df.groupby(0)
 1394:     result = grouped.mean()
 1395:     expected = df.groupby(df[0]).mean()
 1396:     tm.assert_frame_equal(result, expected)
 1397: 
 1398: 
 1399: def test_groupby_mixed_type_columns():
 1400:     # GH 13432, unorderable types in py3
 1401:     df = DataFrame([[0, 1, 2]], columns=["A", "B", 0])
 1402:     expected = DataFrame([[1, 2]], columns=["B", 0], index=Index([0], name="A"))
 1403: 
 1404:     result = df.groupby("A").first()
 1405:     tm.assert_frame_equal(result, expected)
 1406: 
 1407:     result = df.groupby("A").sum()
 1408:     tm.assert_frame_equal(result, expected)
 1409: 
 1410: 
 1411: def test_cython_grouper_series_bug_noncontig():
 1412:     arr = np.empty((100, 100))
 1413:     arr.fill(np.nan)
 1414:     obj = Series(arr[:, 0])
 1415:     inds = np.tile(range(10), 10)
 1416: 
 1417:     result = obj.groupby(inds).agg(Series.median)
 1418:     assert result.isna().all()
 1419: 
 1420: 
 1421: def test_series_grouper_noncontig_index():
 1422:     index = Index(["a" * 10] * 100)
 1423: 
 1424:     values = Series(np.random.default_rng(2).standard_normal(50), index=index[::2])
 1425:     labels = np.random.default_rng(2).integers(0, 5, 50)
 1426: 
 1427:     # it works!
 1428:     grouped = values.groupby(labels)
 1429: 
 1430:     # accessing the index elements causes segfault
 1431:     f = lambda x: len(set(map(id, x.index)))
 1432:     grouped.agg(f)
 1433: 
 1434: 
 1435: def test_convert_objects_leave_decimal_alone():
 1436:     s = Series(range(5))
 1437:     labels = np.array(["a", "b", "c", "d", "e"], dtype="O")
 1438: 
 1439:     def convert_fast(x):
 1440:         return Decimal(str(x.mean()))
 1441: 
 1442:     def convert_force_pure(x):
 1443:         # base will be length 0
 1444:         assert len(x.values.base) > 0
 1445:         return Decimal(str(x.mean()))
 1446: 
 1447:     grouped = s.groupby(labels)
 1448: 
 1449:     result = grouped.agg(convert_fast)
 1450:     assert result.dtype == np.object_
 1451:     assert isinstance(result.iloc[0], Decimal)
 1452: 
 1453:     result = grouped.agg(convert_force_pure)
 1454:     assert result.dtype == np.object_
 1455:     assert isinstance(result.iloc[0], Decimal)
 1456: 
 1457: 
 1458: def test_groupby_dtype_inference_empty():
 1459:     # GH 6733
 1460:     df = DataFrame({"x": [], "range": np.arange(0, dtype="int64")})
 1461:     assert df["x"].dtype == np.float64
 1462: 
 1463:     result = df.groupby("x").first()
 1464:     exp_index = Index([], name="x", dtype=np.float64)
 1465:     expected = DataFrame({"range": Series([], index=exp_index, dtype="int64")})
 1466:     tm.assert_frame_equal(result, expected, by_blocks=True)
 1467: 
 1468: 
 1469: def test_groupby_unit64_float_conversion():
 1470:     # GH: 30859 groupby converts unit64 to floats sometimes
 1471:     df = DataFrame({"first": [1], "second": [1], "value": [16148277970000000000]})
 1472:     result = df.groupby(["first", "second"])["value"].max()
 1473:     expected = Series(
 1474:         [16148277970000000000],
 1475:         MultiIndex.from_product([[1], [1]], names=["first", "second"]),
 1476:         name="value",
 1477:     )
 1478:     tm.assert_series_equal(result, expected)
 1479: 
 1480: 
 1481: def test_groupby_list_infer_array_like(df):
 1482:     result = df.groupby(list(df["A"])).mean(numeric_only=True)
 1483:     expected = df.groupby(df["A"]).mean(numeric_only=True)
 1484:     tm.assert_frame_equal(result, expected, check_names=False)
 1485: 
 1486:     with pytest.raises(KeyError, match=r"^'foo'$"):
 1487:         df.groupby(list(df["A"][:-1]))
 1488: 
 1489:     # pathological case of ambiguity
 1490:     df = DataFrame(
 1491:         {
 1492:             "foo": [0, 1],
 1493:             "bar": [3, 4],
 1494:             "val": np.random.default_rng(2).standard_normal(2),
 1495:         }
 1496:     )
 1497: 
 1498:     result = df.groupby(["foo", "bar"]).mean()
 1499:     expected = df.groupby([df["foo"], df["bar"]]).mean()[["val"]]
 1500: 
 1501: 
 1502: def test_groupby_keys_same_size_as_index():
 1503:     # GH 11185
 1504:     freq = "s"
 1505:     index = date_range(
 1506:         start=Timestamp("2015-09-29T11:34:44-0700"), periods=2, freq=freq
 1507:     )
 1508:     df = DataFrame([["A", 10], ["B", 15]], columns=["metric", "values"], index=index)
 1509:     result = df.groupby([Grouper(level=0, freq=freq), "metric"]).mean()
 1510:     expected = df.set_index([df.index, "metric"]).astype(float)
 1511: 
 1512:     tm.assert_frame_equal(result, expected)
 1513: 
 1514: 
 1515: def test_groupby_one_row():
 1516:     # GH 11741
 1517:     msg = r"^'Z'$"
 1518:     df1 = DataFrame(
 1519:         np.random.default_rng(2).standard_normal((1, 4)), columns=list("ABCD")
 1520:     )
 1521:     with pytest.raises(KeyError, match=msg):
 1522:         df1.groupby("Z")
 1523:     df2 = DataFrame(
 1524:         np.random.default_rng(2).standard_normal((2, 4)), columns=list("ABCD")
 1525:     )
 1526:     with pytest.raises(KeyError, match=msg):
 1527:         df2.groupby("Z")
 1528: 
 1529: 
 1530: def test_groupby_nat_exclude():
 1531:     # GH 6992
 1532:     df = DataFrame(
 1533:         {
 1534:             "values": np.random.default_rng(2).standard_normal(8),
 1535:             "dt": [
 1536:                 np.nan,
 1537:                 Timestamp("2013-01-01"),
 1538:                 np.nan,
 1539:                 Timestamp("2013-02-01"),
 1540:                 np.nan,
 1541:                 Timestamp("2013-02-01"),
 1542:                 np.nan,
 1543:                 Timestamp("2013-01-01"),
 1544:             ],
 1545:             "str": [np.nan, "a", np.nan, "a", np.nan, "a", np.nan, "b"],
 1546:         }
 1547:     )
 1548:     grouped = df.groupby("dt")
 1549: 
 1550:     expected = [Index([1, 7]), Index([3, 5])]
 1551:     keys = sorted(grouped.groups.keys())
 1552:     assert len(keys) == 2
 1553:     for k, e in zip(keys, expected):
 1554:         # grouped.groups keys are np.datetime64 with system tz
 1555:         # not to be affected by tz, only compare values
 1556:         tm.assert_index_equal(grouped.groups[k], e)
 1557: 
 1558:     # confirm obj is not filtered
 1559:     tm.assert_frame_equal(grouped._grouper.groupings[0].obj, df)
 1560:     assert grouped.ngroups == 2
 1561: 
 1562:     expected = {
 1563:         Timestamp("2013-01-01 00:00:00"): np.array([1, 7], dtype=np.intp),
 1564:         Timestamp("2013-02-01 00:00:00"): np.array([3, 5], dtype=np.intp),
 1565:     }
 1566: 
 1567:     for k in grouped.indices:
 1568:         tm.assert_numpy_array_equal(grouped.indices[k], expected[k])
 1569: 
 1570:     tm.assert_frame_equal(grouped.get_group(Timestamp("2013-01-01")), df.iloc[[1, 7]])
 1571:     tm.assert_frame_equal(grouped.get_group(Timestamp("2013-02-01")), df.iloc[[3, 5]])
 1572: 
 1573:     with pytest.raises(KeyError, match=r"^NaT$"):
 1574:         grouped.get_group(pd.NaT)
 1575: 
 1576:     nan_df = DataFrame(
 1577:         {"nan": [np.nan, np.nan, np.nan], "nat": [pd.NaT, pd.NaT, pd.NaT]}
 1578:     )
 1579:     assert nan_df["nan"].dtype == "float64"
 1580:     assert nan_df["nat"].dtype == "datetime64[ns]"
 1581: 
 1582:     for key in ["nan", "nat"]:
 1583:         grouped = nan_df.groupby(key)
 1584:         assert grouped.groups == {}
 1585:         assert grouped.ngroups == 0
 1586:         assert grouped.indices == {}
 1587:         with pytest.raises(KeyError, match=r"^nan$"):
 1588:             grouped.get_group(np.nan)
 1589:         with pytest.raises(KeyError, match=r"^NaT$"):
 1590:             grouped.get_group(pd.NaT)
 1591: 
 1592: 
 1593: def test_groupby_two_group_keys_all_nan():
 1594:     # GH #36842: Grouping over two group keys shouldn't raise an error
 1595:     df = DataFrame({"a": [np.nan, np.nan], "b": [np.nan, np.nan], "c": [1, 2]})
 1596:     result = df.groupby(["a", "b"]).indices
 1597:     assert result == {}
 1598: 
 1599: 
 1600: def test_groupby_2d_malformed():
 1601:     d = DataFrame(index=range(2))
 1602:     d["group"] = ["g1", "g2"]
 1603:     d["zeros"] = [0, 0]
 1604:     d["ones"] = [1, 1]
 1605:     d["label"] = ["l1", "l2"]
 1606:     tmp = d.groupby(["group"]).mean(numeric_only=True)
 1607:     res_values = np.array([[0.0, 1.0], [0.0, 1.0]])
 1608:     tm.assert_index_equal(tmp.columns, Index(["zeros", "ones"]))
 1609:     tm.assert_numpy_array_equal(tmp.values, res_values)
 1610: 
 1611: 
 1612: def test_int32_overflow():
 1613:     B = np.concatenate((np.arange(10000), np.arange(10000), np.arange(5000)))
 1614:     A = np.arange(25000)
 1615:     df = DataFrame(
 1616:         {
 1617:             "A": A,
 1618:             "B": B,
 1619:             "C": A,
 1620:             "D": B,
 1621:             "E": np.random.default_rng(2).standard_normal(25000),
 1622:         }
 1623:     )
 1624: 
 1625:     left = df.groupby(["A", "B", "C", "D"]).sum()
 1626:     right = df.groupby(["D", "C", "B", "A"]).sum()
 1627:     assert len(left) == len(right)
 1628: 
 1629: 
 1630: def test_groupby_sort_multi():
 1631:     df = DataFrame(
 1632:         {
 1633:             "a": ["foo", "bar", "baz"],
 1634:             "b": [3, 2, 1],
 1635:             "c": [0, 1, 2],
 1636:             "d": np.random.default_rng(2).standard_normal(3),
 1637:         }
 1638:     )
 1639: 
 1640:     tups = [tuple(row) for row in df[["a", "b", "c"]].values]
 1641:     tups = com.asarray_tuplesafe(tups)
 1642:     result = df.groupby(["a", "b", "c"], sort=True).sum()
 1643:     tm.assert_numpy_array_equal(result.index.values, tups[[1, 2, 0]])
 1644: 
 1645:     tups = [tuple(row) for row in df[["c", "a", "b"]].values]
 1646:     tups = com.asarray_tuplesafe(tups)
 1647:     result = df.groupby(["c", "a", "b"], sort=True).sum()
 1648:     tm.assert_numpy_array_equal(result.index.values, tups)
 1649: 
 1650:     tups = [tuple(x) for x in df[["b", "c", "a"]].values]
 1651:     tups = com.asarray_tuplesafe(tups)
 1652:     result = df.groupby(["b", "c", "a"], sort=True).sum()
 1653:     tm.assert_numpy_array_equal(result.index.values, tups[[2, 1, 0]])
 1654: 
 1655:     df = DataFrame(
 1656:         {
 1657:             "a": [0, 1, 2, 0, 1, 2],
 1658:             "b": [0, 0, 0, 1, 1, 1],
 1659:             "d": np.random.default_rng(2).standard_normal(6),
 1660:         }
 1661:     )
 1662:     grouped = df.groupby(["a", "b"])["d"]
 1663:     result = grouped.sum()
 1664: 
 1665:     def _check_groupby(df, result, keys, field, f=lambda x: x.sum()):
 1666:         tups = [tuple(row) for row in df[keys].values]
 1667:         tups = com.asarray_tuplesafe(tups)
 1668:         expected = f(df.groupby(tups)[field])
 1669:         for k, v in expected.items():
 1670:             assert result[k] == v
 1671: 
 1672:     _check_groupby(df, result, ["a", "b"], "d")
 1673: 
 1674: 
 1675: def test_dont_clobber_name_column():
 1676:     df = DataFrame(
 1677:         {"key": ["a", "a", "a", "b", "b", "b"], "name": ["foo", "bar", "baz"] * 2}
 1678:     )
 1679: 
 1680:     msg = "DataFrameGroupBy.apply operated on the grouping columns"
 1681:     with tm.assert_produces_warning(DeprecationWarning, match=msg):
 1682:         result = df.groupby("key", group_keys=False).apply(lambda x: x)
 1683:     tm.assert_frame_equal(result, df)
 1684: 
 1685: 
 1686: def test_skip_group_keys():
 1687:     tsf = DataFrame(
 1688:         np.random.default_rng(2).standard_normal((10, 4)),
 1689:         columns=Index(list("ABCD"), dtype=object),
 1690:         index=date_range("2000-01-01", periods=10, freq="B"),
 1691:     )
 1692: 
 1693:     grouped = tsf.groupby(lambda x: x.month, group_keys=False)
 1694:     result = grouped.apply(lambda x: x.sort_values(by="A")[:3])
 1695: 
 1696:     pieces = [group.sort_values(by="A")[:3] for key, group in grouped]
 1697: 
 1698:     expected = pd.concat(pieces)
 1699:     tm.assert_frame_equal(result, expected)
 1700: 
 1701:     grouped = tsf["A"].groupby(lambda x: x.month, group_keys=False)
 1702:     result = grouped.apply(lambda x: x.sort_values()[:3])
 1703: 
 1704:     pieces = [group.sort_values()[:3] for key, group in grouped]
 1705: 
 1706:     expected = pd.concat(pieces)
 1707:     tm.assert_series_equal(result, expected)
 1708: 
 1709: 
 1710: def test_no_nonsense_name(float_frame):
 1711:     # GH #995
 1712:     s = float_frame["C"].copy()
 1713:     s.name = None
 1714: 
 1715:     result = s.groupby(float_frame["A"]).agg("sum")
 1716:     assert result.name is None
 1717: 
 1718: 
 1719: def test_multifunc_sum_bug():
 1720:     # GH #1065
 1721:     x = DataFrame(np.arange(9).reshape(3, 3))
 1722:     x["test"] = 0
 1723:     x["fl"] = [1.3, 1.5, 1.6]
 1724: 
 1725:     grouped = x.groupby("test")
 1726:     result = grouped.agg({"fl": "sum", 2: "size"})
 1727:     assert result["fl"].dtype == np.float64
 1728: 
 1729: 
 1730: def test_handle_dict_return_value(df):
 1731:     def f(group):
 1732:         return {"max": group.max(), "min": group.min()}
 1733: 
 1734:     def g(group):
 1735:         return Series({"max": group.max(), "min": group.min()})
 1736: 
 1737:     result = df.groupby("A")["C"].apply(f)
 1738:     expected = df.groupby("A")["C"].apply(g)
 1739: 
 1740:     assert isinstance(result, Series)
 1741:     tm.assert_series_equal(result, expected)
 1742: 
 1743: 
 1744: @pytest.mark.parametrize("grouper", ["A", ["A", "B"]])
 1745: def test_set_group_name(df, grouper, using_infer_string):
 1746:     def f(group):
 1747:         assert group.name is not None
 1748:         return group
 1749: 
 1750:     def freduce(group):
 1751:         assert group.name is not None
 1752:         if using_infer_string and grouper == "A" and is_string_dtype(group.dtype):
 1753:             with pytest.raises(TypeError, match="does not support"):
 1754:                 group.sum()
 1755:         else:
 1756:             return group.sum()
 1757: 
 1758:     def freducex(x):
 1759:         return freduce(x)
 1760: 
 1761:     grouped = df.groupby(grouper, group_keys=False)
 1762: 
 1763:     # make sure all these work
 1764:     msg = "DataFrameGroupBy.apply operated on the grouping columns"
 1765:     with tm.assert_produces_warning(DeprecationWarning, match=msg):
 1766:         grouped.apply(f)
 1767:     grouped.aggregate(freduce)
 1768:     grouped.aggregate({"C": freduce, "D": freduce})
 1769:     grouped.transform(f)
 1770: 
 1771:     grouped["C"].apply(f)
 1772:     grouped["C"].aggregate(freduce)
 1773:     grouped["C"].aggregate([freduce, freducex])
 1774:     grouped["C"].transform(f)
 1775: 
 1776: 
 1777: def test_group_name_available_in_inference_pass():
 1778:     # gh-15062
 1779:     df = DataFrame({"a": [0, 0, 1, 1, 2, 2], "b": np.arange(6)})
 1780: 
 1781:     names = []
 1782: 
 1783:     def f(group):
 1784:         names.append(group.name)
 1785:         return group.copy()
 1786: 
 1787:     msg = "DataFrameGroupBy.apply operated on the grouping columns"
 1788:     with tm.assert_produces_warning(DeprecationWarning, match=msg):
 1789:         df.groupby("a", sort=False, group_keys=False).apply(f)
 1790: 
 1791:     expected_names = [0, 1, 2]
 1792:     assert names == expected_names
 1793: 
 1794: 
 1795: def test_no_dummy_key_names(df):
 1796:     # see gh-1291
 1797:     result = df.groupby(df["A"].values).sum()
 1798:     assert result.index.name is None
 1799: 
 1800:     result = df.groupby([df["A"].values, df["B"].values]).sum()
 1801:     assert result.index.names == (None, None)
 1802: 
 1803: 
 1804: def test_groupby_sort_multiindex_series():
 1805:     # series multiindex groupby sort argument was not being passed through
 1806:     # _compress_group_index
 1807:     # GH 9444
 1808:     index = MultiIndex(
 1809:         levels=[[1, 2], [1, 2]],
 1810:         codes=[[0, 0, 0, 0, 1, 1], [1, 1, 0, 0, 0, 0]],
 1811:         names=["a", "b"],
 1812:     )
 1813:     mseries = Series([0, 1, 2, 3, 4, 5], index=index)
 1814:     index = MultiIndex(
 1815:         levels=[[1, 2], [1, 2]], codes=[[0, 0, 1], [1, 0, 0]], names=["a", "b"]
 1816:     )
 1817:     mseries_result = Series([0, 2, 4], index=index)
 1818: 
 1819:     result = mseries.groupby(level=["a", "b"], sort=False).first()
 1820:     tm.assert_series_equal(result, mseries_result)
 1821:     result = mseries.groupby(level=["a", "b"], sort=True).first()
 1822:     tm.assert_series_equal(result, mseries_result.sort_index())
 1823: 
 1824: 
 1825: def test_groupby_reindex_inside_function():
 1826:     periods = 1000
 1827:     ind = date_range(start="2012/1/1", freq="5min", periods=periods)
 1828:     df = DataFrame({"high": np.arange(periods), "low": np.arange(periods)}, index=ind)
 1829: 
 1830:     def agg_before(func, fix=False):
 1831:         """
 1832:         Run an aggregate func on the subset of data.
 1833:         """
 1834: 
 1835:         def _func(data):
 1836:             d = data.loc[data.index.map(lambda x: x.hour < 11)].dropna()
 1837:             if fix:
 1838:                 data[data.index[0]]
 1839:             if len(d) == 0:
 1840:                 return None
 1841:             return func(d)
 1842: 
 1843:         return _func
 1844: 
 1845:     grouped = df.groupby(lambda x: datetime(x.year, x.month, x.day))
 1846:     closure_bad = grouped.agg({"high": agg_before(np.max)})
 1847:     closure_good = grouped.agg({"high": agg_before(np.max, True)})
 1848: 
 1849:     tm.assert_frame_equal(closure_bad, closure_good)
 1850: 
 1851: 
 1852: def test_groupby_multiindex_missing_pair():
 1853:     # GH9049
 1854:     df = DataFrame(
 1855:         {
 1856:             "group1": ["a", "a", "a", "b"],
 1857:             "group2": ["c", "c", "d", "c"],
 1858:             "value": [1, 1, 1, 5],
 1859:         }
 1860:     )
 1861:     df = df.set_index(["group1", "group2"])
 1862:     df_grouped = df.groupby(level=["group1", "group2"], sort=True)
 1863: 
 1864:     res = df_grouped.agg("sum")
 1865:     idx = MultiIndex.from_tuples(
 1866:         [("a", "c"), ("a", "d"), ("b", "c")], names=["group1", "group2"]
 1867:     )
 1868:     exp = DataFrame([[2], [1], [5]], index=idx, columns=["value"])
 1869: 
 1870:     tm.assert_frame_equal(res, exp)
 1871: 
 1872: 
 1873: def test_groupby_multiindex_not_lexsorted():
 1874:     # GH 11640
 1875: 
 1876:     # define the lexsorted version
 1877:     lexsorted_mi = MultiIndex.from_tuples(
 1878:         [("a", ""), ("b1", "c1"), ("b2", "c2")], names=["b", "c"]
 1879:     )
 1880:     lexsorted_df = DataFrame([[1, 3, 4]], columns=lexsorted_mi)
 1881:     assert lexsorted_df.columns._is_lexsorted()
 1882: 
 1883:     # define the non-lexsorted version
 1884:     not_lexsorted_df = DataFrame(
 1885:         columns=["a", "b", "c", "d"], data=[[1, "b1", "c1", 3], [1, "b2", "c2", 4]]
 1886:     )
 1887:     not_lexsorted_df = not_lexsorted_df.pivot_table(
 1888:         index="a", columns=["b", "c"], values="d"
 1889:     )
 1890:     not_lexsorted_df = not_lexsorted_df.reset_index()
 1891:     assert not not_lexsorted_df.columns._is_lexsorted()
 1892: 
 1893:     expected = lexsorted_df.groupby("a").mean()
 1894:     with tm.assert_produces_warning(PerformanceWarning):
 1895:         result = not_lexsorted_df.groupby("a").mean()
 1896:     tm.assert_frame_equal(expected, result)
 1897: 
 1898:     # a transforming function should work regardless of sort
 1899:     # GH 14776
 1900:     df = DataFrame(
 1901:         {"x": ["a", "a", "b", "a"], "y": [1, 1, 2, 2], "z": [1, 2, 3, 4]}
 1902:     ).set_index(["x", "y"])
 1903:     assert not df.index._is_lexsorted()
 1904: 
 1905:     for level in [0, 1, [0, 1]]:
 1906:         for sort in [False, True]:
 1907:             result = df.groupby(level=level, sort=sort, group_keys=False).apply(
 1908:                 DataFrame.drop_duplicates
 1909:             )
 1910:             expected = df
 1911:             tm.assert_frame_equal(expected, result)
 1912: 
 1913:             result = (
 1914:                 df.sort_index()
 1915:                 .groupby(level=level, sort=sort, group_keys=False)
 1916:                 .apply(DataFrame.drop_duplicates)
 1917:             )
 1918:             expected = df.sort_index()
 1919:             tm.assert_frame_equal(expected, result)
 1920: 
 1921: 
 1922: def test_index_label_overlaps_location():
 1923:     # checking we don't have any label/location confusion in the
 1924:     # wake of GH5375
 1925:     df = DataFrame(list("ABCDE"), index=[2, 0, 2, 1, 1])
 1926:     g = df.groupby(list("ababb"))
 1927:     actual = g.filter(lambda x: len(x) > 2)
 1928:     expected = df.iloc[[1, 3, 4]]
 1929:     tm.assert_frame_equal(actual, expected)
 1930: 
 1931:     ser = df[0]
 1932:     g = ser.groupby(list("ababb"))
 1933:     actual = g.filter(lambda x: len(x) > 2)
 1934:     expected = ser.take([1, 3, 4])
 1935:     tm.assert_series_equal(actual, expected)
 1936: 
 1937:     #  and again, with a generic Index of floats
 1938:     df.index = df.index.astype(float)
 1939:     g = df.groupby(list("ababb"))
 1940:     actual = g.filter(lambda x: len(x) > 2)
 1941:     expected = df.iloc[[1, 3, 4]]
 1942:     tm.assert_frame_equal(actual, expected)
 1943: 
 1944:     ser = df[0]
 1945:     g = ser.groupby(list("ababb"))
 1946:     actual = g.filter(lambda x: len(x) > 2)
 1947:     expected = ser.take([1, 3, 4])
 1948:     tm.assert_series_equal(actual, expected)
 1949: 
 1950: 
 1951: def test_transform_doesnt_clobber_ints():
 1952:     # GH 7972
 1953:     n = 6
 1954:     x = np.arange(n)
 1955:     df = DataFrame({"a": x // 2, "b": 2.0 * x, "c": 3.0 * x})
 1956:     df2 = DataFrame({"a": x // 2 * 1.0, "b": 2.0 * x, "c": 3.0 * x})
 1957: 
 1958:     gb = df.groupby("a")
 1959:     result = gb.transform("mean")
 1960: 
 1961:     gb2 = df2.groupby("a")
 1962:     expected = gb2.transform("mean")
 1963:     tm.assert_frame_equal(result, expected)
 1964: 
 1965: 
 1966: @pytest.mark.parametrize(
 1967:     "sort_column",
 1968:     ["ints", "floats", "strings", ["ints", "floats"], ["ints", "strings"]],
 1969: )
 1970: @pytest.mark.parametrize(
 1971:     "group_column", ["int_groups", "string_groups", ["int_groups", "string_groups"]]
 1972: )
 1973: def test_groupby_preserves_sort(sort_column, group_column):
 1974:     # Test to ensure that groupby always preserves sort order of original
 1975:     # object. Issue #8588 and #9651
 1976: 
 1977:     df = DataFrame(
 1978:         {
 1979:             "int_groups": [3, 1, 0, 1, 0, 3, 3, 3],
 1980:             "string_groups": ["z", "a", "z", "a", "a", "g", "g", "g"],
 1981:             "ints": [8, 7, 4, 5, 2, 9, 1, 1],
 1982:             "floats": [2.3, 5.3, 6.2, -2.4, 2.2, 1.1, 1.1, 5],
 1983:             "strings": ["z", "d", "a", "e", "word", "word2", "42", "47"],
 1984:         }
 1985:     )
 1986: 
 1987:     # Try sorting on different types and with different group types
 1988: 
 1989:     df = df.sort_values(by=sort_column)
 1990:     g = df.groupby(group_column)
 1991: 
 1992:     def test_sort(x):
 1993:         tm.assert_frame_equal(x, x.sort_values(by=sort_column))
 1994: 
 1995:     msg = "DataFrameGroupBy.apply operated on the grouping columns"
 1996:     with tm.assert_produces_warning(DeprecationWarning, match=msg):
 1997:         g.apply(test_sort)
 1998: 
 1999: 
 2000: def test_pivot_table_values_key_error():
 2001:     # This test is designed to replicate the error in issue #14938
 2002:     df = DataFrame(
 2003:         {
 2004:             "eventDate": date_range(datetime.today(), periods=20, freq="ME").tolist(),
 2005:             "thename": range(20),
 2006:         }
 2007:     )
 2008: 
 2009:     df["year"] = df.set_index("eventDate").index.year
 2010:     df["month"] = df.set_index("eventDate").index.month
 2011: 
 2012:     with pytest.raises(KeyError, match="'badname'"):
 2013:         df.reset_index().pivot_table(
 2014:             index="year", columns="month", values="badname", aggfunc="count"
 2015:         )
 2016: 
 2017: 
 2018: @pytest.mark.parametrize("columns", ["C", ["C"]])
 2019: @pytest.mark.parametrize("keys", [["A"], ["A", "B"]])
 2020: @pytest.mark.parametrize(
 2021:     "values",
 2022:     [
 2023:         [True],
 2024:         [0],
 2025:         [0.0],
 2026:         ["a"],
 2027:         Categorical([0]),
 2028:         [to_datetime(0)],
 2029:         date_range(0, 1, 1, tz="US/Eastern"),
 2030:         pd.period_range("2016-01-01", periods=3, freq="D"),
 2031:         pd.array([0], dtype="Int64"),
 2032:         pd.array([0], dtype="Float64"),
 2033:         pd.array([False], dtype="boolean"),
 2034:     ],
 2035:     ids=[
 2036:         "bool",
 2037:         "int",
 2038:         "float",
 2039:         "str",
 2040:         "cat",
 2041:         "dt64",
 2042:         "dt64tz",
 2043:         "period",
 2044:         "Int64",
 2045:         "Float64",
 2046:         "boolean",
 2047:     ],
 2048: )
 2049: @pytest.mark.parametrize("method", ["attr", "agg", "apply"])
 2050: @pytest.mark.parametrize(
 2051:     "op", ["idxmax", "idxmin", "min", "max", "sum", "prod", "skew"]
 2052: )
 2053: def test_empty_groupby(
 2054:     columns, keys, values, method, op, using_array_manager, dropna, using_infer_string
 2055: ):
 2056:     # GH8093 & GH26411
 2057:     override_dtype = None
 2058: 
 2059:     if isinstance(values, BooleanArray) and op in ["sum", "prod"]:
 2060:         # We expect to get Int64 back for these
 2061:         override_dtype = "Int64"
 2062: 
 2063:     if isinstance(values[0], bool) and op in ("prod", "sum"):
 2064:         # sum/product of bools is an integer
 2065:         override_dtype = "int64"
 2066: 
 2067:     df = DataFrame({"A": values, "B": values, "C": values}, columns=list("ABC"))
 2068: 
 2069:     if hasattr(values, "dtype"):
 2070:         # check that we did the construction right
 2071:         assert (df.dtypes == values.dtype).all()
 2072: 
 2073:     df = df.iloc[:0]
 2074: 
 2075:     gb = df.groupby(keys, group_keys=False, dropna=dropna, observed=False)[columns]
 2076: 
 2077:     def get_result(**kwargs):
 2078:         if method == "attr":
 2079:             return getattr(gb, op)(**kwargs)
 2080:         else:
 2081:             return getattr(gb, method)(op, **kwargs)
 2082: 
 2083:     def get_categorical_invalid_expected():
 2084:         # Categorical is special without 'observed=True', we get an NaN entry
 2085:         #  corresponding to the unobserved group. If we passed observed=True
 2086:         #  to groupby, expected would just be 'df.set_index(keys)[columns]'
 2087:         #  as below
 2088:         lev = Categorical([0], dtype=values.dtype)
 2089:         if len(keys) != 1:
 2090:             idx = MultiIndex.from_product([lev, lev], names=keys)
 2091:         else:
 2092:             # all columns are dropped, but we end up with one row
 2093:             # Categorical is special without 'observed=True'
 2094:             idx = Index(lev, name=keys[0])
 2095: 
 2096:         if using_infer_string:
 2097:             columns = Index([], dtype="string[pyarrow_numpy]")
 2098:         else:
 2099:             columns = []
 2100:         expected = DataFrame([], columns=columns, index=idx)
 2101:         return expected
 2102: 
 2103:     is_per = isinstance(df.dtypes.iloc[0], pd.PeriodDtype)
 2104:     is_dt64 = df.dtypes.iloc[0].kind == "M"
 2105:     is_cat = isinstance(values, Categorical)
 2106: 
 2107:     if (
 2108:         isinstance(values, Categorical)
 2109:         and not values.ordered
 2110:         and op in ["min", "max", "idxmin", "idxmax"]
 2111:     ):
 2112:         if op in ["min", "max"]:
 2113:             msg = f"Cannot perform {op} with non-ordered Categorical"
 2114:             klass = TypeError
 2115:         else:
 2116:             msg = f"Can't get {op} of an empty group due to unobserved categories"
 2117:             klass = ValueError
 2118:         with pytest.raises(klass, match=msg):
 2119:             get_result()
 2120: 
 2121:         if op in ["min", "max", "idxmin", "idxmax"] and isinstance(columns, list):
 2122:             # i.e. DataframeGroupBy, not SeriesGroupBy
 2123:             result = get_result(numeric_only=True)
 2124:             expected = get_categorical_invalid_expected()
 2125:             tm.assert_equal(result, expected)
 2126:         return
 2127: 
 2128:     if op in ["prod", "sum", "skew"]:
 2129:         # ops that require more than just ordered-ness
 2130:         if is_dt64 or is_cat or is_per:
 2131:             # GH#41291
 2132:             # datetime64 -> prod and sum are invalid
 2133:             if is_dt64:
 2134:                 msg = "datetime64 type does not support"
 2135:             elif is_per:
 2136:                 msg = "Period type does not support"
 2137:             else:
 2138:                 msg = "category type does not support"
 2139:             if op == "skew":
 2140:                 msg = "|".join([msg, "does not support reduction 'skew'"])
 2141:             with pytest.raises(TypeError, match=msg):
 2142:                 get_result()
 2143: 
 2144:             if not isinstance(columns, list):
 2145:                 # i.e. SeriesGroupBy
 2146:                 return
 2147:             elif op == "skew":
 2148:                 # TODO: test the numeric_only=True case
 2149:                 return
 2150:             else:
 2151:                 # i.e. op in ["prod", "sum"]:
 2152:                 # i.e. DataFrameGroupBy
 2153:                 # ops that require more than just ordered-ness
 2154:                 # GH#41291
 2155:                 result = get_result(numeric_only=True)
 2156: 
 2157:                 # with numeric_only=True, these are dropped, and we get
 2158:                 # an empty DataFrame back
 2159:                 expected = df.set_index(keys)[[]]
 2160:                 if is_cat:
 2161:                     expected = get_categorical_invalid_expected()
 2162:                 tm.assert_equal(result, expected)
 2163:                 return
 2164: 
 2165:     result = get_result()
 2166:     expected = df.set_index(keys)[columns]
 2167:     if op in ["idxmax", "idxmin"]:
 2168:         expected = expected.astype(df.index.dtype)
 2169:     if override_dtype is not None:
 2170:         expected = expected.astype(override_dtype)
 2171:     if len(keys) == 1:
 2172:         expected.index.name = keys[0]
 2173:     tm.assert_equal(result, expected)
 2174: 
 2175: 
 2176: def test_empty_groupby_apply_nonunique_columns():
 2177:     # GH#44417
 2178:     df = DataFrame(np.random.default_rng(2).standard_normal((0, 4)))
 2179:     df[3] = df[3].astype(np.int64)
 2180:     df.columns = [0, 1, 2, 0]
 2181:     gb = df.groupby(df[1], group_keys=False)
 2182:     msg = "DataFrameGroupBy.apply operated on the grouping columns"
 2183:     with tm.assert_produces_warning(DeprecationWarning, match=msg):
 2184:         res = gb.apply(lambda x: x)
 2185:     assert (res.dtypes == df.dtypes).all()
 2186: 
 2187: 
 2188: def test_tuple_as_grouping():
 2189:     # https://github.com/pandas-dev/pandas/issues/18314
 2190:     df = DataFrame(
 2191:         {
 2192:             ("a", "b"): [1, 1, 1, 1],
 2193:             "a": [2, 2, 2, 2],
 2194:             "b": [2, 2, 2, 2],
 2195:             "c": [1, 1, 1, 1],
 2196:         }
 2197:     )
 2198: 
 2199:     with pytest.raises(KeyError, match=r"('a', 'b')"):
 2200:         df[["a", "b", "c"]].groupby(("a", "b"))
 2201: 
 2202:     result = df.groupby(("a", "b"))["c"].sum()
 2203:     expected = Series([4], name="c", index=Index([1], name=("a", "b")))
 2204:     tm.assert_series_equal(result, expected)
 2205: 
 2206: 
 2207: def test_tuple_correct_keyerror():
 2208:     # https://github.com/pandas-dev/pandas/issues/18798
 2209:     df = DataFrame(1, index=range(3), columns=MultiIndex.from_product([[1, 2], [3, 4]]))
 2210:     with pytest.raises(KeyError, match=r"^\(7, 8\)$"):
 2211:         df.groupby((7, 8)).mean()
 2212: 
 2213: 
 2214: def test_groupby_agg_ohlc_non_first():
 2215:     # GH 21716
 2216:     df = DataFrame(
 2217:         [[1], [1]],
 2218:         columns=Index(["foo"], name="mycols"),
 2219:         index=date_range("2018-01-01", periods=2, freq="D", name="dti"),
 2220:     )
 2221: 
 2222:     expected = DataFrame(
 2223:         [[1, 1, 1, 1, 1], [1, 1, 1, 1, 1]],
 2224:         columns=MultiIndex.from_tuples(
 2225:             (
 2226:                 ("foo", "sum", "foo"),
 2227:                 ("foo", "ohlc", "open"),
 2228:                 ("foo", "ohlc", "high"),
 2229:                 ("foo", "ohlc", "low"),
 2230:                 ("foo", "ohlc", "close"),
 2231:             ),
 2232:             names=["mycols", None, None],
 2233:         ),
 2234:         index=date_range("2018-01-01", periods=2, freq="D", name="dti"),
 2235:     )
 2236: 
 2237:     result = df.groupby(Grouper(freq="D")).agg(["sum", "ohlc"])
 2238: 
 2239:     tm.assert_frame_equal(result, expected)
 2240: 
 2241: 
 2242: def test_groupby_multiindex_nat():
 2243:     # GH 9236
 2244:     values = [
 2245:         (pd.NaT, "a"),
 2246:         (datetime(2012, 1, 2), "a"),
 2247:         (datetime(2012, 1, 2), "b"),
 2248:         (datetime(2012, 1, 3), "a"),
 2249:     ]
 2250:     mi = MultiIndex.from_tuples(values, names=["date", None])
 2251:     ser = Series([3, 2, 2.5, 4], index=mi)
 2252: 
 2253:     result = ser.groupby(level=1).mean()
 2254:     expected = Series([3.0, 2.5], index=["a", "b"])
 2255:     tm.assert_series_equal(result, expected)
 2256: 
 2257: 
 2258: def test_groupby_empty_list_raises():
 2259:     # GH 5289
 2260:     values = zip(range(10), range(10))
 2261:     df = DataFrame(values, columns=["apple", "b"])
 2262:     msg = "Grouper and axis must be same length"
 2263:     with pytest.raises(ValueError, match=msg):
 2264:         df.groupby([[]])
 2265: 
 2266: 
 2267: def test_groupby_multiindex_series_keys_len_equal_group_axis():
 2268:     # GH 25704
 2269:     index_array = [["x", "x"], ["a", "b"], ["k", "k"]]
 2270:     index_names = ["first", "second", "third"]
 2271:     ri = MultiIndex.from_arrays(index_array, names=index_names)
 2272:     s = Series(data=[1, 2], index=ri)
 2273:     result = s.groupby(["first", "third"]).sum()
 2274: 
 2275:     index_array = [["x"], ["k"]]
 2276:     index_names = ["first", "third"]
 2277:     ei = MultiIndex.from_arrays(index_array, names=index_names)
 2278:     expected = Series([3], index=ei)
 2279: 
 2280:     tm.assert_series_equal(result, expected)
 2281: 
 2282: 
 2283: def test_groupby_groups_in_BaseGrouper():
 2284:     # GH 26326
 2285:     # Test if DataFrame grouped with a pandas.Grouper has correct groups
 2286:     mi = MultiIndex.from_product([["A", "B"], ["C", "D"]], names=["alpha", "beta"])
 2287:     df = DataFrame({"foo": [1, 2, 1, 2], "bar": [1, 2, 3, 4]}, index=mi)
 2288:     result = df.groupby([Grouper(level="alpha"), "beta"])
 2289:     expected = df.groupby(["alpha", "beta"])
 2290:     assert result.groups == expected.groups
 2291: 
 2292:     result = df.groupby(["beta", Grouper(level="alpha")])
 2293:     expected = df.groupby(["beta", "alpha"])
 2294:     assert result.groups == expected.groups
 2295: 
 2296: 
 2297: @pytest.mark.parametrize("group_name", ["x", ["x"]])
 2298: def test_groupby_axis_1(group_name):
 2299:     # GH 27614
 2300:     df = DataFrame(
 2301:         np.arange(12).reshape(3, 4), index=[0, 1, 0], columns=[10, 20, 10, 20]
 2302:     )
 2303:     df.index.name = "y"
 2304:     df.columns.name = "x"
 2305: 
 2306:     depr_msg = "DataFrame.groupby with axis=1 is deprecated"
 2307:     with tm.assert_produces_warning(FutureWarning, match=depr_msg):
 2308:         gb = df.groupby(group_name, axis=1)
 2309: 
 2310:     results = gb.sum()
 2311:     expected = df.T.groupby(group_name).sum().T
 2312:     tm.assert_frame_equal(results, expected)
 2313: 
 2314:     # test on MI column
 2315:     iterables = [["bar", "baz", "foo"], ["one", "two"]]
 2316:     mi = MultiIndex.from_product(iterables=iterables, names=["x", "x1"])
 2317:     df = DataFrame(np.arange(18).reshape(3, 6), index=[0, 1, 0], columns=mi)
 2318:     with tm.assert_produces_warning(FutureWarning, match=depr_msg):
 2319:         gb = df.groupby(group_name, axis=1)
 2320:     results = gb.sum()
 2321:     expected = df.T.groupby(group_name).sum().T
 2322:     tm.assert_frame_equal(results, expected)
 2323: 
 2324: 
 2325: @pytest.mark.parametrize(
 2326:     "op, expected",
 2327:     [
 2328:         (
 2329:             "shift",
 2330:             {
 2331:                 "time": [
 2332:                     None,
 2333:                     None,
 2334:                     Timestamp("2019-01-01 12:00:00"),
 2335:                     Timestamp("2019-01-01 12:30:00"),
 2336:                     None,
 2337:                     None,
 2338:                 ]
 2339:             },
 2340:         ),
 2341:         (
 2342:             "bfill",
 2343:             {
 2344:                 "time": [
 2345:                     Timestamp("2019-01-01 12:00:00"),
 2346:                     Timestamp("2019-01-01 12:30:00"),
 2347:                     Timestamp("2019-01-01 14:00:00"),
 2348:                     Timestamp("2019-01-01 14:30:00"),
 2349:                     Timestamp("2019-01-01 14:00:00"),
 2350:                     Timestamp("2019-01-01 14:30:00"),
 2351:                 ]
 2352:             },
 2353:         ),
 2354:         (
 2355:             "ffill",
 2356:             {
 2357:                 "time": [
 2358:                     Timestamp("2019-01-01 12:00:00"),
 2359:                     Timestamp("2019-01-01 12:30:00"),
 2360:                     Timestamp("2019-01-01 12:00:00"),
 2361:                     Timestamp("2019-01-01 12:30:00"),
 2362:                     Timestamp("2019-01-01 14:00:00"),
 2363:                     Timestamp("2019-01-01 14:30:00"),
 2364:                 ]
 2365:             },
 2366:         ),
 2367:     ],
 2368: )
 2369: def test_shift_bfill_ffill_tz(tz_naive_fixture, op, expected):
 2370:     # GH19995, GH27992: Check that timezone does not drop in shift, bfill, and ffill
 2371:     tz = tz_naive_fixture
 2372:     data = {
 2373:         "id": ["A", "B", "A", "B", "A", "B"],
 2374:         "time": [
 2375:             Timestamp("2019-01-01 12:00:00"),
 2376:             Timestamp("2019-01-01 12:30:00"),
 2377:             None,
 2378:             None,
 2379:             Timestamp("2019-01-01 14:00:00"),
 2380:             Timestamp("2019-01-01 14:30:00"),
 2381:         ],
 2382:     }
 2383:     df = DataFrame(data).assign(time=lambda x: x.time.dt.tz_localize(tz))
 2384: 
 2385:     grouped = df.groupby("id")
 2386:     result = getattr(grouped, op)()
 2387:     expected = DataFrame(expected).assign(time=lambda x: x.time.dt.tz_localize(tz))
 2388:     tm.assert_frame_equal(result, expected)
 2389: 
 2390: 
 2391: def test_groupby_only_none_group():
 2392:     # see GH21624
 2393:     # this was crashing with "ValueError: Length of passed values is 1, index implies 0"
 2394:     df = DataFrame({"g": [None], "x": 1})
 2395:     actual = df.groupby("g")["x"].transform("sum")
 2396:     expected = Series([np.nan], name="x")
 2397: 
 2398:     tm.assert_series_equal(actual, expected)
 2399: 
 2400: 
 2401: def test_groupby_duplicate_index():
 2402:     # GH#29189 the groupby call here used to raise
 2403:     ser = Series([2, 5, 6, 8], index=[2.0, 4.0, 4.0, 5.0])
 2404:     gb = ser.groupby(level=0)
 2405: 
 2406:     result = gb.mean()
 2407:     expected = Series([2, 5.5, 8], index=[2.0, 4.0, 5.0])
 2408:     tm.assert_series_equal(result, expected)
 2409: 
 2410: 
 2411: def test_group_on_empty_multiindex(transformation_func, request):
 2412:     # GH 47787
 2413:     # With one row, those are transforms so the schema should be the same
 2414:     df = DataFrame(
 2415:         data=[[1, Timestamp("today"), 3, 4]],
 2416:         columns=["col_1", "col_2", "col_3", "col_4"],
 2417:     )
 2418:     df["col_3"] = df["col_3"].astype(int)
 2419:     df["col_4"] = df["col_4"].astype(int)
 2420:     df = df.set_index(["col_1", "col_2"])
 2421:     if transformation_func == "fillna":
 2422:         args = ("ffill",)
 2423:     else:
 2424:         args = ()
 2425:     warn = FutureWarning if transformation_func == "fillna" else None
 2426:     warn_msg = "DataFrameGroupBy.fillna is deprecated"
 2427:     with tm.assert_produces_warning(warn, match=warn_msg):
 2428:         result = df.iloc[:0].groupby(["col_1"]).transform(transformation_func, *args)
 2429:     with tm.assert_produces_warning(warn, match=warn_msg):
 2430:         expected = df.groupby(["col_1"]).transform(transformation_func, *args).iloc[:0]
 2431:     if transformation_func in ("diff", "shift"):
 2432:         expected = expected.astype(int)
 2433:     tm.assert_equal(result, expected)
 2434: 
 2435:     warn_msg = "SeriesGroupBy.fillna is deprecated"
 2436:     with tm.assert_produces_warning(warn, match=warn_msg):
 2437:         result = (
 2438:             df["col_3"]
 2439:             .iloc[:0]
 2440:             .groupby(["col_1"])
 2441:             .transform(transformation_func, *args)
 2442:         )
 2443:     warn_msg = "SeriesGroupBy.fillna is deprecated"
 2444:     with tm.assert_produces_warning(warn, match=warn_msg):
 2445:         expected = (
 2446:             df["col_3"]
 2447:             .groupby(["col_1"])
 2448:             .transform(transformation_func, *args)
 2449:             .iloc[:0]
 2450:         )
 2451:     if transformation_func in ("diff", "shift"):
 2452:         expected = expected.astype(int)
 2453:     tm.assert_equal(result, expected)
 2454: 
 2455: 
 2456: def test_groupby_crash_on_nunique(axis):
 2457:     # Fix following 30253
 2458:     dti = date_range("2016-01-01", periods=2, name="foo")
 2459:     df = DataFrame({("A", "B"): [1, 2], ("A", "C"): [1, 3], ("D", "B"): [0, 0]})
 2460:     df.columns.names = ("bar", "baz")
 2461:     df.index = dti
 2462: 
 2463:     axis_number = df._get_axis_number(axis)
 2464:     if not axis_number:
 2465:         df = df.T
 2466:         msg = "The 'axis' keyword in DataFrame.groupby is deprecated"
 2467:     else:
 2468:         msg = "DataFrame.groupby with axis=1 is deprecated"
 2469: 
 2470:     with tm.assert_produces_warning(FutureWarning, match=msg):
 2471:         gb = df.groupby(axis=axis_number, level=0)
 2472:     result = gb.nunique()
 2473: 
 2474:     expected = DataFrame({"A": [1, 2], "D": [1, 1]}, index=dti)
 2475:     expected.columns.name = "bar"
 2476:     if not axis_number:
 2477:         expected = expected.T
 2478: 
 2479:     tm.assert_frame_equal(result, expected)
 2480: 
 2481:     if axis_number == 0:
 2482:         # same thing, but empty columns
 2483:         with tm.assert_produces_warning(FutureWarning, match=msg):
 2484:             gb2 = df[[]].groupby(axis=axis_number, level=0)
 2485:         exp = expected[[]]
 2486:     else:
 2487:         # same thing, but empty rows
 2488:         with tm.assert_produces_warning(FutureWarning, match=msg):
 2489:             gb2 = df.loc[[]].groupby(axis=axis_number, level=0)
 2490:         # default for empty when we can't infer a dtype is float64
 2491:         exp = expected.loc[[]].astype(np.float64)
 2492: 
 2493:     res = gb2.nunique()
 2494:     tm.assert_frame_equal(res, exp)
 2495: 
 2496: 
 2497: def test_groupby_list_level():
 2498:     # GH 9790
 2499:     expected = DataFrame(np.arange(0, 9).reshape(3, 3), dtype=float)
 2500:     result = expected.groupby(level=[0]).mean()
 2501:     tm.assert_frame_equal(result, expected)
 2502: 
 2503: 
 2504: @pytest.mark.parametrize(
 2505:     "max_seq_items, expected",
 2506:     [
 2507:         (5, "{0: [0], 1: [1], 2: [2], 3: [3], 4: [4]}"),
 2508:         (4, "{0: [0], 1: [1], 2: [2], 3: [3], ...}"),
 2509:         (1, "{0: [0], ...}"),
 2510:     ],
 2511: )
 2512: def test_groups_repr_truncates(max_seq_items, expected):
 2513:     # GH 1135
 2514:     df = DataFrame(np.random.default_rng(2).standard_normal((5, 1)))
 2515:     df["a"] = df.index
 2516: 
 2517:     with pd.option_context("display.max_seq_items", max_seq_items):
 2518:         result = df.groupby("a").groups.__repr__()
 2519:         assert result == expected
 2520: 
 2521:         result = df.groupby(np.array(df.a)).groups.__repr__()
 2522:         assert result == expected
 2523: 
 2524: 
 2525: def test_group_on_two_row_multiindex_returns_one_tuple_key():
 2526:     # GH 18451
 2527:     df = DataFrame([{"a": 1, "b": 2, "c": 99}, {"a": 1, "b": 2, "c": 88}])
 2528:     df = df.set_index(["a", "b"])
 2529: 
 2530:     grp = df.groupby(["a", "b"])
 2531:     result = grp.indices
 2532:     expected = {(1, 2): np.array([0, 1], dtype=np.int64)}
 2533: 
 2534:     assert len(result) == 1
 2535:     key = (1, 2)
 2536:     assert (result[key] == expected[key]).all()
 2537: 
 2538: 
 2539: @pytest.mark.parametrize(
 2540:     "klass, attr, value",
 2541:     [
 2542:         (DataFrame, "level", "a"),
 2543:         (DataFrame, "as_index", False),
 2544:         (DataFrame, "sort", False),
 2545:         (DataFrame, "group_keys", False),
 2546:         (DataFrame, "observed", True),
 2547:         (DataFrame, "dropna", False),
 2548:         (Series, "level", "a"),
 2549:         (Series, "as_index", False),
 2550:         (Series, "sort", False),
 2551:         (Series, "group_keys", False),
 2552:         (Series, "observed", True),
 2553:         (Series, "dropna", False),
 2554:     ],
 2555: )
 2556: def test_subsetting_columns_keeps_attrs(klass, attr, value):
 2557:     # GH 9959 - When subsetting columns, don't drop attributes
 2558:     df = DataFrame({"a": [1], "b": [2], "c": [3]})
 2559:     if attr != "axis":
 2560:         df = df.set_index("a")
 2561: 
 2562:     expected = df.groupby("a", **{attr: value})
 2563:     result = expected[["b"]] if klass is DataFrame else expected["b"]
 2564:     assert getattr(result, attr) == getattr(expected, attr)
 2565: 
 2566: 
 2567: def test_subsetting_columns_axis_1():
 2568:     # GH 37725
 2569:     df = DataFrame({"A": [1], "B": [2], "C": [3]})
 2570:     msg = "DataFrame.groupby with axis=1 is deprecated"
 2571:     with tm.assert_produces_warning(FutureWarning, match=msg):
 2572:         g = df.groupby([0, 0, 1], axis=1)
 2573:     match = "Cannot subset columns when using axis=1"
 2574:     with pytest.raises(ValueError, match=match):
 2575:         g[["A", "B"]].sum()
 2576: 
 2577: 
 2578: @pytest.mark.parametrize("func", ["sum", "any", "shift"])
 2579: def test_groupby_column_index_name_lost(func):
 2580:     # GH: 29764 groupby loses index sometimes
 2581:     expected = Index(["a"], name="idx")
 2582:     df = DataFrame([[1]], columns=expected)
 2583:     df_grouped = df.groupby([1])
 2584:     result = getattr(df_grouped, func)().columns
 2585:     tm.assert_index_equal(result, expected)
 2586: 
 2587: 
 2588: @pytest.mark.parametrize(
 2589:     "infer_string",
 2590:     [
 2591:         False,
 2592:         pytest.param(True, marks=td.skip_if_no("pyarrow")),
 2593:     ],
 2594: )
 2595: def test_groupby_duplicate_columns(infer_string):
 2596:     # GH: 31735
 2597:     if infer_string:
 2598:         pytest.importorskip("pyarrow")
 2599:     df = DataFrame(
 2600:         {"A": ["f", "e", "g", "h"], "B": ["a", "b", "c", "d"], "C": [1, 2, 3, 4]}
 2601:     ).astype(object)
 2602:     df.columns = ["A", "B", "B"]
 2603:     with pd.option_context("future.infer_string", infer_string):
 2604:         result = df.groupby([0, 0, 0, 0]).min()
 2605:     expected = DataFrame(
 2606:         [["e", "a", 1]], index=np.array([0]), columns=["A", "B", "B"], dtype=object
 2607:     )
 2608:     tm.assert_frame_equal(result, expected)
 2609: 
 2610: 
 2611: def test_groupby_series_with_tuple_name():
 2612:     # GH 37755
 2613:     ser = Series([1, 2, 3, 4], index=[1, 1, 2, 2], name=("a", "a"))
 2614:     ser.index.name = ("b", "b")
 2615:     result = ser.groupby(level=0).last()
 2616:     expected = Series([2, 4], index=[1, 2], name=("a", "a"))
 2617:     expected.index.name = ("b", "b")
 2618:     tm.assert_series_equal(result, expected)
 2619: 
 2620: 
 2621: @pytest.mark.parametrize(
 2622:     "func, values", [("sum", [97.0, 98.0]), ("mean", [24.25, 24.5])]
 2623: )
 2624: def test_groupby_numerical_stability_sum_mean(func, values):
 2625:     # GH#38778
 2626:     data = [1e16, 1e16, 97, 98, -5e15, -5e15, -5e15, -5e15]
 2627:     df = DataFrame({"group": [1, 2] * 4, "a": data, "b": data})
 2628:     result = getattr(df.groupby("group"), func)()
 2629:     expected = DataFrame({"a": values, "b": values}, index=Index([1, 2], name="group"))
 2630:     tm.assert_frame_equal(result, expected)
 2631: 
 2632: 
 2633: def test_groupby_numerical_stability_cumsum():
 2634:     # GH#38934
 2635:     data = [1e16, 1e16, 97, 98, -5e15, -5e15, -5e15, -5e15]
 2636:     df = DataFrame({"group": [1, 2] * 4, "a": data, "b": data})
 2637:     result = df.groupby("group").cumsum()
 2638:     exp_data = (
 2639:         [1e16] * 2 + [1e16 + 96, 1e16 + 98] + [5e15 + 97, 5e15 + 98] + [97.0, 98.0]
 2640:     )
 2641:     expected = DataFrame({"a": exp_data, "b": exp_data})
 2642:     tm.assert_frame_equal(result, expected, check_exact=True)
 2643: 
 2644: 
 2645: def test_groupby_cumsum_skipna_false():
 2646:     # GH#46216 don't propagate np.nan above the diagonal
 2647:     arr = np.random.default_rng(2).standard_normal((5, 5))
 2648:     df = DataFrame(arr)
 2649:     for i in range(5):
 2650:         df.iloc[i, i] = np.nan
 2651: 
 2652:     df["A"] = 1
 2653:     gb = df.groupby("A")
 2654: 
 2655:     res = gb.cumsum(skipna=False)
 2656: 
 2657:     expected = df[[0, 1, 2, 3, 4]].cumsum(skipna=False)
 2658:     tm.assert_frame_equal(res, expected)
 2659: 
 2660: 
 2661: def test_groupby_cumsum_timedelta64():
 2662:     # GH#46216 don't ignore is_datetimelike in libgroupby.group_cumsum
 2663:     dti = date_range("2016-01-01", periods=5)
 2664:     ser = Series(dti) - dti[0]
 2665:     ser[2] = pd.NaT
 2666: 
 2667:     df = DataFrame({"A": 1, "B": ser})
 2668:     gb = df.groupby("A")
 2669: 
 2670:     res = gb.cumsum(numeric_only=False, skipna=True)
 2671:     exp = DataFrame({"B": [ser[0], ser[1], pd.NaT, ser[4], ser[4] * 2]})
 2672:     tm.assert_frame_equal(res, exp)
 2673: 
 2674:     res = gb.cumsum(numeric_only=False, skipna=False)
 2675:     exp = DataFrame({"B": [ser[0], ser[1], pd.NaT, pd.NaT, pd.NaT]})
 2676:     tm.assert_frame_equal(res, exp)
 2677: 
 2678: 
 2679: def test_groupby_mean_duplicate_index(rand_series_with_duplicate_datetimeindex):
 2680:     dups = rand_series_with_duplicate_datetimeindex
 2681:     result = dups.groupby(level=0).mean()
 2682:     expected = dups.groupby(dups.index).mean()
 2683:     tm.assert_series_equal(result, expected)
 2684: 
 2685: 
 2686: def test_groupby_all_nan_groups_drop():
 2687:     # GH 15036
 2688:     s = Series([1, 2, 3], [np.nan, np.nan, np.nan])
 2689:     result = s.groupby(s.index).sum()
 2690:     expected = Series([], index=Index([], dtype=np.float64), dtype=np.int64)
 2691:     tm.assert_series_equal(result, expected)
 2692: 
 2693: 
 2694: @pytest.mark.parametrize("numeric_only", [True, False])
 2695: def test_groupby_empty_multi_column(as_index, numeric_only):
 2696:     # GH 15106 & GH 41998
 2697:     df = DataFrame(data=[], columns=["A", "B", "C"])
 2698:     gb = df.groupby(["A", "B"], as_index=as_index)
 2699:     result = gb.sum(numeric_only=numeric_only)
 2700:     if as_index:
 2701:         index = MultiIndex([[], []], [[], []], names=["A", "B"])
 2702:         columns = ["C"] if not numeric_only else []
 2703:     else:
 2704:         index = RangeIndex(0)
 2705:         columns = ["A", "B", "C"] if not numeric_only else ["A", "B"]
 2706:     expected = DataFrame([], columns=columns, index=index)
 2707:     tm.assert_frame_equal(result, expected)
 2708: 
 2709: 
 2710: def test_groupby_aggregation_non_numeric_dtype():
 2711:     # GH #43108
 2712:     df = DataFrame(
 2713:         [["M", [1]], ["M", [1]], ["W", [10]], ["W", [20]]], columns=["MW", "v"]
 2714:     )
 2715: 
 2716:     expected = DataFrame(
 2717:         {
 2718:             "v": [[1, 1], [10, 20]],
 2719:         },
 2720:         index=Index(["M", "W"], dtype="object", name="MW"),
 2721:     )
 2722: 
 2723:     gb = df.groupby(by=["MW"])
 2724:     result = gb.sum()
 2725:     tm.assert_frame_equal(result, expected)
 2726: 
 2727: 
 2728: def test_groupby_aggregation_multi_non_numeric_dtype():
 2729:     # GH #42395
 2730:     df = DataFrame(
 2731:         {
 2732:             "x": [1, 0, 1, 1, 0],
 2733:             "y": [Timedelta(i, "days") for i in range(1, 6)],
 2734:             "z": [Timedelta(i * 10, "days") for i in range(1, 6)],
 2735:         }
 2736:     )
 2737: 
 2738:     expected = DataFrame(
 2739:         {
 2740:             "y": [Timedelta(i, "days") for i in range(7, 9)],
 2741:             "z": [Timedelta(i * 10, "days") for i in range(7, 9)],
 2742:         },
 2743:         index=Index([0, 1], dtype="int64", name="x"),
 2744:     )
 2745: 
 2746:     gb = df.groupby(by=["x"])
 2747:     result = gb.sum()
 2748:     tm.assert_frame_equal(result, expected)
 2749: 
 2750: 
 2751: def test_groupby_aggregation_numeric_with_non_numeric_dtype():
 2752:     # GH #43108
 2753:     df = DataFrame(
 2754:         {
 2755:             "x": [1, 0, 1, 1, 0],
 2756:             "y": [Timedelta(i, "days") for i in range(1, 6)],
 2757:             "z": list(range(1, 6)),
 2758:         }
 2759:     )
 2760: 
 2761:     expected = DataFrame(
 2762:         {"y": [Timedelta(7, "days"), Timedelta(8, "days")], "z": [7, 8]},
 2763:         index=Index([0, 1], dtype="int64", name="x"),
 2764:     )
 2765: 
 2766:     gb = df.groupby(by=["x"])
 2767:     result = gb.sum()
 2768:     tm.assert_frame_equal(result, expected)
 2769: 
 2770: 
 2771: def test_groupby_filtered_df_std():
 2772:     # GH 16174
 2773:     dicts = [
 2774:         {"filter_col": False, "groupby_col": True, "bool_col": True, "float_col": 10.5},
 2775:         {"filter_col": True, "groupby_col": True, "bool_col": True, "float_col": 20.5},
 2776:         {"filter_col": True, "groupby_col": True, "bool_col": True, "float_col": 30.5},
 2777:     ]
 2778:     df = DataFrame(dicts)
 2779: 
 2780:     df_filter = df[df["filter_col"] == True]  # noqa: E712
 2781:     dfgb = df_filter.groupby("groupby_col")
 2782:     result = dfgb.std()
 2783:     expected = DataFrame(
 2784:         [[0.0, 0.0, 7.071068]],
 2785:         columns=["filter_col", "bool_col", "float_col"],
 2786:         index=Index([True], name="groupby_col"),
 2787:     )
 2788:     tm.assert_frame_equal(result, expected)
 2789: 
 2790: 
 2791: def test_datetime_categorical_multikey_groupby_indices():
 2792:     # GH 26859
 2793:     df = DataFrame(
 2794:         {
 2795:             "a": Series(list("abc")),
 2796:             "b": Series(
 2797:                 to_datetime(["2018-01-01", "2018-02-01", "2018-03-01"]),
 2798:                 dtype="category",
 2799:             ),
 2800:             "c": Categorical.from_codes([-1, 0, 1], categories=[0, 1]),
 2801:         }
 2802:     )
 2803:     result = df.groupby(["a", "b"], observed=False).indices
 2804:     expected = {
 2805:         ("a", Timestamp("2018-01-01 00:00:00")): np.array([0]),
 2806:         ("b", Timestamp("2018-02-01 00:00:00")): np.array([1]),
 2807:         ("c", Timestamp("2018-03-01 00:00:00")): np.array([2]),
 2808:     }
 2809:     assert result == expected
 2810: 
 2811: 
 2812: def test_rolling_wrong_param_min_period():
 2813:     # GH34037
 2814:     name_l = ["Alice"] * 5 + ["Bob"] * 5
 2815:     val_l = [np.nan, np.nan, 1, 2, 3] + [np.nan, 1, 2, 3, 4]
 2816:     test_df = DataFrame([name_l, val_l]).T
 2817:     test_df.columns = ["name", "val"]
 2818: 
 2819:     result_error_msg = r"__init__\(\) got an unexpected keyword argument 'min_period'"
 2820:     with pytest.raises(TypeError, match=result_error_msg):
 2821:         test_df.groupby("name")["val"].rolling(window=2, min_period=1).sum()
 2822: 
 2823: 
 2824: @pytest.mark.parametrize(
 2825:     "dtype",
 2826:     [
 2827:         object,
 2828:         pytest.param("string[pyarrow_numpy]", marks=td.skip_if_no("pyarrow")),
 2829:     ],
 2830: )
 2831: def test_by_column_values_with_same_starting_value(dtype):
 2832:     # GH29635
 2833:     df = DataFrame(
 2834:         {
 2835:             "Name": ["Thomas", "Thomas", "Thomas John"],
 2836:             "Credit": [1200, 1300, 900],
 2837:             "Mood": Series(["sad", "happy", "happy"], dtype=dtype),
 2838:         }
 2839:     )
 2840:     aggregate_details = {"Mood": Series.mode, "Credit": "sum"}
 2841: 
 2842:     result = df.groupby(["Name"]).agg(aggregate_details)
 2843:     expected_result = DataFrame(
 2844:         {
 2845:             "Mood": [["happy", "sad"], "happy"],
 2846:             "Credit": [2500, 900],
 2847:             "Name": ["Thomas", "Thomas John"],
 2848:         }
 2849:     ).set_index("Name")
 2850: 
 2851:     tm.assert_frame_equal(result, expected_result)
 2852: 
 2853: 
 2854: def test_groupby_none_in_first_mi_level():
 2855:     # GH#47348
 2856:     arr = [[None, 1, 0, 1], [2, 3, 2, 3]]
 2857:     ser = Series(1, index=MultiIndex.from_arrays(arr, names=["a", "b"]))
 2858:     result = ser.groupby(level=[0, 1]).sum()
 2859:     expected = Series(
 2860:         [1, 2], MultiIndex.from_tuples([(0.0, 2), (1.0, 3)], names=["a", "b"])
 2861:     )
 2862:     tm.assert_series_equal(result, expected)
 2863: 
 2864: 
 2865: def test_groupby_none_column_name():
 2866:     # GH#47348
 2867:     df = DataFrame({None: [1, 1, 2, 2], "b": [1, 1, 2, 3], "c": [4, 5, 6, 7]})
 2868:     result = df.groupby(by=[None]).sum()
 2869:     expected = DataFrame({"b": [2, 5], "c": [9, 13]}, index=Index([1, 2], name=None))
 2870:     tm.assert_frame_equal(result, expected)
 2871: 
 2872: 
 2873: @pytest.mark.parametrize("selection", [None, "a", ["a"]])
 2874: def test_single_element_list_grouping(selection):
 2875:     # GH#42795, GH#53500
 2876:     df = DataFrame({"a": [1, 2], "b": [np.nan, 5], "c": [np.nan, 2]}, index=["x", "y"])
 2877:     grouped = df.groupby(["a"]) if selection is None else df.groupby(["a"])[selection]
 2878:     result = [key for key, _ in grouped]
 2879: 
 2880:     expected = [(1,), (2,)]
 2881:     assert result == expected
 2882: 
 2883: 
 2884: def test_groupby_string_dtype():
 2885:     # GH 40148
 2886:     df = DataFrame({"str_col": ["a", "b", "c", "a"], "num_col": [1, 2, 3, 2]})
 2887:     df["str_col"] = df["str_col"].astype("string")
 2888:     expected = DataFrame(
 2889:         {
 2890:             "str_col": [
 2891:                 "a",
 2892:                 "b",
 2893:                 "c",
 2894:             ],
 2895:             "num_col": [1.5, 2.0, 3.0],
 2896:         }
 2897:     )
 2898:     expected["str_col"] = expected["str_col"].astype("string")
 2899:     grouped = df.groupby("str_col", as_index=False)
 2900:     result = grouped.mean()
 2901:     tm.assert_frame_equal(result, expected)
 2902: 
 2903: 
 2904: @pytest.mark.parametrize(
 2905:     "level_arg, multiindex", [([0], False), ((0,), False), ([0], True), ((0,), True)]
 2906: )
 2907: def test_single_element_listlike_level_grouping_deprecation(level_arg, multiindex):
 2908:     # GH 51583
 2909:     df = DataFrame({"a": [1, 2], "b": [3, 4], "c": [5, 6]}, index=["x", "y"])
 2910:     if multiindex:
 2911:         df = df.set_index(["a", "b"])
 2912:     depr_msg = (
 2913:         "Creating a Groupby object with a length-1 list-like "
 2914:         "level parameter will yield indexes as tuples in a future version. "
 2915:         "To keep indexes as scalars, create Groupby objects with "
 2916:         "a scalar level parameter instead."
 2917:     )
 2918:     with tm.assert_produces_warning(FutureWarning, match=depr_msg):
 2919:         [key for key, _ in df.groupby(level=level_arg)]
 2920: 
 2921: 
 2922: @pytest.mark.parametrize("func", ["sum", "cumsum", "cumprod", "prod"])
 2923: def test_groupby_avoid_casting_to_float(func):
 2924:     # GH#37493
 2925:     val = 922337203685477580
 2926:     df = DataFrame({"a": 1, "b": [val]})
 2927:     result = getattr(df.groupby("a"), func)() - val
 2928:     expected = DataFrame({"b": [0]}, index=Index([1], name="a"))
 2929:     if func in ["cumsum", "cumprod"]:
 2930:         expected = expected.reset_index(drop=True)
 2931:     tm.assert_frame_equal(result, expected)
 2932: 
 2933: 
 2934: @pytest.mark.parametrize("func, val", [("sum", 3), ("prod", 2)])
 2935: def test_groupby_sum_support_mask(any_numeric_ea_dtype, func, val):
 2936:     # GH#37493
 2937:     df = DataFrame({"a": 1, "b": [1, 2, pd.NA]}, dtype=any_numeric_ea_dtype)
 2938:     result = getattr(df.groupby("a"), func)()
 2939:     expected = DataFrame(
 2940:         {"b": [val]},
 2941:         index=Index([1], name="a", dtype=any_numeric_ea_dtype),
 2942:         dtype=any_numeric_ea_dtype,
 2943:     )
 2944:     tm.assert_frame_equal(result, expected)
 2945: 
 2946: 
 2947: @pytest.mark.parametrize("val, dtype", [(111, "int"), (222, "uint")])
 2948: def test_groupby_overflow(val, dtype):
 2949:     # GH#37493
 2950:     df = DataFrame({"a": 1, "b": [val, val]}, dtype=f"{dtype}8")
 2951:     result = df.groupby("a").sum()
 2952:     expected = DataFrame(
 2953:         {"b": [val * 2]},
 2954:         index=Index([1], name="a", dtype=f"{dtype}8"),
 2955:         dtype=f"{dtype}64",
 2956:     )
 2957:     tm.assert_frame_equal(result, expected)
 2958: 
 2959:     result = df.groupby("a").cumsum()
 2960:     expected = DataFrame({"b": [val, val * 2]}, dtype=f"{dtype}64")
 2961:     tm.assert_frame_equal(result, expected)
 2962: 
 2963:     result = df.groupby("a").prod()
 2964:     expected = DataFrame(
 2965:         {"b": [val * val]},
 2966:         index=Index([1], name="a", dtype=f"{dtype}8"),
 2967:         dtype=f"{dtype}64",
 2968:     )
 2969:     tm.assert_frame_equal(result, expected)
 2970: 
 2971: 
 2972: @pytest.mark.parametrize("skipna, val", [(True, 3), (False, pd.NA)])
 2973: def test_groupby_cumsum_mask(any_numeric_ea_dtype, skipna, val):
 2974:     # GH#37493
 2975:     df = DataFrame({"a": 1, "b": [1, pd.NA, 2]}, dtype=any_numeric_ea_dtype)
 2976:     result = df.groupby("a").cumsum(skipna=skipna)
 2977:     expected = DataFrame(
 2978:         {"b": [1, pd.NA, val]},
 2979:         dtype=any_numeric_ea_dtype,
 2980:     )
 2981:     tm.assert_frame_equal(result, expected)
 2982: 
 2983: 
 2984: @pytest.mark.parametrize(
 2985:     "val_in, index, val_out",
 2986:     [
 2987:         (
 2988:             [1.0, 2.0, 3.0, 4.0, 5.0],
 2989:             ["foo", "foo", "bar", "baz", "blah"],
 2990:             [3.0, 4.0, 5.0, 3.0],
 2991:         ),
 2992:         (
 2993:             [1.0, 2.0, 3.0, 4.0, 5.0, 6.0],
 2994:             ["foo", "foo", "bar", "baz", "blah", "blah"],
 2995:             [3.0, 4.0, 11.0, 3.0],
 2996:         ),
 2997:     ],
 2998: )
 2999: def test_groupby_index_name_in_index_content(val_in, index, val_out):
 3000:     # GH 48567
 3001:     series = Series(data=val_in, name="values", index=Index(index, name="blah"))
 3002:     result = series.groupby("blah").sum()
 3003:     expected = Series(
 3004:         data=val_out,
 3005:         name="values",
 3006:         index=Index(["bar", "baz", "blah", "foo"], name="blah"),
 3007:     )
 3008:     tm.assert_series_equal(result, expected)
 3009: 
 3010:     result = series.to_frame().groupby("blah").sum()
 3011:     expected = expected.to_frame()
 3012:     tm.assert_frame_equal(result, expected)
 3013: 
 3014: 
 3015: @pytest.mark.parametrize("n", [1, 10, 32, 100, 1000])
 3016: def test_sum_of_booleans(n):
 3017:     # GH 50347
 3018:     df = DataFrame({"groupby_col": 1, "bool": [True] * n})
 3019:     df["bool"] = df["bool"].eq(True)
 3020:     result = df.groupby("groupby_col").sum()
 3021:     expected = DataFrame({"bool": [n]}, index=Index([1], name="groupby_col"))
 3022:     tm.assert_frame_equal(result, expected)
 3023: 
 3024: 
 3025: @pytest.mark.filterwarnings(
 3026:     "ignore:invalid value encountered in remainder:RuntimeWarning"
 3027: )
 3028: @pytest.mark.parametrize("method", ["head", "tail", "nth", "first", "last"])
 3029: def test_groupby_method_drop_na(method):
 3030:     # GH 21755
 3031:     df = DataFrame({"A": ["a", np.nan, "b", np.nan, "c"], "B": range(5)})
 3032: 
 3033:     if method == "nth":
 3034:         result = getattr(df.groupby("A"), method)(n=0)
 3035:     else:
 3036:         result = getattr(df.groupby("A"), method)()
 3037: 
 3038:     if method in ["first", "last"]:
 3039:         expected = DataFrame({"B": [0, 2, 4]}).set_index(
 3040:             Series(["a", "b", "c"], name="A")
 3041:         )
 3042:     else:
 3043:         expected = DataFrame({"A": ["a", "b", "c"], "B": [0, 2, 4]}, index=[0, 2, 4])
 3044:     tm.assert_frame_equal(result, expected)
 3045: 
 3046: 
 3047: def test_groupby_reduce_period():
 3048:     # GH#51040
 3049:     pi = pd.period_range("2016-01-01", periods=100, freq="D")
 3050:     grps = list(range(10)) * 10
 3051:     ser = pi.to_series()
 3052:     gb = ser.groupby(grps)
 3053: 
 3054:     with pytest.raises(TypeError, match="Period type does not support sum operations"):
 3055:         gb.sum()
 3056:     with pytest.raises(
 3057:         TypeError, match="Period type does not support cumsum operations"
 3058:     ):
 3059:         gb.cumsum()
 3060:     with pytest.raises(TypeError, match="Period type does not support prod operations"):
 3061:         gb.prod()
 3062:     with pytest.raises(
 3063:         TypeError, match="Period type does not support cumprod operations"
 3064:     ):
 3065:         gb.cumprod()
 3066: 
 3067:     res = gb.max()
 3068:     expected = ser[-10:]
 3069:     expected.index = Index(range(10), dtype=int)
 3070:     tm.assert_series_equal(res, expected)
 3071: 
 3072:     res = gb.min()
 3073:     expected = ser[:10]
 3074:     expected.index = Index(range(10), dtype=int)
 3075:     tm.assert_series_equal(res, expected)
 3076: 
 3077: 
 3078: def test_obj_with_exclusions_duplicate_columns():
 3079:     # GH#50806
 3080:     df = DataFrame([[0, 1, 2, 3]])
 3081:     df.columns = [0, 1, 2, 0]
 3082:     gb = df.groupby(df[1])
 3083:     result = gb._obj_with_exclusions
 3084:     expected = df.take([0, 2, 3], axis=1)
 3085:     tm.assert_frame_equal(result, expected)
 3086: 
 3087: 
 3088: @pytest.mark.parametrize("numeric_only", [True, False])
 3089: def test_groupby_numeric_only_std_no_result(numeric_only):
 3090:     # GH 51080
 3091:     dicts_non_numeric = [{"a": "foo", "b": "bar"}, {"a": "car", "b": "dar"}]
 3092:     df = DataFrame(dicts_non_numeric)
 3093:     dfgb = df.groupby("a", as_index=False, sort=False)
 3094: 
 3095:     if numeric_only:
 3096:         result = dfgb.std(numeric_only=True)
 3097:         expected_df = DataFrame(["foo", "car"], columns=["a"])
 3098:         tm.assert_frame_equal(result, expected_df)
 3099:     else:
 3100:         with pytest.raises(
 3101:             ValueError, match="could not convert string to float: 'bar'"
 3102:         ):
 3103:             dfgb.std(numeric_only=numeric_only)
 3104: 
 3105: 
 3106: def test_grouping_with_categorical_interval_columns():
 3107:     # GH#34164
 3108:     df = DataFrame({"x": [0.1, 0.2, 0.3, -0.4, 0.5], "w": ["a", "b", "a", "c", "a"]})
 3109:     qq = pd.qcut(df["x"], q=np.linspace(0, 1, 5))
 3110:     result = df.groupby([qq, "w"], observed=False)["x"].agg("mean")
 3111:     categorical_index_level_1 = Categorical(
 3112:         [
 3113:             Interval(-0.401, 0.1, closed="right"),
 3114:             Interval(0.1, 0.2, closed="right"),
 3115:             Interval(0.2, 0.3, closed="right"),
 3116:             Interval(0.3, 0.5, closed="right"),
 3117:         ],
 3118:         ordered=True,
 3119:     )
 3120:     index_level_2 = ["a", "b", "c"]
 3121:     mi = MultiIndex.from_product(
 3122:         [categorical_index_level_1, index_level_2], names=["x", "w"]
 3123:     )
 3124:     expected = Series(
 3125:         np.array(
 3126:             [
 3127:                 0.1,
 3128:                 np.nan,
 3129:                 -0.4,
 3130:                 np.nan,
 3131:                 0.2,
 3132:                 np.nan,
 3133:                 0.3,
 3134:                 np.nan,
 3135:                 np.nan,
 3136:                 0.5,
 3137:                 np.nan,
 3138:                 np.nan,
 3139:             ]
 3140:         ),
 3141:         index=mi,
 3142:         name="x",
 3143:     )
 3144:     tm.assert_series_equal(result, expected)
 3145: 
 3146: 
 3147: @pytest.mark.parametrize("bug_var", [1, "a"])
 3148: def test_groupby_sum_on_nan_should_return_nan(bug_var):
 3149:     # GH 24196
 3150:     df = DataFrame({"A": [bug_var, bug_var, bug_var, np.nan]})
 3151:     dfgb = df.groupby(lambda x: x)
 3152:     result = dfgb.sum(min_count=1)
 3153: 
 3154:     expected_df = DataFrame([bug_var, bug_var, bug_var, None], columns=["A"])
 3155:     tm.assert_frame_equal(result, expected_df)
 3156: 
 3157: 
 3158: @pytest.mark.parametrize(
 3159:     "method",
 3160:     [
 3161:         "count",
 3162:         "corr",
 3163:         "cummax",
 3164:         "cummin",
 3165:         "cumprod",
 3166:         "describe",
 3167:         "rank",
 3168:         "quantile",
 3169:         "diff",
 3170:         "shift",
 3171:         "all",
 3172:         "any",
 3173:         "idxmin",
 3174:         "idxmax",
 3175:         "ffill",
 3176:         "bfill",
 3177:         "pct_change",
 3178:     ],
 3179: )
 3180: def test_groupby_selection_with_methods(df, method):
 3181:     # some methods which require DatetimeIndex
 3182:     rng = date_range("2014", periods=len(df))
 3183:     df.index = rng
 3184: 
 3185:     g = df.groupby(["A"])[["C"]]
 3186:     g_exp = df[["C"]].groupby(df["A"])
 3187:     # TODO check groupby with > 1 col ?
 3188: 
 3189:     res = getattr(g, method)()
 3190:     exp = getattr(g_exp, method)()
 3191: 
 3192:     # should always be frames!
 3193:     tm.assert_frame_equal(res, exp)
 3194: 
 3195: 
 3196: def test_groupby_selection_other_methods(df):
 3197:     # some methods which require DatetimeIndex
 3198:     rng = date_range("2014", periods=len(df))
 3199:     df.columns.name = "foo"
 3200:     df.index = rng
 3201: 
 3202:     g = df.groupby(["A"])[["C"]]
 3203:     g_exp = df[["C"]].groupby(df["A"])
 3204: 
 3205:     # methods which aren't just .foo()
 3206:     warn_msg = "DataFrameGroupBy.fillna is deprecated"
 3207:     with tm.assert_produces_warning(FutureWarning, match=warn_msg):
 3208:         tm.assert_frame_equal(g.fillna(0), g_exp.fillna(0))
 3209:     msg = "DataFrameGroupBy.dtypes is deprecated"
 3210:     with tm.assert_produces_warning(FutureWarning, match=msg):
 3211:         tm.assert_frame_equal(g.dtypes, g_exp.dtypes)
 3212:     tm.assert_frame_equal(g.apply(lambda x: x.sum()), g_exp.apply(lambda x: x.sum()))
 3213: 
 3214:     tm.assert_frame_equal(g.resample("D").mean(), g_exp.resample("D").mean())
 3215:     tm.assert_frame_equal(g.resample("D").ohlc(), g_exp.resample("D").ohlc())
 3216: 
 3217:     tm.assert_frame_equal(
 3218:         g.filter(lambda x: len(x) == 3), g_exp.filter(lambda x: len(x) == 3)
 3219:     )
 3220: 
 3221: 
 3222: def test_groupby_with_Time_Grouper(unit):
 3223:     idx2 = to_datetime(
 3224:         [
 3225:             "2016-08-31 22:08:12.000",
 3226:             "2016-08-31 22:09:12.200",
 3227:             "2016-08-31 22:20:12.400",
 3228:         ]
 3229:     ).as_unit(unit)
 3230: 
 3231:     test_data = DataFrame(
 3232:         {"quant": [1.0, 1.0, 3.0], "quant2": [1.0, 1.0, 3.0], "time2": idx2}
 3233:     )
 3234: 
 3235:     time2 = date_range("2016-08-31 22:08:00", periods=13, freq="1min", unit=unit)
 3236:     expected_output = DataFrame(
 3237:         {
 3238:             "time2": time2,
 3239:             "quant": [1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1],
 3240:             "quant2": [1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1],
 3241:         }
 3242:     )
 3243: 
 3244:     gb = test_data.groupby(Grouper(key="time2", freq="1min"))
 3245:     result = gb.count().reset_index()
 3246: 
 3247:     tm.assert_frame_equal(result, expected_output)
 3248: 
 3249: 
 3250: def test_groupby_series_with_datetimeindex_month_name():
 3251:     # GH 48509
 3252:     s = Series([0, 1, 0], index=date_range("2022-01-01", periods=3), name="jan")
 3253:     result = s.groupby(s).count()
 3254:     expected = Series([2, 1], name="jan")
 3255:     expected.index.name = "jan"
 3256:     tm.assert_series_equal(result, expected)
 3257: 
 3258: 
 3259: @pytest.mark.parametrize("test_series", [True, False])
 3260: @pytest.mark.parametrize(
 3261:     "kwarg, value, name, warn",
 3262:     [
 3263:         ("by", "a", 1, None),
 3264:         ("by", ["a"], 1, FutureWarning),
 3265:         ("by", ["a"], (1,), None),
 3266:         ("level", 0, 1, None),
 3267:         ("level", [0], 1, FutureWarning),
 3268:         ("level", [0], (1,), None),
 3269:     ],
 3270: )
 3271: def test_depr_get_group_len_1_list_likes(test_series, kwarg, value, name, warn):
 3272:     # GH#25971
 3273:     obj = DataFrame({"b": [3, 4, 5]}, index=Index([1, 1, 2], name="a"))
 3274:     if test_series:
 3275:         obj = obj["b"]
 3276:     gb = obj.groupby(**{kwarg: value})
 3277:     msg = "you will need to pass a length-1 tuple"
 3278:     with tm.assert_produces_warning(warn, match=msg):
 3279:         result = gb.get_group(name)
 3280:     if test_series:
 3281:         expected = Series([3, 4], index=Index([1, 1], name="a"), name="b")
 3282:     else:
 3283:         expected = DataFrame({"b": [3, 4]}, index=Index([1, 1], name="a"))
 3284:     tm.assert_equal(result, expected)
 3285: 
 3286: 
 3287: def test_groupby_ngroup_with_nan():
 3288:     # GH#50100
 3289:     df = DataFrame({"a": Categorical([np.nan]), "b": [1]})
 3290:     result = df.groupby(["a", "b"], dropna=False, observed=False).ngroup()
 3291:     expected = Series([0])
 3292:     tm.assert_series_equal(result, expected)
 3293: 
 3294: 
 3295: def test_get_group_axis_1():
 3296:     # GH#54858
 3297:     df = DataFrame(
 3298:         {
 3299:             "col1": [0, 3, 2, 3],
 3300:             "col2": [4, 1, 6, 7],
 3301:             "col3": [3, 8, 2, 10],
 3302:             "col4": [1, 13, 6, 15],
 3303:             "col5": [-4, 5, 6, -7],
 3304:         }
 3305:     )
 3306:     with tm.assert_produces_warning(FutureWarning, match="deprecated"):
 3307:         grouped = df.groupby(axis=1, by=[1, 2, 3, 2, 1])
 3308:     result = grouped.get_group(1)
 3309:     expected = DataFrame(
 3310:         {
 3311:             "col1": [0, 3, 2, 3],
 3312:             "col5": [-4, 5, 6, -7],
 3313:         }
 3314:     )
 3315:     tm.assert_frame_equal(result, expected)
 3316: 
 3317: 
 3318: def test_groupby_ffill_with_duplicated_index():
 3319:     # GH#43412
 3320:     df = DataFrame({"a": [1, 2, 3, 4, np.nan, np.nan]}, index=[0, 1, 2, 0, 1, 2])
 3321: 
 3322:     result = df.groupby(level=0).ffill()
 3323:     expected = DataFrame({"a": [1, 2, 3, 4, 2, 3]}, index=[0, 1, 2, 0, 1, 2])
 3324:     tm.assert_frame_equal(result, expected, check_dtype=False)
 3325: 
 3326: 
 3327: @pytest.mark.parametrize("test_series", [True, False])
 3328: def test_decimal_na_sort(test_series):
 3329:     # GH#54847
 3330:     # We catch both TypeError and decimal.InvalidOperation exceptions in safe_sort.
 3331:     # If this next assert raises, we can just catch TypeError
 3332:     assert not isinstance(decimal.InvalidOperation, TypeError)
 3333:     df = DataFrame(
 3334:         {
 3335:             "key": [Decimal(1), Decimal(1), None, None],
 3336:             "value": [Decimal(2), Decimal(3), Decimal(4), Decimal(5)],
 3337:         }
 3338:     )
 3339:     gb = df.groupby("key", dropna=False)
 3340:     if test_series:
 3341:         gb = gb["value"]
 3342:     result = gb._grouper.result_index
 3343:     expected = Index([Decimal(1), None], name="key")
 3344:     tm.assert_index_equal(result, expected)
