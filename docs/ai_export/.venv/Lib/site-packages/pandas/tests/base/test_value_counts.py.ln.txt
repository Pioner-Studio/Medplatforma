    1: import collections
    2: from datetime import timedelta
    3: 
    4: import numpy as np
    5: import pytest
    6: 
    7: import pandas as pd
    8: from pandas import (
    9:     DatetimeIndex,
   10:     Index,
   11:     Interval,
   12:     IntervalIndex,
   13:     MultiIndex,
   14:     Series,
   15:     Timedelta,
   16:     TimedeltaIndex,
   17:     array,
   18: )
   19: import pandas._testing as tm
   20: from pandas.tests.base.common import allow_na_ops
   21: 
   22: 
   23: @pytest.mark.filterwarnings(r"ignore:PeriodDtype\[B\] is deprecated:FutureWarning")
   24: def test_value_counts(index_or_series_obj):
   25:     obj = index_or_series_obj
   26:     obj = np.repeat(obj, range(1, len(obj) + 1))
   27:     result = obj.value_counts()
   28: 
   29:     counter = collections.Counter(obj)
   30:     expected = Series(dict(counter.most_common()), dtype=np.int64, name="count")
   31: 
   32:     if obj.dtype != np.float16:
   33:         expected.index = expected.index.astype(obj.dtype)
   34:     else:
   35:         with pytest.raises(NotImplementedError, match="float16 indexes are not "):
   36:             expected.index.astype(obj.dtype)
   37:         return
   38:     if isinstance(expected.index, MultiIndex):
   39:         expected.index.names = obj.names
   40:     else:
   41:         expected.index.name = obj.name
   42: 
   43:     if not isinstance(result.dtype, np.dtype):
   44:         if getattr(obj.dtype, "storage", "") == "pyarrow":
   45:             expected = expected.astype("int64[pyarrow]")
   46:         else:
   47:             # i.e IntegerDtype
   48:             expected = expected.astype("Int64")
   49: 
   50:     # TODO(GH#32514): Order of entries with the same count is inconsistent
   51:     #  on CI (gh-32449)
   52:     if obj.duplicated().any():
   53:         result = result.sort_index()
   54:         expected = expected.sort_index()
   55:     tm.assert_series_equal(result, expected)
   56: 
   57: 
   58: @pytest.mark.parametrize("null_obj", [np.nan, None])
   59: @pytest.mark.filterwarnings(r"ignore:PeriodDtype\[B\] is deprecated:FutureWarning")
   60: def test_value_counts_null(null_obj, index_or_series_obj):
   61:     orig = index_or_series_obj
   62:     obj = orig.copy()
   63: 
   64:     if not allow_na_ops(obj):
   65:         pytest.skip("type doesn't allow for NA operations")
   66:     elif len(obj) < 1:
   67:         pytest.skip("Test doesn't make sense on empty data")
   68:     elif isinstance(orig, MultiIndex):
   69:         pytest.skip(f"MultiIndex can't hold '{null_obj}'")
   70: 
   71:     values = obj._values
   72:     values[0:2] = null_obj
   73: 
   74:     klass = type(obj)
   75:     repeated_values = np.repeat(values, range(1, len(values) + 1))
   76:     obj = klass(repeated_values, dtype=obj.dtype)
   77: 
   78:     # because np.nan == np.nan is False, but None == None is True
   79:     # np.nan would be duplicated, whereas None wouldn't
   80:     counter = collections.Counter(obj.dropna())
   81:     expected = Series(dict(counter.most_common()), dtype=np.int64, name="count")
   82: 
   83:     if obj.dtype != np.float16:
   84:         expected.index = expected.index.astype(obj.dtype)
   85:     else:
   86:         with pytest.raises(NotImplementedError, match="float16 indexes are not "):
   87:             expected.index.astype(obj.dtype)
   88:         return
   89:     expected.index.name = obj.name
   90: 
   91:     result = obj.value_counts()
   92:     if obj.duplicated().any():
   93:         # TODO(GH#32514):
   94:         #  Order of entries with the same count is inconsistent on CI (gh-32449)
   95:         expected = expected.sort_index()
   96:         result = result.sort_index()
   97: 
   98:     if not isinstance(result.dtype, np.dtype):
   99:         if getattr(obj.dtype, "storage", "") == "pyarrow":
  100:             expected = expected.astype("int64[pyarrow]")
  101:         else:
  102:             # i.e IntegerDtype
  103:             expected = expected.astype("Int64")
  104:     tm.assert_series_equal(result, expected)
  105: 
  106:     expected[null_obj] = 3
  107: 
  108:     result = obj.value_counts(dropna=False)
  109:     if obj.duplicated().any():
  110:         # TODO(GH#32514):
  111:         #  Order of entries with the same count is inconsistent on CI (gh-32449)
  112:         expected = expected.sort_index()
  113:         result = result.sort_index()
  114:     tm.assert_series_equal(result, expected)
  115: 
  116: 
  117: def test_value_counts_inferred(index_or_series, using_infer_string):
  118:     klass = index_or_series
  119:     s_values = ["a", "b", "b", "b", "b", "c", "d", "d", "a", "a"]
  120:     s = klass(s_values)
  121:     expected = Series([4, 3, 2, 1], index=["b", "a", "d", "c"], name="count")
  122:     tm.assert_series_equal(s.value_counts(), expected)
  123: 
  124:     if isinstance(s, Index):
  125:         exp = Index(np.unique(np.array(s_values, dtype=np.object_)))
  126:         tm.assert_index_equal(s.unique(), exp)
  127:     else:
  128:         exp = np.unique(np.array(s_values, dtype=np.object_))
  129:         if using_infer_string:
  130:             exp = array(exp)
  131:         tm.assert_equal(s.unique(), exp)
  132: 
  133:     assert s.nunique() == 4
  134:     # don't sort, have to sort after the fact as not sorting is
  135:     # platform-dep
  136:     hist = s.value_counts(sort=False).sort_values()
  137:     expected = Series([3, 1, 4, 2], index=list("acbd"), name="count").sort_values()
  138:     tm.assert_series_equal(hist, expected)
  139: 
  140:     # sort ascending
  141:     hist = s.value_counts(ascending=True)
  142:     expected = Series([1, 2, 3, 4], index=list("cdab"), name="count")
  143:     tm.assert_series_equal(hist, expected)
  144: 
  145:     # relative histogram.
  146:     hist = s.value_counts(normalize=True)
  147:     expected = Series(
  148:         [0.4, 0.3, 0.2, 0.1], index=["b", "a", "d", "c"], name="proportion"
  149:     )
  150:     tm.assert_series_equal(hist, expected)
  151: 
  152: 
  153: def test_value_counts_bins(index_or_series, using_infer_string):
  154:     klass = index_or_series
  155:     s_values = ["a", "b", "b", "b", "b", "c", "d", "d", "a", "a"]
  156:     s = klass(s_values)
  157: 
  158:     # bins
  159:     msg = "bins argument only works with numeric data"
  160:     with pytest.raises(TypeError, match=msg):
  161:         s.value_counts(bins=1)
  162: 
  163:     s1 = Series([1, 1, 2, 3])
  164:     res1 = s1.value_counts(bins=1)
  165:     exp1 = Series({Interval(0.997, 3.0): 4}, name="count")
  166:     tm.assert_series_equal(res1, exp1)
  167:     res1n = s1.value_counts(bins=1, normalize=True)
  168:     exp1n = Series({Interval(0.997, 3.0): 1.0}, name="proportion")
  169:     tm.assert_series_equal(res1n, exp1n)
  170: 
  171:     if isinstance(s1, Index):
  172:         tm.assert_index_equal(s1.unique(), Index([1, 2, 3]))
  173:     else:
  174:         exp = np.array([1, 2, 3], dtype=np.int64)
  175:         tm.assert_numpy_array_equal(s1.unique(), exp)
  176: 
  177:     assert s1.nunique() == 3
  178: 
  179:     # these return the same
  180:     res4 = s1.value_counts(bins=4, dropna=True)
  181:     intervals = IntervalIndex.from_breaks([0.997, 1.5, 2.0, 2.5, 3.0])
  182:     exp4 = Series([2, 1, 1, 0], index=intervals.take([0, 1, 3, 2]), name="count")
  183:     tm.assert_series_equal(res4, exp4)
  184: 
  185:     res4 = s1.value_counts(bins=4, dropna=False)
  186:     intervals = IntervalIndex.from_breaks([0.997, 1.5, 2.0, 2.5, 3.0])
  187:     exp4 = Series([2, 1, 1, 0], index=intervals.take([0, 1, 3, 2]), name="count")
  188:     tm.assert_series_equal(res4, exp4)
  189: 
  190:     res4n = s1.value_counts(bins=4, normalize=True)
  191:     exp4n = Series(
  192:         [0.5, 0.25, 0.25, 0], index=intervals.take([0, 1, 3, 2]), name="proportion"
  193:     )
  194:     tm.assert_series_equal(res4n, exp4n)
  195: 
  196:     # handle NA's properly
  197:     s_values = ["a", "b", "b", "b", np.nan, np.nan, "d", "d", "a", "a", "b"]
  198:     s = klass(s_values)
  199:     expected = Series([4, 3, 2], index=["b", "a", "d"], name="count")
  200:     tm.assert_series_equal(s.value_counts(), expected)
  201: 
  202:     if isinstance(s, Index):
  203:         exp = Index(["a", "b", np.nan, "d"])
  204:         tm.assert_index_equal(s.unique(), exp)
  205:     else:
  206:         exp = np.array(["a", "b", np.nan, "d"], dtype=object)
  207:         if using_infer_string:
  208:             exp = array(exp)
  209:         tm.assert_equal(s.unique(), exp)
  210:     assert s.nunique() == 3
  211: 
  212:     s = klass({}) if klass is dict else klass({}, dtype=object)
  213:     expected = Series([], dtype=np.int64, name="count")
  214:     tm.assert_series_equal(s.value_counts(), expected, check_index_type=False)
  215:     # returned dtype differs depending on original
  216:     if isinstance(s, Index):
  217:         tm.assert_index_equal(s.unique(), Index([]), exact=False)
  218:     else:
  219:         tm.assert_numpy_array_equal(s.unique(), np.array([]), check_dtype=False)
  220: 
  221:     assert s.nunique() == 0
  222: 
  223: 
  224: def test_value_counts_datetime64(index_or_series, unit):
  225:     klass = index_or_series
  226: 
  227:     # GH 3002, datetime64[ns]
  228:     # don't test names though
  229:     df = pd.DataFrame(
  230:         {
  231:             "person_id": ["xxyyzz", "xxyyzz", "xxyyzz", "xxyyww", "foofoo", "foofoo"],
  232:             "dt": pd.to_datetime(
  233:                 [
  234:                     "2010-01-01",
  235:                     "2010-01-01",
  236:                     "2010-01-01",
  237:                     "2009-01-01",
  238:                     "2008-09-09",
  239:                     "2008-09-09",
  240:                 ]
  241:             ).as_unit(unit),
  242:             "food": ["PIE", "GUM", "EGG", "EGG", "PIE", "GUM"],
  243:         }
  244:     )
  245: 
  246:     s = klass(df["dt"].copy())
  247:     s.name = None
  248:     idx = pd.to_datetime(
  249:         ["2010-01-01 00:00:00", "2008-09-09 00:00:00", "2009-01-01 00:00:00"]
  250:     ).as_unit(unit)
  251:     expected_s = Series([3, 2, 1], index=idx, name="count")
  252:     tm.assert_series_equal(s.value_counts(), expected_s)
  253: 
  254:     expected = array(
  255:         np.array(
  256:             ["2010-01-01 00:00:00", "2009-01-01 00:00:00", "2008-09-09 00:00:00"],
  257:             dtype=f"datetime64[{unit}]",
  258:         )
  259:     )
  260:     result = s.unique()
  261:     if isinstance(s, Index):
  262:         tm.assert_index_equal(result, DatetimeIndex(expected))
  263:     else:
  264:         tm.assert_extension_array_equal(result, expected)
  265: 
  266:     assert s.nunique() == 3
  267: 
  268:     # with NaT
  269:     s = df["dt"].copy()
  270:     s = klass(list(s.values) + [pd.NaT] * 4)
  271:     if klass is Series:
  272:         s = s.dt.as_unit(unit)
  273:     else:
  274:         s = s.as_unit(unit)
  275: 
  276:     result = s.value_counts()
  277:     assert result.index.dtype == f"datetime64[{unit}]"
  278:     tm.assert_series_equal(result, expected_s)
  279: 
  280:     result = s.value_counts(dropna=False)
  281:     expected_s = pd.concat(
  282:         [
  283:             Series([4], index=DatetimeIndex([pd.NaT]).as_unit(unit), name="count"),
  284:             expected_s,
  285:         ]
  286:     )
  287:     tm.assert_series_equal(result, expected_s)
  288: 
  289:     assert s.dtype == f"datetime64[{unit}]"
  290:     unique = s.unique()
  291:     assert unique.dtype == f"datetime64[{unit}]"
  292: 
  293:     # numpy_array_equal cannot compare pd.NaT
  294:     if isinstance(s, Index):
  295:         exp_idx = DatetimeIndex(expected.tolist() + [pd.NaT]).as_unit(unit)
  296:         tm.assert_index_equal(unique, exp_idx)
  297:     else:
  298:         tm.assert_extension_array_equal(unique[:3], expected)
  299:         assert pd.isna(unique[3])
  300: 
  301:     assert s.nunique() == 3
  302:     assert s.nunique(dropna=False) == 4
  303: 
  304: 
  305: def test_value_counts_timedelta64(index_or_series, unit):
  306:     # timedelta64[ns]
  307:     klass = index_or_series
  308: 
  309:     day = Timedelta(timedelta(1)).as_unit(unit)
  310:     tdi = TimedeltaIndex([day], name="dt").as_unit(unit)
  311: 
  312:     tdvals = np.zeros(6, dtype=f"m8[{unit}]") + day
  313:     td = klass(tdvals, name="dt")
  314: 
  315:     result = td.value_counts()
  316:     expected_s = Series([6], index=tdi, name="count")
  317:     tm.assert_series_equal(result, expected_s)
  318: 
  319:     expected = tdi
  320:     result = td.unique()
  321:     if isinstance(td, Index):
  322:         tm.assert_index_equal(result, expected)
  323:     else:
  324:         tm.assert_extension_array_equal(result, expected._values)
  325: 
  326:     td2 = day + np.zeros(6, dtype=f"m8[{unit}]")
  327:     td2 = klass(td2, name="dt")
  328:     result2 = td2.value_counts()
  329:     tm.assert_series_equal(result2, expected_s)
  330: 
  331: 
  332: @pytest.mark.parametrize("dropna", [True, False])
  333: def test_value_counts_with_nan(dropna, index_or_series):
  334:     # GH31944
  335:     klass = index_or_series
  336:     values = [True, pd.NA, np.nan]
  337:     obj = klass(values)
  338:     res = obj.value_counts(dropna=dropna)
  339:     if dropna is True:
  340:         expected = Series([1], index=Index([True], dtype=obj.dtype), name="count")
  341:     else:
  342:         expected = Series([1, 1, 1], index=[True, pd.NA, np.nan], name="count")
  343:     tm.assert_series_equal(res, expected)
  344: 
  345: 
  346: def test_value_counts_object_inference_deprecated():
  347:     # GH#56161
  348:     dti = pd.date_range("2016-01-01", periods=3, tz="UTC")
  349: 
  350:     idx = dti.astype(object)
  351:     msg = "The behavior of value_counts with object-dtype is deprecated"
  352:     with tm.assert_produces_warning(FutureWarning, match=msg):
  353:         res = idx.value_counts()
  354: 
  355:     exp = dti.value_counts()
  356:     tm.assert_series_equal(res, exp)
