    1: from datetime import datetime
    2: from operator import methodcaller
    3: 
    4: import numpy as np
    5: import pytest
    6: 
    7: import pandas as pd
    8: from pandas import (
    9:     DataFrame,
   10:     Index,
   11:     Series,
   12:     Timestamp,
   13: )
   14: import pandas._testing as tm
   15: from pandas.core.groupby.grouper import Grouper
   16: from pandas.core.indexes.datetimes import date_range
   17: 
   18: 
   19: @pytest.fixture
   20: def test_series():
   21:     return Series(
   22:         np.random.default_rng(2).standard_normal(1000),
   23:         index=date_range("1/1/2000", periods=1000),
   24:     )
   25: 
   26: 
   27: def test_apply(test_series):
   28:     grouper = Grouper(freq="YE", label="right", closed="right")
   29: 
   30:     grouped = test_series.groupby(grouper)
   31: 
   32:     def f(x):
   33:         return x.sort_values()[-3:]
   34: 
   35:     applied = grouped.apply(f)
   36:     expected = test_series.groupby(lambda x: x.year).apply(f)
   37: 
   38:     applied.index = applied.index.droplevel(0)
   39:     expected.index = expected.index.droplevel(0)
   40:     tm.assert_series_equal(applied, expected)
   41: 
   42: 
   43: def test_count(test_series):
   44:     test_series[::3] = np.nan
   45: 
   46:     expected = test_series.groupby(lambda x: x.year).count()
   47: 
   48:     grouper = Grouper(freq="YE", label="right", closed="right")
   49:     result = test_series.groupby(grouper).count()
   50:     expected.index = result.index
   51:     tm.assert_series_equal(result, expected)
   52: 
   53:     result = test_series.resample("YE").count()
   54:     expected.index = result.index
   55:     tm.assert_series_equal(result, expected)
   56: 
   57: 
   58: def test_numpy_reduction(test_series):
   59:     result = test_series.resample("YE", closed="right").prod()
   60: 
   61:     msg = "using SeriesGroupBy.prod"
   62:     with tm.assert_produces_warning(FutureWarning, match=msg):
   63:         expected = test_series.groupby(lambda x: x.year).agg(np.prod)
   64:     expected.index = result.index
   65: 
   66:     tm.assert_series_equal(result, expected)
   67: 
   68: 
   69: def test_apply_iteration():
   70:     # #2300
   71:     N = 1000
   72:     ind = date_range(start="2000-01-01", freq="D", periods=N)
   73:     df = DataFrame({"open": 1, "close": 2}, index=ind)
   74:     tg = Grouper(freq="ME")
   75: 
   76:     grouper, _ = tg._get_grouper(df)
   77: 
   78:     # Errors
   79:     grouped = df.groupby(grouper, group_keys=False)
   80: 
   81:     def f(df):
   82:         return df["close"] / df["open"]
   83: 
   84:     # it works!
   85:     result = grouped.apply(f)
   86:     tm.assert_index_equal(result.index, df.index)
   87: 
   88: 
   89: @pytest.mark.parametrize(
   90:     "index",
   91:     [
   92:         Index([1, 2]),
   93:         Index(["a", "b"]),
   94:         Index([1.1, 2.2]),
   95:         pd.MultiIndex.from_arrays([[1, 2], ["a", "b"]]),
   96:     ],
   97: )
   98: def test_fails_on_no_datetime_index(index):
   99:     name = type(index).__name__
  100:     df = DataFrame({"a": range(len(index))}, index=index)
  101: 
  102:     msg = (
  103:         "Only valid with DatetimeIndex, TimedeltaIndex "
  104:         f"or PeriodIndex, but got an instance of '{name}'"
  105:     )
  106:     with pytest.raises(TypeError, match=msg):
  107:         df.groupby(Grouper(freq="D"))
  108: 
  109: 
  110: def test_aaa_group_order():
  111:     # GH 12840
  112:     # check TimeGrouper perform stable sorts
  113:     n = 20
  114:     data = np.random.default_rng(2).standard_normal((n, 4))
  115:     df = DataFrame(data, columns=["A", "B", "C", "D"])
  116:     df["key"] = [
  117:         datetime(2013, 1, 1),
  118:         datetime(2013, 1, 2),
  119:         datetime(2013, 1, 3),
  120:         datetime(2013, 1, 4),
  121:         datetime(2013, 1, 5),
  122:     ] * 4
  123:     grouped = df.groupby(Grouper(key="key", freq="D"))
  124: 
  125:     tm.assert_frame_equal(grouped.get_group(datetime(2013, 1, 1)), df[::5])
  126:     tm.assert_frame_equal(grouped.get_group(datetime(2013, 1, 2)), df[1::5])
  127:     tm.assert_frame_equal(grouped.get_group(datetime(2013, 1, 3)), df[2::5])
  128:     tm.assert_frame_equal(grouped.get_group(datetime(2013, 1, 4)), df[3::5])
  129:     tm.assert_frame_equal(grouped.get_group(datetime(2013, 1, 5)), df[4::5])
  130: 
  131: 
  132: def test_aggregate_normal(resample_method):
  133:     """Check TimeGrouper's aggregation is identical as normal groupby."""
  134: 
  135:     data = np.random.default_rng(2).standard_normal((20, 4))
  136:     normal_df = DataFrame(data, columns=["A", "B", "C", "D"])
  137:     normal_df["key"] = [1, 2, 3, 4, 5] * 4
  138: 
  139:     dt_df = DataFrame(data, columns=["A", "B", "C", "D"])
  140:     dt_df["key"] = Index(
  141:         [
  142:             datetime(2013, 1, 1),
  143:             datetime(2013, 1, 2),
  144:             datetime(2013, 1, 3),
  145:             datetime(2013, 1, 4),
  146:             datetime(2013, 1, 5),
  147:         ]
  148:         * 4,
  149:         dtype="M8[ns]",
  150:     )
  151: 
  152:     normal_grouped = normal_df.groupby("key")
  153:     dt_grouped = dt_df.groupby(Grouper(key="key", freq="D"))
  154: 
  155:     expected = getattr(normal_grouped, resample_method)()
  156:     dt_result = getattr(dt_grouped, resample_method)()
  157:     expected.index = date_range(start="2013-01-01", freq="D", periods=5, name="key")
  158:     tm.assert_equal(expected, dt_result)
  159: 
  160: 
  161: @pytest.mark.xfail(reason="if TimeGrouper is used included, 'nth' doesn't work yet")
  162: def test_aggregate_nth():
  163:     """Check TimeGrouper's aggregation is identical as normal groupby."""
  164: 
  165:     data = np.random.default_rng(2).standard_normal((20, 4))
  166:     normal_df = DataFrame(data, columns=["A", "B", "C", "D"])
  167:     normal_df["key"] = [1, 2, 3, 4, 5] * 4
  168: 
  169:     dt_df = DataFrame(data, columns=["A", "B", "C", "D"])
  170:     dt_df["key"] = [
  171:         datetime(2013, 1, 1),
  172:         datetime(2013, 1, 2),
  173:         datetime(2013, 1, 3),
  174:         datetime(2013, 1, 4),
  175:         datetime(2013, 1, 5),
  176:     ] * 4
  177: 
  178:     normal_grouped = normal_df.groupby("key")
  179:     dt_grouped = dt_df.groupby(Grouper(key="key", freq="D"))
  180: 
  181:     expected = normal_grouped.nth(3)
  182:     expected.index = date_range(start="2013-01-01", freq="D", periods=5, name="key")
  183:     dt_result = dt_grouped.nth(3)
  184:     tm.assert_frame_equal(expected, dt_result)
  185: 
  186: 
  187: @pytest.mark.parametrize(
  188:     "method, method_args, unit",
  189:     [
  190:         ("sum", {}, 0),
  191:         ("sum", {"min_count": 0}, 0),
  192:         ("sum", {"min_count": 1}, np.nan),
  193:         ("prod", {}, 1),
  194:         ("prod", {"min_count": 0}, 1),
  195:         ("prod", {"min_count": 1}, np.nan),
  196:     ],
  197: )
  198: def test_resample_entirely_nat_window(method, method_args, unit):
  199:     ser = Series([0] * 2 + [np.nan] * 2, index=date_range("2017", periods=4))
  200:     result = methodcaller(method, **method_args)(ser.resample("2d"))
  201: 
  202:     exp_dti = pd.DatetimeIndex(["2017-01-01", "2017-01-03"], dtype="M8[ns]", freq="2D")
  203:     expected = Series([0.0, unit], index=exp_dti)
  204:     tm.assert_series_equal(result, expected)
  205: 
  206: 
  207: @pytest.mark.parametrize(
  208:     "func, fill_value",
  209:     [("min", np.nan), ("max", np.nan), ("sum", 0), ("prod", 1), ("count", 0)],
  210: )
  211: def test_aggregate_with_nat(func, fill_value):
  212:     # check TimeGrouper's aggregation is identical as normal groupby
  213:     # if NaT is included, 'var', 'std', 'mean', 'first','last'
  214:     # and 'nth' doesn't work yet
  215: 
  216:     n = 20
  217:     data = np.random.default_rng(2).standard_normal((n, 4)).astype("int64")
  218:     normal_df = DataFrame(data, columns=["A", "B", "C", "D"])
  219:     normal_df["key"] = [1, 2, np.nan, 4, 5] * 4
  220: 
  221:     dt_df = DataFrame(data, columns=["A", "B", "C", "D"])
  222:     dt_df["key"] = Index(
  223:         [
  224:             datetime(2013, 1, 1),
  225:             datetime(2013, 1, 2),
  226:             pd.NaT,
  227:             datetime(2013, 1, 4),
  228:             datetime(2013, 1, 5),
  229:         ]
  230:         * 4,
  231:         dtype="M8[ns]",
  232:     )
  233: 
  234:     normal_grouped = normal_df.groupby("key")
  235:     dt_grouped = dt_df.groupby(Grouper(key="key", freq="D"))
  236: 
  237:     normal_result = getattr(normal_grouped, func)()
  238:     dt_result = getattr(dt_grouped, func)()
  239: 
  240:     pad = DataFrame([[fill_value] * 4], index=[3], columns=["A", "B", "C", "D"])
  241:     expected = pd.concat([normal_result, pad])
  242:     expected = expected.sort_index()
  243:     dti = date_range(
  244:         start="2013-01-01",
  245:         freq="D",
  246:         periods=5,
  247:         name="key",
  248:         unit=dt_df["key"]._values.unit,
  249:     )
  250:     expected.index = dti._with_freq(None)  # TODO: is this desired?
  251:     tm.assert_frame_equal(expected, dt_result)
  252:     assert dt_result.index.name == "key"
  253: 
  254: 
  255: def test_aggregate_with_nat_size():
  256:     # GH 9925
  257:     n = 20
  258:     data = np.random.default_rng(2).standard_normal((n, 4)).astype("int64")
  259:     normal_df = DataFrame(data, columns=["A", "B", "C", "D"])
  260:     normal_df["key"] = [1, 2, np.nan, 4, 5] * 4
  261: 
  262:     dt_df = DataFrame(data, columns=["A", "B", "C", "D"])
  263:     dt_df["key"] = Index(
  264:         [
  265:             datetime(2013, 1, 1),
  266:             datetime(2013, 1, 2),
  267:             pd.NaT,
  268:             datetime(2013, 1, 4),
  269:             datetime(2013, 1, 5),
  270:         ]
  271:         * 4,
  272:         dtype="M8[ns]",
  273:     )
  274: 
  275:     normal_grouped = normal_df.groupby("key")
  276:     dt_grouped = dt_df.groupby(Grouper(key="key", freq="D"))
  277: 
  278:     normal_result = normal_grouped.size()
  279:     dt_result = dt_grouped.size()
  280: 
  281:     pad = Series([0], index=[3])
  282:     expected = pd.concat([normal_result, pad])
  283:     expected = expected.sort_index()
  284:     expected.index = date_range(
  285:         start="2013-01-01",
  286:         freq="D",
  287:         periods=5,
  288:         name="key",
  289:         unit=dt_df["key"]._values.unit,
  290:     )._with_freq(None)
  291:     tm.assert_series_equal(expected, dt_result)
  292:     assert dt_result.index.name == "key"
  293: 
  294: 
  295: def test_repr():
  296:     # GH18203
  297:     result = repr(Grouper(key="A", freq="h"))
  298:     expected = (
  299:         "TimeGrouper(key='A', freq=<Hour>, axis=0, sort=True, dropna=True, "
  300:         "closed='left', label='left', how='mean', "
  301:         "convention='e', origin='start_day')"
  302:     )
  303:     assert result == expected
  304: 
  305:     result = repr(Grouper(key="A", freq="h", origin="2000-01-01"))
  306:     expected = (
  307:         "TimeGrouper(key='A', freq=<Hour>, axis=0, sort=True, dropna=True, "
  308:         "closed='left', label='left', how='mean', "
  309:         "convention='e', origin=Timestamp('2000-01-01 00:00:00'))"
  310:     )
  311:     assert result == expected
  312: 
  313: 
  314: @pytest.mark.parametrize(
  315:     "method, method_args, expected_values",
  316:     [
  317:         ("sum", {}, [1, 0, 1]),
  318:         ("sum", {"min_count": 0}, [1, 0, 1]),
  319:         ("sum", {"min_count": 1}, [1, np.nan, 1]),
  320:         ("sum", {"min_count": 2}, [np.nan, np.nan, np.nan]),
  321:         ("prod", {}, [1, 1, 1]),
  322:         ("prod", {"min_count": 0}, [1, 1, 1]),
  323:         ("prod", {"min_count": 1}, [1, np.nan, 1]),
  324:         ("prod", {"min_count": 2}, [np.nan, np.nan, np.nan]),
  325:     ],
  326: )
  327: def test_upsample_sum(method, method_args, expected_values):
  328:     ser = Series(1, index=date_range("2017", periods=2, freq="h"))
  329:     resampled = ser.resample("30min")
  330:     index = pd.DatetimeIndex(
  331:         ["2017-01-01T00:00:00", "2017-01-01T00:30:00", "2017-01-01T01:00:00"],
  332:         dtype="M8[ns]",
  333:         freq="30min",
  334:     )
  335:     result = methodcaller(method, **method_args)(resampled)
  336:     expected = Series(expected_values, index=index)
  337:     tm.assert_series_equal(result, expected)
  338: 
  339: 
  340: def test_groupby_resample_interpolate():
  341:     # GH 35325
  342:     d = {"price": [10, 11, 9], "volume": [50, 60, 50]}
  343: 
  344:     df = DataFrame(d)
  345: 
  346:     df["week_starting"] = date_range("01/01/2018", periods=3, freq="W")
  347: 
  348:     msg = "DataFrameGroupBy.resample operated on the grouping columns"
  349:     with tm.assert_produces_warning(DeprecationWarning, match=msg):
  350:         result = (
  351:             df.set_index("week_starting")
  352:             .groupby("volume")
  353:             .resample("1D")
  354:             .interpolate(method="linear")
  355:         )
  356: 
  357:     volume = [50] * 15 + [60]
  358:     week_starting = list(date_range("2018-01-07", "2018-01-21")) + [
  359:         Timestamp("2018-01-14")
  360:     ]
  361:     expected_ind = pd.MultiIndex.from_arrays(
  362:         [volume, week_starting],
  363:         names=["volume", "week_starting"],
  364:     )
  365: 
  366:     expected = DataFrame(
  367:         data={
  368:             "price": [
  369:                 10.0,
  370:                 9.928571428571429,
  371:                 9.857142857142858,
  372:                 9.785714285714286,
  373:                 9.714285714285714,
  374:                 9.642857142857142,
  375:                 9.571428571428571,
  376:                 9.5,
  377:                 9.428571428571429,
  378:                 9.357142857142858,
  379:                 9.285714285714286,
  380:                 9.214285714285714,
  381:                 9.142857142857142,
  382:                 9.071428571428571,
  383:                 9.0,
  384:                 11.0,
  385:             ],
  386:             "volume": [50.0] * 15 + [60],
  387:         },
  388:         index=expected_ind,
  389:     )
  390:     tm.assert_frame_equal(result, expected)
