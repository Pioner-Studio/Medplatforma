    1: from textwrap import dedent
    2: 
    3: import numpy as np
    4: import pytest
    5: 
    6: from pandas.compat import is_platform_windows
    7: 
    8: import pandas as pd
    9: from pandas import (
   10:     DataFrame,
   11:     Index,
   12:     Series,
   13:     TimedeltaIndex,
   14:     Timestamp,
   15: )
   16: import pandas._testing as tm
   17: from pandas.core.indexes.datetimes import date_range
   18: 
   19: 
   20: @pytest.fixture
   21: def test_frame():
   22:     return DataFrame(
   23:         {"A": [1] * 20 + [2] * 12 + [3] * 8, "B": np.arange(40)},
   24:         index=date_range("1/1/2000", freq="s", periods=40),
   25:     )
   26: 
   27: 
   28: def test_tab_complete_ipython6_warning(ip):
   29:     from IPython.core.completer import provisionalcompleter
   30: 
   31:     code = dedent(
   32:         """\
   33:     import numpy as np
   34:     from pandas import Series, date_range
   35:     data = np.arange(10, dtype=np.float64)
   36:     index = date_range("2020-01-01", periods=len(data))
   37:     s = Series(data, index=index)
   38:     rs = s.resample("D")
   39:     """
   40:     )
   41:     ip.run_cell(code)
   42: 
   43:     # GH 31324 newer jedi version raises Deprecation warning;
   44:     #  appears resolved 2021-02-02
   45:     with tm.assert_produces_warning(None, raise_on_extra_warnings=False):
   46:         with provisionalcompleter("ignore"):
   47:             list(ip.Completer.completions("rs.", 1))
   48: 
   49: 
   50: def test_deferred_with_groupby():
   51:     # GH 12486
   52:     # support deferred resample ops with groupby
   53:     data = [
   54:         ["2010-01-01", "A", 2],
   55:         ["2010-01-02", "A", 3],
   56:         ["2010-01-05", "A", 8],
   57:         ["2010-01-10", "A", 7],
   58:         ["2010-01-13", "A", 3],
   59:         ["2010-01-01", "B", 5],
   60:         ["2010-01-03", "B", 2],
   61:         ["2010-01-04", "B", 1],
   62:         ["2010-01-11", "B", 7],
   63:         ["2010-01-14", "B", 3],
   64:     ]
   65: 
   66:     df = DataFrame(data, columns=["date", "id", "score"])
   67:     df.date = pd.to_datetime(df.date)
   68: 
   69:     def f_0(x):
   70:         return x.set_index("date").resample("D").asfreq()
   71: 
   72:     msg = "DataFrameGroupBy.apply operated on the grouping columns"
   73:     with tm.assert_produces_warning(DeprecationWarning, match=msg):
   74:         expected = df.groupby("id").apply(f_0)
   75:     msg = "DataFrameGroupBy.resample operated on the grouping columns"
   76:     with tm.assert_produces_warning(DeprecationWarning, match=msg):
   77:         result = df.set_index("date").groupby("id").resample("D").asfreq()
   78:     tm.assert_frame_equal(result, expected)
   79: 
   80:     df = DataFrame(
   81:         {
   82:             "date": date_range(start="2016-01-01", periods=4, freq="W"),
   83:             "group": [1, 1, 2, 2],
   84:             "val": [5, 6, 7, 8],
   85:         }
   86:     ).set_index("date")
   87: 
   88:     def f_1(x):
   89:         return x.resample("1D").ffill()
   90: 
   91:     msg = "DataFrameGroupBy.apply operated on the grouping columns"
   92:     with tm.assert_produces_warning(DeprecationWarning, match=msg):
   93:         expected = df.groupby("group").apply(f_1)
   94:     msg = "DataFrameGroupBy.resample operated on the grouping columns"
   95:     with tm.assert_produces_warning(DeprecationWarning, match=msg):
   96:         result = df.groupby("group").resample("1D").ffill()
   97:     tm.assert_frame_equal(result, expected)
   98: 
   99: 
  100: def test_getitem(test_frame):
  101:     g = test_frame.groupby("A")
  102: 
  103:     expected = g.B.apply(lambda x: x.resample("2s").mean())
  104: 
  105:     result = g.resample("2s").B.mean()
  106:     tm.assert_series_equal(result, expected)
  107: 
  108:     result = g.B.resample("2s").mean()
  109:     tm.assert_series_equal(result, expected)
  110: 
  111:     msg = "DataFrameGroupBy.resample operated on the grouping columns"
  112:     with tm.assert_produces_warning(DeprecationWarning, match=msg):
  113:         result = g.resample("2s").mean().B
  114:     tm.assert_series_equal(result, expected)
  115: 
  116: 
  117: def test_getitem_multiple():
  118:     # GH 13174
  119:     # multiple calls after selection causing an issue with aliasing
  120:     data = [{"id": 1, "buyer": "A"}, {"id": 2, "buyer": "B"}]
  121:     df = DataFrame(data, index=date_range("2016-01-01", periods=2))
  122:     r = df.groupby("id").resample("1D")
  123:     result = r["buyer"].count()
  124: 
  125:     exp_mi = pd.MultiIndex.from_arrays([[1, 2], df.index], names=("id", None))
  126:     expected = Series(
  127:         [1, 1],
  128:         index=exp_mi,
  129:         name="buyer",
  130:     )
  131:     tm.assert_series_equal(result, expected)
  132: 
  133:     result = r["buyer"].count()
  134:     tm.assert_series_equal(result, expected)
  135: 
  136: 
  137: def test_groupby_resample_on_api_with_getitem():
  138:     # GH 17813
  139:     df = DataFrame(
  140:         {"id": list("aabbb"), "date": date_range("1-1-2016", periods=5), "data": 1}
  141:     )
  142:     exp = df.set_index("date").groupby("id").resample("2D")["data"].sum()
  143:     result = df.groupby("id").resample("2D", on="date")["data"].sum()
  144:     tm.assert_series_equal(result, exp)
  145: 
  146: 
  147: def test_groupby_with_origin():
  148:     # GH 31809
  149: 
  150:     freq = "1399min"  # prime number that is smaller than 24h
  151:     start, end = "1/1/2000 00:00:00", "1/31/2000 00:00"
  152:     middle = "1/15/2000 00:00:00"
  153: 
  154:     rng = date_range(start, end, freq="1231min")  # prime number
  155:     ts = Series(np.random.default_rng(2).standard_normal(len(rng)), index=rng)
  156:     ts2 = ts[middle:end]
  157: 
  158:     # proves that grouper without a fixed origin does not work
  159:     # when dealing with unusual frequencies
  160:     simple_grouper = pd.Grouper(freq=freq)
  161:     count_ts = ts.groupby(simple_grouper).agg("count")
  162:     count_ts = count_ts[middle:end]
  163:     count_ts2 = ts2.groupby(simple_grouper).agg("count")
  164:     with pytest.raises(AssertionError, match="Index are different"):
  165:         tm.assert_index_equal(count_ts.index, count_ts2.index)
  166: 
  167:     # test origin on 1970-01-01 00:00:00
  168:     origin = Timestamp(0)
  169:     adjusted_grouper = pd.Grouper(freq=freq, origin=origin)
  170:     adjusted_count_ts = ts.groupby(adjusted_grouper).agg("count")
  171:     adjusted_count_ts = adjusted_count_ts[middle:end]
  172:     adjusted_count_ts2 = ts2.groupby(adjusted_grouper).agg("count")
  173:     tm.assert_series_equal(adjusted_count_ts, adjusted_count_ts2)
  174: 
  175:     # test origin on 2049-10-18 20:00:00
  176:     origin_future = Timestamp(0) + pd.Timedelta("1399min") * 30_000
  177:     adjusted_grouper2 = pd.Grouper(freq=freq, origin=origin_future)
  178:     adjusted2_count_ts = ts.groupby(adjusted_grouper2).agg("count")
  179:     adjusted2_count_ts = adjusted2_count_ts[middle:end]
  180:     adjusted2_count_ts2 = ts2.groupby(adjusted_grouper2).agg("count")
  181:     tm.assert_series_equal(adjusted2_count_ts, adjusted2_count_ts2)
  182: 
  183:     # both grouper use an adjusted timestamp that is a multiple of 1399 min
  184:     # they should be equals even if the adjusted_timestamp is in the future
  185:     tm.assert_series_equal(adjusted_count_ts, adjusted2_count_ts2)
  186: 
  187: 
  188: def test_nearest():
  189:     # GH 17496
  190:     # Resample nearest
  191:     index = date_range("1/1/2000", periods=3, freq="min")
  192:     result = Series(range(3), index=index).resample("20s").nearest()
  193: 
  194:     expected = Series(
  195:         [0, 0, 1, 1, 1, 2, 2],
  196:         index=pd.DatetimeIndex(
  197:             [
  198:                 "2000-01-01 00:00:00",
  199:                 "2000-01-01 00:00:20",
  200:                 "2000-01-01 00:00:40",
  201:                 "2000-01-01 00:01:00",
  202:                 "2000-01-01 00:01:20",
  203:                 "2000-01-01 00:01:40",
  204:                 "2000-01-01 00:02:00",
  205:             ],
  206:             dtype="datetime64[ns]",
  207:             freq="20s",
  208:         ),
  209:     )
  210:     tm.assert_series_equal(result, expected)
  211: 
  212: 
  213: @pytest.mark.parametrize(
  214:     "f",
  215:     [
  216:         "first",
  217:         "last",
  218:         "median",
  219:         "sem",
  220:         "sum",
  221:         "mean",
  222:         "min",
  223:         "max",
  224:         "size",
  225:         "count",
  226:         "nearest",
  227:         "bfill",
  228:         "ffill",
  229:         "asfreq",
  230:         "ohlc",
  231:     ],
  232: )
  233: def test_methods(f, test_frame):
  234:     g = test_frame.groupby("A")
  235:     r = g.resample("2s")
  236: 
  237:     msg = "DataFrameGroupBy.resample operated on the grouping columns"
  238:     with tm.assert_produces_warning(DeprecationWarning, match=msg):
  239:         result = getattr(r, f)()
  240:     msg = "DataFrameGroupBy.apply operated on the grouping columns"
  241:     with tm.assert_produces_warning(DeprecationWarning, match=msg):
  242:         expected = g.apply(lambda x: getattr(x.resample("2s"), f)())
  243:     tm.assert_equal(result, expected)
  244: 
  245: 
  246: def test_methods_nunique(test_frame):
  247:     # series only
  248:     g = test_frame.groupby("A")
  249:     r = g.resample("2s")
  250:     result = r.B.nunique()
  251:     expected = g.B.apply(lambda x: x.resample("2s").nunique())
  252:     tm.assert_series_equal(result, expected)
  253: 
  254: 
  255: @pytest.mark.parametrize("f", ["std", "var"])
  256: def test_methods_std_var(f, test_frame):
  257:     g = test_frame.groupby("A")
  258:     r = g.resample("2s")
  259:     msg = "DataFrameGroupBy.resample operated on the grouping columns"
  260:     with tm.assert_produces_warning(DeprecationWarning, match=msg):
  261:         result = getattr(r, f)(ddof=1)
  262:     msg = "DataFrameGroupBy.apply operated on the grouping columns"
  263:     with tm.assert_produces_warning(DeprecationWarning, match=msg):
  264:         expected = g.apply(lambda x: getattr(x.resample("2s"), f)(ddof=1))
  265:     tm.assert_frame_equal(result, expected)
  266: 
  267: 
  268: def test_apply(test_frame):
  269:     g = test_frame.groupby("A")
  270:     r = g.resample("2s")
  271: 
  272:     # reduction
  273:     msg = "DataFrameGroupBy.resample operated on the grouping columns"
  274:     with tm.assert_produces_warning(DeprecationWarning, match=msg):
  275:         expected = g.resample("2s").sum()
  276: 
  277:     def f_0(x):
  278:         return x.resample("2s").sum()
  279: 
  280:     msg = "DataFrameGroupBy.resample operated on the grouping columns"
  281:     with tm.assert_produces_warning(DeprecationWarning, match=msg):
  282:         result = r.apply(f_0)
  283:     tm.assert_frame_equal(result, expected)
  284: 
  285:     def f_1(x):
  286:         return x.resample("2s").apply(lambda y: y.sum())
  287: 
  288:     msg = "DataFrameGroupBy.apply operated on the grouping columns"
  289:     with tm.assert_produces_warning(DeprecationWarning, match=msg):
  290:         result = g.apply(f_1)
  291:     # y.sum() results in int64 instead of int32 on 32-bit architectures
  292:     expected = expected.astype("int64")
  293:     tm.assert_frame_equal(result, expected)
  294: 
  295: 
  296: def test_apply_with_mutated_index():
  297:     # GH 15169
  298:     index = date_range("1-1-2015", "12-31-15", freq="D")
  299:     df = DataFrame(
  300:         data={"col1": np.random.default_rng(2).random(len(index))}, index=index
  301:     )
  302: 
  303:     def f(x):
  304:         s = Series([1, 2], index=["a", "b"])
  305:         return s
  306: 
  307:     expected = df.groupby(pd.Grouper(freq="ME")).apply(f)
  308: 
  309:     result = df.resample("ME").apply(f)
  310:     tm.assert_frame_equal(result, expected)
  311: 
  312:     # A case for series
  313:     expected = df["col1"].groupby(pd.Grouper(freq="ME"), group_keys=False).apply(f)
  314:     result = df["col1"].resample("ME").apply(f)
  315:     tm.assert_series_equal(result, expected)
  316: 
  317: 
  318: def test_apply_columns_multilevel():
  319:     # GH 16231
  320:     cols = pd.MultiIndex.from_tuples([("A", "a", "", "one"), ("B", "b", "i", "two")])
  321:     ind = date_range(start="2017-01-01", freq="15Min", periods=8)
  322:     df = DataFrame(np.array([0] * 16).reshape(8, 2), index=ind, columns=cols)
  323:     agg_dict = {col: (np.sum if col[3] == "one" else np.mean) for col in df.columns}
  324:     result = df.resample("h").apply(lambda x: agg_dict[x.name](x))
  325:     expected = DataFrame(
  326:         2 * [[0, 0.0]],
  327:         index=date_range(start="2017-01-01", freq="1h", periods=2),
  328:         columns=pd.MultiIndex.from_tuples(
  329:             [("A", "a", "", "one"), ("B", "b", "i", "two")]
  330:         ),
  331:     )
  332:     tm.assert_frame_equal(result, expected)
  333: 
  334: 
  335: def test_apply_non_naive_index():
  336:     def weighted_quantile(series, weights, q):
  337:         series = series.sort_values()
  338:         cumsum = weights.reindex(series.index).fillna(0).cumsum()
  339:         cutoff = cumsum.iloc[-1] * q
  340:         return series[cumsum >= cutoff].iloc[0]
  341: 
  342:     times = date_range("2017-6-23 18:00", periods=8, freq="15min", tz="UTC")
  343:     data = Series([1.0, 1, 1, 1, 1, 2, 2, 0], index=times)
  344:     weights = Series([160.0, 91, 65, 43, 24, 10, 1, 0], index=times)
  345: 
  346:     result = data.resample("D").apply(weighted_quantile, weights=weights, q=0.5)
  347:     ind = date_range(
  348:         "2017-06-23 00:00:00+00:00", "2017-06-23 00:00:00+00:00", freq="D", tz="UTC"
  349:     )
  350:     expected = Series([1.0], index=ind)
  351:     tm.assert_series_equal(result, expected)
  352: 
  353: 
  354: def test_resample_groupby_with_label(unit):
  355:     # GH 13235
  356:     index = date_range("2000-01-01", freq="2D", periods=5, unit=unit)
  357:     df = DataFrame(index=index, data={"col0": [0, 0, 1, 1, 2], "col1": [1, 1, 1, 1, 1]})
  358:     msg = "DataFrameGroupBy.resample operated on the grouping columns"
  359:     with tm.assert_produces_warning(DeprecationWarning, match=msg):
  360:         result = df.groupby("col0").resample("1W", label="left").sum()
  361: 
  362:     mi = [
  363:         np.array([0, 0, 1, 2], dtype=np.int64),
  364:         np.array(
  365:             ["1999-12-26", "2000-01-02", "2000-01-02", "2000-01-02"],
  366:             dtype=f"M8[{unit}]",
  367:         ),
  368:     ]
  369:     mindex = pd.MultiIndex.from_arrays(mi, names=["col0", None])
  370:     expected = DataFrame(
  371:         data={"col0": [0, 0, 2, 2], "col1": [1, 1, 2, 1]}, index=mindex
  372:     )
  373: 
  374:     tm.assert_frame_equal(result, expected)
  375: 
  376: 
  377: def test_consistency_with_window(test_frame):
  378:     # consistent return values with window
  379:     df = test_frame
  380:     expected = Index([1, 2, 3], name="A")
  381:     msg = "DataFrameGroupBy.resample operated on the grouping columns"
  382:     with tm.assert_produces_warning(DeprecationWarning, match=msg):
  383:         result = df.groupby("A").resample("2s").mean()
  384:     assert result.index.nlevels == 2
  385:     tm.assert_index_equal(result.index.levels[0], expected)
  386: 
  387:     result = df.groupby("A").rolling(20).mean()
  388:     assert result.index.nlevels == 2
  389:     tm.assert_index_equal(result.index.levels[0], expected)
  390: 
  391: 
  392: def test_median_duplicate_columns():
  393:     # GH 14233
  394: 
  395:     df = DataFrame(
  396:         np.random.default_rng(2).standard_normal((20, 3)),
  397:         columns=list("aaa"),
  398:         index=date_range("2012-01-01", periods=20, freq="s"),
  399:     )
  400:     df2 = df.copy()
  401:     df2.columns = ["a", "b", "c"]
  402:     expected = df2.resample("5s").median()
  403:     result = df.resample("5s").median()
  404:     expected.columns = result.columns
  405:     tm.assert_frame_equal(result, expected)
  406: 
  407: 
  408: def test_apply_to_one_column_of_df():
  409:     # GH: 36951
  410:     df = DataFrame(
  411:         {"col": range(10), "col1": range(10, 20)},
  412:         index=date_range("2012-01-01", periods=10, freq="20min"),
  413:     )
  414: 
  415:     # access "col" via getattr -> make sure we handle AttributeError
  416:     result = df.resample("h").apply(lambda group: group.col.sum())
  417:     expected = Series(
  418:         [3, 12, 21, 9], index=date_range("2012-01-01", periods=4, freq="h")
  419:     )
  420:     tm.assert_series_equal(result, expected)
  421: 
  422:     # access "col" via _getitem__ -> make sure we handle KeyErrpr
  423:     result = df.resample("h").apply(lambda group: group["col"].sum())
  424:     tm.assert_series_equal(result, expected)
  425: 
  426: 
  427: def test_resample_groupby_agg():
  428:     # GH: 33548
  429:     df = DataFrame(
  430:         {
  431:             "cat": [
  432:                 "cat_1",
  433:                 "cat_1",
  434:                 "cat_2",
  435:                 "cat_1",
  436:                 "cat_2",
  437:                 "cat_1",
  438:                 "cat_2",
  439:                 "cat_1",
  440:             ],
  441:             "num": [5, 20, 22, 3, 4, 30, 10, 50],
  442:             "date": [
  443:                 "2019-2-1",
  444:                 "2018-02-03",
  445:                 "2020-3-11",
  446:                 "2019-2-2",
  447:                 "2019-2-2",
  448:                 "2018-12-4",
  449:                 "2020-3-11",
  450:                 "2020-12-12",
  451:             ],
  452:         }
  453:     )
  454:     df["date"] = pd.to_datetime(df["date"])
  455: 
  456:     resampled = df.groupby("cat").resample("YE", on="date")
  457:     expected = resampled[["num"]].sum()
  458:     result = resampled.agg({"num": "sum"})
  459: 
  460:     tm.assert_frame_equal(result, expected)
  461: 
  462: 
  463: def test_resample_groupby_agg_listlike():
  464:     # GH 42905
  465:     ts = Timestamp("2021-02-28 00:00:00")
  466:     df = DataFrame({"class": ["beta"], "value": [69]}, index=Index([ts], name="date"))
  467:     resampled = df.groupby("class").resample("ME")["value"]
  468:     result = resampled.agg(["sum", "size"])
  469:     expected = DataFrame(
  470:         [[69, 1]],
  471:         index=pd.MultiIndex.from_tuples([("beta", ts)], names=["class", "date"]),
  472:         columns=["sum", "size"],
  473:     )
  474:     tm.assert_frame_equal(result, expected)
  475: 
  476: 
  477: @pytest.mark.parametrize("keys", [["a"], ["a", "b"]])
  478: def test_empty(keys):
  479:     # GH 26411
  480:     df = DataFrame([], columns=["a", "b"], index=TimedeltaIndex([]))
  481:     msg = "DataFrameGroupBy.resample operated on the grouping columns"
  482:     with tm.assert_produces_warning(DeprecationWarning, match=msg):
  483:         result = df.groupby(keys).resample(rule=pd.to_timedelta("00:00:01")).mean()
  484:     expected = (
  485:         DataFrame(columns=["a", "b"])
  486:         .set_index(keys, drop=False)
  487:         .set_index(TimedeltaIndex([]), append=True)
  488:     )
  489:     if len(keys) == 1:
  490:         expected.index.name = keys[0]
  491: 
  492:     tm.assert_frame_equal(result, expected)
  493: 
  494: 
  495: @pytest.mark.parametrize("consolidate", [True, False])
  496: def test_resample_groupby_agg_object_dtype_all_nan(consolidate):
  497:     # https://github.com/pandas-dev/pandas/issues/39329
  498: 
  499:     dates = date_range("2020-01-01", periods=15, freq="D")
  500:     df1 = DataFrame({"key": "A", "date": dates, "col1": range(15), "col_object": "val"})
  501:     df2 = DataFrame({"key": "B", "date": dates, "col1": range(15)})
  502:     df = pd.concat([df1, df2], ignore_index=True)
  503:     if consolidate:
  504:         df = df._consolidate()
  505: 
  506:     msg = "DataFrameGroupBy.resample operated on the grouping columns"
  507:     with tm.assert_produces_warning(DeprecationWarning, match=msg):
  508:         result = df.groupby(["key"]).resample("W", on="date").min()
  509:     idx = pd.MultiIndex.from_arrays(
  510:         [
  511:             ["A"] * 3 + ["B"] * 3,
  512:             pd.to_datetime(["2020-01-05", "2020-01-12", "2020-01-19"] * 2).as_unit(
  513:                 "ns"
  514:             ),
  515:         ],
  516:         names=["key", "date"],
  517:     )
  518:     expected = DataFrame(
  519:         {
  520:             "key": ["A"] * 3 + ["B"] * 3,
  521:             "col1": [0, 5, 12] * 2,
  522:             "col_object": ["val"] * 3 + [np.nan] * 3,
  523:         },
  524:         index=idx,
  525:     )
  526:     tm.assert_frame_equal(result, expected)
  527: 
  528: 
  529: def test_groupby_resample_with_list_of_keys():
  530:     # GH 47362
  531:     df = DataFrame(
  532:         data={
  533:             "date": date_range(start="2016-01-01", periods=8),
  534:             "group": [0, 0, 0, 0, 1, 1, 1, 1],
  535:             "val": [1, 7, 5, 2, 3, 10, 5, 1],
  536:         }
  537:     )
  538:     result = df.groupby("group").resample("2D", on="date")[["val"]].mean()
  539: 
  540:     mi_exp = pd.MultiIndex.from_arrays(
  541:         [[0, 0, 1, 1], df["date"]._values[::2]], names=["group", "date"]
  542:     )
  543:     expected = DataFrame(
  544:         data={
  545:             "val": [4.0, 3.5, 6.5, 3.0],
  546:         },
  547:         index=mi_exp,
  548:     )
  549:     tm.assert_frame_equal(result, expected)
  550: 
  551: 
  552: @pytest.mark.parametrize("keys", [["a"], ["a", "b"]])
  553: def test_resample_no_index(keys):
  554:     # GH 47705
  555:     df = DataFrame([], columns=["a", "b", "date"])
  556:     df["date"] = pd.to_datetime(df["date"])
  557:     df = df.set_index("date")
  558:     msg = "DataFrameGroupBy.resample operated on the grouping columns"
  559:     with tm.assert_produces_warning(DeprecationWarning, match=msg):
  560:         result = df.groupby(keys).resample(rule=pd.to_timedelta("00:00:01")).mean()
  561:     expected = DataFrame(columns=["a", "b", "date"]).set_index(keys, drop=False)
  562:     expected["date"] = pd.to_datetime(expected["date"])
  563:     expected = expected.set_index("date", append=True, drop=True)
  564:     if len(keys) == 1:
  565:         expected.index.name = keys[0]
  566: 
  567:     tm.assert_frame_equal(result, expected)
  568: 
  569: 
  570: def test_resample_no_columns():
  571:     # GH#52484
  572:     df = DataFrame(
  573:         index=Index(
  574:             pd.to_datetime(
  575:                 ["2018-01-01 00:00:00", "2018-01-01 12:00:00", "2018-01-02 00:00:00"]
  576:             ),
  577:             name="date",
  578:         )
  579:     )
  580:     result = df.groupby([0, 0, 1]).resample(rule=pd.to_timedelta("06:00:00")).mean()
  581:     index = pd.to_datetime(
  582:         [
  583:             "2018-01-01 00:00:00",
  584:             "2018-01-01 06:00:00",
  585:             "2018-01-01 12:00:00",
  586:             "2018-01-02 00:00:00",
  587:         ]
  588:     )
  589:     expected = DataFrame(
  590:         index=pd.MultiIndex(
  591:             levels=[np.array([0, 1], dtype=np.intp), index],
  592:             codes=[[0, 0, 0, 1], [0, 1, 2, 3]],
  593:             names=[None, "date"],
  594:         )
  595:     )
  596: 
  597:     # GH#52710 - Index comes out as 32-bit on 64-bit Windows
  598:     tm.assert_frame_equal(result, expected, check_index_type=not is_platform_windows())
  599: 
  600: 
  601: def test_groupby_resample_size_all_index_same():
  602:     # GH 46826
  603:     df = DataFrame(
  604:         {"A": [1] * 3 + [2] * 3 + [1] * 3 + [2] * 3, "B": np.arange(12)},
  605:         index=date_range("31/12/2000 18:00", freq="h", periods=12),
  606:     )
  607:     msg = "DataFrameGroupBy.resample operated on the grouping columns"
  608:     with tm.assert_produces_warning(DeprecationWarning, match=msg):
  609:         result = df.groupby("A").resample("D").size()
  610: 
  611:     mi_exp = pd.MultiIndex.from_arrays(
  612:         [
  613:             [1, 1, 2, 2],
  614:             pd.DatetimeIndex(["2000-12-31", "2001-01-01"] * 2, dtype="M8[ns]"),
  615:         ],
  616:         names=["A", None],
  617:     )
  618:     expected = Series(
  619:         3,
  620:         index=mi_exp,
  621:     )
  622:     tm.assert_series_equal(result, expected)
  623: 
  624: 
  625: def test_groupby_resample_on_index_with_list_of_keys():
  626:     # GH 50840
  627:     df = DataFrame(
  628:         data={
  629:             "group": [0, 0, 0, 0, 1, 1, 1, 1],
  630:             "val": [3, 1, 4, 1, 5, 9, 2, 6],
  631:         },
  632:         index=date_range(start="2016-01-01", periods=8, name="date"),
  633:     )
  634:     result = df.groupby("group").resample("2D")[["val"]].mean()
  635: 
  636:     mi_exp = pd.MultiIndex.from_arrays(
  637:         [[0, 0, 1, 1], df.index[::2]], names=["group", "date"]
  638:     )
  639:     expected = DataFrame(
  640:         data={
  641:             "val": [2.0, 2.5, 7.0, 4.0],
  642:         },
  643:         index=mi_exp,
  644:     )
  645:     tm.assert_frame_equal(result, expected)
  646: 
  647: 
  648: def test_groupby_resample_on_index_with_list_of_keys_multi_columns():
  649:     # GH 50876
  650:     df = DataFrame(
  651:         data={
  652:             "group": [0, 0, 0, 0, 1, 1, 1, 1],
  653:             "first_val": [3, 1, 4, 1, 5, 9, 2, 6],
  654:             "second_val": [2, 7, 1, 8, 2, 8, 1, 8],
  655:             "third_val": [1, 4, 1, 4, 2, 1, 3, 5],
  656:         },
  657:         index=date_range(start="2016-01-01", periods=8, name="date"),
  658:     )
  659:     result = df.groupby("group").resample("2D")[["first_val", "second_val"]].mean()
  660: 
  661:     mi_exp = pd.MultiIndex.from_arrays(
  662:         [[0, 0, 1, 1], df.index[::2]], names=["group", "date"]
  663:     )
  664:     expected = DataFrame(
  665:         data={
  666:             "first_val": [2.0, 2.5, 7.0, 4.0],
  667:             "second_val": [4.5, 4.5, 5.0, 4.5],
  668:         },
  669:         index=mi_exp,
  670:     )
  671:     tm.assert_frame_equal(result, expected)
  672: 
  673: 
  674: def test_groupby_resample_on_index_with_list_of_keys_missing_column():
  675:     # GH 50876
  676:     df = DataFrame(
  677:         data={
  678:             "group": [0, 0, 0, 0, 1, 1, 1, 1],
  679:             "val": [3, 1, 4, 1, 5, 9, 2, 6],
  680:         },
  681:         index=Series(
  682:             date_range(start="2016-01-01", periods=8),
  683:             name="date",
  684:         ),
  685:     )
  686:     gb = df.groupby("group")
  687:     rs = gb.resample("2D")
  688:     with pytest.raises(KeyError, match="Columns not found"):
  689:         rs[["val_not_in_dataframe"]]
  690: 
  691: 
  692: @pytest.mark.parametrize("kind", ["datetime", "period"])
  693: def test_groupby_resample_kind(kind):
  694:     # GH 24103
  695:     df = DataFrame(
  696:         {
  697:             "datetime": pd.to_datetime(
  698:                 ["20181101 1100", "20181101 1200", "20181102 1300", "20181102 1400"]
  699:             ),
  700:             "group": ["A", "B", "A", "B"],
  701:             "value": [1, 2, 3, 4],
  702:         }
  703:     )
  704:     df = df.set_index("datetime")
  705:     result = df.groupby("group")["value"].resample("D", kind=kind).last()
  706: 
  707:     dt_level = pd.DatetimeIndex(["2018-11-01", "2018-11-02"])
  708:     if kind == "period":
  709:         dt_level = dt_level.to_period(freq="D")
  710:     expected_index = pd.MultiIndex.from_product(
  711:         [["A", "B"], dt_level],
  712:         names=["group", "datetime"],
  713:     )
  714:     expected = Series([1, 3, 2, 4], index=expected_index, name="value")
  715:     tm.assert_series_equal(result, expected)
