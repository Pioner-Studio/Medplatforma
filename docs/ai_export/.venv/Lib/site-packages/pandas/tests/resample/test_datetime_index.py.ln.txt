    1: from datetime import datetime
    2: from functools import partial
    3: 
    4: import numpy as np
    5: import pytest
    6: import pytz
    7: 
    8: from pandas._libs import lib
    9: from pandas._typing import DatetimeNaTType
   10: from pandas.compat import is_platform_windows
   11: import pandas.util._test_decorators as td
   12: 
   13: import pandas as pd
   14: from pandas import (
   15:     DataFrame,
   16:     Index,
   17:     Series,
   18:     Timedelta,
   19:     Timestamp,
   20:     isna,
   21:     notna,
   22: )
   23: import pandas._testing as tm
   24: from pandas.core.groupby.grouper import Grouper
   25: from pandas.core.indexes.datetimes import date_range
   26: from pandas.core.indexes.period import (
   27:     Period,
   28:     period_range,
   29: )
   30: from pandas.core.resample import (
   31:     DatetimeIndex,
   32:     _get_timestamp_range_edges,
   33: )
   34: 
   35: from pandas.tseries import offsets
   36: from pandas.tseries.offsets import Minute
   37: 
   38: 
   39: @pytest.fixture()
   40: def _index_factory():
   41:     return date_range
   42: 
   43: 
   44: @pytest.fixture
   45: def _index_freq():
   46:     return "Min"
   47: 
   48: 
   49: @pytest.fixture
   50: def _static_values(index):
   51:     return np.random.default_rng(2).random(len(index))
   52: 
   53: 
   54: @pytest.fixture(params=["s", "ms", "us", "ns"])
   55: def unit(request):
   56:     return request.param
   57: 
   58: 
   59: @pytest.fixture
   60: def simple_date_range_series():
   61:     """
   62:     Series with date range index and random data for test purposes.
   63:     """
   64: 
   65:     def _simple_date_range_series(start, end, freq="D"):
   66:         rng = date_range(start, end, freq=freq)
   67:         return Series(np.random.default_rng(2).standard_normal(len(rng)), index=rng)
   68: 
   69:     return _simple_date_range_series
   70: 
   71: 
   72: def test_custom_grouper(index, unit):
   73:     dti = index.as_unit(unit)
   74:     s = Series(np.array([1] * len(dti)), index=dti, dtype="int64")
   75: 
   76:     b = Grouper(freq=Minute(5))
   77:     g = s.groupby(b)
   78: 
   79:     # check all cython functions work
   80:     g.ohlc()  # doesn't use _cython_agg_general
   81:     funcs = ["sum", "mean", "prod", "min", "max", "var"]
   82:     for f in funcs:
   83:         g._cython_agg_general(f, alt=None, numeric_only=True)
   84: 
   85:     b = Grouper(freq=Minute(5), closed="right", label="right")
   86:     g = s.groupby(b)
   87:     # check all cython functions work
   88:     g.ohlc()  # doesn't use _cython_agg_general
   89:     funcs = ["sum", "mean", "prod", "min", "max", "var"]
   90:     for f in funcs:
   91:         g._cython_agg_general(f, alt=None, numeric_only=True)
   92: 
   93:     assert g.ngroups == 2593
   94:     assert notna(g.mean()).all()
   95: 
   96:     # construct expected val
   97:     arr = [1] + [5] * 2592
   98:     idx = dti[0:-1:5]
   99:     idx = idx.append(dti[-1:])
  100:     idx = DatetimeIndex(idx, freq="5min").as_unit(unit)
  101:     expect = Series(arr, index=idx)
  102: 
  103:     # GH2763 - return input dtype if we can
  104:     result = g.agg("sum")
  105:     tm.assert_series_equal(result, expect)
  106: 
  107: 
  108: def test_custom_grouper_df(index, unit):
  109:     b = Grouper(freq=Minute(5), closed="right", label="right")
  110:     dti = index.as_unit(unit)
  111:     df = DataFrame(
  112:         np.random.default_rng(2).random((len(dti), 10)), index=dti, dtype="float64"
  113:     )
  114:     r = df.groupby(b).agg("sum")
  115: 
  116:     assert len(r.columns) == 10
  117:     assert len(r.index) == 2593
  118: 
  119: 
  120: @pytest.mark.parametrize(
  121:     "_index_start,_index_end,_index_name",
  122:     [("1/1/2000 00:00:00", "1/1/2000 00:13:00", "index")],
  123: )
  124: @pytest.mark.parametrize(
  125:     "closed, expected",
  126:     [
  127:         (
  128:             "right",
  129:             lambda s: Series(
  130:                 [s.iloc[0], s[1:6].mean(), s[6:11].mean(), s[11:].mean()],
  131:                 index=date_range("1/1/2000", periods=4, freq="5min", name="index"),
  132:             ),
  133:         ),
  134:         (
  135:             "left",
  136:             lambda s: Series(
  137:                 [s[:5].mean(), s[5:10].mean(), s[10:].mean()],
  138:                 index=date_range(
  139:                     "1/1/2000 00:05", periods=3, freq="5min", name="index"
  140:                 ),
  141:             ),
  142:         ),
  143:     ],
  144: )
  145: def test_resample_basic(series, closed, expected, unit):
  146:     s = series
  147:     s.index = s.index.as_unit(unit)
  148:     expected = expected(s)
  149:     expected.index = expected.index.as_unit(unit)
  150:     result = s.resample("5min", closed=closed, label="right").mean()
  151:     tm.assert_series_equal(result, expected)
  152: 
  153: 
  154: def test_resample_integerarray(unit):
  155:     # GH 25580, resample on IntegerArray
  156:     ts = Series(
  157:         range(9),
  158:         index=date_range("1/1/2000", periods=9, freq="min").as_unit(unit),
  159:         dtype="Int64",
  160:     )
  161:     result = ts.resample("3min").sum()
  162:     expected = Series(
  163:         [3, 12, 21],
  164:         index=date_range("1/1/2000", periods=3, freq="3min").as_unit(unit),
  165:         dtype="Int64",
  166:     )
  167:     tm.assert_series_equal(result, expected)
  168: 
  169:     result = ts.resample("3min").mean()
  170:     expected = Series(
  171:         [1, 4, 7],
  172:         index=date_range("1/1/2000", periods=3, freq="3min").as_unit(unit),
  173:         dtype="Float64",
  174:     )
  175:     tm.assert_series_equal(result, expected)
  176: 
  177: 
  178: def test_resample_basic_grouper(series, unit):
  179:     s = series
  180:     s.index = s.index.as_unit(unit)
  181:     result = s.resample("5Min").last()
  182:     grouper = Grouper(freq=Minute(5), closed="left", label="left")
  183:     expected = s.groupby(grouper).agg(lambda x: x.iloc[-1])
  184:     tm.assert_series_equal(result, expected)
  185: 
  186: 
  187: @pytest.mark.filterwarnings(
  188:     "ignore:The 'convention' keyword in Series.resample:FutureWarning"
  189: )
  190: @pytest.mark.parametrize(
  191:     "_index_start,_index_end,_index_name",
  192:     [("1/1/2000 00:00:00", "1/1/2000 00:13:00", "index")],
  193: )
  194: @pytest.mark.parametrize(
  195:     "keyword,value",
  196:     [("label", "righttt"), ("closed", "righttt"), ("convention", "starttt")],
  197: )
  198: def test_resample_string_kwargs(series, keyword, value, unit):
  199:     # see gh-19303
  200:     # Check that wrong keyword argument strings raise an error
  201:     series.index = series.index.as_unit(unit)
  202:     msg = f"Unsupported value {value} for `{keyword}`"
  203:     with pytest.raises(ValueError, match=msg):
  204:         series.resample("5min", **({keyword: value}))
  205: 
  206: 
  207: @pytest.mark.parametrize(
  208:     "_index_start,_index_end,_index_name",
  209:     [("1/1/2000 00:00:00", "1/1/2000 00:13:00", "index")],
  210: )
  211: def test_resample_how(series, downsample_method, unit):
  212:     if downsample_method == "ohlc":
  213:         pytest.skip("covered by test_resample_how_ohlc")
  214: 
  215:     s = series
  216:     s.index = s.index.as_unit(unit)
  217:     grouplist = np.ones_like(s)
  218:     grouplist[0] = 0
  219:     grouplist[1:6] = 1
  220:     grouplist[6:11] = 2
  221:     grouplist[11:] = 3
  222:     expected = s.groupby(grouplist).agg(downsample_method)
  223:     expected.index = date_range(
  224:         "1/1/2000", periods=4, freq="5min", name="index"
  225:     ).as_unit(unit)
  226: 
  227:     result = getattr(
  228:         s.resample("5min", closed="right", label="right"), downsample_method
  229:     )()
  230:     tm.assert_series_equal(result, expected)
  231: 
  232: 
  233: @pytest.mark.parametrize(
  234:     "_index_start,_index_end,_index_name",
  235:     [("1/1/2000 00:00:00", "1/1/2000 00:13:00", "index")],
  236: )
  237: def test_resample_how_ohlc(series, unit):
  238:     s = series
  239:     s.index = s.index.as_unit(unit)
  240:     grouplist = np.ones_like(s)
  241:     grouplist[0] = 0
  242:     grouplist[1:6] = 1
  243:     grouplist[6:11] = 2
  244:     grouplist[11:] = 3
  245: 
  246:     def _ohlc(group):
  247:         if isna(group).all():
  248:             return np.repeat(np.nan, 4)
  249:         return [group.iloc[0], group.max(), group.min(), group.iloc[-1]]
  250: 
  251:     expected = DataFrame(
  252:         s.groupby(grouplist).agg(_ohlc).values.tolist(),
  253:         index=date_range("1/1/2000", periods=4, freq="5min", name="index").as_unit(
  254:             unit
  255:         ),
  256:         columns=["open", "high", "low", "close"],
  257:     )
  258: 
  259:     result = s.resample("5min", closed="right", label="right").ohlc()
  260:     tm.assert_frame_equal(result, expected)
  261: 
  262: 
  263: def test_resample_how_callables(unit):
  264:     # GH#7929
  265:     data = np.arange(5, dtype=np.int64)
  266:     ind = date_range(start="2014-01-01", periods=len(data), freq="d").as_unit(unit)
  267:     df = DataFrame({"A": data, "B": data}, index=ind)
  268: 
  269:     def fn(x, a=1):
  270:         return str(type(x))
  271: 
  272:     class FnClass:
  273:         def __call__(self, x):
  274:             return str(type(x))
  275: 
  276:     df_standard = df.resample("ME").apply(fn)
  277:     df_lambda = df.resample("ME").apply(lambda x: str(type(x)))
  278:     df_partial = df.resample("ME").apply(partial(fn))
  279:     df_partial2 = df.resample("ME").apply(partial(fn, a=2))
  280:     df_class = df.resample("ME").apply(FnClass())
  281: 
  282:     tm.assert_frame_equal(df_standard, df_lambda)
  283:     tm.assert_frame_equal(df_standard, df_partial)
  284:     tm.assert_frame_equal(df_standard, df_partial2)
  285:     tm.assert_frame_equal(df_standard, df_class)
  286: 
  287: 
  288: def test_resample_rounding(unit):
  289:     # GH 8371
  290:     # odd results when rounding is needed
  291: 
  292:     ts = [
  293:         "2014-11-08 00:00:01",
  294:         "2014-11-08 00:00:02",
  295:         "2014-11-08 00:00:02",
  296:         "2014-11-08 00:00:03",
  297:         "2014-11-08 00:00:07",
  298:         "2014-11-08 00:00:07",
  299:         "2014-11-08 00:00:08",
  300:         "2014-11-08 00:00:08",
  301:         "2014-11-08 00:00:08",
  302:         "2014-11-08 00:00:09",
  303:         "2014-11-08 00:00:10",
  304:         "2014-11-08 00:00:11",
  305:         "2014-11-08 00:00:11",
  306:         "2014-11-08 00:00:13",
  307:         "2014-11-08 00:00:14",
  308:         "2014-11-08 00:00:15",
  309:         "2014-11-08 00:00:17",
  310:         "2014-11-08 00:00:20",
  311:         "2014-11-08 00:00:21",
  312:     ]
  313:     df = DataFrame({"value": [1] * 19}, index=pd.to_datetime(ts))
  314:     df.index = df.index.as_unit(unit)
  315: 
  316:     result = df.resample("6s").sum()
  317:     expected = DataFrame(
  318:         {"value": [4, 9, 4, 2]},
  319:         index=date_range("2014-11-08", freq="6s", periods=4).as_unit(unit),
  320:     )
  321:     tm.assert_frame_equal(result, expected)
  322: 
  323:     result = df.resample("7s").sum()
  324:     expected = DataFrame(
  325:         {"value": [4, 10, 4, 1]},
  326:         index=date_range("2014-11-08", freq="7s", periods=4).as_unit(unit),
  327:     )
  328:     tm.assert_frame_equal(result, expected)
  329: 
  330:     result = df.resample("11s").sum()
  331:     expected = DataFrame(
  332:         {"value": [11, 8]},
  333:         index=date_range("2014-11-08", freq="11s", periods=2).as_unit(unit),
  334:     )
  335:     tm.assert_frame_equal(result, expected)
  336: 
  337:     result = df.resample("13s").sum()
  338:     expected = DataFrame(
  339:         {"value": [13, 6]},
  340:         index=date_range("2014-11-08", freq="13s", periods=2).as_unit(unit),
  341:     )
  342:     tm.assert_frame_equal(result, expected)
  343: 
  344:     result = df.resample("17s").sum()
  345:     expected = DataFrame(
  346:         {"value": [16, 3]},
  347:         index=date_range("2014-11-08", freq="17s", periods=2).as_unit(unit),
  348:     )
  349:     tm.assert_frame_equal(result, expected)
  350: 
  351: 
  352: def test_resample_basic_from_daily(unit):
  353:     # from daily
  354:     dti = date_range(
  355:         start=datetime(2005, 1, 1), end=datetime(2005, 1, 10), freq="D", name="index"
  356:     ).as_unit(unit)
  357: 
  358:     s = Series(np.random.default_rng(2).random(len(dti)), dti)
  359: 
  360:     # to weekly
  361:     result = s.resample("w-sun").last()
  362: 
  363:     assert len(result) == 3
  364:     assert (result.index.dayofweek == [6, 6, 6]).all()
  365:     assert result.iloc[0] == s["1/2/2005"]
  366:     assert result.iloc[1] == s["1/9/2005"]
  367:     assert result.iloc[2] == s.iloc[-1]
  368: 
  369:     result = s.resample("W-MON").last()
  370:     assert len(result) == 2
  371:     assert (result.index.dayofweek == [0, 0]).all()
  372:     assert result.iloc[0] == s["1/3/2005"]
  373:     assert result.iloc[1] == s["1/10/2005"]
  374: 
  375:     result = s.resample("W-TUE").last()
  376:     assert len(result) == 2
  377:     assert (result.index.dayofweek == [1, 1]).all()
  378:     assert result.iloc[0] == s["1/4/2005"]
  379:     assert result.iloc[1] == s["1/10/2005"]
  380: 
  381:     result = s.resample("W-WED").last()
  382:     assert len(result) == 2
  383:     assert (result.index.dayofweek == [2, 2]).all()
  384:     assert result.iloc[0] == s["1/5/2005"]
  385:     assert result.iloc[1] == s["1/10/2005"]
  386: 
  387:     result = s.resample("W-THU").last()
  388:     assert len(result) == 2
  389:     assert (result.index.dayofweek == [3, 3]).all()
  390:     assert result.iloc[0] == s["1/6/2005"]
  391:     assert result.iloc[1] == s["1/10/2005"]
  392: 
  393:     result = s.resample("W-FRI").last()
  394:     assert len(result) == 2
  395:     assert (result.index.dayofweek == [4, 4]).all()
  396:     assert result.iloc[0] == s["1/7/2005"]
  397:     assert result.iloc[1] == s["1/10/2005"]
  398: 
  399:     # to biz day
  400:     result = s.resample("B").last()
  401:     assert len(result) == 7
  402:     assert (result.index.dayofweek == [4, 0, 1, 2, 3, 4, 0]).all()
  403: 
  404:     assert result.iloc[0] == s["1/2/2005"]
  405:     assert result.iloc[1] == s["1/3/2005"]
  406:     assert result.iloc[5] == s["1/9/2005"]
  407:     assert result.index.name == "index"
  408: 
  409: 
  410: def test_resample_upsampling_picked_but_not_correct(unit):
  411:     # Test for issue #3020
  412:     dates = date_range("01-Jan-2014", "05-Jan-2014", freq="D").as_unit(unit)
  413:     series = Series(1, index=dates)
  414: 
  415:     result = series.resample("D").mean()
  416:     assert result.index[0] == dates[0]
  417: 
  418:     # GH 5955
  419:     # incorrect deciding to upsample when the axis frequency matches the
  420:     # resample frequency
  421: 
  422:     s = Series(
  423:         np.arange(1.0, 6), index=[datetime(1975, 1, i, 12, 0) for i in range(1, 6)]
  424:     )
  425:     s.index = s.index.as_unit(unit)
  426:     expected = Series(
  427:         np.arange(1.0, 6),
  428:         index=date_range("19750101", periods=5, freq="D").as_unit(unit),
  429:     )
  430: 
  431:     result = s.resample("D").count()
  432:     tm.assert_series_equal(result, Series(1, index=expected.index))
  433: 
  434:     result1 = s.resample("D").sum()
  435:     result2 = s.resample("D").mean()
  436:     tm.assert_series_equal(result1, expected)
  437:     tm.assert_series_equal(result2, expected)
  438: 
  439: 
  440: @pytest.mark.parametrize("f", ["sum", "mean", "prod", "min", "max", "var"])
  441: def test_resample_frame_basic_cy_funcs(f, unit):
  442:     df = DataFrame(
  443:         np.random.default_rng(2).standard_normal((50, 4)),
  444:         columns=Index(list("ABCD"), dtype=object),
  445:         index=date_range("2000-01-01", periods=50, freq="B"),
  446:     )
  447:     df.index = df.index.as_unit(unit)
  448: 
  449:     b = Grouper(freq="ME")
  450:     g = df.groupby(b)
  451: 
  452:     # check all cython functions work
  453:     g._cython_agg_general(f, alt=None, numeric_only=True)
  454: 
  455: 
  456: @pytest.mark.parametrize("freq", ["YE", "ME"])
  457: def test_resample_frame_basic_M_A(freq, unit):
  458:     df = DataFrame(
  459:         np.random.default_rng(2).standard_normal((50, 4)),
  460:         columns=Index(list("ABCD"), dtype=object),
  461:         index=date_range("2000-01-01", periods=50, freq="B"),
  462:     )
  463:     df.index = df.index.as_unit(unit)
  464:     result = df.resample(freq).mean()
  465:     tm.assert_series_equal(result["A"], df["A"].resample(freq).mean())
  466: 
  467: 
  468: @pytest.mark.parametrize("freq", ["W-WED", "ME"])
  469: def test_resample_frame_basic_kind(freq, unit):
  470:     df = DataFrame(
  471:         np.random.default_rng(2).standard_normal((10, 4)),
  472:         columns=Index(list("ABCD"), dtype=object),
  473:         index=date_range("2000-01-01", periods=10, freq="B"),
  474:     )
  475:     df.index = df.index.as_unit(unit)
  476:     msg = "The 'kind' keyword in DataFrame.resample is deprecated"
  477:     with tm.assert_produces_warning(FutureWarning, match=msg):
  478:         df.resample(freq, kind="period").mean()
  479: 
  480: 
  481: def test_resample_upsample(unit):
  482:     # from daily
  483:     dti = date_range(
  484:         start=datetime(2005, 1, 1), end=datetime(2005, 1, 10), freq="D", name="index"
  485:     ).as_unit(unit)
  486: 
  487:     s = Series(np.random.default_rng(2).random(len(dti)), dti)
  488: 
  489:     # to minutely, by padding
  490:     result = s.resample("Min").ffill()
  491:     assert len(result) == 12961
  492:     assert result.iloc[0] == s.iloc[0]
  493:     assert result.iloc[-1] == s.iloc[-1]
  494: 
  495:     assert result.index.name == "index"
  496: 
  497: 
  498: def test_resample_how_method(unit):
  499:     # GH9915
  500:     s = Series(
  501:         [11, 22],
  502:         index=[
  503:             Timestamp("2015-03-31 21:48:52.672000"),
  504:             Timestamp("2015-03-31 21:49:52.739000"),
  505:         ],
  506:     )
  507:     s.index = s.index.as_unit(unit)
  508:     expected = Series(
  509:         [11, np.nan, np.nan, np.nan, np.nan, np.nan, 22],
  510:         index=DatetimeIndex(
  511:             [
  512:                 Timestamp("2015-03-31 21:48:50"),
  513:                 Timestamp("2015-03-31 21:49:00"),
  514:                 Timestamp("2015-03-31 21:49:10"),
  515:                 Timestamp("2015-03-31 21:49:20"),
  516:                 Timestamp("2015-03-31 21:49:30"),
  517:                 Timestamp("2015-03-31 21:49:40"),
  518:                 Timestamp("2015-03-31 21:49:50"),
  519:             ],
  520:             freq="10s",
  521:         ),
  522:     )
  523:     expected.index = expected.index.as_unit(unit)
  524:     tm.assert_series_equal(s.resample("10s").mean(), expected)
  525: 
  526: 
  527: def test_resample_extra_index_point(unit):
  528:     # GH#9756
  529:     index = date_range(start="20150101", end="20150331", freq="BME").as_unit(unit)
  530:     expected = DataFrame({"A": Series([21, 41, 63], index=index)})
  531: 
  532:     index = date_range(start="20150101", end="20150331", freq="B").as_unit(unit)
  533:     df = DataFrame({"A": Series(range(len(index)), index=index)}, dtype="int64")
  534:     result = df.resample("BME").last()
  535:     tm.assert_frame_equal(result, expected)
  536: 
  537: 
  538: def test_upsample_with_limit(unit):
  539:     rng = date_range("1/1/2000", periods=3, freq="5min").as_unit(unit)
  540:     ts = Series(np.random.default_rng(2).standard_normal(len(rng)), rng)
  541: 
  542:     result = ts.resample("min").ffill(limit=2)
  543:     expected = ts.reindex(result.index, method="ffill", limit=2)
  544:     tm.assert_series_equal(result, expected)
  545: 
  546: 
  547: @pytest.mark.parametrize("freq", ["1D", "10h", "5Min", "10s"])
  548: @pytest.mark.parametrize("rule", ["YE", "3ME", "15D", "30h", "15Min", "30s"])
  549: def test_nearest_upsample_with_limit(tz_aware_fixture, freq, rule, unit):
  550:     # GH 33939
  551:     rng = date_range("1/1/2000", periods=3, freq=freq, tz=tz_aware_fixture).as_unit(
  552:         unit
  553:     )
  554:     ts = Series(np.random.default_rng(2).standard_normal(len(rng)), rng)
  555: 
  556:     result = ts.resample(rule).nearest(limit=2)
  557:     expected = ts.reindex(result.index, method="nearest", limit=2)
  558:     tm.assert_series_equal(result, expected)
  559: 
  560: 
  561: def test_resample_ohlc(series, unit):
  562:     s = series
  563:     s.index = s.index.as_unit(unit)
  564: 
  565:     grouper = Grouper(freq=Minute(5))
  566:     expect = s.groupby(grouper).agg(lambda x: x.iloc[-1])
  567:     result = s.resample("5Min").ohlc()
  568: 
  569:     assert len(result) == len(expect)
  570:     assert len(result.columns) == 4
  571: 
  572:     xs = result.iloc[-2]
  573:     assert xs["open"] == s.iloc[-6]
  574:     assert xs["high"] == s[-6:-1].max()
  575:     assert xs["low"] == s[-6:-1].min()
  576:     assert xs["close"] == s.iloc[-2]
  577: 
  578:     xs = result.iloc[0]
  579:     assert xs["open"] == s.iloc[0]
  580:     assert xs["high"] == s[:5].max()
  581:     assert xs["low"] == s[:5].min()
  582:     assert xs["close"] == s.iloc[4]
  583: 
  584: 
  585: def test_resample_ohlc_result(unit):
  586:     # GH 12332
  587:     index = date_range("1-1-2000", "2-15-2000", freq="h").as_unit(unit)
  588:     index = index.union(date_range("4-15-2000", "5-15-2000", freq="h").as_unit(unit))
  589:     s = Series(range(len(index)), index=index)
  590: 
  591:     a = s.loc[:"4-15-2000"].resample("30min").ohlc()
  592:     assert isinstance(a, DataFrame)
  593: 
  594:     b = s.loc[:"4-14-2000"].resample("30min").ohlc()
  595:     assert isinstance(b, DataFrame)
  596: 
  597: 
  598: def test_resample_ohlc_result_odd_period(unit):
  599:     # GH12348
  600:     # raising on odd period
  601:     rng = date_range("2013-12-30", "2014-01-07").as_unit(unit)
  602:     index = rng.drop(
  603:         [
  604:             Timestamp("2014-01-01"),
  605:             Timestamp("2013-12-31"),
  606:             Timestamp("2014-01-04"),
  607:             Timestamp("2014-01-05"),
  608:         ]
  609:     )
  610:     df = DataFrame(data=np.arange(len(index)), index=index)
  611:     result = df.resample("B").mean()
  612:     expected = df.reindex(index=date_range(rng[0], rng[-1], freq="B").as_unit(unit))
  613:     tm.assert_frame_equal(result, expected)
  614: 
  615: 
  616: def test_resample_ohlc_dataframe(unit):
  617:     df = (
  618:         DataFrame(
  619:             {
  620:                 "PRICE": {
  621:                     Timestamp("2011-01-06 10:59:05", tz=None): 24990,
  622:                     Timestamp("2011-01-06 12:43:33", tz=None): 25499,
  623:                     Timestamp("2011-01-06 12:54:09", tz=None): 25499,
  624:                 },
  625:                 "VOLUME": {
  626:                     Timestamp("2011-01-06 10:59:05", tz=None): 1500000000,
  627:                     Timestamp("2011-01-06 12:43:33", tz=None): 5000000000,
  628:                     Timestamp("2011-01-06 12:54:09", tz=None): 100000000,
  629:                 },
  630:             }
  631:         )
  632:     ).reindex(["VOLUME", "PRICE"], axis=1)
  633:     df.index = df.index.as_unit(unit)
  634:     df.columns.name = "Cols"
  635:     res = df.resample("h").ohlc()
  636:     exp = pd.concat(
  637:         [df["VOLUME"].resample("h").ohlc(), df["PRICE"].resample("h").ohlc()],
  638:         axis=1,
  639:         keys=df.columns,
  640:     )
  641:     assert exp.columns.names[0] == "Cols"
  642:     tm.assert_frame_equal(exp, res)
  643: 
  644:     df.columns = [["a", "b"], ["c", "d"]]
  645:     res = df.resample("h").ohlc()
  646:     exp.columns = pd.MultiIndex.from_tuples(
  647:         [
  648:             ("a", "c", "open"),
  649:             ("a", "c", "high"),
  650:             ("a", "c", "low"),
  651:             ("a", "c", "close"),
  652:             ("b", "d", "open"),
  653:             ("b", "d", "high"),
  654:             ("b", "d", "low"),
  655:             ("b", "d", "close"),
  656:         ]
  657:     )
  658:     tm.assert_frame_equal(exp, res)
  659: 
  660:     # dupe columns fail atm
  661:     # df.columns = ['PRICE', 'PRICE']
  662: 
  663: 
  664: def test_resample_dup_index():
  665:     # GH 4812
  666:     # dup columns with resample raising
  667:     df = DataFrame(
  668:         np.random.default_rng(2).standard_normal((4, 12)),
  669:         index=[2000, 2000, 2000, 2000],
  670:         columns=[Period(year=2000, month=i + 1, freq="M") for i in range(12)],
  671:     )
  672:     df.iloc[3, :] = np.nan
  673:     warning_msg = "DataFrame.resample with axis=1 is deprecated."
  674:     with tm.assert_produces_warning(FutureWarning, match=warning_msg):
  675:         result = df.resample("QE", axis=1).mean()
  676: 
  677:     msg = "DataFrame.groupby with axis=1 is deprecated"
  678:     with tm.assert_produces_warning(FutureWarning, match=msg):
  679:         expected = df.groupby(lambda x: int((x.month - 1) / 3), axis=1).mean()
  680:     expected.columns = [Period(year=2000, quarter=i + 1, freq="Q") for i in range(4)]
  681:     tm.assert_frame_equal(result, expected)
  682: 
  683: 
  684: def test_resample_reresample(unit):
  685:     dti = date_range(
  686:         start=datetime(2005, 1, 1), end=datetime(2005, 1, 10), freq="D"
  687:     ).as_unit(unit)
  688:     s = Series(np.random.default_rng(2).random(len(dti)), dti)
  689:     bs = s.resample("B", closed="right", label="right").mean()
  690:     result = bs.resample("8h").mean()
  691:     assert len(result) == 25
  692:     assert isinstance(result.index.freq, offsets.DateOffset)
  693:     assert result.index.freq == offsets.Hour(8)
  694: 
  695: 
  696: @pytest.mark.parametrize(
  697:     "freq, expected_kwargs",
  698:     [
  699:         ["YE-DEC", {"start": "1990", "end": "2000", "freq": "Y-DEC"}],
  700:         ["YE-JUN", {"start": "1990", "end": "2000", "freq": "Y-JUN"}],
  701:         ["ME", {"start": "1990-01", "end": "2000-01", "freq": "M"}],
  702:     ],
  703: )
  704: def test_resample_timestamp_to_period(
  705:     simple_date_range_series, freq, expected_kwargs, unit
  706: ):
  707:     ts = simple_date_range_series("1/1/1990", "1/1/2000")
  708:     ts.index = ts.index.as_unit(unit)
  709: 
  710:     msg = "The 'kind' keyword in Series.resample is deprecated"
  711:     with tm.assert_produces_warning(FutureWarning, match=msg):
  712:         result = ts.resample(freq, kind="period").mean()
  713:     expected = ts.resample(freq).mean()
  714:     expected.index = period_range(**expected_kwargs)
  715:     tm.assert_series_equal(result, expected)
  716: 
  717: 
  718: def test_ohlc_5min(unit):
  719:     def _ohlc(group):
  720:         if isna(group).all():
  721:             return np.repeat(np.nan, 4)
  722:         return [group.iloc[0], group.max(), group.min(), group.iloc[-1]]
  723: 
  724:     rng = date_range("1/1/2000 00:00:00", "1/1/2000 5:59:50", freq="10s").as_unit(unit)
  725:     ts = Series(np.random.default_rng(2).standard_normal(len(rng)), index=rng)
  726: 
  727:     resampled = ts.resample("5min", closed="right", label="right").ohlc()
  728: 
  729:     assert (resampled.loc["1/1/2000 00:00"] == ts.iloc[0]).all()
  730: 
  731:     exp = _ohlc(ts[1:31])
  732:     assert (resampled.loc["1/1/2000 00:05"] == exp).all()
  733: 
  734:     exp = _ohlc(ts["1/1/2000 5:55:01":])
  735:     assert (resampled.loc["1/1/2000 6:00:00"] == exp).all()
  736: 
  737: 
  738: def test_downsample_non_unique(unit):
  739:     rng = date_range("1/1/2000", "2/29/2000").as_unit(unit)
  740:     rng2 = rng.repeat(5).values
  741:     ts = Series(np.random.default_rng(2).standard_normal(len(rng2)), index=rng2)
  742: 
  743:     result = ts.resample("ME").mean()
  744: 
  745:     expected = ts.groupby(lambda x: x.month).mean()
  746:     assert len(result) == 2
  747:     tm.assert_almost_equal(result.iloc[0], expected[1])
  748:     tm.assert_almost_equal(result.iloc[1], expected[2])
  749: 
  750: 
  751: def test_asfreq_non_unique(unit):
  752:     # GH #1077
  753:     rng = date_range("1/1/2000", "2/29/2000").as_unit(unit)
  754:     rng2 = rng.repeat(2).values
  755:     ts = Series(np.random.default_rng(2).standard_normal(len(rng2)), index=rng2)
  756: 
  757:     msg = "cannot reindex on an axis with duplicate labels"
  758:     with pytest.raises(ValueError, match=msg):
  759:         ts.asfreq("B")
  760: 
  761: 
  762: def test_resample_axis1(unit):
  763:     rng = date_range("1/1/2000", "2/29/2000").as_unit(unit)
  764:     df = DataFrame(
  765:         np.random.default_rng(2).standard_normal((3, len(rng))),
  766:         columns=rng,
  767:         index=["a", "b", "c"],
  768:     )
  769: 
  770:     warning_msg = "DataFrame.resample with axis=1 is deprecated."
  771:     with tm.assert_produces_warning(FutureWarning, match=warning_msg):
  772:         result = df.resample("ME", axis=1).mean()
  773:     expected = df.T.resample("ME").mean().T
  774:     tm.assert_frame_equal(result, expected)
  775: 
  776: 
  777: @pytest.mark.parametrize("freq", ["min", "5min", "15min", "30min", "4h", "12h"])
  778: def test_resample_anchored_ticks(freq, unit):
  779:     # If a fixed delta (5 minute, 4 hour) evenly divides a day, we should
  780:     # "anchor" the origin at midnight so we get regular intervals rather
  781:     # than starting from the first timestamp which might start in the
  782:     # middle of a desired interval
  783: 
  784:     rng = date_range("1/1/2000 04:00:00", periods=86400, freq="s").as_unit(unit)
  785:     ts = Series(np.random.default_rng(2).standard_normal(len(rng)), index=rng)
  786:     ts[:2] = np.nan  # so results are the same
  787:     result = ts[2:].resample(freq, closed="left", label="left").mean()
  788:     expected = ts.resample(freq, closed="left", label="left").mean()
  789:     tm.assert_series_equal(result, expected)
  790: 
  791: 
  792: @pytest.mark.parametrize("end", [1, 2])
  793: def test_resample_single_group(end, unit):
  794:     mysum = lambda x: x.sum()
  795: 
  796:     rng = date_range("2000-1-1", f"2000-{end}-10", freq="D").as_unit(unit)
  797:     ts = Series(np.random.default_rng(2).standard_normal(len(rng)), index=rng)
  798:     tm.assert_series_equal(ts.resample("ME").sum(), ts.resample("ME").apply(mysum))
  799: 
  800: 
  801: def test_resample_single_group_std(unit):
  802:     # GH 3849
  803:     s = Series(
  804:         [30.1, 31.6],
  805:         index=[Timestamp("20070915 15:30:00"), Timestamp("20070915 15:40:00")],
  806:     )
  807:     s.index = s.index.as_unit(unit)
  808:     expected = Series(
  809:         [0.75], index=DatetimeIndex([Timestamp("20070915")], freq="D").as_unit(unit)
  810:     )
  811:     result = s.resample("D").apply(lambda x: np.std(x))
  812:     tm.assert_series_equal(result, expected)
  813: 
  814: 
  815: def test_resample_offset(unit):
  816:     # GH 31809
  817: 
  818:     rng = date_range("1/1/2000 00:00:00", "1/1/2000 02:00", freq="s").as_unit(unit)
  819:     ts = Series(np.random.default_rng(2).standard_normal(len(rng)), index=rng)
  820: 
  821:     resampled = ts.resample("5min", offset="2min").mean()
  822:     exp_rng = date_range("12/31/1999 23:57:00", "1/1/2000 01:57", freq="5min").as_unit(
  823:         unit
  824:     )
  825:     tm.assert_index_equal(resampled.index, exp_rng)
  826: 
  827: 
  828: @pytest.mark.parametrize(
  829:     "kwargs",
  830:     [
  831:         {"origin": "1999-12-31 23:57:00"},
  832:         {"origin": Timestamp("1970-01-01 00:02:00")},
  833:         {"origin": "epoch", "offset": "2m"},
  834:         # origin of '1999-31-12 12:02:00' should be equivalent for this case
  835:         {"origin": "1999-12-31 12:02:00"},
  836:         {"offset": "-3m"},
  837:     ],
  838: )
  839: def test_resample_origin(kwargs, unit):
  840:     # GH 31809
  841:     rng = date_range("2000-01-01 00:00:00", "2000-01-01 02:00", freq="s").as_unit(unit)
  842:     ts = Series(np.random.default_rng(2).standard_normal(len(rng)), index=rng)
  843: 
  844:     exp_rng = date_range(
  845:         "1999-12-31 23:57:00", "2000-01-01 01:57", freq="5min"
  846:     ).as_unit(unit)
  847: 
  848:     resampled = ts.resample("5min", **kwargs).mean()
  849:     tm.assert_index_equal(resampled.index, exp_rng)
  850: 
  851: 
  852: @pytest.mark.parametrize(
  853:     "origin", ["invalid_value", "epch", "startday", "startt", "2000-30-30", object()]
  854: )
  855: def test_resample_bad_origin(origin, unit):
  856:     rng = date_range("2000-01-01 00:00:00", "2000-01-01 02:00", freq="s").as_unit(unit)
  857:     ts = Series(np.random.default_rng(2).standard_normal(len(rng)), index=rng)
  858:     msg = (
  859:         "'origin' should be equal to 'epoch', 'start', 'start_day', "
  860:         "'end', 'end_day' or should be a Timestamp convertible type. Got "
  861:         f"'{origin}' instead."
  862:     )
  863:     with pytest.raises(ValueError, match=msg):
  864:         ts.resample("5min", origin=origin)
  865: 
  866: 
  867: @pytest.mark.parametrize("offset", ["invalid_value", "12dayys", "2000-30-30", object()])
  868: def test_resample_bad_offset(offset, unit):
  869:     rng = date_range("2000-01-01 00:00:00", "2000-01-01 02:00", freq="s").as_unit(unit)
  870:     ts = Series(np.random.default_rng(2).standard_normal(len(rng)), index=rng)
  871:     msg = f"'offset' should be a Timedelta convertible type. Got '{offset}' instead."
  872:     with pytest.raises(ValueError, match=msg):
  873:         ts.resample("5min", offset=offset)
  874: 
  875: 
  876: def test_resample_origin_prime_freq(unit):
  877:     # GH 31809
  878:     start, end = "2000-10-01 23:30:00", "2000-10-02 00:30:00"
  879:     rng = date_range(start, end, freq="7min").as_unit(unit)
  880:     ts = Series(np.random.default_rng(2).standard_normal(len(rng)), index=rng)
  881: 
  882:     exp_rng = date_range(
  883:         "2000-10-01 23:14:00", "2000-10-02 00:22:00", freq="17min"
  884:     ).as_unit(unit)
  885:     resampled = ts.resample("17min").mean()
  886:     tm.assert_index_equal(resampled.index, exp_rng)
  887:     resampled = ts.resample("17min", origin="start_day").mean()
  888:     tm.assert_index_equal(resampled.index, exp_rng)
  889: 
  890:     exp_rng = date_range(
  891:         "2000-10-01 23:30:00", "2000-10-02 00:21:00", freq="17min"
  892:     ).as_unit(unit)
  893:     resampled = ts.resample("17min", origin="start").mean()
  894:     tm.assert_index_equal(resampled.index, exp_rng)
  895:     resampled = ts.resample("17min", offset="23h30min").mean()
  896:     tm.assert_index_equal(resampled.index, exp_rng)
  897:     resampled = ts.resample("17min", origin="start_day", offset="23h30min").mean()
  898:     tm.assert_index_equal(resampled.index, exp_rng)
  899: 
  900:     exp_rng = date_range(
  901:         "2000-10-01 23:18:00", "2000-10-02 00:26:00", freq="17min"
  902:     ).as_unit(unit)
  903:     resampled = ts.resample("17min", origin="epoch").mean()
  904:     tm.assert_index_equal(resampled.index, exp_rng)
  905: 
  906:     exp_rng = date_range(
  907:         "2000-10-01 23:24:00", "2000-10-02 00:15:00", freq="17min"
  908:     ).as_unit(unit)
  909:     resampled = ts.resample("17min", origin="2000-01-01").mean()
  910:     tm.assert_index_equal(resampled.index, exp_rng)
  911: 
  912: 
  913: def test_resample_origin_with_tz(unit):
  914:     # GH 31809
  915:     msg = "The origin must have the same timezone as the index."
  916: 
  917:     tz = "Europe/Paris"
  918:     rng = date_range(
  919:         "2000-01-01 00:00:00", "2000-01-01 02:00", freq="s", tz=tz
  920:     ).as_unit(unit)
  921:     ts = Series(np.random.default_rng(2).standard_normal(len(rng)), index=rng)
  922: 
  923:     exp_rng = date_range(
  924:         "1999-12-31 23:57:00", "2000-01-01 01:57", freq="5min", tz=tz
  925:     ).as_unit(unit)
  926:     resampled = ts.resample("5min", origin="1999-12-31 23:57:00+00:00").mean()
  927:     tm.assert_index_equal(resampled.index, exp_rng)
  928: 
  929:     # origin of '1999-31-12 12:02:00+03:00' should be equivalent for this case
  930:     resampled = ts.resample("5min", origin="1999-12-31 12:02:00+03:00").mean()
  931:     tm.assert_index_equal(resampled.index, exp_rng)
  932: 
  933:     resampled = ts.resample("5min", origin="epoch", offset="2m").mean()
  934:     tm.assert_index_equal(resampled.index, exp_rng)
  935: 
  936:     with pytest.raises(ValueError, match=msg):
  937:         ts.resample("5min", origin="12/31/1999 23:57:00").mean()
  938: 
  939:     # if the series is not tz aware, origin should not be tz aware
  940:     rng = date_range("2000-01-01 00:00:00", "2000-01-01 02:00", freq="s").as_unit(unit)
  941:     ts = Series(np.random.default_rng(2).standard_normal(len(rng)), index=rng)
  942:     with pytest.raises(ValueError, match=msg):
  943:         ts.resample("5min", origin="12/31/1999 23:57:00+03:00").mean()
  944: 
  945: 
  946: def test_resample_origin_epoch_with_tz_day_vs_24h(unit):
  947:     # GH 34474
  948:     start, end = "2000-10-01 23:30:00+0500", "2000-12-02 00:30:00+0500"
  949:     rng = date_range(start, end, freq="7min").as_unit(unit)
  950:     random_values = np.random.default_rng(2).standard_normal(len(rng))
  951:     ts_1 = Series(random_values, index=rng)
  952: 
  953:     result_1 = ts_1.resample("D", origin="epoch").mean()
  954:     result_2 = ts_1.resample("24h", origin="epoch").mean()
  955:     tm.assert_series_equal(result_1, result_2)
  956: 
  957:     # check that we have the same behavior with epoch even if we are not timezone aware
  958:     ts_no_tz = ts_1.tz_localize(None)
  959:     result_3 = ts_no_tz.resample("D", origin="epoch").mean()
  960:     result_4 = ts_no_tz.resample("24h", origin="epoch").mean()
  961:     tm.assert_series_equal(result_1, result_3.tz_localize(rng.tz), check_freq=False)
  962:     tm.assert_series_equal(result_1, result_4.tz_localize(rng.tz), check_freq=False)
  963: 
  964:     # check that we have the similar results with two different timezones (+2H and +5H)
  965:     start, end = "2000-10-01 23:30:00+0200", "2000-12-02 00:30:00+0200"
  966:     rng = date_range(start, end, freq="7min").as_unit(unit)
  967:     ts_2 = Series(random_values, index=rng)
  968:     result_5 = ts_2.resample("D", origin="epoch").mean()
  969:     result_6 = ts_2.resample("24h", origin="epoch").mean()
  970:     tm.assert_series_equal(result_1.tz_localize(None), result_5.tz_localize(None))
  971:     tm.assert_series_equal(result_1.tz_localize(None), result_6.tz_localize(None))
  972: 
  973: 
  974: def test_resample_origin_with_day_freq_on_dst(unit):
  975:     # GH 31809
  976:     tz = "America/Chicago"
  977: 
  978:     def _create_series(values, timestamps, freq="D"):
  979:         return Series(
  980:             values,
  981:             index=DatetimeIndex(
  982:                 [Timestamp(t, tz=tz) for t in timestamps], freq=freq, ambiguous=True
  983:             ).as_unit(unit),
  984:         )
  985: 
  986:     # test classical behavior of origin in a DST context
  987:     start = Timestamp("2013-11-02", tz=tz)
  988:     end = Timestamp("2013-11-03 23:59", tz=tz)
  989:     rng = date_range(start, end, freq="1h").as_unit(unit)
  990:     ts = Series(np.ones(len(rng)), index=rng)
  991: 
  992:     expected = _create_series([24.0, 25.0], ["2013-11-02", "2013-11-03"])
  993:     for origin in ["epoch", "start", "start_day", start, None]:
  994:         result = ts.resample("D", origin=origin).sum()
  995:         tm.assert_series_equal(result, expected)
  996: 
  997:     # test complex behavior of origin/offset in a DST context
  998:     start = Timestamp("2013-11-03", tz=tz)
  999:     end = Timestamp("2013-11-03 23:59", tz=tz)
 1000:     rng = date_range(start, end, freq="1h").as_unit(unit)
 1001:     ts = Series(np.ones(len(rng)), index=rng)
 1002: 
 1003:     expected_ts = ["2013-11-02 22:00-05:00", "2013-11-03 22:00-06:00"]
 1004:     expected = _create_series([23.0, 2.0], expected_ts)
 1005:     result = ts.resample("D", origin="start", offset="-2h").sum()
 1006:     tm.assert_series_equal(result, expected)
 1007: 
 1008:     expected_ts = ["2013-11-02 22:00-05:00", "2013-11-03 21:00-06:00"]
 1009:     expected = _create_series([22.0, 3.0], expected_ts, freq="24h")
 1010:     result = ts.resample("24h", origin="start", offset="-2h").sum()
 1011:     tm.assert_series_equal(result, expected)
 1012: 
 1013:     expected_ts = ["2013-11-02 02:00-05:00", "2013-11-03 02:00-06:00"]
 1014:     expected = _create_series([3.0, 22.0], expected_ts)
 1015:     result = ts.resample("D", origin="start", offset="2h").sum()
 1016:     tm.assert_series_equal(result, expected)
 1017: 
 1018:     expected_ts = ["2013-11-02 23:00-05:00", "2013-11-03 23:00-06:00"]
 1019:     expected = _create_series([24.0, 1.0], expected_ts)
 1020:     result = ts.resample("D", origin="start", offset="-1h").sum()
 1021:     tm.assert_series_equal(result, expected)
 1022: 
 1023:     expected_ts = ["2013-11-02 01:00-05:00", "2013-11-03 01:00:00-0500"]
 1024:     expected = _create_series([1.0, 24.0], expected_ts)
 1025:     result = ts.resample("D", origin="start", offset="1h").sum()
 1026:     tm.assert_series_equal(result, expected)
 1027: 
 1028: 
 1029: def test_resample_daily_anchored(unit):
 1030:     rng = date_range("1/1/2000 0:00:00", periods=10000, freq="min").as_unit(unit)
 1031:     ts = Series(np.random.default_rng(2).standard_normal(len(rng)), index=rng)
 1032:     ts[:2] = np.nan  # so results are the same
 1033: 
 1034:     result = ts[2:].resample("D", closed="left", label="left").mean()
 1035:     expected = ts.resample("D", closed="left", label="left").mean()
 1036:     tm.assert_series_equal(result, expected)
 1037: 
 1038: 
 1039: def test_resample_to_period_monthly_buglet(unit):
 1040:     # GH #1259
 1041: 
 1042:     rng = date_range("1/1/2000", "12/31/2000").as_unit(unit)
 1043:     ts = Series(np.random.default_rng(2).standard_normal(len(rng)), index=rng)
 1044: 
 1045:     msg = "The 'kind' keyword in Series.resample is deprecated"
 1046:     with tm.assert_produces_warning(FutureWarning, match=msg):
 1047:         result = ts.resample("ME", kind="period").mean()
 1048:     exp_index = period_range("Jan-2000", "Dec-2000", freq="M")
 1049:     tm.assert_index_equal(result.index, exp_index)
 1050: 
 1051: 
 1052: def test_period_with_agg():
 1053:     # aggregate a period resampler with a lambda
 1054:     s2 = Series(
 1055:         np.random.default_rng(2).integers(0, 5, 50),
 1056:         index=period_range("2012-01-01", freq="h", periods=50),
 1057:         dtype="float64",
 1058:     )
 1059: 
 1060:     expected = s2.to_timestamp().resample("D").mean().to_period()
 1061:     msg = "Resampling with a PeriodIndex is deprecated"
 1062:     with tm.assert_produces_warning(FutureWarning, match=msg):
 1063:         rs = s2.resample("D")
 1064:     result = rs.agg(lambda x: x.mean())
 1065:     tm.assert_series_equal(result, expected)
 1066: 
 1067: 
 1068: def test_resample_segfault(unit):
 1069:     # GH 8573
 1070:     # segfaulting in older versions
 1071:     all_wins_and_wagers = [
 1072:         (1, datetime(2013, 10, 1, 16, 20), 1, 0),
 1073:         (2, datetime(2013, 10, 1, 16, 10), 1, 0),
 1074:         (2, datetime(2013, 10, 1, 18, 15), 1, 0),
 1075:         (2, datetime(2013, 10, 1, 16, 10, 31), 1, 0),
 1076:     ]
 1077: 
 1078:     df = DataFrame.from_records(
 1079:         all_wins_and_wagers, columns=("ID", "timestamp", "A", "B")
 1080:     ).set_index("timestamp")
 1081:     df.index = df.index.as_unit(unit)
 1082:     msg = "DataFrameGroupBy.resample operated on the grouping columns"
 1083:     with tm.assert_produces_warning(DeprecationWarning, match=msg):
 1084:         result = df.groupby("ID").resample("5min").sum()
 1085:     msg = "DataFrameGroupBy.apply operated on the grouping columns"
 1086:     with tm.assert_produces_warning(DeprecationWarning, match=msg):
 1087:         expected = df.groupby("ID").apply(lambda x: x.resample("5min").sum())
 1088:     tm.assert_frame_equal(result, expected)
 1089: 
 1090: 
 1091: def test_resample_dtype_preservation(unit):
 1092:     # GH 12202
 1093:     # validation tests for dtype preservation
 1094: 
 1095:     df = DataFrame(
 1096:         {
 1097:             "date": date_range(start="2016-01-01", periods=4, freq="W").as_unit(unit),
 1098:             "group": [1, 1, 2, 2],
 1099:             "val": Series([5, 6, 7, 8], dtype="int32"),
 1100:         }
 1101:     ).set_index("date")
 1102: 
 1103:     result = df.resample("1D").ffill()
 1104:     assert result.val.dtype == np.int32
 1105: 
 1106:     msg = "DataFrameGroupBy.resample operated on the grouping columns"
 1107:     with tm.assert_produces_warning(DeprecationWarning, match=msg):
 1108:         result = df.groupby("group").resample("1D").ffill()
 1109:     assert result.val.dtype == np.int32
 1110: 
 1111: 
 1112: def test_resample_dtype_coercion(unit):
 1113:     pytest.importorskip("scipy.interpolate")
 1114: 
 1115:     # GH 16361
 1116:     df = {"a": [1, 3, 1, 4]}
 1117:     df = DataFrame(df, index=date_range("2017-01-01", "2017-01-04").as_unit(unit))
 1118: 
 1119:     expected = df.astype("float64").resample("h").mean()["a"].interpolate("cubic")
 1120: 
 1121:     result = df.resample("h")["a"].mean().interpolate("cubic")
 1122:     tm.assert_series_equal(result, expected)
 1123: 
 1124:     result = df.resample("h").mean()["a"].interpolate("cubic")
 1125:     tm.assert_series_equal(result, expected)
 1126: 
 1127: 
 1128: def test_weekly_resample_buglet(unit):
 1129:     # #1327
 1130:     rng = date_range("1/1/2000", freq="B", periods=20).as_unit(unit)
 1131:     ts = Series(np.random.default_rng(2).standard_normal(len(rng)), index=rng)
 1132: 
 1133:     resampled = ts.resample("W").mean()
 1134:     expected = ts.resample("W-SUN").mean()
 1135:     tm.assert_series_equal(resampled, expected)
 1136: 
 1137: 
 1138: def test_monthly_resample_error(unit):
 1139:     # #1451
 1140:     dates = date_range("4/16/2012 20:00", periods=5000, freq="h").as_unit(unit)
 1141:     ts = Series(np.random.default_rng(2).standard_normal(len(dates)), index=dates)
 1142:     # it works!
 1143:     ts.resample("ME")
 1144: 
 1145: 
 1146: def test_nanosecond_resample_error():
 1147:     # GH 12307 - Values falls after last bin when
 1148:     # Resampling using pd.tseries.offsets.Nano as period
 1149:     start = 1443707890427
 1150:     exp_start = 1443707890400
 1151:     indx = date_range(start=pd.to_datetime(start), periods=10, freq="100ns")
 1152:     ts = Series(range(len(indx)), index=indx)
 1153:     r = ts.resample(pd.tseries.offsets.Nano(100))
 1154:     result = r.agg("mean")
 1155: 
 1156:     exp_indx = date_range(start=pd.to_datetime(exp_start), periods=10, freq="100ns")
 1157:     exp = Series(range(len(exp_indx)), index=exp_indx, dtype=float)
 1158: 
 1159:     tm.assert_series_equal(result, exp)
 1160: 
 1161: 
 1162: def test_resample_anchored_intraday(unit):
 1163:     # #1471, #1458
 1164: 
 1165:     rng = date_range("1/1/2012", "4/1/2012", freq="100min").as_unit(unit)
 1166:     df = DataFrame(rng.month, index=rng)
 1167: 
 1168:     result = df.resample("ME").mean()
 1169:     msg = "The 'kind' keyword in DataFrame.resample is deprecated"
 1170:     with tm.assert_produces_warning(FutureWarning, match=msg):
 1171:         expected = df.resample("ME", kind="period").mean().to_timestamp(how="end")
 1172:     expected.index += Timedelta(1, "ns") - Timedelta(1, "D")
 1173:     expected.index = expected.index.as_unit(unit)._with_freq("infer")
 1174:     assert expected.index.freq == "ME"
 1175:     tm.assert_frame_equal(result, expected)
 1176: 
 1177:     result = df.resample("ME", closed="left").mean()
 1178:     msg = "The 'kind' keyword in DataFrame.resample is deprecated"
 1179:     with tm.assert_produces_warning(FutureWarning, match=msg):
 1180:         exp = df.shift(1, freq="D").resample("ME", kind="period").mean()
 1181:     exp = exp.to_timestamp(how="end")
 1182: 
 1183:     exp.index = exp.index + Timedelta(1, "ns") - Timedelta(1, "D")
 1184:     exp.index = exp.index.as_unit(unit)._with_freq("infer")
 1185:     assert exp.index.freq == "ME"
 1186:     tm.assert_frame_equal(result, exp)
 1187: 
 1188: 
 1189: def test_resample_anchored_intraday2(unit):
 1190:     rng = date_range("1/1/2012", "4/1/2012", freq="100min").as_unit(unit)
 1191:     df = DataFrame(rng.month, index=rng)
 1192: 
 1193:     result = df.resample("QE").mean()
 1194:     msg = "The 'kind' keyword in DataFrame.resample is deprecated"
 1195:     with tm.assert_produces_warning(FutureWarning, match=msg):
 1196:         expected = df.resample("QE", kind="period").mean().to_timestamp(how="end")
 1197:     expected.index += Timedelta(1, "ns") - Timedelta(1, "D")
 1198:     expected.index._data.freq = "QE"
 1199:     expected.index._freq = lib.no_default
 1200:     expected.index = expected.index.as_unit(unit)
 1201:     tm.assert_frame_equal(result, expected)
 1202: 
 1203:     result = df.resample("QE", closed="left").mean()
 1204:     msg = "The 'kind' keyword in DataFrame.resample is deprecated"
 1205:     with tm.assert_produces_warning(FutureWarning, match=msg):
 1206:         expected = (
 1207:             df.shift(1, freq="D").resample("QE", kind="period", closed="left").mean()
 1208:         )
 1209:     expected = expected.to_timestamp(how="end")
 1210:     expected.index += Timedelta(1, "ns") - Timedelta(1, "D")
 1211:     expected.index._data.freq = "QE"
 1212:     expected.index._freq = lib.no_default
 1213:     expected.index = expected.index.as_unit(unit)
 1214:     tm.assert_frame_equal(result, expected)
 1215: 
 1216: 
 1217: def test_resample_anchored_intraday3(simple_date_range_series, unit):
 1218:     ts = simple_date_range_series("2012-04-29 23:00", "2012-04-30 5:00", freq="h")
 1219:     ts.index = ts.index.as_unit(unit)
 1220:     resampled = ts.resample("ME").mean()
 1221:     assert len(resampled) == 1
 1222: 
 1223: 
 1224: @pytest.mark.parametrize("freq", ["MS", "BMS", "QS-MAR", "YS-DEC", "YS-JUN"])
 1225: def test_resample_anchored_monthstart(simple_date_range_series, freq, unit):
 1226:     ts = simple_date_range_series("1/1/2000", "12/31/2002")
 1227:     ts.index = ts.index.as_unit(unit)
 1228:     ts.resample(freq).mean()
 1229: 
 1230: 
 1231: @pytest.mark.parametrize("label, sec", [[None, 2.0], ["right", "4.2"]])
 1232: def test_resample_anchored_multiday(label, sec):
 1233:     # When resampling a range spanning multiple days, ensure that the
 1234:     # start date gets used to determine the offset.  Fixes issue where
 1235:     # a one day period is not a multiple of the frequency.
 1236:     #
 1237:     # See: https://github.com/pandas-dev/pandas/issues/8683
 1238: 
 1239:     index1 = date_range("2014-10-14 23:06:23.206", periods=3, freq="400ms")
 1240:     index2 = date_range("2014-10-15 23:00:00", periods=2, freq="2200ms")
 1241:     index = index1.union(index2)
 1242: 
 1243:     s = Series(np.random.default_rng(2).standard_normal(5), index=index)
 1244: 
 1245:     # Ensure left closing works
 1246:     result = s.resample("2200ms", label=label).mean()
 1247:     assert result.index[-1] == Timestamp(f"2014-10-15 23:00:{sec}00")
 1248: 
 1249: 
 1250: def test_corner_cases(unit):
 1251:     # miscellaneous test coverage
 1252: 
 1253:     rng = date_range("1/1/2000", periods=12, freq="min").as_unit(unit)
 1254:     ts = Series(np.random.default_rng(2).standard_normal(len(rng)), index=rng)
 1255: 
 1256:     result = ts.resample("5min", closed="right", label="left").mean()
 1257:     ex_index = date_range("1999-12-31 23:55", periods=4, freq="5min").as_unit(unit)
 1258:     tm.assert_index_equal(result.index, ex_index)
 1259: 
 1260: 
 1261: def test_corner_cases_date(simple_date_range_series, unit):
 1262:     # resample to periods
 1263:     ts = simple_date_range_series("2000-04-28", "2000-04-30 11:00", freq="h")
 1264:     ts.index = ts.index.as_unit(unit)
 1265:     msg = "The 'kind' keyword in Series.resample is deprecated"
 1266:     with tm.assert_produces_warning(FutureWarning, match=msg):
 1267:         result = ts.resample("ME", kind="period").mean()
 1268:     assert len(result) == 1
 1269:     assert result.index[0] == Period("2000-04", freq="M")
 1270: 
 1271: 
 1272: def test_anchored_lowercase_buglet(unit):
 1273:     dates = date_range("4/16/2012 20:00", periods=50000, freq="s").as_unit(unit)
 1274:     ts = Series(np.random.default_rng(2).standard_normal(len(dates)), index=dates)
 1275:     # it works!
 1276:     ts.resample("d").mean()
 1277: 
 1278: 
 1279: def test_upsample_apply_functions(unit):
 1280:     # #1596
 1281:     rng = date_range("2012-06-12", periods=4, freq="h").as_unit(unit)
 1282: 
 1283:     ts = Series(np.random.default_rng(2).standard_normal(len(rng)), index=rng)
 1284: 
 1285:     result = ts.resample("20min").aggregate(["mean", "sum"])
 1286:     assert isinstance(result, DataFrame)
 1287: 
 1288: 
 1289: def test_resample_not_monotonic(unit):
 1290:     rng = date_range("2012-06-12", periods=200, freq="h").as_unit(unit)
 1291:     ts = Series(np.random.default_rng(2).standard_normal(len(rng)), index=rng)
 1292: 
 1293:     ts = ts.take(np.random.default_rng(2).permutation(len(ts)))
 1294: 
 1295:     result = ts.resample("D").sum()
 1296:     exp = ts.sort_index().resample("D").sum()
 1297:     tm.assert_series_equal(result, exp)
 1298: 
 1299: 
 1300: @pytest.mark.parametrize(
 1301:     "dtype",
 1302:     [
 1303:         "int64",
 1304:         "int32",
 1305:         "float64",
 1306:         pytest.param(
 1307:             "float32",
 1308:             marks=pytest.mark.xfail(
 1309:                 reason="Empty groups cause x.mean() to return float64"
 1310:             ),
 1311:         ),
 1312:     ],
 1313: )
 1314: def test_resample_median_bug_1688(dtype, unit):
 1315:     # GH#55958
 1316:     dti = DatetimeIndex(
 1317:         [datetime(2012, 1, 1, 0, 0, 0), datetime(2012, 1, 1, 0, 5, 0)]
 1318:     ).as_unit(unit)
 1319:     df = DataFrame(
 1320:         [1, 2],
 1321:         index=dti,
 1322:         dtype=dtype,
 1323:     )
 1324: 
 1325:     result = df.resample("min").apply(lambda x: x.mean())
 1326:     exp = df.asfreq("min")
 1327:     tm.assert_frame_equal(result, exp)
 1328: 
 1329:     result = df.resample("min").median()
 1330:     exp = df.asfreq("min")
 1331:     tm.assert_frame_equal(result, exp)
 1332: 
 1333: 
 1334: def test_how_lambda_functions(simple_date_range_series, unit):
 1335:     ts = simple_date_range_series("1/1/2000", "4/1/2000")
 1336:     ts.index = ts.index.as_unit(unit)
 1337: 
 1338:     result = ts.resample("ME").apply(lambda x: x.mean())
 1339:     exp = ts.resample("ME").mean()
 1340:     tm.assert_series_equal(result, exp)
 1341: 
 1342:     foo_exp = ts.resample("ME").mean()
 1343:     foo_exp.name = "foo"
 1344:     bar_exp = ts.resample("ME").std()
 1345:     bar_exp.name = "bar"
 1346: 
 1347:     result = ts.resample("ME").apply([lambda x: x.mean(), lambda x: x.std(ddof=1)])
 1348:     result.columns = ["foo", "bar"]
 1349:     tm.assert_series_equal(result["foo"], foo_exp)
 1350:     tm.assert_series_equal(result["bar"], bar_exp)
 1351: 
 1352:     # this is a MI Series, so comparing the names of the results
 1353:     # doesn't make sense
 1354:     result = ts.resample("ME").aggregate(
 1355:         {"foo": lambda x: x.mean(), "bar": lambda x: x.std(ddof=1)}
 1356:     )
 1357:     tm.assert_series_equal(result["foo"], foo_exp, check_names=False)
 1358:     tm.assert_series_equal(result["bar"], bar_exp, check_names=False)
 1359: 
 1360: 
 1361: def test_resample_unequal_times(unit):
 1362:     # #1772
 1363:     start = datetime(1999, 3, 1, 5)
 1364:     # end hour is less than start
 1365:     end = datetime(2012, 7, 31, 4)
 1366:     bad_ind = date_range(start, end, freq="30min").as_unit(unit)
 1367:     df = DataFrame({"close": 1}, index=bad_ind)
 1368: 
 1369:     # it works!
 1370:     df.resample("YS").sum()
 1371: 
 1372: 
 1373: def test_resample_consistency(unit):
 1374:     # GH 6418
 1375:     # resample with bfill / limit / reindex consistency
 1376: 
 1377:     i30 = date_range("2002-02-02", periods=4, freq="30min").as_unit(unit)
 1378:     s = Series(np.arange(4.0), index=i30)
 1379:     s.iloc[2] = np.nan
 1380: 
 1381:     # Upsample by factor 3 with reindex() and resample() methods:
 1382:     i10 = date_range(i30[0], i30[-1], freq="10min").as_unit(unit)
 1383: 
 1384:     s10 = s.reindex(index=i10, method="bfill")
 1385:     s10_2 = s.reindex(index=i10, method="bfill", limit=2)
 1386:     rl = s.reindex_like(s10, method="bfill", limit=2)
 1387:     r10_2 = s.resample("10Min").bfill(limit=2)
 1388:     r10 = s.resample("10Min").bfill()
 1389: 
 1390:     # s10_2, r10, r10_2, rl should all be equal
 1391:     tm.assert_series_equal(s10_2, r10)
 1392:     tm.assert_series_equal(s10_2, r10_2)
 1393:     tm.assert_series_equal(s10_2, rl)
 1394: 
 1395: 
 1396: dates1: list[DatetimeNaTType] = [
 1397:     datetime(2014, 10, 1),
 1398:     datetime(2014, 9, 3),
 1399:     datetime(2014, 11, 5),
 1400:     datetime(2014, 9, 5),
 1401:     datetime(2014, 10, 8),
 1402:     datetime(2014, 7, 15),
 1403: ]
 1404: 
 1405: dates2: list[DatetimeNaTType] = (
 1406:     dates1[:2] + [pd.NaT] + dates1[2:4] + [pd.NaT] + dates1[4:]
 1407: )
 1408: dates3 = [pd.NaT] + dates1 + [pd.NaT]
 1409: 
 1410: 
 1411: @pytest.mark.parametrize("dates", [dates1, dates2, dates3])
 1412: def test_resample_timegrouper(dates, unit):
 1413:     # GH 7227
 1414:     dates = DatetimeIndex(dates).as_unit(unit)
 1415:     df = DataFrame({"A": dates, "B": np.arange(len(dates))})
 1416:     result = df.set_index("A").resample("ME").count()
 1417:     exp_idx = DatetimeIndex(
 1418:         ["2014-07-31", "2014-08-31", "2014-09-30", "2014-10-31", "2014-11-30"],
 1419:         freq="ME",
 1420:         name="A",
 1421:     ).as_unit(unit)
 1422:     expected = DataFrame({"B": [1, 0, 2, 2, 1]}, index=exp_idx)
 1423:     if df["A"].isna().any():
 1424:         expected.index = expected.index._with_freq(None)
 1425:     tm.assert_frame_equal(result, expected)
 1426: 
 1427:     result = df.groupby(Grouper(freq="ME", key="A")).count()
 1428:     tm.assert_frame_equal(result, expected)
 1429: 
 1430: 
 1431: @pytest.mark.parametrize("dates", [dates1, dates2, dates3])
 1432: def test_resample_timegrouper2(dates, unit):
 1433:     dates = DatetimeIndex(dates).as_unit(unit)
 1434: 
 1435:     df = DataFrame({"A": dates, "B": np.arange(len(dates)), "C": np.arange(len(dates))})
 1436:     result = df.set_index("A").resample("ME").count()
 1437: 
 1438:     exp_idx = DatetimeIndex(
 1439:         ["2014-07-31", "2014-08-31", "2014-09-30", "2014-10-31", "2014-11-30"],
 1440:         freq="ME",
 1441:         name="A",
 1442:     ).as_unit(unit)
 1443:     expected = DataFrame(
 1444:         {"B": [1, 0, 2, 2, 1], "C": [1, 0, 2, 2, 1]},
 1445:         index=exp_idx,
 1446:         columns=["B", "C"],
 1447:     )
 1448:     if df["A"].isna().any():
 1449:         expected.index = expected.index._with_freq(None)
 1450:     tm.assert_frame_equal(result, expected)
 1451: 
 1452:     result = df.groupby(Grouper(freq="ME", key="A")).count()
 1453:     tm.assert_frame_equal(result, expected)
 1454: 
 1455: 
 1456: def test_resample_nunique(unit):
 1457:     # GH 12352
 1458:     df = DataFrame(
 1459:         {
 1460:             "ID": {
 1461:                 Timestamp("2015-06-05 00:00:00"): "0010100903",
 1462:                 Timestamp("2015-06-08 00:00:00"): "0010150847",
 1463:             },
 1464:             "DATE": {
 1465:                 Timestamp("2015-06-05 00:00:00"): "2015-06-05",
 1466:                 Timestamp("2015-06-08 00:00:00"): "2015-06-08",
 1467:             },
 1468:         }
 1469:     )
 1470:     df.index = df.index.as_unit(unit)
 1471:     r = df.resample("D")
 1472:     g = df.groupby(Grouper(freq="D"))
 1473:     expected = df.groupby(Grouper(freq="D")).ID.apply(lambda x: x.nunique())
 1474:     assert expected.name == "ID"
 1475: 
 1476:     for t in [r, g]:
 1477:         result = t.ID.nunique()
 1478:         tm.assert_series_equal(result, expected)
 1479: 
 1480:     result = df.ID.resample("D").nunique()
 1481:     tm.assert_series_equal(result, expected)
 1482: 
 1483:     result = df.ID.groupby(Grouper(freq="D")).nunique()
 1484:     tm.assert_series_equal(result, expected)
 1485: 
 1486: 
 1487: def test_resample_nunique_preserves_column_level_names(unit):
 1488:     # see gh-23222
 1489:     df = DataFrame(
 1490:         np.random.default_rng(2).standard_normal((5, 4)),
 1491:         columns=Index(list("ABCD"), dtype=object),
 1492:         index=date_range("2000-01-01", periods=5, freq="D"),
 1493:     ).abs()
 1494:     df.index = df.index.as_unit(unit)
 1495:     df.columns = pd.MultiIndex.from_arrays(
 1496:         [df.columns.tolist()] * 2, names=["lev0", "lev1"]
 1497:     )
 1498:     result = df.resample("1h").nunique()
 1499:     tm.assert_index_equal(df.columns, result.columns)
 1500: 
 1501: 
 1502: @pytest.mark.parametrize(
 1503:     "func",
 1504:     [
 1505:         lambda x: x.nunique(),
 1506:         lambda x: x.agg(Series.nunique),
 1507:         lambda x: x.agg("nunique"),
 1508:     ],
 1509:     ids=["nunique", "series_nunique", "nunique_str"],
 1510: )
 1511: def test_resample_nunique_with_date_gap(func, unit):
 1512:     # GH 13453
 1513:     # Since all elements are unique, these should all be the same
 1514:     index = date_range("1-1-2000", "2-15-2000", freq="h").as_unit(unit)
 1515:     index2 = date_range("4-15-2000", "5-15-2000", freq="h").as_unit(unit)
 1516:     index3 = index.append(index2)
 1517:     s = Series(range(len(index3)), index=index3, dtype="int64")
 1518:     r = s.resample("ME")
 1519:     result = r.count()
 1520:     expected = func(r)
 1521:     tm.assert_series_equal(result, expected)
 1522: 
 1523: 
 1524: @pytest.mark.parametrize("n", [10000, 100000])
 1525: @pytest.mark.parametrize("k", [10, 100, 1000])
 1526: def test_resample_group_info(n, k, unit):
 1527:     # GH10914
 1528: 
 1529:     # use a fixed seed to always have the same uniques
 1530:     prng = np.random.default_rng(2)
 1531: 
 1532:     dr = date_range(start="2015-08-27", periods=n // 10, freq="min").as_unit(unit)
 1533:     ts = Series(prng.integers(0, n // k, n).astype("int64"), index=prng.choice(dr, n))
 1534: 
 1535:     left = ts.resample("30min").nunique()
 1536:     ix = date_range(start=ts.index.min(), end=ts.index.max(), freq="30min").as_unit(
 1537:         unit
 1538:     )
 1539: 
 1540:     vals = ts.values
 1541:     bins = np.searchsorted(ix.values, ts.index, side="right")
 1542: 
 1543:     sorter = np.lexsort((vals, bins))
 1544:     vals, bins = vals[sorter], bins[sorter]
 1545: 
 1546:     mask = np.r_[True, vals[1:] != vals[:-1]]
 1547:     mask |= np.r_[True, bins[1:] != bins[:-1]]
 1548: 
 1549:     arr = np.bincount(bins[mask] - 1, minlength=len(ix)).astype("int64", copy=False)
 1550:     right = Series(arr, index=ix)
 1551: 
 1552:     tm.assert_series_equal(left, right)
 1553: 
 1554: 
 1555: def test_resample_size(unit):
 1556:     n = 10000
 1557:     dr = date_range("2015-09-19", periods=n, freq="min").as_unit(unit)
 1558:     ts = Series(
 1559:         np.random.default_rng(2).standard_normal(n),
 1560:         index=np.random.default_rng(2).choice(dr, n),
 1561:     )
 1562: 
 1563:     left = ts.resample("7min").size()
 1564:     ix = date_range(start=left.index.min(), end=ts.index.max(), freq="7min").as_unit(
 1565:         unit
 1566:     )
 1567: 
 1568:     bins = np.searchsorted(ix.values, ts.index.values, side="right")
 1569:     val = np.bincount(bins, minlength=len(ix) + 1)[1:].astype("int64", copy=False)
 1570: 
 1571:     right = Series(val, index=ix)
 1572:     tm.assert_series_equal(left, right)
 1573: 
 1574: 
 1575: def test_resample_across_dst():
 1576:     # The test resamples a DatetimeIndex with values before and after a
 1577:     # DST change
 1578:     # Issue: 14682
 1579: 
 1580:     # The DatetimeIndex we will start with
 1581:     # (note that DST happens at 03:00+02:00 -> 02:00+01:00)
 1582:     # 2016-10-30 02:23:00+02:00, 2016-10-30 02:23:00+01:00
 1583:     df1 = DataFrame([1477786980, 1477790580], columns=["ts"])
 1584:     dti1 = DatetimeIndex(
 1585:         pd.to_datetime(df1.ts, unit="s")
 1586:         .dt.tz_localize("UTC")
 1587:         .dt.tz_convert("Europe/Madrid")
 1588:     )
 1589: 
 1590:     # The expected DatetimeIndex after resampling.
 1591:     # 2016-10-30 02:00:00+02:00, 2016-10-30 02:00:00+01:00
 1592:     df2 = DataFrame([1477785600, 1477789200], columns=["ts"])
 1593:     dti2 = DatetimeIndex(
 1594:         pd.to_datetime(df2.ts, unit="s")
 1595:         .dt.tz_localize("UTC")
 1596:         .dt.tz_convert("Europe/Madrid"),
 1597:         freq="h",
 1598:     )
 1599:     df = DataFrame([5, 5], index=dti1)
 1600: 
 1601:     result = df.resample(rule="h").sum()
 1602:     expected = DataFrame([5, 5], index=dti2)
 1603: 
 1604:     tm.assert_frame_equal(result, expected)
 1605: 
 1606: 
 1607: def test_groupby_with_dst_time_change(unit):
 1608:     # GH 24972
 1609:     index = (
 1610:         DatetimeIndex([1478064900001000000, 1480037118776792000], tz="UTC")
 1611:         .tz_convert("America/Chicago")
 1612:         .as_unit(unit)
 1613:     )
 1614: 
 1615:     df = DataFrame([1, 2], index=index)
 1616:     result = df.groupby(Grouper(freq="1d")).last()
 1617:     expected_index_values = date_range(
 1618:         "2016-11-02", "2016-11-24", freq="d", tz="America/Chicago"
 1619:     ).as_unit(unit)
 1620: 
 1621:     index = DatetimeIndex(expected_index_values)
 1622:     expected = DataFrame([1.0] + ([np.nan] * 21) + [2.0], index=index)
 1623:     tm.assert_frame_equal(result, expected)
 1624: 
 1625: 
 1626: def test_resample_dst_anchor(unit):
 1627:     # 5172
 1628:     dti = DatetimeIndex([datetime(2012, 11, 4, 23)], tz="US/Eastern").as_unit(unit)
 1629:     df = DataFrame([5], index=dti)
 1630: 
 1631:     dti = DatetimeIndex(df.index.normalize(), freq="D").as_unit(unit)
 1632:     expected = DataFrame([5], index=dti)
 1633:     tm.assert_frame_equal(df.resample(rule="D").sum(), expected)
 1634:     df.resample(rule="MS").sum()
 1635:     tm.assert_frame_equal(
 1636:         df.resample(rule="MS").sum(),
 1637:         DataFrame(
 1638:             [5],
 1639:             index=DatetimeIndex(
 1640:                 [datetime(2012, 11, 1)], tz="US/Eastern", freq="MS"
 1641:             ).as_unit(unit),
 1642:         ),
 1643:     )
 1644: 
 1645: 
 1646: def test_resample_dst_anchor2(unit):
 1647:     dti = date_range(
 1648:         "2013-09-30", "2013-11-02", freq="30Min", tz="Europe/Paris"
 1649:     ).as_unit(unit)
 1650:     values = range(dti.size)
 1651:     df = DataFrame({"a": values, "b": values, "c": values}, index=dti, dtype="int64")
 1652:     how = {"a": "min", "b": "max", "c": "count"}
 1653: 
 1654:     rs = df.resample("W-MON")
 1655:     result = rs.agg(how)[["a", "b", "c"]]
 1656:     expected = DataFrame(
 1657:         {
 1658:             "a": [0, 48, 384, 720, 1056, 1394],
 1659:             "b": [47, 383, 719, 1055, 1393, 1586],
 1660:             "c": [48, 336, 336, 336, 338, 193],
 1661:         },
 1662:         index=date_range(
 1663:             "9/30/2013", "11/4/2013", freq="W-MON", tz="Europe/Paris"
 1664:         ).as_unit(unit),
 1665:     )
 1666:     tm.assert_frame_equal(
 1667:         result,
 1668:         expected,
 1669:         "W-MON Frequency",
 1670:     )
 1671: 
 1672:     rs2 = df.resample("2W-MON")
 1673:     result2 = rs2.agg(how)[["a", "b", "c"]]
 1674:     expected2 = DataFrame(
 1675:         {
 1676:             "a": [0, 48, 720, 1394],
 1677:             "b": [47, 719, 1393, 1586],
 1678:             "c": [48, 672, 674, 193],
 1679:         },
 1680:         index=date_range(
 1681:             "9/30/2013", "11/11/2013", freq="2W-MON", tz="Europe/Paris"
 1682:         ).as_unit(unit),
 1683:     )
 1684:     tm.assert_frame_equal(
 1685:         result2,
 1686:         expected2,
 1687:         "2W-MON Frequency",
 1688:     )
 1689: 
 1690:     rs3 = df.resample("MS")
 1691:     result3 = rs3.agg(how)[["a", "b", "c"]]
 1692:     expected3 = DataFrame(
 1693:         {"a": [0, 48, 1538], "b": [47, 1537, 1586], "c": [48, 1490, 49]},
 1694:         index=date_range("9/1/2013", "11/1/2013", freq="MS", tz="Europe/Paris").as_unit(
 1695:             unit
 1696:         ),
 1697:     )
 1698:     tm.assert_frame_equal(
 1699:         result3,
 1700:         expected3,
 1701:         "MS Frequency",
 1702:     )
 1703: 
 1704:     rs4 = df.resample("2MS")
 1705:     result4 = rs4.agg(how)[["a", "b", "c"]]
 1706:     expected4 = DataFrame(
 1707:         {"a": [0, 1538], "b": [1537, 1586], "c": [1538, 49]},
 1708:         index=date_range(
 1709:             "9/1/2013", "11/1/2013", freq="2MS", tz="Europe/Paris"
 1710:         ).as_unit(unit),
 1711:     )
 1712:     tm.assert_frame_equal(
 1713:         result4,
 1714:         expected4,
 1715:         "2MS Frequency",
 1716:     )
 1717: 
 1718:     df_daily = df["10/26/2013":"10/29/2013"]
 1719:     rs_d = df_daily.resample("D")
 1720:     result_d = rs_d.agg({"a": "min", "b": "max", "c": "count"})[["a", "b", "c"]]
 1721:     expected_d = DataFrame(
 1722:         {
 1723:             "a": [1248, 1296, 1346, 1394],
 1724:             "b": [1295, 1345, 1393, 1441],
 1725:             "c": [48, 50, 48, 48],
 1726:         },
 1727:         index=date_range(
 1728:             "10/26/2013", "10/29/2013", freq="D", tz="Europe/Paris"
 1729:         ).as_unit(unit),
 1730:     )
 1731:     tm.assert_frame_equal(
 1732:         result_d,
 1733:         expected_d,
 1734:         "D Frequency",
 1735:     )
 1736: 
 1737: 
 1738: def test_downsample_across_dst(unit):
 1739:     # GH 8531
 1740:     tz = pytz.timezone("Europe/Berlin")
 1741:     dt = datetime(2014, 10, 26)
 1742:     dates = date_range(tz.localize(dt), periods=4, freq="2h").as_unit(unit)
 1743:     result = Series(5, index=dates).resample("h").mean()
 1744:     expected = Series(
 1745:         [5.0, np.nan] * 3 + [5.0],
 1746:         index=date_range(tz.localize(dt), periods=7, freq="h").as_unit(unit),
 1747:     )
 1748:     tm.assert_series_equal(result, expected)
 1749: 
 1750: 
 1751: def test_downsample_across_dst_weekly(unit):
 1752:     # GH 9119, GH 21459
 1753:     df = DataFrame(
 1754:         index=DatetimeIndex(
 1755:             ["2017-03-25", "2017-03-26", "2017-03-27", "2017-03-28", "2017-03-29"],
 1756:             tz="Europe/Amsterdam",
 1757:         ).as_unit(unit),
 1758:         data=[11, 12, 13, 14, 15],
 1759:     )
 1760:     result = df.resample("1W").sum()
 1761:     expected = DataFrame(
 1762:         [23, 42],
 1763:         index=DatetimeIndex(
 1764:             ["2017-03-26", "2017-04-02"], tz="Europe/Amsterdam", freq="W"
 1765:         ).as_unit(unit),
 1766:     )
 1767:     tm.assert_frame_equal(result, expected)
 1768: 
 1769: 
 1770: def test_downsample_across_dst_weekly_2(unit):
 1771:     # GH 9119, GH 21459
 1772:     idx = date_range("2013-04-01", "2013-05-01", tz="Europe/London", freq="h").as_unit(
 1773:         unit
 1774:     )
 1775:     s = Series(index=idx, dtype=np.float64)
 1776:     result = s.resample("W").mean()
 1777:     expected = Series(
 1778:         index=date_range("2013-04-07", freq="W", periods=5, tz="Europe/London").as_unit(
 1779:             unit
 1780:         ),
 1781:         dtype=np.float64,
 1782:     )
 1783:     tm.assert_series_equal(result, expected)
 1784: 
 1785: 
 1786: def test_downsample_dst_at_midnight(unit):
 1787:     # GH 25758
 1788:     start = datetime(2018, 11, 3, 12)
 1789:     end = datetime(2018, 11, 5, 12)
 1790:     index = date_range(start, end, freq="1h").as_unit(unit)
 1791:     index = index.tz_localize("UTC").tz_convert("America/Havana")
 1792:     data = list(range(len(index)))
 1793:     dataframe = DataFrame(data, index=index)
 1794:     result = dataframe.groupby(Grouper(freq="1D")).mean()
 1795: 
 1796:     dti = date_range("2018-11-03", periods=3).tz_localize(
 1797:         "America/Havana", ambiguous=True
 1798:     )
 1799:     dti = DatetimeIndex(dti, freq="D").as_unit(unit)
 1800:     expected = DataFrame([7.5, 28.0, 44.5], index=dti)
 1801:     tm.assert_frame_equal(result, expected)
 1802: 
 1803: 
 1804: def test_resample_with_nat(unit):
 1805:     # GH 13020
 1806:     index = DatetimeIndex(
 1807:         [
 1808:             pd.NaT,
 1809:             "1970-01-01 00:00:00",
 1810:             pd.NaT,
 1811:             "1970-01-01 00:00:01",
 1812:             "1970-01-01 00:00:02",
 1813:         ]
 1814:     ).as_unit(unit)
 1815:     frame = DataFrame([2, 3, 5, 7, 11], index=index)
 1816: 
 1817:     index_1s = DatetimeIndex(
 1818:         ["1970-01-01 00:00:00", "1970-01-01 00:00:01", "1970-01-01 00:00:02"]
 1819:     ).as_unit(unit)
 1820:     frame_1s = DataFrame([3.0, 7.0, 11.0], index=index_1s)
 1821:     tm.assert_frame_equal(frame.resample("1s").mean(), frame_1s)
 1822: 
 1823:     index_2s = DatetimeIndex(["1970-01-01 00:00:00", "1970-01-01 00:00:02"]).as_unit(
 1824:         unit
 1825:     )
 1826:     frame_2s = DataFrame([5.0, 11.0], index=index_2s)
 1827:     tm.assert_frame_equal(frame.resample("2s").mean(), frame_2s)
 1828: 
 1829:     index_3s = DatetimeIndex(["1970-01-01 00:00:00"]).as_unit(unit)
 1830:     frame_3s = DataFrame([7.0], index=index_3s)
 1831:     tm.assert_frame_equal(frame.resample("3s").mean(), frame_3s)
 1832: 
 1833:     tm.assert_frame_equal(frame.resample("60s").mean(), frame_3s)
 1834: 
 1835: 
 1836: def test_resample_datetime_values(unit):
 1837:     # GH 13119
 1838:     # check that datetime dtype is preserved when NaT values are
 1839:     # introduced by the resampling
 1840: 
 1841:     dates = [datetime(2016, 1, 15), datetime(2016, 1, 19)]
 1842:     df = DataFrame({"timestamp": dates}, index=dates)
 1843:     df.index = df.index.as_unit(unit)
 1844: 
 1845:     exp = Series(
 1846:         [datetime(2016, 1, 15), pd.NaT, datetime(2016, 1, 19)],
 1847:         index=date_range("2016-01-15", periods=3, freq="2D").as_unit(unit),
 1848:         name="timestamp",
 1849:     )
 1850: 
 1851:     res = df.resample("2D").first()["timestamp"]
 1852:     tm.assert_series_equal(res, exp)
 1853:     res = df["timestamp"].resample("2D").first()
 1854:     tm.assert_series_equal(res, exp)
 1855: 
 1856: 
 1857: def test_resample_apply_with_additional_args(series, unit):
 1858:     # GH 14615
 1859:     def f(data, add_arg):
 1860:         return np.mean(data) * add_arg
 1861: 
 1862:     series.index = series.index.as_unit(unit)
 1863: 
 1864:     multiplier = 10
 1865:     result = series.resample("D").apply(f, multiplier)
 1866:     expected = series.resample("D").mean().multiply(multiplier)
 1867:     tm.assert_series_equal(result, expected)
 1868: 
 1869:     # Testing as kwarg
 1870:     result = series.resample("D").apply(f, add_arg=multiplier)
 1871:     expected = series.resample("D").mean().multiply(multiplier)
 1872:     tm.assert_series_equal(result, expected)
 1873: 
 1874: 
 1875: def test_resample_apply_with_additional_args2():
 1876:     # Testing dataframe
 1877:     def f(data, add_arg):
 1878:         return np.mean(data) * add_arg
 1879: 
 1880:     multiplier = 10
 1881: 
 1882:     df = DataFrame({"A": 1, "B": 2}, index=date_range("2017", periods=10))
 1883:     msg = "DataFrameGroupBy.resample operated on the grouping columns"
 1884:     with tm.assert_produces_warning(DeprecationWarning, match=msg):
 1885:         result = df.groupby("A").resample("D").agg(f, multiplier).astype(float)
 1886:     msg = "DataFrameGroupBy.resample operated on the grouping columns"
 1887:     with tm.assert_produces_warning(DeprecationWarning, match=msg):
 1888:         expected = df.groupby("A").resample("D").mean().multiply(multiplier)
 1889:     tm.assert_frame_equal(result, expected)
 1890: 
 1891: 
 1892: @pytest.mark.parametrize("k", [1, 2, 3])
 1893: @pytest.mark.parametrize(
 1894:     "n1, freq1, n2, freq2",
 1895:     [
 1896:         (30, "s", 0.5, "Min"),
 1897:         (60, "s", 1, "Min"),
 1898:         (3600, "s", 1, "h"),
 1899:         (60, "Min", 1, "h"),
 1900:         (21600, "s", 0.25, "D"),
 1901:         (86400, "s", 1, "D"),
 1902:         (43200, "s", 0.5, "D"),
 1903:         (1440, "Min", 1, "D"),
 1904:         (12, "h", 0.5, "D"),
 1905:         (24, "h", 1, "D"),
 1906:     ],
 1907: )
 1908: def test_resample_equivalent_offsets(n1, freq1, n2, freq2, k, unit):
 1909:     # GH 24127
 1910:     n1_ = n1 * k
 1911:     n2_ = n2 * k
 1912:     dti = date_range("1991-09-05", "1991-09-12", freq=freq1).as_unit(unit)
 1913:     ser = Series(range(len(dti)), index=dti)
 1914: 
 1915:     result1 = ser.resample(str(n1_) + freq1).mean()
 1916:     result2 = ser.resample(str(n2_) + freq2).mean()
 1917:     tm.assert_series_equal(result1, result2)
 1918: 
 1919: 
 1920: @pytest.mark.parametrize(
 1921:     "first,last,freq,exp_first,exp_last",
 1922:     [
 1923:         ("19910905", "19920406", "D", "19910905", "19920407"),
 1924:         ("19910905 00:00", "19920406 06:00", "D", "19910905", "19920407"),
 1925:         ("19910905 06:00", "19920406 06:00", "h", "19910905 06:00", "19920406 07:00"),
 1926:         ("19910906", "19920406", "ME", "19910831", "19920430"),
 1927:         ("19910831", "19920430", "ME", "19910831", "19920531"),
 1928:         ("1991-08", "1992-04", "ME", "19910831", "19920531"),
 1929:     ],
 1930: )
 1931: def test_get_timestamp_range_edges(first, last, freq, exp_first, exp_last, unit):
 1932:     first = Period(first)
 1933:     first = first.to_timestamp(first.freq).as_unit(unit)
 1934:     last = Period(last)
 1935:     last = last.to_timestamp(last.freq).as_unit(unit)
 1936: 
 1937:     exp_first = Timestamp(exp_first)
 1938:     exp_last = Timestamp(exp_last)
 1939: 
 1940:     freq = pd.tseries.frequencies.to_offset(freq)
 1941:     result = _get_timestamp_range_edges(first, last, freq, unit="ns")
 1942:     expected = (exp_first, exp_last)
 1943:     assert result == expected
 1944: 
 1945: 
 1946: @pytest.mark.parametrize("duplicates", [True, False])
 1947: def test_resample_apply_product(duplicates, unit):
 1948:     # GH 5586
 1949:     index = date_range(start="2012-01-31", freq="ME", periods=12).as_unit(unit)
 1950: 
 1951:     ts = Series(range(12), index=index)
 1952:     df = DataFrame({"A": ts, "B": ts + 2})
 1953:     if duplicates:
 1954:         df.columns = ["A", "A"]
 1955: 
 1956:     msg = "using DatetimeIndexResampler.prod"
 1957:     with tm.assert_produces_warning(FutureWarning, match=msg):
 1958:         result = df.resample("QE").apply(np.prod)
 1959:     expected = DataFrame(
 1960:         np.array([[0, 24], [60, 210], [336, 720], [990, 1716]], dtype=np.int64),
 1961:         index=DatetimeIndex(
 1962:             ["2012-03-31", "2012-06-30", "2012-09-30", "2012-12-31"], freq="QE-DEC"
 1963:         ).as_unit(unit),
 1964:         columns=df.columns,
 1965:     )
 1966:     tm.assert_frame_equal(result, expected)
 1967: 
 1968: 
 1969: @pytest.mark.parametrize(
 1970:     "first,last,freq_in,freq_out,exp_last",
 1971:     [
 1972:         (
 1973:             "2020-03-28",
 1974:             "2020-03-31",
 1975:             "D",
 1976:             "24h",
 1977:             "2020-03-30 01:00",
 1978:         ),  # includes transition into DST
 1979:         (
 1980:             "2020-03-28",
 1981:             "2020-10-27",
 1982:             "D",
 1983:             "24h",
 1984:             "2020-10-27 00:00",
 1985:         ),  # includes transition into and out of DST
 1986:         (
 1987:             "2020-10-25",
 1988:             "2020-10-27",
 1989:             "D",
 1990:             "24h",
 1991:             "2020-10-26 23:00",
 1992:         ),  # includes transition out of DST
 1993:         (
 1994:             "2020-03-28",
 1995:             "2020-03-31",
 1996:             "24h",
 1997:             "D",
 1998:             "2020-03-30 00:00",
 1999:         ),  # same as above, but from 24H to D
 2000:         ("2020-03-28", "2020-10-27", "24h", "D", "2020-10-27 00:00"),
 2001:         ("2020-10-25", "2020-10-27", "24h", "D", "2020-10-26 00:00"),
 2002:     ],
 2003: )
 2004: def test_resample_calendar_day_with_dst(
 2005:     first: str, last: str, freq_in: str, freq_out: str, exp_last: str, unit
 2006: ):
 2007:     # GH 35219
 2008:     ts = Series(
 2009:         1.0, date_range(first, last, freq=freq_in, tz="Europe/Amsterdam").as_unit(unit)
 2010:     )
 2011:     result = ts.resample(freq_out).ffill()
 2012:     expected = Series(
 2013:         1.0,
 2014:         date_range(first, exp_last, freq=freq_out, tz="Europe/Amsterdam").as_unit(unit),
 2015:     )
 2016:     tm.assert_series_equal(result, expected)
 2017: 
 2018: 
 2019: @pytest.mark.parametrize("func", ["min", "max", "first", "last"])
 2020: def test_resample_aggregate_functions_min_count(func, unit):
 2021:     # GH#37768
 2022:     index = date_range(start="2020", freq="ME", periods=3).as_unit(unit)
 2023:     ser = Series([1, np.nan, np.nan], index)
 2024:     result = getattr(ser.resample("QE"), func)(min_count=2)
 2025:     expected = Series(
 2026:         [np.nan],
 2027:         index=DatetimeIndex(["2020-03-31"], freq="QE-DEC").as_unit(unit),
 2028:     )
 2029:     tm.assert_series_equal(result, expected)
 2030: 
 2031: 
 2032: def test_resample_unsigned_int(any_unsigned_int_numpy_dtype, unit):
 2033:     # gh-43329
 2034:     df = DataFrame(
 2035:         index=date_range(start="2000-01-01", end="2000-01-03 23", freq="12h").as_unit(
 2036:             unit
 2037:         ),
 2038:         columns=["x"],
 2039:         data=[0, 1, 0] * 2,
 2040:         dtype=any_unsigned_int_numpy_dtype,
 2041:     )
 2042:     df = df.loc[(df.index < "2000-01-02") | (df.index > "2000-01-03"), :]
 2043: 
 2044:     result = df.resample("D").max()
 2045: 
 2046:     expected = DataFrame(
 2047:         [1, np.nan, 0],
 2048:         columns=["x"],
 2049:         index=date_range(start="2000-01-01", end="2000-01-03 23", freq="D").as_unit(
 2050:             unit
 2051:         ),
 2052:     )
 2053:     tm.assert_frame_equal(result, expected)
 2054: 
 2055: 
 2056: def test_long_rule_non_nano():
 2057:     # https://github.com/pandas-dev/pandas/issues/51024
 2058:     idx = date_range("0300-01-01", "2000-01-01", unit="s", freq="100YE")
 2059:     ser = Series([1, 4, 2, 8, 5, 7, 1, 4, 2, 8, 5, 7, 1, 4, 2, 8, 5], index=idx)
 2060:     result = ser.resample("200YE").mean()
 2061:     expected_idx = DatetimeIndex(
 2062:         np.array(
 2063:             [
 2064:                 "0300-12-31",
 2065:                 "0500-12-31",
 2066:                 "0700-12-31",
 2067:                 "0900-12-31",
 2068:                 "1100-12-31",
 2069:                 "1300-12-31",
 2070:                 "1500-12-31",
 2071:                 "1700-12-31",
 2072:                 "1900-12-31",
 2073:             ]
 2074:         ).astype("datetime64[s]"),
 2075:         freq="200YE-DEC",
 2076:     )
 2077:     expected = Series([1.0, 3.0, 6.5, 4.0, 3.0, 6.5, 4.0, 3.0, 6.5], index=expected_idx)
 2078:     tm.assert_series_equal(result, expected)
 2079: 
 2080: 
 2081: def test_resample_empty_series_with_tz():
 2082:     # GH#53664
 2083:     df = DataFrame({"ts": [], "values": []}).astype(
 2084:         {"ts": "datetime64[ns, Atlantic/Faroe]"}
 2085:     )
 2086:     result = df.resample("2MS", on="ts", closed="left", label="left", origin="start")[
 2087:         "values"
 2088:     ].sum()
 2089: 
 2090:     expected_idx = DatetimeIndex(
 2091:         [], freq="2MS", name="ts", dtype="datetime64[ns, Atlantic/Faroe]"
 2092:     )
 2093:     expected = Series([], index=expected_idx, name="values", dtype="float64")
 2094:     tm.assert_series_equal(result, expected)
 2095: 
 2096: 
 2097: @pytest.mark.parametrize(
 2098:     "freq, freq_depr",
 2099:     [
 2100:         ("2ME", "2M"),
 2101:         ("2QE", "2Q"),
 2102:         ("2QE-SEP", "2Q-SEP"),
 2103:         ("1YE", "1Y"),
 2104:         ("2YE-MAR", "2Y-MAR"),
 2105:         ("1YE", "1A"),
 2106:         ("2YE-MAR", "2A-MAR"),
 2107:     ],
 2108: )
 2109: def test_resample_M_Q_Y_A_deprecated(freq, freq_depr):
 2110:     # GH#9586
 2111:     depr_msg = f"'{freq_depr[1:]}' is deprecated and will be removed "
 2112:     f"in a future version, please use '{freq[1:]}' instead."
 2113: 
 2114:     s = Series(range(10), index=date_range("20130101", freq="d", periods=10))
 2115:     expected = s.resample(freq).mean()
 2116:     with tm.assert_produces_warning(FutureWarning, match=depr_msg):
 2117:         result = s.resample(freq_depr).mean()
 2118:     tm.assert_series_equal(result, expected)
 2119: 
 2120: 
 2121: @pytest.mark.parametrize(
 2122:     "freq, freq_depr",
 2123:     [
 2124:         ("2BME", "2BM"),
 2125:         ("2BQE", "2BQ"),
 2126:         ("2BQE-MAR", "2BQ-MAR"),
 2127:     ],
 2128: )
 2129: def test_resample_BM_BQ_deprecated(freq, freq_depr):
 2130:     # GH#52064
 2131:     depr_msg = f"'{freq_depr[1:]}' is deprecated and will be removed "
 2132:     f"in a future version, please use '{freq[1:]}' instead."
 2133: 
 2134:     s = Series(range(10), index=date_range("20130101", freq="d", periods=10))
 2135:     expected = s.resample(freq).mean()
 2136:     with tm.assert_produces_warning(FutureWarning, match=depr_msg):
 2137:         result = s.resample(freq_depr).mean()
 2138:     tm.assert_series_equal(result, expected)
 2139: 
 2140: 
 2141: def test_resample_ms_closed_right(unit):
 2142:     # https://github.com/pandas-dev/pandas/issues/55271
 2143:     dti = date_range(start="2020-01-31", freq="1min", periods=6000, unit=unit)
 2144:     df = DataFrame({"ts": dti}, index=dti)
 2145:     grouped = df.resample("MS", closed="right")
 2146:     result = grouped.last()
 2147:     exp_dti = DatetimeIndex(
 2148:         [datetime(2020, 1, 1), datetime(2020, 2, 1)], freq="MS"
 2149:     ).as_unit(unit)
 2150:     expected = DataFrame(
 2151:         {"ts": [datetime(2020, 2, 1), datetime(2020, 2, 4, 3, 59)]},
 2152:         index=exp_dti,
 2153:     ).astype(f"M8[{unit}]")
 2154:     tm.assert_frame_equal(result, expected)
 2155: 
 2156: 
 2157: @pytest.mark.parametrize("freq", ["B", "C"])
 2158: def test_resample_c_b_closed_right(freq: str, unit):
 2159:     # https://github.com/pandas-dev/pandas/issues/55281
 2160:     dti = date_range(start="2020-01-31", freq="1min", periods=6000, unit=unit)
 2161:     df = DataFrame({"ts": dti}, index=dti)
 2162:     grouped = df.resample(freq, closed="right")
 2163:     result = grouped.last()
 2164: 
 2165:     exp_dti = DatetimeIndex(
 2166:         [
 2167:             datetime(2020, 1, 30),
 2168:             datetime(2020, 1, 31),
 2169:             datetime(2020, 2, 3),
 2170:             datetime(2020, 2, 4),
 2171:         ],
 2172:         freq=freq,
 2173:     ).as_unit(unit)
 2174:     expected = DataFrame(
 2175:         {
 2176:             "ts": [
 2177:                 datetime(2020, 1, 31),
 2178:                 datetime(2020, 2, 3),
 2179:                 datetime(2020, 2, 4),
 2180:                 datetime(2020, 2, 4, 3, 59),
 2181:             ]
 2182:         },
 2183:         index=exp_dti,
 2184:     ).astype(f"M8[{unit}]")
 2185:     tm.assert_frame_equal(result, expected)
 2186: 
 2187: 
 2188: def test_resample_b_55282(unit):
 2189:     # https://github.com/pandas-dev/pandas/issues/55282
 2190:     dti = date_range("2023-09-26", periods=6, freq="12h", unit=unit)
 2191:     ser = Series([1, 2, 3, 4, 5, 6], index=dti)
 2192:     result = ser.resample("B", closed="right", label="right").mean()
 2193: 
 2194:     exp_dti = DatetimeIndex(
 2195:         [
 2196:             datetime(2023, 9, 26),
 2197:             datetime(2023, 9, 27),
 2198:             datetime(2023, 9, 28),
 2199:             datetime(2023, 9, 29),
 2200:         ],
 2201:         freq="B",
 2202:     ).as_unit(unit)
 2203:     expected = Series(
 2204:         [1.0, 2.5, 4.5, 6.0],
 2205:         index=exp_dti,
 2206:     )
 2207:     tm.assert_series_equal(result, expected)
 2208: 
 2209: 
 2210: @td.skip_if_no("pyarrow")
 2211: @pytest.mark.parametrize(
 2212:     "tz",
 2213:     [
 2214:         None,
 2215:         pytest.param(
 2216:             "UTC",
 2217:             marks=pytest.mark.xfail(
 2218:                 condition=is_platform_windows(),
 2219:                 reason="TODO: Set ARROW_TIMEZONE_DATABASE env var in CI",
 2220:             ),
 2221:         ),
 2222:     ],
 2223: )
 2224: def test_arrow_timestamp_resample(tz):
 2225:     # GH 56371
 2226:     idx = Series(date_range("2020-01-01", periods=5), dtype="timestamp[ns][pyarrow]")
 2227:     if tz is not None:
 2228:         idx = idx.dt.tz_localize(tz)
 2229:     expected = Series(np.arange(5, dtype=np.float64), index=idx)
 2230:     result = expected.resample("1D").mean()
 2231:     tm.assert_series_equal(result, expected)
