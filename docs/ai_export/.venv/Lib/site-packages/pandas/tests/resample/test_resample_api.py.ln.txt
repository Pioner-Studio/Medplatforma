    1: from datetime import datetime
    2: import re
    3: 
    4: import numpy as np
    5: import pytest
    6: 
    7: from pandas._libs import lib
    8: from pandas.errors import UnsupportedFunctionCall
    9: 
   10: import pandas as pd
   11: from pandas import (
   12:     DataFrame,
   13:     NamedAgg,
   14:     Series,
   15: )
   16: import pandas._testing as tm
   17: from pandas.core.indexes.datetimes import date_range
   18: 
   19: 
   20: @pytest.fixture
   21: def dti():
   22:     return date_range(start=datetime(2005, 1, 1), end=datetime(2005, 1, 10), freq="Min")
   23: 
   24: 
   25: @pytest.fixture
   26: def _test_series(dti):
   27:     return Series(np.random.default_rng(2).random(len(dti)), dti)
   28: 
   29: 
   30: @pytest.fixture
   31: def test_frame(dti, _test_series):
   32:     return DataFrame({"A": _test_series, "B": _test_series, "C": np.arange(len(dti))})
   33: 
   34: 
   35: def test_str(_test_series):
   36:     r = _test_series.resample("h")
   37:     assert (
   38:         "DatetimeIndexResampler [freq=<Hour>, axis=0, closed=left, "
   39:         "label=left, convention=start, origin=start_day]" in str(r)
   40:     )
   41: 
   42:     r = _test_series.resample("h", origin="2000-01-01")
   43:     assert (
   44:         "DatetimeIndexResampler [freq=<Hour>, axis=0, closed=left, "
   45:         "label=left, convention=start, origin=2000-01-01 00:00:00]" in str(r)
   46:     )
   47: 
   48: 
   49: def test_api(_test_series):
   50:     r = _test_series.resample("h")
   51:     result = r.mean()
   52:     assert isinstance(result, Series)
   53:     assert len(result) == 217
   54: 
   55:     r = _test_series.to_frame().resample("h")
   56:     result = r.mean()
   57:     assert isinstance(result, DataFrame)
   58:     assert len(result) == 217
   59: 
   60: 
   61: def test_groupby_resample_api():
   62:     # GH 12448
   63:     # .groupby(...).resample(...) hitting warnings
   64:     # when appropriate
   65:     df = DataFrame(
   66:         {
   67:             "date": date_range(start="2016-01-01", periods=4, freq="W"),
   68:             "group": [1, 1, 2, 2],
   69:             "val": [5, 6, 7, 8],
   70:         }
   71:     ).set_index("date")
   72: 
   73:     # replication step
   74:     i = (
   75:         date_range("2016-01-03", periods=8).tolist()
   76:         + date_range("2016-01-17", periods=8).tolist()
   77:     )
   78:     index = pd.MultiIndex.from_arrays([[1] * 8 + [2] * 8, i], names=["group", "date"])
   79:     expected = DataFrame({"val": [5] * 7 + [6] + [7] * 7 + [8]}, index=index)
   80:     msg = "DataFrameGroupBy.apply operated on the grouping columns"
   81:     with tm.assert_produces_warning(DeprecationWarning, match=msg):
   82:         result = df.groupby("group").apply(lambda x: x.resample("1D").ffill())[["val"]]
   83:     tm.assert_frame_equal(result, expected)
   84: 
   85: 
   86: def test_groupby_resample_on_api():
   87:     # GH 15021
   88:     # .groupby(...).resample(on=...) results in an unexpected
   89:     # keyword warning.
   90:     df = DataFrame(
   91:         {
   92:             "key": ["A", "B"] * 5,
   93:             "dates": date_range("2016-01-01", periods=10),
   94:             "values": np.random.default_rng(2).standard_normal(10),
   95:         }
   96:     )
   97: 
   98:     expected = df.set_index("dates").groupby("key").resample("D").mean()
   99:     result = df.groupby("key").resample("D", on="dates").mean()
  100:     tm.assert_frame_equal(result, expected)
  101: 
  102: 
  103: def test_resample_group_keys():
  104:     df = DataFrame({"A": 1, "B": 2}, index=date_range("2000", periods=10))
  105:     expected = df.copy()
  106: 
  107:     # group_keys=False
  108:     g = df.resample("5D", group_keys=False)
  109:     result = g.apply(lambda x: x)
  110:     tm.assert_frame_equal(result, expected)
  111: 
  112:     # group_keys defaults to False
  113:     g = df.resample("5D")
  114:     result = g.apply(lambda x: x)
  115:     tm.assert_frame_equal(result, expected)
  116: 
  117:     # group_keys=True
  118:     expected.index = pd.MultiIndex.from_arrays(
  119:         [
  120:             pd.to_datetime(["2000-01-01", "2000-01-06"]).as_unit("ns").repeat(5),
  121:             expected.index,
  122:         ]
  123:     )
  124:     g = df.resample("5D", group_keys=True)
  125:     result = g.apply(lambda x: x)
  126:     tm.assert_frame_equal(result, expected)
  127: 
  128: 
  129: def test_pipe(test_frame, _test_series):
  130:     # GH17905
  131: 
  132:     # series
  133:     r = _test_series.resample("h")
  134:     expected = r.max() - r.mean()
  135:     result = r.pipe(lambda x: x.max() - x.mean())
  136:     tm.assert_series_equal(result, expected)
  137: 
  138:     # dataframe
  139:     r = test_frame.resample("h")
  140:     expected = r.max() - r.mean()
  141:     result = r.pipe(lambda x: x.max() - x.mean())
  142:     tm.assert_frame_equal(result, expected)
  143: 
  144: 
  145: def test_getitem(test_frame):
  146:     r = test_frame.resample("h")
  147:     tm.assert_index_equal(r._selected_obj.columns, test_frame.columns)
  148: 
  149:     r = test_frame.resample("h")["B"]
  150:     assert r._selected_obj.name == test_frame.columns[1]
  151: 
  152:     # technically this is allowed
  153:     r = test_frame.resample("h")["A", "B"]
  154:     tm.assert_index_equal(r._selected_obj.columns, test_frame.columns[[0, 1]])
  155: 
  156:     r = test_frame.resample("h")["A", "B"]
  157:     tm.assert_index_equal(r._selected_obj.columns, test_frame.columns[[0, 1]])
  158: 
  159: 
  160: @pytest.mark.parametrize("key", [["D"], ["A", "D"]])
  161: def test_select_bad_cols(key, test_frame):
  162:     g = test_frame.resample("h")
  163:     # 'A' should not be referenced as a bad column...
  164:     # will have to rethink regex if you change message!
  165:     msg = r"^\"Columns not found: 'D'\"$"
  166:     with pytest.raises(KeyError, match=msg):
  167:         g[key]
  168: 
  169: 
  170: def test_attribute_access(test_frame):
  171:     r = test_frame.resample("h")
  172:     tm.assert_series_equal(r.A.sum(), r["A"].sum())
  173: 
  174: 
  175: @pytest.mark.parametrize("attr", ["groups", "ngroups", "indices"])
  176: def test_api_compat_before_use(attr):
  177:     # make sure that we are setting the binner
  178:     # on these attributes
  179:     rng = date_range("1/1/2012", periods=100, freq="s")
  180:     ts = Series(np.arange(len(rng)), index=rng)
  181:     rs = ts.resample("30s")
  182: 
  183:     # before use
  184:     getattr(rs, attr)
  185: 
  186:     # after grouper is initialized is ok
  187:     rs.mean()
  188:     getattr(rs, attr)
  189: 
  190: 
  191: def tests_raises_on_nuisance(test_frame):
  192:     df = test_frame
  193:     df["D"] = "foo"
  194:     r = df.resample("h")
  195:     result = r[["A", "B"]].mean()
  196:     expected = pd.concat([r.A.mean(), r.B.mean()], axis=1)
  197:     tm.assert_frame_equal(result, expected)
  198: 
  199:     expected = r[["A", "B", "C"]].mean()
  200:     msg = re.escape("agg function failed [how->mean,dtype->")
  201:     with pytest.raises(TypeError, match=msg):
  202:         r.mean()
  203:     result = r.mean(numeric_only=True)
  204:     tm.assert_frame_equal(result, expected)
  205: 
  206: 
  207: def test_downsample_but_actually_upsampling():
  208:     # this is reindex / asfreq
  209:     rng = date_range("1/1/2012", periods=100, freq="s")
  210:     ts = Series(np.arange(len(rng), dtype="int64"), index=rng)
  211:     result = ts.resample("20s").asfreq()
  212:     expected = Series(
  213:         [0, 20, 40, 60, 80],
  214:         index=date_range("2012-01-01 00:00:00", freq="20s", periods=5),
  215:     )
  216:     tm.assert_series_equal(result, expected)
  217: 
  218: 
  219: def test_combined_up_downsampling_of_irregular():
  220:     # since we are really doing an operation like this
  221:     # ts2.resample('2s').mean().ffill()
  222:     # preserve these semantics
  223: 
  224:     rng = date_range("1/1/2012", periods=100, freq="s")
  225:     ts = Series(np.arange(len(rng)), index=rng)
  226:     ts2 = ts.iloc[[0, 1, 2, 3, 5, 7, 11, 15, 16, 25, 30]]
  227: 
  228:     result = ts2.resample("2s").mean().ffill()
  229:     expected = Series(
  230:         [
  231:             0.5,
  232:             2.5,
  233:             5.0,
  234:             7.0,
  235:             7.0,
  236:             11.0,
  237:             11.0,
  238:             15.0,
  239:             16.0,
  240:             16.0,
  241:             16.0,
  242:             16.0,
  243:             25.0,
  244:             25.0,
  245:             25.0,
  246:             30.0,
  247:         ],
  248:         index=pd.DatetimeIndex(
  249:             [
  250:                 "2012-01-01 00:00:00",
  251:                 "2012-01-01 00:00:02",
  252:                 "2012-01-01 00:00:04",
  253:                 "2012-01-01 00:00:06",
  254:                 "2012-01-01 00:00:08",
  255:                 "2012-01-01 00:00:10",
  256:                 "2012-01-01 00:00:12",
  257:                 "2012-01-01 00:00:14",
  258:                 "2012-01-01 00:00:16",
  259:                 "2012-01-01 00:00:18",
  260:                 "2012-01-01 00:00:20",
  261:                 "2012-01-01 00:00:22",
  262:                 "2012-01-01 00:00:24",
  263:                 "2012-01-01 00:00:26",
  264:                 "2012-01-01 00:00:28",
  265:                 "2012-01-01 00:00:30",
  266:             ],
  267:             dtype="datetime64[ns]",
  268:             freq="2s",
  269:         ),
  270:     )
  271:     tm.assert_series_equal(result, expected)
  272: 
  273: 
  274: def test_transform_series(_test_series):
  275:     r = _test_series.resample("20min")
  276:     expected = _test_series.groupby(pd.Grouper(freq="20min")).transform("mean")
  277:     result = r.transform("mean")
  278:     tm.assert_series_equal(result, expected)
  279: 
  280: 
  281: @pytest.mark.parametrize("on", [None, "date"])
  282: def test_transform_frame(on):
  283:     # GH#47079
  284:     index = date_range(datetime(2005, 1, 1), datetime(2005, 1, 10), freq="D")
  285:     index.name = "date"
  286:     df = DataFrame(
  287:         np.random.default_rng(2).random((10, 2)), columns=list("AB"), index=index
  288:     )
  289:     expected = df.groupby(pd.Grouper(freq="20min")).transform("mean")
  290:     if on == "date":
  291:         # Move date to being a column; result will then have a RangeIndex
  292:         expected = expected.reset_index(drop=True)
  293:         df = df.reset_index()
  294: 
  295:     r = df.resample("20min", on=on)
  296:     result = r.transform("mean")
  297:     tm.assert_frame_equal(result, expected)
  298: 
  299: 
  300: def test_fillna():
  301:     # need to upsample here
  302:     rng = date_range("1/1/2012", periods=10, freq="2s")
  303:     ts = Series(np.arange(len(rng), dtype="int64"), index=rng)
  304:     r = ts.resample("s")
  305: 
  306:     expected = r.ffill()
  307:     msg = "DatetimeIndexResampler.fillna is deprecated"
  308:     with tm.assert_produces_warning(FutureWarning, match=msg):
  309:         result = r.fillna(method="ffill")
  310:     tm.assert_series_equal(result, expected)
  311: 
  312:     expected = r.bfill()
  313:     with tm.assert_produces_warning(FutureWarning, match=msg):
  314:         result = r.fillna(method="bfill")
  315:     tm.assert_series_equal(result, expected)
  316: 
  317:     msg2 = (
  318:         r"Invalid fill method\. Expecting pad \(ffill\), backfill "
  319:         r"\(bfill\) or nearest\. Got 0"
  320:     )
  321:     with pytest.raises(ValueError, match=msg2):
  322:         with tm.assert_produces_warning(FutureWarning, match=msg):
  323:             r.fillna(0)
  324: 
  325: 
  326: @pytest.mark.parametrize(
  327:     "func",
  328:     [
  329:         lambda x: x.resample("20min", group_keys=False),
  330:         lambda x: x.groupby(pd.Grouper(freq="20min"), group_keys=False),
  331:     ],
  332:     ids=["resample", "groupby"],
  333: )
  334: def test_apply_without_aggregation(func, _test_series):
  335:     # both resample and groupby should work w/o aggregation
  336:     t = func(_test_series)
  337:     result = t.apply(lambda x: x)
  338:     tm.assert_series_equal(result, _test_series)
  339: 
  340: 
  341: def test_apply_without_aggregation2(_test_series):
  342:     grouped = _test_series.to_frame(name="foo").resample("20min", group_keys=False)
  343:     result = grouped["foo"].apply(lambda x: x)
  344:     tm.assert_series_equal(result, _test_series.rename("foo"))
  345: 
  346: 
  347: def test_agg_consistency():
  348:     # make sure that we are consistent across
  349:     # similar aggregations with and w/o selection list
  350:     df = DataFrame(
  351:         np.random.default_rng(2).standard_normal((1000, 3)),
  352:         index=date_range("1/1/2012", freq="s", periods=1000),
  353:         columns=["A", "B", "C"],
  354:     )
  355: 
  356:     r = df.resample("3min")
  357: 
  358:     msg = r"Column\(s\) \['r1', 'r2'\] do not exist"
  359:     with pytest.raises(KeyError, match=msg):
  360:         r.agg({"r1": "mean", "r2": "sum"})
  361: 
  362: 
  363: def test_agg_consistency_int_str_column_mix():
  364:     # GH#39025
  365:     df = DataFrame(
  366:         np.random.default_rng(2).standard_normal((1000, 2)),
  367:         index=date_range("1/1/2012", freq="s", periods=1000),
  368:         columns=[1, "a"],
  369:     )
  370: 
  371:     r = df.resample("3min")
  372: 
  373:     msg = r"Column\(s\) \[2, 'b'\] do not exist"
  374:     with pytest.raises(KeyError, match=msg):
  375:         r.agg({2: "mean", "b": "sum"})
  376: 
  377: 
  378: # TODO(GH#14008): once GH 14008 is fixed, move these tests into
  379: # `Base` test class
  380: 
  381: 
  382: @pytest.fixture
  383: def index():
  384:     index = date_range(datetime(2005, 1, 1), datetime(2005, 1, 10), freq="D")
  385:     index.name = "date"
  386:     return index
  387: 
  388: 
  389: @pytest.fixture
  390: def df(index):
  391:     frame = DataFrame(
  392:         np.random.default_rng(2).random((10, 2)), columns=list("AB"), index=index
  393:     )
  394:     return frame
  395: 
  396: 
  397: @pytest.fixture
  398: def df_col(df):
  399:     return df.reset_index()
  400: 
  401: 
  402: @pytest.fixture
  403: def df_mult(df_col, index):
  404:     df_mult = df_col.copy()
  405:     df_mult.index = pd.MultiIndex.from_arrays(
  406:         [range(10), index], names=["index", "date"]
  407:     )
  408:     return df_mult
  409: 
  410: 
  411: @pytest.fixture
  412: def a_mean(df):
  413:     return df.resample("2D")["A"].mean()
  414: 
  415: 
  416: @pytest.fixture
  417: def a_std(df):
  418:     return df.resample("2D")["A"].std()
  419: 
  420: 
  421: @pytest.fixture
  422: def a_sum(df):
  423:     return df.resample("2D")["A"].sum()
  424: 
  425: 
  426: @pytest.fixture
  427: def b_mean(df):
  428:     return df.resample("2D")["B"].mean()
  429: 
  430: 
  431: @pytest.fixture
  432: def b_std(df):
  433:     return df.resample("2D")["B"].std()
  434: 
  435: 
  436: @pytest.fixture
  437: def b_sum(df):
  438:     return df.resample("2D")["B"].sum()
  439: 
  440: 
  441: @pytest.fixture
  442: def df_resample(df):
  443:     return df.resample("2D")
  444: 
  445: 
  446: @pytest.fixture
  447: def df_col_resample(df_col):
  448:     return df_col.resample("2D", on="date")
  449: 
  450: 
  451: @pytest.fixture
  452: def df_mult_resample(df_mult):
  453:     return df_mult.resample("2D", level="date")
  454: 
  455: 
  456: @pytest.fixture
  457: def df_grouper_resample(df):
  458:     return df.groupby(pd.Grouper(freq="2D"))
  459: 
  460: 
  461: @pytest.fixture(
  462:     params=["df_resample", "df_col_resample", "df_mult_resample", "df_grouper_resample"]
  463: )
  464: def cases(request):
  465:     return request.getfixturevalue(request.param)
  466: 
  467: 
  468: def test_agg_mixed_column_aggregation(cases, a_mean, a_std, b_mean, b_std, request):
  469:     expected = pd.concat([a_mean, a_std, b_mean, b_std], axis=1)
  470:     expected.columns = pd.MultiIndex.from_product([["A", "B"], ["mean", "std"]])
  471:     msg = "using SeriesGroupBy.[mean|std]"
  472:     # "date" is an index and a column, so get included in the agg
  473:     if "df_mult" in request.node.callspec.id:
  474:         date_mean = cases["date"].mean()
  475:         date_std = cases["date"].std()
  476:         expected = pd.concat([date_mean, date_std, expected], axis=1)
  477:         expected.columns = pd.MultiIndex.from_product(
  478:             [["date", "A", "B"], ["mean", "std"]]
  479:         )
  480:     with tm.assert_produces_warning(FutureWarning, match=msg):
  481:         result = cases.aggregate([np.mean, np.std])
  482:     tm.assert_frame_equal(result, expected)
  483: 
  484: 
  485: @pytest.mark.parametrize(
  486:     "agg",
  487:     [
  488:         {"func": {"A": np.mean, "B": np.std}},
  489:         {"A": ("A", np.mean), "B": ("B", np.std)},
  490:         {"A": NamedAgg("A", np.mean), "B": NamedAgg("B", np.std)},
  491:     ],
  492: )
  493: def test_agg_both_mean_std_named_result(cases, a_mean, b_std, agg):
  494:     msg = "using SeriesGroupBy.[mean|std]"
  495:     expected = pd.concat([a_mean, b_std], axis=1)
  496:     with tm.assert_produces_warning(FutureWarning, match=msg):
  497:         result = cases.aggregate(**agg)
  498:     tm.assert_frame_equal(result, expected, check_like=True)
  499: 
  500: 
  501: def test_agg_both_mean_std_dict_of_list(cases, a_mean, a_std):
  502:     expected = pd.concat([a_mean, a_std], axis=1)
  503:     expected.columns = pd.MultiIndex.from_tuples([("A", "mean"), ("A", "std")])
  504:     result = cases.aggregate({"A": ["mean", "std"]})
  505:     tm.assert_frame_equal(result, expected)
  506: 
  507: 
  508: @pytest.mark.parametrize(
  509:     "agg", [{"func": ["mean", "sum"]}, {"mean": "mean", "sum": "sum"}]
  510: )
  511: def test_agg_both_mean_sum(cases, a_mean, a_sum, agg):
  512:     expected = pd.concat([a_mean, a_sum], axis=1)
  513:     expected.columns = ["mean", "sum"]
  514:     result = cases["A"].aggregate(**agg)
  515:     tm.assert_frame_equal(result, expected)
  516: 
  517: 
  518: @pytest.mark.parametrize(
  519:     "agg",
  520:     [
  521:         {"A": {"mean": "mean", "sum": "sum"}},
  522:         {
  523:             "A": {"mean": "mean", "sum": "sum"},
  524:             "B": {"mean2": "mean", "sum2": "sum"},
  525:         },
  526:     ],
  527: )
  528: def test_agg_dict_of_dict_specificationerror(cases, agg):
  529:     msg = "nested renamer is not supported"
  530:     with pytest.raises(pd.errors.SpecificationError, match=msg):
  531:         cases.aggregate(agg)
  532: 
  533: 
  534: def test_agg_dict_of_lists(cases, a_mean, a_std, b_mean, b_std):
  535:     expected = pd.concat([a_mean, a_std, b_mean, b_std], axis=1)
  536:     expected.columns = pd.MultiIndex.from_tuples(
  537:         [("A", "mean"), ("A", "std"), ("B", "mean"), ("B", "std")]
  538:     )
  539:     result = cases.aggregate({"A": ["mean", "std"], "B": ["mean", "std"]})
  540:     tm.assert_frame_equal(result, expected, check_like=True)
  541: 
  542: 
  543: @pytest.mark.parametrize(
  544:     "agg",
  545:     [
  546:         {"func": {"A": np.sum, "B": lambda x: np.std(x, ddof=1)}},
  547:         {"A": ("A", np.sum), "B": ("B", lambda x: np.std(x, ddof=1))},
  548:         {"A": NamedAgg("A", np.sum), "B": NamedAgg("B", lambda x: np.std(x, ddof=1))},
  549:     ],
  550: )
  551: def test_agg_with_lambda(cases, agg):
  552:     # passed lambda
  553:     msg = "using SeriesGroupBy.sum"
  554:     rcustom = cases["B"].apply(lambda x: np.std(x, ddof=1))
  555:     expected = pd.concat([cases["A"].sum(), rcustom], axis=1)
  556:     with tm.assert_produces_warning(FutureWarning, match=msg):
  557:         result = cases.agg(**agg)
  558:     tm.assert_frame_equal(result, expected, check_like=True)
  559: 
  560: 
  561: @pytest.mark.parametrize(
  562:     "agg",
  563:     [
  564:         {"func": {"result1": np.sum, "result2": np.mean}},
  565:         {"A": ("result1", np.sum), "B": ("result2", np.mean)},
  566:         {"A": NamedAgg("result1", np.sum), "B": NamedAgg("result2", np.mean)},
  567:     ],
  568: )
  569: def test_agg_no_column(cases, agg):
  570:     msg = r"Column\(s\) \['result1', 'result2'\] do not exist"
  571:     with pytest.raises(KeyError, match=msg):
  572:         cases[["A", "B"]].agg(**agg)
  573: 
  574: 
  575: @pytest.mark.parametrize(
  576:     "cols, agg",
  577:     [
  578:         [None, {"A": ["sum", "std"], "B": ["mean", "std"]}],
  579:         [
  580:             [
  581:                 "A",
  582:                 "B",
  583:             ],
  584:             {"A": ["sum", "std"], "B": ["mean", "std"]},
  585:         ],
  586:     ],
  587: )
  588: def test_agg_specificationerror_nested(cases, cols, agg, a_sum, a_std, b_mean, b_std):
  589:     # agg with different hows
  590:     # equivalent of using a selection list / or not
  591:     expected = pd.concat([a_sum, a_std, b_mean, b_std], axis=1)
  592:     expected.columns = pd.MultiIndex.from_tuples(
  593:         [("A", "sum"), ("A", "std"), ("B", "mean"), ("B", "std")]
  594:     )
  595:     if cols is not None:
  596:         obj = cases[cols]
  597:     else:
  598:         obj = cases
  599: 
  600:     result = obj.agg(agg)
  601:     tm.assert_frame_equal(result, expected, check_like=True)
  602: 
  603: 
  604: @pytest.mark.parametrize(
  605:     "agg", [{"A": ["sum", "std"]}, {"A": ["sum", "std"], "B": ["mean", "std"]}]
  606: )
  607: def test_agg_specificationerror_series(cases, agg):
  608:     msg = "nested renamer is not supported"
  609: 
  610:     # series like aggs
  611:     with pytest.raises(pd.errors.SpecificationError, match=msg):
  612:         cases["A"].agg(agg)
  613: 
  614: 
  615: def test_agg_specificationerror_invalid_names(cases):
  616:     # errors
  617:     # invalid names in the agg specification
  618:     msg = r"Column\(s\) \['B'\] do not exist"
  619:     with pytest.raises(KeyError, match=msg):
  620:         cases[["A"]].agg({"A": ["sum", "std"], "B": ["mean", "std"]})
  621: 
  622: 
  623: @pytest.mark.parametrize(
  624:     "func", [["min"], ["mean", "max"], {"A": "sum"}, {"A": "prod", "B": "median"}]
  625: )
  626: def test_multi_agg_axis_1_raises(func):
  627:     # GH#46904
  628: 
  629:     index = date_range(datetime(2005, 1, 1), datetime(2005, 1, 10), freq="D")
  630:     index.name = "date"
  631:     df = DataFrame(
  632:         np.random.default_rng(2).random((10, 2)), columns=list("AB"), index=index
  633:     ).T
  634:     warning_msg = "DataFrame.resample with axis=1 is deprecated."
  635:     with tm.assert_produces_warning(FutureWarning, match=warning_msg):
  636:         res = df.resample("ME", axis=1)
  637:         with pytest.raises(
  638:             NotImplementedError, match="axis other than 0 is not supported"
  639:         ):
  640:             res.agg(func)
  641: 
  642: 
  643: def test_agg_nested_dicts():
  644:     index = date_range(datetime(2005, 1, 1), datetime(2005, 1, 10), freq="D")
  645:     index.name = "date"
  646:     df = DataFrame(
  647:         np.random.default_rng(2).random((10, 2)), columns=list("AB"), index=index
  648:     )
  649:     df_col = df.reset_index()
  650:     df_mult = df_col.copy()
  651:     df_mult.index = pd.MultiIndex.from_arrays(
  652:         [range(10), df.index], names=["index", "date"]
  653:     )
  654:     r = df.resample("2D")
  655:     cases = [
  656:         r,
  657:         df_col.resample("2D", on="date"),
  658:         df_mult.resample("2D", level="date"),
  659:         df.groupby(pd.Grouper(freq="2D")),
  660:     ]
  661: 
  662:     msg = "nested renamer is not supported"
  663:     for t in cases:
  664:         with pytest.raises(pd.errors.SpecificationError, match=msg):
  665:             t.aggregate({"r1": {"A": ["mean", "sum"]}, "r2": {"B": ["mean", "sum"]}})
  666: 
  667:     for t in cases:
  668:         with pytest.raises(pd.errors.SpecificationError, match=msg):
  669:             t[["A", "B"]].agg(
  670:                 {"A": {"ra": ["mean", "std"]}, "B": {"rb": ["mean", "std"]}}
  671:             )
  672: 
  673:         with pytest.raises(pd.errors.SpecificationError, match=msg):
  674:             t.agg({"A": {"ra": ["mean", "std"]}, "B": {"rb": ["mean", "std"]}})
  675: 
  676: 
  677: def test_try_aggregate_non_existing_column():
  678:     # GH 16766
  679:     data = [
  680:         {"dt": datetime(2017, 6, 1, 0), "x": 1.0, "y": 2.0},
  681:         {"dt": datetime(2017, 6, 1, 1), "x": 2.0, "y": 2.0},
  682:         {"dt": datetime(2017, 6, 1, 2), "x": 3.0, "y": 1.5},
  683:     ]
  684:     df = DataFrame(data).set_index("dt")
  685: 
  686:     # Error as we don't have 'z' column
  687:     msg = r"Column\(s\) \['z'\] do not exist"
  688:     with pytest.raises(KeyError, match=msg):
  689:         df.resample("30min").agg({"x": ["mean"], "y": ["median"], "z": ["sum"]})
  690: 
  691: 
  692: def test_agg_list_like_func_with_args():
  693:     # 50624
  694:     df = DataFrame(
  695:         {"x": [1, 2, 3]}, index=date_range("2020-01-01", periods=3, freq="D")
  696:     )
  697: 
  698:     def foo1(x, a=1, c=0):
  699:         return x + a + c
  700: 
  701:     def foo2(x, b=2, c=0):
  702:         return x + b + c
  703: 
  704:     msg = r"foo1\(\) got an unexpected keyword argument 'b'"
  705:     with pytest.raises(TypeError, match=msg):
  706:         df.resample("D").agg([foo1, foo2], 3, b=3, c=4)
  707: 
  708:     result = df.resample("D").agg([foo1, foo2], 3, c=4)
  709:     expected = DataFrame(
  710:         [[8, 8], [9, 9], [10, 10]],
  711:         index=date_range("2020-01-01", periods=3, freq="D"),
  712:         columns=pd.MultiIndex.from_tuples([("x", "foo1"), ("x", "foo2")]),
  713:     )
  714:     tm.assert_frame_equal(result, expected)
  715: 
  716: 
  717: def test_selection_api_validation():
  718:     # GH 13500
  719:     index = date_range(datetime(2005, 1, 1), datetime(2005, 1, 10), freq="D")
  720: 
  721:     rng = np.arange(len(index), dtype=np.int64)
  722:     df = DataFrame(
  723:         {"date": index, "a": rng},
  724:         index=pd.MultiIndex.from_arrays([rng, index], names=["v", "d"]),
  725:     )
  726:     df_exp = DataFrame({"a": rng}, index=index)
  727: 
  728:     # non DatetimeIndex
  729:     msg = (
  730:         "Only valid with DatetimeIndex, TimedeltaIndex or PeriodIndex, "
  731:         "but got an instance of 'Index'"
  732:     )
  733:     with pytest.raises(TypeError, match=msg):
  734:         df.resample("2D", level="v")
  735: 
  736:     msg = "The Grouper cannot specify both a key and a level!"
  737:     with pytest.raises(ValueError, match=msg):
  738:         df.resample("2D", on="date", level="d")
  739: 
  740:     msg = "unhashable type: 'list'"
  741:     with pytest.raises(TypeError, match=msg):
  742:         df.resample("2D", on=["a", "date"])
  743: 
  744:     msg = r"\"Level \['a', 'date'\] not found\""
  745:     with pytest.raises(KeyError, match=msg):
  746:         df.resample("2D", level=["a", "date"])
  747: 
  748:     # upsampling not allowed
  749:     msg = (
  750:         "Upsampling from level= or on= selection is not supported, use "
  751:         r"\.set_index\(\.\.\.\) to explicitly set index to datetime-like"
  752:     )
  753:     with pytest.raises(ValueError, match=msg):
  754:         df.resample("2D", level="d").asfreq()
  755:     with pytest.raises(ValueError, match=msg):
  756:         df.resample("2D", on="date").asfreq()
  757: 
  758:     exp = df_exp.resample("2D").sum()
  759:     exp.index.name = "date"
  760:     result = df.resample("2D", on="date").sum()
  761:     tm.assert_frame_equal(exp, result)
  762: 
  763:     exp.index.name = "d"
  764:     with pytest.raises(TypeError, match="datetime64 type does not support sum"):
  765:         df.resample("2D", level="d").sum()
  766:     result = df.resample("2D", level="d").sum(numeric_only=True)
  767:     tm.assert_frame_equal(exp, result)
  768: 
  769: 
  770: @pytest.mark.parametrize(
  771:     "col_name", ["t2", "t2x", "t2q", "T_2M", "t2p", "t2m", "t2m1", "T2M"]
  772: )
  773: def test_agg_with_datetime_index_list_agg_func(col_name):
  774:     # GH 22660
  775:     # The parametrized column names would get converted to dates by our
  776:     # date parser. Some would result in OutOfBoundsError (ValueError) while
  777:     # others would result in OverflowError when passed into Timestamp.
  778:     # We catch these errors and move on to the correct branch.
  779:     df = DataFrame(
  780:         list(range(200)),
  781:         index=date_range(
  782:             start="2017-01-01", freq="15min", periods=200, tz="Europe/Berlin"
  783:         ),
  784:         columns=[col_name],
  785:     )
  786:     result = df.resample("1d").aggregate(["mean"])
  787:     expected = DataFrame(
  788:         [47.5, 143.5, 195.5],
  789:         index=date_range(start="2017-01-01", freq="D", periods=3, tz="Europe/Berlin"),
  790:         columns=pd.MultiIndex(levels=[[col_name], ["mean"]], codes=[[0], [0]]),
  791:     )
  792:     tm.assert_frame_equal(result, expected)
  793: 
  794: 
  795: def test_resample_agg_readonly():
  796:     # GH#31710 cython needs to allow readonly data
  797:     index = date_range("2020-01-01", "2020-01-02", freq="1h")
  798:     arr = np.zeros_like(index)
  799:     arr.setflags(write=False)
  800: 
  801:     ser = Series(arr, index=index)
  802:     rs = ser.resample("1D")
  803: 
  804:     expected = Series([pd.Timestamp(0), pd.Timestamp(0)], index=index[::24])
  805: 
  806:     result = rs.agg("last")
  807:     tm.assert_series_equal(result, expected)
  808: 
  809:     result = rs.agg("first")
  810:     tm.assert_series_equal(result, expected)
  811: 
  812:     result = rs.agg("max")
  813:     tm.assert_series_equal(result, expected)
  814: 
  815:     result = rs.agg("min")
  816:     tm.assert_series_equal(result, expected)
  817: 
  818: 
  819: @pytest.mark.parametrize(
  820:     "start,end,freq,data,resample_freq,origin,closed,exp_data,exp_end,exp_periods",
  821:     [
  822:         (
  823:             "2000-10-01 23:30:00",
  824:             "2000-10-02 00:26:00",
  825:             "7min",
  826:             [0, 3, 6, 9, 12, 15, 18, 21, 24],
  827:             "17min",
  828:             "end",
  829:             None,
  830:             [0, 18, 27, 63],
  831:             "20001002 00:26:00",
  832:             4,
  833:         ),
  834:         (
  835:             "20200101 8:26:35",
  836:             "20200101 9:31:58",
  837:             "77s",
  838:             [1] * 51,
  839:             "7min",
  840:             "end",
  841:             "right",
  842:             [1, 6, 5, 6, 5, 6, 5, 6, 5, 6],
  843:             "2020-01-01 09:30:45",
  844:             10,
  845:         ),
  846:         (
  847:             "2000-10-01 23:30:00",
  848:             "2000-10-02 00:26:00",
  849:             "7min",
  850:             [0, 3, 6, 9, 12, 15, 18, 21, 24],
  851:             "17min",
  852:             "end",
  853:             "left",
  854:             [0, 18, 27, 39, 24],
  855:             "20001002 00:43:00",
  856:             5,
  857:         ),
  858:         (
  859:             "2000-10-01 23:30:00",
  860:             "2000-10-02 00:26:00",
  861:             "7min",
  862:             [0, 3, 6, 9, 12, 15, 18, 21, 24],
  863:             "17min",
  864:             "end_day",
  865:             None,
  866:             [3, 15, 45, 45],
  867:             "2000-10-02 00:29:00",
  868:             4,
  869:         ),
  870:     ],
  871: )
  872: def test_end_and_end_day_origin(
  873:     start,
  874:     end,
  875:     freq,
  876:     data,
  877:     resample_freq,
  878:     origin,
  879:     closed,
  880:     exp_data,
  881:     exp_end,
  882:     exp_periods,
  883: ):
  884:     rng = date_range(start, end, freq=freq)
  885:     ts = Series(data, index=rng)
  886: 
  887:     res = ts.resample(resample_freq, origin=origin, closed=closed).sum()
  888:     expected = Series(
  889:         exp_data,
  890:         index=date_range(end=exp_end, freq=resample_freq, periods=exp_periods),
  891:     )
  892: 
  893:     tm.assert_series_equal(res, expected)
  894: 
  895: 
  896: @pytest.mark.parametrize(
  897:     # expected_data is a string when op raises a ValueError
  898:     "method, numeric_only, expected_data",
  899:     [
  900:         ("sum", True, {"num": [25]}),
  901:         ("sum", False, {"cat": ["cat_1cat_2"], "num": [25]}),
  902:         ("sum", lib.no_default, {"cat": ["cat_1cat_2"], "num": [25]}),
  903:         ("prod", True, {"num": [100]}),
  904:         ("prod", False, "can't multiply sequence"),
  905:         ("prod", lib.no_default, "can't multiply sequence"),
  906:         ("min", True, {"num": [5]}),
  907:         ("min", False, {"cat": ["cat_1"], "num": [5]}),
  908:         ("min", lib.no_default, {"cat": ["cat_1"], "num": [5]}),
  909:         ("max", True, {"num": [20]}),
  910:         ("max", False, {"cat": ["cat_2"], "num": [20]}),
  911:         ("max", lib.no_default, {"cat": ["cat_2"], "num": [20]}),
  912:         ("first", True, {"num": [5]}),
  913:         ("first", False, {"cat": ["cat_1"], "num": [5]}),
  914:         ("first", lib.no_default, {"cat": ["cat_1"], "num": [5]}),
  915:         ("last", True, {"num": [20]}),
  916:         ("last", False, {"cat": ["cat_2"], "num": [20]}),
  917:         ("last", lib.no_default, {"cat": ["cat_2"], "num": [20]}),
  918:         ("mean", True, {"num": [12.5]}),
  919:         ("mean", False, "Could not convert"),
  920:         ("mean", lib.no_default, "Could not convert"),
  921:         ("median", True, {"num": [12.5]}),
  922:         ("median", False, r"Cannot convert \['cat_1' 'cat_2'\] to numeric"),
  923:         ("median", lib.no_default, r"Cannot convert \['cat_1' 'cat_2'\] to numeric"),
  924:         ("std", True, {"num": [10.606601717798213]}),
  925:         ("std", False, "could not convert string to float"),
  926:         ("std", lib.no_default, "could not convert string to float"),
  927:         ("var", True, {"num": [112.5]}),
  928:         ("var", False, "could not convert string to float"),
  929:         ("var", lib.no_default, "could not convert string to float"),
  930:         ("sem", True, {"num": [7.5]}),
  931:         ("sem", False, "could not convert string to float"),
  932:         ("sem", lib.no_default, "could not convert string to float"),
  933:     ],
  934: )
  935: def test_frame_downsample_method(method, numeric_only, expected_data):
  936:     # GH#46442 test if `numeric_only` behave as expected for DataFrameGroupBy
  937: 
  938:     index = date_range("2018-01-01", periods=2, freq="D")
  939:     expected_index = date_range("2018-12-31", periods=1, freq="YE")
  940:     df = DataFrame({"cat": ["cat_1", "cat_2"], "num": [5, 20]}, index=index)
  941:     resampled = df.resample("YE")
  942:     if numeric_only is lib.no_default:
  943:         kwargs = {}
  944:     else:
  945:         kwargs = {"numeric_only": numeric_only}
  946: 
  947:     func = getattr(resampled, method)
  948:     if isinstance(expected_data, str):
  949:         if method in ("var", "mean", "median", "prod"):
  950:             klass = TypeError
  951:             msg = re.escape(f"agg function failed [how->{method},dtype->")
  952:         else:
  953:             klass = ValueError
  954:             msg = expected_data
  955:         with pytest.raises(klass, match=msg):
  956:             _ = func(**kwargs)
  957:     else:
  958:         result = func(**kwargs)
  959:         expected = DataFrame(expected_data, index=expected_index)
  960:         tm.assert_frame_equal(result, expected)
  961: 
  962: 
  963: @pytest.mark.parametrize(
  964:     "method, numeric_only, expected_data",
  965:     [
  966:         ("sum", True, ()),
  967:         ("sum", False, ["cat_1cat_2"]),
  968:         ("sum", lib.no_default, ["cat_1cat_2"]),
  969:         ("prod", True, ()),
  970:         ("prod", False, ()),
  971:         ("prod", lib.no_default, ()),
  972:         ("min", True, ()),
  973:         ("min", False, ["cat_1"]),
  974:         ("min", lib.no_default, ["cat_1"]),
  975:         ("max", True, ()),
  976:         ("max", False, ["cat_2"]),
  977:         ("max", lib.no_default, ["cat_2"]),
  978:         ("first", True, ()),
  979:         ("first", False, ["cat_1"]),
  980:         ("first", lib.no_default, ["cat_1"]),
  981:         ("last", True, ()),
  982:         ("last", False, ["cat_2"]),
  983:         ("last", lib.no_default, ["cat_2"]),
  984:     ],
  985: )
  986: def test_series_downsample_method(method, numeric_only, expected_data):
  987:     # GH#46442 test if `numeric_only` behave as expected for SeriesGroupBy
  988: 
  989:     index = date_range("2018-01-01", periods=2, freq="D")
  990:     expected_index = date_range("2018-12-31", periods=1, freq="YE")
  991:     df = Series(["cat_1", "cat_2"], index=index)
  992:     resampled = df.resample("YE")
  993:     kwargs = {} if numeric_only is lib.no_default else {"numeric_only": numeric_only}
  994: 
  995:     func = getattr(resampled, method)
  996:     if numeric_only and numeric_only is not lib.no_default:
  997:         msg = rf"Cannot use numeric_only=True with SeriesGroupBy\.{method}"
  998:         with pytest.raises(TypeError, match=msg):
  999:             func(**kwargs)
 1000:     elif method == "prod":
 1001:         msg = re.escape("agg function failed [how->prod,dtype->")
 1002:         with pytest.raises(TypeError, match=msg):
 1003:             func(**kwargs)
 1004:     else:
 1005:         result = func(**kwargs)
 1006:         expected = Series(expected_data, index=expected_index)
 1007:         tm.assert_series_equal(result, expected)
 1008: 
 1009: 
 1010: @pytest.mark.parametrize(
 1011:     "method, raises",
 1012:     [
 1013:         ("sum", True),
 1014:         ("prod", True),
 1015:         ("min", True),
 1016:         ("max", True),
 1017:         ("first", False),
 1018:         ("last", False),
 1019:         ("median", False),
 1020:         ("mean", True),
 1021:         ("std", True),
 1022:         ("var", True),
 1023:         ("sem", False),
 1024:         ("ohlc", False),
 1025:         ("nunique", False),
 1026:     ],
 1027: )
 1028: def test_args_kwargs_depr(method, raises):
 1029:     index = date_range("20180101", periods=3, freq="h")
 1030:     df = Series([2, 4, 6], index=index)
 1031:     resampled = df.resample("30min")
 1032:     args = ()
 1033: 
 1034:     func = getattr(resampled, method)
 1035: 
 1036:     error_msg = "numpy operations are not valid with resample."
 1037:     error_msg_type = "too many arguments passed in"
 1038:     warn_msg = f"Passing additional args to DatetimeIndexResampler.{method}"
 1039: 
 1040:     if raises:
 1041:         with tm.assert_produces_warning(FutureWarning, match=warn_msg):
 1042:             with pytest.raises(UnsupportedFunctionCall, match=error_msg):
 1043:                 func(*args, 1, 2, 3, 4)
 1044:     else:
 1045:         with tm.assert_produces_warning(FutureWarning, match=warn_msg):
 1046:             with pytest.raises(TypeError, match=error_msg_type):
 1047:                 func(*args, 1, 2, 3, 4)
 1048: 
 1049: 
 1050: def test_df_axis_param_depr():
 1051:     index = date_range(datetime(2005, 1, 1), datetime(2005, 1, 10), freq="D")
 1052:     index.name = "date"
 1053:     df = DataFrame(
 1054:         np.random.default_rng(2).random((10, 2)), columns=list("AB"), index=index
 1055:     ).T
 1056: 
 1057:     # Deprecation error when axis=1 is explicitly passed
 1058:     warning_msg = "DataFrame.resample with axis=1 is deprecated."
 1059:     with tm.assert_produces_warning(FutureWarning, match=warning_msg):
 1060:         df.resample("ME", axis=1)
 1061: 
 1062:     # Deprecation error when axis=0 is explicitly passed
 1063:     df = df.T
 1064:     warning_msg = (
 1065:         "The 'axis' keyword in DataFrame.resample is deprecated and "
 1066:         "will be removed in a future version."
 1067:     )
 1068:     with tm.assert_produces_warning(FutureWarning, match=warning_msg):
 1069:         df.resample("ME", axis=0)
 1070: 
 1071: 
 1072: def test_series_axis_param_depr(_test_series):
 1073:     warning_msg = (
 1074:         "The 'axis' keyword in Series.resample is "
 1075:         "deprecated and will be removed in a future version."
 1076:     )
 1077:     with tm.assert_produces_warning(FutureWarning, match=warning_msg):
 1078:         _test_series.resample("h", axis=0)
 1079: 
 1080: 
 1081: def test_resample_empty():
 1082:     # GH#52484
 1083:     df = DataFrame(
 1084:         index=pd.to_datetime(
 1085:             ["2018-01-01 00:00:00", "2018-01-01 12:00:00", "2018-01-02 00:00:00"]
 1086:         )
 1087:     )
 1088:     expected = DataFrame(
 1089:         index=pd.to_datetime(
 1090:             [
 1091:                 "2018-01-01 00:00:00",
 1092:                 "2018-01-01 08:00:00",
 1093:                 "2018-01-01 16:00:00",
 1094:                 "2018-01-02 00:00:00",
 1095:             ]
 1096:         )
 1097:     )
 1098:     result = df.resample("8h").mean()
 1099:     tm.assert_frame_equal(result, expected)
