    1: from collections import (
    2:     abc,
    3:     deque,
    4: )
    5: from collections.abc import Iterator
    6: from datetime import datetime
    7: from decimal import Decimal
    8: 
    9: import numpy as np
   10: import pytest
   11: 
   12: from pandas.errors import InvalidIndexError
   13: import pandas.util._test_decorators as td
   14: 
   15: import pandas as pd
   16: from pandas import (
   17:     DataFrame,
   18:     Index,
   19:     MultiIndex,
   20:     PeriodIndex,
   21:     Series,
   22:     concat,
   23:     date_range,
   24: )
   25: import pandas._testing as tm
   26: from pandas.core.arrays import SparseArray
   27: from pandas.tests.extension.decimal import to_decimal
   28: 
   29: 
   30: class TestConcatenate:
   31:     def test_append_concat(self):
   32:         # GH#1815
   33:         d1 = date_range("12/31/1990", "12/31/1999", freq="YE-DEC")
   34:         d2 = date_range("12/31/2000", "12/31/2009", freq="YE-DEC")
   35: 
   36:         s1 = Series(np.random.default_rng(2).standard_normal(10), d1)
   37:         s2 = Series(np.random.default_rng(2).standard_normal(10), d2)
   38: 
   39:         s1 = s1.to_period()
   40:         s2 = s2.to_period()
   41: 
   42:         # drops index
   43:         result = concat([s1, s2])
   44:         assert isinstance(result.index, PeriodIndex)
   45:         assert result.index[0] == s1.index[0]
   46: 
   47:     def test_concat_copy(self, using_array_manager, using_copy_on_write):
   48:         df = DataFrame(np.random.default_rng(2).standard_normal((4, 3)))
   49:         df2 = DataFrame(np.random.default_rng(2).integers(0, 10, size=4).reshape(4, 1))
   50:         df3 = DataFrame({5: "foo"}, index=range(4))
   51: 
   52:         # These are actual copies.
   53:         result = concat([df, df2, df3], axis=1, copy=True)
   54: 
   55:         if not using_copy_on_write:
   56:             for arr in result._mgr.arrays:
   57:                 assert not any(
   58:                     np.shares_memory(arr, y)
   59:                     for x in [df, df2, df3]
   60:                     for y in x._mgr.arrays
   61:                 )
   62:         else:
   63:             for arr in result._mgr.arrays:
   64:                 assert arr.base is not None
   65: 
   66:         # These are the same.
   67:         result = concat([df, df2, df3], axis=1, copy=False)
   68: 
   69:         for arr in result._mgr.arrays:
   70:             if arr.dtype.kind == "f":
   71:                 assert arr.base is df._mgr.arrays[0].base
   72:             elif arr.dtype.kind in ["i", "u"]:
   73:                 assert arr.base is df2._mgr.arrays[0].base
   74:             elif arr.dtype == object:
   75:                 if using_array_manager:
   76:                     # we get the same array object, which has no base
   77:                     assert arr is df3._mgr.arrays[0]
   78:                 else:
   79:                     assert arr.base is not None
   80: 
   81:         # Float block was consolidated.
   82:         df4 = DataFrame(np.random.default_rng(2).standard_normal((4, 1)))
   83:         result = concat([df, df2, df3, df4], axis=1, copy=False)
   84:         for arr in result._mgr.arrays:
   85:             if arr.dtype.kind == "f":
   86:                 if using_array_manager or using_copy_on_write:
   87:                     # this is a view on some array in either df or df4
   88:                     assert any(
   89:                         np.shares_memory(arr, other)
   90:                         for other in df._mgr.arrays + df4._mgr.arrays
   91:                     )
   92:                 else:
   93:                     # the block was consolidated, so we got a copy anyway
   94:                     assert arr.base is None
   95:             elif arr.dtype.kind in ["i", "u"]:
   96:                 assert arr.base is df2._mgr.arrays[0].base
   97:             elif arr.dtype == object:
   98:                 # this is a view on df3
   99:                 assert any(np.shares_memory(arr, other) for other in df3._mgr.arrays)
  100: 
  101:     def test_concat_with_group_keys(self):
  102:         # axis=0
  103:         df = DataFrame(np.random.default_rng(2).standard_normal((3, 4)))
  104:         df2 = DataFrame(np.random.default_rng(2).standard_normal((4, 4)))
  105: 
  106:         result = concat([df, df2], keys=[0, 1])
  107:         exp_index = MultiIndex.from_arrays(
  108:             [[0, 0, 0, 1, 1, 1, 1], [0, 1, 2, 0, 1, 2, 3]]
  109:         )
  110:         expected = DataFrame(np.r_[df.values, df2.values], index=exp_index)
  111:         tm.assert_frame_equal(result, expected)
  112: 
  113:         result = concat([df, df], keys=[0, 1])
  114:         exp_index2 = MultiIndex.from_arrays([[0, 0, 0, 1, 1, 1], [0, 1, 2, 0, 1, 2]])
  115:         expected = DataFrame(np.r_[df.values, df.values], index=exp_index2)
  116:         tm.assert_frame_equal(result, expected)
  117: 
  118:         # axis=1
  119:         df = DataFrame(np.random.default_rng(2).standard_normal((4, 3)))
  120:         df2 = DataFrame(np.random.default_rng(2).standard_normal((4, 4)))
  121: 
  122:         result = concat([df, df2], keys=[0, 1], axis=1)
  123:         expected = DataFrame(np.c_[df.values, df2.values], columns=exp_index)
  124:         tm.assert_frame_equal(result, expected)
  125: 
  126:         result = concat([df, df], keys=[0, 1], axis=1)
  127:         expected = DataFrame(np.c_[df.values, df.values], columns=exp_index2)
  128:         tm.assert_frame_equal(result, expected)
  129: 
  130:     def test_concat_keys_specific_levels(self):
  131:         df = DataFrame(np.random.default_rng(2).standard_normal((10, 4)))
  132:         pieces = [df.iloc[:, [0, 1]], df.iloc[:, [2]], df.iloc[:, [3]]]
  133:         level = ["three", "two", "one", "zero"]
  134:         result = concat(
  135:             pieces,
  136:             axis=1,
  137:             keys=["one", "two", "three"],
  138:             levels=[level],
  139:             names=["group_key"],
  140:         )
  141: 
  142:         tm.assert_index_equal(result.columns.levels[0], Index(level, name="group_key"))
  143:         tm.assert_index_equal(result.columns.levels[1], Index([0, 1, 2, 3]))
  144: 
  145:         assert result.columns.names == ["group_key", None]
  146: 
  147:     @pytest.mark.parametrize("mapping", ["mapping", "dict"])
  148:     def test_concat_mapping(self, mapping, non_dict_mapping_subclass):
  149:         constructor = dict if mapping == "dict" else non_dict_mapping_subclass
  150:         frames = constructor(
  151:             {
  152:                 "foo": DataFrame(np.random.default_rng(2).standard_normal((4, 3))),
  153:                 "bar": DataFrame(np.random.default_rng(2).standard_normal((4, 3))),
  154:                 "baz": DataFrame(np.random.default_rng(2).standard_normal((4, 3))),
  155:                 "qux": DataFrame(np.random.default_rng(2).standard_normal((4, 3))),
  156:             }
  157:         )
  158: 
  159:         sorted_keys = list(frames.keys())
  160: 
  161:         result = concat(frames)
  162:         expected = concat([frames[k] for k in sorted_keys], keys=sorted_keys)
  163:         tm.assert_frame_equal(result, expected)
  164: 
  165:         result = concat(frames, axis=1)
  166:         expected = concat([frames[k] for k in sorted_keys], keys=sorted_keys, axis=1)
  167:         tm.assert_frame_equal(result, expected)
  168: 
  169:         keys = ["baz", "foo", "bar"]
  170:         result = concat(frames, keys=keys)
  171:         expected = concat([frames[k] for k in keys], keys=keys)
  172:         tm.assert_frame_equal(result, expected)
  173: 
  174:     def test_concat_keys_and_levels(self):
  175:         df = DataFrame(np.random.default_rng(2).standard_normal((1, 3)))
  176:         df2 = DataFrame(np.random.default_rng(2).standard_normal((1, 4)))
  177: 
  178:         levels = [["foo", "baz"], ["one", "two"]]
  179:         names = ["first", "second"]
  180:         result = concat(
  181:             [df, df2, df, df2],
  182:             keys=[("foo", "one"), ("foo", "two"), ("baz", "one"), ("baz", "two")],
  183:             levels=levels,
  184:             names=names,
  185:         )
  186:         expected = concat([df, df2, df, df2])
  187:         exp_index = MultiIndex(
  188:             levels=levels + [[0]],
  189:             codes=[[0, 0, 1, 1], [0, 1, 0, 1], [0, 0, 0, 0]],
  190:             names=names + [None],
  191:         )
  192:         expected.index = exp_index
  193: 
  194:         tm.assert_frame_equal(result, expected)
  195: 
  196:         # no names
  197:         result = concat(
  198:             [df, df2, df, df2],
  199:             keys=[("foo", "one"), ("foo", "two"), ("baz", "one"), ("baz", "two")],
  200:             levels=levels,
  201:         )
  202:         assert result.index.names == (None,) * 3
  203: 
  204:         # no levels
  205:         result = concat(
  206:             [df, df2, df, df2],
  207:             keys=[("foo", "one"), ("foo", "two"), ("baz", "one"), ("baz", "two")],
  208:             names=["first", "second"],
  209:         )
  210:         assert result.index.names == ("first", "second", None)
  211:         tm.assert_index_equal(
  212:             result.index.levels[0], Index(["baz", "foo"], name="first")
  213:         )
  214: 
  215:     def test_concat_keys_levels_no_overlap(self):
  216:         # GH #1406
  217:         df = DataFrame(np.random.default_rng(2).standard_normal((1, 3)), index=["a"])
  218:         df2 = DataFrame(np.random.default_rng(2).standard_normal((1, 4)), index=["b"])
  219: 
  220:         msg = "Values not found in passed level"
  221:         with pytest.raises(ValueError, match=msg):
  222:             concat([df, df], keys=["one", "two"], levels=[["foo", "bar", "baz"]])
  223: 
  224:         msg = "Key one not in level"
  225:         with pytest.raises(ValueError, match=msg):
  226:             concat([df, df2], keys=["one", "two"], levels=[["foo", "bar", "baz"]])
  227: 
  228:     def test_crossed_dtypes_weird_corner(self):
  229:         columns = ["A", "B", "C", "D"]
  230:         df1 = DataFrame(
  231:             {
  232:                 "A": np.array([1, 2, 3, 4], dtype="f8"),
  233:                 "B": np.array([1, 2, 3, 4], dtype="i8"),
  234:                 "C": np.array([1, 2, 3, 4], dtype="f8"),
  235:                 "D": np.array([1, 2, 3, 4], dtype="i8"),
  236:             },
  237:             columns=columns,
  238:         )
  239: 
  240:         df2 = DataFrame(
  241:             {
  242:                 "A": np.array([1, 2, 3, 4], dtype="i8"),
  243:                 "B": np.array([1, 2, 3, 4], dtype="f8"),
  244:                 "C": np.array([1, 2, 3, 4], dtype="i8"),
  245:                 "D": np.array([1, 2, 3, 4], dtype="f8"),
  246:             },
  247:             columns=columns,
  248:         )
  249: 
  250:         appended = concat([df1, df2], ignore_index=True)
  251:         expected = DataFrame(
  252:             np.concatenate([df1.values, df2.values], axis=0), columns=columns
  253:         )
  254:         tm.assert_frame_equal(appended, expected)
  255: 
  256:         df = DataFrame(np.random.default_rng(2).standard_normal((1, 3)), index=["a"])
  257:         df2 = DataFrame(np.random.default_rng(2).standard_normal((1, 4)), index=["b"])
  258:         result = concat([df, df2], keys=["one", "two"], names=["first", "second"])
  259:         assert result.index.names == ("first", "second")
  260: 
  261:     def test_with_mixed_tuples(self, sort):
  262:         # 10697
  263:         # columns have mixed tuples, so handle properly
  264:         df1 = DataFrame({"A": "foo", ("B", 1): "bar"}, index=range(2))
  265:         df2 = DataFrame({"B": "foo", ("B", 1): "bar"}, index=range(2))
  266: 
  267:         # it works
  268:         concat([df1, df2], sort=sort)
  269: 
  270:     def test_concat_mixed_objs_columns(self):
  271:         # Test column-wise concat for mixed series/frames (axis=1)
  272:         # G2385
  273: 
  274:         index = date_range("01-Jan-2013", periods=10, freq="h")
  275:         arr = np.arange(10, dtype="int64")
  276:         s1 = Series(arr, index=index)
  277:         s2 = Series(arr, index=index)
  278:         df = DataFrame(arr.reshape(-1, 1), index=index)
  279: 
  280:         expected = DataFrame(
  281:             np.repeat(arr, 2).reshape(-1, 2), index=index, columns=[0, 0]
  282:         )
  283:         result = concat([df, df], axis=1)
  284:         tm.assert_frame_equal(result, expected)
  285: 
  286:         expected = DataFrame(
  287:             np.repeat(arr, 2).reshape(-1, 2), index=index, columns=[0, 1]
  288:         )
  289:         result = concat([s1, s2], axis=1)
  290:         tm.assert_frame_equal(result, expected)
  291: 
  292:         expected = DataFrame(
  293:             np.repeat(arr, 3).reshape(-1, 3), index=index, columns=[0, 1, 2]
  294:         )
  295:         result = concat([s1, s2, s1], axis=1)
  296:         tm.assert_frame_equal(result, expected)
  297: 
  298:         expected = DataFrame(
  299:             np.repeat(arr, 5).reshape(-1, 5), index=index, columns=[0, 0, 1, 2, 3]
  300:         )
  301:         result = concat([s1, df, s2, s2, s1], axis=1)
  302:         tm.assert_frame_equal(result, expected)
  303: 
  304:         # with names
  305:         s1.name = "foo"
  306:         expected = DataFrame(
  307:             np.repeat(arr, 3).reshape(-1, 3), index=index, columns=["foo", 0, 0]
  308:         )
  309:         result = concat([s1, df, s2], axis=1)
  310:         tm.assert_frame_equal(result, expected)
  311: 
  312:         s2.name = "bar"
  313:         expected = DataFrame(
  314:             np.repeat(arr, 3).reshape(-1, 3), index=index, columns=["foo", 0, "bar"]
  315:         )
  316:         result = concat([s1, df, s2], axis=1)
  317:         tm.assert_frame_equal(result, expected)
  318: 
  319:         # ignore index
  320:         expected = DataFrame(
  321:             np.repeat(arr, 3).reshape(-1, 3), index=index, columns=[0, 1, 2]
  322:         )
  323:         result = concat([s1, df, s2], axis=1, ignore_index=True)
  324:         tm.assert_frame_equal(result, expected)
  325: 
  326:     def test_concat_mixed_objs_index(self):
  327:         # Test row-wise concat for mixed series/frames with a common name
  328:         # GH2385, GH15047
  329: 
  330:         index = date_range("01-Jan-2013", periods=10, freq="h")
  331:         arr = np.arange(10, dtype="int64")
  332:         s1 = Series(arr, index=index)
  333:         s2 = Series(arr, index=index)
  334:         df = DataFrame(arr.reshape(-1, 1), index=index)
  335: 
  336:         expected = DataFrame(
  337:             np.tile(arr, 3).reshape(-1, 1), index=index.tolist() * 3, columns=[0]
  338:         )
  339:         result = concat([s1, df, s2])
  340:         tm.assert_frame_equal(result, expected)
  341: 
  342:     def test_concat_mixed_objs_index_names(self):
  343:         # Test row-wise concat for mixed series/frames with distinct names
  344:         # GH2385, GH15047
  345: 
  346:         index = date_range("01-Jan-2013", periods=10, freq="h")
  347:         arr = np.arange(10, dtype="int64")
  348:         s1 = Series(arr, index=index, name="foo")
  349:         s2 = Series(arr, index=index, name="bar")
  350:         df = DataFrame(arr.reshape(-1, 1), index=index)
  351: 
  352:         expected = DataFrame(
  353:             np.kron(np.where(np.identity(3) == 1, 1, np.nan), arr).T,
  354:             index=index.tolist() * 3,
  355:             columns=["foo", 0, "bar"],
  356:         )
  357:         result = concat([s1, df, s2])
  358:         tm.assert_frame_equal(result, expected)
  359: 
  360:         # Rename all series to 0 when ignore_index=True
  361:         expected = DataFrame(np.tile(arr, 3).reshape(-1, 1), columns=[0])
  362:         result = concat([s1, df, s2], ignore_index=True)
  363:         tm.assert_frame_equal(result, expected)
  364: 
  365:     def test_dtype_coercion(self):
  366:         # 12411
  367:         df = DataFrame({"date": [pd.Timestamp("20130101").tz_localize("UTC"), pd.NaT]})
  368: 
  369:         result = concat([df.iloc[[0]], df.iloc[[1]]])
  370:         tm.assert_series_equal(result.dtypes, df.dtypes)
  371: 
  372:         # 12045
  373:         df = DataFrame({"date": [datetime(2012, 1, 1), datetime(1012, 1, 2)]})
  374:         result = concat([df.iloc[[0]], df.iloc[[1]]])
  375:         tm.assert_series_equal(result.dtypes, df.dtypes)
  376: 
  377:         # 11594
  378:         df = DataFrame({"text": ["some words"] + [None] * 9})
  379:         result = concat([df.iloc[[0]], df.iloc[[1]]])
  380:         tm.assert_series_equal(result.dtypes, df.dtypes)
  381: 
  382:     def test_concat_single_with_key(self):
  383:         df = DataFrame(np.random.default_rng(2).standard_normal((10, 4)))
  384: 
  385:         result = concat([df], keys=["foo"])
  386:         expected = concat([df, df], keys=["foo", "bar"])
  387:         tm.assert_frame_equal(result, expected[:10])
  388: 
  389:     def test_concat_no_items_raises(self):
  390:         with pytest.raises(ValueError, match="No objects to concatenate"):
  391:             concat([])
  392: 
  393:     def test_concat_exclude_none(self):
  394:         df = DataFrame(np.random.default_rng(2).standard_normal((10, 4)))
  395: 
  396:         pieces = [df[:5], None, None, df[5:]]
  397:         result = concat(pieces)
  398:         tm.assert_frame_equal(result, df)
  399:         with pytest.raises(ValueError, match="All objects passed were None"):
  400:             concat([None, None])
  401: 
  402:     def test_concat_keys_with_none(self):
  403:         # #1649
  404:         df0 = DataFrame([[10, 20, 30], [10, 20, 30], [10, 20, 30]])
  405: 
  406:         result = concat({"a": None, "b": df0, "c": df0[:2], "d": df0[:1], "e": df0})
  407:         expected = concat({"b": df0, "c": df0[:2], "d": df0[:1], "e": df0})
  408:         tm.assert_frame_equal(result, expected)
  409: 
  410:         result = concat(
  411:             [None, df0, df0[:2], df0[:1], df0], keys=["a", "b", "c", "d", "e"]
  412:         )
  413:         expected = concat([df0, df0[:2], df0[:1], df0], keys=["b", "c", "d", "e"])
  414:         tm.assert_frame_equal(result, expected)
  415: 
  416:     def test_concat_bug_1719(self):
  417:         ts1 = Series(
  418:             np.arange(10, dtype=np.float64), index=date_range("2020-01-01", periods=10)
  419:         )
  420:         ts2 = ts1.copy()[::2]
  421: 
  422:         # to join with union
  423:         # these two are of different length!
  424:         left = concat([ts1, ts2], join="outer", axis=1)
  425:         right = concat([ts2, ts1], join="outer", axis=1)
  426: 
  427:         assert len(left) == len(right)
  428: 
  429:     def test_concat_bug_2972(self):
  430:         ts0 = Series(np.zeros(5))
  431:         ts1 = Series(np.ones(5))
  432:         ts0.name = ts1.name = "same name"
  433:         result = concat([ts0, ts1], axis=1)
  434: 
  435:         expected = DataFrame({0: ts0, 1: ts1})
  436:         expected.columns = ["same name", "same name"]
  437:         tm.assert_frame_equal(result, expected)
  438: 
  439:     def test_concat_bug_3602(self):
  440:         # GH 3602, duplicate columns
  441:         df1 = DataFrame(
  442:             {
  443:                 "firmNo": [0, 0, 0, 0],
  444:                 "prc": [6, 6, 6, 6],
  445:                 "stringvar": ["rrr", "rrr", "rrr", "rrr"],
  446:             }
  447:         )
  448:         df2 = DataFrame(
  449:             {"C": [9, 10, 11, 12], "misc": [1, 2, 3, 4], "prc": [6, 6, 6, 6]}
  450:         )
  451:         expected = DataFrame(
  452:             [
  453:                 [0, 6, "rrr", 9, 1, 6],
  454:                 [0, 6, "rrr", 10, 2, 6],
  455:                 [0, 6, "rrr", 11, 3, 6],
  456:                 [0, 6, "rrr", 12, 4, 6],
  457:             ]
  458:         )
  459:         expected.columns = ["firmNo", "prc", "stringvar", "C", "misc", "prc"]
  460: 
  461:         result = concat([df1, df2], axis=1)
  462:         tm.assert_frame_equal(result, expected)
  463: 
  464:     def test_concat_iterables(self):
  465:         # GH8645 check concat works with tuples, list, generators, and weird
  466:         # stuff like deque and custom iterables
  467:         df1 = DataFrame([1, 2, 3])
  468:         df2 = DataFrame([4, 5, 6])
  469:         expected = DataFrame([1, 2, 3, 4, 5, 6])
  470:         tm.assert_frame_equal(concat((df1, df2), ignore_index=True), expected)
  471:         tm.assert_frame_equal(concat([df1, df2], ignore_index=True), expected)
  472:         tm.assert_frame_equal(
  473:             concat((df for df in (df1, df2)), ignore_index=True), expected
  474:         )
  475:         tm.assert_frame_equal(concat(deque((df1, df2)), ignore_index=True), expected)
  476: 
  477:         class CustomIterator1:
  478:             def __len__(self) -> int:
  479:                 return 2
  480: 
  481:             def __getitem__(self, index):
  482:                 try:
  483:                     return {0: df1, 1: df2}[index]
  484:                 except KeyError as err:
  485:                     raise IndexError from err
  486: 
  487:         tm.assert_frame_equal(concat(CustomIterator1(), ignore_index=True), expected)
  488: 
  489:         class CustomIterator2(abc.Iterable):
  490:             def __iter__(self) -> Iterator:
  491:                 yield df1
  492:                 yield df2
  493: 
  494:         tm.assert_frame_equal(concat(CustomIterator2(), ignore_index=True), expected)
  495: 
  496:     def test_concat_order(self):
  497:         # GH 17344, GH#47331
  498:         dfs = [DataFrame(index=range(3), columns=["a", 1, None])]
  499:         dfs += [DataFrame(index=range(3), columns=[None, 1, "a"]) for _ in range(100)]
  500: 
  501:         result = concat(dfs, sort=True).columns
  502:         expected = Index([1, "a", None])
  503:         tm.assert_index_equal(result, expected)
  504: 
  505:     def test_concat_different_extension_dtypes_upcasts(self):
  506:         a = Series(pd.array([1, 2], dtype="Int64"))
  507:         b = Series(to_decimal([1, 2]))
  508: 
  509:         result = concat([a, b], ignore_index=True)
  510:         expected = Series([1, 2, Decimal(1), Decimal(2)], dtype=object)
  511:         tm.assert_series_equal(result, expected)
  512: 
  513:     def test_concat_ordered_dict(self):
  514:         # GH 21510
  515:         expected = concat(
  516:             [Series(range(3)), Series(range(4))], keys=["First", "Another"]
  517:         )
  518:         result = concat({"First": Series(range(3)), "Another": Series(range(4))})
  519:         tm.assert_series_equal(result, expected)
  520: 
  521:     def test_concat_duplicate_indices_raise(self):
  522:         # GH 45888: test raise for concat DataFrames with duplicate indices
  523:         # https://github.com/pandas-dev/pandas/issues/36263
  524:         df1 = DataFrame(
  525:             np.random.default_rng(2).standard_normal(5),
  526:             index=[0, 1, 2, 3, 3],
  527:             columns=["a"],
  528:         )
  529:         df2 = DataFrame(
  530:             np.random.default_rng(2).standard_normal(5),
  531:             index=[0, 1, 2, 2, 4],
  532:             columns=["b"],
  533:         )
  534:         msg = "Reindexing only valid with uniquely valued Index objects"
  535:         with pytest.raises(InvalidIndexError, match=msg):
  536:             concat([df1, df2], axis=1)
  537: 
  538: 
  539: def test_concat_no_unnecessary_upcast(float_numpy_dtype, frame_or_series):
  540:     # GH 13247
  541:     dims = frame_or_series(dtype=object).ndim
  542:     dt = float_numpy_dtype
  543: 
  544:     dfs = [
  545:         frame_or_series(np.array([1], dtype=dt, ndmin=dims)),
  546:         frame_or_series(np.array([np.nan], dtype=dt, ndmin=dims)),
  547:         frame_or_series(np.array([5], dtype=dt, ndmin=dims)),
  548:     ]
  549:     x = concat(dfs)
  550:     assert x.values.dtype == dt
  551: 
  552: 
  553: @pytest.mark.parametrize("pdt", [Series, DataFrame])
  554: def test_concat_will_upcast(pdt, any_signed_int_numpy_dtype):
  555:     dt = any_signed_int_numpy_dtype
  556:     dims = pdt().ndim
  557:     dfs = [
  558:         pdt(np.array([1], dtype=dt, ndmin=dims)),
  559:         pdt(np.array([np.nan], ndmin=dims)),
  560:         pdt(np.array([5], dtype=dt, ndmin=dims)),
  561:     ]
  562:     x = concat(dfs)
  563:     assert x.values.dtype == "float64"
  564: 
  565: 
  566: def test_concat_empty_and_non_empty_frame_regression():
  567:     # GH 18178 regression test
  568:     df1 = DataFrame({"foo": [1]})
  569:     df2 = DataFrame({"foo": []})
  570:     expected = DataFrame({"foo": [1.0]})
  571:     result = concat([df1, df2])
  572:     tm.assert_frame_equal(result, expected)
  573: 
  574: 
  575: def test_concat_sparse():
  576:     # GH 23557
  577:     a = Series(SparseArray([0, 1, 2]))
  578:     expected = DataFrame(data=[[0, 0], [1, 1], [2, 2]]).astype(
  579:         pd.SparseDtype(np.int64, 0)
  580:     )
  581:     result = concat([a, a], axis=1)
  582:     tm.assert_frame_equal(result, expected)
  583: 
  584: 
  585: def test_concat_dense_sparse():
  586:     # GH 30668
  587:     dtype = pd.SparseDtype(np.float64, None)
  588:     a = Series(pd.arrays.SparseArray([1, None]), dtype=dtype)
  589:     b = Series([1], dtype=float)
  590:     expected = Series(data=[1, None, 1], index=[0, 1, 0]).astype(dtype)
  591:     result = concat([a, b], axis=0)
  592:     tm.assert_series_equal(result, expected)
  593: 
  594: 
  595: @pytest.mark.parametrize("keys", [["e", "f", "f"], ["f", "e", "f"]])
  596: def test_duplicate_keys(keys):
  597:     # GH 33654
  598:     df = DataFrame({"a": [1, 2, 3], "b": [4, 5, 6]})
  599:     s1 = Series([7, 8, 9], name="c")
  600:     s2 = Series([10, 11, 12], name="d")
  601:     result = concat([df, s1, s2], axis=1, keys=keys)
  602:     expected_values = [[1, 4, 7, 10], [2, 5, 8, 11], [3, 6, 9, 12]]
  603:     expected_columns = MultiIndex.from_tuples(
  604:         [(keys[0], "a"), (keys[0], "b"), (keys[1], "c"), (keys[2], "d")]
  605:     )
  606:     expected = DataFrame(expected_values, columns=expected_columns)
  607:     tm.assert_frame_equal(result, expected)
  608: 
  609: 
  610: def test_duplicate_keys_same_frame():
  611:     # GH 43595
  612:     keys = ["e", "e"]
  613:     df = DataFrame({"a": [1, 2, 3], "b": [4, 5, 6]})
  614:     result = concat([df, df], axis=1, keys=keys)
  615:     expected_values = [[1, 4, 1, 4], [2, 5, 2, 5], [3, 6, 3, 6]]
  616:     expected_columns = MultiIndex.from_tuples(
  617:         [(keys[0], "a"), (keys[0], "b"), (keys[1], "a"), (keys[1], "b")]
  618:     )
  619:     expected = DataFrame(expected_values, columns=expected_columns)
  620:     tm.assert_frame_equal(result, expected)
  621: 
  622: 
  623: @pytest.mark.filterwarnings(
  624:     "ignore:Passing a BlockManager|Passing a SingleBlockManager:DeprecationWarning"
  625: )
  626: @pytest.mark.parametrize(
  627:     "obj",
  628:     [
  629:         tm.SubclassedDataFrame({"A": np.arange(0, 10)}),
  630:         tm.SubclassedSeries(np.arange(0, 10), name="A"),
  631:     ],
  632: )
  633: def test_concat_preserves_subclass(obj):
  634:     # GH28330 -- preserve subclass
  635: 
  636:     result = concat([obj, obj])
  637:     assert isinstance(result, type(obj))
  638: 
  639: 
  640: def test_concat_frame_axis0_extension_dtypes():
  641:     # preserve extension dtype (through common_dtype mechanism)
  642:     df1 = DataFrame({"a": pd.array([1, 2, 3], dtype="Int64")})
  643:     df2 = DataFrame({"a": np.array([4, 5, 6])})
  644: 
  645:     result = concat([df1, df2], ignore_index=True)
  646:     expected = DataFrame({"a": [1, 2, 3, 4, 5, 6]}, dtype="Int64")
  647:     tm.assert_frame_equal(result, expected)
  648: 
  649:     result = concat([df2, df1], ignore_index=True)
  650:     expected = DataFrame({"a": [4, 5, 6, 1, 2, 3]}, dtype="Int64")
  651:     tm.assert_frame_equal(result, expected)
  652: 
  653: 
  654: def test_concat_preserves_extension_int64_dtype():
  655:     # GH 24768
  656:     df_a = DataFrame({"a": [-1]}, dtype="Int64")
  657:     df_b = DataFrame({"b": [1]}, dtype="Int64")
  658:     result = concat([df_a, df_b], ignore_index=True)
  659:     expected = DataFrame({"a": [-1, None], "b": [None, 1]}, dtype="Int64")
  660:     tm.assert_frame_equal(result, expected)
  661: 
  662: 
  663: @pytest.mark.parametrize(
  664:     "dtype1,dtype2,expected_dtype",
  665:     [
  666:         ("bool", "bool", "bool"),
  667:         ("boolean", "bool", "boolean"),
  668:         ("bool", "boolean", "boolean"),
  669:         ("boolean", "boolean", "boolean"),
  670:     ],
  671: )
  672: def test_concat_bool_types(dtype1, dtype2, expected_dtype):
  673:     # GH 42800
  674:     ser1 = Series([True, False], dtype=dtype1)
  675:     ser2 = Series([False, True], dtype=dtype2)
  676:     result = concat([ser1, ser2], ignore_index=True)
  677:     expected = Series([True, False, False, True], dtype=expected_dtype)
  678:     tm.assert_series_equal(result, expected)
  679: 
  680: 
  681: @pytest.mark.parametrize(
  682:     ("keys", "integrity"),
  683:     [
  684:         (["red"] * 3, True),
  685:         (["red"] * 3, False),
  686:         (["red", "blue", "red"], False),
  687:         (["red", "blue", "red"], True),
  688:     ],
  689: )
  690: def test_concat_repeated_keys(keys, integrity):
  691:     # GH: 20816
  692:     series_list = [Series({"a": 1}), Series({"b": 2}), Series({"c": 3})]
  693:     result = concat(series_list, keys=keys, verify_integrity=integrity)
  694:     tuples = list(zip(keys, ["a", "b", "c"]))
  695:     expected = Series([1, 2, 3], index=MultiIndex.from_tuples(tuples))
  696:     tm.assert_series_equal(result, expected)
  697: 
  698: 
  699: def test_concat_null_object_with_dti():
  700:     # GH#40841
  701:     dti = pd.DatetimeIndex(
  702:         ["2021-04-08 21:21:14+00:00"], dtype="datetime64[ns, UTC]", name="Time (UTC)"
  703:     )
  704:     right = DataFrame(data={"C": [0.5274]}, index=dti)
  705: 
  706:     idx = Index([None], dtype="object", name="Maybe Time (UTC)")
  707:     left = DataFrame(data={"A": [None], "B": [np.nan]}, index=idx)
  708: 
  709:     result = concat([left, right], axis="columns")
  710: 
  711:     exp_index = Index([None, dti[0]], dtype=object)
  712:     expected = DataFrame(
  713:         {
  714:             "A": np.array([None, np.nan], dtype=object),
  715:             "B": [np.nan, np.nan],
  716:             "C": [np.nan, 0.5274],
  717:         },
  718:         index=exp_index,
  719:     )
  720:     tm.assert_frame_equal(result, expected)
  721: 
  722: 
  723: def test_concat_multiindex_with_empty_rangeindex():
  724:     # GH#41234
  725:     mi = MultiIndex.from_tuples([("B", 1), ("C", 1)])
  726:     df1 = DataFrame([[1, 2]], columns=mi)
  727:     df2 = DataFrame(index=[1], columns=pd.RangeIndex(0))
  728: 
  729:     result = concat([df1, df2])
  730:     expected = DataFrame([[1, 2], [np.nan, np.nan]], columns=mi)
  731:     tm.assert_frame_equal(result, expected)
  732: 
  733: 
  734: @pytest.mark.parametrize(
  735:     "data",
  736:     [
  737:         Series(data=[1, 2]),
  738:         DataFrame(
  739:             data={
  740:                 "col1": [1, 2],
  741:             }
  742:         ),
  743:         DataFrame(dtype=float),
  744:         Series(dtype=float),
  745:     ],
  746: )
  747: def test_concat_drop_attrs(data):
  748:     # GH#41828
  749:     df1 = data.copy()
  750:     df1.attrs = {1: 1}
  751:     df2 = data.copy()
  752:     df2.attrs = {1: 2}
  753:     df = concat([df1, df2])
  754:     assert len(df.attrs) == 0
  755: 
  756: 
  757: @pytest.mark.parametrize(
  758:     "data",
  759:     [
  760:         Series(data=[1, 2]),
  761:         DataFrame(
  762:             data={
  763:                 "col1": [1, 2],
  764:             }
  765:         ),
  766:         DataFrame(dtype=float),
  767:         Series(dtype=float),
  768:     ],
  769: )
  770: def test_concat_retain_attrs(data):
  771:     # GH#41828
  772:     df1 = data.copy()
  773:     df1.attrs = {1: 1}
  774:     df2 = data.copy()
  775:     df2.attrs = {1: 1}
  776:     df = concat([df1, df2])
  777:     assert df.attrs[1] == 1
  778: 
  779: 
  780: @td.skip_array_manager_invalid_test
  781: @pytest.mark.parametrize("df_dtype", ["float64", "int64", "datetime64[ns]"])
  782: @pytest.mark.parametrize("empty_dtype", [None, "float64", "object"])
  783: def test_concat_ignore_empty_object_float(empty_dtype, df_dtype):
  784:     # https://github.com/pandas-dev/pandas/issues/45637
  785:     df = DataFrame({"foo": [1, 2], "bar": [1, 2]}, dtype=df_dtype)
  786:     empty = DataFrame(columns=["foo", "bar"], dtype=empty_dtype)
  787: 
  788:     msg = "The behavior of DataFrame concatenation with empty or all-NA entries"
  789:     warn = None
  790:     if df_dtype == "datetime64[ns]" or (
  791:         df_dtype == "float64" and empty_dtype != "float64"
  792:     ):
  793:         warn = FutureWarning
  794:     with tm.assert_produces_warning(warn, match=msg):
  795:         result = concat([empty, df])
  796:     expected = df
  797:     if df_dtype == "int64":
  798:         # TODO what exact behaviour do we want for integer eventually?
  799:         if empty_dtype == "float64":
  800:             expected = df.astype("float64")
  801:         else:
  802:             expected = df.astype("object")
  803:     tm.assert_frame_equal(result, expected)
  804: 
  805: 
  806: @td.skip_array_manager_invalid_test
  807: @pytest.mark.parametrize("df_dtype", ["float64", "int64", "datetime64[ns]"])
  808: @pytest.mark.parametrize("empty_dtype", [None, "float64", "object"])
  809: def test_concat_ignore_all_na_object_float(empty_dtype, df_dtype):
  810:     df = DataFrame({"foo": [1, 2], "bar": [1, 2]}, dtype=df_dtype)
  811:     empty = DataFrame({"foo": [np.nan], "bar": [np.nan]}, dtype=empty_dtype)
  812: 
  813:     if df_dtype == "int64":
  814:         # TODO what exact behaviour do we want for integer eventually?
  815:         if empty_dtype == "object":
  816:             df_dtype = "object"
  817:         else:
  818:             df_dtype = "float64"
  819: 
  820:     msg = "The behavior of DataFrame concatenation with empty or all-NA entries"
  821:     warn = None
  822:     if empty_dtype != df_dtype and empty_dtype is not None:
  823:         warn = FutureWarning
  824:     elif df_dtype == "datetime64[ns]":
  825:         warn = FutureWarning
  826: 
  827:     with tm.assert_produces_warning(warn, match=msg):
  828:         result = concat([empty, df], ignore_index=True)
  829: 
  830:     expected = DataFrame({"foo": [np.nan, 1, 2], "bar": [np.nan, 1, 2]}, dtype=df_dtype)
  831:     tm.assert_frame_equal(result, expected)
  832: 
  833: 
  834: @td.skip_array_manager_invalid_test
  835: def test_concat_ignore_empty_from_reindex():
  836:     # https://github.com/pandas-dev/pandas/pull/43507#issuecomment-920375856
  837:     df1 = DataFrame({"a": [1], "b": [pd.Timestamp("2012-01-01")]})
  838:     df2 = DataFrame({"a": [2]})
  839: 
  840:     aligned = df2.reindex(columns=df1.columns)
  841: 
  842:     msg = "The behavior of DataFrame concatenation with empty or all-NA entries"
  843:     with tm.assert_produces_warning(FutureWarning, match=msg):
  844:         result = concat([df1, aligned], ignore_index=True)
  845:     expected = df1 = DataFrame({"a": [1, 2], "b": [pd.Timestamp("2012-01-01"), pd.NaT]})
  846:     tm.assert_frame_equal(result, expected)
  847: 
  848: 
  849: def test_concat_mismatched_keys_length():
  850:     # GH#43485
  851:     ser = Series(range(5))
  852:     sers = [ser + n for n in range(4)]
  853:     keys = ["A", "B", "C"]
  854: 
  855:     msg = r"The behavior of pd.concat with len\(keys\) != len\(objs\) is deprecated"
  856:     with tm.assert_produces_warning(FutureWarning, match=msg):
  857:         concat(sers, keys=keys, axis=1)
  858:     with tm.assert_produces_warning(FutureWarning, match=msg):
  859:         concat(sers, keys=keys, axis=0)
  860:     with tm.assert_produces_warning(FutureWarning, match=msg):
  861:         concat((x for x in sers), keys=(y for y in keys), axis=1)
  862:     with tm.assert_produces_warning(FutureWarning, match=msg):
  863:         concat((x for x in sers), keys=(y for y in keys), axis=0)
  864: 
  865: 
  866: def test_concat_multiindex_with_category():
  867:     df1 = DataFrame(
  868:         {
  869:             "c1": Series(list("abc"), dtype="category"),
  870:             "c2": Series(list("eee"), dtype="category"),
  871:             "i2": Series([1, 2, 3]),
  872:         }
  873:     )
  874:     df1 = df1.set_index(["c1", "c2"])
  875:     df2 = DataFrame(
  876:         {
  877:             "c1": Series(list("abc"), dtype="category"),
  878:             "c2": Series(list("eee"), dtype="category"),
  879:             "i2": Series([4, 5, 6]),
  880:         }
  881:     )
  882:     df2 = df2.set_index(["c1", "c2"])
  883:     result = concat([df1, df2])
  884:     expected = DataFrame(
  885:         {
  886:             "c1": Series(list("abcabc"), dtype="category"),
  887:             "c2": Series(list("eeeeee"), dtype="category"),
  888:             "i2": Series([1, 2, 3, 4, 5, 6]),
  889:         }
  890:     )
  891:     expected = expected.set_index(["c1", "c2"])
  892:     tm.assert_frame_equal(result, expected)
  893: 
  894: 
  895: def test_concat_ea_upcast():
  896:     # GH#54848
  897:     df1 = DataFrame(["a"], dtype="string")
  898:     df2 = DataFrame([1], dtype="Int64")
  899:     result = concat([df1, df2])
  900:     expected = DataFrame(["a", 1], index=[0, 0])
  901:     tm.assert_frame_equal(result, expected)
  902: 
  903: 
  904: def test_concat_none_with_timezone_timestamp():
  905:     # GH#52093
  906:     df1 = DataFrame([{"A": None}])
  907:     df2 = DataFrame([{"A": pd.Timestamp("1990-12-20 00:00:00+00:00")}])
  908:     msg = "The behavior of DataFrame concatenation with empty or all-NA entries"
  909:     with tm.assert_produces_warning(FutureWarning, match=msg):
  910:         result = concat([df1, df2], ignore_index=True)
  911:     expected = DataFrame({"A": [None, pd.Timestamp("1990-12-20 00:00:00+00:00")]})
  912:     tm.assert_frame_equal(result, expected)
