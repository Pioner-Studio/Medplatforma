    1: import datetime
    2: 
    3: import numpy as np
    4: import pytest
    5: import pytz
    6: 
    7: import pandas.util._test_decorators as td
    8: 
    9: import pandas as pd
   10: from pandas import (
   11:     Index,
   12:     Timedelta,
   13:     merge_asof,
   14:     option_context,
   15:     to_datetime,
   16: )
   17: import pandas._testing as tm
   18: from pandas.core.reshape.merge import MergeError
   19: 
   20: 
   21: @pytest.fixture(params=["s", "ms", "us", "ns"])
   22: def unit(request):
   23:     """
   24:     Resolution for datetimelike dtypes.
   25:     """
   26:     return request.param
   27: 
   28: 
   29: class TestAsOfMerge:
   30:     def prep_data(self, df, dedupe=False):
   31:         if dedupe:
   32:             df = df.drop_duplicates(["time", "ticker"], keep="last").reset_index(
   33:                 drop=True
   34:             )
   35:         df.time = to_datetime(df.time)
   36:         return df
   37: 
   38:     @pytest.fixture
   39:     def trades(self):
   40:         df = pd.DataFrame(
   41:             [
   42:                 ["20160525 13:30:00.023", "MSFT", "51.9500", "75", "NASDAQ"],
   43:                 ["20160525 13:30:00.038", "MSFT", "51.9500", "155", "NASDAQ"],
   44:                 ["20160525 13:30:00.048", "GOOG", "720.7700", "100", "NASDAQ"],
   45:                 ["20160525 13:30:00.048", "GOOG", "720.9200", "100", "NASDAQ"],
   46:                 ["20160525 13:30:00.048", "GOOG", "720.9300", "200", "NASDAQ"],
   47:                 ["20160525 13:30:00.048", "GOOG", "720.9300", "300", "NASDAQ"],
   48:                 ["20160525 13:30:00.048", "GOOG", "720.9300", "600", "NASDAQ"],
   49:                 ["20160525 13:30:00.048", "GOOG", "720.9300", "44", "NASDAQ"],
   50:                 ["20160525 13:30:00.074", "AAPL", "98.6700", "478343", "NASDAQ"],
   51:                 ["20160525 13:30:00.075", "AAPL", "98.6700", "478343", "NASDAQ"],
   52:                 ["20160525 13:30:00.075", "AAPL", "98.6600", "6", "NASDAQ"],
   53:                 ["20160525 13:30:00.075", "AAPL", "98.6500", "30", "NASDAQ"],
   54:                 ["20160525 13:30:00.075", "AAPL", "98.6500", "75", "NASDAQ"],
   55:                 ["20160525 13:30:00.075", "AAPL", "98.6500", "20", "NASDAQ"],
   56:                 ["20160525 13:30:00.075", "AAPL", "98.6500", "35", "NASDAQ"],
   57:                 ["20160525 13:30:00.075", "AAPL", "98.6500", "10", "NASDAQ"],
   58:                 ["20160525 13:30:00.075", "AAPL", "98.5500", "6", "ARCA"],
   59:                 ["20160525 13:30:00.075", "AAPL", "98.5500", "6", "ARCA"],
   60:                 ["20160525 13:30:00.076", "AAPL", "98.5600", "1000", "ARCA"],
   61:                 ["20160525 13:30:00.076", "AAPL", "98.5600", "200", "ARCA"],
   62:                 ["20160525 13:30:00.076", "AAPL", "98.5600", "300", "ARCA"],
   63:                 ["20160525 13:30:00.076", "AAPL", "98.5600", "400", "ARCA"],
   64:                 ["20160525 13:30:00.076", "AAPL", "98.5600", "600", "ARCA"],
   65:                 ["20160525 13:30:00.076", "AAPL", "98.5600", "200", "ARCA"],
   66:                 ["20160525 13:30:00.078", "MSFT", "51.9500", "783", "NASDAQ"],
   67:                 ["20160525 13:30:00.078", "MSFT", "51.9500", "100", "NASDAQ"],
   68:                 ["20160525 13:30:00.078", "MSFT", "51.9500", "100", "NASDAQ"],
   69:             ],
   70:             columns="time,ticker,price,quantity,marketCenter".split(","),
   71:         )
   72:         df["price"] = df["price"].astype("float64")
   73:         df["quantity"] = df["quantity"].astype("int64")
   74:         return self.prep_data(df)
   75: 
   76:     @pytest.fixture
   77:     def quotes(self):
   78:         df = pd.DataFrame(
   79:             [
   80:                 ["20160525 13:30:00.023", "GOOG", "720.50", "720.93"],
   81:                 ["20160525 13:30:00.023", "MSFT", "51.95", "51.95"],
   82:                 ["20160525 13:30:00.041", "MSFT", "51.95", "51.95"],
   83:                 ["20160525 13:30:00.048", "GOOG", "720.50", "720.93"],
   84:                 ["20160525 13:30:00.048", "GOOG", "720.50", "720.93"],
   85:                 ["20160525 13:30:00.048", "GOOG", "720.50", "720.93"],
   86:                 ["20160525 13:30:00.048", "GOOG", "720.50", "720.93"],
   87:                 ["20160525 13:30:00.072", "GOOG", "720.50", "720.88"],
   88:                 ["20160525 13:30:00.075", "AAPL", "98.55", "98.56"],
   89:                 ["20160525 13:30:00.076", "AAPL", "98.55", "98.56"],
   90:                 ["20160525 13:30:00.076", "AAPL", "98.55", "98.56"],
   91:                 ["20160525 13:30:00.076", "AAPL", "98.55", "98.56"],
   92:                 ["20160525 13:30:00.078", "MSFT", "51.95", "51.95"],
   93:                 ["20160525 13:30:00.078", "MSFT", "51.95", "51.95"],
   94:                 ["20160525 13:30:00.078", "MSFT", "51.95", "51.95"],
   95:                 ["20160525 13:30:00.078", "MSFT", "51.92", "51.95"],
   96:             ],
   97:             columns="time,ticker,bid,ask".split(","),
   98:         )
   99:         df["bid"] = df["bid"].astype("float64")
  100:         df["ask"] = df["ask"].astype("float64")
  101:         return self.prep_data(df, dedupe=True)
  102: 
  103:     @pytest.fixture
  104:     def asof(self):
  105:         df = pd.DataFrame(
  106:             [
  107:                 [
  108:                     "20160525 13:30:00.023",
  109:                     "MSFT",
  110:                     "51.95",
  111:                     "75",
  112:                     "NASDAQ",
  113:                     "51.95",
  114:                     "51.95",
  115:                 ],
  116:                 [
  117:                     "20160525 13:30:00.038",
  118:                     "MSFT",
  119:                     "51.95",
  120:                     "155",
  121:                     "NASDAQ",
  122:                     "51.95",
  123:                     "51.95",
  124:                 ],
  125:                 [
  126:                     "20160525 13:30:00.048",
  127:                     "GOOG",
  128:                     "720.77",
  129:                     "100",
  130:                     "NASDAQ",
  131:                     "720.5",
  132:                     "720.93",
  133:                 ],
  134:                 [
  135:                     "20160525 13:30:00.048",
  136:                     "GOOG",
  137:                     "720.92",
  138:                     "100",
  139:                     "NASDAQ",
  140:                     "720.5",
  141:                     "720.93",
  142:                 ],
  143:                 [
  144:                     "20160525 13:30:00.048",
  145:                     "GOOG",
  146:                     "720.93",
  147:                     "200",
  148:                     "NASDAQ",
  149:                     "720.5",
  150:                     "720.93",
  151:                 ],
  152:                 [
  153:                     "20160525 13:30:00.048",
  154:                     "GOOG",
  155:                     "720.93",
  156:                     "300",
  157:                     "NASDAQ",
  158:                     "720.5",
  159:                     "720.93",
  160:                 ],
  161:                 [
  162:                     "20160525 13:30:00.048",
  163:                     "GOOG",
  164:                     "720.93",
  165:                     "600",
  166:                     "NASDAQ",
  167:                     "720.5",
  168:                     "720.93",
  169:                 ],
  170:                 [
  171:                     "20160525 13:30:00.048",
  172:                     "GOOG",
  173:                     "720.93",
  174:                     "44",
  175:                     "NASDAQ",
  176:                     "720.5",
  177:                     "720.93",
  178:                 ],
  179:                 [
  180:                     "20160525 13:30:00.074",
  181:                     "AAPL",
  182:                     "98.67",
  183:                     "478343",
  184:                     "NASDAQ",
  185:                     np.nan,
  186:                     np.nan,
  187:                 ],
  188:                 [
  189:                     "20160525 13:30:00.075",
  190:                     "AAPL",
  191:                     "98.67",
  192:                     "478343",
  193:                     "NASDAQ",
  194:                     "98.55",
  195:                     "98.56",
  196:                 ],
  197:                 [
  198:                     "20160525 13:30:00.075",
  199:                     "AAPL",
  200:                     "98.66",
  201:                     "6",
  202:                     "NASDAQ",
  203:                     "98.55",
  204:                     "98.56",
  205:                 ],
  206:                 [
  207:                     "20160525 13:30:00.075",
  208:                     "AAPL",
  209:                     "98.65",
  210:                     "30",
  211:                     "NASDAQ",
  212:                     "98.55",
  213:                     "98.56",
  214:                 ],
  215:                 [
  216:                     "20160525 13:30:00.075",
  217:                     "AAPL",
  218:                     "98.65",
  219:                     "75",
  220:                     "NASDAQ",
  221:                     "98.55",
  222:                     "98.56",
  223:                 ],
  224:                 [
  225:                     "20160525 13:30:00.075",
  226:                     "AAPL",
  227:                     "98.65",
  228:                     "20",
  229:                     "NASDAQ",
  230:                     "98.55",
  231:                     "98.56",
  232:                 ],
  233:                 [
  234:                     "20160525 13:30:00.075",
  235:                     "AAPL",
  236:                     "98.65",
  237:                     "35",
  238:                     "NASDAQ",
  239:                     "98.55",
  240:                     "98.56",
  241:                 ],
  242:                 [
  243:                     "20160525 13:30:00.075",
  244:                     "AAPL",
  245:                     "98.65",
  246:                     "10",
  247:                     "NASDAQ",
  248:                     "98.55",
  249:                     "98.56",
  250:                 ],
  251:                 [
  252:                     "20160525 13:30:00.075",
  253:                     "AAPL",
  254:                     "98.55",
  255:                     "6",
  256:                     "ARCA",
  257:                     "98.55",
  258:                     "98.56",
  259:                 ],
  260:                 [
  261:                     "20160525 13:30:00.075",
  262:                     "AAPL",
  263:                     "98.55",
  264:                     "6",
  265:                     "ARCA",
  266:                     "98.55",
  267:                     "98.56",
  268:                 ],
  269:                 [
  270:                     "20160525 13:30:00.076",
  271:                     "AAPL",
  272:                     "98.56",
  273:                     "1000",
  274:                     "ARCA",
  275:                     "98.55",
  276:                     "98.56",
  277:                 ],
  278:                 [
  279:                     "20160525 13:30:00.076",
  280:                     "AAPL",
  281:                     "98.56",
  282:                     "200",
  283:                     "ARCA",
  284:                     "98.55",
  285:                     "98.56",
  286:                 ],
  287:                 [
  288:                     "20160525 13:30:00.076",
  289:                     "AAPL",
  290:                     "98.56",
  291:                     "300",
  292:                     "ARCA",
  293:                     "98.55",
  294:                     "98.56",
  295:                 ],
  296:                 [
  297:                     "20160525 13:30:00.076",
  298:                     "AAPL",
  299:                     "98.56",
  300:                     "400",
  301:                     "ARCA",
  302:                     "98.55",
  303:                     "98.56",
  304:                 ],
  305:                 [
  306:                     "20160525 13:30:00.076",
  307:                     "AAPL",
  308:                     "98.56",
  309:                     "600",
  310:                     "ARCA",
  311:                     "98.55",
  312:                     "98.56",
  313:                 ],
  314:                 [
  315:                     "20160525 13:30:00.076",
  316:                     "AAPL",
  317:                     "98.56",
  318:                     "200",
  319:                     "ARCA",
  320:                     "98.55",
  321:                     "98.56",
  322:                 ],
  323:                 [
  324:                     "20160525 13:30:00.078",
  325:                     "MSFT",
  326:                     "51.95",
  327:                     "783",
  328:                     "NASDAQ",
  329:                     "51.92",
  330:                     "51.95",
  331:                 ],
  332:                 [
  333:                     "20160525 13:30:00.078",
  334:                     "MSFT",
  335:                     "51.95",
  336:                     "100",
  337:                     "NASDAQ",
  338:                     "51.92",
  339:                     "51.95",
  340:                 ],
  341:                 [
  342:                     "20160525 13:30:00.078",
  343:                     "MSFT",
  344:                     "51.95",
  345:                     "100",
  346:                     "NASDAQ",
  347:                     "51.92",
  348:                     "51.95",
  349:                 ],
  350:             ],
  351:             columns="time,ticker,price,quantity,marketCenter,bid,ask".split(","),
  352:         )
  353:         df["price"] = df["price"].astype("float64")
  354:         df["quantity"] = df["quantity"].astype("int64")
  355:         df["bid"] = df["bid"].astype("float64")
  356:         df["ask"] = df["ask"].astype("float64")
  357:         return self.prep_data(df)
  358: 
  359:     @pytest.fixture
  360:     def tolerance(self):
  361:         df = pd.DataFrame(
  362:             [
  363:                 [
  364:                     "20160525 13:30:00.023",
  365:                     "MSFT",
  366:                     "51.95",
  367:                     "75",
  368:                     "NASDAQ",
  369:                     "51.95",
  370:                     "51.95",
  371:                 ],
  372:                 [
  373:                     "20160525 13:30:00.038",
  374:                     "MSFT",
  375:                     "51.95",
  376:                     "155",
  377:                     "NASDAQ",
  378:                     "51.95",
  379:                     "51.95",
  380:                 ],
  381:                 [
  382:                     "20160525 13:30:00.048",
  383:                     "GOOG",
  384:                     "720.77",
  385:                     "100",
  386:                     "NASDAQ",
  387:                     "720.5",
  388:                     "720.93",
  389:                 ],
  390:                 [
  391:                     "20160525 13:30:00.048",
  392:                     "GOOG",
  393:                     "720.92",
  394:                     "100",
  395:                     "NASDAQ",
  396:                     "720.5",
  397:                     "720.93",
  398:                 ],
  399:                 [
  400:                     "20160525 13:30:00.048",
  401:                     "GOOG",
  402:                     "720.93",
  403:                     "200",
  404:                     "NASDAQ",
  405:                     "720.5",
  406:                     "720.93",
  407:                 ],
  408:                 [
  409:                     "20160525 13:30:00.048",
  410:                     "GOOG",
  411:                     "720.93",
  412:                     "300",
  413:                     "NASDAQ",
  414:                     "720.5",
  415:                     "720.93",
  416:                 ],
  417:                 [
  418:                     "20160525 13:30:00.048",
  419:                     "GOOG",
  420:                     "720.93",
  421:                     "600",
  422:                     "NASDAQ",
  423:                     "720.5",
  424:                     "720.93",
  425:                 ],
  426:                 [
  427:                     "20160525 13:30:00.048",
  428:                     "GOOG",
  429:                     "720.93",
  430:                     "44",
  431:                     "NASDAQ",
  432:                     "720.5",
  433:                     "720.93",
  434:                 ],
  435:                 [
  436:                     "20160525 13:30:00.074",
  437:                     "AAPL",
  438:                     "98.67",
  439:                     "478343",
  440:                     "NASDAQ",
  441:                     np.nan,
  442:                     np.nan,
  443:                 ],
  444:                 [
  445:                     "20160525 13:30:00.075",
  446:                     "AAPL",
  447:                     "98.67",
  448:                     "478343",
  449:                     "NASDAQ",
  450:                     "98.55",
  451:                     "98.56",
  452:                 ],
  453:                 [
  454:                     "20160525 13:30:00.075",
  455:                     "AAPL",
  456:                     "98.66",
  457:                     "6",
  458:                     "NASDAQ",
  459:                     "98.55",
  460:                     "98.56",
  461:                 ],
  462:                 [
  463:                     "20160525 13:30:00.075",
  464:                     "AAPL",
  465:                     "98.65",
  466:                     "30",
  467:                     "NASDAQ",
  468:                     "98.55",
  469:                     "98.56",
  470:                 ],
  471:                 [
  472:                     "20160525 13:30:00.075",
  473:                     "AAPL",
  474:                     "98.65",
  475:                     "75",
  476:                     "NASDAQ",
  477:                     "98.55",
  478:                     "98.56",
  479:                 ],
  480:                 [
  481:                     "20160525 13:30:00.075",
  482:                     "AAPL",
  483:                     "98.65",
  484:                     "20",
  485:                     "NASDAQ",
  486:                     "98.55",
  487:                     "98.56",
  488:                 ],
  489:                 [
  490:                     "20160525 13:30:00.075",
  491:                     "AAPL",
  492:                     "98.65",
  493:                     "35",
  494:                     "NASDAQ",
  495:                     "98.55",
  496:                     "98.56",
  497:                 ],
  498:                 [
  499:                     "20160525 13:30:00.075",
  500:                     "AAPL",
  501:                     "98.65",
  502:                     "10",
  503:                     "NASDAQ",
  504:                     "98.55",
  505:                     "98.56",
  506:                 ],
  507:                 [
  508:                     "20160525 13:30:00.075",
  509:                     "AAPL",
  510:                     "98.55",
  511:                     "6",
  512:                     "ARCA",
  513:                     "98.55",
  514:                     "98.56",
  515:                 ],
  516:                 [
  517:                     "20160525 13:30:00.075",
  518:                     "AAPL",
  519:                     "98.55",
  520:                     "6",
  521:                     "ARCA",
  522:                     "98.55",
  523:                     "98.56",
  524:                 ],
  525:                 [
  526:                     "20160525 13:30:00.076",
  527:                     "AAPL",
  528:                     "98.56",
  529:                     "1000",
  530:                     "ARCA",
  531:                     "98.55",
  532:                     "98.56",
  533:                 ],
  534:                 [
  535:                     "20160525 13:30:00.076",
  536:                     "AAPL",
  537:                     "98.56",
  538:                     "200",
  539:                     "ARCA",
  540:                     "98.55",
  541:                     "98.56",
  542:                 ],
  543:                 [
  544:                     "20160525 13:30:00.076",
  545:                     "AAPL",
  546:                     "98.56",
  547:                     "300",
  548:                     "ARCA",
  549:                     "98.55",
  550:                     "98.56",
  551:                 ],
  552:                 [
  553:                     "20160525 13:30:00.076",
  554:                     "AAPL",
  555:                     "98.56",
  556:                     "400",
  557:                     "ARCA",
  558:                     "98.55",
  559:                     "98.56",
  560:                 ],
  561:                 [
  562:                     "20160525 13:30:00.076",
  563:                     "AAPL",
  564:                     "98.56",
  565:                     "600",
  566:                     "ARCA",
  567:                     "98.55",
  568:                     "98.56",
  569:                 ],
  570:                 [
  571:                     "20160525 13:30:00.076",
  572:                     "AAPL",
  573:                     "98.56",
  574:                     "200",
  575:                     "ARCA",
  576:                     "98.55",
  577:                     "98.56",
  578:                 ],
  579:                 [
  580:                     "20160525 13:30:00.078",
  581:                     "MSFT",
  582:                     "51.95",
  583:                     "783",
  584:                     "NASDAQ",
  585:                     "51.92",
  586:                     "51.95",
  587:                 ],
  588:                 [
  589:                     "20160525 13:30:00.078",
  590:                     "MSFT",
  591:                     "51.95",
  592:                     "100",
  593:                     "NASDAQ",
  594:                     "51.92",
  595:                     "51.95",
  596:                 ],
  597:                 [
  598:                     "20160525 13:30:00.078",
  599:                     "MSFT",
  600:                     "51.95",
  601:                     "100",
  602:                     "NASDAQ",
  603:                     "51.92",
  604:                     "51.95",
  605:                 ],
  606:             ],
  607:             columns="time,ticker,price,quantity,marketCenter,bid,ask".split(","),
  608:         )
  609:         df["price"] = df["price"].astype("float64")
  610:         df["quantity"] = df["quantity"].astype("int64")
  611:         df["bid"] = df["bid"].astype("float64")
  612:         df["ask"] = df["ask"].astype("float64")
  613:         return self.prep_data(df)
  614: 
  615:     @pytest.fixture
  616:     def allow_exact_matches(self, datapath):
  617:         df = pd.DataFrame(
  618:             [
  619:                 [
  620:                     "20160525 13:30:00.023",
  621:                     "MSFT",
  622:                     "51.95",
  623:                     "75",
  624:                     "NASDAQ",
  625:                     np.nan,
  626:                     np.nan,
  627:                 ],
  628:                 [
  629:                     "20160525 13:30:00.038",
  630:                     "MSFT",
  631:                     "51.95",
  632:                     "155",
  633:                     "NASDAQ",
  634:                     "51.95",
  635:                     "51.95",
  636:                 ],
  637:                 [
  638:                     "20160525 13:30:00.048",
  639:                     "GOOG",
  640:                     "720.77",
  641:                     "100",
  642:                     "NASDAQ",
  643:                     "720.5",
  644:                     "720.93",
  645:                 ],
  646:                 [
  647:                     "20160525 13:30:00.048",
  648:                     "GOOG",
  649:                     "720.92",
  650:                     "100",
  651:                     "NASDAQ",
  652:                     "720.5",
  653:                     "720.93",
  654:                 ],
  655:                 [
  656:                     "20160525 13:30:00.048",
  657:                     "GOOG",
  658:                     "720.93",
  659:                     "200",
  660:                     "NASDAQ",
  661:                     "720.5",
  662:                     "720.93",
  663:                 ],
  664:                 [
  665:                     "20160525 13:30:00.048",
  666:                     "GOOG",
  667:                     "720.93",
  668:                     "300",
  669:                     "NASDAQ",
  670:                     "720.5",
  671:                     "720.93",
  672:                 ],
  673:                 [
  674:                     "20160525 13:30:00.048",
  675:                     "GOOG",
  676:                     "720.93",
  677:                     "600",
  678:                     "NASDAQ",
  679:                     "720.5",
  680:                     "720.93",
  681:                 ],
  682:                 [
  683:                     "20160525 13:30:00.048",
  684:                     "GOOG",
  685:                     "720.93",
  686:                     "44",
  687:                     "NASDAQ",
  688:                     "720.5",
  689:                     "720.93",
  690:                 ],
  691:                 [
  692:                     "20160525 13:30:00.074",
  693:                     "AAPL",
  694:                     "98.67",
  695:                     "478343",
  696:                     "NASDAQ",
  697:                     np.nan,
  698:                     np.nan,
  699:                 ],
  700:                 [
  701:                     "20160525 13:30:00.075",
  702:                     "AAPL",
  703:                     "98.67",
  704:                     "478343",
  705:                     "NASDAQ",
  706:                     np.nan,
  707:                     np.nan,
  708:                 ],
  709:                 [
  710:                     "20160525 13:30:00.075",
  711:                     "AAPL",
  712:                     "98.66",
  713:                     "6",
  714:                     "NASDAQ",
  715:                     np.nan,
  716:                     np.nan,
  717:                 ],
  718:                 [
  719:                     "20160525 13:30:00.075",
  720:                     "AAPL",
  721:                     "98.65",
  722:                     "30",
  723:                     "NASDAQ",
  724:                     np.nan,
  725:                     np.nan,
  726:                 ],
  727:                 [
  728:                     "20160525 13:30:00.075",
  729:                     "AAPL",
  730:                     "98.65",
  731:                     "75",
  732:                     "NASDAQ",
  733:                     np.nan,
  734:                     np.nan,
  735:                 ],
  736:                 [
  737:                     "20160525 13:30:00.075",
  738:                     "AAPL",
  739:                     "98.65",
  740:                     "20",
  741:                     "NASDAQ",
  742:                     np.nan,
  743:                     np.nan,
  744:                 ],
  745:                 [
  746:                     "20160525 13:30:00.075",
  747:                     "AAPL",
  748:                     "98.65",
  749:                     "35",
  750:                     "NASDAQ",
  751:                     np.nan,
  752:                     np.nan,
  753:                 ],
  754:                 [
  755:                     "20160525 13:30:00.075",
  756:                     "AAPL",
  757:                     "98.65",
  758:                     "10",
  759:                     "NASDAQ",
  760:                     np.nan,
  761:                     np.nan,
  762:                 ],
  763:                 ["20160525 13:30:00.075", "AAPL", "98.55", "6", "ARCA", np.nan, np.nan],
  764:                 ["20160525 13:30:00.075", "AAPL", "98.55", "6", "ARCA", np.nan, np.nan],
  765:                 [
  766:                     "20160525 13:30:00.076",
  767:                     "AAPL",
  768:                     "98.56",
  769:                     "1000",
  770:                     "ARCA",
  771:                     "98.55",
  772:                     "98.56",
  773:                 ],
  774:                 [
  775:                     "20160525 13:30:00.076",
  776:                     "AAPL",
  777:                     "98.56",
  778:                     "200",
  779:                     "ARCA",
  780:                     "98.55",
  781:                     "98.56",
  782:                 ],
  783:                 [
  784:                     "20160525 13:30:00.076",
  785:                     "AAPL",
  786:                     "98.56",
  787:                     "300",
  788:                     "ARCA",
  789:                     "98.55",
  790:                     "98.56",
  791:                 ],
  792:                 [
  793:                     "20160525 13:30:00.076",
  794:                     "AAPL",
  795:                     "98.56",
  796:                     "400",
  797:                     "ARCA",
  798:                     "98.55",
  799:                     "98.56",
  800:                 ],
  801:                 [
  802:                     "20160525 13:30:00.076",
  803:                     "AAPL",
  804:                     "98.56",
  805:                     "600",
  806:                     "ARCA",
  807:                     "98.55",
  808:                     "98.56",
  809:                 ],
  810:                 [
  811:                     "20160525 13:30:00.076",
  812:                     "AAPL",
  813:                     "98.56",
  814:                     "200",
  815:                     "ARCA",
  816:                     "98.55",
  817:                     "98.56",
  818:                 ],
  819:                 [
  820:                     "20160525 13:30:00.078",
  821:                     "MSFT",
  822:                     "51.95",
  823:                     "783",
  824:                     "NASDAQ",
  825:                     "51.95",
  826:                     "51.95",
  827:                 ],
  828:                 [
  829:                     "20160525 13:30:00.078",
  830:                     "MSFT",
  831:                     "51.95",
  832:                     "100",
  833:                     "NASDAQ",
  834:                     "51.95",
  835:                     "51.95",
  836:                 ],
  837:                 [
  838:                     "20160525 13:30:00.078",
  839:                     "MSFT",
  840:                     "51.95",
  841:                     "100",
  842:                     "NASDAQ",
  843:                     "51.95",
  844:                     "51.95",
  845:                 ],
  846:             ],
  847:             columns="time,ticker,price,quantity,marketCenter,bid,ask".split(","),
  848:         )
  849:         df["price"] = df["price"].astype("float64")
  850:         df["quantity"] = df["quantity"].astype("int64")
  851:         df["bid"] = df["bid"].astype("float64")
  852:         df["ask"] = df["ask"].astype("float64")
  853:         return self.prep_data(df)
  854: 
  855:     @pytest.fixture
  856:     def allow_exact_matches_and_tolerance(self):
  857:         df = pd.DataFrame(
  858:             [
  859:                 [
  860:                     "20160525 13:30:00.023",
  861:                     "MSFT",
  862:                     "51.95",
  863:                     "75",
  864:                     "NASDAQ",
  865:                     np.nan,
  866:                     np.nan,
  867:                 ],
  868:                 [
  869:                     "20160525 13:30:00.038",
  870:                     "MSFT",
  871:                     "51.95",
  872:                     "155",
  873:                     "NASDAQ",
  874:                     "51.95",
  875:                     "51.95",
  876:                 ],
  877:                 [
  878:                     "20160525 13:30:00.048",
  879:                     "GOOG",
  880:                     "720.77",
  881:                     "100",
  882:                     "NASDAQ",
  883:                     "720.5",
  884:                     "720.93",
  885:                 ],
  886:                 [
  887:                     "20160525 13:30:00.048",
  888:                     "GOOG",
  889:                     "720.92",
  890:                     "100",
  891:                     "NASDAQ",
  892:                     "720.5",
  893:                     "720.93",
  894:                 ],
  895:                 [
  896:                     "20160525 13:30:00.048",
  897:                     "GOOG",
  898:                     "720.93",
  899:                     "200",
  900:                     "NASDAQ",
  901:                     "720.5",
  902:                     "720.93",
  903:                 ],
  904:                 [
  905:                     "20160525 13:30:00.048",
  906:                     "GOOG",
  907:                     "720.93",
  908:                     "300",
  909:                     "NASDAQ",
  910:                     "720.5",
  911:                     "720.93",
  912:                 ],
  913:                 [
  914:                     "20160525 13:30:00.048",
  915:                     "GOOG",
  916:                     "720.93",
  917:                     "600",
  918:                     "NASDAQ",
  919:                     "720.5",
  920:                     "720.93",
  921:                 ],
  922:                 [
  923:                     "20160525 13:30:00.048",
  924:                     "GOOG",
  925:                     "720.93",
  926:                     "44",
  927:                     "NASDAQ",
  928:                     "720.5",
  929:                     "720.93",
  930:                 ],
  931:                 [
  932:                     "20160525 13:30:00.074",
  933:                     "AAPL",
  934:                     "98.67",
  935:                     "478343",
  936:                     "NASDAQ",
  937:                     np.nan,
  938:                     np.nan,
  939:                 ],
  940:                 [
  941:                     "20160525 13:30:00.075",
  942:                     "AAPL",
  943:                     "98.67",
  944:                     "478343",
  945:                     "NASDAQ",
  946:                     np.nan,
  947:                     np.nan,
  948:                 ],
  949:                 [
  950:                     "20160525 13:30:00.075",
  951:                     "AAPL",
  952:                     "98.66",
  953:                     "6",
  954:                     "NASDAQ",
  955:                     np.nan,
  956:                     np.nan,
  957:                 ],
  958:                 [
  959:                     "20160525 13:30:00.075",
  960:                     "AAPL",
  961:                     "98.65",
  962:                     "30",
  963:                     "NASDAQ",
  964:                     np.nan,
  965:                     np.nan,
  966:                 ],
  967:                 [
  968:                     "20160525 13:30:00.075",
  969:                     "AAPL",
  970:                     "98.65",
  971:                     "75",
  972:                     "NASDAQ",
  973:                     np.nan,
  974:                     np.nan,
  975:                 ],
  976:                 [
  977:                     "20160525 13:30:00.075",
  978:                     "AAPL",
  979:                     "98.65",
  980:                     "20",
  981:                     "NASDAQ",
  982:                     np.nan,
  983:                     np.nan,
  984:                 ],
  985:                 [
  986:                     "20160525 13:30:00.075",
  987:                     "AAPL",
  988:                     "98.65",
  989:                     "35",
  990:                     "NASDAQ",
  991:                     np.nan,
  992:                     np.nan,
  993:                 ],
  994:                 [
  995:                     "20160525 13:30:00.075",
  996:                     "AAPL",
  997:                     "98.65",
  998:                     "10",
  999:                     "NASDAQ",
 1000:                     np.nan,
 1001:                     np.nan,
 1002:                 ],
 1003:                 ["20160525 13:30:00.075", "AAPL", "98.55", "6", "ARCA", np.nan, np.nan],
 1004:                 ["20160525 13:30:00.075", "AAPL", "98.55", "6", "ARCA", np.nan, np.nan],
 1005:                 [
 1006:                     "20160525 13:30:00.076",
 1007:                     "AAPL",
 1008:                     "98.56",
 1009:                     "1000",
 1010:                     "ARCA",
 1011:                     "98.55",
 1012:                     "98.56",
 1013:                 ],
 1014:                 [
 1015:                     "20160525 13:30:00.076",
 1016:                     "AAPL",
 1017:                     "98.56",
 1018:                     "200",
 1019:                     "ARCA",
 1020:                     "98.55",
 1021:                     "98.56",
 1022:                 ],
 1023:                 [
 1024:                     "20160525 13:30:00.076",
 1025:                     "AAPL",
 1026:                     "98.56",
 1027:                     "300",
 1028:                     "ARCA",
 1029:                     "98.55",
 1030:                     "98.56",
 1031:                 ],
 1032:                 [
 1033:                     "20160525 13:30:00.076",
 1034:                     "AAPL",
 1035:                     "98.56",
 1036:                     "400",
 1037:                     "ARCA",
 1038:                     "98.55",
 1039:                     "98.56",
 1040:                 ],
 1041:                 [
 1042:                     "20160525 13:30:00.076",
 1043:                     "AAPL",
 1044:                     "98.56",
 1045:                     "600",
 1046:                     "ARCA",
 1047:                     "98.55",
 1048:                     "98.56",
 1049:                 ],
 1050:                 [
 1051:                     "20160525 13:30:00.076",
 1052:                     "AAPL",
 1053:                     "98.56",
 1054:                     "200",
 1055:                     "ARCA",
 1056:                     "98.55",
 1057:                     "98.56",
 1058:                 ],
 1059:                 [
 1060:                     "20160525 13:30:00.078",
 1061:                     "MSFT",
 1062:                     "51.95",
 1063:                     "783",
 1064:                     "NASDAQ",
 1065:                     "51.95",
 1066:                     "51.95",
 1067:                 ],
 1068:                 [
 1069:                     "20160525 13:30:00.078",
 1070:                     "MSFT",
 1071:                     "51.95",
 1072:                     "100",
 1073:                     "NASDAQ",
 1074:                     "51.95",
 1075:                     "51.95",
 1076:                 ],
 1077:                 [
 1078:                     "20160525 13:30:00.078",
 1079:                     "MSFT",
 1080:                     "51.95",
 1081:                     "100",
 1082:                     "NASDAQ",
 1083:                     "51.95",
 1084:                     "51.95",
 1085:                 ],
 1086:             ],
 1087:             columns="time,ticker,price,quantity,marketCenter,bid,ask".split(","),
 1088:         )
 1089:         df["price"] = df["price"].astype("float64")
 1090:         df["quantity"] = df["quantity"].astype("int64")
 1091:         df["bid"] = df["bid"].astype("float64")
 1092:         df["ask"] = df["ask"].astype("float64")
 1093:         return self.prep_data(df)
 1094: 
 1095:     def test_examples1(self):
 1096:         """doc-string examples"""
 1097:         left = pd.DataFrame({"a": [1, 5, 10], "left_val": ["a", "b", "c"]})
 1098:         right = pd.DataFrame({"a": [1, 2, 3, 6, 7], "right_val": [1, 2, 3, 6, 7]})
 1099: 
 1100:         expected = pd.DataFrame(
 1101:             {"a": [1, 5, 10], "left_val": ["a", "b", "c"], "right_val": [1, 3, 7]}
 1102:         )
 1103: 
 1104:         result = merge_asof(left, right, on="a")
 1105:         tm.assert_frame_equal(result, expected)
 1106: 
 1107:     def test_examples2(self, unit):
 1108:         """doc-string examples"""
 1109:         if unit == "s":
 1110:             pytest.skip(
 1111:                 "This test is invalid for unit='s' because that would "
 1112:                 "round the trades['time']]"
 1113:             )
 1114:         trades = pd.DataFrame(
 1115:             {
 1116:                 "time": to_datetime(
 1117:                     [
 1118:                         "20160525 13:30:00.023",
 1119:                         "20160525 13:30:00.038",
 1120:                         "20160525 13:30:00.048",
 1121:                         "20160525 13:30:00.048",
 1122:                         "20160525 13:30:00.048",
 1123:                     ]
 1124:                 ).astype(f"M8[{unit}]"),
 1125:                 "ticker": ["MSFT", "MSFT", "GOOG", "GOOG", "AAPL"],
 1126:                 "price": [51.95, 51.95, 720.77, 720.92, 98.00],
 1127:                 "quantity": [75, 155, 100, 100, 100],
 1128:             },
 1129:             columns=["time", "ticker", "price", "quantity"],
 1130:         )
 1131: 
 1132:         quotes = pd.DataFrame(
 1133:             {
 1134:                 "time": to_datetime(
 1135:                     [
 1136:                         "20160525 13:30:00.023",
 1137:                         "20160525 13:30:00.023",
 1138:                         "20160525 13:30:00.030",
 1139:                         "20160525 13:30:00.041",
 1140:                         "20160525 13:30:00.048",
 1141:                         "20160525 13:30:00.049",
 1142:                         "20160525 13:30:00.072",
 1143:                         "20160525 13:30:00.075",
 1144:                     ]
 1145:                 ).astype(f"M8[{unit}]"),
 1146:                 "ticker": [
 1147:                     "GOOG",
 1148:                     "MSFT",
 1149:                     "MSFT",
 1150:                     "MSFT",
 1151:                     "GOOG",
 1152:                     "AAPL",
 1153:                     "GOOG",
 1154:                     "MSFT",
 1155:                 ],
 1156:                 "bid": [720.50, 51.95, 51.97, 51.99, 720.50, 97.99, 720.50, 52.01],
 1157:                 "ask": [720.93, 51.96, 51.98, 52.00, 720.93, 98.01, 720.88, 52.03],
 1158:             },
 1159:             columns=["time", "ticker", "bid", "ask"],
 1160:         )
 1161: 
 1162:         merge_asof(trades, quotes, on="time", by="ticker")
 1163: 
 1164:         merge_asof(trades, quotes, on="time", by="ticker", tolerance=Timedelta("2ms"))
 1165: 
 1166:         expected = pd.DataFrame(
 1167:             {
 1168:                 "time": to_datetime(
 1169:                     [
 1170:                         "20160525 13:30:00.023",
 1171:                         "20160525 13:30:00.038",
 1172:                         "20160525 13:30:00.048",
 1173:                         "20160525 13:30:00.048",
 1174:                         "20160525 13:30:00.048",
 1175:                     ]
 1176:                 ).astype(f"M8[{unit}]"),
 1177:                 "ticker": ["MSFT", "MSFT", "GOOG", "GOOG", "AAPL"],
 1178:                 "price": [51.95, 51.95, 720.77, 720.92, 98.00],
 1179:                 "quantity": [75, 155, 100, 100, 100],
 1180:                 "bid": [np.nan, 51.97, np.nan, np.nan, np.nan],
 1181:                 "ask": [np.nan, 51.98, np.nan, np.nan, np.nan],
 1182:             },
 1183:             columns=["time", "ticker", "price", "quantity", "bid", "ask"],
 1184:         )
 1185: 
 1186:         result = merge_asof(
 1187:             trades,
 1188:             quotes,
 1189:             on="time",
 1190:             by="ticker",
 1191:             tolerance=Timedelta("10ms"),
 1192:             allow_exact_matches=False,
 1193:         )
 1194:         tm.assert_frame_equal(result, expected)
 1195: 
 1196:     def test_examples3(self):
 1197:         """doc-string examples"""
 1198:         # GH14887
 1199: 
 1200:         left = pd.DataFrame({"a": [1, 5, 10], "left_val": ["a", "b", "c"]})
 1201:         right = pd.DataFrame({"a": [1, 2, 3, 6, 7], "right_val": [1, 2, 3, 6, 7]})
 1202: 
 1203:         expected = pd.DataFrame(
 1204:             {"a": [1, 5, 10], "left_val": ["a", "b", "c"], "right_val": [1, 6, np.nan]}
 1205:         )
 1206: 
 1207:         result = merge_asof(left, right, on="a", direction="forward")
 1208:         tm.assert_frame_equal(result, expected)
 1209: 
 1210:     def test_examples4(self):
 1211:         """doc-string examples"""
 1212:         # GH14887
 1213: 
 1214:         left = pd.DataFrame({"a": [1, 5, 10], "left_val": ["a", "b", "c"]})
 1215:         right = pd.DataFrame({"a": [1, 2, 3, 6, 7], "right_val": [1, 2, 3, 6, 7]})
 1216: 
 1217:         expected = pd.DataFrame(
 1218:             {"a": [1, 5, 10], "left_val": ["a", "b", "c"], "right_val": [1, 6, 7]}
 1219:         )
 1220: 
 1221:         result = merge_asof(left, right, on="a", direction="nearest")
 1222:         tm.assert_frame_equal(result, expected)
 1223: 
 1224:     def test_basic(self, trades, asof, quotes):
 1225:         expected = asof
 1226: 
 1227:         result = merge_asof(trades, quotes, on="time", by="ticker")
 1228:         tm.assert_frame_equal(result, expected)
 1229: 
 1230:     def test_basic_categorical(self, trades, asof, quotes):
 1231:         expected = asof
 1232:         trades.ticker = trades.ticker.astype("category")
 1233:         quotes.ticker = quotes.ticker.astype("category")
 1234:         expected.ticker = expected.ticker.astype("category")
 1235: 
 1236:         result = merge_asof(trades, quotes, on="time", by="ticker")
 1237:         tm.assert_frame_equal(result, expected)
 1238: 
 1239:     def test_basic_left_index(self, trades, asof, quotes):
 1240:         # GH14253
 1241:         expected = asof
 1242:         trades = trades.set_index("time")
 1243: 
 1244:         result = merge_asof(
 1245:             trades, quotes, left_index=True, right_on="time", by="ticker"
 1246:         )
 1247:         # left-only index uses right"s index, oddly
 1248:         expected.index = result.index
 1249:         # time column appears after left"s columns
 1250:         expected = expected[result.columns]
 1251:         tm.assert_frame_equal(result, expected)
 1252: 
 1253:     def test_basic_right_index(self, trades, asof, quotes):
 1254:         expected = asof
 1255:         quotes = quotes.set_index("time")
 1256: 
 1257:         result = merge_asof(
 1258:             trades, quotes, left_on="time", right_index=True, by="ticker"
 1259:         )
 1260:         tm.assert_frame_equal(result, expected)
 1261: 
 1262:     def test_basic_left_index_right_index(self, trades, asof, quotes):
 1263:         expected = asof.set_index("time")
 1264:         trades = trades.set_index("time")
 1265:         quotes = quotes.set_index("time")
 1266: 
 1267:         result = merge_asof(
 1268:             trades, quotes, left_index=True, right_index=True, by="ticker"
 1269:         )
 1270:         tm.assert_frame_equal(result, expected)
 1271: 
 1272:     def test_multi_index_left(self, trades, quotes):
 1273:         # MultiIndex is prohibited
 1274:         trades = trades.set_index(["time", "price"])
 1275:         quotes = quotes.set_index("time")
 1276:         with pytest.raises(MergeError, match="left can only have one index"):
 1277:             merge_asof(trades, quotes, left_index=True, right_index=True)
 1278: 
 1279:     def test_multi_index_right(self, trades, quotes):
 1280:         # MultiIndex is prohibited
 1281:         trades = trades.set_index("time")
 1282:         quotes = quotes.set_index(["time", "bid"])
 1283:         with pytest.raises(MergeError, match="right can only have one index"):
 1284:             merge_asof(trades, quotes, left_index=True, right_index=True)
 1285: 
 1286:     def test_on_and_index_left_on(self, trades, quotes):
 1287:         # "on" parameter and index together is prohibited
 1288:         trades = trades.set_index("time")
 1289:         quotes = quotes.set_index("time")
 1290:         msg = 'Can only pass argument "left_on" OR "left_index" not both.'
 1291:         with pytest.raises(MergeError, match=msg):
 1292:             merge_asof(
 1293:                 trades, quotes, left_on="price", left_index=True, right_index=True
 1294:             )
 1295: 
 1296:     def test_on_and_index_right_on(self, trades, quotes):
 1297:         trades = trades.set_index("time")
 1298:         quotes = quotes.set_index("time")
 1299:         msg = 'Can only pass argument "right_on" OR "right_index" not both.'
 1300:         with pytest.raises(MergeError, match=msg):
 1301:             merge_asof(
 1302:                 trades, quotes, right_on="bid", left_index=True, right_index=True
 1303:             )
 1304: 
 1305:     def test_basic_left_by_right_by(self, trades, asof, quotes):
 1306:         # GH14253
 1307:         expected = asof
 1308: 
 1309:         result = merge_asof(
 1310:             trades, quotes, on="time", left_by="ticker", right_by="ticker"
 1311:         )
 1312:         tm.assert_frame_equal(result, expected)
 1313: 
 1314:     def test_missing_right_by(self, trades, asof, quotes):
 1315:         expected = asof
 1316: 
 1317:         q = quotes[quotes.ticker != "MSFT"]
 1318:         result = merge_asof(trades, q, on="time", by="ticker")
 1319:         expected.loc[expected.ticker == "MSFT", ["bid", "ask"]] = np.nan
 1320:         tm.assert_frame_equal(result, expected)
 1321: 
 1322:     def test_multiby(self):
 1323:         # GH13936
 1324:         trades = pd.DataFrame(
 1325:             {
 1326:                 "time": to_datetime(
 1327:                     [
 1328:                         "20160525 13:30:00.023",
 1329:                         "20160525 13:30:00.023",
 1330:                         "20160525 13:30:00.046",
 1331:                         "20160525 13:30:00.048",
 1332:                         "20160525 13:30:00.050",
 1333:                     ]
 1334:                 ),
 1335:                 "ticker": ["MSFT", "MSFT", "GOOG", "GOOG", "AAPL"],
 1336:                 "exch": ["ARCA", "NSDQ", "NSDQ", "BATS", "NSDQ"],
 1337:                 "price": [51.95, 51.95, 720.77, 720.92, 98.00],
 1338:                 "quantity": [75, 155, 100, 100, 100],
 1339:             },
 1340:             columns=["time", "ticker", "exch", "price", "quantity"],
 1341:         )
 1342: 
 1343:         quotes = pd.DataFrame(
 1344:             {
 1345:                 "time": to_datetime(
 1346:                     [
 1347:                         "20160525 13:30:00.023",
 1348:                         "20160525 13:30:00.023",
 1349:                         "20160525 13:30:00.030",
 1350:                         "20160525 13:30:00.041",
 1351:                         "20160525 13:30:00.045",
 1352:                         "20160525 13:30:00.049",
 1353:                     ]
 1354:                 ),
 1355:                 "ticker": ["GOOG", "MSFT", "MSFT", "MSFT", "GOOG", "AAPL"],
 1356:                 "exch": ["BATS", "NSDQ", "ARCA", "ARCA", "NSDQ", "ARCA"],
 1357:                 "bid": [720.51, 51.95, 51.97, 51.99, 720.50, 97.99],
 1358:                 "ask": [720.92, 51.96, 51.98, 52.00, 720.93, 98.01],
 1359:             },
 1360:             columns=["time", "ticker", "exch", "bid", "ask"],
 1361:         )
 1362: 
 1363:         expected = pd.DataFrame(
 1364:             {
 1365:                 "time": to_datetime(
 1366:                     [
 1367:                         "20160525 13:30:00.023",
 1368:                         "20160525 13:30:00.023",
 1369:                         "20160525 13:30:00.046",
 1370:                         "20160525 13:30:00.048",
 1371:                         "20160525 13:30:00.050",
 1372:                     ]
 1373:                 ),
 1374:                 "ticker": ["MSFT", "MSFT", "GOOG", "GOOG", "AAPL"],
 1375:                 "exch": ["ARCA", "NSDQ", "NSDQ", "BATS", "NSDQ"],
 1376:                 "price": [51.95, 51.95, 720.77, 720.92, 98.00],
 1377:                 "quantity": [75, 155, 100, 100, 100],
 1378:                 "bid": [np.nan, 51.95, 720.50, 720.51, np.nan],
 1379:                 "ask": [np.nan, 51.96, 720.93, 720.92, np.nan],
 1380:             },
 1381:             columns=["time", "ticker", "exch", "price", "quantity", "bid", "ask"],
 1382:         )
 1383: 
 1384:         result = merge_asof(trades, quotes, on="time", by=["ticker", "exch"])
 1385:         tm.assert_frame_equal(result, expected)
 1386: 
 1387:     @pytest.mark.parametrize("dtype", ["object", "string"])
 1388:     def test_multiby_heterogeneous_types(self, dtype):
 1389:         # GH13936
 1390:         trades = pd.DataFrame(
 1391:             {
 1392:                 "time": to_datetime(
 1393:                     [
 1394:                         "20160525 13:30:00.023",
 1395:                         "20160525 13:30:00.023",
 1396:                         "20160525 13:30:00.046",
 1397:                         "20160525 13:30:00.048",
 1398:                         "20160525 13:30:00.050",
 1399:                     ]
 1400:                 ),
 1401:                 "ticker": [0, 0, 1, 1, 2],
 1402:                 "exch": ["ARCA", "NSDQ", "NSDQ", "BATS", "NSDQ"],
 1403:                 "price": [51.95, 51.95, 720.77, 720.92, 98.00],
 1404:                 "quantity": [75, 155, 100, 100, 100],
 1405:             },
 1406:             columns=["time", "ticker", "exch", "price", "quantity"],
 1407:         )
 1408:         trades = trades.astype({"ticker": dtype, "exch": dtype})
 1409: 
 1410:         quotes = pd.DataFrame(
 1411:             {
 1412:                 "time": to_datetime(
 1413:                     [
 1414:                         "20160525 13:30:00.023",
 1415:                         "20160525 13:30:00.023",
 1416:                         "20160525 13:30:00.030",
 1417:                         "20160525 13:30:00.041",
 1418:                         "20160525 13:30:00.045",
 1419:                         "20160525 13:30:00.049",
 1420:                     ]
 1421:                 ),
 1422:                 "ticker": [1, 0, 0, 0, 1, 2],
 1423:                 "exch": ["BATS", "NSDQ", "ARCA", "ARCA", "NSDQ", "ARCA"],
 1424:                 "bid": [720.51, 51.95, 51.97, 51.99, 720.50, 97.99],
 1425:                 "ask": [720.92, 51.96, 51.98, 52.00, 720.93, 98.01],
 1426:             },
 1427:             columns=["time", "ticker", "exch", "bid", "ask"],
 1428:         )
 1429:         quotes = quotes.astype({"ticker": dtype, "exch": dtype})
 1430: 
 1431:         expected = pd.DataFrame(
 1432:             {
 1433:                 "time": to_datetime(
 1434:                     [
 1435:                         "20160525 13:30:00.023",
 1436:                         "20160525 13:30:00.023",
 1437:                         "20160525 13:30:00.046",
 1438:                         "20160525 13:30:00.048",
 1439:                         "20160525 13:30:00.050",
 1440:                     ]
 1441:                 ),
 1442:                 "ticker": [0, 0, 1, 1, 2],
 1443:                 "exch": ["ARCA", "NSDQ", "NSDQ", "BATS", "NSDQ"],
 1444:                 "price": [51.95, 51.95, 720.77, 720.92, 98.00],
 1445:                 "quantity": [75, 155, 100, 100, 100],
 1446:                 "bid": [np.nan, 51.95, 720.50, 720.51, np.nan],
 1447:                 "ask": [np.nan, 51.96, 720.93, 720.92, np.nan],
 1448:             },
 1449:             columns=["time", "ticker", "exch", "price", "quantity", "bid", "ask"],
 1450:         )
 1451:         expected = expected.astype({"ticker": dtype, "exch": dtype})
 1452: 
 1453:         result = merge_asof(trades, quotes, on="time", by=["ticker", "exch"])
 1454:         tm.assert_frame_equal(result, expected)
 1455: 
 1456:     def test_mismatched_index_dtype(self):
 1457:         # similar to test_multiby_indexed, but we change the dtype on left.index
 1458:         left = pd.DataFrame(
 1459:             [
 1460:                 [to_datetime("20160602"), 1, "a"],
 1461:                 [to_datetime("20160602"), 2, "a"],
 1462:                 [to_datetime("20160603"), 1, "b"],
 1463:                 [to_datetime("20160603"), 2, "b"],
 1464:             ],
 1465:             columns=["time", "k1", "k2"],
 1466:         ).set_index("time")
 1467:         # different dtype for the index
 1468:         left.index = left.index - pd.Timestamp(0)
 1469: 
 1470:         right = pd.DataFrame(
 1471:             [
 1472:                 [to_datetime("20160502"), 1, "a", 1.0],
 1473:                 [to_datetime("20160502"), 2, "a", 2.0],
 1474:                 [to_datetime("20160503"), 1, "b", 3.0],
 1475:                 [to_datetime("20160503"), 2, "b", 4.0],
 1476:             ],
 1477:             columns=["time", "k1", "k2", "value"],
 1478:         ).set_index("time")
 1479: 
 1480:         msg = "incompatible merge keys"
 1481:         with pytest.raises(MergeError, match=msg):
 1482:             merge_asof(left, right, left_index=True, right_index=True, by=["k1", "k2"])
 1483: 
 1484:     def test_multiby_indexed(self):
 1485:         # GH15676
 1486:         left = pd.DataFrame(
 1487:             [
 1488:                 [to_datetime("20160602"), 1, "a"],
 1489:                 [to_datetime("20160602"), 2, "a"],
 1490:                 [to_datetime("20160603"), 1, "b"],
 1491:                 [to_datetime("20160603"), 2, "b"],
 1492:             ],
 1493:             columns=["time", "k1", "k2"],
 1494:         ).set_index("time")
 1495: 
 1496:         right = pd.DataFrame(
 1497:             [
 1498:                 [to_datetime("20160502"), 1, "a", 1.0],
 1499:                 [to_datetime("20160502"), 2, "a", 2.0],
 1500:                 [to_datetime("20160503"), 1, "b", 3.0],
 1501:                 [to_datetime("20160503"), 2, "b", 4.0],
 1502:             ],
 1503:             columns=["time", "k1", "k2", "value"],
 1504:         ).set_index("time")
 1505: 
 1506:         expected = pd.DataFrame(
 1507:             [
 1508:                 [to_datetime("20160602"), 1, "a", 1.0],
 1509:                 [to_datetime("20160602"), 2, "a", 2.0],
 1510:                 [to_datetime("20160603"), 1, "b", 3.0],
 1511:                 [to_datetime("20160603"), 2, "b", 4.0],
 1512:             ],
 1513:             columns=["time", "k1", "k2", "value"],
 1514:         ).set_index("time")
 1515: 
 1516:         result = merge_asof(
 1517:             left, right, left_index=True, right_index=True, by=["k1", "k2"]
 1518:         )
 1519: 
 1520:         tm.assert_frame_equal(expected, result)
 1521: 
 1522:         with pytest.raises(
 1523:             MergeError, match="left_by and right_by must be the same length"
 1524:         ):
 1525:             merge_asof(
 1526:                 left,
 1527:                 right,
 1528:                 left_index=True,
 1529:                 right_index=True,
 1530:                 left_by=["k1", "k2"],
 1531:                 right_by=["k1"],
 1532:             )
 1533: 
 1534:     def test_basic2(self, datapath):
 1535:         expected = pd.DataFrame(
 1536:             [
 1537:                 [
 1538:                     "20160525 13:30:00.023",
 1539:                     "MSFT",
 1540:                     "51.95",
 1541:                     "75",
 1542:                     "NASDAQ",
 1543:                     "51.95",
 1544:                     "51.95",
 1545:                 ],
 1546:                 [
 1547:                     "20160525 13:30:00.038",
 1548:                     "MSFT",
 1549:                     "51.95",
 1550:                     "155",
 1551:                     "NASDAQ",
 1552:                     "51.95",
 1553:                     "51.95",
 1554:                 ],
 1555:                 [
 1556:                     "20160525 13:30:00.048",
 1557:                     "GOOG",
 1558:                     "720.77",
 1559:                     "100",
 1560:                     "NASDAQ",
 1561:                     "720.5",
 1562:                     "720.93",
 1563:                 ],
 1564:                 [
 1565:                     "20160525 13:30:00.048",
 1566:                     "GOOG",
 1567:                     "720.92",
 1568:                     "100",
 1569:                     "NASDAQ",
 1570:                     "720.5",
 1571:                     "720.93",
 1572:                 ],
 1573:                 [
 1574:                     "20160525 13:30:00.048",
 1575:                     "GOOG",
 1576:                     "720.93",
 1577:                     "200",
 1578:                     "NASDAQ",
 1579:                     "720.5",
 1580:                     "720.93",
 1581:                 ],
 1582:                 [
 1583:                     "20160525 13:30:00.048",
 1584:                     "GOOG",
 1585:                     "720.93",
 1586:                     "300",
 1587:                     "NASDAQ",
 1588:                     "720.5",
 1589:                     "720.93",
 1590:                 ],
 1591:                 [
 1592:                     "20160525 13:30:00.048",
 1593:                     "GOOG",
 1594:                     "720.93",
 1595:                     "600",
 1596:                     "NASDAQ",
 1597:                     "720.5",
 1598:                     "720.93",
 1599:                 ],
 1600:                 [
 1601:                     "20160525 13:30:00.048",
 1602:                     "GOOG",
 1603:                     "720.93",
 1604:                     "44",
 1605:                     "NASDAQ",
 1606:                     "720.5",
 1607:                     "720.93",
 1608:                 ],
 1609:                 [
 1610:                     "20160525 13:30:00.074",
 1611:                     "AAPL",
 1612:                     "98.67",
 1613:                     "478343",
 1614:                     "NASDAQ",
 1615:                     np.nan,
 1616:                     np.nan,
 1617:                 ],
 1618:                 [
 1619:                     "20160525 13:30:00.075",
 1620:                     "AAPL",
 1621:                     "98.67",
 1622:                     "478343",
 1623:                     "NASDAQ",
 1624:                     "98.55",
 1625:                     "98.56",
 1626:                 ],
 1627:                 [
 1628:                     "20160525 13:30:00.075",
 1629:                     "AAPL",
 1630:                     "98.66",
 1631:                     "6",
 1632:                     "NASDAQ",
 1633:                     "98.55",
 1634:                     "98.56",
 1635:                 ],
 1636:                 [
 1637:                     "20160525 13:30:00.075",
 1638:                     "AAPL",
 1639:                     "98.65",
 1640:                     "30",
 1641:                     "NASDAQ",
 1642:                     "98.55",
 1643:                     "98.56",
 1644:                 ],
 1645:                 [
 1646:                     "20160525 13:30:00.075",
 1647:                     "AAPL",
 1648:                     "98.65",
 1649:                     "75",
 1650:                     "NASDAQ",
 1651:                     "98.55",
 1652:                     "98.56",
 1653:                 ],
 1654:                 [
 1655:                     "20160525 13:30:00.075",
 1656:                     "AAPL",
 1657:                     "98.65",
 1658:                     "20",
 1659:                     "NASDAQ",
 1660:                     "98.55",
 1661:                     "98.56",
 1662:                 ],
 1663:                 [
 1664:                     "20160525 13:30:00.075",
 1665:                     "AAPL",
 1666:                     "98.65",
 1667:                     "35",
 1668:                     "NASDAQ",
 1669:                     "98.55",
 1670:                     "98.56",
 1671:                 ],
 1672:                 [
 1673:                     "20160525 13:30:00.075",
 1674:                     "AAPL",
 1675:                     "98.65",
 1676:                     "10",
 1677:                     "NASDAQ",
 1678:                     "98.55",
 1679:                     "98.56",
 1680:                 ],
 1681:                 [
 1682:                     "20160525 13:30:00.075",
 1683:                     "AAPL",
 1684:                     "98.55",
 1685:                     "6",
 1686:                     "ARCA",
 1687:                     "98.55",
 1688:                     "98.56",
 1689:                 ],
 1690:                 [
 1691:                     "20160525 13:30:00.075",
 1692:                     "AAPL",
 1693:                     "98.55",
 1694:                     "6",
 1695:                     "ARCA",
 1696:                     "98.55",
 1697:                     "98.56",
 1698:                 ],
 1699:                 [
 1700:                     "20160525 13:30:00.076",
 1701:                     "AAPL",
 1702:                     "98.56",
 1703:                     "1000",
 1704:                     "ARCA",
 1705:                     "98.55",
 1706:                     "98.56",
 1707:                 ],
 1708:                 [
 1709:                     "20160525 13:30:00.076",
 1710:                     "AAPL",
 1711:                     "98.56",
 1712:                     "200",
 1713:                     "ARCA",
 1714:                     "98.55",
 1715:                     "98.56",
 1716:                 ],
 1717:                 [
 1718:                     "20160525 13:30:00.076",
 1719:                     "AAPL",
 1720:                     "98.56",
 1721:                     "300",
 1722:                     "ARCA",
 1723:                     "98.55",
 1724:                     "98.56",
 1725:                 ],
 1726:                 [
 1727:                     "20160525 13:30:00.076",
 1728:                     "AAPL",
 1729:                     "98.56",
 1730:                     "400",
 1731:                     "ARCA",
 1732:                     "98.55",
 1733:                     "98.56",
 1734:                 ],
 1735:                 [
 1736:                     "20160525 13:30:00.076",
 1737:                     "AAPL",
 1738:                     "98.56",
 1739:                     "600",
 1740:                     "ARCA",
 1741:                     "98.55",
 1742:                     "98.56",
 1743:                 ],
 1744:                 [
 1745:                     "20160525 13:30:00.076",
 1746:                     "AAPL",
 1747:                     "98.56",
 1748:                     "200",
 1749:                     "ARCA",
 1750:                     "98.55",
 1751:                     "98.56",
 1752:                 ],
 1753:                 [
 1754:                     "20160525 13:30:00.078",
 1755:                     "MSFT",
 1756:                     "51.95",
 1757:                     "783",
 1758:                     "NASDAQ",
 1759:                     "51.92",
 1760:                     "51.95",
 1761:                 ],
 1762:                 [
 1763:                     "20160525 13:30:00.078",
 1764:                     "MSFT",
 1765:                     "51.95",
 1766:                     "100",
 1767:                     "NASDAQ",
 1768:                     "51.92",
 1769:                     "51.95",
 1770:                 ],
 1771:                 [
 1772:                     "20160525 13:30:00.078",
 1773:                     "MSFT",
 1774:                     "51.95",
 1775:                     "100",
 1776:                     "NASDAQ",
 1777:                     "51.92",
 1778:                     "51.95",
 1779:                 ],
 1780:                 [
 1781:                     "20160525 13:30:00.084",
 1782:                     "AAPL",
 1783:                     "98.64",
 1784:                     "40",
 1785:                     "NASDAQ",
 1786:                     "98.55",
 1787:                     "98.56",
 1788:                 ],
 1789:                 [
 1790:                     "20160525 13:30:00.084",
 1791:                     "AAPL",
 1792:                     "98.55",
 1793:                     "149",
 1794:                     "EDGX",
 1795:                     "98.55",
 1796:                     "98.56",
 1797:                 ],
 1798:                 [
 1799:                     "20160525 13:30:00.086",
 1800:                     "AAPL",
 1801:                     "98.56",
 1802:                     "500",
 1803:                     "ARCA",
 1804:                     "98.55",
 1805:                     "98.63",
 1806:                 ],
 1807:                 [
 1808:                     "20160525 13:30:00.104",
 1809:                     "AAPL",
 1810:                     "98.63",
 1811:                     "647",
 1812:                     "EDGX",
 1813:                     "98.62",
 1814:                     "98.63",
 1815:                 ],
 1816:                 [
 1817:                     "20160525 13:30:00.104",
 1818:                     "AAPL",
 1819:                     "98.63",
 1820:                     "300",
 1821:                     "EDGX",
 1822:                     "98.62",
 1823:                     "98.63",
 1824:                 ],
 1825:                 [
 1826:                     "20160525 13:30:00.104",
 1827:                     "AAPL",
 1828:                     "98.63",
 1829:                     "50",
 1830:                     "NASDAQ",
 1831:                     "98.62",
 1832:                     "98.63",
 1833:                 ],
 1834:                 [
 1835:                     "20160525 13:30:00.104",
 1836:                     "AAPL",
 1837:                     "98.63",
 1838:                     "50",
 1839:                     "NASDAQ",
 1840:                     "98.62",
 1841:                     "98.63",
 1842:                 ],
 1843:                 [
 1844:                     "20160525 13:30:00.104",
 1845:                     "AAPL",
 1846:                     "98.63",
 1847:                     "70",
 1848:                     "NASDAQ",
 1849:                     "98.62",
 1850:                     "98.63",
 1851:                 ],
 1852:                 [
 1853:                     "20160525 13:30:00.104",
 1854:                     "AAPL",
 1855:                     "98.63",
 1856:                     "70",
 1857:                     "NASDAQ",
 1858:                     "98.62",
 1859:                     "98.63",
 1860:                 ],
 1861:                 [
 1862:                     "20160525 13:30:00.104",
 1863:                     "AAPL",
 1864:                     "98.63",
 1865:                     "1",
 1866:                     "NASDAQ",
 1867:                     "98.62",
 1868:                     "98.63",
 1869:                 ],
 1870:                 [
 1871:                     "20160525 13:30:00.104",
 1872:                     "AAPL",
 1873:                     "98.63",
 1874:                     "62",
 1875:                     "NASDAQ",
 1876:                     "98.62",
 1877:                     "98.63",
 1878:                 ],
 1879:                 [
 1880:                     "20160525 13:30:00.104",
 1881:                     "AAPL",
 1882:                     "98.63",
 1883:                     "10",
 1884:                     "NASDAQ",
 1885:                     "98.62",
 1886:                     "98.63",
 1887:                 ],
 1888:                 [
 1889:                     "20160525 13:30:00.104",
 1890:                     "AAPL",
 1891:                     "98.63",
 1892:                     "100",
 1893:                     "ARCA",
 1894:                     "98.62",
 1895:                     "98.63",
 1896:                 ],
 1897:                 [
 1898:                     "20160525 13:30:00.105",
 1899:                     "AAPL",
 1900:                     "98.63",
 1901:                     "100",
 1902:                     "ARCA",
 1903:                     "98.62",
 1904:                     "98.63",
 1905:                 ],
 1906:                 [
 1907:                     "20160525 13:30:00.105",
 1908:                     "AAPL",
 1909:                     "98.63",
 1910:                     "700",
 1911:                     "ARCA",
 1912:                     "98.62",
 1913:                     "98.63",
 1914:                 ],
 1915:                 [
 1916:                     "20160525 13:30:00.106",
 1917:                     "AAPL",
 1918:                     "98.63",
 1919:                     "61",
 1920:                     "EDGX",
 1921:                     "98.62",
 1922:                     "98.63",
 1923:                 ],
 1924:                 [
 1925:                     "20160525 13:30:00.107",
 1926:                     "AAPL",
 1927:                     "98.63",
 1928:                     "100",
 1929:                     "ARCA",
 1930:                     "98.62",
 1931:                     "98.63",
 1932:                 ],
 1933:                 [
 1934:                     "20160525 13:30:00.107",
 1935:                     "AAPL",
 1936:                     "98.63",
 1937:                     "53",
 1938:                     "ARCA",
 1939:                     "98.62",
 1940:                     "98.63",
 1941:                 ],
 1942:                 [
 1943:                     "20160525 13:30:00.108",
 1944:                     "AAPL",
 1945:                     "98.63",
 1946:                     "100",
 1947:                     "ARCA",
 1948:                     "98.62",
 1949:                     "98.63",
 1950:                 ],
 1951:                 [
 1952:                     "20160525 13:30:00.108",
 1953:                     "AAPL",
 1954:                     "98.63",
 1955:                     "839",
 1956:                     "ARCA",
 1957:                     "98.62",
 1958:                     "98.63",
 1959:                 ],
 1960:                 [
 1961:                     "20160525 13:30:00.115",
 1962:                     "AAPL",
 1963:                     "98.63",
 1964:                     "5",
 1965:                     "EDGX",
 1966:                     "98.62",
 1967:                     "98.63",
 1968:                 ],
 1969:                 [
 1970:                     "20160525 13:30:00.118",
 1971:                     "AAPL",
 1972:                     "98.63",
 1973:                     "295",
 1974:                     "EDGX",
 1975:                     "98.62",
 1976:                     "98.63",
 1977:                 ],
 1978:                 [
 1979:                     "20160525 13:30:00.118",
 1980:                     "AAPL",
 1981:                     "98.63",
 1982:                     "5",
 1983:                     "EDGX",
 1984:                     "98.62",
 1985:                     "98.63",
 1986:                 ],
 1987:                 [
 1988:                     "20160525 13:30:00.128",
 1989:                     "AAPL",
 1990:                     "98.63",
 1991:                     "100",
 1992:                     "NASDAQ",
 1993:                     "98.62",
 1994:                     "98.63",
 1995:                 ],
 1996:                 [
 1997:                     "20160525 13:30:00.128",
 1998:                     "AAPL",
 1999:                     "98.63",
 2000:                     "100",
 2001:                     "NASDAQ",
 2002:                     "98.62",
 2003:                     "98.63",
 2004:                 ],
 2005:                 [
 2006:                     "20160525 13:30:00.128",
 2007:                     "MSFT",
 2008:                     "51.92",
 2009:                     "100",
 2010:                     "ARCA",
 2011:                     "51.92",
 2012:                     "51.95",
 2013:                 ],
 2014:                 [
 2015:                     "20160525 13:30:00.129",
 2016:                     "AAPL",
 2017:                     "98.62",
 2018:                     "100",
 2019:                     "NASDAQ",
 2020:                     "98.61",
 2021:                     "98.63",
 2022:                 ],
 2023:                 [
 2024:                     "20160525 13:30:00.129",
 2025:                     "AAPL",
 2026:                     "98.62",
 2027:                     "10",
 2028:                     "NASDAQ",
 2029:                     "98.61",
 2030:                     "98.63",
 2031:                 ],
 2032:                 [
 2033:                     "20160525 13:30:00.129",
 2034:                     "AAPL",
 2035:                     "98.62",
 2036:                     "59",
 2037:                     "NASDAQ",
 2038:                     "98.61",
 2039:                     "98.63",
 2040:                 ],
 2041:                 [
 2042:                     "20160525 13:30:00.129",
 2043:                     "AAPL",
 2044:                     "98.62",
 2045:                     "31",
 2046:                     "NASDAQ",
 2047:                     "98.61",
 2048:                     "98.63",
 2049:                 ],
 2050:                 [
 2051:                     "20160525 13:30:00.129",
 2052:                     "AAPL",
 2053:                     "98.62",
 2054:                     "69",
 2055:                     "NASDAQ",
 2056:                     "98.61",
 2057:                     "98.63",
 2058:                 ],
 2059:                 [
 2060:                     "20160525 13:30:00.129",
 2061:                     "AAPL",
 2062:                     "98.62",
 2063:                     "12",
 2064:                     "NASDAQ",
 2065:                     "98.61",
 2066:                     "98.63",
 2067:                 ],
 2068:                 [
 2069:                     "20160525 13:30:00.129",
 2070:                     "AAPL",
 2071:                     "98.62",
 2072:                     "12",
 2073:                     "EDGX",
 2074:                     "98.61",
 2075:                     "98.63",
 2076:                 ],
 2077:                 [
 2078:                     "20160525 13:30:00.129",
 2079:                     "AAPL",
 2080:                     "98.62",
 2081:                     "100",
 2082:                     "ARCA",
 2083:                     "98.61",
 2084:                     "98.63",
 2085:                 ],
 2086:                 [
 2087:                     "20160525 13:30:00.129",
 2088:                     "AAPL",
 2089:                     "98.62",
 2090:                     "100",
 2091:                     "ARCA",
 2092:                     "98.61",
 2093:                     "98.63",
 2094:                 ],
 2095:                 [
 2096:                     "20160525 13:30:00.130",
 2097:                     "MSFT",
 2098:                     "51.95",
 2099:                     "317",
 2100:                     "ARCA",
 2101:                     "51.93",
 2102:                     "51.95",
 2103:                 ],
 2104:                 [
 2105:                     "20160525 13:30:00.130",
 2106:                     "MSFT",
 2107:                     "51.95",
 2108:                     "283",
 2109:                     "ARCA",
 2110:                     "51.93",
 2111:                     "51.95",
 2112:                 ],
 2113:                 [
 2114:                     "20160525 13:30:00.135",
 2115:                     "MSFT",
 2116:                     "51.93",
 2117:                     "100",
 2118:                     "EDGX",
 2119:                     "51.92",
 2120:                     "51.95",
 2121:                 ],
 2122:                 [
 2123:                     "20160525 13:30:00.135",
 2124:                     "AAPL",
 2125:                     "98.62",
 2126:                     "100",
 2127:                     "ARCA",
 2128:                     "98.61",
 2129:                     "98.62",
 2130:                 ],
 2131:                 [
 2132:                     "20160525 13:30:00.144",
 2133:                     "AAPL",
 2134:                     "98.62",
 2135:                     "12",
 2136:                     "NASDAQ",
 2137:                     "98.61",
 2138:                     "98.62",
 2139:                 ],
 2140:                 [
 2141:                     "20160525 13:30:00.144",
 2142:                     "AAPL",
 2143:                     "98.62",
 2144:                     "88",
 2145:                     "NASDAQ",
 2146:                     "98.61",
 2147:                     "98.62",
 2148:                 ],
 2149:                 [
 2150:                     "20160525 13:30:00.144",
 2151:                     "AAPL",
 2152:                     "98.62",
 2153:                     "162",
 2154:                     "NASDAQ",
 2155:                     "98.61",
 2156:                     "98.62",
 2157:                 ],
 2158:                 [
 2159:                     "20160525 13:30:00.144",
 2160:                     "AAPL",
 2161:                     "98.61",
 2162:                     "100",
 2163:                     "BATS",
 2164:                     "98.61",
 2165:                     "98.62",
 2166:                 ],
 2167:                 [
 2168:                     "20160525 13:30:00.144",
 2169:                     "AAPL",
 2170:                     "98.62",
 2171:                     "61",
 2172:                     "ARCA",
 2173:                     "98.61",
 2174:                     "98.62",
 2175:                 ],
 2176:                 [
 2177:                     "20160525 13:30:00.144",
 2178:                     "AAPL",
 2179:                     "98.62",
 2180:                     "25",
 2181:                     "ARCA",
 2182:                     "98.61",
 2183:                     "98.62",
 2184:                 ],
 2185:                 [
 2186:                     "20160525 13:30:00.144",
 2187:                     "AAPL",
 2188:                     "98.62",
 2189:                     "14",
 2190:                     "ARCA",
 2191:                     "98.61",
 2192:                     "98.62",
 2193:                 ],
 2194:                 [
 2195:                     "20160525 13:30:00.145",
 2196:                     "AAPL",
 2197:                     "98.62",
 2198:                     "12",
 2199:                     "ARCA",
 2200:                     "98.6",
 2201:                     "98.63",
 2202:                 ],
 2203:                 [
 2204:                     "20160525 13:30:00.145",
 2205:                     "AAPL",
 2206:                     "98.62",
 2207:                     "100",
 2208:                     "ARCA",
 2209:                     "98.6",
 2210:                     "98.63",
 2211:                 ],
 2212:                 [
 2213:                     "20160525 13:30:00.145",
 2214:                     "AAPL",
 2215:                     "98.63",
 2216:                     "100",
 2217:                     "NASDAQ",
 2218:                     "98.6",
 2219:                     "98.63",
 2220:                 ],
 2221:                 [
 2222:                     "20160525 13:30:00.145",
 2223:                     "AAPL",
 2224:                     "98.63",
 2225:                     "100",
 2226:                     "NASDAQ",
 2227:                     "98.6",
 2228:                     "98.63",
 2229:                 ],
 2230:             ],
 2231:             columns="time,ticker,price,quantity,marketCenter,bid,ask".split(","),
 2232:         )
 2233:         expected["price"] = expected["price"].astype("float64")
 2234:         expected["quantity"] = expected["quantity"].astype("int64")
 2235:         expected["bid"] = expected["bid"].astype("float64")
 2236:         expected["ask"] = expected["ask"].astype("float64")
 2237:         expected = self.prep_data(expected)
 2238: 
 2239:         trades = pd.DataFrame(
 2240:             [
 2241:                 ["20160525 13:30:00.023", "MSFT", "51.9500", "75", "NASDAQ"],
 2242:                 ["20160525 13:30:00.038", "MSFT", "51.9500", "155", "NASDAQ"],
 2243:                 ["20160525 13:30:00.048", "GOOG", "720.7700", "100", "NASDAQ"],
 2244:                 ["20160525 13:30:00.048", "GOOG", "720.9200", "100", "NASDAQ"],
 2245:                 ["20160525 13:30:00.048", "GOOG", "720.9300", "200", "NASDAQ"],
 2246:                 ["20160525 13:30:00.048", "GOOG", "720.9300", "300", "NASDAQ"],
 2247:                 ["20160525 13:30:00.048", "GOOG", "720.9300", "600", "NASDAQ"],
 2248:                 ["20160525 13:30:00.048", "GOOG", "720.9300", "44", "NASDAQ"],
 2249:                 ["20160525 13:30:00.074", "AAPL", "98.6700", "478343", "NASDAQ"],
 2250:                 ["20160525 13:30:00.075", "AAPL", "98.6700", "478343", "NASDAQ"],
 2251:                 ["20160525 13:30:00.075", "AAPL", "98.6600", "6", "NASDAQ"],
 2252:                 ["20160525 13:30:00.075", "AAPL", "98.6500", "30", "NASDAQ"],
 2253:                 ["20160525 13:30:00.075", "AAPL", "98.6500", "75", "NASDAQ"],
 2254:                 ["20160525 13:30:00.075", "AAPL", "98.6500", "20", "NASDAQ"],
 2255:                 ["20160525 13:30:00.075", "AAPL", "98.6500", "35", "NASDAQ"],
 2256:                 ["20160525 13:30:00.075", "AAPL", "98.6500", "10", "NASDAQ"],
 2257:                 ["20160525 13:30:00.075", "AAPL", "98.5500", "6", "ARCA"],
 2258:                 ["20160525 13:30:00.075", "AAPL", "98.5500", "6", "ARCA"],
 2259:                 ["20160525 13:30:00.076", "AAPL", "98.5600", "1000", "ARCA"],
 2260:                 ["20160525 13:30:00.076", "AAPL", "98.5600", "200", "ARCA"],
 2261:                 ["20160525 13:30:00.076", "AAPL", "98.5600", "300", "ARCA"],
 2262:                 ["20160525 13:30:00.076", "AAPL", "98.5600", "400", "ARCA"],
 2263:                 ["20160525 13:30:00.076", "AAPL", "98.5600", "600", "ARCA"],
 2264:                 ["20160525 13:30:00.076", "AAPL", "98.5600", "200", "ARCA"],
 2265:                 ["20160525 13:30:00.078", "MSFT", "51.9500", "783", "NASDAQ"],
 2266:                 ["20160525 13:30:00.078", "MSFT", "51.9500", "100", "NASDAQ"],
 2267:                 ["20160525 13:30:00.078", "MSFT", "51.9500", "100", "NASDAQ"],
 2268:                 ["20160525 13:30:00.084", "AAPL", "98.6400", "40", "NASDAQ"],
 2269:                 ["20160525 13:30:00.084", "AAPL", "98.5500", "149", "EDGX"],
 2270:                 ["20160525 13:30:00.086", "AAPL", "98.5600", "500", "ARCA"],
 2271:                 ["20160525 13:30:00.104", "AAPL", "98.6300", "647", "EDGX"],
 2272:                 ["20160525 13:30:00.104", "AAPL", "98.6300", "300", "EDGX"],
 2273:                 ["20160525 13:30:00.104", "AAPL", "98.6300", "50", "NASDAQ"],
 2274:                 ["20160525 13:30:00.104", "AAPL", "98.6300", "50", "NASDAQ"],
 2275:                 ["20160525 13:30:00.104", "AAPL", "98.6300", "70", "NASDAQ"],
 2276:                 ["20160525 13:30:00.104", "AAPL", "98.6300", "70", "NASDAQ"],
 2277:                 ["20160525 13:30:00.104", "AAPL", "98.6300", "1", "NASDAQ"],
 2278:                 ["20160525 13:30:00.104", "AAPL", "98.6300", "62", "NASDAQ"],
 2279:                 ["20160525 13:30:00.104", "AAPL", "98.6300", "10", "NASDAQ"],
 2280:                 ["20160525 13:30:00.104", "AAPL", "98.6300", "100", "ARCA"],
 2281:                 ["20160525 13:30:00.105", "AAPL", "98.6300", "100", "ARCA"],
 2282:                 ["20160525 13:30:00.105", "AAPL", "98.6300", "700", "ARCA"],
 2283:                 ["20160525 13:30:00.106", "AAPL", "98.6300", "61", "EDGX"],
 2284:                 ["20160525 13:30:00.107", "AAPL", "98.6300", "100", "ARCA"],
 2285:                 ["20160525 13:30:00.107", "AAPL", "98.6300", "53", "ARCA"],
 2286:                 ["20160525 13:30:00.108", "AAPL", "98.6300", "100", "ARCA"],
 2287:                 ["20160525 13:30:00.108", "AAPL", "98.6300", "839", "ARCA"],
 2288:                 ["20160525 13:30:00.115", "AAPL", "98.6300", "5", "EDGX"],
 2289:                 ["20160525 13:30:00.118", "AAPL", "98.6300", "295", "EDGX"],
 2290:                 ["20160525 13:30:00.118", "AAPL", "98.6300", "5", "EDGX"],
 2291:                 ["20160525 13:30:00.128", "AAPL", "98.6300", "100", "NASDAQ"],
 2292:                 ["20160525 13:30:00.128", "AAPL", "98.6300", "100", "NASDAQ"],
 2293:                 ["20160525 13:30:00.128", "MSFT", "51.9200", "100", "ARCA"],
 2294:                 ["20160525 13:30:00.129", "AAPL", "98.6200", "100", "NASDAQ"],
 2295:                 ["20160525 13:30:00.129", "AAPL", "98.6200", "10", "NASDAQ"],
 2296:                 ["20160525 13:30:00.129", "AAPL", "98.6200", "59", "NASDAQ"],
 2297:                 ["20160525 13:30:00.129", "AAPL", "98.6200", "31", "NASDAQ"],
 2298:                 ["20160525 13:30:00.129", "AAPL", "98.6200", "69", "NASDAQ"],
 2299:                 ["20160525 13:30:00.129", "AAPL", "98.6200", "12", "NASDAQ"],
 2300:                 ["20160525 13:30:00.129", "AAPL", "98.6200", "12", "EDGX"],
 2301:                 ["20160525 13:30:00.129", "AAPL", "98.6200", "100", "ARCA"],
 2302:                 ["20160525 13:30:00.129", "AAPL", "98.6200", "100", "ARCA"],
 2303:                 ["20160525 13:30:00.130", "MSFT", "51.9500", "317", "ARCA"],
 2304:                 ["20160525 13:30:00.130", "MSFT", "51.9500", "283", "ARCA"],
 2305:                 ["20160525 13:30:00.135", "MSFT", "51.9300", "100", "EDGX"],
 2306:                 ["20160525 13:30:00.135", "AAPL", "98.6200", "100", "ARCA"],
 2307:                 ["20160525 13:30:00.144", "AAPL", "98.6200", "12", "NASDAQ"],
 2308:                 ["20160525 13:30:00.144", "AAPL", "98.6200", "88", "NASDAQ"],
 2309:                 ["20160525 13:30:00.144", "AAPL", "98.6200", "162", "NASDAQ"],
 2310:                 ["20160525 13:30:00.144", "AAPL", "98.6100", "100", "BATS"],
 2311:                 ["20160525 13:30:00.144", "AAPL", "98.6200", "61", "ARCA"],
 2312:                 ["20160525 13:30:00.144", "AAPL", "98.6200", "25", "ARCA"],
 2313:                 ["20160525 13:30:00.144", "AAPL", "98.6200", "14", "ARCA"],
 2314:                 ["20160525 13:30:00.145", "AAPL", "98.6200", "12", "ARCA"],
 2315:                 ["20160525 13:30:00.145", "AAPL", "98.6200", "100", "ARCA"],
 2316:                 ["20160525 13:30:00.145", "AAPL", "98.6300", "100", "NASDAQ"],
 2317:                 ["20160525 13:30:00.145", "AAPL", "98.6300", "100", "NASDAQ"],
 2318:             ],
 2319:             columns="time,ticker,price,quantity,marketCenter".split(","),
 2320:         )
 2321:         trades["price"] = trades["price"].astype("float64")
 2322:         trades["quantity"] = trades["quantity"].astype("int64")
 2323:         trades = self.prep_data(trades)
 2324: 
 2325:         quotes = pd.DataFrame(
 2326:             [
 2327:                 ["20160525 13:30:00.023", "GOOG", "720.50", "720.93"],
 2328:                 ["20160525 13:30:00.023", "MSFT", "51.95", "51.95"],
 2329:                 ["20160525 13:30:00.041", "MSFT", "51.95", "51.95"],
 2330:                 ["20160525 13:30:00.048", "GOOG", "720.50", "720.93"],
 2331:                 ["20160525 13:30:00.048", "GOOG", "720.50", "720.93"],
 2332:                 ["20160525 13:30:00.048", "GOOG", "720.50", "720.93"],
 2333:                 ["20160525 13:30:00.048", "GOOG", "720.50", "720.93"],
 2334:                 ["20160525 13:30:00.072", "GOOG", "720.50", "720.88"],
 2335:                 ["20160525 13:30:00.075", "AAPL", "98.55", "98.56"],
 2336:                 ["20160525 13:30:00.076", "AAPL", "98.55", "98.56"],
 2337:                 ["20160525 13:30:00.076", "AAPL", "98.55", "98.56"],
 2338:                 ["20160525 13:30:00.076", "AAPL", "98.55", "98.56"],
 2339:                 ["20160525 13:30:00.078", "MSFT", "51.95", "51.95"],
 2340:                 ["20160525 13:30:00.078", "MSFT", "51.95", "51.95"],
 2341:                 ["20160525 13:30:00.078", "MSFT", "51.95", "51.95"],
 2342:                 ["20160525 13:30:00.078", "MSFT", "51.92", "51.95"],
 2343:                 ["20160525 13:30:00.079", "MSFT", "51.92", "51.95"],
 2344:                 ["20160525 13:30:00.080", "AAPL", "98.55", "98.56"],
 2345:                 ["20160525 13:30:00.084", "AAPL", "98.55", "98.56"],
 2346:                 ["20160525 13:30:00.086", "AAPL", "98.55", "98.63"],
 2347:                 ["20160525 13:30:00.088", "AAPL", "98.65", "98.63"],
 2348:                 ["20160525 13:30:00.089", "AAPL", "98.63", "98.63"],
 2349:                 ["20160525 13:30:00.104", "AAPL", "98.63", "98.63"],
 2350:                 ["20160525 13:30:00.104", "AAPL", "98.63", "98.63"],
 2351:                 ["20160525 13:30:00.104", "AAPL", "98.63", "98.63"],
 2352:                 ["20160525 13:30:00.104", "AAPL", "98.63", "98.63"],
 2353:                 ["20160525 13:30:00.104", "AAPL", "98.62", "98.63"],
 2354:                 ["20160525 13:30:00.105", "AAPL", "98.62", "98.63"],
 2355:                 ["20160525 13:30:00.107", "AAPL", "98.62", "98.63"],
 2356:                 ["20160525 13:30:00.115", "AAPL", "98.62", "98.63"],
 2357:                 ["20160525 13:30:00.115", "AAPL", "98.62", "98.63"],
 2358:                 ["20160525 13:30:00.118", "AAPL", "98.62", "98.63"],
 2359:                 ["20160525 13:30:00.128", "AAPL", "98.62", "98.63"],
 2360:                 ["20160525 13:30:00.128", "AAPL", "98.62", "98.63"],
 2361:                 ["20160525 13:30:00.129", "AAPL", "98.62", "98.63"],
 2362:                 ["20160525 13:30:00.129", "AAPL", "98.61", "98.63"],
 2363:                 ["20160525 13:30:00.129", "AAPL", "98.62", "98.63"],
 2364:                 ["20160525 13:30:00.129", "AAPL", "98.62", "98.63"],
 2365:                 ["20160525 13:30:00.129", "AAPL", "98.61", "98.63"],
 2366:                 ["20160525 13:30:00.130", "MSFT", "51.93", "51.95"],
 2367:                 ["20160525 13:30:00.130", "MSFT", "51.93", "51.95"],
 2368:                 ["20160525 13:30:00.130", "AAPL", "98.61", "98.63"],
 2369:                 ["20160525 13:30:00.131", "AAPL", "98.61", "98.62"],
 2370:                 ["20160525 13:30:00.131", "AAPL", "98.61", "98.62"],
 2371:                 ["20160525 13:30:00.135", "MSFT", "51.92", "51.95"],
 2372:                 ["20160525 13:30:00.135", "AAPL", "98.61", "98.62"],
 2373:                 ["20160525 13:30:00.136", "AAPL", "98.61", "98.62"],
 2374:                 ["20160525 13:30:00.136", "AAPL", "98.61", "98.62"],
 2375:                 ["20160525 13:30:00.144", "AAPL", "98.61", "98.62"],
 2376:                 ["20160525 13:30:00.144", "AAPL", "98.61", "98.62"],
 2377:                 ["20160525 13:30:00.145", "AAPL", "98.61", "98.62"],
 2378:                 ["20160525 13:30:00.145", "AAPL", "98.61", "98.63"],
 2379:                 ["20160525 13:30:00.145", "AAPL", "98.61", "98.63"],
 2380:                 ["20160525 13:30:00.145", "AAPL", "98.60", "98.63"],
 2381:                 ["20160525 13:30:00.145", "AAPL", "98.61", "98.63"],
 2382:                 ["20160525 13:30:00.145", "AAPL", "98.60", "98.63"],
 2383:             ],
 2384:             columns="time,ticker,bid,ask".split(","),
 2385:         )
 2386:         quotes["bid"] = quotes["bid"].astype("float64")
 2387:         quotes["ask"] = quotes["ask"].astype("float64")
 2388:         quotes = self.prep_data(quotes, dedupe=True)
 2389: 
 2390:         result = merge_asof(trades, quotes, on="time", by="ticker")
 2391:         tm.assert_frame_equal(result, expected)
 2392: 
 2393:     def test_basic_no_by(self, trades, asof, quotes):
 2394:         f = (
 2395:             lambda x: x[x.ticker == "MSFT"]
 2396:             .drop("ticker", axis=1)
 2397:             .reset_index(drop=True)
 2398:         )
 2399: 
 2400:         # just use a single ticker
 2401:         expected = f(asof)
 2402:         trades = f(trades)
 2403:         quotes = f(quotes)
 2404: 
 2405:         result = merge_asof(trades, quotes, on="time")
 2406:         tm.assert_frame_equal(result, expected)
 2407: 
 2408:     def test_valid_join_keys(self, trades, quotes):
 2409:         msg = r"incompatible merge keys \[1\] .* must be the same type"
 2410: 
 2411:         with pytest.raises(MergeError, match=msg):
 2412:             merge_asof(trades, quotes, left_on="time", right_on="bid", by="ticker")
 2413: 
 2414:         with pytest.raises(MergeError, match="can only asof on a key for left"):
 2415:             merge_asof(trades, quotes, on=["time", "ticker"], by="ticker")
 2416: 
 2417:         with pytest.raises(MergeError, match="can only asof on a key for left"):
 2418:             merge_asof(trades, quotes, by="ticker")
 2419: 
 2420:     def test_with_duplicates(self, datapath, trades, quotes, asof):
 2421:         q = (
 2422:             pd.concat([quotes, quotes])
 2423:             .sort_values(["time", "ticker"])
 2424:             .reset_index(drop=True)
 2425:         )
 2426:         result = merge_asof(trades, q, on="time", by="ticker")
 2427:         expected = self.prep_data(asof)
 2428:         tm.assert_frame_equal(result, expected)
 2429: 
 2430:     def test_with_duplicates_no_on(self):
 2431:         df1 = pd.DataFrame({"key": [1, 1, 3], "left_val": [1, 2, 3]})
 2432:         df2 = pd.DataFrame({"key": [1, 2, 2], "right_val": [1, 2, 3]})
 2433:         result = merge_asof(df1, df2, on="key")
 2434:         expected = pd.DataFrame(
 2435:             {"key": [1, 1, 3], "left_val": [1, 2, 3], "right_val": [1, 1, 3]}
 2436:         )
 2437:         tm.assert_frame_equal(result, expected)
 2438: 
 2439:     def test_valid_allow_exact_matches(self, trades, quotes):
 2440:         msg = "allow_exact_matches must be boolean, passed foo"
 2441: 
 2442:         with pytest.raises(MergeError, match=msg):
 2443:             merge_asof(
 2444:                 trades, quotes, on="time", by="ticker", allow_exact_matches="foo"
 2445:             )
 2446: 
 2447:     def test_valid_tolerance(self, trades, quotes):
 2448:         # dti
 2449:         merge_asof(trades, quotes, on="time", by="ticker", tolerance=Timedelta("1s"))
 2450: 
 2451:         # integer
 2452:         merge_asof(
 2453:             trades.reset_index(),
 2454:             quotes.reset_index(),
 2455:             on="index",
 2456:             by="ticker",
 2457:             tolerance=1,
 2458:         )
 2459: 
 2460:         msg = r"incompatible tolerance .*, must be compat with type .*"
 2461: 
 2462:         # incompat
 2463:         with pytest.raises(MergeError, match=msg):
 2464:             merge_asof(trades, quotes, on="time", by="ticker", tolerance=1)
 2465: 
 2466:         # invalid
 2467:         with pytest.raises(MergeError, match=msg):
 2468:             merge_asof(
 2469:                 trades.reset_index(),
 2470:                 quotes.reset_index(),
 2471:                 on="index",
 2472:                 by="ticker",
 2473:                 tolerance=1.0,
 2474:             )
 2475: 
 2476:         msg = "tolerance must be positive"
 2477: 
 2478:         # invalid negative
 2479:         with pytest.raises(MergeError, match=msg):
 2480:             merge_asof(
 2481:                 trades, quotes, on="time", by="ticker", tolerance=-Timedelta("1s")
 2482:             )
 2483: 
 2484:         with pytest.raises(MergeError, match=msg):
 2485:             merge_asof(
 2486:                 trades.reset_index(),
 2487:                 quotes.reset_index(),
 2488:                 on="index",
 2489:                 by="ticker",
 2490:                 tolerance=-1,
 2491:             )
 2492: 
 2493:     def test_non_sorted(self, trades, quotes):
 2494:         trades = trades.sort_values("time", ascending=False)
 2495:         quotes = quotes.sort_values("time", ascending=False)
 2496: 
 2497:         # we require that we are already sorted on time & quotes
 2498:         assert not trades.time.is_monotonic_increasing
 2499:         assert not quotes.time.is_monotonic_increasing
 2500:         with pytest.raises(ValueError, match="left keys must be sorted"):
 2501:             merge_asof(trades, quotes, on="time", by="ticker")
 2502: 
 2503:         trades = trades.sort_values("time")
 2504:         assert trades.time.is_monotonic_increasing
 2505:         assert not quotes.time.is_monotonic_increasing
 2506:         with pytest.raises(ValueError, match="right keys must be sorted"):
 2507:             merge_asof(trades, quotes, on="time", by="ticker")
 2508: 
 2509:         quotes = quotes.sort_values("time")
 2510:         assert trades.time.is_monotonic_increasing
 2511:         assert quotes.time.is_monotonic_increasing
 2512: 
 2513:         # ok, though has dupes
 2514:         merge_asof(trades, quotes, on="time", by="ticker")
 2515: 
 2516:     @pytest.mark.parametrize(
 2517:         "tolerance_ts",
 2518:         [Timedelta("1day"), datetime.timedelta(days=1)],
 2519:         ids=["Timedelta", "datetime.timedelta"],
 2520:     )
 2521:     def test_tolerance(self, tolerance_ts, trades, quotes, tolerance):
 2522:         result = merge_asof(
 2523:             trades, quotes, on="time", by="ticker", tolerance=tolerance_ts
 2524:         )
 2525:         expected = tolerance
 2526:         tm.assert_frame_equal(result, expected)
 2527: 
 2528:     def test_tolerance_forward(self):
 2529:         # GH14887
 2530: 
 2531:         left = pd.DataFrame({"a": [1, 5, 10], "left_val": ["a", "b", "c"]})
 2532:         right = pd.DataFrame({"a": [1, 2, 3, 7, 11], "right_val": [1, 2, 3, 7, 11]})
 2533: 
 2534:         expected = pd.DataFrame(
 2535:             {"a": [1, 5, 10], "left_val": ["a", "b", "c"], "right_val": [1, np.nan, 11]}
 2536:         )
 2537: 
 2538:         result = merge_asof(left, right, on="a", direction="forward", tolerance=1)
 2539:         tm.assert_frame_equal(result, expected)
 2540: 
 2541:     def test_tolerance_nearest(self):
 2542:         # GH14887
 2543: 
 2544:         left = pd.DataFrame({"a": [1, 5, 10], "left_val": ["a", "b", "c"]})
 2545:         right = pd.DataFrame({"a": [1, 2, 3, 7, 11], "right_val": [1, 2, 3, 7, 11]})
 2546: 
 2547:         expected = pd.DataFrame(
 2548:             {"a": [1, 5, 10], "left_val": ["a", "b", "c"], "right_val": [1, np.nan, 11]}
 2549:         )
 2550: 
 2551:         result = merge_asof(left, right, on="a", direction="nearest", tolerance=1)
 2552:         tm.assert_frame_equal(result, expected)
 2553: 
 2554:     def test_tolerance_tz(self, unit):
 2555:         # GH 14844
 2556:         left = pd.DataFrame(
 2557:             {
 2558:                 "date": pd.date_range(
 2559:                     start=to_datetime("2016-01-02"),
 2560:                     freq="D",
 2561:                     periods=5,
 2562:                     tz=pytz.timezone("UTC"),
 2563:                     unit=unit,
 2564:                 ),
 2565:                 "value1": np.arange(5),
 2566:             }
 2567:         )
 2568:         right = pd.DataFrame(
 2569:             {
 2570:                 "date": pd.date_range(
 2571:                     start=to_datetime("2016-01-01"),
 2572:                     freq="D",
 2573:                     periods=5,
 2574:                     tz=pytz.timezone("UTC"),
 2575:                     unit=unit,
 2576:                 ),
 2577:                 "value2": list("ABCDE"),
 2578:             }
 2579:         )
 2580:         result = merge_asof(left, right, on="date", tolerance=Timedelta("1 day"))
 2581: 
 2582:         expected = pd.DataFrame(
 2583:             {
 2584:                 "date": pd.date_range(
 2585:                     start=to_datetime("2016-01-02"),
 2586:                     freq="D",
 2587:                     periods=5,
 2588:                     tz=pytz.timezone("UTC"),
 2589:                     unit=unit,
 2590:                 ),
 2591:                 "value1": np.arange(5),
 2592:                 "value2": list("BCDEE"),
 2593:             }
 2594:         )
 2595:         tm.assert_frame_equal(result, expected)
 2596: 
 2597:     def test_tolerance_float(self):
 2598:         # GH22981
 2599:         left = pd.DataFrame({"a": [1.1, 3.5, 10.9], "left_val": ["a", "b", "c"]})
 2600:         right = pd.DataFrame(
 2601:             {"a": [1.0, 2.5, 3.3, 7.5, 11.5], "right_val": [1.0, 2.5, 3.3, 7.5, 11.5]}
 2602:         )
 2603: 
 2604:         expected = pd.DataFrame(
 2605:             {
 2606:                 "a": [1.1, 3.5, 10.9],
 2607:                 "left_val": ["a", "b", "c"],
 2608:                 "right_val": [1, 3.3, np.nan],
 2609:             }
 2610:         )
 2611: 
 2612:         result = merge_asof(left, right, on="a", direction="nearest", tolerance=0.5)
 2613:         tm.assert_frame_equal(result, expected)
 2614: 
 2615:     def test_index_tolerance(self, trades, quotes, tolerance):
 2616:         # GH 15135
 2617:         expected = tolerance.set_index("time")
 2618:         trades = trades.set_index("time")
 2619:         quotes = quotes.set_index("time")
 2620: 
 2621:         result = merge_asof(
 2622:             trades,
 2623:             quotes,
 2624:             left_index=True,
 2625:             right_index=True,
 2626:             by="ticker",
 2627:             tolerance=Timedelta("1day"),
 2628:         )
 2629:         tm.assert_frame_equal(result, expected)
 2630: 
 2631:     def test_allow_exact_matches(self, trades, quotes, allow_exact_matches):
 2632:         result = merge_asof(
 2633:             trades, quotes, on="time", by="ticker", allow_exact_matches=False
 2634:         )
 2635:         expected = allow_exact_matches
 2636:         tm.assert_frame_equal(result, expected)
 2637: 
 2638:     def test_allow_exact_matches_forward(self):
 2639:         # GH14887
 2640: 
 2641:         left = pd.DataFrame({"a": [1, 5, 10], "left_val": ["a", "b", "c"]})
 2642:         right = pd.DataFrame({"a": [1, 2, 3, 7, 11], "right_val": [1, 2, 3, 7, 11]})
 2643: 
 2644:         expected = pd.DataFrame(
 2645:             {"a": [1, 5, 10], "left_val": ["a", "b", "c"], "right_val": [2, 7, 11]}
 2646:         )
 2647: 
 2648:         result = merge_asof(
 2649:             left, right, on="a", direction="forward", allow_exact_matches=False
 2650:         )
 2651:         tm.assert_frame_equal(result, expected)
 2652: 
 2653:     def test_allow_exact_matches_nearest(self):
 2654:         # GH14887
 2655: 
 2656:         left = pd.DataFrame({"a": [1, 5, 10], "left_val": ["a", "b", "c"]})
 2657:         right = pd.DataFrame({"a": [1, 2, 3, 7, 11], "right_val": [1, 2, 3, 7, 11]})
 2658: 
 2659:         expected = pd.DataFrame(
 2660:             {"a": [1, 5, 10], "left_val": ["a", "b", "c"], "right_val": [2, 3, 11]}
 2661:         )
 2662: 
 2663:         result = merge_asof(
 2664:             left, right, on="a", direction="nearest", allow_exact_matches=False
 2665:         )
 2666:         tm.assert_frame_equal(result, expected)
 2667: 
 2668:     def test_allow_exact_matches_and_tolerance(
 2669:         self, trades, quotes, allow_exact_matches_and_tolerance
 2670:     ):
 2671:         result = merge_asof(
 2672:             trades,
 2673:             quotes,
 2674:             on="time",
 2675:             by="ticker",
 2676:             tolerance=Timedelta("100ms"),
 2677:             allow_exact_matches=False,
 2678:         )
 2679:         expected = allow_exact_matches_and_tolerance
 2680:         tm.assert_frame_equal(result, expected)
 2681: 
 2682:     def test_allow_exact_matches_and_tolerance2(self):
 2683:         # GH 13695
 2684:         df1 = pd.DataFrame(
 2685:             {"time": to_datetime(["2016-07-15 13:30:00.030"]), "username": ["bob"]}
 2686:         )
 2687:         df2 = pd.DataFrame(
 2688:             {
 2689:                 "time": to_datetime(
 2690:                     ["2016-07-15 13:30:00.000", "2016-07-15 13:30:00.030"]
 2691:                 ),
 2692:                 "version": [1, 2],
 2693:             }
 2694:         )
 2695: 
 2696:         result = merge_asof(df1, df2, on="time")
 2697:         expected = pd.DataFrame(
 2698:             {
 2699:                 "time": to_datetime(["2016-07-15 13:30:00.030"]),
 2700:                 "username": ["bob"],
 2701:                 "version": [2],
 2702:             }
 2703:         )
 2704:         tm.assert_frame_equal(result, expected)
 2705: 
 2706:         result = merge_asof(df1, df2, on="time", allow_exact_matches=False)
 2707:         expected = pd.DataFrame(
 2708:             {
 2709:                 "time": to_datetime(["2016-07-15 13:30:00.030"]),
 2710:                 "username": ["bob"],
 2711:                 "version": [1],
 2712:             }
 2713:         )
 2714:         tm.assert_frame_equal(result, expected)
 2715: 
 2716:         result = merge_asof(
 2717:             df1,
 2718:             df2,
 2719:             on="time",
 2720:             allow_exact_matches=False,
 2721:             tolerance=Timedelta("10ms"),
 2722:         )
 2723:         expected = pd.DataFrame(
 2724:             {
 2725:                 "time": to_datetime(["2016-07-15 13:30:00.030"]),
 2726:                 "username": ["bob"],
 2727:                 "version": [np.nan],
 2728:             }
 2729:         )
 2730:         tm.assert_frame_equal(result, expected)
 2731: 
 2732:     def test_allow_exact_matches_and_tolerance3(self):
 2733:         # GH 13709
 2734:         df1 = pd.DataFrame(
 2735:             {
 2736:                 "time": to_datetime(
 2737:                     ["2016-07-15 13:30:00.030", "2016-07-15 13:30:00.030"]
 2738:                 ),
 2739:                 "username": ["bob", "charlie"],
 2740:             }
 2741:         )
 2742:         df2 = pd.DataFrame(
 2743:             {
 2744:                 "time": to_datetime(
 2745:                     ["2016-07-15 13:30:00.000", "2016-07-15 13:30:00.030"]
 2746:                 ),
 2747:                 "version": [1, 2],
 2748:             }
 2749:         )
 2750: 
 2751:         result = merge_asof(
 2752:             df1,
 2753:             df2,
 2754:             on="time",
 2755:             allow_exact_matches=False,
 2756:             tolerance=Timedelta("10ms"),
 2757:         )
 2758:         expected = pd.DataFrame(
 2759:             {
 2760:                 "time": to_datetime(
 2761:                     ["2016-07-15 13:30:00.030", "2016-07-15 13:30:00.030"]
 2762:                 ),
 2763:                 "username": ["bob", "charlie"],
 2764:                 "version": [np.nan, np.nan],
 2765:             }
 2766:         )
 2767:         tm.assert_frame_equal(result, expected)
 2768: 
 2769:     def test_allow_exact_matches_and_tolerance_forward(self):
 2770:         # GH14887
 2771: 
 2772:         left = pd.DataFrame({"a": [1, 5, 10], "left_val": ["a", "b", "c"]})
 2773:         right = pd.DataFrame({"a": [1, 3, 4, 6, 11], "right_val": [1, 3, 4, 6, 11]})
 2774: 
 2775:         expected = pd.DataFrame(
 2776:             {"a": [1, 5, 10], "left_val": ["a", "b", "c"], "right_val": [np.nan, 6, 11]}
 2777:         )
 2778: 
 2779:         result = merge_asof(
 2780:             left,
 2781:             right,
 2782:             on="a",
 2783:             direction="forward",
 2784:             allow_exact_matches=False,
 2785:             tolerance=1,
 2786:         )
 2787:         tm.assert_frame_equal(result, expected)
 2788: 
 2789:     def test_allow_exact_matches_and_tolerance_nearest(self):
 2790:         # GH14887
 2791: 
 2792:         left = pd.DataFrame({"a": [1, 5, 10], "left_val": ["a", "b", "c"]})
 2793:         right = pd.DataFrame({"a": [1, 3, 4, 6, 11], "right_val": [1, 3, 4, 7, 11]})
 2794: 
 2795:         expected = pd.DataFrame(
 2796:             {"a": [1, 5, 10], "left_val": ["a", "b", "c"], "right_val": [np.nan, 4, 11]}
 2797:         )
 2798: 
 2799:         result = merge_asof(
 2800:             left,
 2801:             right,
 2802:             on="a",
 2803:             direction="nearest",
 2804:             allow_exact_matches=False,
 2805:             tolerance=1,
 2806:         )
 2807:         tm.assert_frame_equal(result, expected)
 2808: 
 2809:     def test_forward_by(self):
 2810:         # GH14887
 2811: 
 2812:         left = pd.DataFrame(
 2813:             {
 2814:                 "a": [1, 5, 10, 12, 15],
 2815:                 "b": ["X", "X", "Y", "Z", "Y"],
 2816:                 "left_val": ["a", "b", "c", "d", "e"],
 2817:             }
 2818:         )
 2819:         right = pd.DataFrame(
 2820:             {
 2821:                 "a": [1, 6, 11, 15, 16],
 2822:                 "b": ["X", "Z", "Y", "Z", "Y"],
 2823:                 "right_val": [1, 6, 11, 15, 16],
 2824:             }
 2825:         )
 2826: 
 2827:         expected = pd.DataFrame(
 2828:             {
 2829:                 "a": [1, 5, 10, 12, 15],
 2830:                 "b": ["X", "X", "Y", "Z", "Y"],
 2831:                 "left_val": ["a", "b", "c", "d", "e"],
 2832:                 "right_val": [1, np.nan, 11, 15, 16],
 2833:             }
 2834:         )
 2835: 
 2836:         result = merge_asof(left, right, on="a", by="b", direction="forward")
 2837:         tm.assert_frame_equal(result, expected)
 2838: 
 2839:     def test_nearest_by(self):
 2840:         # GH14887
 2841: 
 2842:         left = pd.DataFrame(
 2843:             {
 2844:                 "a": [1, 5, 10, 12, 15],
 2845:                 "b": ["X", "X", "Z", "Z", "Y"],
 2846:                 "left_val": ["a", "b", "c", "d", "e"],
 2847:             }
 2848:         )
 2849:         right = pd.DataFrame(
 2850:             {
 2851:                 "a": [1, 6, 11, 15, 16],
 2852:                 "b": ["X", "Z", "Z", "Z", "Y"],
 2853:                 "right_val": [1, 6, 11, 15, 16],
 2854:             }
 2855:         )
 2856: 
 2857:         expected = pd.DataFrame(
 2858:             {
 2859:                 "a": [1, 5, 10, 12, 15],
 2860:                 "b": ["X", "X", "Z", "Z", "Y"],
 2861:                 "left_val": ["a", "b", "c", "d", "e"],
 2862:                 "right_val": [1, 1, 11, 11, 16],
 2863:             }
 2864:         )
 2865: 
 2866:         result = merge_asof(left, right, on="a", by="b", direction="nearest")
 2867:         tm.assert_frame_equal(result, expected)
 2868: 
 2869:     def test_by_int(self):
 2870:         # we specialize by type, so test that this is correct
 2871:         df1 = pd.DataFrame(
 2872:             {
 2873:                 "time": to_datetime(
 2874:                     [
 2875:                         "20160525 13:30:00.020",
 2876:                         "20160525 13:30:00.030",
 2877:                         "20160525 13:30:00.040",
 2878:                         "20160525 13:30:00.050",
 2879:                         "20160525 13:30:00.060",
 2880:                     ]
 2881:                 ),
 2882:                 "key": [1, 2, 1, 3, 2],
 2883:                 "value1": [1.1, 1.2, 1.3, 1.4, 1.5],
 2884:             },
 2885:             columns=["time", "key", "value1"],
 2886:         )
 2887: 
 2888:         df2 = pd.DataFrame(
 2889:             {
 2890:                 "time": to_datetime(
 2891:                     [
 2892:                         "20160525 13:30:00.015",
 2893:                         "20160525 13:30:00.020",
 2894:                         "20160525 13:30:00.025",
 2895:                         "20160525 13:30:00.035",
 2896:                         "20160525 13:30:00.040",
 2897:                         "20160525 13:30:00.055",
 2898:                         "20160525 13:30:00.060",
 2899:                         "20160525 13:30:00.065",
 2900:                     ]
 2901:                 ),
 2902:                 "key": [2, 1, 1, 3, 2, 1, 2, 3],
 2903:                 "value2": [2.1, 2.2, 2.3, 2.4, 2.5, 2.6, 2.7, 2.8],
 2904:             },
 2905:             columns=["time", "key", "value2"],
 2906:         )
 2907: 
 2908:         result = merge_asof(df1, df2, on="time", by="key")
 2909: 
 2910:         expected = pd.DataFrame(
 2911:             {
 2912:                 "time": to_datetime(
 2913:                     [
 2914:                         "20160525 13:30:00.020",
 2915:                         "20160525 13:30:00.030",
 2916:                         "20160525 13:30:00.040",
 2917:                         "20160525 13:30:00.050",
 2918:                         "20160525 13:30:00.060",
 2919:                     ]
 2920:                 ),
 2921:                 "key": [1, 2, 1, 3, 2],
 2922:                 "value1": [1.1, 1.2, 1.3, 1.4, 1.5],
 2923:                 "value2": [2.2, 2.1, 2.3, 2.4, 2.7],
 2924:             },
 2925:             columns=["time", "key", "value1", "value2"],
 2926:         )
 2927: 
 2928:         tm.assert_frame_equal(result, expected)
 2929: 
 2930:     def test_on_float(self):
 2931:         # mimics how to determine the minimum-price variation
 2932:         df1 = pd.DataFrame(
 2933:             {
 2934:                 "price": [5.01, 0.0023, 25.13, 340.05, 30.78, 1040.90, 0.0078],
 2935:                 "symbol": list("ABCDEFG"),
 2936:             },
 2937:             columns=["symbol", "price"],
 2938:         )
 2939: 
 2940:         df2 = pd.DataFrame(
 2941:             {"price": [0.0, 1.0, 100.0], "mpv": [0.0001, 0.01, 0.05]},
 2942:             columns=["price", "mpv"],
 2943:         )
 2944: 
 2945:         df1 = df1.sort_values("price").reset_index(drop=True)
 2946: 
 2947:         result = merge_asof(df1, df2, on="price")
 2948: 
 2949:         expected = pd.DataFrame(
 2950:             {
 2951:                 "symbol": list("BGACEDF"),
 2952:                 "price": [0.0023, 0.0078, 5.01, 25.13, 30.78, 340.05, 1040.90],
 2953:                 "mpv": [0.0001, 0.0001, 0.01, 0.01, 0.01, 0.05, 0.05],
 2954:             },
 2955:             columns=["symbol", "price", "mpv"],
 2956:         )
 2957: 
 2958:         tm.assert_frame_equal(result, expected)
 2959: 
 2960:     def test_on_specialized_type(self, any_real_numpy_dtype):
 2961:         # see gh-13936
 2962:         dtype = np.dtype(any_real_numpy_dtype).type
 2963: 
 2964:         df1 = pd.DataFrame(
 2965:             {"value": [5, 2, 25, 100, 78, 120, 79], "symbol": list("ABCDEFG")},
 2966:             columns=["symbol", "value"],
 2967:         )
 2968:         df1.value = dtype(df1.value)
 2969: 
 2970:         df2 = pd.DataFrame(
 2971:             {"value": [0, 80, 120, 125], "result": list("xyzw")},
 2972:             columns=["value", "result"],
 2973:         )
 2974:         df2.value = dtype(df2.value)
 2975: 
 2976:         df1 = df1.sort_values("value").reset_index(drop=True)
 2977:         result = merge_asof(df1, df2, on="value")
 2978: 
 2979:         expected = pd.DataFrame(
 2980:             {
 2981:                 "symbol": list("BACEGDF"),
 2982:                 "value": [2, 5, 25, 78, 79, 100, 120],
 2983:                 "result": list("xxxxxyz"),
 2984:             },
 2985:             columns=["symbol", "value", "result"],
 2986:         )
 2987:         expected.value = dtype(expected.value)
 2988: 
 2989:         tm.assert_frame_equal(result, expected)
 2990: 
 2991:     def test_on_specialized_type_by_int(self, any_real_numpy_dtype):
 2992:         # see gh-13936
 2993:         dtype = np.dtype(any_real_numpy_dtype).type
 2994: 
 2995:         df1 = pd.DataFrame(
 2996:             {
 2997:                 "value": [5, 2, 25, 100, 78, 120, 79],
 2998:                 "key": [1, 2, 3, 2, 3, 1, 2],
 2999:                 "symbol": list("ABCDEFG"),
 3000:             },
 3001:             columns=["symbol", "key", "value"],
 3002:         )
 3003:         df1.value = dtype(df1.value)
 3004: 
 3005:         df2 = pd.DataFrame(
 3006:             {"value": [0, 80, 120, 125], "key": [1, 2, 2, 3], "result": list("xyzw")},
 3007:             columns=["value", "key", "result"],
 3008:         )
 3009:         df2.value = dtype(df2.value)
 3010: 
 3011:         df1 = df1.sort_values("value").reset_index(drop=True)
 3012:         result = merge_asof(df1, df2, on="value", by="key")
 3013: 
 3014:         expected = pd.DataFrame(
 3015:             {
 3016:                 "symbol": list("BACEGDF"),
 3017:                 "key": [2, 1, 3, 3, 2, 2, 1],
 3018:                 "value": [2, 5, 25, 78, 79, 100, 120],
 3019:                 "result": [np.nan, "x", np.nan, np.nan, np.nan, "y", "x"],
 3020:             },
 3021:             columns=["symbol", "key", "value", "result"],
 3022:         )
 3023:         expected.value = dtype(expected.value)
 3024: 
 3025:         tm.assert_frame_equal(result, expected)
 3026: 
 3027:     def test_on_float_by_int(self):
 3028:         # type specialize both "by" and "on" parameters
 3029:         df1 = pd.DataFrame(
 3030:             {
 3031:                 "symbol": list("AAABBBCCC"),
 3032:                 "exch": [1, 2, 3, 1, 2, 3, 1, 2, 3],
 3033:                 "price": [
 3034:                     3.26,
 3035:                     3.2599,
 3036:                     3.2598,
 3037:                     12.58,
 3038:                     12.59,
 3039:                     12.5,
 3040:                     378.15,
 3041:                     378.2,
 3042:                     378.25,
 3043:                 ],
 3044:             },
 3045:             columns=["symbol", "exch", "price"],
 3046:         )
 3047: 
 3048:         df2 = pd.DataFrame(
 3049:             {
 3050:                 "exch": [1, 1, 1, 2, 2, 2, 3, 3, 3],
 3051:                 "price": [0.0, 1.0, 100.0, 0.0, 5.0, 100.0, 0.0, 5.0, 1000.0],
 3052:                 "mpv": [0.0001, 0.01, 0.05, 0.0001, 0.01, 0.1, 0.0001, 0.25, 1.0],
 3053:             },
 3054:             columns=["exch", "price", "mpv"],
 3055:         )
 3056: 
 3057:         df1 = df1.sort_values("price").reset_index(drop=True)
 3058:         df2 = df2.sort_values("price").reset_index(drop=True)
 3059: 
 3060:         result = merge_asof(df1, df2, on="price", by="exch")
 3061: 
 3062:         expected = pd.DataFrame(
 3063:             {
 3064:                 "symbol": list("AAABBBCCC"),
 3065:                 "exch": [3, 2, 1, 3, 1, 2, 1, 2, 3],
 3066:                 "price": [
 3067:                     3.2598,
 3068:                     3.2599,
 3069:                     3.26,
 3070:                     12.5,
 3071:                     12.58,
 3072:                     12.59,
 3073:                     378.15,
 3074:                     378.2,
 3075:                     378.25,
 3076:                 ],
 3077:                 "mpv": [0.0001, 0.0001, 0.01, 0.25, 0.01, 0.01, 0.05, 0.1, 0.25],
 3078:             },
 3079:             columns=["symbol", "exch", "price", "mpv"],
 3080:         )
 3081: 
 3082:         tm.assert_frame_equal(result, expected)
 3083: 
 3084:     def test_merge_datatype_error_raises(self, using_infer_string):
 3085:         if using_infer_string:
 3086:             msg = "incompatible merge keys"
 3087:         else:
 3088:             msg = r"Incompatible merge dtype, .*, both sides must have numeric dtype"
 3089: 
 3090:         left = pd.DataFrame({"left_val": [1, 5, 10], "a": ["a", "b", "c"]})
 3091:         right = pd.DataFrame({"right_val": [1, 2, 3, 6, 7], "a": [1, 2, 3, 6, 7]})
 3092: 
 3093:         with pytest.raises(MergeError, match=msg):
 3094:             merge_asof(left, right, on="a")
 3095: 
 3096:     def test_merge_datatype_categorical_error_raises(self):
 3097:         msg = (
 3098:             r"incompatible merge keys \[0\] .* both sides category, "
 3099:             "but not equal ones"
 3100:         )
 3101: 
 3102:         left = pd.DataFrame(
 3103:             {"left_val": [1, 5, 10], "a": pd.Categorical(["a", "b", "c"])}
 3104:         )
 3105:         right = pd.DataFrame(
 3106:             {
 3107:                 "right_val": [1, 2, 3, 6, 7],
 3108:                 "a": pd.Categorical(["a", "X", "c", "X", "b"]),
 3109:             }
 3110:         )
 3111: 
 3112:         with pytest.raises(MergeError, match=msg):
 3113:             merge_asof(left, right, on="a")
 3114: 
 3115:     def test_merge_groupby_multiple_column_with_categorical_column(self):
 3116:         # GH 16454
 3117:         df = pd.DataFrame({"x": [0], "y": [0], "z": pd.Categorical([0])})
 3118:         result = merge_asof(df, df, on="x", by=["y", "z"])
 3119:         expected = pd.DataFrame({"x": [0], "y": [0], "z": pd.Categorical([0])})
 3120:         tm.assert_frame_equal(result, expected)
 3121: 
 3122:     @pytest.mark.parametrize(
 3123:         "func", [lambda x: x, lambda x: to_datetime(x)], ids=["numeric", "datetime"]
 3124:     )
 3125:     @pytest.mark.parametrize("side", ["left", "right"])
 3126:     def test_merge_on_nans(self, func, side):
 3127:         # GH 23189
 3128:         msg = f"Merge keys contain null values on {side} side"
 3129:         nulls = func([1.0, 5.0, np.nan])
 3130:         non_nulls = func([1.0, 5.0, 10.0])
 3131:         df_null = pd.DataFrame({"a": nulls, "left_val": ["a", "b", "c"]})
 3132:         df = pd.DataFrame({"a": non_nulls, "right_val": [1, 6, 11]})
 3133: 
 3134:         with pytest.raises(ValueError, match=msg):
 3135:             if side == "left":
 3136:                 merge_asof(df_null, df, on="a")
 3137:             else:
 3138:                 merge_asof(df, df_null, on="a")
 3139: 
 3140:     def test_by_nullable(self, any_numeric_ea_dtype, using_infer_string):
 3141:         # Note: this test passes if instead of using pd.array we use
 3142:         #  np.array([np.nan, 1]).  Other than that, I (@jbrockmendel)
 3143:         #  have NO IDEA what the expected behavior is.
 3144:         # TODO(GH#32306): may be relevant to the expected behavior here.
 3145: 
 3146:         arr = pd.array([pd.NA, 0, 1], dtype=any_numeric_ea_dtype)
 3147:         if arr.dtype.kind in ["i", "u"]:
 3148:             max_val = np.iinfo(arr.dtype.numpy_dtype).max
 3149:         else:
 3150:             max_val = np.finfo(arr.dtype.numpy_dtype).max
 3151:         # set value s.t. (at least for integer dtypes) arr._values_for_argsort
 3152:         #  is not an injection
 3153:         arr[2] = max_val
 3154: 
 3155:         left = pd.DataFrame(
 3156:             {
 3157:                 "by_col1": arr,
 3158:                 "by_col2": ["HELLO", "To", "You"],
 3159:                 "on_col": [2, 4, 6],
 3160:                 "value": ["a", "c", "e"],
 3161:             }
 3162:         )
 3163:         right = pd.DataFrame(
 3164:             {
 3165:                 "by_col1": arr,
 3166:                 "by_col2": ["WORLD", "Wide", "Web"],
 3167:                 "on_col": [1, 2, 6],
 3168:                 "value": ["b", "d", "f"],
 3169:             }
 3170:         )
 3171: 
 3172:         result = merge_asof(left, right, by=["by_col1", "by_col2"], on="on_col")
 3173:         expected = pd.DataFrame(
 3174:             {
 3175:                 "by_col1": arr,
 3176:                 "by_col2": ["HELLO", "To", "You"],
 3177:                 "on_col": [2, 4, 6],
 3178:                 "value_x": ["a", "c", "e"],
 3179:             }
 3180:         )
 3181:         expected["value_y"] = np.array([np.nan, np.nan, np.nan], dtype=object)
 3182:         if using_infer_string:
 3183:             expected["value_y"] = expected["value_y"].astype("string[pyarrow_numpy]")
 3184:         tm.assert_frame_equal(result, expected)
 3185: 
 3186:     def test_merge_by_col_tz_aware(self):
 3187:         # GH 21184
 3188:         left = pd.DataFrame(
 3189:             {
 3190:                 "by_col": pd.DatetimeIndex(["2018-01-01"]).tz_localize("UTC"),
 3191:                 "on_col": [2],
 3192:                 "values": ["a"],
 3193:             }
 3194:         )
 3195:         right = pd.DataFrame(
 3196:             {
 3197:                 "by_col": pd.DatetimeIndex(["2018-01-01"]).tz_localize("UTC"),
 3198:                 "on_col": [1],
 3199:                 "values": ["b"],
 3200:             }
 3201:         )
 3202:         result = merge_asof(left, right, by="by_col", on="on_col")
 3203:         expected = pd.DataFrame(
 3204:             [[pd.Timestamp("2018-01-01", tz="UTC"), 2, "a", "b"]],
 3205:             columns=["by_col", "on_col", "values_x", "values_y"],
 3206:         )
 3207:         tm.assert_frame_equal(result, expected)
 3208: 
 3209:     def test_by_mixed_tz_aware(self, using_infer_string):
 3210:         # GH 26649
 3211:         left = pd.DataFrame(
 3212:             {
 3213:                 "by_col1": pd.DatetimeIndex(["2018-01-01"]).tz_localize("UTC"),
 3214:                 "by_col2": ["HELLO"],
 3215:                 "on_col": [2],
 3216:                 "value": ["a"],
 3217:             }
 3218:         )
 3219:         right = pd.DataFrame(
 3220:             {
 3221:                 "by_col1": pd.DatetimeIndex(["2018-01-01"]).tz_localize("UTC"),
 3222:                 "by_col2": ["WORLD"],
 3223:                 "on_col": [1],
 3224:                 "value": ["b"],
 3225:             }
 3226:         )
 3227:         result = merge_asof(left, right, by=["by_col1", "by_col2"], on="on_col")
 3228:         expected = pd.DataFrame(
 3229:             [[pd.Timestamp("2018-01-01", tz="UTC"), "HELLO", 2, "a"]],
 3230:             columns=["by_col1", "by_col2", "on_col", "value_x"],
 3231:         )
 3232:         expected["value_y"] = np.array([np.nan], dtype=object)
 3233:         if using_infer_string:
 3234:             expected["value_y"] = expected["value_y"].astype("string[pyarrow_numpy]")
 3235:         tm.assert_frame_equal(result, expected)
 3236: 
 3237:     @pytest.mark.parametrize("dtype", ["float64", "int16", "m8[ns]", "M8[us]"])
 3238:     def test_by_dtype(self, dtype):
 3239:         # GH 55453, GH 22794
 3240:         left = pd.DataFrame(
 3241:             {
 3242:                 "by_col": np.array([1], dtype=dtype),
 3243:                 "on_col": [2],
 3244:                 "value": ["a"],
 3245:             }
 3246:         )
 3247:         right = pd.DataFrame(
 3248:             {
 3249:                 "by_col": np.array([1], dtype=dtype),
 3250:                 "on_col": [1],
 3251:                 "value": ["b"],
 3252:             }
 3253:         )
 3254:         result = merge_asof(left, right, by="by_col", on="on_col")
 3255:         expected = pd.DataFrame(
 3256:             {
 3257:                 "by_col": np.array([1], dtype=dtype),
 3258:                 "on_col": [2],
 3259:                 "value_x": ["a"],
 3260:                 "value_y": ["b"],
 3261:             }
 3262:         )
 3263:         tm.assert_frame_equal(result, expected)
 3264: 
 3265:     def test_timedelta_tolerance_nearest(self, unit):
 3266:         # GH 27642
 3267:         if unit == "s":
 3268:             pytest.skip(
 3269:                 "This test is invalid with unit='s' because that would "
 3270:                 "round left['time']"
 3271:             )
 3272: 
 3273:         left = pd.DataFrame(
 3274:             list(zip([0, 5, 10, 15, 20, 25], [0, 1, 2, 3, 4, 5])),
 3275:             columns=["time", "left"],
 3276:         )
 3277: 
 3278:         left["time"] = pd.to_timedelta(left["time"], "ms").astype(f"m8[{unit}]")
 3279: 
 3280:         right = pd.DataFrame(
 3281:             list(zip([0, 3, 9, 12, 15, 18], [0, 1, 2, 3, 4, 5])),
 3282:             columns=["time", "right"],
 3283:         )
 3284: 
 3285:         right["time"] = pd.to_timedelta(right["time"], "ms").astype(f"m8[{unit}]")
 3286: 
 3287:         expected = pd.DataFrame(
 3288:             list(
 3289:                 zip(
 3290:                     [0, 5, 10, 15, 20, 25],
 3291:                     [0, 1, 2, 3, 4, 5],
 3292:                     [0, np.nan, 2, 4, np.nan, np.nan],
 3293:                 )
 3294:             ),
 3295:             columns=["time", "left", "right"],
 3296:         )
 3297: 
 3298:         expected["time"] = pd.to_timedelta(expected["time"], "ms").astype(f"m8[{unit}]")
 3299: 
 3300:         result = merge_asof(
 3301:             left, right, on="time", tolerance=Timedelta("1ms"), direction="nearest"
 3302:         )
 3303: 
 3304:         tm.assert_frame_equal(result, expected)
 3305: 
 3306:     def test_int_type_tolerance(self, any_int_dtype):
 3307:         # GH #28870
 3308: 
 3309:         left = pd.DataFrame({"a": [0, 10, 20], "left_val": [1, 2, 3]})
 3310:         right = pd.DataFrame({"a": [5, 15, 25], "right_val": [1, 2, 3]})
 3311:         left["a"] = left["a"].astype(any_int_dtype)
 3312:         right["a"] = right["a"].astype(any_int_dtype)
 3313: 
 3314:         expected = pd.DataFrame(
 3315:             {"a": [0, 10, 20], "left_val": [1, 2, 3], "right_val": [np.nan, 1.0, 2.0]}
 3316:         )
 3317:         expected["a"] = expected["a"].astype(any_int_dtype)
 3318: 
 3319:         result = merge_asof(left, right, on="a", tolerance=10)
 3320:         tm.assert_frame_equal(result, expected)
 3321: 
 3322:     def test_merge_index_column_tz(self):
 3323:         # GH 29864
 3324:         index = pd.date_range("2019-10-01", freq="30min", periods=5, tz="UTC")
 3325:         left = pd.DataFrame([0.9, 0.8, 0.7, 0.6], columns=["xyz"], index=index[1:])
 3326:         right = pd.DataFrame({"from_date": index, "abc": [2.46] * 4 + [2.19]})
 3327:         result = merge_asof(
 3328:             left=left, right=right, left_index=True, right_on=["from_date"]
 3329:         )
 3330:         expected = pd.DataFrame(
 3331:             {
 3332:                 "xyz": [0.9, 0.8, 0.7, 0.6],
 3333:                 "from_date": index[1:],
 3334:                 "abc": [2.46] * 3 + [2.19],
 3335:             },
 3336:             index=pd.date_range(
 3337:                 "2019-10-01 00:30:00", freq="30min", periods=4, tz="UTC"
 3338:             ),
 3339:         )
 3340:         tm.assert_frame_equal(result, expected)
 3341: 
 3342:         result = merge_asof(
 3343:             left=right, right=left, right_index=True, left_on=["from_date"]
 3344:         )
 3345:         expected = pd.DataFrame(
 3346:             {
 3347:                 "from_date": index,
 3348:                 "abc": [2.46] * 4 + [2.19],
 3349:                 "xyz": [np.nan, 0.9, 0.8, 0.7, 0.6],
 3350:             },
 3351:             index=Index([0, 1, 2, 3, 4]),
 3352:         )
 3353:         tm.assert_frame_equal(result, expected)
 3354: 
 3355:     def test_left_index_right_index_tolerance(self, unit):
 3356:         # https://github.com/pandas-dev/pandas/issues/35558
 3357:         if unit == "s":
 3358:             pytest.skip(
 3359:                 "This test is invalid with unit='s' because that would round dr1"
 3360:             )
 3361: 
 3362:         dr1 = pd.date_range(
 3363:             start="1/1/2020", end="1/20/2020", freq="2D", unit=unit
 3364:         ) + Timedelta(seconds=0.4).as_unit(unit)
 3365:         dr2 = pd.date_range(start="1/1/2020", end="2/1/2020", unit=unit)
 3366: 
 3367:         df1 = pd.DataFrame({"val1": "foo"}, index=pd.DatetimeIndex(dr1))
 3368:         df2 = pd.DataFrame({"val2": "bar"}, index=pd.DatetimeIndex(dr2))
 3369: 
 3370:         expected = pd.DataFrame(
 3371:             {"val1": "foo", "val2": "bar"}, index=pd.DatetimeIndex(dr1)
 3372:         )
 3373:         result = merge_asof(
 3374:             df1,
 3375:             df2,
 3376:             left_index=True,
 3377:             right_index=True,
 3378:             tolerance=Timedelta(seconds=0.5),
 3379:         )
 3380:         tm.assert_frame_equal(result, expected)
 3381: 
 3382: 
 3383: @pytest.mark.parametrize(
 3384:     "infer_string", [False, pytest.param(True, marks=td.skip_if_no("pyarrow"))]
 3385: )
 3386: @pytest.mark.parametrize(
 3387:     "kwargs", [{"on": "x"}, {"left_index": True, "right_index": True}]
 3388: )
 3389: @pytest.mark.parametrize(
 3390:     "data",
 3391:     [["2019-06-01 00:09:12", "2019-06-01 00:10:29"], [1.0, "2019-06-01 00:10:29"]],
 3392: )
 3393: def test_merge_asof_non_numerical_dtype(kwargs, data, infer_string):
 3394:     # GH#29130
 3395:     with option_context("future.infer_string", infer_string):
 3396:         left = pd.DataFrame({"x": data}, index=data)
 3397:         right = pd.DataFrame({"x": data}, index=data)
 3398:         with pytest.raises(
 3399:             MergeError,
 3400:             match=r"Incompatible merge dtype, .*, both sides must have numeric dtype",
 3401:         ):
 3402:             merge_asof(left, right, **kwargs)
 3403: 
 3404: 
 3405: def test_merge_asof_non_numerical_dtype_object():
 3406:     # GH#29130
 3407:     left = pd.DataFrame({"a": ["12", "13", "15"], "left_val1": ["a", "b", "c"]})
 3408:     right = pd.DataFrame({"a": ["a", "b", "c"], "left_val": ["d", "e", "f"]})
 3409:     with pytest.raises(
 3410:         MergeError,
 3411:         match=r"Incompatible merge dtype, .*, both sides must have numeric dtype",
 3412:     ):
 3413:         merge_asof(
 3414:             left,
 3415:             right,
 3416:             left_on="left_val1",
 3417:             right_on="a",
 3418:             left_by="a",
 3419:             right_by="left_val",
 3420:         )
 3421: 
 3422: 
 3423: @pytest.mark.parametrize(
 3424:     "kwargs",
 3425:     [
 3426:         {"right_index": True, "left_index": True},
 3427:         {"left_on": "left_time", "right_index": True},
 3428:         {"left_index": True, "right_on": "right"},
 3429:     ],
 3430: )
 3431: def test_merge_asof_index_behavior(kwargs):
 3432:     # GH 33463
 3433:     index = Index([1, 5, 10], name="test")
 3434:     left = pd.DataFrame({"left": ["a", "b", "c"], "left_time": [1, 4, 10]}, index=index)
 3435:     right = pd.DataFrame({"right": [1, 2, 3, 6, 7]}, index=[1, 2, 3, 6, 7])
 3436:     result = merge_asof(left, right, **kwargs)
 3437: 
 3438:     expected = pd.DataFrame(
 3439:         {"left": ["a", "b", "c"], "left_time": [1, 4, 10], "right": [1, 3, 7]},
 3440:         index=index,
 3441:     )
 3442:     tm.assert_frame_equal(result, expected)
 3443: 
 3444: 
 3445: def test_merge_asof_numeric_column_in_index():
 3446:     # GH#34488
 3447:     left = pd.DataFrame({"b": [10, 11, 12]}, index=Index([1, 2, 3], name="a"))
 3448:     right = pd.DataFrame({"c": [20, 21, 22]}, index=Index([0, 2, 3], name="a"))
 3449: 
 3450:     result = merge_asof(left, right, left_on="a", right_on="a")
 3451:     expected = pd.DataFrame({"a": [1, 2, 3], "b": [10, 11, 12], "c": [20, 21, 22]})
 3452:     tm.assert_frame_equal(result, expected)
 3453: 
 3454: 
 3455: def test_merge_asof_numeric_column_in_multiindex():
 3456:     # GH#34488
 3457:     left = pd.DataFrame(
 3458:         {"b": [10, 11, 12]},
 3459:         index=pd.MultiIndex.from_arrays([[1, 2, 3], ["a", "b", "c"]], names=["a", "z"]),
 3460:     )
 3461:     right = pd.DataFrame(
 3462:         {"c": [20, 21, 22]},
 3463:         index=pd.MultiIndex.from_arrays([[1, 2, 3], ["x", "y", "z"]], names=["a", "y"]),
 3464:     )
 3465: 
 3466:     result = merge_asof(left, right, left_on="a", right_on="a")
 3467:     expected = pd.DataFrame({"a": [1, 2, 3], "b": [10, 11, 12], "c": [20, 21, 22]})
 3468:     tm.assert_frame_equal(result, expected)
 3469: 
 3470: 
 3471: def test_merge_asof_numeri_column_in_index_object_dtype():
 3472:     # GH#34488
 3473:     left = pd.DataFrame({"b": [10, 11, 12]}, index=Index(["1", "2", "3"], name="a"))
 3474:     right = pd.DataFrame({"c": [20, 21, 22]}, index=Index(["m", "n", "o"], name="a"))
 3475: 
 3476:     with pytest.raises(
 3477:         MergeError,
 3478:         match=r"Incompatible merge dtype, .*, both sides must have numeric dtype",
 3479:     ):
 3480:         merge_asof(left, right, left_on="a", right_on="a")
 3481: 
 3482:     left = left.reset_index().set_index(["a", "b"])
 3483:     right = right.reset_index().set_index(["a", "c"])
 3484: 
 3485:     with pytest.raises(
 3486:         MergeError,
 3487:         match=r"Incompatible merge dtype, .*, both sides must have numeric dtype",
 3488:     ):
 3489:         merge_asof(left, right, left_on="a", right_on="a")
 3490: 
 3491: 
 3492: def test_merge_asof_array_as_on(unit):
 3493:     # GH#42844
 3494:     dti = pd.DatetimeIndex(
 3495:         ["2021/01/01 00:37", "2021/01/01 01:40"], dtype=f"M8[{unit}]"
 3496:     )
 3497:     right = pd.DataFrame(
 3498:         {
 3499:             "a": [2, 6],
 3500:             "ts": dti,
 3501:         }
 3502:     )
 3503:     ts_merge = pd.date_range(
 3504:         start=pd.Timestamp("2021/01/01 00:00"), periods=3, freq="1h", unit=unit
 3505:     )
 3506:     left = pd.DataFrame({"b": [4, 8, 7]})
 3507:     result = merge_asof(
 3508:         left,
 3509:         right,
 3510:         left_on=ts_merge,
 3511:         right_on="ts",
 3512:         allow_exact_matches=False,
 3513:         direction="backward",
 3514:     )
 3515:     expected = pd.DataFrame({"b": [4, 8, 7], "a": [np.nan, 2, 6], "ts": ts_merge})
 3516:     tm.assert_frame_equal(result, expected)
 3517: 
 3518:     result = merge_asof(
 3519:         right,
 3520:         left,
 3521:         left_on="ts",
 3522:         right_on=ts_merge,
 3523:         allow_exact_matches=False,
 3524:         direction="backward",
 3525:     )
 3526:     expected = pd.DataFrame(
 3527:         {
 3528:             "a": [2, 6],
 3529:             "ts": dti,
 3530:             "b": [4, 8],
 3531:         }
 3532:     )
 3533:     tm.assert_frame_equal(result, expected)
 3534: 
 3535: 
 3536: def test_merge_asof_raise_for_duplicate_columns():
 3537:     # GH#50102
 3538:     left = pd.DataFrame([[1, 2, "a"]], columns=["a", "a", "left_val"])
 3539:     right = pd.DataFrame([[1, 1, 1]], columns=["a", "a", "right_val"])
 3540: 
 3541:     with pytest.raises(ValueError, match="column label 'a'"):
 3542:         merge_asof(left, right, on="a")
 3543: 
 3544:     with pytest.raises(ValueError, match="column label 'a'"):
 3545:         merge_asof(left, right, left_on="a", right_on="right_val")
 3546: 
 3547:     with pytest.raises(ValueError, match="column label 'a'"):
 3548:         merge_asof(left, right, left_on="left_val", right_on="a")
 3549: 
 3550: 
 3551: @pytest.mark.parametrize(
 3552:     "dtype",
 3553:     [
 3554:         "Int64",
 3555:         pytest.param("int64[pyarrow]", marks=td.skip_if_no("pyarrow")),
 3556:         pytest.param("timestamp[s][pyarrow]", marks=td.skip_if_no("pyarrow")),
 3557:     ],
 3558: )
 3559: def test_merge_asof_extension_dtype(dtype):
 3560:     # GH 52904
 3561:     left = pd.DataFrame(
 3562:         {
 3563:             "join_col": [1, 3, 5],
 3564:             "left_val": [1, 2, 3],
 3565:         }
 3566:     )
 3567:     right = pd.DataFrame(
 3568:         {
 3569:             "join_col": [2, 3, 4],
 3570:             "right_val": [1, 2, 3],
 3571:         }
 3572:     )
 3573:     left = left.astype({"join_col": dtype})
 3574:     right = right.astype({"join_col": dtype})
 3575:     result = merge_asof(left, right, on="join_col")
 3576:     expected = pd.DataFrame(
 3577:         {
 3578:             "join_col": [1, 3, 5],
 3579:             "left_val": [1, 2, 3],
 3580:             "right_val": [np.nan, 2.0, 3.0],
 3581:         }
 3582:     )
 3583:     expected = expected.astype({"join_col": dtype})
 3584:     tm.assert_frame_equal(result, expected)
 3585: 
 3586: 
 3587: @td.skip_if_no("pyarrow")
 3588: def test_merge_asof_pyarrow_td_tolerance():
 3589:     # GH 56486
 3590:     ser = pd.Series(
 3591:         [datetime.datetime(2023, 1, 1)], dtype="timestamp[us, UTC][pyarrow]"
 3592:     )
 3593:     df = pd.DataFrame(
 3594:         {
 3595:             "timestamp": ser,
 3596:             "value": [1],
 3597:         }
 3598:     )
 3599:     result = merge_asof(df, df, on="timestamp", tolerance=Timedelta("1s"))
 3600:     expected = pd.DataFrame(
 3601:         {
 3602:             "timestamp": ser,
 3603:             "value_x": [1],
 3604:             "value_y": [1],
 3605:         }
 3606:     )
 3607:     tm.assert_frame_equal(result, expected)
 3608: 
 3609: 
 3610: def test_merge_asof_read_only_ndarray():
 3611:     # GH 53513
 3612:     left = pd.Series([2], index=[2], name="left")
 3613:     right = pd.Series([1], index=[1], name="right")
 3614:     # set to read-only
 3615:     left.index.values.flags.writeable = False
 3616:     right.index.values.flags.writeable = False
 3617:     result = merge_asof(left, right, left_index=True, right_index=True)
 3618:     expected = pd.DataFrame({"left": [2], "right": [1]}, index=[2])
 3619:     tm.assert_frame_equal(result, expected)
 3620: 
 3621: 
 3622: def test_merge_asof_multiby_with_categorical():
 3623:     # GH 43541
 3624:     left = pd.DataFrame(
 3625:         {
 3626:             "c1": pd.Categorical(["a", "a", "b", "b"], categories=["a", "b"]),
 3627:             "c2": ["x"] * 4,
 3628:             "t": [1] * 4,
 3629:             "v": range(4),
 3630:         }
 3631:     )
 3632:     right = pd.DataFrame(
 3633:         {
 3634:             "c1": pd.Categorical(["b", "b"], categories=["b", "a"]),
 3635:             "c2": ["x"] * 2,
 3636:             "t": [1, 2],
 3637:             "v": range(2),
 3638:         }
 3639:     )
 3640:     result = merge_asof(
 3641:         left,
 3642:         right,
 3643:         by=["c1", "c2"],
 3644:         on="t",
 3645:         direction="forward",
 3646:         suffixes=["_left", "_right"],
 3647:     )
 3648:     expected = pd.DataFrame(
 3649:         {
 3650:             "c1": pd.Categorical(["a", "a", "b", "b"], categories=["a", "b"]),
 3651:             "c2": ["x"] * 4,
 3652:             "t": [1] * 4,
 3653:             "v_left": range(4),
 3654:             "v_right": [np.nan, np.nan, 0.0, 0.0],
 3655:         }
 3656:     )
 3657:     tm.assert_frame_equal(result, expected)
