    1: import numpy as np
    2: import pytest
    3: 
    4: import pandas as pd
    5: from pandas import (
    6:     DataFrame,
    7:     Index,
    8:     MultiIndex,
    9:     Series,
   10:     period_range,
   11:     timedelta_range,
   12: )
   13: import pandas._testing as tm
   14: from pandas.core.util.hashing import hash_tuples
   15: from pandas.util import (
   16:     hash_array,
   17:     hash_pandas_object,
   18: )
   19: 
   20: 
   21: @pytest.fixture(
   22:     params=[
   23:         Series([1, 2, 3] * 3, dtype="int32"),
   24:         Series([None, 2.5, 3.5] * 3, dtype="float32"),
   25:         Series(["a", "b", "c"] * 3, dtype="category"),
   26:         Series(["d", "e", "f"] * 3),
   27:         Series([True, False, True] * 3),
   28:         Series(pd.date_range("20130101", periods=9)),
   29:         Series(pd.date_range("20130101", periods=9, tz="US/Eastern")),
   30:         Series(timedelta_range("2000", periods=9)),
   31:     ]
   32: )
   33: def series(request):
   34:     return request.param
   35: 
   36: 
   37: @pytest.fixture(params=[True, False])
   38: def index(request):
   39:     return request.param
   40: 
   41: 
   42: def test_consistency():
   43:     # Check that our hash doesn't change because of a mistake
   44:     # in the actual code; this is the ground truth.
   45:     result = hash_pandas_object(Index(["foo", "bar", "baz"]))
   46:     expected = Series(
   47:         np.array(
   48:             [3600424527151052760, 1374399572096150070, 477881037637427054],
   49:             dtype="uint64",
   50:         ),
   51:         index=["foo", "bar", "baz"],
   52:     )
   53:     tm.assert_series_equal(result, expected)
   54: 
   55: 
   56: def test_hash_array(series):
   57:     arr = series.values
   58:     tm.assert_numpy_array_equal(hash_array(arr), hash_array(arr))
   59: 
   60: 
   61: @pytest.mark.parametrize("dtype", ["U", object])
   62: def test_hash_array_mixed(dtype):
   63:     result1 = hash_array(np.array(["3", "4", "All"]))
   64:     result2 = hash_array(np.array([3, 4, "All"], dtype=dtype))
   65: 
   66:     tm.assert_numpy_array_equal(result1, result2)
   67: 
   68: 
   69: @pytest.mark.parametrize("val", [5, "foo", pd.Timestamp("20130101")])
   70: def test_hash_array_errors(val):
   71:     msg = "must pass a ndarray-like"
   72:     with pytest.raises(TypeError, match=msg):
   73:         hash_array(val)
   74: 
   75: 
   76: def test_hash_array_index_exception():
   77:     # GH42003 TypeError instead of AttributeError
   78:     obj = pd.DatetimeIndex(["2018-10-28 01:20:00"], tz="Europe/Berlin")
   79: 
   80:     msg = "Use hash_pandas_object instead"
   81:     with pytest.raises(TypeError, match=msg):
   82:         hash_array(obj)
   83: 
   84: 
   85: def test_hash_tuples():
   86:     tuples = [(1, "one"), (1, "two"), (2, "one")]
   87:     result = hash_tuples(tuples)
   88: 
   89:     expected = hash_pandas_object(MultiIndex.from_tuples(tuples)).values
   90:     tm.assert_numpy_array_equal(result, expected)
   91: 
   92:     # We only need to support MultiIndex and list-of-tuples
   93:     msg = "|".join(["object is not iterable", "zip argument #1 must support iteration"])
   94:     with pytest.raises(TypeError, match=msg):
   95:         hash_tuples(tuples[0])
   96: 
   97: 
   98: @pytest.mark.parametrize("val", [5, "foo", pd.Timestamp("20130101")])
   99: def test_hash_tuples_err(val):
  100:     msg = "must be convertible to a list-of-tuples"
  101:     with pytest.raises(TypeError, match=msg):
  102:         hash_tuples(val)
  103: 
  104: 
  105: def test_multiindex_unique():
  106:     mi = MultiIndex.from_tuples([(118, 472), (236, 118), (51, 204), (102, 51)])
  107:     assert mi.is_unique is True
  108: 
  109:     result = hash_pandas_object(mi)
  110:     assert result.is_unique is True
  111: 
  112: 
  113: def test_multiindex_objects():
  114:     mi = MultiIndex(
  115:         levels=[["b", "d", "a"], [1, 2, 3]],
  116:         codes=[[0, 1, 0, 2], [2, 0, 0, 1]],
  117:         names=["col1", "col2"],
  118:     )
  119:     recons = mi._sort_levels_monotonic()
  120: 
  121:     # These are equal.
  122:     assert mi.equals(recons)
  123:     assert Index(mi.values).equals(Index(recons.values))
  124: 
  125: 
  126: @pytest.mark.parametrize(
  127:     "obj",
  128:     [
  129:         Series([1, 2, 3]),
  130:         Series([1.0, 1.5, 3.2]),
  131:         Series([1.0, 1.5, np.nan]),
  132:         Series([1.0, 1.5, 3.2], index=[1.5, 1.1, 3.3]),
  133:         Series(["a", "b", "c"]),
  134:         Series(["a", np.nan, "c"]),
  135:         Series(["a", None, "c"]),
  136:         Series([True, False, True]),
  137:         Series(dtype=object),
  138:         DataFrame({"x": ["a", "b", "c"], "y": [1, 2, 3]}),
  139:         DataFrame(),
  140:         DataFrame(np.full((10, 4), np.nan)),
  141:         DataFrame(
  142:             {
  143:                 "A": [0.0, 1.0, 2.0, 3.0, 4.0],
  144:                 "B": [0.0, 1.0, 0.0, 1.0, 0.0],
  145:                 "C": Index(["foo1", "foo2", "foo3", "foo4", "foo5"], dtype=object),
  146:                 "D": pd.date_range("20130101", periods=5),
  147:             }
  148:         ),
  149:         DataFrame(range(5), index=pd.date_range("2020-01-01", periods=5)),
  150:         Series(range(5), index=pd.date_range("2020-01-01", periods=5)),
  151:         Series(period_range("2020-01-01", periods=10, freq="D")),
  152:         Series(pd.date_range("20130101", periods=3, tz="US/Eastern")),
  153:     ],
  154: )
  155: def test_hash_pandas_object(obj, index):
  156:     a = hash_pandas_object(obj, index=index)
  157:     b = hash_pandas_object(obj, index=index)
  158:     tm.assert_series_equal(a, b)
  159: 
  160: 
  161: @pytest.mark.parametrize(
  162:     "obj",
  163:     [
  164:         Series([1, 2, 3]),
  165:         Series([1.0, 1.5, 3.2]),
  166:         Series([1.0, 1.5, np.nan]),
  167:         Series([1.0, 1.5, 3.2], index=[1.5, 1.1, 3.3]),
  168:         Series(["a", "b", "c"]),
  169:         Series(["a", np.nan, "c"]),
  170:         Series(["a", None, "c"]),
  171:         Series([True, False, True]),
  172:         DataFrame({"x": ["a", "b", "c"], "y": [1, 2, 3]}),
  173:         DataFrame(np.full((10, 4), np.nan)),
  174:         DataFrame(
  175:             {
  176:                 "A": [0.0, 1.0, 2.0, 3.0, 4.0],
  177:                 "B": [0.0, 1.0, 0.0, 1.0, 0.0],
  178:                 "C": Index(["foo1", "foo2", "foo3", "foo4", "foo5"], dtype=object),
  179:                 "D": pd.date_range("20130101", periods=5),
  180:             }
  181:         ),
  182:         DataFrame(range(5), index=pd.date_range("2020-01-01", periods=5)),
  183:         Series(range(5), index=pd.date_range("2020-01-01", periods=5)),
  184:         Series(period_range("2020-01-01", periods=10, freq="D")),
  185:         Series(pd.date_range("20130101", periods=3, tz="US/Eastern")),
  186:     ],
  187: )
  188: def test_hash_pandas_object_diff_index_non_empty(obj):
  189:     a = hash_pandas_object(obj, index=True)
  190:     b = hash_pandas_object(obj, index=False)
  191:     assert not (a == b).all()
  192: 
  193: 
  194: @pytest.mark.parametrize(
  195:     "obj",
  196:     [
  197:         Index([1, 2, 3]),
  198:         Index([True, False, True]),
  199:         timedelta_range("1 day", periods=2),
  200:         period_range("2020-01-01", freq="D", periods=2),
  201:         MultiIndex.from_product(
  202:             [range(5), ["foo", "bar", "baz"], pd.date_range("20130101", periods=2)]
  203:         ),
  204:         MultiIndex.from_product([pd.CategoricalIndex(list("aabc")), range(3)]),
  205:     ],
  206: )
  207: def test_hash_pandas_index(obj, index):
  208:     a = hash_pandas_object(obj, index=index)
  209:     b = hash_pandas_object(obj, index=index)
  210:     tm.assert_series_equal(a, b)
  211: 
  212: 
  213: def test_hash_pandas_series(series, index):
  214:     a = hash_pandas_object(series, index=index)
  215:     b = hash_pandas_object(series, index=index)
  216:     tm.assert_series_equal(a, b)
  217: 
  218: 
  219: def test_hash_pandas_series_diff_index(series):
  220:     a = hash_pandas_object(series, index=True)
  221:     b = hash_pandas_object(series, index=False)
  222:     assert not (a == b).all()
  223: 
  224: 
  225: @pytest.mark.parametrize(
  226:     "obj", [Series([], dtype="float64"), Series([], dtype="object"), Index([])]
  227: )
  228: def test_hash_pandas_empty_object(obj, index):
  229:     # These are by-definition the same with
  230:     # or without the index as the data is empty.
  231:     a = hash_pandas_object(obj, index=index)
  232:     b = hash_pandas_object(obj, index=index)
  233:     tm.assert_series_equal(a, b)
  234: 
  235: 
  236: @pytest.mark.parametrize(
  237:     "s1",
  238:     [
  239:         Series(["a", "b", "c", "d"]),
  240:         Series([1000, 2000, 3000, 4000]),
  241:         Series(pd.date_range(0, periods=4)),
  242:     ],
  243: )
  244: @pytest.mark.parametrize("categorize", [True, False])
  245: def test_categorical_consistency(s1, categorize):
  246:     # see gh-15143
  247:     #
  248:     # Check that categoricals hash consistent with their values,
  249:     # not codes. This should work for categoricals of any dtype.
  250:     s2 = s1.astype("category").cat.set_categories(s1)
  251:     s3 = s2.cat.set_categories(list(reversed(s1)))
  252: 
  253:     # These should all hash identically.
  254:     h1 = hash_pandas_object(s1, categorize=categorize)
  255:     h2 = hash_pandas_object(s2, categorize=categorize)
  256:     h3 = hash_pandas_object(s3, categorize=categorize)
  257: 
  258:     tm.assert_series_equal(h1, h2)
  259:     tm.assert_series_equal(h1, h3)
  260: 
  261: 
  262: def test_categorical_with_nan_consistency():
  263:     c = pd.Categorical.from_codes(
  264:         [-1, 0, 1, 2, 3, 4], categories=pd.date_range("2012-01-01", periods=5, name="B")
  265:     )
  266:     expected = hash_array(c, categorize=False)
  267: 
  268:     c = pd.Categorical.from_codes([-1, 0], categories=[pd.Timestamp("2012-01-01")])
  269:     result = hash_array(c, categorize=False)
  270: 
  271:     assert result[0] in expected
  272:     assert result[1] in expected
  273: 
  274: 
  275: def test_pandas_errors():
  276:     msg = "Unexpected type for hashing"
  277:     with pytest.raises(TypeError, match=msg):
  278:         hash_pandas_object(pd.Timestamp("20130101"))
  279: 
  280: 
  281: def test_hash_keys():
  282:     # Using different hash keys, should have
  283:     # different hashes for the same data.
  284:     #
  285:     # This only matters for object dtypes.
  286:     obj = Series(list("abc"))
  287: 
  288:     a = hash_pandas_object(obj, hash_key="9876543210123456")
  289:     b = hash_pandas_object(obj, hash_key="9876543210123465")
  290: 
  291:     assert (a != b).all()
  292: 
  293: 
  294: def test_df_hash_keys():
  295:     # DataFrame version of the test_hash_keys.
  296:     # https://github.com/pandas-dev/pandas/issues/41404
  297:     obj = DataFrame({"x": np.arange(3), "y": list("abc")})
  298: 
  299:     a = hash_pandas_object(obj, hash_key="9876543210123456")
  300:     b = hash_pandas_object(obj, hash_key="9876543210123465")
  301: 
  302:     assert (a != b).all()
  303: 
  304: 
  305: def test_df_encoding():
  306:     # Check that DataFrame recognizes optional encoding.
  307:     # https://github.com/pandas-dev/pandas/issues/41404
  308:     # https://github.com/pandas-dev/pandas/pull/42049
  309:     obj = DataFrame({"x": np.arange(3), "y": list("a+c")})
  310: 
  311:     a = hash_pandas_object(obj, encoding="utf8")
  312:     b = hash_pandas_object(obj, encoding="utf7")
  313: 
  314:     # Note that the "+" is encoded as "+-" in utf-7.
  315:     assert a[0] == b[0]
  316:     assert a[1] != b[1]
  317:     assert a[2] == b[2]
  318: 
  319: 
  320: def test_invalid_key():
  321:     # This only matters for object dtypes.
  322:     msg = "key should be a 16-byte string encoded"
  323: 
  324:     with pytest.raises(ValueError, match=msg):
  325:         hash_pandas_object(Series(list("abc")), hash_key="foo")
  326: 
  327: 
  328: def test_already_encoded(index):
  329:     # If already encoded, then ok.
  330:     obj = Series(list("abc")).str.encode("utf8")
  331:     a = hash_pandas_object(obj, index=index)
  332:     b = hash_pandas_object(obj, index=index)
  333:     tm.assert_series_equal(a, b)
  334: 
  335: 
  336: def test_alternate_encoding(index):
  337:     obj = Series(list("abc"))
  338:     a = hash_pandas_object(obj, index=index)
  339:     b = hash_pandas_object(obj, index=index)
  340:     tm.assert_series_equal(a, b)
  341: 
  342: 
  343: @pytest.mark.parametrize("l_exp", range(8))
  344: @pytest.mark.parametrize("l_add", [0, 1])
  345: def test_same_len_hash_collisions(l_exp, l_add):
  346:     length = 2 ** (l_exp + 8) + l_add
  347:     idx = np.array([str(i) for i in range(length)], dtype=object)
  348: 
  349:     result = hash_array(idx, "utf8")
  350:     assert not result[0] == result[1]
  351: 
  352: 
  353: def test_hash_collisions():
  354:     # Hash collisions are bad.
  355:     #
  356:     # https://github.com/pandas-dev/pandas/issues/14711#issuecomment-264885726
  357:     hashes = [
  358:         "Ingrid-9Z9fKIZmkO7i7Cn51Li34pJm44fgX6DYGBNj3VPlOH50m7HnBlPxfIwFMrcNJNMP6PSgLmwWnInciMWrCSAlLEvt7JkJl4IxiMrVbXSa8ZQoVaq5xoQPjltuJEfwdNlO6jo8qRRHvD8sBEBMQASrRa6TsdaPTPCBo3nwIBpE7YzzmyH0vMBhjQZLx1aCT7faSEx7PgFxQhHdKFWROcysamgy9iVj8DO2Fmwg1NNl93rIAqC3mdqfrCxrzfvIY8aJdzin2cHVzy3QUJxZgHvtUtOLxoqnUHsYbNTeq0xcLXpTZEZCxD4PGubIuCNf32c33M7HFsnjWSEjE2yVdWKhmSVodyF8hFYVmhYnMCztQnJrt3O8ZvVRXd5IKwlLexiSp4h888w7SzAIcKgc3g5XQJf6MlSMftDXm9lIsE1mJNiJEv6uY6pgvC3fUPhatlR5JPpVAHNSbSEE73MBzJrhCAbOLXQumyOXigZuPoME7QgJcBalliQol7YZ9",
  359:         "Tim-b9MddTxOWW2AT1Py6vtVbZwGAmYCjbp89p8mxsiFoVX4FyDOF3wFiAkyQTUgwg9sVqVYOZo09Dh1AzhFHbgij52ylF0SEwgzjzHH8TGY8Lypart4p4onnDoDvVMBa0kdthVGKl6K0BDVGzyOXPXKpmnMF1H6rJzqHJ0HywfwS4XYpVwlAkoeNsiicHkJUFdUAhG229INzvIAiJuAHeJDUoyO4DCBqtoZ5TDend6TK7Y914yHlfH3g1WZu5LksKv68VQHJriWFYusW5e6ZZ6dKaMjTwEGuRgdT66iU5nqWTHRH8WSzpXoCFwGcTOwyuqPSe0fTe21DVtJn1FKj9F9nEnR9xOvJUO7E0piCIF4Ad9yAIDY4DBimpsTfKXCu1vdHpKYerzbndfuFe5AhfMduLYZJi5iAw8qKSwR5h86ttXV0Mc0QmXz8dsRvDgxjXSmupPxBggdlqUlC828hXiTPD7am0yETBV0F3bEtvPiNJfremszcV8NcqAoARMe",
  360:     ]
  361: 
  362:     # These should be different.
  363:     result1 = hash_array(np.asarray(hashes[0:1], dtype=object), "utf8")
  364:     expected1 = np.array([14963968704024874985], dtype=np.uint64)
  365:     tm.assert_numpy_array_equal(result1, expected1)
  366: 
  367:     result2 = hash_array(np.asarray(hashes[1:2], dtype=object), "utf8")
  368:     expected2 = np.array([16428432627716348016], dtype=np.uint64)
  369:     tm.assert_numpy_array_equal(result2, expected2)
  370: 
  371:     result = hash_array(np.asarray(hashes, dtype=object), "utf8")
  372:     tm.assert_numpy_array_equal(result, np.concatenate([expected1, expected2], axis=0))
  373: 
  374: 
  375: @pytest.mark.parametrize(
  376:     "data, result_data",
  377:     [
  378:         [[tuple("1"), tuple("2")], [10345501319357378243, 8331063931016360761]],
  379:         [[(1,), (2,)], [9408946347443669104, 3278256261030523334]],
  380:     ],
  381: )
  382: def test_hash_with_tuple(data, result_data):
  383:     # GH#28969 array containing a tuple raises on call to arr.astype(str)
  384:     #  apparently a numpy bug github.com/numpy/numpy/issues/9441
  385: 
  386:     df = DataFrame({"data": data})
  387:     result = hash_pandas_object(df)
  388:     expected = Series(result_data, dtype=np.uint64)
  389:     tm.assert_series_equal(result, expected)
  390: 
  391: 
  392: def test_hashable_tuple_args():
  393:     # require that the elements of such tuples are themselves hashable
  394: 
  395:     df3 = DataFrame(
  396:         {
  397:             "data": [
  398:                 (
  399:                     1,
  400:                     [],
  401:                 ),
  402:                 (
  403:                     2,
  404:                     {},
  405:                 ),
  406:             ]
  407:         }
  408:     )
  409:     with pytest.raises(TypeError, match="unhashable type: 'list'"):
  410:         hash_pandas_object(df3)
  411: 
  412: 
  413: def test_hash_object_none_key():
  414:     # https://github.com/pandas-dev/pandas/issues/30887
  415:     result = pd.util.hash_pandas_object(Series(["a", "b"]), hash_key=None)
  416:     expected = Series([4578374827886788867, 17338122309987883691], dtype="uint64")
  417:     tm.assert_series_equal(result, expected)
