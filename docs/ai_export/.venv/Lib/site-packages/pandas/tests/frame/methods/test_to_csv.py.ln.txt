    1: import csv
    2: from io import StringIO
    3: import os
    4: 
    5: import numpy as np
    6: import pytest
    7: 
    8: from pandas.errors import ParserError
    9: 
   10: import pandas as pd
   11: from pandas import (
   12:     DataFrame,
   13:     Index,
   14:     MultiIndex,
   15:     NaT,
   16:     Series,
   17:     Timestamp,
   18:     date_range,
   19:     period_range,
   20:     read_csv,
   21:     to_datetime,
   22: )
   23: import pandas._testing as tm
   24: import pandas.core.common as com
   25: 
   26: from pandas.io.common import get_handle
   27: 
   28: 
   29: class TestDataFrameToCSV:
   30:     def read_csv(self, path, **kwargs):
   31:         params = {"index_col": 0}
   32:         params.update(**kwargs)
   33: 
   34:         return read_csv(path, **params)
   35: 
   36:     def test_to_csv_from_csv1(self, float_frame, datetime_frame):
   37:         with tm.ensure_clean("__tmp_to_csv_from_csv1__") as path:
   38:             float_frame.iloc[:5, float_frame.columns.get_loc("A")] = np.nan
   39: 
   40:             float_frame.to_csv(path)
   41:             float_frame.to_csv(path, columns=["A", "B"])
   42:             float_frame.to_csv(path, header=False)
   43:             float_frame.to_csv(path, index=False)
   44: 
   45:             # test roundtrip
   46:             # freq does not roundtrip
   47:             datetime_frame.index = datetime_frame.index._with_freq(None)
   48:             datetime_frame.to_csv(path)
   49:             recons = self.read_csv(path, parse_dates=True)
   50:             tm.assert_frame_equal(datetime_frame, recons)
   51: 
   52:             datetime_frame.to_csv(path, index_label="index")
   53:             recons = self.read_csv(path, index_col=None, parse_dates=True)
   54: 
   55:             assert len(recons.columns) == len(datetime_frame.columns) + 1
   56: 
   57:             # no index
   58:             datetime_frame.to_csv(path, index=False)
   59:             recons = self.read_csv(path, index_col=None, parse_dates=True)
   60:             tm.assert_almost_equal(datetime_frame.values, recons.values)
   61: 
   62:             # corner case
   63:             dm = DataFrame(
   64:                 {
   65:                     "s1": Series(range(3), index=np.arange(3, dtype=np.int64)),
   66:                     "s2": Series(range(2), index=np.arange(2, dtype=np.int64)),
   67:                 }
   68:             )
   69:             dm.to_csv(path)
   70: 
   71:             recons = self.read_csv(path)
   72:             tm.assert_frame_equal(dm, recons)
   73: 
   74:     def test_to_csv_from_csv2(self, float_frame):
   75:         with tm.ensure_clean("__tmp_to_csv_from_csv2__") as path:
   76:             # duplicate index
   77:             df = DataFrame(
   78:                 np.random.default_rng(2).standard_normal((3, 3)),
   79:                 index=["a", "a", "b"],
   80:                 columns=["x", "y", "z"],
   81:             )
   82:             df.to_csv(path)
   83:             result = self.read_csv(path)
   84:             tm.assert_frame_equal(result, df)
   85: 
   86:             midx = MultiIndex.from_tuples([("A", 1, 2), ("A", 1, 2), ("B", 1, 2)])
   87:             df = DataFrame(
   88:                 np.random.default_rng(2).standard_normal((3, 3)),
   89:                 index=midx,
   90:                 columns=["x", "y", "z"],
   91:             )
   92: 
   93:             df.to_csv(path)
   94:             result = self.read_csv(path, index_col=[0, 1, 2], parse_dates=False)
   95:             tm.assert_frame_equal(result, df, check_names=False)
   96: 
   97:             # column aliases
   98:             col_aliases = Index(["AA", "X", "Y", "Z"])
   99:             float_frame.to_csv(path, header=col_aliases)
  100: 
  101:             rs = self.read_csv(path)
  102:             xp = float_frame.copy()
  103:             xp.columns = col_aliases
  104:             tm.assert_frame_equal(xp, rs)
  105: 
  106:             msg = "Writing 4 cols but got 2 aliases"
  107:             with pytest.raises(ValueError, match=msg):
  108:                 float_frame.to_csv(path, header=["AA", "X"])
  109: 
  110:     def test_to_csv_from_csv3(self):
  111:         with tm.ensure_clean("__tmp_to_csv_from_csv3__") as path:
  112:             df1 = DataFrame(np.random.default_rng(2).standard_normal((3, 1)))
  113:             df2 = DataFrame(np.random.default_rng(2).standard_normal((3, 1)))
  114: 
  115:             df1.to_csv(path)
  116:             df2.to_csv(path, mode="a", header=False)
  117:             xp = pd.concat([df1, df2])
  118:             rs = read_csv(path, index_col=0)
  119:             rs.columns = [int(label) for label in rs.columns]
  120:             xp.columns = [int(label) for label in xp.columns]
  121:             tm.assert_frame_equal(xp, rs)
  122: 
  123:     def test_to_csv_from_csv4(self):
  124:         with tm.ensure_clean("__tmp_to_csv_from_csv4__") as path:
  125:             # GH 10833 (TimedeltaIndex formatting)
  126:             dt = pd.Timedelta(seconds=1)
  127:             df = DataFrame(
  128:                 {"dt_data": [i * dt for i in range(3)]},
  129:                 index=Index([i * dt for i in range(3)], name="dt_index"),
  130:             )
  131:             df.to_csv(path)
  132: 
  133:             result = read_csv(path, index_col="dt_index")
  134:             result.index = pd.to_timedelta(result.index)
  135:             result["dt_data"] = pd.to_timedelta(result["dt_data"])
  136: 
  137:             tm.assert_frame_equal(df, result, check_index_type=True)
  138: 
  139:     def test_to_csv_from_csv5(self, timezone_frame):
  140:         # tz, 8260
  141:         with tm.ensure_clean("__tmp_to_csv_from_csv5__") as path:
  142:             timezone_frame.to_csv(path)
  143:             result = read_csv(path, index_col=0, parse_dates=["A"])
  144: 
  145:             converter = (
  146:                 lambda c: to_datetime(result[c])
  147:                 .dt.tz_convert("UTC")
  148:                 .dt.tz_convert(timezone_frame[c].dt.tz)
  149:             )
  150:             result["B"] = converter("B")
  151:             result["C"] = converter("C")
  152:             tm.assert_frame_equal(result, timezone_frame)
  153: 
  154:     def test_to_csv_cols_reordering(self):
  155:         # GH3454
  156:         chunksize = 5
  157:         N = int(chunksize * 2.5)
  158: 
  159:         df = DataFrame(
  160:             np.ones((N, 3)),
  161:             index=Index([f"i-{i}" for i in range(N)], name="a"),
  162:             columns=Index([f"i-{i}" for i in range(3)], name="a"),
  163:         )
  164:         cs = df.columns
  165:         cols = [cs[2], cs[0]]
  166: 
  167:         with tm.ensure_clean() as path:
  168:             df.to_csv(path, columns=cols, chunksize=chunksize)
  169:             rs_c = read_csv(path, index_col=0)
  170: 
  171:         tm.assert_frame_equal(df[cols], rs_c, check_names=False)
  172: 
  173:     @pytest.mark.parametrize("cols", [None, ["b", "a"]])
  174:     def test_to_csv_new_dupe_cols(self, cols):
  175:         chunksize = 5
  176:         N = int(chunksize * 2.5)
  177: 
  178:         # dupe cols
  179:         df = DataFrame(
  180:             np.ones((N, 3)),
  181:             index=Index([f"i-{i}" for i in range(N)], name="a"),
  182:             columns=["a", "a", "b"],
  183:         )
  184:         with tm.ensure_clean() as path:
  185:             df.to_csv(path, columns=cols, chunksize=chunksize)
  186:             rs_c = read_csv(path, index_col=0)
  187: 
  188:             # we wrote them in a different order
  189:             # so compare them in that order
  190:             if cols is not None:
  191:                 if df.columns.is_unique:
  192:                     rs_c.columns = cols
  193:                 else:
  194:                     indexer, missing = df.columns.get_indexer_non_unique(cols)
  195:                     rs_c.columns = df.columns.take(indexer)
  196: 
  197:                 for c in cols:
  198:                     obj_df = df[c]
  199:                     obj_rs = rs_c[c]
  200:                     if isinstance(obj_df, Series):
  201:                         tm.assert_series_equal(obj_df, obj_rs)
  202:                     else:
  203:                         tm.assert_frame_equal(obj_df, obj_rs, check_names=False)
  204: 
  205:             # wrote in the same order
  206:             else:
  207:                 rs_c.columns = df.columns
  208:                 tm.assert_frame_equal(df, rs_c, check_names=False)
  209: 
  210:     @pytest.mark.slow
  211:     def test_to_csv_dtnat(self):
  212:         # GH3437
  213:         def make_dtnat_arr(n, nnat=None):
  214:             if nnat is None:
  215:                 nnat = int(n * 0.1)  # 10%
  216:             s = list(date_range("2000", freq="5min", periods=n))
  217:             if nnat:
  218:                 for i in np.random.default_rng(2).integers(0, len(s), nnat):
  219:                     s[i] = NaT
  220:                 i = np.random.default_rng(2).integers(100)
  221:                 s[-i] = NaT
  222:                 s[i] = NaT
  223:             return s
  224: 
  225:         chunksize = 1000
  226:         s1 = make_dtnat_arr(chunksize + 5)
  227:         s2 = make_dtnat_arr(chunksize + 5, 0)
  228: 
  229:         with tm.ensure_clean("1.csv") as pth:
  230:             df = DataFrame({"a": s1, "b": s2})
  231:             df.to_csv(pth, chunksize=chunksize)
  232: 
  233:             recons = self.read_csv(pth).apply(to_datetime)
  234:             tm.assert_frame_equal(df, recons, check_names=False)
  235: 
  236:     def _return_result_expected(
  237:         self,
  238:         df,
  239:         chunksize,
  240:         r_dtype=None,
  241:         c_dtype=None,
  242:         rnlvl=None,
  243:         cnlvl=None,
  244:         dupe_col=False,
  245:     ):
  246:         kwargs = {"parse_dates": False}
  247:         if cnlvl:
  248:             if rnlvl is not None:
  249:                 kwargs["index_col"] = list(range(rnlvl))
  250:             kwargs["header"] = list(range(cnlvl))
  251: 
  252:             with tm.ensure_clean("__tmp_to_csv_moar__") as path:
  253:                 df.to_csv(path, encoding="utf8", chunksize=chunksize)
  254:                 recons = self.read_csv(path, **kwargs)
  255:         else:
  256:             kwargs["header"] = 0
  257: 
  258:             with tm.ensure_clean("__tmp_to_csv_moar__") as path:
  259:                 df.to_csv(path, encoding="utf8", chunksize=chunksize)
  260:                 recons = self.read_csv(path, **kwargs)
  261: 
  262:         def _to_uni(x):
  263:             if not isinstance(x, str):
  264:                 return x.decode("utf8")
  265:             return x
  266: 
  267:         if dupe_col:
  268:             # read_Csv disambiguates the columns by
  269:             # labeling them dupe.1,dupe.2, etc'. monkey patch columns
  270:             recons.columns = df.columns
  271:         if rnlvl and not cnlvl:
  272:             delta_lvl = [recons.iloc[:, i].values for i in range(rnlvl - 1)]
  273:             ix = MultiIndex.from_arrays([list(recons.index)] + delta_lvl)
  274:             recons.index = ix
  275:             recons = recons.iloc[:, rnlvl - 1 :]
  276: 
  277:         type_map = {"i": "i", "f": "f", "s": "O", "u": "O", "dt": "O", "p": "O"}
  278:         if r_dtype:
  279:             if r_dtype == "u":  # unicode
  280:                 r_dtype = "O"
  281:                 recons.index = np.array(
  282:                     [_to_uni(label) for label in recons.index], dtype=r_dtype
  283:                 )
  284:                 df.index = np.array(
  285:                     [_to_uni(label) for label in df.index], dtype=r_dtype
  286:                 )
  287:             elif r_dtype == "dt":  # unicode
  288:                 r_dtype = "O"
  289:                 recons.index = np.array(
  290:                     [Timestamp(label) for label in recons.index], dtype=r_dtype
  291:                 )
  292:                 df.index = np.array(
  293:                     [Timestamp(label) for label in df.index], dtype=r_dtype
  294:                 )
  295:             elif r_dtype == "p":
  296:                 r_dtype = "O"
  297:                 idx_list = to_datetime(recons.index)
  298:                 recons.index = np.array(
  299:                     [Timestamp(label) for label in idx_list], dtype=r_dtype
  300:                 )
  301:                 df.index = np.array(
  302:                     list(map(Timestamp, df.index.to_timestamp())), dtype=r_dtype
  303:                 )
  304:             else:
  305:                 r_dtype = type_map.get(r_dtype)
  306:                 recons.index = np.array(recons.index, dtype=r_dtype)
  307:                 df.index = np.array(df.index, dtype=r_dtype)
  308:         if c_dtype:
  309:             if c_dtype == "u":
  310:                 c_dtype = "O"
  311:                 recons.columns = np.array(
  312:                     [_to_uni(label) for label in recons.columns], dtype=c_dtype
  313:                 )
  314:                 df.columns = np.array(
  315:                     [_to_uni(label) for label in df.columns], dtype=c_dtype
  316:                 )
  317:             elif c_dtype == "dt":
  318:                 c_dtype = "O"
  319:                 recons.columns = np.array(
  320:                     [Timestamp(label) for label in recons.columns], dtype=c_dtype
  321:                 )
  322:                 df.columns = np.array(
  323:                     [Timestamp(label) for label in df.columns], dtype=c_dtype
  324:                 )
  325:             elif c_dtype == "p":
  326:                 c_dtype = "O"
  327:                 col_list = to_datetime(recons.columns)
  328:                 recons.columns = np.array(
  329:                     [Timestamp(label) for label in col_list], dtype=c_dtype
  330:                 )
  331:                 col_list = df.columns.to_timestamp()
  332:                 df.columns = np.array(
  333:                     [Timestamp(label) for label in col_list], dtype=c_dtype
  334:                 )
  335:             else:
  336:                 c_dtype = type_map.get(c_dtype)
  337:                 recons.columns = np.array(recons.columns, dtype=c_dtype)
  338:                 df.columns = np.array(df.columns, dtype=c_dtype)
  339:         return df, recons
  340: 
  341:     @pytest.mark.slow
  342:     @pytest.mark.parametrize(
  343:         "nrows", [2, 10, 99, 100, 101, 102, 198, 199, 200, 201, 202, 249, 250, 251]
  344:     )
  345:     def test_to_csv_nrows(self, nrows):
  346:         df = DataFrame(
  347:             np.ones((nrows, 4)),
  348:             index=date_range("2020-01-01", periods=nrows),
  349:             columns=Index(list("abcd"), dtype=object),
  350:         )
  351:         result, expected = self._return_result_expected(df, 1000, "dt", "s")
  352:         tm.assert_frame_equal(result, expected, check_names=False)
  353: 
  354:     @pytest.mark.slow
  355:     @pytest.mark.parametrize(
  356:         "nrows", [2, 10, 99, 100, 101, 102, 198, 199, 200, 201, 202, 249, 250, 251]
  357:     )
  358:     @pytest.mark.parametrize(
  359:         "r_idx_type, c_idx_type", [("i", "i"), ("s", "s"), ("s", "dt"), ("p", "p")]
  360:     )
  361:     @pytest.mark.parametrize("ncols", [1, 2, 3, 4])
  362:     @pytest.mark.filterwarnings(r"ignore:PeriodDtype\[B\] is deprecated:FutureWarning")
  363:     def test_to_csv_idx_types(self, nrows, r_idx_type, c_idx_type, ncols):
  364:         axes = {
  365:             "i": lambda n: Index(np.arange(n), dtype=np.int64),
  366:             "s": lambda n: Index([f"{i}_{chr(i)}" for i in range(97, 97 + n)]),
  367:             "dt": lambda n: date_range("2020-01-01", periods=n),
  368:             "p": lambda n: period_range("2020-01-01", periods=n, freq="D"),
  369:         }
  370:         df = DataFrame(
  371:             np.ones((nrows, ncols)),
  372:             index=axes[r_idx_type](nrows),
  373:             columns=axes[c_idx_type](ncols),
  374:         )
  375:         result, expected = self._return_result_expected(
  376:             df,
  377:             1000,
  378:             r_idx_type,
  379:             c_idx_type,
  380:         )
  381:         tm.assert_frame_equal(result, expected, check_names=False)
  382: 
  383:     @pytest.mark.slow
  384:     @pytest.mark.parametrize(
  385:         "nrows", [10, 98, 99, 100, 101, 102, 198, 199, 200, 201, 202, 249, 250, 251]
  386:     )
  387:     @pytest.mark.parametrize("ncols", [1, 2, 3, 4])
  388:     def test_to_csv_idx_ncols(self, nrows, ncols):
  389:         df = DataFrame(
  390:             np.ones((nrows, ncols)),
  391:             index=Index([f"i-{i}" for i in range(nrows)], name="a"),
  392:             columns=Index([f"i-{i}" for i in range(ncols)], name="a"),
  393:         )
  394:         result, expected = self._return_result_expected(df, 1000)
  395:         tm.assert_frame_equal(result, expected, check_names=False)
  396: 
  397:     @pytest.mark.slow
  398:     @pytest.mark.parametrize("nrows", [10, 98, 99, 100, 101, 102])
  399:     def test_to_csv_dup_cols(self, nrows):
  400:         df = DataFrame(
  401:             np.ones((nrows, 3)),
  402:             index=Index([f"i-{i}" for i in range(nrows)], name="a"),
  403:             columns=Index([f"i-{i}" for i in range(3)], name="a"),
  404:         )
  405: 
  406:         cols = list(df.columns)
  407:         cols[:2] = ["dupe", "dupe"]
  408:         cols[-2:] = ["dupe", "dupe"]
  409:         ix = list(df.index)
  410:         ix[:2] = ["rdupe", "rdupe"]
  411:         ix[-2:] = ["rdupe", "rdupe"]
  412:         df.index = ix
  413:         df.columns = cols
  414:         result, expected = self._return_result_expected(df, 1000, dupe_col=True)
  415:         tm.assert_frame_equal(result, expected, check_names=False)
  416: 
  417:     @pytest.mark.slow
  418:     def test_to_csv_empty(self):
  419:         df = DataFrame(index=np.arange(10, dtype=np.int64))
  420:         result, expected = self._return_result_expected(df, 1000)
  421:         tm.assert_frame_equal(result, expected, check_column_type=False)
  422: 
  423:     @pytest.mark.slow
  424:     def test_to_csv_chunksize(self):
  425:         chunksize = 1000
  426:         rows = chunksize // 2 + 1
  427:         df = DataFrame(
  428:             np.ones((rows, 2)),
  429:             columns=Index(list("ab"), dtype=object),
  430:             index=MultiIndex.from_arrays([range(rows) for _ in range(2)]),
  431:         )
  432:         result, expected = self._return_result_expected(df, chunksize, rnlvl=2)
  433:         tm.assert_frame_equal(result, expected, check_names=False)
  434: 
  435:     @pytest.mark.slow
  436:     @pytest.mark.parametrize(
  437:         "nrows", [2, 10, 99, 100, 101, 102, 198, 199, 200, 201, 202, 249, 250, 251]
  438:     )
  439:     @pytest.mark.parametrize("ncols", [2, 3, 4])
  440:     @pytest.mark.parametrize(
  441:         "df_params, func_params",
  442:         [
  443:             [{"r_idx_nlevels": 2}, {"rnlvl": 2}],
  444:             [{"c_idx_nlevels": 2}, {"cnlvl": 2}],
  445:             [{"r_idx_nlevels": 2, "c_idx_nlevels": 2}, {"rnlvl": 2, "cnlvl": 2}],
  446:         ],
  447:     )
  448:     def test_to_csv_params(self, nrows, df_params, func_params, ncols):
  449:         if df_params.get("r_idx_nlevels"):
  450:             index = MultiIndex.from_arrays(
  451:                 [f"i-{i}" for i in range(nrows)]
  452:                 for _ in range(df_params["r_idx_nlevels"])
  453:             )
  454:         else:
  455:             index = None
  456: 
  457:         if df_params.get("c_idx_nlevels"):
  458:             columns = MultiIndex.from_arrays(
  459:                 [f"i-{i}" for i in range(ncols)]
  460:                 for _ in range(df_params["c_idx_nlevels"])
  461:             )
  462:         else:
  463:             columns = Index([f"i-{i}" for i in range(ncols)], dtype=object)
  464:         df = DataFrame(np.ones((nrows, ncols)), index=index, columns=columns)
  465:         result, expected = self._return_result_expected(df, 1000, **func_params)
  466:         tm.assert_frame_equal(result, expected, check_names=False)
  467: 
  468:     def test_to_csv_from_csv_w_some_infs(self, float_frame):
  469:         # test roundtrip with inf, -inf, nan, as full columns and mix
  470:         float_frame["G"] = np.nan
  471:         f = lambda x: [np.inf, np.nan][np.random.default_rng(2).random() < 0.5]
  472:         float_frame["h"] = float_frame.index.map(f)
  473: 
  474:         with tm.ensure_clean() as path:
  475:             float_frame.to_csv(path)
  476:             recons = self.read_csv(path)
  477: 
  478:             tm.assert_frame_equal(float_frame, recons)
  479:             tm.assert_frame_equal(np.isinf(float_frame), np.isinf(recons))
  480: 
  481:     def test_to_csv_from_csv_w_all_infs(self, float_frame):
  482:         # test roundtrip with inf, -inf, nan, as full columns and mix
  483:         float_frame["E"] = np.inf
  484:         float_frame["F"] = -np.inf
  485: 
  486:         with tm.ensure_clean() as path:
  487:             float_frame.to_csv(path)
  488:             recons = self.read_csv(path)
  489: 
  490:             tm.assert_frame_equal(float_frame, recons)
  491:             tm.assert_frame_equal(np.isinf(float_frame), np.isinf(recons))
  492: 
  493:     def test_to_csv_no_index(self):
  494:         # GH 3624, after appending columns, to_csv fails
  495:         with tm.ensure_clean("__tmp_to_csv_no_index__") as path:
  496:             df = DataFrame({"c1": [1, 2, 3], "c2": [4, 5, 6]})
  497:             df.to_csv(path, index=False)
  498:             result = read_csv(path)
  499:             tm.assert_frame_equal(df, result)
  500:             df["c3"] = Series([7, 8, 9], dtype="int64")
  501:             df.to_csv(path, index=False)
  502:             result = read_csv(path)
  503:             tm.assert_frame_equal(df, result)
  504: 
  505:     def test_to_csv_with_mix_columns(self):
  506:         # gh-11637: incorrect output when a mix of integer and string column
  507:         # names passed as columns parameter in to_csv
  508: 
  509:         df = DataFrame({0: ["a", "b", "c"], 1: ["aa", "bb", "cc"]})
  510:         df["test"] = "txt"
  511:         assert df.to_csv() == df.to_csv(columns=[0, 1, "test"])
  512: 
  513:     def test_to_csv_headers(self):
  514:         # GH6186, the presence or absence of `index` incorrectly
  515:         # causes to_csv to have different header semantics.
  516:         from_df = DataFrame([[1, 2], [3, 4]], columns=["A", "B"])
  517:         to_df = DataFrame([[1, 2], [3, 4]], columns=["X", "Y"])
  518:         with tm.ensure_clean("__tmp_to_csv_headers__") as path:
  519:             from_df.to_csv(path, header=["X", "Y"])
  520:             recons = self.read_csv(path)
  521: 
  522:             tm.assert_frame_equal(to_df, recons)
  523: 
  524:             from_df.to_csv(path, index=False, header=["X", "Y"])
  525:             recons = self.read_csv(path)
  526: 
  527:             return_value = recons.reset_index(inplace=True)
  528:             assert return_value is None
  529:             tm.assert_frame_equal(to_df, recons)
  530: 
  531:     def test_to_csv_multiindex(self, float_frame, datetime_frame):
  532:         frame = float_frame
  533:         old_index = frame.index
  534:         arrays = np.arange(len(old_index) * 2, dtype=np.int64).reshape(2, -1)
  535:         new_index = MultiIndex.from_arrays(arrays, names=["first", "second"])
  536:         frame.index = new_index
  537: 
  538:         with tm.ensure_clean("__tmp_to_csv_multiindex__") as path:
  539:             frame.to_csv(path, header=False)
  540:             frame.to_csv(path, columns=["A", "B"])
  541: 
  542:             # round trip
  543:             frame.to_csv(path)
  544: 
  545:             df = self.read_csv(path, index_col=[0, 1], parse_dates=False)
  546: 
  547:             # TODO to_csv drops column name
  548:             tm.assert_frame_equal(frame, df, check_names=False)
  549:             assert frame.index.names == df.index.names
  550: 
  551:             # needed if setUp becomes a class method
  552:             float_frame.index = old_index
  553: 
  554:             # try multiindex with dates
  555:             tsframe = datetime_frame
  556:             old_index = tsframe.index
  557:             new_index = [old_index, np.arange(len(old_index), dtype=np.int64)]
  558:             tsframe.index = MultiIndex.from_arrays(new_index)
  559: 
  560:             tsframe.to_csv(path, index_label=["time", "foo"])
  561:             with tm.assert_produces_warning(
  562:                 UserWarning, match="Could not infer format"
  563:             ):
  564:                 recons = self.read_csv(path, index_col=[0, 1], parse_dates=True)
  565: 
  566:             # TODO to_csv drops column name
  567:             tm.assert_frame_equal(tsframe, recons, check_names=False)
  568: 
  569:             # do not load index
  570:             tsframe.to_csv(path)
  571:             recons = self.read_csv(path, index_col=None)
  572:             assert len(recons.columns) == len(tsframe.columns) + 2
  573: 
  574:             # no index
  575:             tsframe.to_csv(path, index=False)
  576:             recons = self.read_csv(path, index_col=None)
  577:             tm.assert_almost_equal(recons.values, datetime_frame.values)
  578: 
  579:             # needed if setUp becomes class method
  580:             datetime_frame.index = old_index
  581: 
  582:         with tm.ensure_clean("__tmp_to_csv_multiindex__") as path:
  583:             # GH3571, GH1651, GH3141
  584: 
  585:             def _make_frame(names=None):
  586:                 if names is True:
  587:                     names = ["first", "second"]
  588:                 return DataFrame(
  589:                     np.random.default_rng(2).integers(0, 10, size=(3, 3)),
  590:                     columns=MultiIndex.from_tuples(
  591:                         [("bah", "foo"), ("bah", "bar"), ("ban", "baz")], names=names
  592:                     ),
  593:                     dtype="int64",
  594:                 )
  595: 
  596:             # column & index are multi-index
  597:             df = DataFrame(
  598:                 np.ones((5, 3)),
  599:                 columns=MultiIndex.from_arrays(
  600:                     [[f"i-{i}" for i in range(3)] for _ in range(4)], names=list("abcd")
  601:                 ),
  602:                 index=MultiIndex.from_arrays(
  603:                     [[f"i-{i}" for i in range(5)] for _ in range(2)], names=list("ab")
  604:                 ),
  605:             )
  606:             df.to_csv(path)
  607:             result = read_csv(path, header=[0, 1, 2, 3], index_col=[0, 1])
  608:             tm.assert_frame_equal(df, result)
  609: 
  610:             # column is mi
  611:             df = DataFrame(
  612:                 np.ones((5, 3)),
  613:                 columns=MultiIndex.from_arrays(
  614:                     [[f"i-{i}" for i in range(3)] for _ in range(4)], names=list("abcd")
  615:                 ),
  616:             )
  617:             df.to_csv(path)
  618:             result = read_csv(path, header=[0, 1, 2, 3], index_col=0)
  619:             tm.assert_frame_equal(df, result)
  620: 
  621:             # dup column names?
  622:             df = DataFrame(
  623:                 np.ones((5, 3)),
  624:                 columns=MultiIndex.from_arrays(
  625:                     [[f"i-{i}" for i in range(3)] for _ in range(4)], names=list("abcd")
  626:                 ),
  627:                 index=MultiIndex.from_arrays(
  628:                     [[f"i-{i}" for i in range(5)] for _ in range(3)], names=list("abc")
  629:                 ),
  630:             )
  631:             df.to_csv(path)
  632:             result = read_csv(path, header=[0, 1, 2, 3], index_col=[0, 1, 2])
  633:             tm.assert_frame_equal(df, result)
  634: 
  635:             # writing with no index
  636:             df = _make_frame()
  637:             df.to_csv(path, index=False)
  638:             result = read_csv(path, header=[0, 1])
  639:             tm.assert_frame_equal(df, result)
  640: 
  641:             # we lose the names here
  642:             df = _make_frame(True)
  643:             df.to_csv(path, index=False)
  644:             result = read_csv(path, header=[0, 1])
  645:             assert com.all_none(*result.columns.names)
  646:             result.columns.names = df.columns.names
  647:             tm.assert_frame_equal(df, result)
  648: 
  649:             # whatsnew example
  650:             df = _make_frame()
  651:             df.to_csv(path)
  652:             result = read_csv(path, header=[0, 1], index_col=[0])
  653:             tm.assert_frame_equal(df, result)
  654: 
  655:             df = _make_frame(True)
  656:             df.to_csv(path)
  657:             result = read_csv(path, header=[0, 1], index_col=[0])
  658:             tm.assert_frame_equal(df, result)
  659: 
  660:             # invalid options
  661:             df = _make_frame(True)
  662:             df.to_csv(path)
  663: 
  664:             for i in [6, 7]:
  665:                 msg = f"len of {i}, but only 5 lines in file"
  666:                 with pytest.raises(ParserError, match=msg):
  667:                     read_csv(path, header=list(range(i)), index_col=0)
  668: 
  669:             # write with cols
  670:             msg = "cannot specify cols with a MultiIndex"
  671:             with pytest.raises(TypeError, match=msg):
  672:                 df.to_csv(path, columns=["foo", "bar"])
  673: 
  674:         with tm.ensure_clean("__tmp_to_csv_multiindex__") as path:
  675:             # empty
  676:             tsframe[:0].to_csv(path)
  677:             recons = self.read_csv(path)
  678: 
  679:             exp = tsframe[:0]
  680:             exp.index = []
  681: 
  682:             tm.assert_index_equal(recons.columns, exp.columns)
  683:             assert len(recons) == 0
  684: 
  685:     def test_to_csv_interval_index(self, using_infer_string):
  686:         # GH 28210
  687:         df = DataFrame({"A": list("abc"), "B": range(3)}, index=pd.interval_range(0, 3))
  688: 
  689:         with tm.ensure_clean("__tmp_to_csv_interval_index__.csv") as path:
  690:             df.to_csv(path)
  691:             result = self.read_csv(path, index_col=0)
  692: 
  693:             # can't roundtrip intervalindex via read_csv so check string repr (GH 23595)
  694:             expected = df.copy()
  695:             if using_infer_string:
  696:                 expected.index = expected.index.astype("string[pyarrow_numpy]")
  697:             else:
  698:                 expected.index = expected.index.astype(str)
  699: 
  700:             tm.assert_frame_equal(result, expected)
  701: 
  702:     def test_to_csv_float32_nanrep(self):
  703:         df = DataFrame(
  704:             np.random.default_rng(2).standard_normal((1, 4)).astype(np.float32)
  705:         )
  706:         df[1] = np.nan
  707: 
  708:         with tm.ensure_clean("__tmp_to_csv_float32_nanrep__.csv") as path:
  709:             df.to_csv(path, na_rep=999)
  710: 
  711:             with open(path, encoding="utf-8") as f:
  712:                 lines = f.readlines()
  713:                 assert lines[1].split(",")[2] == "999"
  714: 
  715:     def test_to_csv_withcommas(self):
  716:         # Commas inside fields should be correctly escaped when saving as CSV.
  717:         df = DataFrame({"A": [1, 2, 3], "B": ["5,6", "7,8", "9,0"]})
  718: 
  719:         with tm.ensure_clean("__tmp_to_csv_withcommas__.csv") as path:
  720:             df.to_csv(path)
  721:             df2 = self.read_csv(path)
  722:             tm.assert_frame_equal(df2, df)
  723: 
  724:     def test_to_csv_mixed(self):
  725:         def create_cols(name):
  726:             return [f"{name}{i:03d}" for i in range(5)]
  727: 
  728:         df_float = DataFrame(
  729:             np.random.default_rng(2).standard_normal((100, 5)),
  730:             dtype="float64",
  731:             columns=create_cols("float"),
  732:         )
  733:         df_int = DataFrame(
  734:             np.random.default_rng(2).standard_normal((100, 5)).astype("int64"),
  735:             dtype="int64",
  736:             columns=create_cols("int"),
  737:         )
  738:         df_bool = DataFrame(True, index=df_float.index, columns=create_cols("bool"))
  739:         df_object = DataFrame(
  740:             "foo", index=df_float.index, columns=create_cols("object")
  741:         )
  742:         df_dt = DataFrame(
  743:             Timestamp("20010101").as_unit("ns"),
  744:             index=df_float.index,
  745:             columns=create_cols("date"),
  746:         )
  747: 
  748:         # add in some nans
  749:         df_float.iloc[30:50, 1:3] = np.nan
  750:         df_dt.iloc[30:50, 1:3] = np.nan
  751: 
  752:         df = pd.concat([df_float, df_int, df_bool, df_object, df_dt], axis=1)
  753: 
  754:         # dtype
  755:         dtypes = {}
  756:         for n, dtype in [
  757:             ("float", np.float64),
  758:             ("int", np.int64),
  759:             ("bool", np.bool_),
  760:             ("object", object),
  761:         ]:
  762:             for c in create_cols(n):
  763:                 dtypes[c] = dtype
  764: 
  765:         with tm.ensure_clean() as filename:
  766:             df.to_csv(filename)
  767:             rs = read_csv(
  768:                 filename, index_col=0, dtype=dtypes, parse_dates=create_cols("date")
  769:             )
  770:             tm.assert_frame_equal(rs, df)
  771: 
  772:     def test_to_csv_dups_cols(self):
  773:         df = DataFrame(
  774:             np.random.default_rng(2).standard_normal((1000, 30)),
  775:             columns=list(range(15)) + list(range(15)),
  776:             dtype="float64",
  777:         )
  778: 
  779:         with tm.ensure_clean() as filename:
  780:             df.to_csv(filename)  # single dtype, fine
  781:             result = read_csv(filename, index_col=0)
  782:             result.columns = df.columns
  783:             tm.assert_frame_equal(result, df)
  784: 
  785:         df_float = DataFrame(
  786:             np.random.default_rng(2).standard_normal((1000, 3)), dtype="float64"
  787:         )
  788:         df_int = DataFrame(np.random.default_rng(2).standard_normal((1000, 3))).astype(
  789:             "int64"
  790:         )
  791:         df_bool = DataFrame(True, index=df_float.index, columns=range(3))
  792:         df_object = DataFrame("foo", index=df_float.index, columns=range(3))
  793:         df_dt = DataFrame(
  794:             Timestamp("20010101").as_unit("ns"), index=df_float.index, columns=range(3)
  795:         )
  796:         df = pd.concat(
  797:             [df_float, df_int, df_bool, df_object, df_dt], axis=1, ignore_index=True
  798:         )
  799: 
  800:         df.columns = [0, 1, 2] * 5
  801: 
  802:         with tm.ensure_clean() as filename:
  803:             df.to_csv(filename)
  804:             result = read_csv(filename, index_col=0)
  805: 
  806:             # date cols
  807:             for i in ["0.4", "1.4", "2.4"]:
  808:                 result[i] = to_datetime(result[i])
  809: 
  810:             result.columns = df.columns
  811:             tm.assert_frame_equal(result, df)
  812: 
  813:     def test_to_csv_dups_cols2(self):
  814:         # GH3457
  815:         df = DataFrame(
  816:             np.ones((5, 3)),
  817:             index=Index([f"i-{i}" for i in range(5)], name="foo"),
  818:             columns=Index(["a", "a", "b"], dtype=object),
  819:         )
  820: 
  821:         with tm.ensure_clean() as filename:
  822:             df.to_csv(filename)
  823: 
  824:             # read_csv will rename the dups columns
  825:             result = read_csv(filename, index_col=0)
  826:             result = result.rename(columns={"a.1": "a"})
  827:             tm.assert_frame_equal(result, df)
  828: 
  829:     @pytest.mark.parametrize("chunksize", [10000, 50000, 100000])
  830:     def test_to_csv_chunking(self, chunksize):
  831:         aa = DataFrame({"A": range(100000)})
  832:         aa["B"] = aa.A + 1.0
  833:         aa["C"] = aa.A + 2.0
  834:         aa["D"] = aa.A + 3.0
  835: 
  836:         with tm.ensure_clean() as filename:
  837:             aa.to_csv(filename, chunksize=chunksize)
  838:             rs = read_csv(filename, index_col=0)
  839:             tm.assert_frame_equal(rs, aa)
  840: 
  841:     @pytest.mark.slow
  842:     def test_to_csv_wide_frame_formatting(self, monkeypatch):
  843:         # Issue #8621
  844:         chunksize = 100
  845:         df = DataFrame(
  846:             np.random.default_rng(2).standard_normal((1, chunksize + 10)),
  847:             columns=None,
  848:             index=None,
  849:         )
  850:         with tm.ensure_clean() as filename:
  851:             with monkeypatch.context() as m:
  852:                 m.setattr("pandas.io.formats.csvs._DEFAULT_CHUNKSIZE_CELLS", chunksize)
  853:                 df.to_csv(filename, header=False, index=False)
  854:             rs = read_csv(filename, header=None)
  855:         tm.assert_frame_equal(rs, df)
  856: 
  857:     def test_to_csv_bug(self):
  858:         f1 = StringIO("a,1.0\nb,2.0")
  859:         df = self.read_csv(f1, header=None)
  860:         newdf = DataFrame({"t": df[df.columns[0]]})
  861: 
  862:         with tm.ensure_clean() as path:
  863:             newdf.to_csv(path)
  864: 
  865:             recons = read_csv(path, index_col=0)
  866:             # don't check_names as t != 1
  867:             tm.assert_frame_equal(recons, newdf, check_names=False)
  868: 
  869:     def test_to_csv_unicode(self):
  870:         df = DataFrame({"c/\u03c3": [1, 2, 3]})
  871:         with tm.ensure_clean() as path:
  872:             df.to_csv(path, encoding="UTF-8")
  873:             df2 = read_csv(path, index_col=0, encoding="UTF-8")
  874:             tm.assert_frame_equal(df, df2)
  875: 
  876:             df.to_csv(path, encoding="UTF-8", index=False)
  877:             df2 = read_csv(path, index_col=None, encoding="UTF-8")
  878:             tm.assert_frame_equal(df, df2)
  879: 
  880:     def test_to_csv_unicode_index_col(self):
  881:         buf = StringIO("")
  882:         df = DataFrame(
  883:             [["\u05d0", "d2", "d3", "d4"], ["a1", "a2", "a3", "a4"]],
  884:             columns=["\u05d0", "\u05d1", "\u05d2", "\u05d3"],
  885:             index=["\u05d0", "\u05d1"],
  886:         )
  887: 
  888:         df.to_csv(buf, encoding="UTF-8")
  889:         buf.seek(0)
  890: 
  891:         df2 = read_csv(buf, index_col=0, encoding="UTF-8")
  892:         tm.assert_frame_equal(df, df2)
  893: 
  894:     def test_to_csv_stringio(self, float_frame):
  895:         buf = StringIO()
  896:         float_frame.to_csv(buf)
  897:         buf.seek(0)
  898:         recons = read_csv(buf, index_col=0)
  899:         tm.assert_frame_equal(recons, float_frame)
  900: 
  901:     def test_to_csv_float_format(self):
  902:         df = DataFrame(
  903:             [[0.123456, 0.234567, 0.567567], [12.32112, 123123.2, 321321.2]],
  904:             index=["A", "B"],
  905:             columns=["X", "Y", "Z"],
  906:         )
  907: 
  908:         with tm.ensure_clean() as filename:
  909:             df.to_csv(filename, float_format="%.2f")
  910: 
  911:             rs = read_csv(filename, index_col=0)
  912:             xp = DataFrame(
  913:                 [[0.12, 0.23, 0.57], [12.32, 123123.20, 321321.20]],
  914:                 index=["A", "B"],
  915:                 columns=["X", "Y", "Z"],
  916:             )
  917:             tm.assert_frame_equal(rs, xp)
  918: 
  919:     def test_to_csv_float_format_over_decimal(self):
  920:         # GH#47436
  921:         df = DataFrame({"a": [0.5, 1.0]})
  922:         result = df.to_csv(
  923:             decimal=",",
  924:             float_format=lambda x: np.format_float_positional(x, trim="-"),
  925:             index=False,
  926:         )
  927:         expected_rows = ["a", "0.5", "1"]
  928:         expected = tm.convert_rows_list_to_csv_str(expected_rows)
  929:         assert result == expected
  930: 
  931:     def test_to_csv_unicodewriter_quoting(self):
  932:         df = DataFrame({"A": [1, 2, 3], "B": ["foo", "bar", "baz"]})
  933: 
  934:         buf = StringIO()
  935:         df.to_csv(buf, index=False, quoting=csv.QUOTE_NONNUMERIC, encoding="utf-8")
  936: 
  937:         result = buf.getvalue()
  938:         expected_rows = ['"A","B"', '1,"foo"', '2,"bar"', '3,"baz"']
  939:         expected = tm.convert_rows_list_to_csv_str(expected_rows)
  940:         assert result == expected
  941: 
  942:     @pytest.mark.parametrize("encoding", [None, "utf-8"])
  943:     def test_to_csv_quote_none(self, encoding):
  944:         # GH4328
  945:         df = DataFrame({"A": ["hello", '{"hello"}']})
  946:         buf = StringIO()
  947:         df.to_csv(buf, quoting=csv.QUOTE_NONE, encoding=encoding, index=False)
  948: 
  949:         result = buf.getvalue()
  950:         expected_rows = ["A", "hello", '{"hello"}']
  951:         expected = tm.convert_rows_list_to_csv_str(expected_rows)
  952:         assert result == expected
  953: 
  954:     def test_to_csv_index_no_leading_comma(self):
  955:         df = DataFrame({"A": [1, 2, 3], "B": [4, 5, 6]}, index=["one", "two", "three"])
  956: 
  957:         buf = StringIO()
  958:         df.to_csv(buf, index_label=False)
  959: 
  960:         expected_rows = ["A,B", "one,1,4", "two,2,5", "three,3,6"]
  961:         expected = tm.convert_rows_list_to_csv_str(expected_rows)
  962:         assert buf.getvalue() == expected
  963: 
  964:     def test_to_csv_lineterminators(self):
  965:         # see gh-20353
  966:         df = DataFrame({"A": [1, 2, 3], "B": [4, 5, 6]}, index=["one", "two", "three"])
  967: 
  968:         with tm.ensure_clean() as path:
  969:             # case 1: CRLF as line terminator
  970:             df.to_csv(path, lineterminator="\r\n")
  971:             expected = b",A,B\r\none,1,4\r\ntwo,2,5\r\nthree,3,6\r\n"
  972: 
  973:             with open(path, mode="rb") as f:
  974:                 assert f.read() == expected
  975: 
  976:         with tm.ensure_clean() as path:
  977:             # case 2: LF as line terminator
  978:             df.to_csv(path, lineterminator="\n")
  979:             expected = b",A,B\none,1,4\ntwo,2,5\nthree,3,6\n"
  980: 
  981:             with open(path, mode="rb") as f:
  982:                 assert f.read() == expected
  983: 
  984:         with tm.ensure_clean() as path:
  985:             # case 3: The default line terminator(=os.linesep)(gh-21406)
  986:             df.to_csv(path)
  987:             os_linesep = os.linesep.encode("utf-8")
  988:             expected = (
  989:                 b",A,B"
  990:                 + os_linesep
  991:                 + b"one,1,4"
  992:                 + os_linesep
  993:                 + b"two,2,5"
  994:                 + os_linesep
  995:                 + b"three,3,6"
  996:                 + os_linesep
  997:             )
  998: 
  999:             with open(path, mode="rb") as f:
 1000:                 assert f.read() == expected
 1001: 
 1002:     def test_to_csv_from_csv_categorical(self):
 1003:         # CSV with categoricals should result in the same output
 1004:         # as when one would add a "normal" Series/DataFrame.
 1005:         s = Series(pd.Categorical(["a", "b", "b", "a", "a", "c", "c", "c"]))
 1006:         s2 = Series(["a", "b", "b", "a", "a", "c", "c", "c"])
 1007:         res = StringIO()
 1008: 
 1009:         s.to_csv(res, header=False)
 1010:         exp = StringIO()
 1011: 
 1012:         s2.to_csv(exp, header=False)
 1013:         assert res.getvalue() == exp.getvalue()
 1014: 
 1015:         df = DataFrame({"s": s})
 1016:         df2 = DataFrame({"s": s2})
 1017: 
 1018:         res = StringIO()
 1019:         df.to_csv(res)
 1020: 
 1021:         exp = StringIO()
 1022:         df2.to_csv(exp)
 1023: 
 1024:         assert res.getvalue() == exp.getvalue()
 1025: 
 1026:     def test_to_csv_path_is_none(self, float_frame):
 1027:         # GH 8215
 1028:         # Make sure we return string for consistency with
 1029:         # Series.to_csv()
 1030:         csv_str = float_frame.to_csv(path_or_buf=None)
 1031:         assert isinstance(csv_str, str)
 1032:         recons = read_csv(StringIO(csv_str), index_col=0)
 1033:         tm.assert_frame_equal(float_frame, recons)
 1034: 
 1035:     @pytest.mark.parametrize(
 1036:         "df,encoding",
 1037:         [
 1038:             (
 1039:                 DataFrame(
 1040:                     [[0.123456, 0.234567, 0.567567], [12.32112, 123123.2, 321321.2]],
 1041:                     index=["A", "B"],
 1042:                     columns=["X", "Y", "Z"],
 1043:                 ),
 1044:                 None,
 1045:             ),
 1046:             # GH 21241, 21118
 1047:             (DataFrame([["abc", "def", "ghi"]], columns=["X", "Y", "Z"]), "ascii"),
 1048:             (DataFrame(5 * [[123, "дЅ еҐЅ", "дё–з•Њ"]], columns=["X", "Y", "Z"]), "gb2312"),
 1049:             (
 1050:                 DataFrame(
 1051:                     5 * [[123, "О“ОµО№О¬ ПѓОїП…", "ОљПЊПѓОјОµ"]],  # noqa: RUF001
 1052:                     columns=["X", "Y", "Z"],
 1053:                 ),
 1054:                 "cp737",
 1055:             ),
 1056:         ],
 1057:     )
 1058:     def test_to_csv_compression(self, df, encoding, compression):
 1059:         with tm.ensure_clean() as filename:
 1060:             df.to_csv(filename, compression=compression, encoding=encoding)
 1061:             # test the round trip - to_csv -> read_csv
 1062:             result = read_csv(
 1063:                 filename, compression=compression, index_col=0, encoding=encoding
 1064:             )
 1065:             tm.assert_frame_equal(df, result)
 1066: 
 1067:             # test the round trip using file handle - to_csv -> read_csv
 1068:             with get_handle(
 1069:                 filename, "w", compression=compression, encoding=encoding
 1070:             ) as handles:
 1071:                 df.to_csv(handles.handle, encoding=encoding)
 1072:                 assert not handles.handle.closed
 1073: 
 1074:             result = read_csv(
 1075:                 filename,
 1076:                 compression=compression,
 1077:                 encoding=encoding,
 1078:                 index_col=0,
 1079:             ).squeeze("columns")
 1080:             tm.assert_frame_equal(df, result)
 1081: 
 1082:             # explicitly make sure file is compressed
 1083:             with tm.decompress_file(filename, compression) as fh:
 1084:                 text = fh.read().decode(encoding or "utf8")
 1085:                 for col in df.columns:
 1086:                     assert col in text
 1087: 
 1088:             with tm.decompress_file(filename, compression) as fh:
 1089:                 tm.assert_frame_equal(df, read_csv(fh, index_col=0, encoding=encoding))
 1090: 
 1091:     def test_to_csv_date_format(self, datetime_frame):
 1092:         with tm.ensure_clean("__tmp_to_csv_date_format__") as path:
 1093:             dt_index = datetime_frame.index
 1094:             datetime_frame = DataFrame(
 1095:                 {"A": dt_index, "B": dt_index.shift(1)}, index=dt_index
 1096:             )
 1097:             datetime_frame.to_csv(path, date_format="%Y%m%d")
 1098: 
 1099:             # Check that the data was put in the specified format
 1100:             test = read_csv(path, index_col=0)
 1101: 
 1102:             datetime_frame_int = datetime_frame.map(lambda x: int(x.strftime("%Y%m%d")))
 1103:             datetime_frame_int.index = datetime_frame_int.index.map(
 1104:                 lambda x: int(x.strftime("%Y%m%d"))
 1105:             )
 1106: 
 1107:             tm.assert_frame_equal(test, datetime_frame_int)
 1108: 
 1109:             datetime_frame.to_csv(path, date_format="%Y-%m-%d")
 1110: 
 1111:             # Check that the data was put in the specified format
 1112:             test = read_csv(path, index_col=0)
 1113:             datetime_frame_str = datetime_frame.map(lambda x: x.strftime("%Y-%m-%d"))
 1114:             datetime_frame_str.index = datetime_frame_str.index.map(
 1115:                 lambda x: x.strftime("%Y-%m-%d")
 1116:             )
 1117: 
 1118:             tm.assert_frame_equal(test, datetime_frame_str)
 1119: 
 1120:             # Check that columns get converted
 1121:             datetime_frame_columns = datetime_frame.T
 1122:             datetime_frame_columns.to_csv(path, date_format="%Y%m%d")
 1123: 
 1124:             test = read_csv(path, index_col=0)
 1125: 
 1126:             datetime_frame_columns = datetime_frame_columns.map(
 1127:                 lambda x: int(x.strftime("%Y%m%d"))
 1128:             )
 1129:             # Columns don't get converted to ints by read_csv
 1130:             datetime_frame_columns.columns = datetime_frame_columns.columns.map(
 1131:                 lambda x: x.strftime("%Y%m%d")
 1132:             )
 1133: 
 1134:             tm.assert_frame_equal(test, datetime_frame_columns)
 1135: 
 1136:             # test NaTs
 1137:             nat_index = to_datetime(
 1138:                 ["NaT"] * 10 + ["2000-01-01", "2000-01-01", "2000-01-01"]
 1139:             )
 1140:             nat_frame = DataFrame({"A": nat_index}, index=nat_index)
 1141:             nat_frame.to_csv(path, date_format="%Y-%m-%d")
 1142: 
 1143:             test = read_csv(path, parse_dates=[0, 1], index_col=0)
 1144: 
 1145:             tm.assert_frame_equal(test, nat_frame)
 1146: 
 1147:     @pytest.mark.parametrize("td", [pd.Timedelta(0), pd.Timedelta("10s")])
 1148:     def test_to_csv_with_dst_transitions(self, td):
 1149:         with tm.ensure_clean("csv_date_format_with_dst") as path:
 1150:             # make sure we are not failing on transitions
 1151:             times = date_range(
 1152:                 "2013-10-26 23:00",
 1153:                 "2013-10-27 01:00",
 1154:                 tz="Europe/London",
 1155:                 freq="h",
 1156:                 ambiguous="infer",
 1157:             )
 1158:             i = times + td
 1159:             i = i._with_freq(None)  # freq is not preserved by read_csv
 1160:             time_range = np.array(range(len(i)), dtype="int64")
 1161:             df = DataFrame({"A": time_range}, index=i)
 1162:             df.to_csv(path, index=True)
 1163:             # we have to reconvert the index as we
 1164:             # don't parse the tz's
 1165:             result = read_csv(path, index_col=0)
 1166:             result.index = to_datetime(result.index, utc=True).tz_convert(
 1167:                 "Europe/London"
 1168:             )
 1169:             tm.assert_frame_equal(result, df)
 1170: 
 1171:     def test_to_csv_with_dst_transitions_with_pickle(self):
 1172:         # GH11619
 1173:         idx = date_range("2015-01-01", "2015-12-31", freq="h", tz="Europe/Paris")
 1174:         idx = idx._with_freq(None)  # freq does not round-trip
 1175:         idx._data._freq = None  # otherwise there is trouble on unpickle
 1176:         df = DataFrame({"values": 1, "idx": idx}, index=idx)
 1177:         with tm.ensure_clean("csv_date_format_with_dst") as path:
 1178:             df.to_csv(path, index=True)
 1179:             result = read_csv(path, index_col=0)
 1180:             result.index = to_datetime(result.index, utc=True).tz_convert(
 1181:                 "Europe/Paris"
 1182:             )
 1183:             result["idx"] = to_datetime(result["idx"], utc=True).astype(
 1184:                 "datetime64[ns, Europe/Paris]"
 1185:             )
 1186:             tm.assert_frame_equal(result, df)
 1187: 
 1188:         # assert working
 1189:         df.astype(str)
 1190: 
 1191:         with tm.ensure_clean("csv_date_format_with_dst") as path:
 1192:             df.to_pickle(path)
 1193:             result = pd.read_pickle(path)
 1194:             tm.assert_frame_equal(result, df)
 1195: 
 1196:     def test_to_csv_quoting(self):
 1197:         df = DataFrame(
 1198:             {
 1199:                 "c_bool": [True, False],
 1200:                 "c_float": [1.0, 3.2],
 1201:                 "c_int": [42, np.nan],
 1202:                 "c_string": ["a", "b,c"],
 1203:             }
 1204:         )
 1205: 
 1206:         expected_rows = [
 1207:             ",c_bool,c_float,c_int,c_string",
 1208:             "0,True,1.0,42.0,a",
 1209:             '1,False,3.2,,"b,c"',
 1210:         ]
 1211:         expected = tm.convert_rows_list_to_csv_str(expected_rows)
 1212: 
 1213:         result = df.to_csv()
 1214:         assert result == expected
 1215: 
 1216:         result = df.to_csv(quoting=None)
 1217:         assert result == expected
 1218: 
 1219:         expected_rows = [
 1220:             ",c_bool,c_float,c_int,c_string",
 1221:             "0,True,1.0,42.0,a",
 1222:             '1,False,3.2,,"b,c"',
 1223:         ]
 1224:         expected = tm.convert_rows_list_to_csv_str(expected_rows)
 1225: 
 1226:         result = df.to_csv(quoting=csv.QUOTE_MINIMAL)
 1227:         assert result == expected
 1228: 
 1229:         expected_rows = [
 1230:             '"","c_bool","c_float","c_int","c_string"',
 1231:             '"0","True","1.0","42.0","a"',
 1232:             '"1","False","3.2","","b,c"',
 1233:         ]
 1234:         expected = tm.convert_rows_list_to_csv_str(expected_rows)
 1235: 
 1236:         result = df.to_csv(quoting=csv.QUOTE_ALL)
 1237:         assert result == expected
 1238: 
 1239:         # see gh-12922, gh-13259: make sure changes to
 1240:         # the formatters do not break this behaviour
 1241:         expected_rows = [
 1242:             '"","c_bool","c_float","c_int","c_string"',
 1243:             '0,True,1.0,42.0,"a"',
 1244:             '1,False,3.2,"","b,c"',
 1245:         ]
 1246:         expected = tm.convert_rows_list_to_csv_str(expected_rows)
 1247:         result = df.to_csv(quoting=csv.QUOTE_NONNUMERIC)
 1248:         assert result == expected
 1249: 
 1250:         msg = "need to escape, but no escapechar set"
 1251:         with pytest.raises(csv.Error, match=msg):
 1252:             df.to_csv(quoting=csv.QUOTE_NONE)
 1253: 
 1254:         with pytest.raises(csv.Error, match=msg):
 1255:             df.to_csv(quoting=csv.QUOTE_NONE, escapechar=None)
 1256: 
 1257:         expected_rows = [
 1258:             ",c_bool,c_float,c_int,c_string",
 1259:             "0,True,1.0,42.0,a",
 1260:             "1,False,3.2,,b!,c",
 1261:         ]
 1262:         expected = tm.convert_rows_list_to_csv_str(expected_rows)
 1263:         result = df.to_csv(quoting=csv.QUOTE_NONE, escapechar="!")
 1264:         assert result == expected
 1265: 
 1266:         expected_rows = [
 1267:             ",c_bool,c_ffloat,c_int,c_string",
 1268:             "0,True,1.0,42.0,a",
 1269:             "1,False,3.2,,bf,c",
 1270:         ]
 1271:         expected = tm.convert_rows_list_to_csv_str(expected_rows)
 1272:         result = df.to_csv(quoting=csv.QUOTE_NONE, escapechar="f")
 1273:         assert result == expected
 1274: 
 1275:         # see gh-3503: quoting Windows line terminators
 1276:         # presents with encoding?
 1277:         text_rows = ["a,b,c", '1,"test \r\n",3']
 1278:         text = tm.convert_rows_list_to_csv_str(text_rows)
 1279:         df = read_csv(StringIO(text))
 1280: 
 1281:         buf = StringIO()
 1282:         df.to_csv(buf, encoding="utf-8", index=False)
 1283:         assert buf.getvalue() == text
 1284: 
 1285:         # xref gh-7791: make sure the quoting parameter is passed through
 1286:         # with multi-indexes
 1287:         df = DataFrame({"a": [1, 2], "b": [3, 4], "c": [5, 6]})
 1288:         df = df.set_index(["a", "b"])
 1289: 
 1290:         expected_rows = ['"a","b","c"', '"1","3","5"', '"2","4","6"']
 1291:         expected = tm.convert_rows_list_to_csv_str(expected_rows)
 1292:         assert df.to_csv(quoting=csv.QUOTE_ALL) == expected
 1293: 
 1294:     def test_period_index_date_overflow(self):
 1295:         # see gh-15982
 1296: 
 1297:         dates = ["1990-01-01", "2000-01-01", "3005-01-01"]
 1298:         index = pd.PeriodIndex(dates, freq="D")
 1299: 
 1300:         df = DataFrame([4, 5, 6], index=index)
 1301:         result = df.to_csv()
 1302: 
 1303:         expected_rows = [",0", "1990-01-01,4", "2000-01-01,5", "3005-01-01,6"]
 1304:         expected = tm.convert_rows_list_to_csv_str(expected_rows)
 1305:         assert result == expected
 1306: 
 1307:         date_format = "%m-%d-%Y"
 1308:         result = df.to_csv(date_format=date_format)
 1309: 
 1310:         expected_rows = [",0", "01-01-1990,4", "01-01-2000,5", "01-01-3005,6"]
 1311:         expected = tm.convert_rows_list_to_csv_str(expected_rows)
 1312:         assert result == expected
 1313: 
 1314:         # Overflow with pd.NaT
 1315:         dates = ["1990-01-01", NaT, "3005-01-01"]
 1316:         index = pd.PeriodIndex(dates, freq="D")
 1317: 
 1318:         df = DataFrame([4, 5, 6], index=index)
 1319:         result = df.to_csv()
 1320: 
 1321:         expected_rows = [",0", "1990-01-01,4", ",5", "3005-01-01,6"]
 1322:         expected = tm.convert_rows_list_to_csv_str(expected_rows)
 1323:         assert result == expected
 1324: 
 1325:     def test_multi_index_header(self):
 1326:         # see gh-5539
 1327:         columns = MultiIndex.from_tuples([("a", 1), ("a", 2), ("b", 1), ("b", 2)])
 1328:         df = DataFrame([[1, 2, 3, 4], [5, 6, 7, 8]])
 1329:         df.columns = columns
 1330: 
 1331:         header = ["a", "b", "c", "d"]
 1332:         result = df.to_csv(header=header)
 1333: 
 1334:         expected_rows = [",a,b,c,d", "0,1,2,3,4", "1,5,6,7,8"]
 1335:         expected = tm.convert_rows_list_to_csv_str(expected_rows)
 1336:         assert result == expected
 1337: 
 1338:     def test_to_csv_single_level_multi_index(self):
 1339:         # see gh-26303
 1340:         index = Index([(1,), (2,), (3,)])
 1341:         df = DataFrame([[1, 2, 3]], columns=index)
 1342:         df = df.reindex(columns=[(1,), (3,)])
 1343:         expected = ",1,3\n0,1,3\n"
 1344:         result = df.to_csv(lineterminator="\n")
 1345:         tm.assert_almost_equal(result, expected)
 1346: 
 1347:     def test_gz_lineend(self):
 1348:         # GH 25311
 1349:         df = DataFrame({"a": [1, 2]})
 1350:         expected_rows = ["a", "1", "2"]
 1351:         expected = tm.convert_rows_list_to_csv_str(expected_rows)
 1352:         with tm.ensure_clean("__test_gz_lineend.csv.gz") as path:
 1353:             df.to_csv(path, index=False)
 1354:             with tm.decompress_file(path, compression="gzip") as f:
 1355:                 result = f.read().decode("utf-8")
 1356: 
 1357:         assert result == expected
 1358: 
 1359:     def test_to_csv_numpy_16_bug(self):
 1360:         frame = DataFrame({"a": date_range("1/1/2000", periods=10)})
 1361: 
 1362:         buf = StringIO()
 1363:         frame.to_csv(buf)
 1364: 
 1365:         result = buf.getvalue()
 1366:         assert "2000-01-01" in result
 1367: 
 1368:     def test_to_csv_na_quoting(self):
 1369:         # GH 15891
 1370:         # Normalize carriage return for Windows OS
 1371:         result = (
 1372:             DataFrame([None, None])
 1373:             .to_csv(None, header=False, index=False, na_rep="")
 1374:             .replace("\r\n", "\n")
 1375:         )
 1376:         expected = '""\n""\n'
 1377:         assert result == expected
 1378: 
 1379:     def test_to_csv_categorical_and_ea(self):
 1380:         # GH#46812
 1381:         df = DataFrame({"a": "x", "b": [1, pd.NA]})
 1382:         df["b"] = df["b"].astype("Int16")
 1383:         df["b"] = df["b"].astype("category")
 1384:         result = df.to_csv()
 1385:         expected_rows = [",a,b", "0,x,1", "1,x,"]
 1386:         expected = tm.convert_rows_list_to_csv_str(expected_rows)
 1387:         assert result == expected
 1388: 
 1389:     def test_to_csv_categorical_and_interval(self):
 1390:         # GH#46297
 1391:         df = DataFrame(
 1392:             {
 1393:                 "a": [
 1394:                     pd.Interval(
 1395:                         Timestamp("2020-01-01"),
 1396:                         Timestamp("2020-01-02"),
 1397:                         closed="both",
 1398:                     )
 1399:                 ]
 1400:             }
 1401:         )
 1402:         df["a"] = df["a"].astype("category")
 1403:         result = df.to_csv()
 1404:         expected_rows = [",a", '0,"[2020-01-01 00:00:00, 2020-01-02 00:00:00]"']
 1405:         expected = tm.convert_rows_list_to_csv_str(expected_rows)
 1406:         assert result == expected
