    1: from datetime import (
    2:     datetime,
    3:     timedelta,
    4: )
    5: import itertools
    6: 
    7: import numpy as np
    8: import pytest
    9: 
   10: from pandas.errors import PerformanceWarning
   11: import pandas.util._test_decorators as td
   12: 
   13: import pandas as pd
   14: from pandas import (
   15:     Categorical,
   16:     DataFrame,
   17:     Series,
   18:     Timestamp,
   19:     date_range,
   20:     option_context,
   21: )
   22: import pandas._testing as tm
   23: from pandas.core.internals.blocks import NumpyBlock
   24: 
   25: # Segregated collection of methods that require the BlockManager internal data
   26: # structure
   27: 
   28: 
   29: # TODO(ArrayManager) check which of those tests need to be rewritten to test the
   30: # equivalent for ArrayManager
   31: pytestmark = td.skip_array_manager_invalid_test
   32: 
   33: 
   34: class TestDataFrameBlockInternals:
   35:     def test_setitem_invalidates_datetime_index_freq(self):
   36:         # GH#24096 altering a datetime64tz column inplace invalidates the
   37:         #  `freq` attribute on the underlying DatetimeIndex
   38: 
   39:         dti = date_range("20130101", periods=3, tz="US/Eastern")
   40:         ts = dti[1]
   41: 
   42:         df = DataFrame({"B": dti})
   43:         assert df["B"]._values.freq is None
   44: 
   45:         df.iloc[1, 0] = pd.NaT
   46:         assert df["B"]._values.freq is None
   47: 
   48:         # check that the DatetimeIndex was not altered in place
   49:         assert dti.freq == "D"
   50:         assert dti[1] == ts
   51: 
   52:     def test_cast_internals(self, float_frame):
   53:         msg = "Passing a BlockManager to DataFrame"
   54:         with tm.assert_produces_warning(
   55:             DeprecationWarning, match=msg, check_stacklevel=False
   56:         ):
   57:             casted = DataFrame(float_frame._mgr, dtype=int)
   58:         expected = DataFrame(float_frame._series, dtype=int)
   59:         tm.assert_frame_equal(casted, expected)
   60: 
   61:         with tm.assert_produces_warning(
   62:             DeprecationWarning, match=msg, check_stacklevel=False
   63:         ):
   64:             casted = DataFrame(float_frame._mgr, dtype=np.int32)
   65:         expected = DataFrame(float_frame._series, dtype=np.int32)
   66:         tm.assert_frame_equal(casted, expected)
   67: 
   68:     def test_consolidate(self, float_frame):
   69:         float_frame["E"] = 7.0
   70:         consolidated = float_frame._consolidate()
   71:         assert len(consolidated._mgr.blocks) == 1
   72: 
   73:         # Ensure copy, do I want this?
   74:         recons = consolidated._consolidate()
   75:         assert recons is not consolidated
   76:         tm.assert_frame_equal(recons, consolidated)
   77: 
   78:         float_frame["F"] = 8.0
   79:         assert len(float_frame._mgr.blocks) == 3
   80: 
   81:         return_value = float_frame._consolidate_inplace()
   82:         assert return_value is None
   83:         assert len(float_frame._mgr.blocks) == 1
   84: 
   85:     def test_consolidate_inplace(self, float_frame):
   86:         # triggers in-place consolidation
   87:         for letter in range(ord("A"), ord("Z")):
   88:             float_frame[chr(letter)] = chr(letter)
   89: 
   90:     def test_modify_values(self, float_frame, using_copy_on_write):
   91:         if using_copy_on_write:
   92:             with pytest.raises(ValueError, match="read-only"):
   93:                 float_frame.values[5] = 5
   94:             assert (float_frame.values[5] != 5).all()
   95:             return
   96: 
   97:         float_frame.values[5] = 5
   98:         assert (float_frame.values[5] == 5).all()
   99: 
  100:         # unconsolidated
  101:         float_frame["E"] = 7.0
  102:         col = float_frame["E"]
  103:         float_frame.values[6] = 6
  104:         # as of 2.0 .values does not consolidate, so subsequent calls to .values
  105:         #  does not share data
  106:         assert not (float_frame.values[6] == 6).all()
  107: 
  108:         assert (col == 7).all()
  109: 
  110:     def test_boolean_set_uncons(self, float_frame):
  111:         float_frame["E"] = 7.0
  112: 
  113:         expected = float_frame.values.copy()
  114:         expected[expected > 1] = 2
  115: 
  116:         float_frame[float_frame > 1] = 2
  117:         tm.assert_almost_equal(expected, float_frame.values)
  118: 
  119:     def test_constructor_with_convert(self):
  120:         # this is actually mostly a test of lib.maybe_convert_objects
  121:         # #2845
  122:         df = DataFrame({"A": [2**63 - 1]})
  123:         result = df["A"]
  124:         expected = Series(np.asarray([2**63 - 1], np.int64), name="A")
  125:         tm.assert_series_equal(result, expected)
  126: 
  127:         df = DataFrame({"A": [2**63]})
  128:         result = df["A"]
  129:         expected = Series(np.asarray([2**63], np.uint64), name="A")
  130:         tm.assert_series_equal(result, expected)
  131: 
  132:         df = DataFrame({"A": [datetime(2005, 1, 1), True]})
  133:         result = df["A"]
  134:         expected = Series(
  135:             np.asarray([datetime(2005, 1, 1), True], np.object_), name="A"
  136:         )
  137:         tm.assert_series_equal(result, expected)
  138: 
  139:         df = DataFrame({"A": [None, 1]})
  140:         result = df["A"]
  141:         expected = Series(np.asarray([np.nan, 1], np.float64), name="A")
  142:         tm.assert_series_equal(result, expected)
  143: 
  144:         df = DataFrame({"A": [1.0, 2]})
  145:         result = df["A"]
  146:         expected = Series(np.asarray([1.0, 2], np.float64), name="A")
  147:         tm.assert_series_equal(result, expected)
  148: 
  149:         df = DataFrame({"A": [1.0 + 2.0j, 3]})
  150:         result = df["A"]
  151:         expected = Series(np.asarray([1.0 + 2.0j, 3], np.complex128), name="A")
  152:         tm.assert_series_equal(result, expected)
  153: 
  154:         df = DataFrame({"A": [1.0 + 2.0j, 3.0]})
  155:         result = df["A"]
  156:         expected = Series(np.asarray([1.0 + 2.0j, 3.0], np.complex128), name="A")
  157:         tm.assert_series_equal(result, expected)
  158: 
  159:         df = DataFrame({"A": [1.0 + 2.0j, True]})
  160:         result = df["A"]
  161:         expected = Series(np.asarray([1.0 + 2.0j, True], np.object_), name="A")
  162:         tm.assert_series_equal(result, expected)
  163: 
  164:         df = DataFrame({"A": [1.0, None]})
  165:         result = df["A"]
  166:         expected = Series(np.asarray([1.0, np.nan], np.float64), name="A")
  167:         tm.assert_series_equal(result, expected)
  168: 
  169:         df = DataFrame({"A": [1.0 + 2.0j, None]})
  170:         result = df["A"]
  171:         expected = Series(np.asarray([1.0 + 2.0j, np.nan], np.complex128), name="A")
  172:         tm.assert_series_equal(result, expected)
  173: 
  174:         df = DataFrame({"A": [2.0, 1, True, None]})
  175:         result = df["A"]
  176:         expected = Series(np.asarray([2.0, 1, True, None], np.object_), name="A")
  177:         tm.assert_series_equal(result, expected)
  178: 
  179:         df = DataFrame({"A": [2.0, 1, datetime(2006, 1, 1), None]})
  180:         result = df["A"]
  181:         expected = Series(
  182:             np.asarray([2.0, 1, datetime(2006, 1, 1), None], np.object_), name="A"
  183:         )
  184:         tm.assert_series_equal(result, expected)
  185: 
  186:     def test_construction_with_mixed(self, float_string_frame, using_infer_string):
  187:         # test construction edge cases with mixed types
  188: 
  189:         # f7u12, this does not work without extensive workaround
  190:         data = [
  191:             [datetime(2001, 1, 5), np.nan, datetime(2001, 1, 2)],
  192:             [datetime(2000, 1, 2), datetime(2000, 1, 3), datetime(2000, 1, 1)],
  193:         ]
  194:         df = DataFrame(data)
  195: 
  196:         # check dtypes
  197:         result = df.dtypes
  198:         expected = Series({"datetime64[us]": 3})
  199: 
  200:         # mixed-type frames
  201:         float_string_frame["datetime"] = datetime.now()
  202:         float_string_frame["timedelta"] = timedelta(days=1, seconds=1)
  203:         assert float_string_frame["datetime"].dtype == "M8[us]"
  204:         assert float_string_frame["timedelta"].dtype == "m8[us]"
  205:         result = float_string_frame.dtypes
  206:         expected = Series(
  207:             [np.dtype("float64")] * 4
  208:             + [
  209:                 np.dtype("object") if not using_infer_string else "string",
  210:                 np.dtype("datetime64[us]"),
  211:                 np.dtype("timedelta64[us]"),
  212:             ],
  213:             index=list("ABCD") + ["foo", "datetime", "timedelta"],
  214:         )
  215:         tm.assert_series_equal(result, expected)
  216: 
  217:     def test_construction_with_conversions(self):
  218:         # convert from a numpy array of non-ns timedelta64; as of 2.0 this does
  219:         #  *not* convert
  220:         arr = np.array([1, 2, 3], dtype="timedelta64[s]")
  221:         df = DataFrame(index=range(3))
  222:         df["A"] = arr
  223:         expected = DataFrame(
  224:             {"A": pd.timedelta_range("00:00:01", periods=3, freq="s")}, index=range(3)
  225:         )
  226:         tm.assert_numpy_array_equal(df["A"].to_numpy(), arr)
  227: 
  228:         expected = DataFrame(
  229:             {
  230:                 "dt1": Timestamp("20130101"),
  231:                 "dt2": date_range("20130101", periods=3).astype("M8[s]"),
  232:                 # 'dt3' : date_range('20130101 00:00:01',periods=3,freq='s'),
  233:                 # FIXME: don't leave commented-out
  234:             },
  235:             index=range(3),
  236:         )
  237:         assert expected.dtypes["dt1"] == "M8[s]"
  238:         assert expected.dtypes["dt2"] == "M8[s]"
  239: 
  240:         df = DataFrame(index=range(3))
  241:         df["dt1"] = np.datetime64("2013-01-01")
  242:         df["dt2"] = np.array(
  243:             ["2013-01-01", "2013-01-02", "2013-01-03"], dtype="datetime64[D]"
  244:         )
  245: 
  246:         # df['dt3'] = np.array(['2013-01-01 00:00:01','2013-01-01
  247:         # 00:00:02','2013-01-01 00:00:03'],dtype='datetime64[s]')
  248:         # FIXME: don't leave commented-out
  249: 
  250:         tm.assert_frame_equal(df, expected)
  251: 
  252:     def test_constructor_compound_dtypes(self):
  253:         # GH 5191
  254:         # compound dtypes should raise not-implementederror
  255: 
  256:         def f(dtype):
  257:             data = list(itertools.repeat((datetime(2001, 1, 1), "aa", 20), 9))
  258:             return DataFrame(data=data, columns=["A", "B", "C"], dtype=dtype)
  259: 
  260:         msg = "compound dtypes are not implemented in the DataFrame constructor"
  261:         with pytest.raises(NotImplementedError, match=msg):
  262:             f([("A", "datetime64[h]"), ("B", "str"), ("C", "int32")])
  263: 
  264:         # pre-2.0 these used to work (though results may be unexpected)
  265:         with pytest.raises(TypeError, match="argument must be"):
  266:             f("int64")
  267:         with pytest.raises(TypeError, match="argument must be"):
  268:             f("float64")
  269: 
  270:         # 10822
  271:         msg = "^Unknown datetime string format, unable to parse: aa, at position 0$"
  272:         with pytest.raises(ValueError, match=msg):
  273:             f("M8[ns]")
  274: 
  275:     def test_pickle(self, float_string_frame, timezone_frame):
  276:         empty_frame = DataFrame()
  277: 
  278:         unpickled = tm.round_trip_pickle(float_string_frame)
  279:         tm.assert_frame_equal(float_string_frame, unpickled)
  280: 
  281:         # buglet
  282:         float_string_frame._mgr.ndim
  283: 
  284:         # empty
  285:         unpickled = tm.round_trip_pickle(empty_frame)
  286:         repr(unpickled)
  287: 
  288:         # tz frame
  289:         unpickled = tm.round_trip_pickle(timezone_frame)
  290:         tm.assert_frame_equal(timezone_frame, unpickled)
  291: 
  292:     def test_consolidate_datetime64(self):
  293:         # numpy vstack bug
  294: 
  295:         df = DataFrame(
  296:             {
  297:                 "starting": pd.to_datetime(
  298:                     [
  299:                         "2012-06-21 00:00",
  300:                         "2012-06-23 07:00",
  301:                         "2012-06-23 16:30",
  302:                         "2012-06-25 08:00",
  303:                         "2012-06-26 12:00",
  304:                     ]
  305:                 ),
  306:                 "ending": pd.to_datetime(
  307:                     [
  308:                         "2012-06-23 07:00",
  309:                         "2012-06-23 16:30",
  310:                         "2012-06-25 08:00",
  311:                         "2012-06-26 12:00",
  312:                         "2012-06-27 08:00",
  313:                     ]
  314:                 ),
  315:                 "measure": [77, 65, 77, 0, 77],
  316:             }
  317:         )
  318: 
  319:         ser_starting = df.starting
  320:         ser_starting.index = ser_starting.values
  321:         ser_starting = ser_starting.tz_localize("US/Eastern")
  322:         ser_starting = ser_starting.tz_convert("UTC")
  323:         ser_starting.index.name = "starting"
  324: 
  325:         ser_ending = df.ending
  326:         ser_ending.index = ser_ending.values
  327:         ser_ending = ser_ending.tz_localize("US/Eastern")
  328:         ser_ending = ser_ending.tz_convert("UTC")
  329:         ser_ending.index.name = "ending"
  330: 
  331:         df.starting = ser_starting.index
  332:         df.ending = ser_ending.index
  333: 
  334:         tm.assert_index_equal(pd.DatetimeIndex(df.starting), ser_starting.index)
  335:         tm.assert_index_equal(pd.DatetimeIndex(df.ending), ser_ending.index)
  336: 
  337:     def test_is_mixed_type(self, float_frame, float_string_frame):
  338:         assert not float_frame._is_mixed_type
  339:         assert float_string_frame._is_mixed_type
  340: 
  341:     def test_stale_cached_series_bug_473(self, using_copy_on_write, warn_copy_on_write):
  342:         # this is chained, but ok
  343:         with option_context("chained_assignment", None):
  344:             Y = DataFrame(
  345:                 np.random.default_rng(2).random((4, 4)),
  346:                 index=("a", "b", "c", "d"),
  347:                 columns=("e", "f", "g", "h"),
  348:             )
  349:             repr(Y)
  350:             Y["e"] = Y["e"].astype("object")
  351:             with tm.raises_chained_assignment_error():
  352:                 Y["g"]["c"] = np.nan
  353:             repr(Y)
  354:             Y.sum()
  355:             Y["g"].sum()
  356:             if using_copy_on_write:
  357:                 assert not pd.isna(Y["g"]["c"])
  358:             else:
  359:                 assert pd.isna(Y["g"]["c"])
  360: 
  361:     @pytest.mark.filterwarnings("ignore:Setting a value on a view:FutureWarning")
  362:     def test_strange_column_corruption_issue(self, using_copy_on_write):
  363:         # TODO(wesm): Unclear how exactly this is related to internal matters
  364:         df = DataFrame(index=[0, 1])
  365:         df[0] = np.nan
  366:         wasCol = {}
  367: 
  368:         with tm.assert_produces_warning(
  369:             PerformanceWarning, raise_on_extra_warnings=False
  370:         ):
  371:             for i, dt in enumerate(df.index):
  372:                 for col in range(100, 200):
  373:                     if col not in wasCol:
  374:                         wasCol[col] = 1
  375:                         df[col] = np.nan
  376:                     if using_copy_on_write:
  377:                         df.loc[dt, col] = i
  378:                     else:
  379:                         df[col][dt] = i
  380: 
  381:         myid = 100
  382: 
  383:         first = len(df.loc[pd.isna(df[myid]), [myid]])
  384:         second = len(df.loc[pd.isna(df[myid]), [myid]])
  385:         assert first == second == 0
  386: 
  387:     def test_constructor_no_pandas_array(self):
  388:         # Ensure that NumpyExtensionArray isn't allowed inside Series
  389:         # See https://github.com/pandas-dev/pandas/issues/23995 for more.
  390:         arr = Series([1, 2, 3]).array
  391:         result = DataFrame({"A": arr})
  392:         expected = DataFrame({"A": [1, 2, 3]})
  393:         tm.assert_frame_equal(result, expected)
  394:         assert isinstance(result._mgr.blocks[0], NumpyBlock)
  395:         assert result._mgr.blocks[0].is_numeric
  396: 
  397:     def test_add_column_with_pandas_array(self):
  398:         # GH 26390
  399:         df = DataFrame({"a": [1, 2, 3, 4], "b": ["a", "b", "c", "d"]})
  400:         df["c"] = pd.arrays.NumpyExtensionArray(np.array([1, 2, None, 3], dtype=object))
  401:         df2 = DataFrame(
  402:             {
  403:                 "a": [1, 2, 3, 4],
  404:                 "b": ["a", "b", "c", "d"],
  405:                 "c": pd.arrays.NumpyExtensionArray(
  406:                     np.array([1, 2, None, 3], dtype=object)
  407:                 ),
  408:             }
  409:         )
  410:         assert type(df["c"]._mgr.blocks[0]) == NumpyBlock
  411:         assert df["c"]._mgr.blocks[0].is_object
  412:         assert type(df2["c"]._mgr.blocks[0]) == NumpyBlock
  413:         assert df2["c"]._mgr.blocks[0].is_object
  414:         tm.assert_frame_equal(df, df2)
  415: 
  416: 
  417: def test_update_inplace_sets_valid_block_values(using_copy_on_write):
  418:     # https://github.com/pandas-dev/pandas/issues/33457
  419:     df = DataFrame({"a": Series([1, 2, None], dtype="category")})
  420: 
  421:     # inplace update of a single column
  422:     if using_copy_on_write:
  423:         with tm.raises_chained_assignment_error():
  424:             df["a"].fillna(1, inplace=True)
  425:     else:
  426:         with tm.assert_produces_warning(FutureWarning, match="inplace method"):
  427:             df["a"].fillna(1, inplace=True)
  428: 
  429:     # check we haven't put a Series into any block.values
  430:     assert isinstance(df._mgr.blocks[0].values, Categorical)
  431: 
  432:     if not using_copy_on_write:
  433:         # smoketest for OP bug from GH#35731
  434:         assert df.isnull().sum().sum() == 0
  435: 
  436: 
  437: def test_nonconsolidated_item_cache_take():
  438:     # https://github.com/pandas-dev/pandas/issues/35521
  439: 
  440:     # create non-consolidated dataframe with object dtype columns
  441:     df = DataFrame()
  442:     df["col1"] = Series(["a"], dtype=object)
  443:     df["col2"] = Series([0], dtype=object)
  444: 
  445:     # access column (item cache)
  446:     df["col1"] == "A"
  447:     # take operation
  448:     # (regression was that this consolidated but didn't reset item cache,
  449:     # resulting in an invalid cache and the .at operation not working properly)
  450:     df[df["col2"] == 0]
  451: 
  452:     # now setting value should update actual dataframe
  453:     df.at[0, "col1"] = "A"
  454: 
  455:     expected = DataFrame({"col1": ["A"], "col2": [0]}, dtype=object)
  456:     tm.assert_frame_equal(df, expected)
  457:     assert df.at[0, "col1"] == "A"
