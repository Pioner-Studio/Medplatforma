    1: from io import StringIO
    2: import re
    3: from string import ascii_uppercase
    4: import sys
    5: import textwrap
    6: 
    7: import numpy as np
    8: import pytest
    9: 
   10: from pandas.compat import (
   11:     IS64,
   12:     PYPY,
   13: )
   14: 
   15: from pandas import (
   16:     CategoricalIndex,
   17:     DataFrame,
   18:     MultiIndex,
   19:     Series,
   20:     date_range,
   21:     option_context,
   22: )
   23: import pandas._testing as tm
   24: 
   25: 
   26: @pytest.fixture
   27: def duplicate_columns_frame():
   28:     """Dataframe with duplicate column names."""
   29:     return DataFrame(
   30:         np.random.default_rng(2).standard_normal((1500, 4)),
   31:         columns=["a", "a", "b", "b"],
   32:     )
   33: 
   34: 
   35: def test_info_empty():
   36:     # GH #45494
   37:     df = DataFrame()
   38:     buf = StringIO()
   39:     df.info(buf=buf)
   40:     result = buf.getvalue()
   41:     expected = textwrap.dedent(
   42:         """\
   43:         <class 'pandas.core.frame.DataFrame'>
   44:         RangeIndex: 0 entries
   45:         Empty DataFrame\n"""
   46:     )
   47:     assert result == expected
   48: 
   49: 
   50: def test_info_categorical_column_smoke_test():
   51:     n = 2500
   52:     df = DataFrame({"int64": np.random.default_rng(2).integers(100, size=n, dtype=int)})
   53:     df["category"] = Series(
   54:         np.array(list("abcdefghij")).take(
   55:             np.random.default_rng(2).integers(0, 10, size=n, dtype=int)
   56:         )
   57:     ).astype("category")
   58:     df.isna()
   59:     buf = StringIO()
   60:     df.info(buf=buf)
   61: 
   62:     df2 = df[df["category"] == "d"]
   63:     buf = StringIO()
   64:     df2.info(buf=buf)
   65: 
   66: 
   67: @pytest.mark.parametrize(
   68:     "fixture_func_name",
   69:     [
   70:         "int_frame",
   71:         "float_frame",
   72:         "datetime_frame",
   73:         "duplicate_columns_frame",
   74:         "float_string_frame",
   75:     ],
   76: )
   77: def test_info_smoke_test(fixture_func_name, request):
   78:     frame = request.getfixturevalue(fixture_func_name)
   79:     buf = StringIO()
   80:     frame.info(buf=buf)
   81:     result = buf.getvalue().splitlines()
   82:     assert len(result) > 10
   83: 
   84:     buf = StringIO()
   85:     frame.info(buf=buf, verbose=False)
   86: 
   87: 
   88: def test_info_smoke_test2(float_frame):
   89:     # pretty useless test, used to be mixed into the repr tests
   90:     buf = StringIO()
   91:     float_frame.reindex(columns=["A"]).info(verbose=False, buf=buf)
   92:     float_frame.reindex(columns=["A", "B"]).info(verbose=False, buf=buf)
   93: 
   94:     # no columns or index
   95:     DataFrame().info(buf=buf)
   96: 
   97: 
   98: @pytest.mark.parametrize(
   99:     "num_columns, max_info_columns, verbose",
  100:     [
  101:         (10, 100, True),
  102:         (10, 11, True),
  103:         (10, 10, True),
  104:         (10, 9, False),
  105:         (10, 1, False),
  106:     ],
  107: )
  108: def test_info_default_verbose_selection(num_columns, max_info_columns, verbose):
  109:     frame = DataFrame(np.random.default_rng(2).standard_normal((5, num_columns)))
  110:     with option_context("display.max_info_columns", max_info_columns):
  111:         io_default = StringIO()
  112:         frame.info(buf=io_default)
  113:         result = io_default.getvalue()
  114: 
  115:         io_explicit = StringIO()
  116:         frame.info(buf=io_explicit, verbose=verbose)
  117:         expected = io_explicit.getvalue()
  118: 
  119:         assert result == expected
  120: 
  121: 
  122: def test_info_verbose_check_header_separator_body():
  123:     buf = StringIO()
  124:     size = 1001
  125:     start = 5
  126:     frame = DataFrame(np.random.default_rng(2).standard_normal((3, size)))
  127:     frame.info(verbose=True, buf=buf)
  128: 
  129:     res = buf.getvalue()
  130:     header = " #     Column  Dtype  \n---    ------  -----  "
  131:     assert header in res
  132: 
  133:     frame.info(verbose=True, buf=buf)
  134:     buf.seek(0)
  135:     lines = buf.readlines()
  136:     assert len(lines) > 0
  137: 
  138:     for i, line in enumerate(lines):
  139:         if start <= i < start + size:
  140:             line_nr = f" {i - start} "
  141:             assert line.startswith(line_nr)
  142: 
  143: 
  144: @pytest.mark.parametrize(
  145:     "size, header_exp, separator_exp, first_line_exp, last_line_exp",
  146:     [
  147:         (
  148:             4,
  149:             " #   Column  Non-Null Count  Dtype  ",
  150:             "---  ------  --------------  -----  ",
  151:             " 0   0       3 non-null      float64",
  152:             " 3   3       3 non-null      float64",
  153:         ),
  154:         (
  155:             11,
  156:             " #   Column  Non-Null Count  Dtype  ",
  157:             "---  ------  --------------  -----  ",
  158:             " 0   0       3 non-null      float64",
  159:             " 10  10      3 non-null      float64",
  160:         ),
  161:         (
  162:             101,
  163:             " #    Column  Non-Null Count  Dtype  ",
  164:             "---   ------  --------------  -----  ",
  165:             " 0    0       3 non-null      float64",
  166:             " 100  100     3 non-null      float64",
  167:         ),
  168:         (
  169:             1001,
  170:             " #     Column  Non-Null Count  Dtype  ",
  171:             "---    ------  --------------  -----  ",
  172:             " 0     0       3 non-null      float64",
  173:             " 1000  1000    3 non-null      float64",
  174:         ),
  175:         (
  176:             10001,
  177:             " #      Column  Non-Null Count  Dtype  ",
  178:             "---     ------  --------------  -----  ",
  179:             " 0      0       3 non-null      float64",
  180:             " 10000  10000   3 non-null      float64",
  181:         ),
  182:     ],
  183: )
  184: def test_info_verbose_with_counts_spacing(
  185:     size, header_exp, separator_exp, first_line_exp, last_line_exp
  186: ):
  187:     """Test header column, spacer, first line and last line in verbose mode."""
  188:     frame = DataFrame(np.random.default_rng(2).standard_normal((3, size)))
  189:     with StringIO() as buf:
  190:         frame.info(verbose=True, show_counts=True, buf=buf)
  191:         all_lines = buf.getvalue().splitlines()
  192:     # Here table would contain only header, separator and table lines
  193:     # dframe repr, index summary, memory usage and dtypes are excluded
  194:     table = all_lines[3:-2]
  195:     header, separator, first_line, *rest, last_line = table
  196:     assert header == header_exp
  197:     assert separator == separator_exp
  198:     assert first_line == first_line_exp
  199:     assert last_line == last_line_exp
  200: 
  201: 
  202: def test_info_memory():
  203:     # https://github.com/pandas-dev/pandas/issues/21056
  204:     df = DataFrame({"a": Series([1, 2], dtype="i8")})
  205:     buf = StringIO()
  206:     df.info(buf=buf)
  207:     result = buf.getvalue()
  208:     bytes = float(df.memory_usage().sum())
  209:     expected = textwrap.dedent(
  210:         f"""\
  211:     <class 'pandas.core.frame.DataFrame'>
  212:     RangeIndex: 2 entries, 0 to 1
  213:     Data columns (total 1 columns):
  214:      #   Column  Non-Null Count  Dtype
  215:     ---  ------  --------------  -----
  216:      0   a       2 non-null      int64
  217:     dtypes: int64(1)
  218:     memory usage: {bytes} bytes
  219:     """
  220:     )
  221:     assert result == expected
  222: 
  223: 
  224: def test_info_wide():
  225:     io = StringIO()
  226:     df = DataFrame(np.random.default_rng(2).standard_normal((5, 101)))
  227:     df.info(buf=io)
  228: 
  229:     io = StringIO()
  230:     df.info(buf=io, max_cols=101)
  231:     result = io.getvalue()
  232:     assert len(result.splitlines()) > 100
  233: 
  234:     expected = result
  235:     with option_context("display.max_info_columns", 101):
  236:         io = StringIO()
  237:         df.info(buf=io)
  238:         result = io.getvalue()
  239:         assert result == expected
  240: 
  241: 
  242: def test_info_duplicate_columns_shows_correct_dtypes():
  243:     # GH11761
  244:     io = StringIO()
  245:     frame = DataFrame([[1, 2.0]], columns=["a", "a"])
  246:     frame.info(buf=io)
  247:     lines = io.getvalue().splitlines(True)
  248:     assert " 0   a       1 non-null      int64  \n" == lines[5]
  249:     assert " 1   a       1 non-null      float64\n" == lines[6]
  250: 
  251: 
  252: def test_info_shows_column_dtypes():
  253:     dtypes = [
  254:         "int64",
  255:         "float64",
  256:         "datetime64[ns]",
  257:         "timedelta64[ns]",
  258:         "complex128",
  259:         "object",
  260:         "bool",
  261:     ]
  262:     data = {}
  263:     n = 10
  264:     for i, dtype in enumerate(dtypes):
  265:         data[i] = np.random.default_rng(2).integers(2, size=n).astype(dtype)
  266:     df = DataFrame(data)
  267:     buf = StringIO()
  268:     df.info(buf=buf)
  269:     res = buf.getvalue()
  270:     header = (
  271:         " #   Column  Non-Null Count  Dtype          \n"
  272:         "---  ------  --------------  -----          "
  273:     )
  274:     assert header in res
  275:     for i, dtype in enumerate(dtypes):
  276:         name = f" {i:d}   {i:d}       {n:d} non-null     {dtype}"
  277:         assert name in res
  278: 
  279: 
  280: def test_info_max_cols():
  281:     df = DataFrame(np.random.default_rng(2).standard_normal((10, 5)))
  282:     for len_, verbose in [(5, None), (5, False), (12, True)]:
  283:         # For verbose always      ^ setting  ^ summarize ^ full output
  284:         with option_context("max_info_columns", 4):
  285:             buf = StringIO()
  286:             df.info(buf=buf, verbose=verbose)
  287:             res = buf.getvalue()
  288:             assert len(res.strip().split("\n")) == len_
  289: 
  290:     for len_, verbose in [(12, None), (5, False), (12, True)]:
  291:         # max_cols not exceeded
  292:         with option_context("max_info_columns", 5):
  293:             buf = StringIO()
  294:             df.info(buf=buf, verbose=verbose)
  295:             res = buf.getvalue()
  296:             assert len(res.strip().split("\n")) == len_
  297: 
  298:     for len_, max_cols in [(12, 5), (5, 4)]:
  299:         # setting truncates
  300:         with option_context("max_info_columns", 4):
  301:             buf = StringIO()
  302:             df.info(buf=buf, max_cols=max_cols)
  303:             res = buf.getvalue()
  304:             assert len(res.strip().split("\n")) == len_
  305: 
  306:         # setting wouldn't truncate
  307:         with option_context("max_info_columns", 5):
  308:             buf = StringIO()
  309:             df.info(buf=buf, max_cols=max_cols)
  310:             res = buf.getvalue()
  311:             assert len(res.strip().split("\n")) == len_
  312: 
  313: 
  314: def test_info_memory_usage():
  315:     # Ensure memory usage is displayed, when asserted, on the last line
  316:     dtypes = [
  317:         "int64",
  318:         "float64",
  319:         "datetime64[ns]",
  320:         "timedelta64[ns]",
  321:         "complex128",
  322:         "object",
  323:         "bool",
  324:     ]
  325:     data = {}
  326:     n = 10
  327:     for i, dtype in enumerate(dtypes):
  328:         data[i] = np.random.default_rng(2).integers(2, size=n).astype(dtype)
  329:     df = DataFrame(data)
  330:     buf = StringIO()
  331: 
  332:     # display memory usage case
  333:     df.info(buf=buf, memory_usage=True)
  334:     res = buf.getvalue().splitlines()
  335:     assert "memory usage: " in res[-1]
  336: 
  337:     # do not display memory usage case
  338:     df.info(buf=buf, memory_usage=False)
  339:     res = buf.getvalue().splitlines()
  340:     assert "memory usage: " not in res[-1]
  341: 
  342:     df.info(buf=buf, memory_usage=True)
  343:     res = buf.getvalue().splitlines()
  344: 
  345:     # memory usage is a lower bound, so print it as XYZ+ MB
  346:     assert re.match(r"memory usage: [^+]+\+", res[-1])
  347: 
  348:     df.iloc[:, :5].info(buf=buf, memory_usage=True)
  349:     res = buf.getvalue().splitlines()
  350: 
  351:     # excluded column with object dtype, so estimate is accurate
  352:     assert not re.match(r"memory usage: [^+]+\+", res[-1])
  353: 
  354:     # Test a DataFrame with duplicate columns
  355:     dtypes = ["int64", "int64", "int64", "float64"]
  356:     data = {}
  357:     n = 100
  358:     for i, dtype in enumerate(dtypes):
  359:         data[i] = np.random.default_rng(2).integers(2, size=n).astype(dtype)
  360:     df = DataFrame(data)
  361:     df.columns = dtypes
  362: 
  363:     df_with_object_index = DataFrame({"a": [1]}, index=["foo"])
  364:     df_with_object_index.info(buf=buf, memory_usage=True)
  365:     res = buf.getvalue().splitlines()
  366:     assert re.match(r"memory usage: [^+]+\+", res[-1])
  367: 
  368:     df_with_object_index.info(buf=buf, memory_usage="deep")
  369:     res = buf.getvalue().splitlines()
  370:     assert re.match(r"memory usage: [^+]+$", res[-1])
  371: 
  372:     # Ensure df size is as expected
  373:     # (cols * rows * bytes) + index size
  374:     df_size = df.memory_usage().sum()
  375:     exp_size = len(dtypes) * n * 8 + df.index.nbytes
  376:     assert df_size == exp_size
  377: 
  378:     # Ensure number of cols in memory_usage is the same as df
  379:     size_df = np.size(df.columns.values) + 1  # index=True; default
  380:     assert size_df == np.size(df.memory_usage())
  381: 
  382:     # assert deep works only on object
  383:     assert df.memory_usage().sum() == df.memory_usage(deep=True).sum()
  384: 
  385:     # test for validity
  386:     DataFrame(1, index=["a"], columns=["A"]).memory_usage(index=True)
  387:     DataFrame(1, index=["a"], columns=["A"]).index.nbytes
  388:     df = DataFrame(
  389:         data=1, index=MultiIndex.from_product([["a"], range(1000)]), columns=["A"]
  390:     )
  391:     df.index.nbytes
  392:     df.memory_usage(index=True)
  393:     df.index.values.nbytes
  394: 
  395:     mem = df.memory_usage(deep=True).sum()
  396:     assert mem > 0
  397: 
  398: 
  399: @pytest.mark.skipif(PYPY, reason="on PyPy deep=True doesn't change result")
  400: def test_info_memory_usage_deep_not_pypy():
  401:     df_with_object_index = DataFrame({"a": [1]}, index=["foo"])
  402:     assert (
  403:         df_with_object_index.memory_usage(index=True, deep=True).sum()
  404:         > df_with_object_index.memory_usage(index=True).sum()
  405:     )
  406: 
  407:     df_object = DataFrame({"a": ["a"]})
  408:     assert df_object.memory_usage(deep=True).sum() > df_object.memory_usage().sum()
  409: 
  410: 
  411: @pytest.mark.xfail(not PYPY, reason="on PyPy deep=True does not change result")
  412: def test_info_memory_usage_deep_pypy():
  413:     df_with_object_index = DataFrame({"a": [1]}, index=["foo"])
  414:     assert (
  415:         df_with_object_index.memory_usage(index=True, deep=True).sum()
  416:         == df_with_object_index.memory_usage(index=True).sum()
  417:     )
  418: 
  419:     df_object = DataFrame({"a": ["a"]})
  420:     assert df_object.memory_usage(deep=True).sum() == df_object.memory_usage().sum()
  421: 
  422: 
  423: @pytest.mark.skipif(PYPY, reason="PyPy getsizeof() fails by design")
  424: def test_usage_via_getsizeof():
  425:     df = DataFrame(
  426:         data=1, index=MultiIndex.from_product([["a"], range(1000)]), columns=["A"]
  427:     )
  428:     mem = df.memory_usage(deep=True).sum()
  429:     # sys.getsizeof will call the .memory_usage with
  430:     # deep=True, and add on some GC overhead
  431:     diff = mem - sys.getsizeof(df)
  432:     assert abs(diff) < 100
  433: 
  434: 
  435: def test_info_memory_usage_qualified():
  436:     buf = StringIO()
  437:     df = DataFrame(1, columns=list("ab"), index=[1, 2, 3])
  438:     df.info(buf=buf)
  439:     assert "+" not in buf.getvalue()
  440: 
  441:     buf = StringIO()
  442:     df = DataFrame(1, columns=list("ab"), index=list("ABC"))
  443:     df.info(buf=buf)
  444:     assert "+" in buf.getvalue()
  445: 
  446:     buf = StringIO()
  447:     df = DataFrame(
  448:         1, columns=list("ab"), index=MultiIndex.from_product([range(3), range(3)])
  449:     )
  450:     df.info(buf=buf)
  451:     assert "+" not in buf.getvalue()
  452: 
  453:     buf = StringIO()
  454:     df = DataFrame(
  455:         1, columns=list("ab"), index=MultiIndex.from_product([range(3), ["foo", "bar"]])
  456:     )
  457:     df.info(buf=buf)
  458:     assert "+" in buf.getvalue()
  459: 
  460: 
  461: def test_info_memory_usage_bug_on_multiindex():
  462:     # GH 14308
  463:     # memory usage introspection should not materialize .values
  464: 
  465:     def memory_usage(f):
  466:         return f.memory_usage(deep=True).sum()
  467: 
  468:     N = 100
  469:     M = len(ascii_uppercase)
  470:     index = MultiIndex.from_product(
  471:         [list(ascii_uppercase), date_range("20160101", periods=N)],
  472:         names=["id", "date"],
  473:     )
  474:     df = DataFrame(
  475:         {"value": np.random.default_rng(2).standard_normal(N * M)}, index=index
  476:     )
  477: 
  478:     unstacked = df.unstack("id")
  479:     assert df.values.nbytes == unstacked.values.nbytes
  480:     assert memory_usage(df) > memory_usage(unstacked)
  481: 
  482:     # high upper bound
  483:     assert memory_usage(unstacked) - memory_usage(df) < 2000
  484: 
  485: 
  486: def test_info_categorical():
  487:     # GH14298
  488:     idx = CategoricalIndex(["a", "b"])
  489:     df = DataFrame(np.zeros((2, 2)), index=idx, columns=idx)
  490: 
  491:     buf = StringIO()
  492:     df.info(buf=buf)
  493: 
  494: 
  495: @pytest.mark.xfail(not IS64, reason="GH 36579: fail on 32-bit system")
  496: def test_info_int_columns():
  497:     # GH#37245
  498:     df = DataFrame({1: [1, 2], 2: [2, 3]}, index=["A", "B"])
  499:     buf = StringIO()
  500:     df.info(show_counts=True, buf=buf)
  501:     result = buf.getvalue()
  502:     expected = textwrap.dedent(
  503:         """\
  504:         <class 'pandas.core.frame.DataFrame'>
  505:         Index: 2 entries, A to B
  506:         Data columns (total 2 columns):
  507:          #   Column  Non-Null Count  Dtype
  508:         ---  ------  --------------  -----
  509:          0   1       2 non-null      int64
  510:          1   2       2 non-null      int64
  511:         dtypes: int64(2)
  512:         memory usage: 48.0+ bytes
  513:         """
  514:     )
  515:     assert result == expected
  516: 
  517: 
  518: def test_memory_usage_empty_no_warning():
  519:     # GH#50066
  520:     df = DataFrame(index=["a", "b"])
  521:     with tm.assert_produces_warning(None):
  522:         result = df.memory_usage()
  523:     expected = Series(16 if IS64 else 8, index=["Index"])
  524:     tm.assert_series_equal(result, expected)
  525: 
  526: 
  527: @pytest.mark.single_cpu
  528: def test_info_compute_numba():
  529:     # GH#51922
  530:     pytest.importorskip("numba")
  531:     df = DataFrame([[1, 2], [3, 4]])
  532: 
  533:     with option_context("compute.use_numba", True):
  534:         buf = StringIO()
  535:         df.info(buf=buf)
  536:         result = buf.getvalue()
  537: 
  538:     buf = StringIO()
  539:     df.info(buf=buf)
  540:     expected = buf.getvalue()
  541:     assert result == expected
  542: 
  543: 
  544: @pytest.mark.parametrize(
  545:     "row, columns, show_counts, result",
  546:     [
  547:         [20, 20, None, True],
  548:         [20, 20, True, True],
  549:         [20, 20, False, False],
  550:         [5, 5, None, False],
  551:         [5, 5, True, False],
  552:         [5, 5, False, False],
  553:     ],
  554: )
  555: def test_info_show_counts(row, columns, show_counts, result):
  556:     # Explicit cast to float to avoid implicit cast when setting nan
  557:     df = DataFrame(1, columns=range(10), index=range(10)).astype({1: "float"})
  558:     df.iloc[1, 1] = np.nan
  559: 
  560:     with option_context(
  561:         "display.max_info_rows", row, "display.max_info_columns", columns
  562:     ):
  563:         with StringIO() as buf:
  564:             df.info(buf=buf, show_counts=show_counts)
  565:             assert ("non-null" in buf.getvalue()) is result
