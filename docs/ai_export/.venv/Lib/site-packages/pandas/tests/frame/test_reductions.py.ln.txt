    1: from datetime import timedelta
    2: from decimal import Decimal
    3: import re
    4: 
    5: from dateutil.tz import tzlocal
    6: import numpy as np
    7: import pytest
    8: 
    9: from pandas._config import using_pyarrow_string_dtype
   10: 
   11: from pandas.compat import (
   12:     IS64,
   13:     is_platform_windows,
   14: )
   15: from pandas.compat.numpy import np_version_gt2
   16: import pandas.util._test_decorators as td
   17: 
   18: import pandas as pd
   19: from pandas import (
   20:     Categorical,
   21:     CategoricalDtype,
   22:     DataFrame,
   23:     DatetimeIndex,
   24:     Index,
   25:     PeriodIndex,
   26:     RangeIndex,
   27:     Series,
   28:     Timestamp,
   29:     date_range,
   30:     isna,
   31:     notna,
   32:     to_datetime,
   33:     to_timedelta,
   34: )
   35: import pandas._testing as tm
   36: from pandas.core import (
   37:     algorithms,
   38:     nanops,
   39: )
   40: 
   41: is_windows_np2_or_is32 = (is_platform_windows() and not np_version_gt2) or not IS64
   42: is_windows_or_is32 = is_platform_windows() or not IS64
   43: 
   44: 
   45: def make_skipna_wrapper(alternative, skipna_alternative=None):
   46:     """
   47:     Create a function for calling on an array.
   48: 
   49:     Parameters
   50:     ----------
   51:     alternative : function
   52:         The function to be called on the array with no NaNs.
   53:         Only used when 'skipna_alternative' is None.
   54:     skipna_alternative : function
   55:         The function to be called on the original array
   56: 
   57:     Returns
   58:     -------
   59:     function
   60:     """
   61:     if skipna_alternative:
   62: 
   63:         def skipna_wrapper(x):
   64:             return skipna_alternative(x.values)
   65: 
   66:     else:
   67: 
   68:         def skipna_wrapper(x):
   69:             nona = x.dropna()
   70:             if len(nona) == 0:
   71:                 return np.nan
   72:             return alternative(nona)
   73: 
   74:     return skipna_wrapper
   75: 
   76: 
   77: def assert_stat_op_calc(
   78:     opname,
   79:     alternative,
   80:     frame,
   81:     has_skipna=True,
   82:     check_dtype=True,
   83:     check_dates=False,
   84:     rtol=1e-5,
   85:     atol=1e-8,
   86:     skipna_alternative=None,
   87: ):
   88:     """
   89:     Check that operator opname works as advertised on frame
   90: 
   91:     Parameters
   92:     ----------
   93:     opname : str
   94:         Name of the operator to test on frame
   95:     alternative : function
   96:         Function that opname is tested against; i.e. "frame.opname()" should
   97:         equal "alternative(frame)".
   98:     frame : DataFrame
   99:         The object that the tests are executed on
  100:     has_skipna : bool, default True
  101:         Whether the method "opname" has the kwarg "skip_na"
  102:     check_dtype : bool, default True
  103:         Whether the dtypes of the result of "frame.opname()" and
  104:         "alternative(frame)" should be checked.
  105:     check_dates : bool, default false
  106:         Whether opname should be tested on a Datetime Series
  107:     rtol : float, default 1e-5
  108:         Relative tolerance.
  109:     atol : float, default 1e-8
  110:         Absolute tolerance.
  111:     skipna_alternative : function, default None
  112:         NaN-safe version of alternative
  113:     """
  114:     f = getattr(frame, opname)
  115: 
  116:     if check_dates:
  117:         df = DataFrame({"b": date_range("1/1/2001", periods=2)})
  118:         with tm.assert_produces_warning(None):
  119:             result = getattr(df, opname)()
  120:         assert isinstance(result, Series)
  121: 
  122:         df["a"] = range(len(df))
  123:         with tm.assert_produces_warning(None):
  124:             result = getattr(df, opname)()
  125:         assert isinstance(result, Series)
  126:         assert len(result)
  127: 
  128:     if has_skipna:
  129: 
  130:         def wrapper(x):
  131:             return alternative(x.values)
  132: 
  133:         skipna_wrapper = make_skipna_wrapper(alternative, skipna_alternative)
  134:         result0 = f(axis=0, skipna=False)
  135:         result1 = f(axis=1, skipna=False)
  136:         tm.assert_series_equal(
  137:             result0, frame.apply(wrapper), check_dtype=check_dtype, rtol=rtol, atol=atol
  138:         )
  139:         tm.assert_series_equal(
  140:             result1,
  141:             frame.apply(wrapper, axis=1),
  142:             rtol=rtol,
  143:             atol=atol,
  144:         )
  145:     else:
  146:         skipna_wrapper = alternative
  147: 
  148:     result0 = f(axis=0)
  149:     result1 = f(axis=1)
  150:     tm.assert_series_equal(
  151:         result0,
  152:         frame.apply(skipna_wrapper),
  153:         check_dtype=check_dtype,
  154:         rtol=rtol,
  155:         atol=atol,
  156:     )
  157: 
  158:     if opname in ["sum", "prod"]:
  159:         expected = frame.apply(skipna_wrapper, axis=1)
  160:         tm.assert_series_equal(
  161:             result1, expected, check_dtype=False, rtol=rtol, atol=atol
  162:         )
  163: 
  164:     # check dtypes
  165:     if check_dtype:
  166:         lcd_dtype = frame.values.dtype
  167:         assert lcd_dtype == result0.dtype
  168:         assert lcd_dtype == result1.dtype
  169: 
  170:     # bad axis
  171:     with pytest.raises(ValueError, match="No axis named 2"):
  172:         f(axis=2)
  173: 
  174:     # all NA case
  175:     if has_skipna:
  176:         all_na = frame * np.nan
  177:         r0 = getattr(all_na, opname)(axis=0)
  178:         r1 = getattr(all_na, opname)(axis=1)
  179:         if opname in ["sum", "prod"]:
  180:             unit = 1 if opname == "prod" else 0  # result for empty sum/prod
  181:             expected = Series(unit, index=r0.index, dtype=r0.dtype)
  182:             tm.assert_series_equal(r0, expected)
  183:             expected = Series(unit, index=r1.index, dtype=r1.dtype)
  184:             tm.assert_series_equal(r1, expected)
  185: 
  186: 
  187: @pytest.fixture
  188: def bool_frame_with_na():
  189:     """
  190:     Fixture for DataFrame of booleans with index of unique strings
  191: 
  192:     Columns are ['A', 'B', 'C', 'D']; some entries are missing
  193:     """
  194:     df = DataFrame(
  195:         np.concatenate(
  196:             [np.ones((15, 4), dtype=bool), np.zeros((15, 4), dtype=bool)], axis=0
  197:         ),
  198:         index=Index([f"foo_{i}" for i in range(30)], dtype=object),
  199:         columns=Index(list("ABCD"), dtype=object),
  200:         dtype=object,
  201:     )
  202:     # set some NAs
  203:     df.iloc[5:10] = np.nan
  204:     df.iloc[15:20, -2:] = np.nan
  205:     return df
  206: 
  207: 
  208: @pytest.fixture
  209: def float_frame_with_na():
  210:     """
  211:     Fixture for DataFrame of floats with index of unique strings
  212: 
  213:     Columns are ['A', 'B', 'C', 'D']; some entries are missing
  214:     """
  215:     df = DataFrame(
  216:         np.random.default_rng(2).standard_normal((30, 4)),
  217:         index=Index([f"foo_{i}" for i in range(30)], dtype=object),
  218:         columns=Index(list("ABCD"), dtype=object),
  219:     )
  220:     # set some NAs
  221:     df.iloc[5:10] = np.nan
  222:     df.iloc[15:20, -2:] = np.nan
  223:     return df
  224: 
  225: 
  226: class TestDataFrameAnalytics:
  227:     # ---------------------------------------------------------------------
  228:     # Reductions
  229:     @pytest.mark.parametrize("axis", [0, 1])
  230:     @pytest.mark.parametrize(
  231:         "opname",
  232:         [
  233:             "count",
  234:             "sum",
  235:             "mean",
  236:             "product",
  237:             "median",
  238:             "min",
  239:             "max",
  240:             "nunique",
  241:             "var",
  242:             "std",
  243:             "sem",
  244:             pytest.param("skew", marks=td.skip_if_no("scipy")),
  245:             pytest.param("kurt", marks=td.skip_if_no("scipy")),
  246:         ],
  247:     )
  248:     def test_stat_op_api_float_string_frame(
  249:         self, float_string_frame, axis, opname, using_infer_string
  250:     ):
  251:         if (
  252:             (opname in ("sum", "min", "max") and axis == 0)
  253:             or opname
  254:             in (
  255:                 "count",
  256:                 "nunique",
  257:             )
  258:         ) and not (using_infer_string and opname == "sum"):
  259:             getattr(float_string_frame, opname)(axis=axis)
  260:         else:
  261:             if opname in ["var", "std", "sem", "skew", "kurt"]:
  262:                 msg = "could not convert string to float: 'bar'"
  263:             elif opname == "product":
  264:                 if axis == 1:
  265:                     msg = "can't multiply sequence by non-int of type 'float'"
  266:                 else:
  267:                     msg = "can't multiply sequence by non-int of type 'str'"
  268:             elif opname == "sum":
  269:                 msg = r"unsupported operand type\(s\) for \+: 'float' and 'str'"
  270:             elif opname == "mean":
  271:                 if axis == 0:
  272:                     # different message on different builds
  273:                     msg = "|".join(
  274:                         [
  275:                             r"Could not convert \['.*'\] to numeric",
  276:                             "Could not convert string '(bar){30}' to numeric",
  277:                         ]
  278:                     )
  279:                 else:
  280:                     msg = r"unsupported operand type\(s\) for \+: 'float' and 'str'"
  281:             elif opname in ["min", "max"]:
  282:                 msg = "'[><]=' not supported between instances of 'float' and 'str'"
  283:             elif opname == "median":
  284:                 msg = re.compile(
  285:                     r"Cannot convert \[.*\] to numeric|does not support", flags=re.S
  286:                 )
  287:             if not isinstance(msg, re.Pattern):
  288:                 msg = msg + "|does not support"
  289:             with pytest.raises(TypeError, match=msg):
  290:                 getattr(float_string_frame, opname)(axis=axis)
  291:         if opname != "nunique":
  292:             getattr(float_string_frame, opname)(axis=axis, numeric_only=True)
  293: 
  294:     @pytest.mark.parametrize("axis", [0, 1])
  295:     @pytest.mark.parametrize(
  296:         "opname",
  297:         [
  298:             "count",
  299:             "sum",
  300:             "mean",
  301:             "product",
  302:             "median",
  303:             "min",
  304:             "max",
  305:             "var",
  306:             "std",
  307:             "sem",
  308:             pytest.param("skew", marks=td.skip_if_no("scipy")),
  309:             pytest.param("kurt", marks=td.skip_if_no("scipy")),
  310:         ],
  311:     )
  312:     def test_stat_op_api_float_frame(self, float_frame, axis, opname):
  313:         getattr(float_frame, opname)(axis=axis, numeric_only=False)
  314: 
  315:     def test_stat_op_calc(self, float_frame_with_na, mixed_float_frame):
  316:         def count(s):
  317:             return notna(s).sum()
  318: 
  319:         def nunique(s):
  320:             return len(algorithms.unique1d(s.dropna()))
  321: 
  322:         def var(x):
  323:             return np.var(x, ddof=1)
  324: 
  325:         def std(x):
  326:             return np.std(x, ddof=1)
  327: 
  328:         def sem(x):
  329:             return np.std(x, ddof=1) / np.sqrt(len(x))
  330: 
  331:         assert_stat_op_calc(
  332:             "nunique",
  333:             nunique,
  334:             float_frame_with_na,
  335:             has_skipna=False,
  336:             check_dtype=False,
  337:             check_dates=True,
  338:         )
  339: 
  340:         # GH#32571: rol needed for flaky CI builds
  341:         # mixed types (with upcasting happening)
  342:         assert_stat_op_calc(
  343:             "sum",
  344:             np.sum,
  345:             mixed_float_frame.astype("float32"),
  346:             check_dtype=False,
  347:             rtol=1e-3,
  348:         )
  349: 
  350:         assert_stat_op_calc(
  351:             "sum", np.sum, float_frame_with_na, skipna_alternative=np.nansum
  352:         )
  353:         assert_stat_op_calc("mean", np.mean, float_frame_with_na, check_dates=True)
  354:         assert_stat_op_calc(
  355:             "product", np.prod, float_frame_with_na, skipna_alternative=np.nanprod
  356:         )
  357: 
  358:         assert_stat_op_calc("var", var, float_frame_with_na)
  359:         assert_stat_op_calc("std", std, float_frame_with_na)
  360:         assert_stat_op_calc("sem", sem, float_frame_with_na)
  361: 
  362:         assert_stat_op_calc(
  363:             "count",
  364:             count,
  365:             float_frame_with_na,
  366:             has_skipna=False,
  367:             check_dtype=False,
  368:             check_dates=True,
  369:         )
  370: 
  371:     def test_stat_op_calc_skew_kurtosis(self, float_frame_with_na):
  372:         sp_stats = pytest.importorskip("scipy.stats")
  373: 
  374:         def skewness(x):
  375:             if len(x) < 3:
  376:                 return np.nan
  377:             return sp_stats.skew(x, bias=False)
  378: 
  379:         def kurt(x):
  380:             if len(x) < 4:
  381:                 return np.nan
  382:             return sp_stats.kurtosis(x, bias=False)
  383: 
  384:         assert_stat_op_calc("skew", skewness, float_frame_with_na)
  385:         assert_stat_op_calc("kurt", kurt, float_frame_with_na)
  386: 
  387:     def test_median(self, float_frame_with_na, int_frame):
  388:         def wrapper(x):
  389:             if isna(x).any():
  390:                 return np.nan
  391:             return np.median(x)
  392: 
  393:         assert_stat_op_calc("median", wrapper, float_frame_with_na, check_dates=True)
  394:         assert_stat_op_calc(
  395:             "median", wrapper, int_frame, check_dtype=False, check_dates=True
  396:         )
  397: 
  398:     @pytest.mark.parametrize(
  399:         "method", ["sum", "mean", "prod", "var", "std", "skew", "min", "max"]
  400:     )
  401:     @pytest.mark.parametrize(
  402:         "df",
  403:         [
  404:             DataFrame(
  405:                 {
  406:                     "a": [
  407:                         -0.00049987540199591344,
  408:                         -0.0016467257772919831,
  409:                         0.00067695870775883013,
  410:                     ],
  411:                     "b": [-0, -0, 0.0],
  412:                     "c": [
  413:                         0.00031111847529610595,
  414:                         0.0014902627951905339,
  415:                         -0.00094099200035979691,
  416:                     ],
  417:                 },
  418:                 index=["foo", "bar", "baz"],
  419:                 dtype="O",
  420:             ),
  421:             DataFrame({0: [np.nan, 2], 1: [np.nan, 3], 2: [np.nan, 4]}, dtype=object),
  422:         ],
  423:     )
  424:     @pytest.mark.filterwarnings("ignore:Mismatched null-like values:FutureWarning")
  425:     def test_stat_operators_attempt_obj_array(self, method, df, axis):
  426:         # GH#676
  427:         assert df.values.dtype == np.object_
  428:         result = getattr(df, method)(axis=axis)
  429:         expected = getattr(df.astype("f8"), method)(axis=axis).astype(object)
  430:         if axis in [1, "columns"] and method in ["min", "max"]:
  431:             expected[expected.isna()] = None
  432:         tm.assert_series_equal(result, expected)
  433: 
  434:     @pytest.mark.parametrize("op", ["mean", "std", "var", "skew", "kurt", "sem"])
  435:     def test_mixed_ops(self, op):
  436:         # GH#16116
  437:         df = DataFrame(
  438:             {
  439:                 "int": [1, 2, 3, 4],
  440:                 "float": [1.0, 2.0, 3.0, 4.0],
  441:                 "str": ["a", "b", "c", "d"],
  442:             }
  443:         )
  444:         msg = "|".join(
  445:             [
  446:                 "Could not convert",
  447:                 "could not convert",
  448:                 "can't multiply sequence by non-int",
  449:                 "does not support",
  450:             ]
  451:         )
  452:         with pytest.raises(TypeError, match=msg):
  453:             getattr(df, op)()
  454: 
  455:         with pd.option_context("use_bottleneck", False):
  456:             msg = "|".join(
  457:                 [
  458:                     "Could not convert",
  459:                     "could not convert",
  460:                     "can't multiply sequence by non-int",
  461:                     "does not support",
  462:                 ]
  463:             )
  464:             with pytest.raises(TypeError, match=msg):
  465:                 getattr(df, op)()
  466: 
  467:     @pytest.mark.xfail(
  468:         using_pyarrow_string_dtype(), reason="sum doesn't work for arrow strings"
  469:     )
  470:     def test_reduce_mixed_frame(self):
  471:         # GH 6806
  472:         df = DataFrame(
  473:             {
  474:                 "bool_data": [True, True, False, False, False],
  475:                 "int_data": [10, 20, 30, 40, 50],
  476:                 "string_data": ["a", "b", "c", "d", "e"],
  477:             }
  478:         )
  479:         df.reindex(columns=["bool_data", "int_data", "string_data"])
  480:         test = df.sum(axis=0)
  481:         tm.assert_numpy_array_equal(
  482:             test.values, np.array([2, 150, "abcde"], dtype=object)
  483:         )
  484:         alt = df.T.sum(axis=1)
  485:         tm.assert_series_equal(test, alt)
  486: 
  487:     def test_nunique(self):
  488:         df = DataFrame({"A": [1, 1, 1], "B": [1, 2, 3], "C": [1, np.nan, 3]})
  489:         tm.assert_series_equal(df.nunique(), Series({"A": 1, "B": 3, "C": 2}))
  490:         tm.assert_series_equal(
  491:             df.nunique(dropna=False), Series({"A": 1, "B": 3, "C": 3})
  492:         )
  493:         tm.assert_series_equal(df.nunique(axis=1), Series({0: 1, 1: 2, 2: 2}))
  494:         tm.assert_series_equal(
  495:             df.nunique(axis=1, dropna=False), Series({0: 1, 1: 3, 2: 2})
  496:         )
  497: 
  498:     @pytest.mark.parametrize("tz", [None, "UTC"])
  499:     def test_mean_mixed_datetime_numeric(self, tz):
  500:         # https://github.com/pandas-dev/pandas/issues/24752
  501:         df = DataFrame({"A": [1, 1], "B": [Timestamp("2000", tz=tz)] * 2})
  502:         result = df.mean()
  503:         expected = Series([1.0, Timestamp("2000", tz=tz)], index=["A", "B"])
  504:         tm.assert_series_equal(result, expected)
  505: 
  506:     @pytest.mark.parametrize("tz", [None, "UTC"])
  507:     def test_mean_includes_datetimes(self, tz):
  508:         # https://github.com/pandas-dev/pandas/issues/24752
  509:         # Behavior in 0.24.0rc1 was buggy.
  510:         # As of 2.0 with numeric_only=None we do *not* drop datetime columns
  511:         df = DataFrame({"A": [Timestamp("2000", tz=tz)] * 2})
  512:         result = df.mean()
  513: 
  514:         expected = Series([Timestamp("2000", tz=tz)], index=["A"])
  515:         tm.assert_series_equal(result, expected)
  516: 
  517:     def test_mean_mixed_string_decimal(self):
  518:         # GH 11670
  519:         # possible bug when calculating mean of DataFrame?
  520: 
  521:         d = [
  522:             {"A": 2, "B": None, "C": Decimal("628.00")},
  523:             {"A": 1, "B": None, "C": Decimal("383.00")},
  524:             {"A": 3, "B": None, "C": Decimal("651.00")},
  525:             {"A": 2, "B": None, "C": Decimal("575.00")},
  526:             {"A": 4, "B": None, "C": Decimal("1114.00")},
  527:             {"A": 1, "B": "TEST", "C": Decimal("241.00")},
  528:             {"A": 2, "B": None, "C": Decimal("572.00")},
  529:             {"A": 4, "B": None, "C": Decimal("609.00")},
  530:             {"A": 3, "B": None, "C": Decimal("820.00")},
  531:             {"A": 5, "B": None, "C": Decimal("1223.00")},
  532:         ]
  533: 
  534:         df = DataFrame(d)
  535: 
  536:         with pytest.raises(
  537:             TypeError, match="unsupported operand type|does not support"
  538:         ):
  539:             df.mean()
  540:         result = df[["A", "C"]].mean()
  541:         expected = Series([2.7, 681.6], index=["A", "C"], dtype=object)
  542:         tm.assert_series_equal(result, expected)
  543: 
  544:     def test_var_std(self, datetime_frame):
  545:         result = datetime_frame.std(ddof=4)
  546:         expected = datetime_frame.apply(lambda x: x.std(ddof=4))
  547:         tm.assert_almost_equal(result, expected)
  548: 
  549:         result = datetime_frame.var(ddof=4)
  550:         expected = datetime_frame.apply(lambda x: x.var(ddof=4))
  551:         tm.assert_almost_equal(result, expected)
  552: 
  553:         arr = np.repeat(np.random.default_rng(2).random((1, 1000)), 1000, 0)
  554:         result = nanops.nanvar(arr, axis=0)
  555:         assert not (result < 0).any()
  556: 
  557:         with pd.option_context("use_bottleneck", False):
  558:             result = nanops.nanvar(arr, axis=0)
  559:             assert not (result < 0).any()
  560: 
  561:     @pytest.mark.parametrize("meth", ["sem", "var", "std"])
  562:     def test_numeric_only_flag(self, meth):
  563:         # GH 9201
  564:         df1 = DataFrame(
  565:             np.random.default_rng(2).standard_normal((5, 3)),
  566:             columns=["foo", "bar", "baz"],
  567:         )
  568:         # Cast to object to avoid implicit cast when setting entry to "100" below
  569:         df1 = df1.astype({"foo": object})
  570:         # set one entry to a number in str format
  571:         df1.loc[0, "foo"] = "100"
  572: 
  573:         df2 = DataFrame(
  574:             np.random.default_rng(2).standard_normal((5, 3)),
  575:             columns=["foo", "bar", "baz"],
  576:         )
  577:         # Cast to object to avoid implicit cast when setting entry to "a" below
  578:         df2 = df2.astype({"foo": object})
  579:         # set one entry to a non-number str
  580:         df2.loc[0, "foo"] = "a"
  581: 
  582:         result = getattr(df1, meth)(axis=1, numeric_only=True)
  583:         expected = getattr(df1[["bar", "baz"]], meth)(axis=1)
  584:         tm.assert_series_equal(expected, result)
  585: 
  586:         result = getattr(df2, meth)(axis=1, numeric_only=True)
  587:         expected = getattr(df2[["bar", "baz"]], meth)(axis=1)
  588:         tm.assert_series_equal(expected, result)
  589: 
  590:         # df1 has all numbers, df2 has a letter inside
  591:         msg = r"unsupported operand type\(s\) for -: 'float' and 'str'"
  592:         with pytest.raises(TypeError, match=msg):
  593:             getattr(df1, meth)(axis=1, numeric_only=False)
  594:         msg = "could not convert string to float: 'a'"
  595:         with pytest.raises(TypeError, match=msg):
  596:             getattr(df2, meth)(axis=1, numeric_only=False)
  597: 
  598:     def test_sem(self, datetime_frame):
  599:         result = datetime_frame.sem(ddof=4)
  600:         expected = datetime_frame.apply(lambda x: x.std(ddof=4) / np.sqrt(len(x)))
  601:         tm.assert_almost_equal(result, expected)
  602: 
  603:         arr = np.repeat(np.random.default_rng(2).random((1, 1000)), 1000, 0)
  604:         result = nanops.nansem(arr, axis=0)
  605:         assert not (result < 0).any()
  606: 
  607:         with pd.option_context("use_bottleneck", False):
  608:             result = nanops.nansem(arr, axis=0)
  609:             assert not (result < 0).any()
  610: 
  611:     @pytest.mark.parametrize(
  612:         "dropna, expected",
  613:         [
  614:             (
  615:                 True,
  616:                 {
  617:                     "A": [12],
  618:                     "B": [10.0],
  619:                     "C": [1.0],
  620:                     "D": ["a"],
  621:                     "E": Categorical(["a"], categories=["a"]),
  622:                     "F": DatetimeIndex(["2000-01-02"], dtype="M8[ns]"),
  623:                     "G": to_timedelta(["1 days"]),
  624:                 },
  625:             ),
  626:             (
  627:                 False,
  628:                 {
  629:                     "A": [12],
  630:                     "B": [10.0],
  631:                     "C": [np.nan],
  632:                     "D": np.array([np.nan], dtype=object),
  633:                     "E": Categorical([np.nan], categories=["a"]),
  634:                     "F": DatetimeIndex([pd.NaT], dtype="M8[ns]"),
  635:                     "G": to_timedelta([pd.NaT]),
  636:                 },
  637:             ),
  638:             (
  639:                 True,
  640:                 {
  641:                     "H": [8, 9, np.nan, np.nan],
  642:                     "I": [8, 9, np.nan, np.nan],
  643:                     "J": [1, np.nan, np.nan, np.nan],
  644:                     "K": Categorical(["a", np.nan, np.nan, np.nan], categories=["a"]),
  645:                     "L": DatetimeIndex(
  646:                         ["2000-01-02", "NaT", "NaT", "NaT"], dtype="M8[ns]"
  647:                     ),
  648:                     "M": to_timedelta(["1 days", "nan", "nan", "nan"]),
  649:                     "N": [0, 1, 2, 3],
  650:                 },
  651:             ),
  652:             (
  653:                 False,
  654:                 {
  655:                     "H": [8, 9, np.nan, np.nan],
  656:                     "I": [8, 9, np.nan, np.nan],
  657:                     "J": [1, np.nan, np.nan, np.nan],
  658:                     "K": Categorical([np.nan, "a", np.nan, np.nan], categories=["a"]),
  659:                     "L": DatetimeIndex(
  660:                         ["NaT", "2000-01-02", "NaT", "NaT"], dtype="M8[ns]"
  661:                     ),
  662:                     "M": to_timedelta(["nan", "1 days", "nan", "nan"]),
  663:                     "N": [0, 1, 2, 3],
  664:                 },
  665:             ),
  666:         ],
  667:     )
  668:     def test_mode_dropna(self, dropna, expected):
  669:         df = DataFrame(
  670:             {
  671:                 "A": [12, 12, 19, 11],
  672:                 "B": [10, 10, np.nan, 3],
  673:                 "C": [1, np.nan, np.nan, np.nan],
  674:                 "D": Series([np.nan, np.nan, "a", np.nan], dtype=object),
  675:                 "E": Categorical([np.nan, np.nan, "a", np.nan]),
  676:                 "F": DatetimeIndex(["NaT", "2000-01-02", "NaT", "NaT"], dtype="M8[ns]"),
  677:                 "G": to_timedelta(["1 days", "nan", "nan", "nan"]),
  678:                 "H": [8, 8, 9, 9],
  679:                 "I": [9, 9, 8, 8],
  680:                 "J": [1, 1, np.nan, np.nan],
  681:                 "K": Categorical(["a", np.nan, "a", np.nan]),
  682:                 "L": DatetimeIndex(
  683:                     ["2000-01-02", "2000-01-02", "NaT", "NaT"], dtype="M8[ns]"
  684:                 ),
  685:                 "M": to_timedelta(["1 days", "nan", "1 days", "nan"]),
  686:                 "N": np.arange(4, dtype="int64"),
  687:             }
  688:         )
  689: 
  690:         result = df[sorted(expected.keys())].mode(dropna=dropna)
  691:         expected = DataFrame(expected)
  692:         tm.assert_frame_equal(result, expected)
  693: 
  694:     def test_mode_sortwarning(self, using_infer_string):
  695:         # Check for the warning that is raised when the mode
  696:         # results cannot be sorted
  697: 
  698:         df = DataFrame({"A": [np.nan, np.nan, "a", "a"]})
  699:         expected = DataFrame({"A": ["a", np.nan]})
  700: 
  701:         warning = None if using_infer_string else UserWarning
  702:         with tm.assert_produces_warning(warning):
  703:             result = df.mode(dropna=False)
  704:             result = result.sort_values(by="A").reset_index(drop=True)
  705: 
  706:         tm.assert_frame_equal(result, expected)
  707: 
  708:     def test_mode_empty_df(self):
  709:         df = DataFrame([], columns=["a", "b"])
  710:         result = df.mode()
  711:         expected = DataFrame([], columns=["a", "b"], index=Index([], dtype=np.int64))
  712:         tm.assert_frame_equal(result, expected)
  713: 
  714:     def test_operators_timedelta64(self):
  715:         df = DataFrame(
  716:             {
  717:                 "A": date_range("2012-1-1", periods=3, freq="D"),
  718:                 "B": date_range("2012-1-2", periods=3, freq="D"),
  719:                 "C": Timestamp("20120101") - timedelta(minutes=5, seconds=5),
  720:             }
  721:         )
  722: 
  723:         diffs = DataFrame({"A": df["A"] - df["C"], "B": df["A"] - df["B"]})
  724: 
  725:         # min
  726:         result = diffs.min()
  727:         assert result.iloc[0] == diffs.loc[0, "A"]
  728:         assert result.iloc[1] == diffs.loc[0, "B"]
  729: 
  730:         result = diffs.min(axis=1)
  731:         assert (result == diffs.loc[0, "B"]).all()
  732: 
  733:         # max
  734:         result = diffs.max()
  735:         assert result.iloc[0] == diffs.loc[2, "A"]
  736:         assert result.iloc[1] == diffs.loc[2, "B"]
  737: 
  738:         result = diffs.max(axis=1)
  739:         assert (result == diffs["A"]).all()
  740: 
  741:         # abs
  742:         result = diffs.abs()
  743:         result2 = abs(diffs)
  744:         expected = DataFrame({"A": df["A"] - df["C"], "B": df["B"] - df["A"]})
  745:         tm.assert_frame_equal(result, expected)
  746:         tm.assert_frame_equal(result2, expected)
  747: 
  748:         # mixed frame
  749:         mixed = diffs.copy()
  750:         mixed["C"] = "foo"
  751:         mixed["D"] = 1
  752:         mixed["E"] = 1.0
  753:         mixed["F"] = Timestamp("20130101")
  754: 
  755:         # results in an object array
  756:         result = mixed.min()
  757:         expected = Series(
  758:             [
  759:                 pd.Timedelta(timedelta(seconds=5 * 60 + 5)),
  760:                 pd.Timedelta(timedelta(days=-1)),
  761:                 "foo",
  762:                 1,
  763:                 1.0,
  764:                 Timestamp("20130101"),
  765:             ],
  766:             index=mixed.columns,
  767:         )
  768:         tm.assert_series_equal(result, expected)
  769: 
  770:         # excludes non-numeric
  771:         result = mixed.min(axis=1, numeric_only=True)
  772:         expected = Series([1, 1, 1.0], index=[0, 1, 2])
  773:         tm.assert_series_equal(result, expected)
  774: 
  775:         # works when only those columns are selected
  776:         result = mixed[["A", "B"]].min(1)
  777:         expected = Series([timedelta(days=-1)] * 3)
  778:         tm.assert_series_equal(result, expected)
  779: 
  780:         result = mixed[["A", "B"]].min()
  781:         expected = Series(
  782:             [timedelta(seconds=5 * 60 + 5), timedelta(days=-1)], index=["A", "B"]
  783:         )
  784:         tm.assert_series_equal(result, expected)
  785: 
  786:         # GH 3106
  787:         df = DataFrame(
  788:             {
  789:                 "time": date_range("20130102", periods=5),
  790:                 "time2": date_range("20130105", periods=5),
  791:             }
  792:         )
  793:         df["off1"] = df["time2"] - df["time"]
  794:         assert df["off1"].dtype == "timedelta64[ns]"
  795: 
  796:         df["off2"] = df["time"] - df["time2"]
  797:         df._consolidate_inplace()
  798:         assert df["off1"].dtype == "timedelta64[ns]"
  799:         assert df["off2"].dtype == "timedelta64[ns]"
  800: 
  801:     def test_std_timedelta64_skipna_false(self):
  802:         # GH#37392
  803:         tdi = pd.timedelta_range("1 Day", periods=10)
  804:         df = DataFrame({"A": tdi, "B": tdi}, copy=True)
  805:         df.iloc[-2, -1] = pd.NaT
  806: 
  807:         result = df.std(skipna=False)
  808:         expected = Series(
  809:             [df["A"].std(), pd.NaT], index=["A", "B"], dtype="timedelta64[ns]"
  810:         )
  811:         tm.assert_series_equal(result, expected)
  812: 
  813:         result = df.std(axis=1, skipna=False)
  814:         expected = Series([pd.Timedelta(0)] * 8 + [pd.NaT, pd.Timedelta(0)])
  815:         tm.assert_series_equal(result, expected)
  816: 
  817:     @pytest.mark.parametrize(
  818:         "values", [["2022-01-01", "2022-01-02", pd.NaT, "2022-01-03"], 4 * [pd.NaT]]
  819:     )
  820:     def test_std_datetime64_with_nat(
  821:         self, values, skipna, using_array_manager, request, unit
  822:     ):
  823:         # GH#51335
  824:         if using_array_manager and (
  825:             not skipna or all(value is pd.NaT for value in values)
  826:         ):
  827:             mark = pytest.mark.xfail(
  828:                 reason="GH#51446: Incorrect type inference on NaT in reduction result"
  829:             )
  830:             request.applymarker(mark)
  831:         dti = to_datetime(values).as_unit(unit)
  832:         df = DataFrame({"a": dti})
  833:         result = df.std(skipna=skipna)
  834:         if not skipna or all(value is pd.NaT for value in values):
  835:             expected = Series({"a": pd.NaT}, dtype=f"timedelta64[{unit}]")
  836:         else:
  837:             # 86400000000000ns == 1 day
  838:             expected = Series({"a": 86400000000000}, dtype=f"timedelta64[{unit}]")
  839:         tm.assert_series_equal(result, expected)
  840: 
  841:     def test_sum_corner(self):
  842:         empty_frame = DataFrame()
  843: 
  844:         axis0 = empty_frame.sum(0)
  845:         axis1 = empty_frame.sum(1)
  846:         assert isinstance(axis0, Series)
  847:         assert isinstance(axis1, Series)
  848:         assert len(axis0) == 0
  849:         assert len(axis1) == 0
  850: 
  851:     @pytest.mark.parametrize(
  852:         "index",
  853:         [
  854:             RangeIndex(0),
  855:             DatetimeIndex([]),
  856:             Index([], dtype=np.int64),
  857:             Index([], dtype=np.float64),
  858:             DatetimeIndex([], freq="ME"),
  859:             PeriodIndex([], freq="D"),
  860:         ],
  861:     )
  862:     def test_axis_1_empty(self, all_reductions, index):
  863:         df = DataFrame(columns=["a"], index=index)
  864:         result = getattr(df, all_reductions)(axis=1)
  865:         if all_reductions in ("any", "all"):
  866:             expected_dtype = "bool"
  867:         elif all_reductions == "count":
  868:             expected_dtype = "int64"
  869:         else:
  870:             expected_dtype = "object"
  871:         expected = Series([], index=index, dtype=expected_dtype)
  872:         tm.assert_series_equal(result, expected)
  873: 
  874:     @pytest.mark.parametrize("method, unit", [("sum", 0), ("prod", 1)])
  875:     @pytest.mark.parametrize("numeric_only", [None, True, False])
  876:     def test_sum_prod_nanops(self, method, unit, numeric_only):
  877:         idx = ["a", "b", "c"]
  878:         df = DataFrame({"a": [unit, unit], "b": [unit, np.nan], "c": [np.nan, np.nan]})
  879:         # The default
  880:         result = getattr(df, method)(numeric_only=numeric_only)
  881:         expected = Series([unit, unit, unit], index=idx, dtype="float64")
  882:         tm.assert_series_equal(result, expected)
  883: 
  884:         # min_count=1
  885:         result = getattr(df, method)(numeric_only=numeric_only, min_count=1)
  886:         expected = Series([unit, unit, np.nan], index=idx)
  887:         tm.assert_series_equal(result, expected)
  888: 
  889:         # min_count=0
  890:         result = getattr(df, method)(numeric_only=numeric_only, min_count=0)
  891:         expected = Series([unit, unit, unit], index=idx, dtype="float64")
  892:         tm.assert_series_equal(result, expected)
  893: 
  894:         result = getattr(df.iloc[1:], method)(numeric_only=numeric_only, min_count=1)
  895:         expected = Series([unit, np.nan, np.nan], index=idx)
  896:         tm.assert_series_equal(result, expected)
  897: 
  898:         # min_count > 1
  899:         df = DataFrame({"A": [unit] * 10, "B": [unit] * 5 + [np.nan] * 5})
  900:         result = getattr(df, method)(numeric_only=numeric_only, min_count=5)
  901:         expected = Series(result, index=["A", "B"])
  902:         tm.assert_series_equal(result, expected)
  903: 
  904:         result = getattr(df, method)(numeric_only=numeric_only, min_count=6)
  905:         expected = Series(result, index=["A", "B"])
  906:         tm.assert_series_equal(result, expected)
  907: 
  908:     def test_sum_nanops_timedelta(self):
  909:         # prod isn't defined on timedeltas
  910:         idx = ["a", "b", "c"]
  911:         df = DataFrame({"a": [0, 0], "b": [0, np.nan], "c": [np.nan, np.nan]})
  912: 
  913:         df2 = df.apply(to_timedelta)
  914: 
  915:         # 0 by default
  916:         result = df2.sum()
  917:         expected = Series([0, 0, 0], dtype="m8[ns]", index=idx)
  918:         tm.assert_series_equal(result, expected)
  919: 
  920:         # min_count=0
  921:         result = df2.sum(min_count=0)
  922:         tm.assert_series_equal(result, expected)
  923: 
  924:         # min_count=1
  925:         result = df2.sum(min_count=1)
  926:         expected = Series([0, 0, np.nan], dtype="m8[ns]", index=idx)
  927:         tm.assert_series_equal(result, expected)
  928: 
  929:     def test_sum_nanops_min_count(self):
  930:         # https://github.com/pandas-dev/pandas/issues/39738
  931:         df = DataFrame({"x": [1, 2, 3], "y": [4, 5, 6]})
  932:         result = df.sum(min_count=10)
  933:         expected = Series([np.nan, np.nan], index=["x", "y"])
  934:         tm.assert_series_equal(result, expected)
  935: 
  936:     @pytest.mark.parametrize("float_type", ["float16", "float32", "float64"])
  937:     @pytest.mark.parametrize(
  938:         "kwargs, expected_result",
  939:         [
  940:             ({"axis": 1, "min_count": 2}, [3.2, 5.3, np.nan]),
  941:             ({"axis": 1, "min_count": 3}, [np.nan, np.nan, np.nan]),
  942:             ({"axis": 1, "skipna": False}, [3.2, 5.3, np.nan]),
  943:         ],
  944:     )
  945:     def test_sum_nanops_dtype_min_count(self, float_type, kwargs, expected_result):
  946:         # GH#46947
  947:         df = DataFrame({"a": [1.0, 2.3, 4.4], "b": [2.2, 3, np.nan]}, dtype=float_type)
  948:         result = df.sum(**kwargs)
  949:         expected = Series(expected_result).astype(float_type)
  950:         tm.assert_series_equal(result, expected)
  951: 
  952:     @pytest.mark.parametrize("float_type", ["float16", "float32", "float64"])
  953:     @pytest.mark.parametrize(
  954:         "kwargs, expected_result",
  955:         [
  956:             ({"axis": 1, "min_count": 2}, [2.0, 4.0, np.nan]),
  957:             ({"axis": 1, "min_count": 3}, [np.nan, np.nan, np.nan]),
  958:             ({"axis": 1, "skipna": False}, [2.0, 4.0, np.nan]),
  959:         ],
  960:     )
  961:     def test_prod_nanops_dtype_min_count(self, float_type, kwargs, expected_result):
  962:         # GH#46947
  963:         df = DataFrame(
  964:             {"a": [1.0, 2.0, 4.4], "b": [2.0, 2.0, np.nan]}, dtype=float_type
  965:         )
  966:         result = df.prod(**kwargs)
  967:         expected = Series(expected_result).astype(float_type)
  968:         tm.assert_series_equal(result, expected)
  969: 
  970:     def test_sum_object(self, float_frame):
  971:         values = float_frame.values.astype(int)
  972:         frame = DataFrame(values, index=float_frame.index, columns=float_frame.columns)
  973:         deltas = frame * timedelta(1)
  974:         deltas.sum()
  975: 
  976:     def test_sum_bool(self, float_frame):
  977:         # ensure this works, bug report
  978:         bools = np.isnan(float_frame)
  979:         bools.sum(1)
  980:         bools.sum(0)
  981: 
  982:     def test_sum_mixed_datetime(self):
  983:         # GH#30886
  984:         df = DataFrame({"A": date_range("2000", periods=4), "B": [1, 2, 3, 4]}).reindex(
  985:             [2, 3, 4]
  986:         )
  987:         with pytest.raises(TypeError, match="does not support reduction 'sum'"):
  988:             df.sum()
  989: 
  990:     def test_mean_corner(self, float_frame, float_string_frame):
  991:         # unit test when have object data
  992:         msg = "Could not convert|does not support"
  993:         with pytest.raises(TypeError, match=msg):
  994:             float_string_frame.mean(axis=0)
  995: 
  996:         # xs sum mixed type, just want to know it works...
  997:         with pytest.raises(TypeError, match="unsupported operand type"):
  998:             float_string_frame.mean(axis=1)
  999: 
 1000:         # take mean of boolean column
 1001:         float_frame["bool"] = float_frame["A"] > 0
 1002:         means = float_frame.mean(0)
 1003:         assert means["bool"] == float_frame["bool"].values.mean()
 1004: 
 1005:     def test_mean_datetimelike(self):
 1006:         # GH#24757 check that datetimelike are excluded by default, handled
 1007:         #  correctly with numeric_only=True
 1008:         #  As of 2.0, datetimelike are *not* excluded with numeric_only=None
 1009: 
 1010:         df = DataFrame(
 1011:             {
 1012:                 "A": np.arange(3),
 1013:                 "B": date_range("2016-01-01", periods=3),
 1014:                 "C": pd.timedelta_range("1D", periods=3),
 1015:                 "D": pd.period_range("2016", periods=3, freq="Y"),
 1016:             }
 1017:         )
 1018:         result = df.mean(numeric_only=True)
 1019:         expected = Series({"A": 1.0})
 1020:         tm.assert_series_equal(result, expected)
 1021: 
 1022:         with pytest.raises(TypeError, match="mean is not implemented for PeriodArray"):
 1023:             df.mean()
 1024: 
 1025:     def test_mean_datetimelike_numeric_only_false(self):
 1026:         df = DataFrame(
 1027:             {
 1028:                 "A": np.arange(3),
 1029:                 "B": date_range("2016-01-01", periods=3),
 1030:                 "C": pd.timedelta_range("1D", periods=3),
 1031:             }
 1032:         )
 1033: 
 1034:         # datetime(tz) and timedelta work
 1035:         result = df.mean(numeric_only=False)
 1036:         expected = Series({"A": 1, "B": df.loc[1, "B"], "C": df.loc[1, "C"]})
 1037:         tm.assert_series_equal(result, expected)
 1038: 
 1039:         # mean of period is not allowed
 1040:         df["D"] = pd.period_range("2016", periods=3, freq="Y")
 1041: 
 1042:         with pytest.raises(TypeError, match="mean is not implemented for Period"):
 1043:             df.mean(numeric_only=False)
 1044: 
 1045:     def test_mean_extensionarray_numeric_only_true(self):
 1046:         # https://github.com/pandas-dev/pandas/issues/33256
 1047:         arr = np.random.default_rng(2).integers(1000, size=(10, 5))
 1048:         df = DataFrame(arr, dtype="Int64")
 1049:         result = df.mean(numeric_only=True)
 1050:         expected = DataFrame(arr).mean().astype("Float64")
 1051:         tm.assert_series_equal(result, expected)
 1052: 
 1053:     def test_stats_mixed_type(self, float_string_frame):
 1054:         with pytest.raises(TypeError, match="could not convert"):
 1055:             float_string_frame.std(1)
 1056:         with pytest.raises(TypeError, match="could not convert"):
 1057:             float_string_frame.var(1)
 1058:         with pytest.raises(TypeError, match="unsupported operand type"):
 1059:             float_string_frame.mean(1)
 1060:         with pytest.raises(TypeError, match="could not convert"):
 1061:             float_string_frame.skew(1)
 1062: 
 1063:     def test_sum_bools(self):
 1064:         df = DataFrame(index=range(1), columns=range(10))
 1065:         bools = isna(df)
 1066:         assert bools.sum(axis=1)[0] == 10
 1067: 
 1068:     # ----------------------------------------------------------------------
 1069:     # Index of max / min
 1070: 
 1071:     @pytest.mark.parametrize("skipna", [True, False])
 1072:     @pytest.mark.parametrize("axis", [0, 1])
 1073:     def test_idxmin(self, float_frame, int_frame, skipna, axis):
 1074:         frame = float_frame
 1075:         frame.iloc[5:10] = np.nan
 1076:         frame.iloc[15:20, -2:] = np.nan
 1077:         for df in [frame, int_frame]:
 1078:             warn = None
 1079:             if skipna is False or axis == 1:
 1080:                 warn = None if df is int_frame else FutureWarning
 1081:             msg = "The behavior of DataFrame.idxmin with all-NA values"
 1082:             with tm.assert_produces_warning(warn, match=msg):
 1083:                 result = df.idxmin(axis=axis, skipna=skipna)
 1084: 
 1085:             msg2 = "The behavior of Series.idxmin"
 1086:             with tm.assert_produces_warning(warn, match=msg2):
 1087:                 expected = df.apply(Series.idxmin, axis=axis, skipna=skipna)
 1088:             expected = expected.astype(df.index.dtype)
 1089:             tm.assert_series_equal(result, expected)
 1090: 
 1091:     @pytest.mark.parametrize("axis", [0, 1])
 1092:     @pytest.mark.filterwarnings(r"ignore:PeriodDtype\[B\] is deprecated:FutureWarning")
 1093:     def test_idxmin_empty(self, index, skipna, axis):
 1094:         # GH53265
 1095:         if axis == 0:
 1096:             frame = DataFrame(index=index)
 1097:         else:
 1098:             frame = DataFrame(columns=index)
 1099: 
 1100:         result = frame.idxmin(axis=axis, skipna=skipna)
 1101:         expected = Series(dtype=index.dtype)
 1102:         tm.assert_series_equal(result, expected)
 1103: 
 1104:     @pytest.mark.parametrize("numeric_only", [True, False])
 1105:     def test_idxmin_numeric_only(self, numeric_only):
 1106:         df = DataFrame({"a": [2, 3, 1], "b": [2, 1, 1], "c": list("xyx")})
 1107:         result = df.idxmin(numeric_only=numeric_only)
 1108:         if numeric_only:
 1109:             expected = Series([2, 1], index=["a", "b"])
 1110:         else:
 1111:             expected = Series([2, 1, 0], index=["a", "b", "c"])
 1112:         tm.assert_series_equal(result, expected)
 1113: 
 1114:     def test_idxmin_axis_2(self, float_frame):
 1115:         frame = float_frame
 1116:         msg = "No axis named 2 for object type DataFrame"
 1117:         with pytest.raises(ValueError, match=msg):
 1118:             frame.idxmin(axis=2)
 1119: 
 1120:     @pytest.mark.parametrize("skipna", [True, False])
 1121:     @pytest.mark.parametrize("axis", [0, 1])
 1122:     def test_idxmax(self, float_frame, int_frame, skipna, axis):
 1123:         frame = float_frame
 1124:         frame.iloc[5:10] = np.nan
 1125:         frame.iloc[15:20, -2:] = np.nan
 1126:         for df in [frame, int_frame]:
 1127:             warn = None
 1128:             if skipna is False or axis == 1:
 1129:                 warn = None if df is int_frame else FutureWarning
 1130:             msg = "The behavior of DataFrame.idxmax with all-NA values"
 1131:             with tm.assert_produces_warning(warn, match=msg):
 1132:                 result = df.idxmax(axis=axis, skipna=skipna)
 1133: 
 1134:             msg2 = "The behavior of Series.idxmax"
 1135:             with tm.assert_produces_warning(warn, match=msg2):
 1136:                 expected = df.apply(Series.idxmax, axis=axis, skipna=skipna)
 1137:             expected = expected.astype(df.index.dtype)
 1138:             tm.assert_series_equal(result, expected)
 1139: 
 1140:     @pytest.mark.parametrize("axis", [0, 1])
 1141:     @pytest.mark.filterwarnings(r"ignore:PeriodDtype\[B\] is deprecated:FutureWarning")
 1142:     def test_idxmax_empty(self, index, skipna, axis):
 1143:         # GH53265
 1144:         if axis == 0:
 1145:             frame = DataFrame(index=index)
 1146:         else:
 1147:             frame = DataFrame(columns=index)
 1148: 
 1149:         result = frame.idxmax(axis=axis, skipna=skipna)
 1150:         expected = Series(dtype=index.dtype)
 1151:         tm.assert_series_equal(result, expected)
 1152: 
 1153:     @pytest.mark.parametrize("numeric_only", [True, False])
 1154:     def test_idxmax_numeric_only(self, numeric_only):
 1155:         df = DataFrame({"a": [2, 3, 1], "b": [2, 1, 1], "c": list("xyx")})
 1156:         result = df.idxmax(numeric_only=numeric_only)
 1157:         if numeric_only:
 1158:             expected = Series([1, 0], index=["a", "b"])
 1159:         else:
 1160:             expected = Series([1, 0, 1], index=["a", "b", "c"])
 1161:         tm.assert_series_equal(result, expected)
 1162: 
 1163:     def test_idxmax_arrow_types(self):
 1164:         # GH#55368
 1165:         pytest.importorskip("pyarrow")
 1166: 
 1167:         df = DataFrame({"a": [2, 3, 1], "b": [2, 1, 1]}, dtype="int64[pyarrow]")
 1168:         result = df.idxmax()
 1169:         expected = Series([1, 0], index=["a", "b"])
 1170:         tm.assert_series_equal(result, expected)
 1171: 
 1172:         result = df.idxmin()
 1173:         expected = Series([2, 1], index=["a", "b"])
 1174:         tm.assert_series_equal(result, expected)
 1175: 
 1176:         df = DataFrame({"a": ["b", "c", "a"]}, dtype="string[pyarrow]")
 1177:         result = df.idxmax(numeric_only=False)
 1178:         expected = Series([1], index=["a"])
 1179:         tm.assert_series_equal(result, expected)
 1180: 
 1181:         result = df.idxmin(numeric_only=False)
 1182:         expected = Series([2], index=["a"])
 1183:         tm.assert_series_equal(result, expected)
 1184: 
 1185:     def test_idxmax_axis_2(self, float_frame):
 1186:         frame = float_frame
 1187:         msg = "No axis named 2 for object type DataFrame"
 1188:         with pytest.raises(ValueError, match=msg):
 1189:             frame.idxmax(axis=2)
 1190: 
 1191:     def test_idxmax_mixed_dtype(self):
 1192:         # don't cast to object, which would raise in nanops
 1193:         dti = date_range("2016-01-01", periods=3)
 1194: 
 1195:         # Copying dti is needed for ArrayManager otherwise when we set
 1196:         #  df.loc[0, 3] = pd.NaT below it edits dti
 1197:         df = DataFrame({1: [0, 2, 1], 2: range(3)[::-1], 3: dti.copy(deep=True)})
 1198: 
 1199:         result = df.idxmax()
 1200:         expected = Series([1, 0, 2], index=[1, 2, 3])
 1201:         tm.assert_series_equal(result, expected)
 1202: 
 1203:         result = df.idxmin()
 1204:         expected = Series([0, 2, 0], index=[1, 2, 3])
 1205:         tm.assert_series_equal(result, expected)
 1206: 
 1207:         # with NaTs
 1208:         df.loc[0, 3] = pd.NaT
 1209:         result = df.idxmax()
 1210:         expected = Series([1, 0, 2], index=[1, 2, 3])
 1211:         tm.assert_series_equal(result, expected)
 1212: 
 1213:         result = df.idxmin()
 1214:         expected = Series([0, 2, 1], index=[1, 2, 3])
 1215:         tm.assert_series_equal(result, expected)
 1216: 
 1217:         # with multi-column dt64 block
 1218:         df[4] = dti[::-1]
 1219:         df._consolidate_inplace()
 1220: 
 1221:         result = df.idxmax()
 1222:         expected = Series([1, 0, 2, 0], index=[1, 2, 3, 4])
 1223:         tm.assert_series_equal(result, expected)
 1224: 
 1225:         result = df.idxmin()
 1226:         expected = Series([0, 2, 1, 2], index=[1, 2, 3, 4])
 1227:         tm.assert_series_equal(result, expected)
 1228: 
 1229:     @pytest.mark.parametrize(
 1230:         "op, expected_value",
 1231:         [("idxmax", [0, 4]), ("idxmin", [0, 5])],
 1232:     )
 1233:     def test_idxmax_idxmin_convert_dtypes(self, op, expected_value):
 1234:         # GH 40346
 1235:         df = DataFrame(
 1236:             {
 1237:                 "ID": [100, 100, 100, 200, 200, 200],
 1238:                 "value": [0, 0, 0, 1, 2, 0],
 1239:             },
 1240:             dtype="Int64",
 1241:         )
 1242:         df = df.groupby("ID")
 1243: 
 1244:         result = getattr(df, op)()
 1245:         expected = DataFrame(
 1246:             {"value": expected_value},
 1247:             index=Index([100, 200], name="ID", dtype="Int64"),
 1248:         )
 1249:         tm.assert_frame_equal(result, expected)
 1250: 
 1251:     def test_idxmax_dt64_multicolumn_axis1(self):
 1252:         dti = date_range("2016-01-01", periods=3)
 1253:         df = DataFrame({3: dti, 4: dti[::-1]}, copy=True)
 1254:         df.iloc[0, 0] = pd.NaT
 1255: 
 1256:         df._consolidate_inplace()
 1257: 
 1258:         result = df.idxmax(axis=1)
 1259:         expected = Series([4, 3, 3])
 1260:         tm.assert_series_equal(result, expected)
 1261: 
 1262:         result = df.idxmin(axis=1)
 1263:         expected = Series([4, 3, 4])
 1264:         tm.assert_series_equal(result, expected)
 1265: 
 1266:     # ----------------------------------------------------------------------
 1267:     # Logical reductions
 1268: 
 1269:     @pytest.mark.parametrize("opname", ["any", "all"])
 1270:     @pytest.mark.parametrize("axis", [0, 1])
 1271:     @pytest.mark.parametrize("bool_only", [False, True])
 1272:     def test_any_all_mixed_float(self, opname, axis, bool_only, float_string_frame):
 1273:         # make sure op works on mixed-type frame
 1274:         mixed = float_string_frame
 1275:         mixed["_bool_"] = np.random.default_rng(2).standard_normal(len(mixed)) > 0.5
 1276: 
 1277:         getattr(mixed, opname)(axis=axis, bool_only=bool_only)
 1278: 
 1279:     @pytest.mark.parametrize("opname", ["any", "all"])
 1280:     @pytest.mark.parametrize("axis", [0, 1])
 1281:     def test_any_all_bool_with_na(self, opname, axis, bool_frame_with_na):
 1282:         getattr(bool_frame_with_na, opname)(axis=axis, bool_only=False)
 1283: 
 1284:     @pytest.mark.filterwarnings("ignore:Downcasting object dtype arrays:FutureWarning")
 1285:     @pytest.mark.parametrize("opname", ["any", "all"])
 1286:     def test_any_all_bool_frame(self, opname, bool_frame_with_na):
 1287:         # GH#12863: numpy gives back non-boolean data for object type
 1288:         # so fill NaNs to compare with pandas behavior
 1289:         frame = bool_frame_with_na.fillna(True)
 1290:         alternative = getattr(np, opname)
 1291:         f = getattr(frame, opname)
 1292: 
 1293:         def skipna_wrapper(x):
 1294:             nona = x.dropna().values
 1295:             return alternative(nona)
 1296: 
 1297:         def wrapper(x):
 1298:             return alternative(x.values)
 1299: 
 1300:         result0 = f(axis=0, skipna=False)
 1301:         result1 = f(axis=1, skipna=False)
 1302: 
 1303:         tm.assert_series_equal(result0, frame.apply(wrapper))
 1304:         tm.assert_series_equal(result1, frame.apply(wrapper, axis=1))
 1305: 
 1306:         result0 = f(axis=0)
 1307:         result1 = f(axis=1)
 1308: 
 1309:         tm.assert_series_equal(result0, frame.apply(skipna_wrapper))
 1310:         tm.assert_series_equal(
 1311:             result1, frame.apply(skipna_wrapper, axis=1), check_dtype=False
 1312:         )
 1313: 
 1314:         # bad axis
 1315:         with pytest.raises(ValueError, match="No axis named 2"):
 1316:             f(axis=2)
 1317: 
 1318:         # all NA case
 1319:         all_na = frame * np.nan
 1320:         r0 = getattr(all_na, opname)(axis=0)
 1321:         r1 = getattr(all_na, opname)(axis=1)
 1322:         if opname == "any":
 1323:             assert not r0.any()
 1324:             assert not r1.any()
 1325:         else:
 1326:             assert r0.all()
 1327:             assert r1.all()
 1328: 
 1329:     def test_any_all_extra(self):
 1330:         df = DataFrame(
 1331:             {
 1332:                 "A": [True, False, False],
 1333:                 "B": [True, True, False],
 1334:                 "C": [True, True, True],
 1335:             },
 1336:             index=["a", "b", "c"],
 1337:         )
 1338:         result = df[["A", "B"]].any(axis=1)
 1339:         expected = Series([True, True, False], index=["a", "b", "c"])
 1340:         tm.assert_series_equal(result, expected)
 1341: 
 1342:         result = df[["A", "B"]].any(axis=1, bool_only=True)
 1343:         tm.assert_series_equal(result, expected)
 1344: 
 1345:         result = df.all(1)
 1346:         expected = Series([True, False, False], index=["a", "b", "c"])
 1347:         tm.assert_series_equal(result, expected)
 1348: 
 1349:         result = df.all(1, bool_only=True)
 1350:         tm.assert_series_equal(result, expected)
 1351: 
 1352:         # Axis is None
 1353:         result = df.all(axis=None).item()
 1354:         assert result is False
 1355: 
 1356:         result = df.any(axis=None).item()
 1357:         assert result is True
 1358: 
 1359:         result = df[["C"]].all(axis=None).item()
 1360:         assert result is True
 1361: 
 1362:     @pytest.mark.parametrize("axis", [0, 1])
 1363:     @pytest.mark.parametrize("bool_agg_func", ["any", "all"])
 1364:     @pytest.mark.parametrize("skipna", [True, False])
 1365:     def test_any_all_object_dtype(
 1366:         self, axis, bool_agg_func, skipna, using_infer_string
 1367:     ):
 1368:         # GH#35450
 1369:         df = DataFrame(
 1370:             data=[
 1371:                 [1, np.nan, np.nan, True],
 1372:                 [np.nan, 2, np.nan, True],
 1373:                 [np.nan, np.nan, np.nan, True],
 1374:                 [np.nan, np.nan, "5", np.nan],
 1375:             ]
 1376:         )
 1377:         if using_infer_string:
 1378:             # na in object is True while in string pyarrow numpy it's false
 1379:             val = not axis == 0 and not skipna and bool_agg_func == "all"
 1380:         else:
 1381:             val = True
 1382:         result = getattr(df, bool_agg_func)(axis=axis, skipna=skipna)
 1383:         expected = Series([True, True, val, True])
 1384:         tm.assert_series_equal(result, expected)
 1385: 
 1386:     # GH#50947 deprecates this but it is not emitting a warning in some builds.
 1387:     @pytest.mark.filterwarnings(
 1388:         "ignore:'any' with datetime64 dtypes is deprecated.*:FutureWarning"
 1389:     )
 1390:     def test_any_datetime(self):
 1391:         # GH 23070
 1392:         float_data = [1, np.nan, 3, np.nan]
 1393:         datetime_data = [
 1394:             Timestamp("1960-02-15"),
 1395:             Timestamp("1960-02-16"),
 1396:             pd.NaT,
 1397:             pd.NaT,
 1398:         ]
 1399:         df = DataFrame({"A": float_data, "B": datetime_data})
 1400: 
 1401:         result = df.any(axis=1)
 1402: 
 1403:         expected = Series([True, True, True, False])
 1404:         tm.assert_series_equal(result, expected)
 1405: 
 1406:     def test_any_all_bool_only(self):
 1407:         # GH 25101
 1408:         df = DataFrame(
 1409:             {"col1": [1, 2, 3], "col2": [4, 5, 6], "col3": [None, None, None]},
 1410:             columns=Index(["col1", "col2", "col3"], dtype=object),
 1411:         )
 1412: 
 1413:         result = df.all(bool_only=True)
 1414:         expected = Series(dtype=np.bool_, index=[])
 1415:         tm.assert_series_equal(result, expected)
 1416: 
 1417:         df = DataFrame(
 1418:             {
 1419:                 "col1": [1, 2, 3],
 1420:                 "col2": [4, 5, 6],
 1421:                 "col3": [None, None, None],
 1422:                 "col4": [False, False, True],
 1423:             }
 1424:         )
 1425: 
 1426:         result = df.all(bool_only=True)
 1427:         expected = Series({"col4": False})
 1428:         tm.assert_series_equal(result, expected)
 1429: 
 1430:     @pytest.mark.parametrize(
 1431:         "func, data, expected",
 1432:         [
 1433:             (np.any, {}, False),
 1434:             (np.all, {}, True),
 1435:             (np.any, {"A": []}, False),
 1436:             (np.all, {"A": []}, True),
 1437:             (np.any, {"A": [False, False]}, False),
 1438:             (np.all, {"A": [False, False]}, False),
 1439:             (np.any, {"A": [True, False]}, True),
 1440:             (np.all, {"A": [True, False]}, False),
 1441:             (np.any, {"A": [True, True]}, True),
 1442:             (np.all, {"A": [True, True]}, True),
 1443:             (np.any, {"A": [False], "B": [False]}, False),
 1444:             (np.all, {"A": [False], "B": [False]}, False),
 1445:             (np.any, {"A": [False, False], "B": [False, True]}, True),
 1446:             (np.all, {"A": [False, False], "B": [False, True]}, False),
 1447:             # other types
 1448:             (np.all, {"A": Series([0.0, 1.0], dtype="float")}, False),
 1449:             (np.any, {"A": Series([0.0, 1.0], dtype="float")}, True),
 1450:             (np.all, {"A": Series([0, 1], dtype=int)}, False),
 1451:             (np.any, {"A": Series([0, 1], dtype=int)}, True),
 1452:             pytest.param(np.all, {"A": Series([0, 1], dtype="M8[ns]")}, False),
 1453:             pytest.param(np.all, {"A": Series([0, 1], dtype="M8[ns, UTC]")}, False),
 1454:             pytest.param(np.any, {"A": Series([0, 1], dtype="M8[ns]")}, True),
 1455:             pytest.param(np.any, {"A": Series([0, 1], dtype="M8[ns, UTC]")}, True),
 1456:             pytest.param(np.all, {"A": Series([1, 2], dtype="M8[ns]")}, True),
 1457:             pytest.param(np.all, {"A": Series([1, 2], dtype="M8[ns, UTC]")}, True),
 1458:             pytest.param(np.any, {"A": Series([1, 2], dtype="M8[ns]")}, True),
 1459:             pytest.param(np.any, {"A": Series([1, 2], dtype="M8[ns, UTC]")}, True),
 1460:             pytest.param(np.all, {"A": Series([0, 1], dtype="m8[ns]")}, False),
 1461:             pytest.param(np.any, {"A": Series([0, 1], dtype="m8[ns]")}, True),
 1462:             pytest.param(np.all, {"A": Series([1, 2], dtype="m8[ns]")}, True),
 1463:             pytest.param(np.any, {"A": Series([1, 2], dtype="m8[ns]")}, True),
 1464:             # np.all on Categorical raises, so the reduction drops the
 1465:             #  column, so all is being done on an empty Series, so is True
 1466:             (np.all, {"A": Series([0, 1], dtype="category")}, True),
 1467:             (np.any, {"A": Series([0, 1], dtype="category")}, False),
 1468:             (np.all, {"A": Series([1, 2], dtype="category")}, True),
 1469:             (np.any, {"A": Series([1, 2], dtype="category")}, False),
 1470:             # Mix GH#21484
 1471:             pytest.param(
 1472:                 np.all,
 1473:                 {
 1474:                     "A": Series([10, 20], dtype="M8[ns]"),
 1475:                     "B": Series([10, 20], dtype="m8[ns]"),
 1476:                 },
 1477:                 True,
 1478:             ),
 1479:         ],
 1480:     )
 1481:     def test_any_all_np_func(self, func, data, expected):
 1482:         # GH 19976
 1483:         data = DataFrame(data)
 1484: 
 1485:         if any(isinstance(x, CategoricalDtype) for x in data.dtypes):
 1486:             with pytest.raises(
 1487:                 TypeError, match="dtype category does not support reduction"
 1488:             ):
 1489:                 func(data)
 1490: 
 1491:             # method version
 1492:             with pytest.raises(
 1493:                 TypeError, match="dtype category does not support reduction"
 1494:             ):
 1495:                 getattr(DataFrame(data), func.__name__)(axis=None)
 1496:         else:
 1497:             msg = "'(any|all)' with datetime64 dtypes is deprecated"
 1498:             if data.dtypes.apply(lambda x: x.kind == "M").any():
 1499:                 warn = FutureWarning
 1500:             else:
 1501:                 warn = None
 1502: 
 1503:             with tm.assert_produces_warning(warn, match=msg, check_stacklevel=False):
 1504:                 # GH#34479
 1505:                 result = func(data)
 1506:             assert isinstance(result, np.bool_)
 1507:             assert result.item() is expected
 1508: 
 1509:             # method version
 1510:             with tm.assert_produces_warning(warn, match=msg):
 1511:                 # GH#34479
 1512:                 result = getattr(DataFrame(data), func.__name__)(axis=None)
 1513:             assert isinstance(result, np.bool_)
 1514:             assert result.item() is expected
 1515: 
 1516:     def test_any_all_object(self):
 1517:         # GH 19976
 1518:         result = np.all(DataFrame(columns=["a", "b"])).item()
 1519:         assert result is True
 1520: 
 1521:         result = np.any(DataFrame(columns=["a", "b"])).item()
 1522:         assert result is False
 1523: 
 1524:     def test_any_all_object_bool_only(self):
 1525:         df = DataFrame({"A": ["foo", 2], "B": [True, False]}).astype(object)
 1526:         df._consolidate_inplace()
 1527:         df["C"] = Series([True, True])
 1528: 
 1529:         # Categorical of bools is _not_ considered booly
 1530:         df["D"] = df["C"].astype("category")
 1531: 
 1532:         # The underlying bug is in DataFrame._get_bool_data, so we check
 1533:         #  that while we're here
 1534:         res = df._get_bool_data()
 1535:         expected = df[["C"]]
 1536:         tm.assert_frame_equal(res, expected)
 1537: 
 1538:         res = df.all(bool_only=True, axis=0)
 1539:         expected = Series([True], index=["C"])
 1540:         tm.assert_series_equal(res, expected)
 1541: 
 1542:         # operating on a subset of columns should not produce a _larger_ Series
 1543:         res = df[["B", "C"]].all(bool_only=True, axis=0)
 1544:         tm.assert_series_equal(res, expected)
 1545: 
 1546:         assert df.all(bool_only=True, axis=None)
 1547: 
 1548:         res = df.any(bool_only=True, axis=0)
 1549:         expected = Series([True], index=["C"])
 1550:         tm.assert_series_equal(res, expected)
 1551: 
 1552:         # operating on a subset of columns should not produce a _larger_ Series
 1553:         res = df[["C"]].any(bool_only=True, axis=0)
 1554:         tm.assert_series_equal(res, expected)
 1555: 
 1556:         assert df.any(bool_only=True, axis=None)
 1557: 
 1558:     # ---------------------------------------------------------------------
 1559:     # Unsorted
 1560: 
 1561:     def test_series_broadcasting(self):
 1562:         # smoke test for numpy warnings
 1563:         # GH 16378, GH 16306
 1564:         df = DataFrame([1.0, 1.0, 1.0])
 1565:         df_nan = DataFrame({"A": [np.nan, 2.0, np.nan]})
 1566:         s = Series([1, 1, 1])
 1567:         s_nan = Series([np.nan, np.nan, 1])
 1568: 
 1569:         with tm.assert_produces_warning(None):
 1570:             df_nan.clip(lower=s, axis=0)
 1571:             for op in ["lt", "le", "gt", "ge", "eq", "ne"]:
 1572:                 getattr(df, op)(s_nan, axis=0)
 1573: 
 1574: 
 1575: class TestDataFrameReductions:
 1576:     def test_min_max_dt64_with_NaT(self):
 1577:         # Both NaT and Timestamp are in DataFrame.
 1578:         df = DataFrame({"foo": [pd.NaT, pd.NaT, Timestamp("2012-05-01")]})
 1579: 
 1580:         res = df.min()
 1581:         exp = Series([Timestamp("2012-05-01")], index=["foo"])
 1582:         tm.assert_series_equal(res, exp)
 1583: 
 1584:         res = df.max()
 1585:         exp = Series([Timestamp("2012-05-01")], index=["foo"])
 1586:         tm.assert_series_equal(res, exp)
 1587: 
 1588:         # GH12941, only NaTs are in DataFrame.
 1589:         df = DataFrame({"foo": [pd.NaT, pd.NaT]})
 1590: 
 1591:         res = df.min()
 1592:         exp = Series([pd.NaT], index=["foo"])
 1593:         tm.assert_series_equal(res, exp)
 1594: 
 1595:         res = df.max()
 1596:         exp = Series([pd.NaT], index=["foo"])
 1597:         tm.assert_series_equal(res, exp)
 1598: 
 1599:     def test_min_max_dt64_with_NaT_skipna_false(self, request, tz_naive_fixture):
 1600:         # GH#36907
 1601:         tz = tz_naive_fixture
 1602:         if isinstance(tz, tzlocal) and is_platform_windows():
 1603:             pytest.skip(
 1604:                 "GH#37659 OSError raised within tzlocal bc Windows "
 1605:                 "chokes in times before 1970-01-01"
 1606:             )
 1607: 
 1608:         df = DataFrame(
 1609:             {
 1610:                 "a": [
 1611:                     Timestamp("2020-01-01 08:00:00", tz=tz),
 1612:                     Timestamp("1920-02-01 09:00:00", tz=tz),
 1613:                 ],
 1614:                 "b": [Timestamp("2020-02-01 08:00:00", tz=tz), pd.NaT],
 1615:             }
 1616:         )
 1617:         res = df.min(axis=1, skipna=False)
 1618:         expected = Series([df.loc[0, "a"], pd.NaT])
 1619:         assert expected.dtype == df["a"].dtype
 1620: 
 1621:         tm.assert_series_equal(res, expected)
 1622: 
 1623:         res = df.max(axis=1, skipna=False)
 1624:         expected = Series([df.loc[0, "b"], pd.NaT])
 1625:         assert expected.dtype == df["a"].dtype
 1626: 
 1627:         tm.assert_series_equal(res, expected)
 1628: 
 1629:     def test_min_max_dt64_api_consistency_with_NaT(self):
 1630:         # Calling the following sum functions returned an error for dataframes but
 1631:         # returned NaT for series. These tests check that the API is consistent in
 1632:         # min/max calls on empty Series/DataFrames. See GH:33704 for more
 1633:         # information
 1634:         df = DataFrame({"x": to_datetime([])})
 1635:         expected_dt_series = Series(to_datetime([]))
 1636:         # check axis 0
 1637:         assert (df.min(axis=0).x is pd.NaT) == (expected_dt_series.min() is pd.NaT)
 1638:         assert (df.max(axis=0).x is pd.NaT) == (expected_dt_series.max() is pd.NaT)
 1639: 
 1640:         # check axis 1
 1641:         tm.assert_series_equal(df.min(axis=1), expected_dt_series)
 1642:         tm.assert_series_equal(df.max(axis=1), expected_dt_series)
 1643: 
 1644:     def test_min_max_dt64_api_consistency_empty_df(self):
 1645:         # check DataFrame/Series api consistency when calling min/max on an empty
 1646:         # DataFrame/Series.
 1647:         df = DataFrame({"x": []})
 1648:         expected_float_series = Series([], dtype=float)
 1649:         # check axis 0
 1650:         assert np.isnan(df.min(axis=0).x) == np.isnan(expected_float_series.min())
 1651:         assert np.isnan(df.max(axis=0).x) == np.isnan(expected_float_series.max())
 1652:         # check axis 1
 1653:         tm.assert_series_equal(df.min(axis=1), expected_float_series)
 1654:         tm.assert_series_equal(df.min(axis=1), expected_float_series)
 1655: 
 1656:     @pytest.mark.parametrize(
 1657:         "initial",
 1658:         ["2018-10-08 13:36:45+00:00", "2018-10-08 13:36:45+03:00"],  # Non-UTC timezone
 1659:     )
 1660:     @pytest.mark.parametrize("method", ["min", "max"])
 1661:     def test_preserve_timezone(self, initial: str, method):
 1662:         # GH 28552
 1663:         initial_dt = to_datetime(initial)
 1664:         expected = Series([initial_dt])
 1665:         df = DataFrame([expected])
 1666:         result = getattr(df, method)(axis=1)
 1667:         tm.assert_series_equal(result, expected)
 1668: 
 1669:     @pytest.mark.parametrize("method", ["min", "max"])
 1670:     def test_minmax_tzaware_skipna_axis_1(self, method, skipna):
 1671:         # GH#51242
 1672:         val = to_datetime("1900-01-01", utc=True)
 1673:         df = DataFrame(
 1674:             {"a": Series([pd.NaT, pd.NaT, val]), "b": Series([pd.NaT, val, val])}
 1675:         )
 1676:         op = getattr(df, method)
 1677:         result = op(axis=1, skipna=skipna)
 1678:         if skipna:
 1679:             expected = Series([pd.NaT, val, val])
 1680:         else:
 1681:             expected = Series([pd.NaT, pd.NaT, val])
 1682:         tm.assert_series_equal(result, expected)
 1683: 
 1684:     def test_frame_any_with_timedelta(self):
 1685:         # GH#17667
 1686:         df = DataFrame(
 1687:             {
 1688:                 "a": Series([0, 0]),
 1689:                 "t": Series([to_timedelta(0, "s"), to_timedelta(1, "ms")]),
 1690:             }
 1691:         )
 1692: 
 1693:         result = df.any(axis=0)
 1694:         expected = Series(data=[False, True], index=["a", "t"])
 1695:         tm.assert_series_equal(result, expected)
 1696: 
 1697:         result = df.any(axis=1)
 1698:         expected = Series(data=[False, True])
 1699:         tm.assert_series_equal(result, expected)
 1700: 
 1701:     def test_reductions_skipna_none_raises(
 1702:         self, request, frame_or_series, all_reductions
 1703:     ):
 1704:         if all_reductions == "count":
 1705:             request.applymarker(
 1706:                 pytest.mark.xfail(reason="Count does not accept skipna")
 1707:             )
 1708:         obj = frame_or_series([1, 2, 3])
 1709:         msg = 'For argument "skipna" expected type bool, received type NoneType.'
 1710:         with pytest.raises(ValueError, match=msg):
 1711:             getattr(obj, all_reductions)(skipna=None)
 1712: 
 1713:     @td.skip_array_manager_invalid_test
 1714:     def test_reduction_timestamp_smallest_unit(self):
 1715:         # GH#52524
 1716:         df = DataFrame(
 1717:             {
 1718:                 "a": Series([Timestamp("2019-12-31")], dtype="datetime64[s]"),
 1719:                 "b": Series(
 1720:                     [Timestamp("2019-12-31 00:00:00.123")], dtype="datetime64[ms]"
 1721:                 ),
 1722:             }
 1723:         )
 1724:         result = df.max()
 1725:         expected = Series(
 1726:             [Timestamp("2019-12-31"), Timestamp("2019-12-31 00:00:00.123")],
 1727:             dtype="datetime64[ms]",
 1728:             index=["a", "b"],
 1729:         )
 1730:         tm.assert_series_equal(result, expected)
 1731: 
 1732:     @td.skip_array_manager_not_yet_implemented
 1733:     def test_reduction_timedelta_smallest_unit(self):
 1734:         # GH#52524
 1735:         df = DataFrame(
 1736:             {
 1737:                 "a": Series([pd.Timedelta("1 days")], dtype="timedelta64[s]"),
 1738:                 "b": Series([pd.Timedelta("1 days")], dtype="timedelta64[ms]"),
 1739:             }
 1740:         )
 1741:         result = df.max()
 1742:         expected = Series(
 1743:             [pd.Timedelta("1 days"), pd.Timedelta("1 days")],
 1744:             dtype="timedelta64[ms]",
 1745:             index=["a", "b"],
 1746:         )
 1747:         tm.assert_series_equal(result, expected)
 1748: 
 1749: 
 1750: class TestNuisanceColumns:
 1751:     @pytest.mark.parametrize("method", ["any", "all"])
 1752:     def test_any_all_categorical_dtype_nuisance_column(self, method):
 1753:         # GH#36076 DataFrame should match Series behavior
 1754:         ser = Series([0, 1], dtype="category", name="A")
 1755:         df = ser.to_frame()
 1756: 
 1757:         # Double-check the Series behavior is to raise
 1758:         with pytest.raises(TypeError, match="does not support reduction"):
 1759:             getattr(ser, method)()
 1760: 
 1761:         with pytest.raises(TypeError, match="does not support reduction"):
 1762:             getattr(np, method)(ser)
 1763: 
 1764:         with pytest.raises(TypeError, match="does not support reduction"):
 1765:             getattr(df, method)(bool_only=False)
 1766: 
 1767:         with pytest.raises(TypeError, match="does not support reduction"):
 1768:             getattr(df, method)(bool_only=None)
 1769: 
 1770:         with pytest.raises(TypeError, match="does not support reduction"):
 1771:             getattr(np, method)(df, axis=0)
 1772: 
 1773:     def test_median_categorical_dtype_nuisance_column(self):
 1774:         # GH#21020 DataFrame.median should match Series.median
 1775:         df = DataFrame({"A": Categorical([1, 2, 2, 2, 3])})
 1776:         ser = df["A"]
 1777: 
 1778:         # Double-check the Series behavior is to raise
 1779:         with pytest.raises(TypeError, match="does not support reduction"):
 1780:             ser.median()
 1781: 
 1782:         with pytest.raises(TypeError, match="does not support reduction"):
 1783:             df.median(numeric_only=False)
 1784: 
 1785:         with pytest.raises(TypeError, match="does not support reduction"):
 1786:             df.median()
 1787: 
 1788:         # same thing, but with an additional non-categorical column
 1789:         df["B"] = df["A"].astype(int)
 1790: 
 1791:         with pytest.raises(TypeError, match="does not support reduction"):
 1792:             df.median(numeric_only=False)
 1793: 
 1794:         with pytest.raises(TypeError, match="does not support reduction"):
 1795:             df.median()
 1796: 
 1797:         # TODO: np.median(df, axis=0) gives np.array([2.0, 2.0]) instead
 1798:         #  of expected.values
 1799: 
 1800:     @pytest.mark.parametrize("method", ["min", "max"])
 1801:     def test_min_max_categorical_dtype_non_ordered_nuisance_column(self, method):
 1802:         # GH#28949 DataFrame.min should behave like Series.min
 1803:         cat = Categorical(["a", "b", "c", "b"], ordered=False)
 1804:         ser = Series(cat)
 1805:         df = ser.to_frame("A")
 1806: 
 1807:         # Double-check the Series behavior
 1808:         with pytest.raises(TypeError, match="is not ordered for operation"):
 1809:             getattr(ser, method)()
 1810: 
 1811:         with pytest.raises(TypeError, match="is not ordered for operation"):
 1812:             getattr(np, method)(ser)
 1813: 
 1814:         with pytest.raises(TypeError, match="is not ordered for operation"):
 1815:             getattr(df, method)(numeric_only=False)
 1816: 
 1817:         with pytest.raises(TypeError, match="is not ordered for operation"):
 1818:             getattr(df, method)()
 1819: 
 1820:         with pytest.raises(TypeError, match="is not ordered for operation"):
 1821:             getattr(np, method)(df, axis=0)
 1822: 
 1823:         # same thing, but with an additional non-categorical column
 1824:         df["B"] = df["A"].astype(object)
 1825:         with pytest.raises(TypeError, match="is not ordered for operation"):
 1826:             getattr(df, method)()
 1827: 
 1828:         with pytest.raises(TypeError, match="is not ordered for operation"):
 1829:             getattr(np, method)(df, axis=0)
 1830: 
 1831: 
 1832: class TestEmptyDataFrameReductions:
 1833:     @pytest.mark.parametrize(
 1834:         "opname, dtype, exp_value, exp_dtype",
 1835:         [
 1836:             ("sum", np.int8, 0, np.int64),
 1837:             ("prod", np.int8, 1, np.int_),
 1838:             ("sum", np.int64, 0, np.int64),
 1839:             ("prod", np.int64, 1, np.int64),
 1840:             ("sum", np.uint8, 0, np.uint64),
 1841:             ("prod", np.uint8, 1, np.uint),
 1842:             ("sum", np.uint64, 0, np.uint64),
 1843:             ("prod", np.uint64, 1, np.uint64),
 1844:             ("sum", np.float32, 0, np.float32),
 1845:             ("prod", np.float32, 1, np.float32),
 1846:             ("sum", np.float64, 0, np.float64),
 1847:         ],
 1848:     )
 1849:     def test_df_empty_min_count_0(self, opname, dtype, exp_value, exp_dtype):
 1850:         df = DataFrame({0: [], 1: []}, dtype=dtype)
 1851:         result = getattr(df, opname)(min_count=0)
 1852: 
 1853:         expected = Series([exp_value, exp_value], dtype=exp_dtype)
 1854:         tm.assert_series_equal(result, expected)
 1855: 
 1856:     @pytest.mark.parametrize(
 1857:         "opname, dtype, exp_dtype",
 1858:         [
 1859:             ("sum", np.int8, np.float64),
 1860:             ("prod", np.int8, np.float64),
 1861:             ("sum", np.int64, np.float64),
 1862:             ("prod", np.int64, np.float64),
 1863:             ("sum", np.uint8, np.float64),
 1864:             ("prod", np.uint8, np.float64),
 1865:             ("sum", np.uint64, np.float64),
 1866:             ("prod", np.uint64, np.float64),
 1867:             ("sum", np.float32, np.float32),
 1868:             ("prod", np.float32, np.float32),
 1869:             ("sum", np.float64, np.float64),
 1870:         ],
 1871:     )
 1872:     def test_df_empty_min_count_1(self, opname, dtype, exp_dtype):
 1873:         df = DataFrame({0: [], 1: []}, dtype=dtype)
 1874:         result = getattr(df, opname)(min_count=1)
 1875: 
 1876:         expected = Series([np.nan, np.nan], dtype=exp_dtype)
 1877:         tm.assert_series_equal(result, expected)
 1878: 
 1879:     @pytest.mark.parametrize(
 1880:         "opname, dtype, exp_value, exp_dtype",
 1881:         [
 1882:             ("sum", "Int8", 0, ("Int32" if is_windows_np2_or_is32 else "Int64")),
 1883:             ("prod", "Int8", 1, ("Int32" if is_windows_np2_or_is32 else "Int64")),
 1884:             ("prod", "Int8", 1, ("Int32" if is_windows_np2_or_is32 else "Int64")),
 1885:             ("sum", "Int64", 0, "Int64"),
 1886:             ("prod", "Int64", 1, "Int64"),
 1887:             ("sum", "UInt8", 0, ("UInt32" if is_windows_np2_or_is32 else "UInt64")),
 1888:             ("prod", "UInt8", 1, ("UInt32" if is_windows_np2_or_is32 else "UInt64")),
 1889:             ("sum", "UInt64", 0, "UInt64"),
 1890:             ("prod", "UInt64", 1, "UInt64"),
 1891:             ("sum", "Float32", 0, "Float32"),
 1892:             ("prod", "Float32", 1, "Float32"),
 1893:             ("sum", "Float64", 0, "Float64"),
 1894:         ],
 1895:     )
 1896:     def test_df_empty_nullable_min_count_0(self, opname, dtype, exp_value, exp_dtype):
 1897:         df = DataFrame({0: [], 1: []}, dtype=dtype)
 1898:         result = getattr(df, opname)(min_count=0)
 1899: 
 1900:         expected = Series([exp_value, exp_value], dtype=exp_dtype)
 1901:         tm.assert_series_equal(result, expected)
 1902: 
 1903:     # TODO: why does min_count=1 impact the resulting Windows dtype
 1904:     # differently than min_count=0?
 1905:     @pytest.mark.parametrize(
 1906:         "opname, dtype, exp_dtype",
 1907:         [
 1908:             ("sum", "Int8", ("Int32" if is_windows_or_is32 else "Int64")),
 1909:             ("prod", "Int8", ("Int32" if is_windows_or_is32 else "Int64")),
 1910:             ("sum", "Int64", "Int64"),
 1911:             ("prod", "Int64", "Int64"),
 1912:             ("sum", "UInt8", ("UInt32" if is_windows_or_is32 else "UInt64")),
 1913:             ("prod", "UInt8", ("UInt32" if is_windows_or_is32 else "UInt64")),
 1914:             ("sum", "UInt64", "UInt64"),
 1915:             ("prod", "UInt64", "UInt64"),
 1916:             ("sum", "Float32", "Float32"),
 1917:             ("prod", "Float32", "Float32"),
 1918:             ("sum", "Float64", "Float64"),
 1919:         ],
 1920:     )
 1921:     def test_df_empty_nullable_min_count_1(self, opname, dtype, exp_dtype):
 1922:         df = DataFrame({0: [], 1: []}, dtype=dtype)
 1923:         result = getattr(df, opname)(min_count=1)
 1924: 
 1925:         expected = Series([pd.NA, pd.NA], dtype=exp_dtype)
 1926:         tm.assert_series_equal(result, expected)
 1927: 
 1928: 
 1929: def test_sum_timedelta64_skipna_false(using_array_manager, request):
 1930:     # GH#17235
 1931:     if using_array_manager:
 1932:         mark = pytest.mark.xfail(
 1933:             reason="Incorrect type inference on NaT in reduction result"
 1934:         )
 1935:         request.applymarker(mark)
 1936: 
 1937:     arr = np.arange(8).astype(np.int64).view("m8[s]").reshape(4, 2)
 1938:     arr[-1, -1] = "Nat"
 1939: 
 1940:     df = DataFrame(arr)
 1941:     assert (df.dtypes == arr.dtype).all()
 1942: 
 1943:     result = df.sum(skipna=False)
 1944:     expected = Series([pd.Timedelta(seconds=12), pd.NaT], dtype="m8[s]")
 1945:     tm.assert_series_equal(result, expected)
 1946: 
 1947:     result = df.sum(axis=0, skipna=False)
 1948:     tm.assert_series_equal(result, expected)
 1949: 
 1950:     result = df.sum(axis=1, skipna=False)
 1951:     expected = Series(
 1952:         [
 1953:             pd.Timedelta(seconds=1),
 1954:             pd.Timedelta(seconds=5),
 1955:             pd.Timedelta(seconds=9),
 1956:             pd.NaT,
 1957:         ],
 1958:         dtype="m8[s]",
 1959:     )
 1960:     tm.assert_series_equal(result, expected)
 1961: 
 1962: 
 1963: @pytest.mark.xfail(
 1964:     using_pyarrow_string_dtype(), reason="sum doesn't work with arrow strings"
 1965: )
 1966: def test_mixed_frame_with_integer_sum():
 1967:     # https://github.com/pandas-dev/pandas/issues/34520
 1968:     df = DataFrame([["a", 1]], columns=list("ab"))
 1969:     df = df.astype({"b": "Int64"})
 1970:     result = df.sum()
 1971:     expected = Series(["a", 1], index=["a", "b"])
 1972:     tm.assert_series_equal(result, expected)
 1973: 
 1974: 
 1975: @pytest.mark.parametrize("numeric_only", [True, False, None])
 1976: @pytest.mark.parametrize("method", ["min", "max"])
 1977: def test_minmax_extensionarray(method, numeric_only):
 1978:     # https://github.com/pandas-dev/pandas/issues/32651
 1979:     int64_info = np.iinfo("int64")
 1980:     ser = Series([int64_info.max, None, int64_info.min], dtype=pd.Int64Dtype())
 1981:     df = DataFrame({"Int64": ser})
 1982:     result = getattr(df, method)(numeric_only=numeric_only)
 1983:     expected = Series(
 1984:         [getattr(int64_info, method)],
 1985:         dtype="Int64",
 1986:         index=Index(["Int64"]),
 1987:     )
 1988:     tm.assert_series_equal(result, expected)
 1989: 
 1990: 
 1991: @pytest.mark.parametrize("ts_value", [Timestamp("2000-01-01"), pd.NaT])
 1992: def test_frame_mixed_numeric_object_with_timestamp(ts_value):
 1993:     # GH 13912
 1994:     df = DataFrame({"a": [1], "b": [1.1], "c": ["foo"], "d": [ts_value]})
 1995:     with pytest.raises(TypeError, match="does not support reduction"):
 1996:         df.sum()
 1997: 
 1998: 
 1999: def test_prod_sum_min_count_mixed_object():
 2000:     # https://github.com/pandas-dev/pandas/issues/41074
 2001:     df = DataFrame([1, "a", True])
 2002: 
 2003:     result = df.prod(axis=0, min_count=1, numeric_only=False)
 2004:     expected = Series(["a"], dtype=object)
 2005:     tm.assert_series_equal(result, expected)
 2006: 
 2007:     msg = re.escape("unsupported operand type(s) for +: 'int' and 'str'")
 2008:     with pytest.raises(TypeError, match=msg):
 2009:         df.sum(axis=0, min_count=1, numeric_only=False)
 2010: 
 2011: 
 2012: @pytest.mark.parametrize("method", ["min", "max", "mean", "median", "skew", "kurt"])
 2013: @pytest.mark.parametrize("numeric_only", [True, False])
 2014: @pytest.mark.parametrize("dtype", ["float64", "Float64"])
 2015: def test_reduction_axis_none_returns_scalar(method, numeric_only, dtype):
 2016:     # GH#21597 As of 2.0, axis=None reduces over all axes.
 2017: 
 2018:     df = DataFrame(np.random.default_rng(2).standard_normal((4, 4)), dtype=dtype)
 2019: 
 2020:     result = getattr(df, method)(axis=None, numeric_only=numeric_only)
 2021:     np_arr = df.to_numpy(dtype=np.float64)
 2022:     if method in {"skew", "kurt"}:
 2023:         comp_mod = pytest.importorskip("scipy.stats")
 2024:         if method == "kurt":
 2025:             method = "kurtosis"
 2026:         expected = getattr(comp_mod, method)(np_arr, bias=False, axis=None)
 2027:         tm.assert_almost_equal(result, expected)
 2028:     else:
 2029:         expected = getattr(np, method)(np_arr, axis=None)
 2030:         assert result == expected
 2031: 
 2032: 
 2033: @pytest.mark.parametrize(
 2034:     "kernel",
 2035:     [
 2036:         "corr",
 2037:         "corrwith",
 2038:         "cov",
 2039:         "idxmax",
 2040:         "idxmin",
 2041:         "kurt",
 2042:         "max",
 2043:         "mean",
 2044:         "median",
 2045:         "min",
 2046:         "prod",
 2047:         "quantile",
 2048:         "sem",
 2049:         "skew",
 2050:         "std",
 2051:         "sum",
 2052:         "var",
 2053:     ],
 2054: )
 2055: def test_fails_on_non_numeric(kernel):
 2056:     # GH#46852
 2057:     df = DataFrame({"a": [1, 2, 3], "b": object})
 2058:     args = (df,) if kernel == "corrwith" else ()
 2059:     msg = "|".join(
 2060:         [
 2061:             "not allowed for this dtype",
 2062:             "argument must be a string or a number",
 2063:             "not supported between instances of",
 2064:             "unsupported operand type",
 2065:             "argument must be a string or a real number",
 2066:         ]
 2067:     )
 2068:     if kernel == "median":
 2069:         # slightly different message on different builds
 2070:         msg1 = (
 2071:             r"Cannot convert \[\[<class 'object'> <class 'object'> "
 2072:             r"<class 'object'>\]\] to numeric"
 2073:         )
 2074:         msg2 = (
 2075:             r"Cannot convert \[<class 'object'> <class 'object'> "
 2076:             r"<class 'object'>\] to numeric"
 2077:         )
 2078:         msg = "|".join([msg1, msg2])
 2079:     with pytest.raises(TypeError, match=msg):
 2080:         getattr(df, kernel)(*args)
 2081: 
 2082: 
 2083: @pytest.mark.parametrize(
 2084:     "method",
 2085:     [
 2086:         "all",
 2087:         "any",
 2088:         "count",
 2089:         "idxmax",
 2090:         "idxmin",
 2091:         "kurt",
 2092:         "kurtosis",
 2093:         "max",
 2094:         "mean",
 2095:         "median",
 2096:         "min",
 2097:         "nunique",
 2098:         "prod",
 2099:         "product",
 2100:         "sem",
 2101:         "skew",
 2102:         "std",
 2103:         "sum",
 2104:         "var",
 2105:     ],
 2106: )
 2107: @pytest.mark.parametrize("min_count", [0, 2])
 2108: def test_numeric_ea_axis_1(method, skipna, min_count, any_numeric_ea_dtype):
 2109:     # GH 54341
 2110:     df = DataFrame(
 2111:         {
 2112:             "a": Series([0, 1, 2, 3], dtype=any_numeric_ea_dtype),
 2113:             "b": Series([0, 1, pd.NA, 3], dtype=any_numeric_ea_dtype),
 2114:         },
 2115:     )
 2116:     expected_df = DataFrame(
 2117:         {
 2118:             "a": [0.0, 1.0, 2.0, 3.0],
 2119:             "b": [0.0, 1.0, np.nan, 3.0],
 2120:         },
 2121:     )
 2122:     if method in ("count", "nunique"):
 2123:         expected_dtype = "int64"
 2124:     elif method in ("all", "any"):
 2125:         expected_dtype = "boolean"
 2126:     elif method in (
 2127:         "kurt",
 2128:         "kurtosis",
 2129:         "mean",
 2130:         "median",
 2131:         "sem",
 2132:         "skew",
 2133:         "std",
 2134:         "var",
 2135:     ) and not any_numeric_ea_dtype.startswith("Float"):
 2136:         expected_dtype = "Float64"
 2137:     else:
 2138:         expected_dtype = any_numeric_ea_dtype
 2139: 
 2140:     kwargs = {}
 2141:     if method not in ("count", "nunique", "quantile"):
 2142:         kwargs["skipna"] = skipna
 2143:     if method in ("prod", "product", "sum"):
 2144:         kwargs["min_count"] = min_count
 2145: 
 2146:     warn = None
 2147:     msg = None
 2148:     if not skipna and method in ("idxmax", "idxmin"):
 2149:         warn = FutureWarning
 2150:         msg = f"The behavior of DataFrame.{method} with all-NA values"
 2151:     with tm.assert_produces_warning(warn, match=msg):
 2152:         result = getattr(df, method)(axis=1, **kwargs)
 2153:     with tm.assert_produces_warning(warn, match=msg):
 2154:         expected = getattr(expected_df, method)(axis=1, **kwargs)
 2155:     if method not in ("idxmax", "idxmin"):
 2156:         expected = expected.astype(expected_dtype)
 2157:     tm.assert_series_equal(result, expected)
