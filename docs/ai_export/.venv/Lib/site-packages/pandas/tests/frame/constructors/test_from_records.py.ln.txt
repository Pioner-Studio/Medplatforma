    1: from collections.abc import Iterator
    2: from datetime import datetime
    3: from decimal import Decimal
    4: 
    5: import numpy as np
    6: import pytest
    7: import pytz
    8: 
    9: from pandas._config import using_pyarrow_string_dtype
   10: 
   11: from pandas.compat import is_platform_little_endian
   12: 
   13: from pandas import (
   14:     CategoricalIndex,
   15:     DataFrame,
   16:     Index,
   17:     Interval,
   18:     RangeIndex,
   19:     Series,
   20:     date_range,
   21: )
   22: import pandas._testing as tm
   23: 
   24: 
   25: class TestFromRecords:
   26:     def test_from_records_dt64tz_frame(self):
   27:         # GH#51162 don't lose tz when calling from_records with DataFrame input
   28:         dti = date_range("2016-01-01", periods=10, tz="US/Pacific")
   29:         df = DataFrame({i: dti for i in range(4)})
   30:         with tm.assert_produces_warning(FutureWarning):
   31:             res = DataFrame.from_records(df)
   32:         tm.assert_frame_equal(res, df)
   33: 
   34:     def test_from_records_with_datetimes(self):
   35:         # this may fail on certain platforms because of a numpy issue
   36:         # related GH#6140
   37:         if not is_platform_little_endian():
   38:             pytest.skip("known failure of test on non-little endian")
   39: 
   40:         # construction with a null in a recarray
   41:         # GH#6140
   42:         expected = DataFrame({"EXPIRY": [datetime(2005, 3, 1, 0, 0), None]})
   43: 
   44:         arrdata = [np.array([datetime(2005, 3, 1, 0, 0), None])]
   45:         dtypes = [("EXPIRY", "<M8[ns]")]
   46: 
   47:         recarray = np.rec.fromarrays(arrdata, dtype=dtypes)
   48: 
   49:         result = DataFrame.from_records(recarray)
   50:         tm.assert_frame_equal(result, expected)
   51: 
   52:         # coercion should work too
   53:         arrdata = [np.array([datetime(2005, 3, 1, 0, 0), None])]
   54:         dtypes = [("EXPIRY", "<M8[m]")]
   55:         recarray = np.rec.fromarrays(arrdata, dtype=dtypes)
   56:         result = DataFrame.from_records(recarray)
   57:         # we get the closest supported unit, "s"
   58:         expected["EXPIRY"] = expected["EXPIRY"].astype("M8[s]")
   59:         tm.assert_frame_equal(result, expected)
   60: 
   61:     @pytest.mark.skipif(
   62:         using_pyarrow_string_dtype(), reason="dtype checking logic doesn't work"
   63:     )
   64:     def test_from_records_sequencelike(self):
   65:         df = DataFrame(
   66:             {
   67:                 "A": np.array(
   68:                     np.random.default_rng(2).standard_normal(6), dtype=np.float64
   69:                 ),
   70:                 "A1": np.array(
   71:                     np.random.default_rng(2).standard_normal(6), dtype=np.float64
   72:                 ),
   73:                 "B": np.array(np.arange(6), dtype=np.int64),
   74:                 "C": ["foo"] * 6,
   75:                 "D": np.array([True, False] * 3, dtype=bool),
   76:                 "E": np.array(
   77:                     np.random.default_rng(2).standard_normal(6), dtype=np.float32
   78:                 ),
   79:                 "E1": np.array(
   80:                     np.random.default_rng(2).standard_normal(6), dtype=np.float32
   81:                 ),
   82:                 "F": np.array(np.arange(6), dtype=np.int32),
   83:             }
   84:         )
   85: 
   86:         # this is actually tricky to create the recordlike arrays and
   87:         # have the dtypes be intact
   88:         blocks = df._to_dict_of_blocks()
   89:         tuples = []
   90:         columns = []
   91:         dtypes = []
   92:         for dtype, b in blocks.items():
   93:             columns.extend(b.columns)
   94:             dtypes.extend([(c, np.dtype(dtype).descr[0][1]) for c in b.columns])
   95:         for i in range(len(df.index)):
   96:             tup = []
   97:             for _, b in blocks.items():
   98:                 tup.extend(b.iloc[i].values)
   99:             tuples.append(tuple(tup))
  100: 
  101:         recarray = np.array(tuples, dtype=dtypes).view(np.rec.recarray)
  102:         recarray2 = df.to_records()
  103:         lists = [list(x) for x in tuples]
  104: 
  105:         # tuples (lose the dtype info)
  106:         result = DataFrame.from_records(tuples, columns=columns).reindex(
  107:             columns=df.columns
  108:         )
  109: 
  110:         # created recarray and with to_records recarray (have dtype info)
  111:         result2 = DataFrame.from_records(recarray, columns=columns).reindex(
  112:             columns=df.columns
  113:         )
  114:         result3 = DataFrame.from_records(recarray2, columns=columns).reindex(
  115:             columns=df.columns
  116:         )
  117: 
  118:         # list of tuples (no dtype info)
  119:         result4 = DataFrame.from_records(lists, columns=columns).reindex(
  120:             columns=df.columns
  121:         )
  122: 
  123:         tm.assert_frame_equal(result, df, check_dtype=False)
  124:         tm.assert_frame_equal(result2, df)
  125:         tm.assert_frame_equal(result3, df)
  126:         tm.assert_frame_equal(result4, df, check_dtype=False)
  127: 
  128:         # tuples is in the order of the columns
  129:         result = DataFrame.from_records(tuples)
  130:         tm.assert_index_equal(result.columns, RangeIndex(8))
  131: 
  132:         # test exclude parameter & we are casting the results here (as we don't
  133:         # have dtype info to recover)
  134:         columns_to_test = [columns.index("C"), columns.index("E1")]
  135: 
  136:         exclude = list(set(range(8)) - set(columns_to_test))
  137:         result = DataFrame.from_records(tuples, exclude=exclude)
  138:         result.columns = [columns[i] for i in sorted(columns_to_test)]
  139:         tm.assert_series_equal(result["C"], df["C"])
  140:         tm.assert_series_equal(result["E1"], df["E1"])
  141: 
  142:     def test_from_records_sequencelike_empty(self):
  143:         # empty case
  144:         result = DataFrame.from_records([], columns=["foo", "bar", "baz"])
  145:         assert len(result) == 0
  146:         tm.assert_index_equal(result.columns, Index(["foo", "bar", "baz"]))
  147: 
  148:         result = DataFrame.from_records([])
  149:         assert len(result) == 0
  150:         assert len(result.columns) == 0
  151: 
  152:     def test_from_records_dictlike(self):
  153:         # test the dict methods
  154:         df = DataFrame(
  155:             {
  156:                 "A": np.array(
  157:                     np.random.default_rng(2).standard_normal(6), dtype=np.float64
  158:                 ),
  159:                 "A1": np.array(
  160:                     np.random.default_rng(2).standard_normal(6), dtype=np.float64
  161:                 ),
  162:                 "B": np.array(np.arange(6), dtype=np.int64),
  163:                 "C": ["foo"] * 6,
  164:                 "D": np.array([True, False] * 3, dtype=bool),
  165:                 "E": np.array(
  166:                     np.random.default_rng(2).standard_normal(6), dtype=np.float32
  167:                 ),
  168:                 "E1": np.array(
  169:                     np.random.default_rng(2).standard_normal(6), dtype=np.float32
  170:                 ),
  171:                 "F": np.array(np.arange(6), dtype=np.int32),
  172:             }
  173:         )
  174: 
  175:         # columns is in a different order here than the actual items iterated
  176:         # from the dict
  177:         blocks = df._to_dict_of_blocks()
  178:         columns = []
  179:         for b in blocks.values():
  180:             columns.extend(b.columns)
  181: 
  182:         asdict = dict(df.items())
  183:         asdict2 = {x: y.values for x, y in df.items()}
  184: 
  185:         # dict of series & dict of ndarrays (have dtype info)
  186:         results = []
  187:         results.append(DataFrame.from_records(asdict).reindex(columns=df.columns))
  188:         results.append(
  189:             DataFrame.from_records(asdict, columns=columns).reindex(columns=df.columns)
  190:         )
  191:         results.append(
  192:             DataFrame.from_records(asdict2, columns=columns).reindex(columns=df.columns)
  193:         )
  194: 
  195:         for r in results:
  196:             tm.assert_frame_equal(r, df)
  197: 
  198:     def test_from_records_with_index_data(self):
  199:         df = DataFrame(
  200:             np.random.default_rng(2).standard_normal((10, 3)), columns=["A", "B", "C"]
  201:         )
  202: 
  203:         data = np.random.default_rng(2).standard_normal(10)
  204:         with tm.assert_produces_warning(FutureWarning):
  205:             df1 = DataFrame.from_records(df, index=data)
  206:         tm.assert_index_equal(df1.index, Index(data))
  207: 
  208:     def test_from_records_bad_index_column(self):
  209:         df = DataFrame(
  210:             np.random.default_rng(2).standard_normal((10, 3)), columns=["A", "B", "C"]
  211:         )
  212: 
  213:         # should pass
  214:         with tm.assert_produces_warning(FutureWarning):
  215:             df1 = DataFrame.from_records(df, index=["C"])
  216:         tm.assert_index_equal(df1.index, Index(df.C))
  217: 
  218:         with tm.assert_produces_warning(FutureWarning):
  219:             df1 = DataFrame.from_records(df, index="C")
  220:         tm.assert_index_equal(df1.index, Index(df.C))
  221: 
  222:         # should fail
  223:         msg = "|".join(
  224:             [
  225:                 r"'None of \[2\] are in the columns'",
  226:             ]
  227:         )
  228:         with pytest.raises(KeyError, match=msg):
  229:             with tm.assert_produces_warning(FutureWarning):
  230:                 DataFrame.from_records(df, index=[2])
  231:         with pytest.raises(KeyError, match=msg):
  232:             with tm.assert_produces_warning(FutureWarning):
  233:                 DataFrame.from_records(df, index=2)
  234: 
  235:     def test_from_records_non_tuple(self):
  236:         class Record:
  237:             def __init__(self, *args) -> None:
  238:                 self.args = args
  239: 
  240:             def __getitem__(self, i):
  241:                 return self.args[i]
  242: 
  243:             def __iter__(self) -> Iterator:
  244:                 return iter(self.args)
  245: 
  246:         recs = [Record(1, 2, 3), Record(4, 5, 6), Record(7, 8, 9)]
  247:         tups = [tuple(rec) for rec in recs]
  248: 
  249:         result = DataFrame.from_records(recs)
  250:         expected = DataFrame.from_records(tups)
  251:         tm.assert_frame_equal(result, expected)
  252: 
  253:     def test_from_records_len0_with_columns(self):
  254:         # GH#2633
  255:         result = DataFrame.from_records([], index="foo", columns=["foo", "bar"])
  256:         expected = Index(["bar"])
  257: 
  258:         assert len(result) == 0
  259:         assert result.index.name == "foo"
  260:         tm.assert_index_equal(result.columns, expected)
  261: 
  262:     def test_from_records_series_list_dict(self):
  263:         # GH#27358
  264:         expected = DataFrame([[{"a": 1, "b": 2}, {"a": 3, "b": 4}]]).T
  265:         data = Series([[{"a": 1, "b": 2}], [{"a": 3, "b": 4}]])
  266:         result = DataFrame.from_records(data)
  267:         tm.assert_frame_equal(result, expected)
  268: 
  269:     def test_from_records_series_categorical_index(self):
  270:         # GH#32805
  271:         index = CategoricalIndex(
  272:             [Interval(-20, -10), Interval(-10, 0), Interval(0, 10)]
  273:         )
  274:         series_of_dicts = Series([{"a": 1}, {"a": 2}, {"b": 3}], index=index)
  275:         frame = DataFrame.from_records(series_of_dicts, index=index)
  276:         expected = DataFrame(
  277:             {"a": [1, 2, np.nan], "b": [np.nan, np.nan, 3]}, index=index
  278:         )
  279:         tm.assert_frame_equal(frame, expected)
  280: 
  281:     def test_frame_from_records_utc(self):
  282:         rec = {"datum": 1.5, "begin_time": datetime(2006, 4, 27, tzinfo=pytz.utc)}
  283: 
  284:         # it works
  285:         DataFrame.from_records([rec], index="begin_time")
  286: 
  287:     def test_from_records_to_records(self):
  288:         # from numpy documentation
  289:         arr = np.zeros((2,), dtype=("i4,f4,S10"))
  290:         arr[:] = [(1, 2.0, "Hello"), (2, 3.0, "World")]
  291: 
  292:         DataFrame.from_records(arr)
  293: 
  294:         index = Index(np.arange(len(arr))[::-1])
  295:         indexed_frame = DataFrame.from_records(arr, index=index)
  296:         tm.assert_index_equal(indexed_frame.index, index)
  297: 
  298:         # without names, it should go to last ditch
  299:         arr2 = np.zeros((2, 3))
  300:         tm.assert_frame_equal(DataFrame.from_records(arr2), DataFrame(arr2))
  301: 
  302:         # wrong length
  303:         msg = "|".join(
  304:             [
  305:                 r"Length of values \(2\) does not match length of index \(1\)",
  306:             ]
  307:         )
  308:         with pytest.raises(ValueError, match=msg):
  309:             DataFrame.from_records(arr, index=index[:-1])
  310: 
  311:         indexed_frame = DataFrame.from_records(arr, index="f1")
  312: 
  313:         # what to do?
  314:         records = indexed_frame.to_records()
  315:         assert len(records.dtype.names) == 3
  316: 
  317:         records = indexed_frame.to_records(index=False)
  318:         assert len(records.dtype.names) == 2
  319:         assert "index" not in records.dtype.names
  320: 
  321:     def test_from_records_nones(self):
  322:         tuples = [(1, 2, None, 3), (1, 2, None, 3), (None, 2, 5, 3)]
  323: 
  324:         df = DataFrame.from_records(tuples, columns=["a", "b", "c", "d"])
  325:         assert np.isnan(df["c"][0])
  326: 
  327:     def test_from_records_iterator(self):
  328:         arr = np.array(
  329:             [(1.0, 1.0, 2, 2), (3.0, 3.0, 4, 4), (5.0, 5.0, 6, 6), (7.0, 7.0, 8, 8)],
  330:             dtype=[
  331:                 ("x", np.float64),
  332:                 ("u", np.float32),
  333:                 ("y", np.int64),
  334:                 ("z", np.int32),
  335:             ],
  336:         )
  337:         df = DataFrame.from_records(iter(arr), nrows=2)
  338:         xp = DataFrame(
  339:             {
  340:                 "x": np.array([1.0, 3.0], dtype=np.float64),
  341:                 "u": np.array([1.0, 3.0], dtype=np.float32),
  342:                 "y": np.array([2, 4], dtype=np.int64),
  343:                 "z": np.array([2, 4], dtype=np.int32),
  344:             }
  345:         )
  346:         tm.assert_frame_equal(df.reindex_like(xp), xp)
  347: 
  348:         # no dtypes specified here, so just compare with the default
  349:         arr = [(1.0, 2), (3.0, 4), (5.0, 6), (7.0, 8)]
  350:         df = DataFrame.from_records(iter(arr), columns=["x", "y"], nrows=2)
  351:         tm.assert_frame_equal(df, xp.reindex(columns=["x", "y"]), check_dtype=False)
  352: 
  353:     def test_from_records_tuples_generator(self):
  354:         def tuple_generator(length):
  355:             for i in range(length):
  356:                 letters = "ABCDEFGHIJKLMNOPQRSTUVWXYZ"
  357:                 yield (i, letters[i % len(letters)], i / length)
  358: 
  359:         columns_names = ["Integer", "String", "Float"]
  360:         columns = [
  361:             [i[j] for i in tuple_generator(10)] for j in range(len(columns_names))
  362:         ]
  363:         data = {"Integer": columns[0], "String": columns[1], "Float": columns[2]}
  364:         expected = DataFrame(data, columns=columns_names)
  365: 
  366:         generator = tuple_generator(10)
  367:         result = DataFrame.from_records(generator, columns=columns_names)
  368:         tm.assert_frame_equal(result, expected)
  369: 
  370:     def test_from_records_lists_generator(self):
  371:         def list_generator(length):
  372:             for i in range(length):
  373:                 letters = "ABCDEFGHIJKLMNOPQRSTUVWXYZ"
  374:                 yield [i, letters[i % len(letters)], i / length]
  375: 
  376:         columns_names = ["Integer", "String", "Float"]
  377:         columns = [
  378:             [i[j] for i in list_generator(10)] for j in range(len(columns_names))
  379:         ]
  380:         data = {"Integer": columns[0], "String": columns[1], "Float": columns[2]}
  381:         expected = DataFrame(data, columns=columns_names)
  382: 
  383:         generator = list_generator(10)
  384:         result = DataFrame.from_records(generator, columns=columns_names)
  385:         tm.assert_frame_equal(result, expected)
  386: 
  387:     def test_from_records_columns_not_modified(self):
  388:         tuples = [(1, 2, 3), (1, 2, 3), (2, 5, 3)]
  389: 
  390:         columns = ["a", "b", "c"]
  391:         original_columns = list(columns)
  392: 
  393:         DataFrame.from_records(tuples, columns=columns, index="a")
  394: 
  395:         assert columns == original_columns
  396: 
  397:     def test_from_records_decimal(self):
  398:         tuples = [(Decimal("1.5"),), (Decimal("2.5"),), (None,)]
  399: 
  400:         df = DataFrame.from_records(tuples, columns=["a"])
  401:         assert df["a"].dtype == object
  402: 
  403:         df = DataFrame.from_records(tuples, columns=["a"], coerce_float=True)
  404:         assert df["a"].dtype == np.float64
  405:         assert np.isnan(df["a"].values[-1])
  406: 
  407:     def test_from_records_duplicates(self):
  408:         result = DataFrame.from_records([(1, 2, 3), (4, 5, 6)], columns=["a", "b", "a"])
  409: 
  410:         expected = DataFrame([(1, 2, 3), (4, 5, 6)], columns=["a", "b", "a"])
  411: 
  412:         tm.assert_frame_equal(result, expected)
  413: 
  414:     def test_from_records_set_index_name(self):
  415:         def create_dict(order_id):
  416:             return {
  417:                 "order_id": order_id,
  418:                 "quantity": np.random.default_rng(2).integers(1, 10),
  419:                 "price": np.random.default_rng(2).integers(1, 10),
  420:             }
  421: 
  422:         documents = [create_dict(i) for i in range(10)]
  423:         # demo missing data
  424:         documents.append({"order_id": 10, "quantity": 5})
  425: 
  426:         result = DataFrame.from_records(documents, index="order_id")
  427:         assert result.index.name == "order_id"
  428: 
  429:         # MultiIndex
  430:         result = DataFrame.from_records(documents, index=["order_id", "quantity"])
  431:         assert result.index.names == ("order_id", "quantity")
  432: 
  433:     def test_from_records_misc_brokenness(self):
  434:         # GH#2179
  435: 
  436:         data = {1: ["foo"], 2: ["bar"]}
  437: 
  438:         result = DataFrame.from_records(data, columns=["a", "b"])
  439:         exp = DataFrame(data, columns=["a", "b"])
  440:         tm.assert_frame_equal(result, exp)
  441: 
  442:         # overlap in index/index_names
  443: 
  444:         data = {"a": [1, 2, 3], "b": [4, 5, 6]}
  445: 
  446:         result = DataFrame.from_records(data, index=["a", "b", "c"])
  447:         exp = DataFrame(data, index=["a", "b", "c"])
  448:         tm.assert_frame_equal(result, exp)
  449: 
  450:     def test_from_records_misc_brokenness2(self):
  451:         # GH#2623
  452:         rows = []
  453:         rows.append([datetime(2010, 1, 1), 1])
  454:         rows.append([datetime(2010, 1, 2), "hi"])  # test col upconverts to obj
  455:         result = DataFrame.from_records(rows, columns=["date", "test"])
  456:         expected = DataFrame(
  457:             {"date": [row[0] for row in rows], "test": [row[1] for row in rows]}
  458:         )
  459:         tm.assert_frame_equal(result, expected)
  460:         assert result.dtypes["test"] == np.dtype(object)
  461: 
  462:     def test_from_records_misc_brokenness3(self):
  463:         rows = []
  464:         rows.append([datetime(2010, 1, 1), 1])
  465:         rows.append([datetime(2010, 1, 2), 1])
  466:         result = DataFrame.from_records(rows, columns=["date", "test"])
  467:         expected = DataFrame(
  468:             {"date": [row[0] for row in rows], "test": [row[1] for row in rows]}
  469:         )
  470:         tm.assert_frame_equal(result, expected)
  471: 
  472:     def test_from_records_empty(self):
  473:         # GH#3562
  474:         result = DataFrame.from_records([], columns=["a", "b", "c"])
  475:         expected = DataFrame(columns=["a", "b", "c"])
  476:         tm.assert_frame_equal(result, expected)
  477: 
  478:         result = DataFrame.from_records([], columns=["a", "b", "b"])
  479:         expected = DataFrame(columns=["a", "b", "b"])
  480:         tm.assert_frame_equal(result, expected)
  481: 
  482:     def test_from_records_empty_with_nonempty_fields_gh3682(self):
  483:         a = np.array([(1, 2)], dtype=[("id", np.int64), ("value", np.int64)])
  484:         df = DataFrame.from_records(a, index="id")
  485: 
  486:         ex_index = Index([1], name="id")
  487:         expected = DataFrame({"value": [2]}, index=ex_index, columns=["value"])
  488:         tm.assert_frame_equal(df, expected)
  489: 
  490:         b = a[:0]
  491:         df2 = DataFrame.from_records(b, index="id")
  492:         tm.assert_frame_equal(df2, df.iloc[:0])
  493: 
  494:     def test_from_records_empty2(self):
  495:         # GH#42456
  496:         dtype = [("prop", int)]
  497:         shape = (0, len(dtype))
  498:         arr = np.empty(shape, dtype=dtype)
  499: 
  500:         result = DataFrame.from_records(arr)
  501:         expected = DataFrame({"prop": np.array([], dtype=int)})
  502:         tm.assert_frame_equal(result, expected)
  503: 
  504:         alt = DataFrame(arr)
  505:         tm.assert_frame_equal(alt, expected)
