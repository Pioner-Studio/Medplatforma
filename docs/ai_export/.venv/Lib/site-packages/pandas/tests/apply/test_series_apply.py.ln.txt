    1: import numpy as np
    2: import pytest
    3: 
    4: import pandas as pd
    5: from pandas import (
    6:     DataFrame,
    7:     Index,
    8:     MultiIndex,
    9:     Series,
   10:     concat,
   11:     date_range,
   12:     timedelta_range,
   13: )
   14: import pandas._testing as tm
   15: from pandas.tests.apply.common import series_transform_kernels
   16: 
   17: 
   18: @pytest.fixture(params=[False, "compat"])
   19: def by_row(request):
   20:     return request.param
   21: 
   22: 
   23: def test_series_map_box_timedelta(by_row):
   24:     # GH#11349
   25:     ser = Series(timedelta_range("1 day 1 s", periods=3, freq="h"))
   26: 
   27:     def f(x):
   28:         return x.total_seconds() if by_row else x.dt.total_seconds()
   29: 
   30:     result = ser.apply(f, by_row=by_row)
   31: 
   32:     expected = ser.map(lambda x: x.total_seconds())
   33:     tm.assert_series_equal(result, expected)
   34: 
   35:     expected = Series([86401.0, 90001.0, 93601.0])
   36:     tm.assert_series_equal(result, expected)
   37: 
   38: 
   39: def test_apply(datetime_series, by_row):
   40:     result = datetime_series.apply(np.sqrt, by_row=by_row)
   41:     with np.errstate(all="ignore"):
   42:         expected = np.sqrt(datetime_series)
   43:     tm.assert_series_equal(result, expected)
   44: 
   45:     # element-wise apply (ufunc)
   46:     result = datetime_series.apply(np.exp, by_row=by_row)
   47:     expected = np.exp(datetime_series)
   48:     tm.assert_series_equal(result, expected)
   49: 
   50:     # empty series
   51:     s = Series(dtype=object, name="foo", index=Index([], name="bar"))
   52:     rs = s.apply(lambda x: x, by_row=by_row)
   53:     tm.assert_series_equal(s, rs)
   54: 
   55:     # check all metadata (GH 9322)
   56:     assert s is not rs
   57:     assert s.index is rs.index
   58:     assert s.dtype == rs.dtype
   59:     assert s.name == rs.name
   60: 
   61:     # index but no data
   62:     s = Series(index=[1, 2, 3], dtype=np.float64)
   63:     rs = s.apply(lambda x: x, by_row=by_row)
   64:     tm.assert_series_equal(s, rs)
   65: 
   66: 
   67: def test_apply_map_same_length_inference_bug():
   68:     s = Series([1, 2])
   69: 
   70:     def f(x):
   71:         return (x, x + 1)
   72: 
   73:     result = s.apply(f, by_row="compat")
   74:     expected = s.map(f)
   75:     tm.assert_series_equal(result, expected)
   76: 
   77: 
   78: @pytest.mark.parametrize("convert_dtype", [True, False])
   79: def test_apply_convert_dtype_deprecated(convert_dtype):
   80:     ser = Series(np.random.default_rng(2).standard_normal(10))
   81: 
   82:     def func(x):
   83:         return x if x > 0 else np.nan
   84: 
   85:     with tm.assert_produces_warning(FutureWarning):
   86:         ser.apply(func, convert_dtype=convert_dtype, by_row="compat")
   87: 
   88: 
   89: def test_apply_args():
   90:     s = Series(["foo,bar"])
   91: 
   92:     result = s.apply(str.split, args=(",",))
   93:     assert result[0] == ["foo", "bar"]
   94:     assert isinstance(result[0], list)
   95: 
   96: 
   97: @pytest.mark.parametrize(
   98:     "args, kwargs, increment",
   99:     [((), {}, 0), ((), {"a": 1}, 1), ((2, 3), {}, 32), ((1,), {"c": 2}, 201)],
  100: )
  101: def test_agg_args(args, kwargs, increment):
  102:     # GH 43357
  103:     def f(x, a=0, b=0, c=0):
  104:         return x + a + 10 * b + 100 * c
  105: 
  106:     s = Series([1, 2])
  107:     msg = (
  108:         "in Series.agg cannot aggregate and has been deprecated. "
  109:         "Use Series.transform to keep behavior unchanged."
  110:     )
  111:     with tm.assert_produces_warning(FutureWarning, match=msg):
  112:         result = s.agg(f, 0, *args, **kwargs)
  113:     expected = s + increment
  114:     tm.assert_series_equal(result, expected)
  115: 
  116: 
  117: def test_agg_mapping_func_deprecated():
  118:     # GH 53325
  119:     s = Series([1, 2, 3])
  120: 
  121:     def foo1(x, a=1, c=0):
  122:         return x + a + c
  123: 
  124:     def foo2(x, b=2, c=0):
  125:         return x + b + c
  126: 
  127:     msg = "using .+ in Series.agg cannot aggregate and"
  128:     with tm.assert_produces_warning(FutureWarning, match=msg):
  129:         s.agg(foo1, 0, 3, c=4)
  130:     with tm.assert_produces_warning(FutureWarning, match=msg):
  131:         s.agg([foo1, foo2], 0, 3, c=4)
  132:     with tm.assert_produces_warning(FutureWarning, match=msg):
  133:         s.agg({"a": foo1, "b": foo2}, 0, 3, c=4)
  134: 
  135: 
  136: def test_series_apply_map_box_timestamps(by_row):
  137:     # GH#2689, GH#2627
  138:     ser = Series(date_range("1/1/2000", periods=10))
  139: 
  140:     def func(x):
  141:         return (x.hour, x.day, x.month)
  142: 
  143:     if not by_row:
  144:         msg = "Series' object has no attribute 'hour'"
  145:         with pytest.raises(AttributeError, match=msg):
  146:             ser.apply(func, by_row=by_row)
  147:         return
  148: 
  149:     result = ser.apply(func, by_row=by_row)
  150:     expected = ser.map(func)
  151:     tm.assert_series_equal(result, expected)
  152: 
  153: 
  154: def test_apply_box_dt64():
  155:     # ufunc will not be boxed. Same test cases as the test_map_box
  156:     vals = [pd.Timestamp("2011-01-01"), pd.Timestamp("2011-01-02")]
  157:     ser = Series(vals, dtype="M8[ns]")
  158:     assert ser.dtype == "datetime64[ns]"
  159:     # boxed value must be Timestamp instance
  160:     res = ser.apply(lambda x: f"{type(x).__name__}_{x.day}_{x.tz}", by_row="compat")
  161:     exp = Series(["Timestamp_1_None", "Timestamp_2_None"])
  162:     tm.assert_series_equal(res, exp)
  163: 
  164: 
  165: def test_apply_box_dt64tz():
  166:     vals = [
  167:         pd.Timestamp("2011-01-01", tz="US/Eastern"),
  168:         pd.Timestamp("2011-01-02", tz="US/Eastern"),
  169:     ]
  170:     ser = Series(vals, dtype="M8[ns, US/Eastern]")
  171:     assert ser.dtype == "datetime64[ns, US/Eastern]"
  172:     res = ser.apply(lambda x: f"{type(x).__name__}_{x.day}_{x.tz}", by_row="compat")
  173:     exp = Series(["Timestamp_1_US/Eastern", "Timestamp_2_US/Eastern"])
  174:     tm.assert_series_equal(res, exp)
  175: 
  176: 
  177: def test_apply_box_td64():
  178:     # timedelta
  179:     vals = [pd.Timedelta("1 days"), pd.Timedelta("2 days")]
  180:     ser = Series(vals)
  181:     assert ser.dtype == "timedelta64[ns]"
  182:     res = ser.apply(lambda x: f"{type(x).__name__}_{x.days}", by_row="compat")
  183:     exp = Series(["Timedelta_1", "Timedelta_2"])
  184:     tm.assert_series_equal(res, exp)
  185: 
  186: 
  187: def test_apply_box_period():
  188:     # period
  189:     vals = [pd.Period("2011-01-01", freq="M"), pd.Period("2011-01-02", freq="M")]
  190:     ser = Series(vals)
  191:     assert ser.dtype == "Period[M]"
  192:     res = ser.apply(lambda x: f"{type(x).__name__}_{x.freqstr}", by_row="compat")
  193:     exp = Series(["Period_M", "Period_M"])
  194:     tm.assert_series_equal(res, exp)
  195: 
  196: 
  197: def test_apply_datetimetz(by_row):
  198:     values = date_range("2011-01-01", "2011-01-02", freq="h").tz_localize("Asia/Tokyo")
  199:     s = Series(values, name="XX")
  200: 
  201:     result = s.apply(lambda x: x + pd.offsets.Day(), by_row=by_row)
  202:     exp_values = date_range("2011-01-02", "2011-01-03", freq="h").tz_localize(
  203:         "Asia/Tokyo"
  204:     )
  205:     exp = Series(exp_values, name="XX")
  206:     tm.assert_series_equal(result, exp)
  207: 
  208:     result = s.apply(lambda x: x.hour if by_row else x.dt.hour, by_row=by_row)
  209:     exp = Series(list(range(24)) + [0], name="XX", dtype="int64" if by_row else "int32")
  210:     tm.assert_series_equal(result, exp)
  211: 
  212:     # not vectorized
  213:     def f(x):
  214:         return str(x.tz) if by_row else str(x.dt.tz)
  215: 
  216:     result = s.apply(f, by_row=by_row)
  217:     if by_row:
  218:         exp = Series(["Asia/Tokyo"] * 25, name="XX")
  219:         tm.assert_series_equal(result, exp)
  220:     else:
  221:         assert result == "Asia/Tokyo"
  222: 
  223: 
  224: def test_apply_categorical(by_row, using_infer_string):
  225:     values = pd.Categorical(list("ABBABCD"), categories=list("DCBA"), ordered=True)
  226:     ser = Series(values, name="XX", index=list("abcdefg"))
  227: 
  228:     if not by_row:
  229:         msg = "Series' object has no attribute 'lower"
  230:         with pytest.raises(AttributeError, match=msg):
  231:             ser.apply(lambda x: x.lower(), by_row=by_row)
  232:         assert ser.apply(lambda x: "A", by_row=by_row) == "A"
  233:         return
  234: 
  235:     result = ser.apply(lambda x: x.lower(), by_row=by_row)
  236: 
  237:     # should be categorical dtype when the number of categories are
  238:     # the same
  239:     values = pd.Categorical(list("abbabcd"), categories=list("dcba"), ordered=True)
  240:     exp = Series(values, name="XX", index=list("abcdefg"))
  241:     tm.assert_series_equal(result, exp)
  242:     tm.assert_categorical_equal(result.values, exp.values)
  243: 
  244:     result = ser.apply(lambda x: "A")
  245:     exp = Series(["A"] * 7, name="XX", index=list("abcdefg"))
  246:     tm.assert_series_equal(result, exp)
  247:     assert result.dtype == object if not using_infer_string else "string[pyarrow_numpy]"
  248: 
  249: 
  250: @pytest.mark.parametrize("series", [["1-1", "1-1", np.nan], ["1-1", "1-2", np.nan]])
  251: def test_apply_categorical_with_nan_values(series, by_row):
  252:     # GH 20714 bug fixed in: GH 24275
  253:     s = Series(series, dtype="category")
  254:     if not by_row:
  255:         msg = "'Series' object has no attribute 'split'"
  256:         with pytest.raises(AttributeError, match=msg):
  257:             s.apply(lambda x: x.split("-")[0], by_row=by_row)
  258:         return
  259: 
  260:     result = s.apply(lambda x: x.split("-")[0], by_row=by_row)
  261:     result = result.astype(object)
  262:     expected = Series(["1", "1", np.nan], dtype="category")
  263:     expected = expected.astype(object)
  264:     tm.assert_series_equal(result, expected)
  265: 
  266: 
  267: def test_apply_empty_integer_series_with_datetime_index(by_row):
  268:     # GH 21245
  269:     s = Series([], index=date_range(start="2018-01-01", periods=0), dtype=int)
  270:     result = s.apply(lambda x: x, by_row=by_row)
  271:     tm.assert_series_equal(result, s)
  272: 
  273: 
  274: def test_apply_dataframe_iloc():
  275:     uintDF = DataFrame(np.uint64([1, 2, 3, 4, 5]), columns=["Numbers"])
  276:     indexDF = DataFrame([2, 3, 2, 1, 2], columns=["Indices"])
  277: 
  278:     def retrieve(targetRow, targetDF):
  279:         val = targetDF["Numbers"].iloc[targetRow]
  280:         return val
  281: 
  282:     result = indexDF["Indices"].apply(retrieve, args=(uintDF,))
  283:     expected = Series([3, 4, 3, 2, 3], name="Indices", dtype="uint64")
  284:     tm.assert_series_equal(result, expected)
  285: 
  286: 
  287: def test_transform(string_series, by_row):
  288:     # transforming functions
  289: 
  290:     with np.errstate(all="ignore"):
  291:         f_sqrt = np.sqrt(string_series)
  292:         f_abs = np.abs(string_series)
  293: 
  294:         # ufunc
  295:         result = string_series.apply(np.sqrt, by_row=by_row)
  296:         expected = f_sqrt.copy()
  297:         tm.assert_series_equal(result, expected)
  298: 
  299:         # list-like
  300:         result = string_series.apply([np.sqrt], by_row=by_row)
  301:         expected = f_sqrt.to_frame().copy()
  302:         expected.columns = ["sqrt"]
  303:         tm.assert_frame_equal(result, expected)
  304: 
  305:         result = string_series.apply(["sqrt"], by_row=by_row)
  306:         tm.assert_frame_equal(result, expected)
  307: 
  308:         # multiple items in list
  309:         # these are in the order as if we are applying both functions per
  310:         # series and then concatting
  311:         expected = concat([f_sqrt, f_abs], axis=1)
  312:         expected.columns = ["sqrt", "absolute"]
  313:         result = string_series.apply([np.sqrt, np.abs], by_row=by_row)
  314:         tm.assert_frame_equal(result, expected)
  315: 
  316:         # dict, provide renaming
  317:         expected = concat([f_sqrt, f_abs], axis=1)
  318:         expected.columns = ["foo", "bar"]
  319:         expected = expected.unstack().rename("series")
  320: 
  321:         result = string_series.apply({"foo": np.sqrt, "bar": np.abs}, by_row=by_row)
  322:         tm.assert_series_equal(result.reindex_like(expected), expected)
  323: 
  324: 
  325: @pytest.mark.parametrize("op", series_transform_kernels)
  326: def test_transform_partial_failure(op, request):
  327:     # GH 35964
  328:     if op in ("ffill", "bfill", "pad", "backfill", "shift"):
  329:         request.applymarker(
  330:             pytest.mark.xfail(reason=f"{op} is successful on any dtype")
  331:         )
  332: 
  333:     # Using object makes most transform kernels fail
  334:     ser = Series(3 * [object])
  335: 
  336:     if op in ("fillna", "ngroup"):
  337:         error = ValueError
  338:         msg = "Transform function failed"
  339:     else:
  340:         error = TypeError
  341:         msg = "|".join(
  342:             [
  343:                 "not supported between instances of 'type' and 'type'",
  344:                 "unsupported operand type",
  345:             ]
  346:         )
  347: 
  348:     with pytest.raises(error, match=msg):
  349:         ser.transform([op, "shift"])
  350: 
  351:     with pytest.raises(error, match=msg):
  352:         ser.transform({"A": op, "B": "shift"})
  353: 
  354:     with pytest.raises(error, match=msg):
  355:         ser.transform({"A": [op], "B": ["shift"]})
  356: 
  357:     with pytest.raises(error, match=msg):
  358:         ser.transform({"A": [op, "shift"], "B": [op]})
  359: 
  360: 
  361: def test_transform_partial_failure_valueerror():
  362:     # GH 40211
  363:     def noop(x):
  364:         return x
  365: 
  366:     def raising_op(_):
  367:         raise ValueError
  368: 
  369:     ser = Series(3 * [object])
  370:     msg = "Transform function failed"
  371: 
  372:     with pytest.raises(ValueError, match=msg):
  373:         ser.transform([noop, raising_op])
  374: 
  375:     with pytest.raises(ValueError, match=msg):
  376:         ser.transform({"A": raising_op, "B": noop})
  377: 
  378:     with pytest.raises(ValueError, match=msg):
  379:         ser.transform({"A": [raising_op], "B": [noop]})
  380: 
  381:     with pytest.raises(ValueError, match=msg):
  382:         ser.transform({"A": [noop, raising_op], "B": [noop]})
  383: 
  384: 
  385: def test_demo():
  386:     # demonstration tests
  387:     s = Series(range(6), dtype="int64", name="series")
  388: 
  389:     result = s.agg(["min", "max"])
  390:     expected = Series([0, 5], index=["min", "max"], name="series")
  391:     tm.assert_series_equal(result, expected)
  392: 
  393:     result = s.agg({"foo": "min"})
  394:     expected = Series([0], index=["foo"], name="series")
  395:     tm.assert_series_equal(result, expected)
  396: 
  397: 
  398: @pytest.mark.parametrize("func", [str, lambda x: str(x)])
  399: def test_apply_map_evaluate_lambdas_the_same(string_series, func, by_row):
  400:     # test that we are evaluating row-by-row first if by_row="compat"
  401:     # else vectorized evaluation
  402:     result = string_series.apply(func, by_row=by_row)
  403: 
  404:     if by_row:
  405:         expected = string_series.map(func)
  406:         tm.assert_series_equal(result, expected)
  407:     else:
  408:         assert result == str(string_series)
  409: 
  410: 
  411: def test_agg_evaluate_lambdas(string_series):
  412:     # GH53325
  413:     # in the future, the result will be a Series class.
  414: 
  415:     with tm.assert_produces_warning(FutureWarning):
  416:         result = string_series.agg(lambda x: type(x))
  417:     assert isinstance(result, Series) and len(result) == len(string_series)
  418: 
  419:     with tm.assert_produces_warning(FutureWarning):
  420:         result = string_series.agg(type)
  421:     assert isinstance(result, Series) and len(result) == len(string_series)
  422: 
  423: 
  424: @pytest.mark.parametrize("op_name", ["agg", "apply"])
  425: def test_with_nested_series(datetime_series, op_name):
  426:     # GH 2316
  427:     # .agg with a reducer and a transform, what to do
  428:     msg = "cannot aggregate"
  429:     warning = FutureWarning if op_name == "agg" else None
  430:     with tm.assert_produces_warning(warning, match=msg):
  431:         # GH52123
  432:         result = getattr(datetime_series, op_name)(
  433:             lambda x: Series([x, x**2], index=["x", "x^2"])
  434:         )
  435:     expected = DataFrame({"x": datetime_series, "x^2": datetime_series**2})
  436:     tm.assert_frame_equal(result, expected)
  437: 
  438:     with tm.assert_produces_warning(FutureWarning, match=msg):
  439:         result = datetime_series.agg(lambda x: Series([x, x**2], index=["x", "x^2"]))
  440:     tm.assert_frame_equal(result, expected)
  441: 
  442: 
  443: def test_replicate_describe(string_series):
  444:     # this also tests a result set that is all scalars
  445:     expected = string_series.describe()
  446:     result = string_series.apply(
  447:         {
  448:             "count": "count",
  449:             "mean": "mean",
  450:             "std": "std",
  451:             "min": "min",
  452:             "25%": lambda x: x.quantile(0.25),
  453:             "50%": "median",
  454:             "75%": lambda x: x.quantile(0.75),
  455:             "max": "max",
  456:         },
  457:     )
  458:     tm.assert_series_equal(result, expected)
  459: 
  460: 
  461: def test_reduce(string_series):
  462:     # reductions with named functions
  463:     result = string_series.agg(["sum", "mean"])
  464:     expected = Series(
  465:         [string_series.sum(), string_series.mean()],
  466:         ["sum", "mean"],
  467:         name=string_series.name,
  468:     )
  469:     tm.assert_series_equal(result, expected)
  470: 
  471: 
  472: @pytest.mark.parametrize(
  473:     "how, kwds",
  474:     [("agg", {}), ("apply", {"by_row": "compat"}), ("apply", {"by_row": False})],
  475: )
  476: def test_non_callable_aggregates(how, kwds):
  477:     # test agg using non-callable series attributes
  478:     # GH 39116 - expand to apply
  479:     s = Series([1, 2, None])
  480: 
  481:     # Calling agg w/ just a string arg same as calling s.arg
  482:     result = getattr(s, how)("size", **kwds)
  483:     expected = s.size
  484:     assert result == expected
  485: 
  486:     # test when mixed w/ callable reducers
  487:     result = getattr(s, how)(["size", "count", "mean"], **kwds)
  488:     expected = Series({"size": 3.0, "count": 2.0, "mean": 1.5})
  489:     tm.assert_series_equal(result, expected)
  490: 
  491:     result = getattr(s, how)({"size": "size", "count": "count", "mean": "mean"}, **kwds)
  492:     tm.assert_series_equal(result, expected)
  493: 
  494: 
  495: def test_series_apply_no_suffix_index(by_row):
  496:     # GH36189
  497:     s = Series([4] * 3)
  498:     result = s.apply(["sum", lambda x: x.sum(), lambda x: x.sum()], by_row=by_row)
  499:     expected = Series([12, 12, 12], index=["sum", "<lambda>", "<lambda>"])
  500: 
  501:     tm.assert_series_equal(result, expected)
  502: 
  503: 
  504: @pytest.mark.parametrize(
  505:     "dti,exp",
  506:     [
  507:         (
  508:             Series([1, 2], index=pd.DatetimeIndex([0, 31536000000])),
  509:             DataFrame(np.repeat([[1, 2]], 2, axis=0), dtype="int64"),
  510:         ),
  511:         (
  512:             Series(
  513:                 np.arange(10, dtype=np.float64),
  514:                 index=date_range("2020-01-01", periods=10),
  515:                 name="ts",
  516:             ),
  517:             DataFrame(np.repeat([[1, 2]], 10, axis=0), dtype="int64"),
  518:         ),
  519:     ],
  520: )
  521: @pytest.mark.parametrize("aware", [True, False])
  522: def test_apply_series_on_date_time_index_aware_series(dti, exp, aware):
  523:     # GH 25959
  524:     # Calling apply on a localized time series should not cause an error
  525:     if aware:
  526:         index = dti.tz_localize("UTC").index
  527:     else:
  528:         index = dti.index
  529:     result = Series(index).apply(lambda x: Series([1, 2]))
  530:     tm.assert_frame_equal(result, exp)
  531: 
  532: 
  533: @pytest.mark.parametrize(
  534:     "by_row, expected", [("compat", Series(np.ones(10), dtype="int64")), (False, 1)]
  535: )
  536: def test_apply_scalar_on_date_time_index_aware_series(by_row, expected):
  537:     # GH 25959
  538:     # Calling apply on a localized time series should not cause an error
  539:     series = Series(
  540:         np.arange(10, dtype=np.float64),
  541:         index=date_range("2020-01-01", periods=10, tz="UTC"),
  542:     )
  543:     result = Series(series.index).apply(lambda x: 1, by_row=by_row)
  544:     tm.assert_equal(result, expected)
  545: 
  546: 
  547: def test_apply_to_timedelta(by_row):
  548:     list_of_valid_strings = ["00:00:01", "00:00:02"]
  549:     a = pd.to_timedelta(list_of_valid_strings)
  550:     b = Series(list_of_valid_strings).apply(pd.to_timedelta, by_row=by_row)
  551:     tm.assert_series_equal(Series(a), b)
  552: 
  553:     list_of_strings = ["00:00:01", np.nan, pd.NaT, pd.NaT]
  554: 
  555:     a = pd.to_timedelta(list_of_strings)
  556:     ser = Series(list_of_strings)
  557:     b = ser.apply(pd.to_timedelta, by_row=by_row)
  558:     tm.assert_series_equal(Series(a), b)
  559: 
  560: 
  561: @pytest.mark.parametrize(
  562:     "ops, names",
  563:     [
  564:         ([np.sum], ["sum"]),
  565:         ([np.sum, np.mean], ["sum", "mean"]),
  566:         (np.array([np.sum]), ["sum"]),
  567:         (np.array([np.sum, np.mean]), ["sum", "mean"]),
  568:     ],
  569: )
  570: @pytest.mark.parametrize(
  571:     "how, kwargs",
  572:     [["agg", {}], ["apply", {"by_row": "compat"}], ["apply", {"by_row": False}]],
  573: )
  574: def test_apply_listlike_reducer(string_series, ops, names, how, kwargs):
  575:     # GH 39140
  576:     expected = Series({name: op(string_series) for name, op in zip(names, ops)})
  577:     expected.name = "series"
  578:     warn = FutureWarning if how == "agg" else None
  579:     msg = f"using Series.[{'|'.join(names)}]"
  580:     with tm.assert_produces_warning(warn, match=msg):
  581:         result = getattr(string_series, how)(ops, **kwargs)
  582:     tm.assert_series_equal(result, expected)
  583: 
  584: 
  585: @pytest.mark.parametrize(
  586:     "ops",
  587:     [
  588:         {"A": np.sum},
  589:         {"A": np.sum, "B": np.mean},
  590:         Series({"A": np.sum}),
  591:         Series({"A": np.sum, "B": np.mean}),
  592:     ],
  593: )
  594: @pytest.mark.parametrize(
  595:     "how, kwargs",
  596:     [["agg", {}], ["apply", {"by_row": "compat"}], ["apply", {"by_row": False}]],
  597: )
  598: def test_apply_dictlike_reducer(string_series, ops, how, kwargs, by_row):
  599:     # GH 39140
  600:     expected = Series({name: op(string_series) for name, op in ops.items()})
  601:     expected.name = string_series.name
  602:     warn = FutureWarning if how == "agg" else None
  603:     msg = "using Series.[sum|mean]"
  604:     with tm.assert_produces_warning(warn, match=msg):
  605:         result = getattr(string_series, how)(ops, **kwargs)
  606:     tm.assert_series_equal(result, expected)
  607: 
  608: 
  609: @pytest.mark.parametrize(
  610:     "ops, names",
  611:     [
  612:         ([np.sqrt], ["sqrt"]),
  613:         ([np.abs, np.sqrt], ["absolute", "sqrt"]),
  614:         (np.array([np.sqrt]), ["sqrt"]),
  615:         (np.array([np.abs, np.sqrt]), ["absolute", "sqrt"]),
  616:     ],
  617: )
  618: def test_apply_listlike_transformer(string_series, ops, names, by_row):
  619:     # GH 39140
  620:     with np.errstate(all="ignore"):
  621:         expected = concat([op(string_series) for op in ops], axis=1)
  622:         expected.columns = names
  623:         result = string_series.apply(ops, by_row=by_row)
  624:         tm.assert_frame_equal(result, expected)
  625: 
  626: 
  627: @pytest.mark.parametrize(
  628:     "ops, expected",
  629:     [
  630:         ([lambda x: x], DataFrame({"<lambda>": [1, 2, 3]})),
  631:         ([lambda x: x.sum()], Series([6], index=["<lambda>"])),
  632:     ],
  633: )
  634: def test_apply_listlike_lambda(ops, expected, by_row):
  635:     # GH53400
  636:     ser = Series([1, 2, 3])
  637:     result = ser.apply(ops, by_row=by_row)
  638:     tm.assert_equal(result, expected)
  639: 
  640: 
  641: @pytest.mark.parametrize(
  642:     "ops",
  643:     [
  644:         {"A": np.sqrt},
  645:         {"A": np.sqrt, "B": np.exp},
  646:         Series({"A": np.sqrt}),
  647:         Series({"A": np.sqrt, "B": np.exp}),
  648:     ],
  649: )
  650: def test_apply_dictlike_transformer(string_series, ops, by_row):
  651:     # GH 39140
  652:     with np.errstate(all="ignore"):
  653:         expected = concat({name: op(string_series) for name, op in ops.items()})
  654:         expected.name = string_series.name
  655:         result = string_series.apply(ops, by_row=by_row)
  656:         tm.assert_series_equal(result, expected)
  657: 
  658: 
  659: @pytest.mark.parametrize(
  660:     "ops, expected",
  661:     [
  662:         (
  663:             {"a": lambda x: x},
  664:             Series([1, 2, 3], index=MultiIndex.from_arrays([["a"] * 3, range(3)])),
  665:         ),
  666:         ({"a": lambda x: x.sum()}, Series([6], index=["a"])),
  667:     ],
  668: )
  669: def test_apply_dictlike_lambda(ops, by_row, expected):
  670:     # GH53400
  671:     ser = Series([1, 2, 3])
  672:     result = ser.apply(ops, by_row=by_row)
  673:     tm.assert_equal(result, expected)
  674: 
  675: 
  676: def test_apply_retains_column_name(by_row):
  677:     # GH 16380
  678:     df = DataFrame({"x": range(3)}, Index(range(3), name="x"))
  679:     result = df.x.apply(lambda x: Series(range(x + 1), Index(range(x + 1), name="y")))
  680:     expected = DataFrame(
  681:         [[0.0, np.nan, np.nan], [0.0, 1.0, np.nan], [0.0, 1.0, 2.0]],
  682:         columns=Index(range(3), name="y"),
  683:         index=Index(range(3), name="x"),
  684:     )
  685:     tm.assert_frame_equal(result, expected)
  686: 
  687: 
  688: def test_apply_type():
  689:     # GH 46719
  690:     s = Series([3, "string", float], index=["a", "b", "c"])
  691:     result = s.apply(type)
  692:     expected = Series([int, str, type], index=["a", "b", "c"])
  693:     tm.assert_series_equal(result, expected)
  694: 
  695: 
  696: def test_series_apply_unpack_nested_data():
  697:     # GH#55189
  698:     ser = Series([[1, 2, 3], [4, 5, 6, 7]])
  699:     result = ser.apply(lambda x: Series(x))
  700:     expected = DataFrame({0: [1.0, 4.0], 1: [2.0, 5.0], 2: [3.0, 6.0], 3: [np.nan, 7]})
  701:     tm.assert_frame_equal(result, expected)
