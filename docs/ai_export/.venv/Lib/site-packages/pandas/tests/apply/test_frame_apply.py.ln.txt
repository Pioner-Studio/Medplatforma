    1: from datetime import datetime
    2: import warnings
    3: 
    4: import numpy as np
    5: import pytest
    6: 
    7: from pandas.core.dtypes.dtypes import CategoricalDtype
    8: 
    9: import pandas as pd
   10: from pandas import (
   11:     DataFrame,
   12:     MultiIndex,
   13:     Series,
   14:     Timestamp,
   15:     date_range,
   16: )
   17: import pandas._testing as tm
   18: from pandas.tests.frame.common import zip_frames
   19: 
   20: 
   21: @pytest.fixture
   22: def int_frame_const_col():
   23:     """
   24:     Fixture for DataFrame of ints which are constant per column
   25: 
   26:     Columns are ['A', 'B', 'C'], with values (per column): [1, 2, 3]
   27:     """
   28:     df = DataFrame(
   29:         np.tile(np.arange(3, dtype="int64"), 6).reshape(6, -1) + 1,
   30:         columns=["A", "B", "C"],
   31:     )
   32:     return df
   33: 
   34: 
   35: @pytest.fixture(params=["python", pytest.param("numba", marks=pytest.mark.single_cpu)])
   36: def engine(request):
   37:     if request.param == "numba":
   38:         pytest.importorskip("numba")
   39:     return request.param
   40: 
   41: 
   42: def test_apply(float_frame, engine, request):
   43:     if engine == "numba":
   44:         mark = pytest.mark.xfail(reason="numba engine not supporting numpy ufunc yet")
   45:         request.node.add_marker(mark)
   46:     with np.errstate(all="ignore"):
   47:         # ufunc
   48:         result = np.sqrt(float_frame["A"])
   49:         expected = float_frame.apply(np.sqrt, engine=engine)["A"]
   50:         tm.assert_series_equal(result, expected)
   51: 
   52:         # aggregator
   53:         result = float_frame.apply(np.mean, engine=engine)["A"]
   54:         expected = np.mean(float_frame["A"])
   55:         assert result == expected
   56: 
   57:         d = float_frame.index[0]
   58:         result = float_frame.apply(np.mean, axis=1, engine=engine)
   59:         expected = np.mean(float_frame.xs(d))
   60:         assert result[d] == expected
   61:         assert result.index is float_frame.index
   62: 
   63: 
   64: @pytest.mark.parametrize("axis", [0, 1])
   65: @pytest.mark.parametrize("raw", [True, False])
   66: def test_apply_args(float_frame, axis, raw, engine, request):
   67:     if engine == "numba":
   68:         mark = pytest.mark.xfail(reason="numba engine doesn't support args")
   69:         request.node.add_marker(mark)
   70:     result = float_frame.apply(
   71:         lambda x, y: x + y, axis, args=(1,), raw=raw, engine=engine
   72:     )
   73:     expected = float_frame + 1
   74:     tm.assert_frame_equal(result, expected)
   75: 
   76: 
   77: def test_apply_categorical_func():
   78:     # GH 9573
   79:     df = DataFrame({"c0": ["A", "A", "B", "B"], "c1": ["C", "C", "D", "D"]})
   80:     result = df.apply(lambda ts: ts.astype("category"))
   81: 
   82:     assert result.shape == (4, 2)
   83:     assert isinstance(result["c0"].dtype, CategoricalDtype)
   84:     assert isinstance(result["c1"].dtype, CategoricalDtype)
   85: 
   86: 
   87: def test_apply_axis1_with_ea():
   88:     # GH#36785
   89:     expected = DataFrame({"A": [Timestamp("2013-01-01", tz="UTC")]})
   90:     result = expected.apply(lambda x: x, axis=1)
   91:     tm.assert_frame_equal(result, expected)
   92: 
   93: 
   94: @pytest.mark.parametrize(
   95:     "data, dtype",
   96:     [(1, None), (1, CategoricalDtype([1])), (Timestamp("2013-01-01", tz="UTC"), None)],
   97: )
   98: def test_agg_axis1_duplicate_index(data, dtype):
   99:     # GH 42380
  100:     expected = DataFrame([[data], [data]], index=["a", "a"], dtype=dtype)
  101:     result = expected.agg(lambda x: x, axis=1)
  102:     tm.assert_frame_equal(result, expected)
  103: 
  104: 
  105: def test_apply_mixed_datetimelike():
  106:     # mixed datetimelike
  107:     # GH 7778
  108:     expected = DataFrame(
  109:         {
  110:             "A": date_range("20130101", periods=3),
  111:             "B": pd.to_timedelta(np.arange(3), unit="s"),
  112:         }
  113:     )
  114:     result = expected.apply(lambda x: x, axis=1)
  115:     tm.assert_frame_equal(result, expected)
  116: 
  117: 
  118: @pytest.mark.parametrize("func", [np.sqrt, np.mean])
  119: def test_apply_empty(func, engine):
  120:     # empty
  121:     empty_frame = DataFrame()
  122: 
  123:     result = empty_frame.apply(func, engine=engine)
  124:     assert result.empty
  125: 
  126: 
  127: def test_apply_float_frame(float_frame, engine):
  128:     no_rows = float_frame[:0]
  129:     result = no_rows.apply(lambda x: x.mean(), engine=engine)
  130:     expected = Series(np.nan, index=float_frame.columns)
  131:     tm.assert_series_equal(result, expected)
  132: 
  133:     no_cols = float_frame.loc[:, []]
  134:     result = no_cols.apply(lambda x: x.mean(), axis=1, engine=engine)
  135:     expected = Series(np.nan, index=float_frame.index)
  136:     tm.assert_series_equal(result, expected)
  137: 
  138: 
  139: def test_apply_empty_except_index(engine):
  140:     # GH 2476
  141:     expected = DataFrame(index=["a"])
  142:     result = expected.apply(lambda x: x["a"], axis=1, engine=engine)
  143:     tm.assert_frame_equal(result, expected)
  144: 
  145: 
  146: def test_apply_with_reduce_empty():
  147:     # reduce with an empty DataFrame
  148:     empty_frame = DataFrame()
  149: 
  150:     x = []
  151:     result = empty_frame.apply(x.append, axis=1, result_type="expand")
  152:     tm.assert_frame_equal(result, empty_frame)
  153:     result = empty_frame.apply(x.append, axis=1, result_type="reduce")
  154:     expected = Series([], dtype=np.float64)
  155:     tm.assert_series_equal(result, expected)
  156: 
  157:     empty_with_cols = DataFrame(columns=["a", "b", "c"])
  158:     result = empty_with_cols.apply(x.append, axis=1, result_type="expand")
  159:     tm.assert_frame_equal(result, empty_with_cols)
  160:     result = empty_with_cols.apply(x.append, axis=1, result_type="reduce")
  161:     expected = Series([], dtype=np.float64)
  162:     tm.assert_series_equal(result, expected)
  163: 
  164:     # Ensure that x.append hasn't been called
  165:     assert x == []
  166: 
  167: 
  168: @pytest.mark.parametrize("func", ["sum", "prod", "any", "all"])
  169: def test_apply_funcs_over_empty(func):
  170:     # GH 28213
  171:     df = DataFrame(columns=["a", "b", "c"])
  172: 
  173:     result = df.apply(getattr(np, func))
  174:     expected = getattr(df, func)()
  175:     if func in ("sum", "prod"):
  176:         expected = expected.astype(float)
  177:     tm.assert_series_equal(result, expected)
  178: 
  179: 
  180: def test_nunique_empty():
  181:     # GH 28213
  182:     df = DataFrame(columns=["a", "b", "c"])
  183: 
  184:     result = df.nunique()
  185:     expected = Series(0, index=df.columns)
  186:     tm.assert_series_equal(result, expected)
  187: 
  188:     result = df.T.nunique()
  189:     expected = Series([], dtype=np.float64)
  190:     tm.assert_series_equal(result, expected)
  191: 
  192: 
  193: def test_apply_standard_nonunique():
  194:     df = DataFrame([[1, 2, 3], [4, 5, 6], [7, 8, 9]], index=["a", "a", "c"])
  195: 
  196:     result = df.apply(lambda s: s[0], axis=1)
  197:     expected = Series([1, 4, 7], ["a", "a", "c"])
  198:     tm.assert_series_equal(result, expected)
  199: 
  200:     result = df.T.apply(lambda s: s[0], axis=0)
  201:     tm.assert_series_equal(result, expected)
  202: 
  203: 
  204: def test_apply_broadcast_scalars(float_frame):
  205:     # scalars
  206:     result = float_frame.apply(np.mean, result_type="broadcast")
  207:     expected = DataFrame([float_frame.mean()], index=float_frame.index)
  208:     tm.assert_frame_equal(result, expected)
  209: 
  210: 
  211: def test_apply_broadcast_scalars_axis1(float_frame):
  212:     result = float_frame.apply(np.mean, axis=1, result_type="broadcast")
  213:     m = float_frame.mean(axis=1)
  214:     expected = DataFrame({c: m for c in float_frame.columns})
  215:     tm.assert_frame_equal(result, expected)
  216: 
  217: 
  218: def test_apply_broadcast_lists_columns(float_frame):
  219:     # lists
  220:     result = float_frame.apply(
  221:         lambda x: list(range(len(float_frame.columns))),
  222:         axis=1,
  223:         result_type="broadcast",
  224:     )
  225:     m = list(range(len(float_frame.columns)))
  226:     expected = DataFrame(
  227:         [m] * len(float_frame.index),
  228:         dtype="float64",
  229:         index=float_frame.index,
  230:         columns=float_frame.columns,
  231:     )
  232:     tm.assert_frame_equal(result, expected)
  233: 
  234: 
  235: def test_apply_broadcast_lists_index(float_frame):
  236:     result = float_frame.apply(
  237:         lambda x: list(range(len(float_frame.index))), result_type="broadcast"
  238:     )
  239:     m = list(range(len(float_frame.index)))
  240:     expected = DataFrame(
  241:         {c: m for c in float_frame.columns},
  242:         dtype="float64",
  243:         index=float_frame.index,
  244:     )
  245:     tm.assert_frame_equal(result, expected)
  246: 
  247: 
  248: def test_apply_broadcast_list_lambda_func(int_frame_const_col):
  249:     # preserve columns
  250:     df = int_frame_const_col
  251:     result = df.apply(lambda x: [1, 2, 3], axis=1, result_type="broadcast")
  252:     tm.assert_frame_equal(result, df)
  253: 
  254: 
  255: def test_apply_broadcast_series_lambda_func(int_frame_const_col):
  256:     df = int_frame_const_col
  257:     result = df.apply(
  258:         lambda x: Series([1, 2, 3], index=list("abc")),
  259:         axis=1,
  260:         result_type="broadcast",
  261:     )
  262:     expected = df.copy()
  263:     tm.assert_frame_equal(result, expected)
  264: 
  265: 
  266: @pytest.mark.parametrize("axis", [0, 1])
  267: def test_apply_raw_float_frame(float_frame, axis, engine):
  268:     if engine == "numba":
  269:         pytest.skip("numba can't handle when UDF returns None.")
  270: 
  271:     def _assert_raw(x):
  272:         assert isinstance(x, np.ndarray)
  273:         assert x.ndim == 1
  274: 
  275:     float_frame.apply(_assert_raw, axis=axis, engine=engine, raw=True)
  276: 
  277: 
  278: @pytest.mark.parametrize("axis", [0, 1])
  279: def test_apply_raw_float_frame_lambda(float_frame, axis, engine):
  280:     result = float_frame.apply(np.mean, axis=axis, engine=engine, raw=True)
  281:     expected = float_frame.apply(lambda x: x.values.mean(), axis=axis)
  282:     tm.assert_series_equal(result, expected)
  283: 
  284: 
  285: def test_apply_raw_float_frame_no_reduction(float_frame, engine):
  286:     # no reduction
  287:     result = float_frame.apply(lambda x: x * 2, engine=engine, raw=True)
  288:     expected = float_frame * 2
  289:     tm.assert_frame_equal(result, expected)
  290: 
  291: 
  292: @pytest.mark.parametrize("axis", [0, 1])
  293: def test_apply_raw_mixed_type_frame(axis, engine):
  294:     if engine == "numba":
  295:         pytest.skip("isinstance check doesn't work with numba")
  296: 
  297:     def _assert_raw(x):
  298:         assert isinstance(x, np.ndarray)
  299:         assert x.ndim == 1
  300: 
  301:     # Mixed dtype (GH-32423)
  302:     df = DataFrame(
  303:         {
  304:             "a": 1.0,
  305:             "b": 2,
  306:             "c": "foo",
  307:             "float32": np.array([1.0] * 10, dtype="float32"),
  308:             "int32": np.array([1] * 10, dtype="int32"),
  309:         },
  310:         index=np.arange(10),
  311:     )
  312:     df.apply(_assert_raw, axis=axis, engine=engine, raw=True)
  313: 
  314: 
  315: def test_apply_axis1(float_frame):
  316:     d = float_frame.index[0]
  317:     result = float_frame.apply(np.mean, axis=1)[d]
  318:     expected = np.mean(float_frame.xs(d))
  319:     assert result == expected
  320: 
  321: 
  322: def test_apply_mixed_dtype_corner():
  323:     df = DataFrame({"A": ["foo"], "B": [1.0]})
  324:     result = df[:0].apply(np.mean, axis=1)
  325:     # the result here is actually kind of ambiguous, should it be a Series
  326:     # or a DataFrame?
  327:     expected = Series(np.nan, index=pd.Index([], dtype="int64"))
  328:     tm.assert_series_equal(result, expected)
  329: 
  330: 
  331: def test_apply_mixed_dtype_corner_indexing():
  332:     df = DataFrame({"A": ["foo"], "B": [1.0]})
  333:     result = df.apply(lambda x: x["A"], axis=1)
  334:     expected = Series(["foo"], index=[0])
  335:     tm.assert_series_equal(result, expected)
  336: 
  337:     result = df.apply(lambda x: x["B"], axis=1)
  338:     expected = Series([1.0], index=[0])
  339:     tm.assert_series_equal(result, expected)
  340: 
  341: 
  342: @pytest.mark.filterwarnings("ignore::RuntimeWarning")
  343: @pytest.mark.parametrize("ax", ["index", "columns"])
  344: @pytest.mark.parametrize(
  345:     "func", [lambda x: x, lambda x: x.mean()], ids=["identity", "mean"]
  346: )
  347: @pytest.mark.parametrize("raw", [True, False])
  348: @pytest.mark.parametrize("axis", [0, 1])
  349: def test_apply_empty_infer_type(ax, func, raw, axis, engine, request):
  350:     df = DataFrame(**{ax: ["a", "b", "c"]})
  351: 
  352:     with np.errstate(all="ignore"):
  353:         test_res = func(np.array([], dtype="f8"))
  354:         is_reduction = not isinstance(test_res, np.ndarray)
  355: 
  356:         result = df.apply(func, axis=axis, engine=engine, raw=raw)
  357:         if is_reduction:
  358:             agg_axis = df._get_agg_axis(axis)
  359:             assert isinstance(result, Series)
  360:             assert result.index is agg_axis
  361:         else:
  362:             assert isinstance(result, DataFrame)
  363: 
  364: 
  365: def test_apply_empty_infer_type_broadcast():
  366:     no_cols = DataFrame(index=["a", "b", "c"])
  367:     result = no_cols.apply(lambda x: x.mean(), result_type="broadcast")
  368:     assert isinstance(result, DataFrame)
  369: 
  370: 
  371: def test_apply_with_args_kwds_add_some(float_frame):
  372:     def add_some(x, howmuch=0):
  373:         return x + howmuch
  374: 
  375:     result = float_frame.apply(add_some, howmuch=2)
  376:     expected = float_frame.apply(lambda x: x + 2)
  377:     tm.assert_frame_equal(result, expected)
  378: 
  379: 
  380: def test_apply_with_args_kwds_agg_and_add(float_frame):
  381:     def agg_and_add(x, howmuch=0):
  382:         return x.mean() + howmuch
  383: 
  384:     result = float_frame.apply(agg_and_add, howmuch=2)
  385:     expected = float_frame.apply(lambda x: x.mean() + 2)
  386:     tm.assert_series_equal(result, expected)
  387: 
  388: 
  389: def test_apply_with_args_kwds_subtract_and_divide(float_frame):
  390:     def subtract_and_divide(x, sub, divide=1):
  391:         return (x - sub) / divide
  392: 
  393:     result = float_frame.apply(subtract_and_divide, args=(2,), divide=2)
  394:     expected = float_frame.apply(lambda x: (x - 2.0) / 2.0)
  395:     tm.assert_frame_equal(result, expected)
  396: 
  397: 
  398: def test_apply_yield_list(float_frame):
  399:     result = float_frame.apply(list)
  400:     tm.assert_frame_equal(result, float_frame)
  401: 
  402: 
  403: def test_apply_reduce_Series(float_frame):
  404:     float_frame.iloc[::2, float_frame.columns.get_loc("A")] = np.nan
  405:     expected = float_frame.mean(1)
  406:     result = float_frame.apply(np.mean, axis=1)
  407:     tm.assert_series_equal(result, expected)
  408: 
  409: 
  410: def test_apply_reduce_to_dict():
  411:     # GH 25196 37544
  412:     data = DataFrame([[1, 2], [3, 4]], columns=["c0", "c1"], index=["i0", "i1"])
  413: 
  414:     result = data.apply(dict, axis=0)
  415:     expected = Series([{"i0": 1, "i1": 3}, {"i0": 2, "i1": 4}], index=data.columns)
  416:     tm.assert_series_equal(result, expected)
  417: 
  418:     result = data.apply(dict, axis=1)
  419:     expected = Series([{"c0": 1, "c1": 2}, {"c0": 3, "c1": 4}], index=data.index)
  420:     tm.assert_series_equal(result, expected)
  421: 
  422: 
  423: def test_apply_differently_indexed():
  424:     df = DataFrame(np.random.default_rng(2).standard_normal((20, 10)))
  425: 
  426:     result = df.apply(Series.describe, axis=0)
  427:     expected = DataFrame({i: v.describe() for i, v in df.items()}, columns=df.columns)
  428:     tm.assert_frame_equal(result, expected)
  429: 
  430:     result = df.apply(Series.describe, axis=1)
  431:     expected = DataFrame({i: v.describe() for i, v in df.T.items()}, columns=df.index).T
  432:     tm.assert_frame_equal(result, expected)
  433: 
  434: 
  435: def test_apply_bug():
  436:     # GH 6125
  437:     positions = DataFrame(
  438:         [
  439:             [1, "ABC0", 50],
  440:             [1, "YUM0", 20],
  441:             [1, "DEF0", 20],
  442:             [2, "ABC1", 50],
  443:             [2, "YUM1", 20],
  444:             [2, "DEF1", 20],
  445:         ],
  446:         columns=["a", "market", "position"],
  447:     )
  448: 
  449:     def f(r):
  450:         return r["market"]
  451: 
  452:     expected = positions.apply(f, axis=1)
  453: 
  454:     positions = DataFrame(
  455:         [
  456:             [datetime(2013, 1, 1), "ABC0", 50],
  457:             [datetime(2013, 1, 2), "YUM0", 20],
  458:             [datetime(2013, 1, 3), "DEF0", 20],
  459:             [datetime(2013, 1, 4), "ABC1", 50],
  460:             [datetime(2013, 1, 5), "YUM1", 20],
  461:             [datetime(2013, 1, 6), "DEF1", 20],
  462:         ],
  463:         columns=["a", "market", "position"],
  464:     )
  465:     result = positions.apply(f, axis=1)
  466:     tm.assert_series_equal(result, expected)
  467: 
  468: 
  469: def test_apply_convert_objects():
  470:     expected = DataFrame(
  471:         {
  472:             "A": [
  473:                 "foo",
  474:                 "foo",
  475:                 "foo",
  476:                 "foo",
  477:                 "bar",
  478:                 "bar",
  479:                 "bar",
  480:                 "bar",
  481:                 "foo",
  482:                 "foo",
  483:                 "foo",
  484:             ],
  485:             "B": [
  486:                 "one",
  487:                 "one",
  488:                 "one",
  489:                 "two",
  490:                 "one",
  491:                 "one",
  492:                 "one",
  493:                 "two",
  494:                 "two",
  495:                 "two",
  496:                 "one",
  497:             ],
  498:             "C": [
  499:                 "dull",
  500:                 "dull",
  501:                 "shiny",
  502:                 "dull",
  503:                 "dull",
  504:                 "shiny",
  505:                 "shiny",
  506:                 "dull",
  507:                 "shiny",
  508:                 "shiny",
  509:                 "shiny",
  510:             ],
  511:             "D": np.random.default_rng(2).standard_normal(11),
  512:             "E": np.random.default_rng(2).standard_normal(11),
  513:             "F": np.random.default_rng(2).standard_normal(11),
  514:         }
  515:     )
  516: 
  517:     result = expected.apply(lambda x: x, axis=1)
  518:     tm.assert_frame_equal(result, expected)
  519: 
  520: 
  521: def test_apply_attach_name(float_frame):
  522:     result = float_frame.apply(lambda x: x.name)
  523:     expected = Series(float_frame.columns, index=float_frame.columns)
  524:     tm.assert_series_equal(result, expected)
  525: 
  526: 
  527: def test_apply_attach_name_axis1(float_frame):
  528:     result = float_frame.apply(lambda x: x.name, axis=1)
  529:     expected = Series(float_frame.index, index=float_frame.index)
  530:     tm.assert_series_equal(result, expected)
  531: 
  532: 
  533: def test_apply_attach_name_non_reduction(float_frame):
  534:     # non-reductions
  535:     result = float_frame.apply(lambda x: np.repeat(x.name, len(x)))
  536:     expected = DataFrame(
  537:         np.tile(float_frame.columns, (len(float_frame.index), 1)),
  538:         index=float_frame.index,
  539:         columns=float_frame.columns,
  540:     )
  541:     tm.assert_frame_equal(result, expected)
  542: 
  543: 
  544: def test_apply_attach_name_non_reduction_axis1(float_frame):
  545:     result = float_frame.apply(lambda x: np.repeat(x.name, len(x)), axis=1)
  546:     expected = Series(
  547:         np.repeat(t[0], len(float_frame.columns)) for t in float_frame.itertuples()
  548:     )
  549:     expected.index = float_frame.index
  550:     tm.assert_series_equal(result, expected)
  551: 
  552: 
  553: def test_apply_multi_index():
  554:     index = MultiIndex.from_arrays([["a", "a", "b"], ["c", "d", "d"]])
  555:     s = DataFrame([[1, 2], [3, 4], [5, 6]], index=index, columns=["col1", "col2"])
  556:     result = s.apply(lambda x: Series({"min": min(x), "max": max(x)}), 1)
  557:     expected = DataFrame([[1, 2], [3, 4], [5, 6]], index=index, columns=["min", "max"])
  558:     tm.assert_frame_equal(result, expected, check_like=True)
  559: 
  560: 
  561: @pytest.mark.parametrize(
  562:     "df, dicts",
  563:     [
  564:         [
  565:             DataFrame([["foo", "bar"], ["spam", "eggs"]]),
  566:             Series([{0: "foo", 1: "spam"}, {0: "bar", 1: "eggs"}]),
  567:         ],
  568:         [DataFrame([[0, 1], [2, 3]]), Series([{0: 0, 1: 2}, {0: 1, 1: 3}])],
  569:     ],
  570: )
  571: def test_apply_dict(df, dicts):
  572:     # GH 8735
  573:     fn = lambda x: x.to_dict()
  574:     reduce_true = df.apply(fn, result_type="reduce")
  575:     reduce_false = df.apply(fn, result_type="expand")
  576:     reduce_none = df.apply(fn)
  577: 
  578:     tm.assert_series_equal(reduce_true, dicts)
  579:     tm.assert_frame_equal(reduce_false, df)
  580:     tm.assert_series_equal(reduce_none, dicts)
  581: 
  582: 
  583: def test_apply_non_numpy_dtype():
  584:     # GH 12244
  585:     df = DataFrame({"dt": date_range("2015-01-01", periods=3, tz="Europe/Brussels")})
  586:     result = df.apply(lambda x: x)
  587:     tm.assert_frame_equal(result, df)
  588: 
  589:     result = df.apply(lambda x: x + pd.Timedelta("1day"))
  590:     expected = DataFrame(
  591:         {"dt": date_range("2015-01-02", periods=3, tz="Europe/Brussels")}
  592:     )
  593:     tm.assert_frame_equal(result, expected)
  594: 
  595: 
  596: def test_apply_non_numpy_dtype_category():
  597:     df = DataFrame({"dt": ["a", "b", "c", "a"]}, dtype="category")
  598:     result = df.apply(lambda x: x)
  599:     tm.assert_frame_equal(result, df)
  600: 
  601: 
  602: def test_apply_dup_names_multi_agg():
  603:     # GH 21063
  604:     df = DataFrame([[0, 1], [2, 3]], columns=["a", "a"])
  605:     expected = DataFrame([[0, 1]], columns=["a", "a"], index=["min"])
  606:     result = df.agg(["min"])
  607: 
  608:     tm.assert_frame_equal(result, expected)
  609: 
  610: 
  611: @pytest.mark.parametrize("op", ["apply", "agg"])
  612: def test_apply_nested_result_axis_1(op):
  613:     # GH 13820
  614:     def apply_list(row):
  615:         return [2 * row["A"], 2 * row["C"], 2 * row["B"]]
  616: 
  617:     df = DataFrame(np.zeros((4, 4)), columns=list("ABCD"))
  618:     result = getattr(df, op)(apply_list, axis=1)
  619:     expected = Series(
  620:         [[0.0, 0.0, 0.0], [0.0, 0.0, 0.0], [0.0, 0.0, 0.0], [0.0, 0.0, 0.0]]
  621:     )
  622:     tm.assert_series_equal(result, expected)
  623: 
  624: 
  625: def test_apply_noreduction_tzaware_object():
  626:     # https://github.com/pandas-dev/pandas/issues/31505
  627:     expected = DataFrame(
  628:         {"foo": [Timestamp("2020", tz="UTC")]}, dtype="datetime64[ns, UTC]"
  629:     )
  630:     result = expected.apply(lambda x: x)
  631:     tm.assert_frame_equal(result, expected)
  632:     result = expected.apply(lambda x: x.copy())
  633:     tm.assert_frame_equal(result, expected)
  634: 
  635: 
  636: def test_apply_function_runs_once():
  637:     # https://github.com/pandas-dev/pandas/issues/30815
  638: 
  639:     df = DataFrame({"a": [1, 2, 3]})
  640:     names = []  # Save row names function is applied to
  641: 
  642:     def reducing_function(row):
  643:         names.append(row.name)
  644: 
  645:     def non_reducing_function(row):
  646:         names.append(row.name)
  647:         return row
  648: 
  649:     for func in [reducing_function, non_reducing_function]:
  650:         del names[:]
  651: 
  652:         df.apply(func, axis=1)
  653:         assert names == list(df.index)
  654: 
  655: 
  656: def test_apply_raw_function_runs_once(engine):
  657:     # https://github.com/pandas-dev/pandas/issues/34506
  658:     if engine == "numba":
  659:         pytest.skip("appending to list outside of numba func is not supported")
  660: 
  661:     df = DataFrame({"a": [1, 2, 3]})
  662:     values = []  # Save row values function is applied to
  663: 
  664:     def reducing_function(row):
  665:         values.extend(row)
  666: 
  667:     def non_reducing_function(row):
  668:         values.extend(row)
  669:         return row
  670: 
  671:     for func in [reducing_function, non_reducing_function]:
  672:         del values[:]
  673: 
  674:         df.apply(func, engine=engine, raw=True, axis=1)
  675:         assert values == list(df.a.to_list())
  676: 
  677: 
  678: def test_apply_with_byte_string():
  679:     # GH 34529
  680:     df = DataFrame(np.array([b"abcd", b"efgh"]), columns=["col"])
  681:     expected = DataFrame(np.array([b"abcd", b"efgh"]), columns=["col"], dtype=object)
  682:     # After we make the apply we expect a dataframe just
  683:     # like the original but with the object datatype
  684:     result = df.apply(lambda x: x.astype("object"))
  685:     tm.assert_frame_equal(result, expected)
  686: 
  687: 
  688: @pytest.mark.parametrize("val", ["asd", 12, None, np.nan])
  689: def test_apply_category_equalness(val):
  690:     # Check if categorical comparisons on apply, GH 21239
  691:     df_values = ["asd", None, 12, "asd", "cde", np.nan]
  692:     df = DataFrame({"a": df_values}, dtype="category")
  693: 
  694:     result = df.a.apply(lambda x: x == val)
  695:     expected = Series(
  696:         [np.nan if pd.isnull(x) else x == val for x in df_values], name="a"
  697:     )
  698:     tm.assert_series_equal(result, expected)
  699: 
  700: 
  701: # the user has supplied an opaque UDF where
  702: # they are transforming the input that requires
  703: # us to infer the output
  704: 
  705: 
  706: def test_infer_row_shape():
  707:     # GH 17437
  708:     # if row shape is changing, infer it
  709:     df = DataFrame(np.random.default_rng(2).random((10, 2)))
  710:     result = df.apply(np.fft.fft, axis=0).shape
  711:     assert result == (10, 2)
  712: 
  713:     result = df.apply(np.fft.rfft, axis=0).shape
  714:     assert result == (6, 2)
  715: 
  716: 
  717: @pytest.mark.parametrize(
  718:     "ops, by_row, expected",
  719:     [
  720:         ({"a": lambda x: x + 1}, "compat", DataFrame({"a": [2, 3]})),
  721:         ({"a": lambda x: x + 1}, False, DataFrame({"a": [2, 3]})),
  722:         ({"a": lambda x: x.sum()}, "compat", Series({"a": 3})),
  723:         ({"a": lambda x: x.sum()}, False, Series({"a": 3})),
  724:         (
  725:             {"a": ["sum", np.sum, lambda x: x.sum()]},
  726:             "compat",
  727:             DataFrame({"a": [3, 3, 3]}, index=["sum", "sum", "<lambda>"]),
  728:         ),
  729:         (
  730:             {"a": ["sum", np.sum, lambda x: x.sum()]},
  731:             False,
  732:             DataFrame({"a": [3, 3, 3]}, index=["sum", "sum", "<lambda>"]),
  733:         ),
  734:         ({"a": lambda x: 1}, "compat", DataFrame({"a": [1, 1]})),
  735:         ({"a": lambda x: 1}, False, Series({"a": 1})),
  736:     ],
  737: )
  738: def test_dictlike_lambda(ops, by_row, expected):
  739:     # GH53601
  740:     df = DataFrame({"a": [1, 2]})
  741:     result = df.apply(ops, by_row=by_row)
  742:     tm.assert_equal(result, expected)
  743: 
  744: 
  745: @pytest.mark.parametrize(
  746:     "ops",
  747:     [
  748:         {"a": lambda x: x + 1},
  749:         {"a": lambda x: x.sum()},
  750:         {"a": ["sum", np.sum, lambda x: x.sum()]},
  751:         {"a": lambda x: 1},
  752:     ],
  753: )
  754: def test_dictlike_lambda_raises(ops):
  755:     # GH53601
  756:     df = DataFrame({"a": [1, 2]})
  757:     with pytest.raises(ValueError, match="by_row=True not allowed"):
  758:         df.apply(ops, by_row=True)
  759: 
  760: 
  761: def test_with_dictlike_columns():
  762:     # GH 17602
  763:     df = DataFrame([[1, 2], [1, 2]], columns=["a", "b"])
  764:     result = df.apply(lambda x: {"s": x["a"] + x["b"]}, axis=1)
  765:     expected = Series([{"s": 3} for t in df.itertuples()])
  766:     tm.assert_series_equal(result, expected)
  767: 
  768:     df["tm"] = [
  769:         Timestamp("2017-05-01 00:00:00"),
  770:         Timestamp("2017-05-02 00:00:00"),
  771:     ]
  772:     result = df.apply(lambda x: {"s": x["a"] + x["b"]}, axis=1)
  773:     tm.assert_series_equal(result, expected)
  774: 
  775:     # compose a series
  776:     result = (df["a"] + df["b"]).apply(lambda x: {"s": x})
  777:     expected = Series([{"s": 3}, {"s": 3}])
  778:     tm.assert_series_equal(result, expected)
  779: 
  780: 
  781: def test_with_dictlike_columns_with_datetime():
  782:     # GH 18775
  783:     df = DataFrame()
  784:     df["author"] = ["X", "Y", "Z"]
  785:     df["publisher"] = ["BBC", "NBC", "N24"]
  786:     df["date"] = pd.to_datetime(
  787:         ["17-10-2010 07:15:30", "13-05-2011 08:20:35", "15-01-2013 09:09:09"],
  788:         dayfirst=True,
  789:     )
  790:     result = df.apply(lambda x: {}, axis=1)
  791:     expected = Series([{}, {}, {}])
  792:     tm.assert_series_equal(result, expected)
  793: 
  794: 
  795: def test_with_dictlike_columns_with_infer():
  796:     # GH 17602
  797:     df = DataFrame([[1, 2], [1, 2]], columns=["a", "b"])
  798:     result = df.apply(lambda x: {"s": x["a"] + x["b"]}, axis=1, result_type="expand")
  799:     expected = DataFrame({"s": [3, 3]})
  800:     tm.assert_frame_equal(result, expected)
  801: 
  802:     df["tm"] = [
  803:         Timestamp("2017-05-01 00:00:00"),
  804:         Timestamp("2017-05-02 00:00:00"),
  805:     ]
  806:     result = df.apply(lambda x: {"s": x["a"] + x["b"]}, axis=1, result_type="expand")
  807:     tm.assert_frame_equal(result, expected)
  808: 
  809: 
  810: @pytest.mark.parametrize(
  811:     "ops, by_row, expected",
  812:     [
  813:         ([lambda x: x + 1], "compat", DataFrame({("a", "<lambda>"): [2, 3]})),
  814:         ([lambda x: x + 1], False, DataFrame({("a", "<lambda>"): [2, 3]})),
  815:         ([lambda x: x.sum()], "compat", DataFrame({"a": [3]}, index=["<lambda>"])),
  816:         ([lambda x: x.sum()], False, DataFrame({"a": [3]}, index=["<lambda>"])),
  817:         (
  818:             ["sum", np.sum, lambda x: x.sum()],
  819:             "compat",
  820:             DataFrame({"a": [3, 3, 3]}, index=["sum", "sum", "<lambda>"]),
  821:         ),
  822:         (
  823:             ["sum", np.sum, lambda x: x.sum()],
  824:             False,
  825:             DataFrame({"a": [3, 3, 3]}, index=["sum", "sum", "<lambda>"]),
  826:         ),
  827:         (
  828:             [lambda x: x + 1, lambda x: 3],
  829:             "compat",
  830:             DataFrame([[2, 3], [3, 3]], columns=[["a", "a"], ["<lambda>", "<lambda>"]]),
  831:         ),
  832:         (
  833:             [lambda x: 2, lambda x: 3],
  834:             False,
  835:             DataFrame({"a": [2, 3]}, ["<lambda>", "<lambda>"]),
  836:         ),
  837:     ],
  838: )
  839: def test_listlike_lambda(ops, by_row, expected):
  840:     # GH53601
  841:     df = DataFrame({"a": [1, 2]})
  842:     result = df.apply(ops, by_row=by_row)
  843:     tm.assert_equal(result, expected)
  844: 
  845: 
  846: @pytest.mark.parametrize(
  847:     "ops",
  848:     [
  849:         [lambda x: x + 1],
  850:         [lambda x: x.sum()],
  851:         ["sum", np.sum, lambda x: x.sum()],
  852:         [lambda x: x + 1, lambda x: 3],
  853:     ],
  854: )
  855: def test_listlike_lambda_raises(ops):
  856:     # GH53601
  857:     df = DataFrame({"a": [1, 2]})
  858:     with pytest.raises(ValueError, match="by_row=True not allowed"):
  859:         df.apply(ops, by_row=True)
  860: 
  861: 
  862: def test_with_listlike_columns():
  863:     # GH 17348
  864:     df = DataFrame(
  865:         {
  866:             "a": Series(np.random.default_rng(2).standard_normal(4)),
  867:             "b": ["a", "list", "of", "words"],
  868:             "ts": date_range("2016-10-01", periods=4, freq="h"),
  869:         }
  870:     )
  871: 
  872:     result = df[["a", "b"]].apply(tuple, axis=1)
  873:     expected = Series([t[1:] for t in df[["a", "b"]].itertuples()])
  874:     tm.assert_series_equal(result, expected)
  875: 
  876:     result = df[["a", "ts"]].apply(tuple, axis=1)
  877:     expected = Series([t[1:] for t in df[["a", "ts"]].itertuples()])
  878:     tm.assert_series_equal(result, expected)
  879: 
  880: 
  881: def test_with_listlike_columns_returning_list():
  882:     # GH 18919
  883:     df = DataFrame({"x": Series([["a", "b"], ["q"]]), "y": Series([["z"], ["q", "t"]])})
  884:     df.index = MultiIndex.from_tuples([("i0", "j0"), ("i1", "j1")])
  885: 
  886:     result = df.apply(lambda row: [el for el in row["x"] if el in row["y"]], axis=1)
  887:     expected = Series([[], ["q"]], index=df.index)
  888:     tm.assert_series_equal(result, expected)
  889: 
  890: 
  891: def test_infer_output_shape_columns():
  892:     # GH 18573
  893: 
  894:     df = DataFrame(
  895:         {
  896:             "number": [1.0, 2.0],
  897:             "string": ["foo", "bar"],
  898:             "datetime": [
  899:                 Timestamp("2017-11-29 03:30:00"),
  900:                 Timestamp("2017-11-29 03:45:00"),
  901:             ],
  902:         }
  903:     )
  904:     result = df.apply(lambda row: (row.number, row.string), axis=1)
  905:     expected = Series([(t.number, t.string) for t in df.itertuples()])
  906:     tm.assert_series_equal(result, expected)
  907: 
  908: 
  909: def test_infer_output_shape_listlike_columns():
  910:     # GH 16353
  911: 
  912:     df = DataFrame(
  913:         np.random.default_rng(2).standard_normal((6, 3)), columns=["A", "B", "C"]
  914:     )
  915: 
  916:     result = df.apply(lambda x: [1, 2, 3], axis=1)
  917:     expected = Series([[1, 2, 3] for t in df.itertuples()])
  918:     tm.assert_series_equal(result, expected)
  919: 
  920:     result = df.apply(lambda x: [1, 2], axis=1)
  921:     expected = Series([[1, 2] for t in df.itertuples()])
  922:     tm.assert_series_equal(result, expected)
  923: 
  924: 
  925: @pytest.mark.parametrize("val", [1, 2])
  926: def test_infer_output_shape_listlike_columns_np_func(val):
  927:     # GH 17970
  928:     df = DataFrame({"a": [1, 2, 3]}, index=list("abc"))
  929: 
  930:     result = df.apply(lambda row: np.ones(val), axis=1)
  931:     expected = Series([np.ones(val) for t in df.itertuples()], index=df.index)
  932:     tm.assert_series_equal(result, expected)
  933: 
  934: 
  935: def test_infer_output_shape_listlike_columns_with_timestamp():
  936:     # GH 17892
  937:     df = DataFrame(
  938:         {
  939:             "a": [
  940:                 Timestamp("2010-02-01"),
  941:                 Timestamp("2010-02-04"),
  942:                 Timestamp("2010-02-05"),
  943:                 Timestamp("2010-02-06"),
  944:             ],
  945:             "b": [9, 5, 4, 3],
  946:             "c": [5, 3, 4, 2],
  947:             "d": [1, 2, 3, 4],
  948:         }
  949:     )
  950: 
  951:     def fun(x):
  952:         return (1, 2)
  953: 
  954:     result = df.apply(fun, axis=1)
  955:     expected = Series([(1, 2) for t in df.itertuples()])
  956:     tm.assert_series_equal(result, expected)
  957: 
  958: 
  959: @pytest.mark.parametrize("lst", [[1, 2, 3], [1, 2]])
  960: def test_consistent_coerce_for_shapes(lst):
  961:     # we want column names to NOT be propagated
  962:     # just because the shape matches the input shape
  963:     df = DataFrame(
  964:         np.random.default_rng(2).standard_normal((4, 3)), columns=["A", "B", "C"]
  965:     )
  966: 
  967:     result = df.apply(lambda x: lst, axis=1)
  968:     expected = Series([lst for t in df.itertuples()])
  969:     tm.assert_series_equal(result, expected)
  970: 
  971: 
  972: def test_consistent_names(int_frame_const_col):
  973:     # if a Series is returned, we should use the resulting index names
  974:     df = int_frame_const_col
  975: 
  976:     result = df.apply(
  977:         lambda x: Series([1, 2, 3], index=["test", "other", "cols"]), axis=1
  978:     )
  979:     expected = int_frame_const_col.rename(
  980:         columns={"A": "test", "B": "other", "C": "cols"}
  981:     )
  982:     tm.assert_frame_equal(result, expected)
  983: 
  984:     result = df.apply(lambda x: Series([1, 2], index=["test", "other"]), axis=1)
  985:     expected = expected[["test", "other"]]
  986:     tm.assert_frame_equal(result, expected)
  987: 
  988: 
  989: def test_result_type(int_frame_const_col):
  990:     # result_type should be consistent no matter which
  991:     # path we take in the code
  992:     df = int_frame_const_col
  993: 
  994:     result = df.apply(lambda x: [1, 2, 3], axis=1, result_type="expand")
  995:     expected = df.copy()
  996:     expected.columns = [0, 1, 2]
  997:     tm.assert_frame_equal(result, expected)
  998: 
  999: 
 1000: def test_result_type_shorter_list(int_frame_const_col):
 1001:     # result_type should be consistent no matter which
 1002:     # path we take in the code
 1003:     df = int_frame_const_col
 1004:     result = df.apply(lambda x: [1, 2], axis=1, result_type="expand")
 1005:     expected = df[["A", "B"]].copy()
 1006:     expected.columns = [0, 1]
 1007:     tm.assert_frame_equal(result, expected)
 1008: 
 1009: 
 1010: def test_result_type_broadcast(int_frame_const_col, request, engine):
 1011:     # result_type should be consistent no matter which
 1012:     # path we take in the code
 1013:     if engine == "numba":
 1014:         mark = pytest.mark.xfail(reason="numba engine doesn't support list return")
 1015:         request.node.add_marker(mark)
 1016:     df = int_frame_const_col
 1017:     # broadcast result
 1018:     result = df.apply(
 1019:         lambda x: [1, 2, 3], axis=1, result_type="broadcast", engine=engine
 1020:     )
 1021:     expected = df.copy()
 1022:     tm.assert_frame_equal(result, expected)
 1023: 
 1024: 
 1025: def test_result_type_broadcast_series_func(int_frame_const_col, engine, request):
 1026:     # result_type should be consistent no matter which
 1027:     # path we take in the code
 1028:     if engine == "numba":
 1029:         mark = pytest.mark.xfail(
 1030:             reason="numba Series constructor only support ndarrays not list data"
 1031:         )
 1032:         request.node.add_marker(mark)
 1033:     df = int_frame_const_col
 1034:     columns = ["other", "col", "names"]
 1035:     result = df.apply(
 1036:         lambda x: Series([1, 2, 3], index=columns),
 1037:         axis=1,
 1038:         result_type="broadcast",
 1039:         engine=engine,
 1040:     )
 1041:     expected = df.copy()
 1042:     tm.assert_frame_equal(result, expected)
 1043: 
 1044: 
 1045: def test_result_type_series_result(int_frame_const_col, engine, request):
 1046:     # result_type should be consistent no matter which
 1047:     # path we take in the code
 1048:     if engine == "numba":
 1049:         mark = pytest.mark.xfail(
 1050:             reason="numba Series constructor only support ndarrays not list data"
 1051:         )
 1052:         request.node.add_marker(mark)
 1053:     df = int_frame_const_col
 1054:     # series result
 1055:     result = df.apply(lambda x: Series([1, 2, 3], index=x.index), axis=1, engine=engine)
 1056:     expected = df.copy()
 1057:     tm.assert_frame_equal(result, expected)
 1058: 
 1059: 
 1060: def test_result_type_series_result_other_index(int_frame_const_col, engine, request):
 1061:     # result_type should be consistent no matter which
 1062:     # path we take in the code
 1063: 
 1064:     if engine == "numba":
 1065:         mark = pytest.mark.xfail(
 1066:             reason="no support in numba Series constructor for list of columns"
 1067:         )
 1068:         request.node.add_marker(mark)
 1069:     df = int_frame_const_col
 1070:     # series result with other index
 1071:     columns = ["other", "col", "names"]
 1072:     result = df.apply(lambda x: Series([1, 2, 3], index=columns), axis=1, engine=engine)
 1073:     expected = df.copy()
 1074:     expected.columns = columns
 1075:     tm.assert_frame_equal(result, expected)
 1076: 
 1077: 
 1078: @pytest.mark.parametrize(
 1079:     "box",
 1080:     [lambda x: list(x), lambda x: tuple(x), lambda x: np.array(x, dtype="int64")],
 1081:     ids=["list", "tuple", "array"],
 1082: )
 1083: def test_consistency_for_boxed(box, int_frame_const_col):
 1084:     # passing an array or list should not affect the output shape
 1085:     df = int_frame_const_col
 1086: 
 1087:     result = df.apply(lambda x: box([1, 2]), axis=1)
 1088:     expected = Series([box([1, 2]) for t in df.itertuples()])
 1089:     tm.assert_series_equal(result, expected)
 1090: 
 1091:     result = df.apply(lambda x: box([1, 2]), axis=1, result_type="expand")
 1092:     expected = int_frame_const_col[["A", "B"]].rename(columns={"A": 0, "B": 1})
 1093:     tm.assert_frame_equal(result, expected)
 1094: 
 1095: 
 1096: def test_agg_transform(axis, float_frame):
 1097:     other_axis = 1 if axis in {0, "index"} else 0
 1098: 
 1099:     with np.errstate(all="ignore"):
 1100:         f_abs = np.abs(float_frame)
 1101:         f_sqrt = np.sqrt(float_frame)
 1102: 
 1103:         # ufunc
 1104:         expected = f_sqrt.copy()
 1105:         result = float_frame.apply(np.sqrt, axis=axis)
 1106:         tm.assert_frame_equal(result, expected)
 1107: 
 1108:         # list-like
 1109:         result = float_frame.apply([np.sqrt], axis=axis)
 1110:         expected = f_sqrt.copy()
 1111:         if axis in {0, "index"}:
 1112:             expected.columns = MultiIndex.from_product([float_frame.columns, ["sqrt"]])
 1113:         else:
 1114:             expected.index = MultiIndex.from_product([float_frame.index, ["sqrt"]])
 1115:         tm.assert_frame_equal(result, expected)
 1116: 
 1117:         # multiple items in list
 1118:         # these are in the order as if we are applying both
 1119:         # functions per series and then concatting
 1120:         result = float_frame.apply([np.abs, np.sqrt], axis=axis)
 1121:         expected = zip_frames([f_abs, f_sqrt], axis=other_axis)
 1122:         if axis in {0, "index"}:
 1123:             expected.columns = MultiIndex.from_product(
 1124:                 [float_frame.columns, ["absolute", "sqrt"]]
 1125:             )
 1126:         else:
 1127:             expected.index = MultiIndex.from_product(
 1128:                 [float_frame.index, ["absolute", "sqrt"]]
 1129:             )
 1130:         tm.assert_frame_equal(result, expected)
 1131: 
 1132: 
 1133: def test_demo():
 1134:     # demonstration tests
 1135:     df = DataFrame({"A": range(5), "B": 5})
 1136: 
 1137:     result = df.agg(["min", "max"])
 1138:     expected = DataFrame(
 1139:         {"A": [0, 4], "B": [5, 5]}, columns=["A", "B"], index=["min", "max"]
 1140:     )
 1141:     tm.assert_frame_equal(result, expected)
 1142: 
 1143: 
 1144: def test_demo_dict_agg():
 1145:     # demonstration tests
 1146:     df = DataFrame({"A": range(5), "B": 5})
 1147:     result = df.agg({"A": ["min", "max"], "B": ["sum", "max"]})
 1148:     expected = DataFrame(
 1149:         {"A": [4.0, 0.0, np.nan], "B": [5.0, np.nan, 25.0]},
 1150:         columns=["A", "B"],
 1151:         index=["max", "min", "sum"],
 1152:     )
 1153:     tm.assert_frame_equal(result.reindex_like(expected), expected)
 1154: 
 1155: 
 1156: def test_agg_with_name_as_column_name():
 1157:     # GH 36212 - Column name is "name"
 1158:     data = {"name": ["foo", "bar"]}
 1159:     df = DataFrame(data)
 1160: 
 1161:     # result's name should be None
 1162:     result = df.agg({"name": "count"})
 1163:     expected = Series({"name": 2})
 1164:     tm.assert_series_equal(result, expected)
 1165: 
 1166:     # Check if name is still preserved when aggregating series instead
 1167:     result = df["name"].agg({"name": "count"})
 1168:     expected = Series({"name": 2}, name="name")
 1169:     tm.assert_series_equal(result, expected)
 1170: 
 1171: 
 1172: def test_agg_multiple_mixed():
 1173:     # GH 20909
 1174:     mdf = DataFrame(
 1175:         {
 1176:             "A": [1, 2, 3],
 1177:             "B": [1.0, 2.0, 3.0],
 1178:             "C": ["foo", "bar", "baz"],
 1179:         }
 1180:     )
 1181:     expected = DataFrame(
 1182:         {
 1183:             "A": [1, 6],
 1184:             "B": [1.0, 6.0],
 1185:             "C": ["bar", "foobarbaz"],
 1186:         },
 1187:         index=["min", "sum"],
 1188:     )
 1189:     # sorted index
 1190:     result = mdf.agg(["min", "sum"])
 1191:     tm.assert_frame_equal(result, expected)
 1192: 
 1193:     result = mdf[["C", "B", "A"]].agg(["sum", "min"])
 1194:     # GH40420: the result of .agg should have an index that is sorted
 1195:     # according to the arguments provided to agg.
 1196:     expected = expected[["C", "B", "A"]].reindex(["sum", "min"])
 1197:     tm.assert_frame_equal(result, expected)
 1198: 
 1199: 
 1200: def test_agg_multiple_mixed_raises():
 1201:     # GH 20909
 1202:     mdf = DataFrame(
 1203:         {
 1204:             "A": [1, 2, 3],
 1205:             "B": [1.0, 2.0, 3.0],
 1206:             "C": ["foo", "bar", "baz"],
 1207:             "D": date_range("20130101", periods=3),
 1208:         }
 1209:     )
 1210: 
 1211:     # sorted index
 1212:     msg = "does not support reduction"
 1213:     with pytest.raises(TypeError, match=msg):
 1214:         mdf.agg(["min", "sum"])
 1215: 
 1216:     with pytest.raises(TypeError, match=msg):
 1217:         mdf[["D", "C", "B", "A"]].agg(["sum", "min"])
 1218: 
 1219: 
 1220: def test_agg_reduce(axis, float_frame):
 1221:     other_axis = 1 if axis in {0, "index"} else 0
 1222:     name1, name2 = float_frame.axes[other_axis].unique()[:2].sort_values()
 1223: 
 1224:     # all reducers
 1225:     expected = pd.concat(
 1226:         [
 1227:             float_frame.mean(axis=axis),
 1228:             float_frame.max(axis=axis),
 1229:             float_frame.sum(axis=axis),
 1230:         ],
 1231:         axis=1,
 1232:     )
 1233:     expected.columns = ["mean", "max", "sum"]
 1234:     expected = expected.T if axis in {0, "index"} else expected
 1235: 
 1236:     result = float_frame.agg(["mean", "max", "sum"], axis=axis)
 1237:     tm.assert_frame_equal(result, expected)
 1238: 
 1239:     # dict input with scalars
 1240:     func = {name1: "mean", name2: "sum"}
 1241:     result = float_frame.agg(func, axis=axis)
 1242:     expected = Series(
 1243:         [
 1244:             float_frame.loc(other_axis)[name1].mean(),
 1245:             float_frame.loc(other_axis)[name2].sum(),
 1246:         ],
 1247:         index=[name1, name2],
 1248:     )
 1249:     tm.assert_series_equal(result, expected)
 1250: 
 1251:     # dict input with lists
 1252:     func = {name1: ["mean"], name2: ["sum"]}
 1253:     result = float_frame.agg(func, axis=axis)
 1254:     expected = DataFrame(
 1255:         {
 1256:             name1: Series([float_frame.loc(other_axis)[name1].mean()], index=["mean"]),
 1257:             name2: Series([float_frame.loc(other_axis)[name2].sum()], index=["sum"]),
 1258:         }
 1259:     )
 1260:     expected = expected.T if axis in {1, "columns"} else expected
 1261:     tm.assert_frame_equal(result, expected)
 1262: 
 1263:     # dict input with lists with multiple
 1264:     func = {name1: ["mean", "sum"], name2: ["sum", "max"]}
 1265:     result = float_frame.agg(func, axis=axis)
 1266:     expected = pd.concat(
 1267:         {
 1268:             name1: Series(
 1269:                 [
 1270:                     float_frame.loc(other_axis)[name1].mean(),
 1271:                     float_frame.loc(other_axis)[name1].sum(),
 1272:                 ],
 1273:                 index=["mean", "sum"],
 1274:             ),
 1275:             name2: Series(
 1276:                 [
 1277:                     float_frame.loc(other_axis)[name2].sum(),
 1278:                     float_frame.loc(other_axis)[name2].max(),
 1279:                 ],
 1280:                 index=["sum", "max"],
 1281:             ),
 1282:         },
 1283:         axis=1,
 1284:     )
 1285:     expected = expected.T if axis in {1, "columns"} else expected
 1286:     tm.assert_frame_equal(result, expected)
 1287: 
 1288: 
 1289: def test_nuiscance_columns():
 1290:     # GH 15015
 1291:     df = DataFrame(
 1292:         {
 1293:             "A": [1, 2, 3],
 1294:             "B": [1.0, 2.0, 3.0],
 1295:             "C": ["foo", "bar", "baz"],
 1296:             "D": date_range("20130101", periods=3),
 1297:         }
 1298:     )
 1299: 
 1300:     result = df.agg("min")
 1301:     expected = Series([1, 1.0, "bar", Timestamp("20130101")], index=df.columns)
 1302:     tm.assert_series_equal(result, expected)
 1303: 
 1304:     result = df.agg(["min"])
 1305:     expected = DataFrame(
 1306:         [[1, 1.0, "bar", Timestamp("20130101").as_unit("ns")]],
 1307:         index=["min"],
 1308:         columns=df.columns,
 1309:     )
 1310:     tm.assert_frame_equal(result, expected)
 1311: 
 1312:     msg = "does not support reduction"
 1313:     with pytest.raises(TypeError, match=msg):
 1314:         df.agg("sum")
 1315: 
 1316:     result = df[["A", "B", "C"]].agg("sum")
 1317:     expected = Series([6, 6.0, "foobarbaz"], index=["A", "B", "C"])
 1318:     tm.assert_series_equal(result, expected)
 1319: 
 1320:     msg = "does not support reduction"
 1321:     with pytest.raises(TypeError, match=msg):
 1322:         df.agg(["sum"])
 1323: 
 1324: 
 1325: @pytest.mark.parametrize("how", ["agg", "apply"])
 1326: def test_non_callable_aggregates(how):
 1327:     # GH 16405
 1328:     # 'size' is a property of frame/series
 1329:     # validate that this is working
 1330:     # GH 39116 - expand to apply
 1331:     df = DataFrame(
 1332:         {"A": [None, 2, 3], "B": [1.0, np.nan, 3.0], "C": ["foo", None, "bar"]}
 1333:     )
 1334: 
 1335:     # Function aggregate
 1336:     result = getattr(df, how)({"A": "count"})
 1337:     expected = Series({"A": 2})
 1338: 
 1339:     tm.assert_series_equal(result, expected)
 1340: 
 1341:     # Non-function aggregate
 1342:     result = getattr(df, how)({"A": "size"})
 1343:     expected = Series({"A": 3})
 1344: 
 1345:     tm.assert_series_equal(result, expected)
 1346: 
 1347:     # Mix function and non-function aggs
 1348:     result1 = getattr(df, how)(["count", "size"])
 1349:     result2 = getattr(df, how)(
 1350:         {"A": ["count", "size"], "B": ["count", "size"], "C": ["count", "size"]}
 1351:     )
 1352:     expected = DataFrame(
 1353:         {
 1354:             "A": {"count": 2, "size": 3},
 1355:             "B": {"count": 2, "size": 3},
 1356:             "C": {"count": 2, "size": 3},
 1357:         }
 1358:     )
 1359: 
 1360:     tm.assert_frame_equal(result1, result2, check_like=True)
 1361:     tm.assert_frame_equal(result2, expected, check_like=True)
 1362: 
 1363:     # Just functional string arg is same as calling df.arg()
 1364:     result = getattr(df, how)("count")
 1365:     expected = df.count()
 1366: 
 1367:     tm.assert_series_equal(result, expected)
 1368: 
 1369: 
 1370: @pytest.mark.parametrize("how", ["agg", "apply"])
 1371: def test_size_as_str(how, axis):
 1372:     # GH 39934
 1373:     df = DataFrame(
 1374:         {"A": [None, 2, 3], "B": [1.0, np.nan, 3.0], "C": ["foo", None, "bar"]}
 1375:     )
 1376:     # Just a string attribute arg same as calling df.arg
 1377:     # on the columns
 1378:     result = getattr(df, how)("size", axis=axis)
 1379:     if axis in (0, "index"):
 1380:         expected = Series(df.shape[0], index=df.columns)
 1381:     else:
 1382:         expected = Series(df.shape[1], index=df.index)
 1383:     tm.assert_series_equal(result, expected)
 1384: 
 1385: 
 1386: def test_agg_listlike_result():
 1387:     # GH-29587 user defined function returning list-likes
 1388:     df = DataFrame({"A": [2, 2, 3], "B": [1.5, np.nan, 1.5], "C": ["foo", None, "bar"]})
 1389: 
 1390:     def func(group_col):
 1391:         return list(group_col.dropna().unique())
 1392: 
 1393:     result = df.agg(func)
 1394:     expected = Series([[2, 3], [1.5], ["foo", "bar"]], index=["A", "B", "C"])
 1395:     tm.assert_series_equal(result, expected)
 1396: 
 1397:     result = df.agg([func])
 1398:     expected = expected.to_frame("func").T
 1399:     tm.assert_frame_equal(result, expected)
 1400: 
 1401: 
 1402: @pytest.mark.parametrize("axis", [0, 1])
 1403: @pytest.mark.parametrize(
 1404:     "args, kwargs",
 1405:     [
 1406:         ((1, 2, 3), {}),
 1407:         ((8, 7, 15), {}),
 1408:         ((1, 2), {}),
 1409:         ((1,), {"b": 2}),
 1410:         ((), {"a": 1, "b": 2}),
 1411:         ((), {"a": 2, "b": 1}),
 1412:         ((), {"a": 1, "b": 2, "c": 3}),
 1413:     ],
 1414: )
 1415: def test_agg_args_kwargs(axis, args, kwargs):
 1416:     def f(x, a, b, c=3):
 1417:         return x.sum() + (a + b) / c
 1418: 
 1419:     df = DataFrame([[1, 2], [3, 4]])
 1420: 
 1421:     if axis == 0:
 1422:         expected = Series([5.0, 7.0])
 1423:     else:
 1424:         expected = Series([4.0, 8.0])
 1425: 
 1426:     result = df.agg(f, axis, *args, **kwargs)
 1427: 
 1428:     tm.assert_series_equal(result, expected)
 1429: 
 1430: 
 1431: @pytest.mark.parametrize("num_cols", [2, 3, 5])
 1432: def test_frequency_is_original(num_cols, engine, request):
 1433:     # GH 22150
 1434:     if engine == "numba":
 1435:         mark = pytest.mark.xfail(reason="numba engine only supports numeric indices")
 1436:         request.node.add_marker(mark)
 1437:     index = pd.DatetimeIndex(["1950-06-30", "1952-10-24", "1953-05-29"])
 1438:     original = index.copy()
 1439:     df = DataFrame(1, index=index, columns=range(num_cols))
 1440:     df.apply(lambda x: x, engine=engine)
 1441:     assert index.freq == original.freq
 1442: 
 1443: 
 1444: def test_apply_datetime_tz_issue(engine, request):
 1445:     # GH 29052
 1446: 
 1447:     if engine == "numba":
 1448:         mark = pytest.mark.xfail(
 1449:             reason="numba engine doesn't support non-numeric indexes"
 1450:         )
 1451:         request.node.add_marker(mark)
 1452: 
 1453:     timestamps = [
 1454:         Timestamp("2019-03-15 12:34:31.909000+0000", tz="UTC"),
 1455:         Timestamp("2019-03-15 12:34:34.359000+0000", tz="UTC"),
 1456:         Timestamp("2019-03-15 12:34:34.660000+0000", tz="UTC"),
 1457:     ]
 1458:     df = DataFrame(data=[0, 1, 2], index=timestamps)
 1459:     result = df.apply(lambda x: x.name, axis=1, engine=engine)
 1460:     expected = Series(index=timestamps, data=timestamps)
 1461: 
 1462:     tm.assert_series_equal(result, expected)
 1463: 
 1464: 
 1465: @pytest.mark.parametrize("df", [DataFrame({"A": ["a", None], "B": ["c", "d"]})])
 1466: @pytest.mark.parametrize("method", ["min", "max", "sum"])
 1467: def test_mixed_column_raises(df, method, using_infer_string):
 1468:     # GH 16832
 1469:     if method == "sum":
 1470:         msg = r'can only concatenate str \(not "int"\) to str|does not support'
 1471:     else:
 1472:         msg = "not supported between instances of 'str' and 'float'"
 1473:     if not using_infer_string:
 1474:         with pytest.raises(TypeError, match=msg):
 1475:             getattr(df, method)()
 1476:     else:
 1477:         getattr(df, method)()
 1478: 
 1479: 
 1480: @pytest.mark.parametrize("col", [1, 1.0, True, "a", np.nan])
 1481: def test_apply_dtype(col):
 1482:     # GH 31466
 1483:     df = DataFrame([[1.0, col]], columns=["a", "b"])
 1484:     result = df.apply(lambda x: x.dtype)
 1485:     expected = df.dtypes
 1486: 
 1487:     tm.assert_series_equal(result, expected)
 1488: 
 1489: 
 1490: def test_apply_mutating(using_array_manager, using_copy_on_write, warn_copy_on_write):
 1491:     # GH#35462 case where applied func pins a new BlockManager to a row
 1492:     df = DataFrame({"a": range(100), "b": range(100, 200)})
 1493:     df_orig = df.copy()
 1494: 
 1495:     def func(row):
 1496:         mgr = row._mgr
 1497:         row.loc["a"] += 1
 1498:         assert row._mgr is not mgr
 1499:         return row
 1500: 
 1501:     expected = df.copy()
 1502:     expected["a"] += 1
 1503: 
 1504:     with tm.assert_cow_warning(warn_copy_on_write):
 1505:         result = df.apply(func, axis=1)
 1506: 
 1507:     tm.assert_frame_equal(result, expected)
 1508:     if using_copy_on_write or using_array_manager:
 1509:         # INFO(CoW) With copy on write, mutating a viewing row doesn't mutate the parent
 1510:         # INFO(ArrayManager) With BlockManager, the row is a view and mutated in place,
 1511:         # with ArrayManager the row is not a view, and thus not mutated in place
 1512:         tm.assert_frame_equal(df, df_orig)
 1513:     else:
 1514:         tm.assert_frame_equal(df, result)
 1515: 
 1516: 
 1517: def test_apply_empty_list_reduce():
 1518:     # GH#35683 get columns correct
 1519:     df = DataFrame([[1, 2], [3, 4], [5, 6], [7, 8], [9, 10]], columns=["a", "b"])
 1520: 
 1521:     result = df.apply(lambda x: [], result_type="reduce")
 1522:     expected = Series({"a": [], "b": []}, dtype=object)
 1523:     tm.assert_series_equal(result, expected)
 1524: 
 1525: 
 1526: def test_apply_no_suffix_index(engine, request):
 1527:     # GH36189
 1528:     if engine == "numba":
 1529:         mark = pytest.mark.xfail(
 1530:             reason="numba engine doesn't support list-likes/dict-like callables"
 1531:         )
 1532:         request.node.add_marker(mark)
 1533:     pdf = DataFrame([[4, 9]] * 3, columns=["A", "B"])
 1534:     result = pdf.apply(["sum", lambda x: x.sum(), lambda x: x.sum()], engine=engine)
 1535:     expected = DataFrame(
 1536:         {"A": [12, 12, 12], "B": [27, 27, 27]}, index=["sum", "<lambda>", "<lambda>"]
 1537:     )
 1538: 
 1539:     tm.assert_frame_equal(result, expected)
 1540: 
 1541: 
 1542: def test_apply_raw_returns_string(engine):
 1543:     # https://github.com/pandas-dev/pandas/issues/35940
 1544:     if engine == "numba":
 1545:         pytest.skip("No object dtype support in numba")
 1546:     df = DataFrame({"A": ["aa", "bbb"]})
 1547:     result = df.apply(lambda x: x[0], engine=engine, axis=1, raw=True)
 1548:     expected = Series(["aa", "bbb"])
 1549:     tm.assert_series_equal(result, expected)
 1550: 
 1551: 
 1552: def test_aggregation_func_column_order():
 1553:     # GH40420: the result of .agg should have an index that is sorted
 1554:     # according to the arguments provided to agg.
 1555:     df = DataFrame(
 1556:         [
 1557:             (1, 0, 0),
 1558:             (2, 0, 0),
 1559:             (3, 0, 0),
 1560:             (4, 5, 4),
 1561:             (5, 6, 6),
 1562:             (6, 7, 7),
 1563:         ],
 1564:         columns=("att1", "att2", "att3"),
 1565:     )
 1566: 
 1567:     def sum_div2(s):
 1568:         return s.sum() / 2
 1569: 
 1570:     aggs = ["sum", sum_div2, "count", "min"]
 1571:     result = df.agg(aggs)
 1572:     expected = DataFrame(
 1573:         {
 1574:             "att1": [21.0, 10.5, 6.0, 1.0],
 1575:             "att2": [18.0, 9.0, 6.0, 0.0],
 1576:             "att3": [17.0, 8.5, 6.0, 0.0],
 1577:         },
 1578:         index=["sum", "sum_div2", "count", "min"],
 1579:     )
 1580:     tm.assert_frame_equal(result, expected)
 1581: 
 1582: 
 1583: def test_apply_getitem_axis_1(engine, request):
 1584:     # GH 13427
 1585:     if engine == "numba":
 1586:         mark = pytest.mark.xfail(
 1587:             reason="numba engine not supporting duplicate index values"
 1588:         )
 1589:         request.node.add_marker(mark)
 1590:     df = DataFrame({"a": [0, 1, 2], "b": [1, 2, 3]})
 1591:     result = df[["a", "a"]].apply(
 1592:         lambda x: x.iloc[0] + x.iloc[1], axis=1, engine=engine
 1593:     )
 1594:     expected = Series([0, 2, 4])
 1595:     tm.assert_series_equal(result, expected)
 1596: 
 1597: 
 1598: def test_nuisance_depr_passes_through_warnings():
 1599:     # GH 43740
 1600:     # DataFrame.agg with list-likes may emit warnings for both individual
 1601:     # args and for entire columns, but we only want to emit once. We
 1602:     # catch and suppress the warnings for individual args, but need to make
 1603:     # sure if some other warnings were raised, they get passed through to
 1604:     # the user.
 1605: 
 1606:     def expected_warning(x):
 1607:         warnings.warn("Hello, World!")
 1608:         return x.sum()
 1609: 
 1610:     df = DataFrame({"a": [1, 2, 3]})
 1611:     with tm.assert_produces_warning(UserWarning, match="Hello, World!"):
 1612:         df.agg([expected_warning])
 1613: 
 1614: 
 1615: def test_apply_type():
 1616:     # GH 46719
 1617:     df = DataFrame(
 1618:         {"col1": [3, "string", float], "col2": [0.25, datetime(2020, 1, 1), np.nan]},
 1619:         index=["a", "b", "c"],
 1620:     )
 1621: 
 1622:     # axis=0
 1623:     result = df.apply(type, axis=0)
 1624:     expected = Series({"col1": Series, "col2": Series})
 1625:     tm.assert_series_equal(result, expected)
 1626: 
 1627:     # axis=1
 1628:     result = df.apply(type, axis=1)
 1629:     expected = Series({"a": Series, "b": Series, "c": Series})
 1630:     tm.assert_series_equal(result, expected)
 1631: 
 1632: 
 1633: def test_apply_on_empty_dataframe(engine):
 1634:     # GH 39111
 1635:     df = DataFrame({"a": [1, 2], "b": [3, 0]})
 1636:     result = df.head(0).apply(lambda x: max(x["a"], x["b"]), axis=1, engine=engine)
 1637:     expected = Series([], dtype=np.float64)
 1638:     tm.assert_series_equal(result, expected)
 1639: 
 1640: 
 1641: def test_apply_return_list():
 1642:     df = DataFrame({"a": [1, 2], "b": [2, 3]})
 1643:     result = df.apply(lambda x: [x.values])
 1644:     expected = DataFrame({"a": [[1, 2]], "b": [[2, 3]]})
 1645:     tm.assert_frame_equal(result, expected)
 1646: 
 1647: 
 1648: @pytest.mark.parametrize(
 1649:     "test, constant",
 1650:     [
 1651:         ({"a": [1, 2, 3], "b": [1, 1, 1]}, {"a": [1, 2, 3], "b": [1]}),
 1652:         ({"a": [2, 2, 2], "b": [1, 1, 1]}, {"a": [2], "b": [1]}),
 1653:     ],
 1654: )
 1655: def test_unique_agg_type_is_series(test, constant):
 1656:     # GH#22558
 1657:     df1 = DataFrame(test)
 1658:     expected = Series(data=constant, index=["a", "b"], dtype="object")
 1659:     aggregation = {"a": "unique", "b": "unique"}
 1660: 
 1661:     result = df1.agg(aggregation)
 1662: 
 1663:     tm.assert_series_equal(result, expected)
 1664: 
 1665: 
 1666: def test_any_apply_keyword_non_zero_axis_regression():
 1667:     # https://github.com/pandas-dev/pandas/issues/48656
 1668:     df = DataFrame({"A": [1, 2, 0], "B": [0, 2, 0], "C": [0, 0, 0]})
 1669:     expected = Series([True, True, False])
 1670:     tm.assert_series_equal(df.any(axis=1), expected)
 1671: 
 1672:     result = df.apply("any", axis=1)
 1673:     tm.assert_series_equal(result, expected)
 1674: 
 1675:     result = df.apply("any", 1)
 1676:     tm.assert_series_equal(result, expected)
 1677: 
 1678: 
 1679: def test_agg_mapping_func_deprecated():
 1680:     # GH 53325
 1681:     df = DataFrame({"x": [1, 2, 3]})
 1682: 
 1683:     def foo1(x, a=1, c=0):
 1684:         return x + a + c
 1685: 
 1686:     def foo2(x, b=2, c=0):
 1687:         return x + b + c
 1688: 
 1689:     # single func already takes the vectorized path
 1690:     result = df.agg(foo1, 0, 3, c=4)
 1691:     expected = df + 7
 1692:     tm.assert_frame_equal(result, expected)
 1693: 
 1694:     msg = "using .+ in Series.agg cannot aggregate and"
 1695: 
 1696:     with tm.assert_produces_warning(FutureWarning, match=msg):
 1697:         result = df.agg([foo1, foo2], 0, 3, c=4)
 1698:     expected = DataFrame(
 1699:         [[8, 8], [9, 9], [10, 10]], columns=[["x", "x"], ["foo1", "foo2"]]
 1700:     )
 1701:     tm.assert_frame_equal(result, expected)
 1702: 
 1703:     # TODO: the result below is wrong, should be fixed (GH53325)
 1704:     with tm.assert_produces_warning(FutureWarning, match=msg):
 1705:         result = df.agg({"x": foo1}, 0, 3, c=4)
 1706:     expected = DataFrame([2, 3, 4], columns=["x"])
 1707:     tm.assert_frame_equal(result, expected)
 1708: 
 1709: 
 1710: def test_agg_std():
 1711:     df = DataFrame(np.arange(6).reshape(3, 2), columns=["A", "B"])
 1712: 
 1713:     with tm.assert_produces_warning(FutureWarning, match="using DataFrame.std"):
 1714:         result = df.agg(np.std)
 1715:     expected = Series({"A": 2.0, "B": 2.0}, dtype=float)
 1716:     tm.assert_series_equal(result, expected)
 1717: 
 1718:     with tm.assert_produces_warning(FutureWarning, match="using Series.std"):
 1719:         result = df.agg([np.std])
 1720:     expected = DataFrame({"A": 2.0, "B": 2.0}, index=["std"])
 1721:     tm.assert_frame_equal(result, expected)
 1722: 
 1723: 
 1724: def test_agg_dist_like_and_nonunique_columns():
 1725:     # GH#51099
 1726:     df = DataFrame(
 1727:         {"A": [None, 2, 3], "B": [1.0, np.nan, 3.0], "C": ["foo", None, "bar"]}
 1728:     )
 1729:     df.columns = ["A", "A", "C"]
 1730: 
 1731:     result = df.agg({"A": "count"})
 1732:     expected = df["A"].count()
 1733:     tm.assert_series_equal(result, expected)
