    1: from datetime import datetime
    2: import struct
    3: 
    4: import numpy as np
    5: import pytest
    6: 
    7: from pandas._libs import (
    8:     algos as libalgos,
    9:     hashtable as ht,
   10: )
   11: 
   12: from pandas.core.dtypes.common import (
   13:     is_bool_dtype,
   14:     is_complex_dtype,
   15:     is_float_dtype,
   16:     is_integer_dtype,
   17:     is_object_dtype,
   18: )
   19: from pandas.core.dtypes.dtypes import CategoricalDtype
   20: 
   21: import pandas as pd
   22: from pandas import (
   23:     Categorical,
   24:     CategoricalIndex,
   25:     DataFrame,
   26:     DatetimeIndex,
   27:     Index,
   28:     IntervalIndex,
   29:     MultiIndex,
   30:     NaT,
   31:     Period,
   32:     PeriodIndex,
   33:     Series,
   34:     Timedelta,
   35:     Timestamp,
   36:     cut,
   37:     date_range,
   38:     timedelta_range,
   39:     to_datetime,
   40:     to_timedelta,
   41: )
   42: import pandas._testing as tm
   43: import pandas.core.algorithms as algos
   44: from pandas.core.arrays import (
   45:     DatetimeArray,
   46:     TimedeltaArray,
   47: )
   48: import pandas.core.common as com
   49: 
   50: 
   51: class TestFactorize:
   52:     def test_factorize_complex(self):
   53:         # GH#17927
   54:         array = [1, 2, 2 + 1j]
   55:         msg = "factorize with argument that is not not a Series"
   56:         with tm.assert_produces_warning(FutureWarning, match=msg):
   57:             labels, uniques = algos.factorize(array)
   58: 
   59:         expected_labels = np.array([0, 1, 2], dtype=np.intp)
   60:         tm.assert_numpy_array_equal(labels, expected_labels)
   61: 
   62:         # Should return a complex dtype in the future
   63:         expected_uniques = np.array([(1 + 0j), (2 + 0j), (2 + 1j)], dtype=object)
   64:         tm.assert_numpy_array_equal(uniques, expected_uniques)
   65: 
   66:     @pytest.mark.parametrize("sort", [True, False])
   67:     def test_factorize(self, index_or_series_obj, sort):
   68:         obj = index_or_series_obj
   69:         result_codes, result_uniques = obj.factorize(sort=sort)
   70: 
   71:         constructor = Index
   72:         if isinstance(obj, MultiIndex):
   73:             constructor = MultiIndex.from_tuples
   74:         expected_arr = obj.unique()
   75:         if expected_arr.dtype == np.float16:
   76:             expected_arr = expected_arr.astype(np.float32)
   77:         expected_uniques = constructor(expected_arr)
   78:         if (
   79:             isinstance(obj, Index)
   80:             and expected_uniques.dtype == bool
   81:             and obj.dtype == object
   82:         ):
   83:             expected_uniques = expected_uniques.astype(object)
   84: 
   85:         if sort:
   86:             expected_uniques = expected_uniques.sort_values()
   87: 
   88:         # construct an integer ndarray so that
   89:         # `expected_uniques.take(expected_codes)` is equal to `obj`
   90:         expected_uniques_list = list(expected_uniques)
   91:         expected_codes = [expected_uniques_list.index(val) for val in obj]
   92:         expected_codes = np.asarray(expected_codes, dtype=np.intp)
   93: 
   94:         tm.assert_numpy_array_equal(result_codes, expected_codes)
   95:         tm.assert_index_equal(result_uniques, expected_uniques, exact=True)
   96: 
   97:     def test_series_factorize_use_na_sentinel_false(self):
   98:         # GH#35667
   99:         values = np.array([1, 2, 1, np.nan])
  100:         ser = Series(values)
  101:         codes, uniques = ser.factorize(use_na_sentinel=False)
  102: 
  103:         expected_codes = np.array([0, 1, 0, 2], dtype=np.intp)
  104:         expected_uniques = Index([1.0, 2.0, np.nan])
  105: 
  106:         tm.assert_numpy_array_equal(codes, expected_codes)
  107:         tm.assert_index_equal(uniques, expected_uniques)
  108: 
  109:     def test_basic(self):
  110:         items = np.array(["a", "b", "b", "a", "a", "c", "c", "c"], dtype=object)
  111:         codes, uniques = algos.factorize(items)
  112:         tm.assert_numpy_array_equal(uniques, np.array(["a", "b", "c"], dtype=object))
  113: 
  114:         codes, uniques = algos.factorize(items, sort=True)
  115:         exp = np.array([0, 1, 1, 0, 0, 2, 2, 2], dtype=np.intp)
  116:         tm.assert_numpy_array_equal(codes, exp)
  117:         exp = np.array(["a", "b", "c"], dtype=object)
  118:         tm.assert_numpy_array_equal(uniques, exp)
  119: 
  120:         arr = np.arange(5, dtype=np.intp)[::-1]
  121: 
  122:         codes, uniques = algos.factorize(arr)
  123:         exp = np.array([0, 1, 2, 3, 4], dtype=np.intp)
  124:         tm.assert_numpy_array_equal(codes, exp)
  125:         exp = np.array([4, 3, 2, 1, 0], dtype=arr.dtype)
  126:         tm.assert_numpy_array_equal(uniques, exp)
  127: 
  128:         codes, uniques = algos.factorize(arr, sort=True)
  129:         exp = np.array([4, 3, 2, 1, 0], dtype=np.intp)
  130:         tm.assert_numpy_array_equal(codes, exp)
  131:         exp = np.array([0, 1, 2, 3, 4], dtype=arr.dtype)
  132:         tm.assert_numpy_array_equal(uniques, exp)
  133: 
  134:         arr = np.arange(5.0)[::-1]
  135: 
  136:         codes, uniques = algos.factorize(arr)
  137:         exp = np.array([0, 1, 2, 3, 4], dtype=np.intp)
  138:         tm.assert_numpy_array_equal(codes, exp)
  139:         exp = np.array([4.0, 3.0, 2.0, 1.0, 0.0], dtype=arr.dtype)
  140:         tm.assert_numpy_array_equal(uniques, exp)
  141: 
  142:         codes, uniques = algos.factorize(arr, sort=True)
  143:         exp = np.array([4, 3, 2, 1, 0], dtype=np.intp)
  144:         tm.assert_numpy_array_equal(codes, exp)
  145:         exp = np.array([0.0, 1.0, 2.0, 3.0, 4.0], dtype=arr.dtype)
  146:         tm.assert_numpy_array_equal(uniques, exp)
  147: 
  148:     def test_mixed(self):
  149:         # doc example reshaping.rst
  150:         x = Series(["A", "A", np.nan, "B", 3.14, np.inf])
  151:         codes, uniques = algos.factorize(x)
  152: 
  153:         exp = np.array([0, 0, -1, 1, 2, 3], dtype=np.intp)
  154:         tm.assert_numpy_array_equal(codes, exp)
  155:         exp = Index(["A", "B", 3.14, np.inf])
  156:         tm.assert_index_equal(uniques, exp)
  157: 
  158:         codes, uniques = algos.factorize(x, sort=True)
  159:         exp = np.array([2, 2, -1, 3, 0, 1], dtype=np.intp)
  160:         tm.assert_numpy_array_equal(codes, exp)
  161:         exp = Index([3.14, np.inf, "A", "B"])
  162:         tm.assert_index_equal(uniques, exp)
  163: 
  164:     def test_factorize_datetime64(self):
  165:         # M8
  166:         v1 = Timestamp("20130101 09:00:00.00004")
  167:         v2 = Timestamp("20130101")
  168:         x = Series([v1, v1, v1, v2, v2, v1])
  169:         codes, uniques = algos.factorize(x)
  170: 
  171:         exp = np.array([0, 0, 0, 1, 1, 0], dtype=np.intp)
  172:         tm.assert_numpy_array_equal(codes, exp)
  173:         exp = DatetimeIndex([v1, v2])
  174:         tm.assert_index_equal(uniques, exp)
  175: 
  176:         codes, uniques = algos.factorize(x, sort=True)
  177:         exp = np.array([1, 1, 1, 0, 0, 1], dtype=np.intp)
  178:         tm.assert_numpy_array_equal(codes, exp)
  179:         exp = DatetimeIndex([v2, v1])
  180:         tm.assert_index_equal(uniques, exp)
  181: 
  182:     def test_factorize_period(self):
  183:         # period
  184:         v1 = Period("201302", freq="M")
  185:         v2 = Period("201303", freq="M")
  186:         x = Series([v1, v1, v1, v2, v2, v1])
  187: 
  188:         # periods are not 'sorted' as they are converted back into an index
  189:         codes, uniques = algos.factorize(x)
  190:         exp = np.array([0, 0, 0, 1, 1, 0], dtype=np.intp)
  191:         tm.assert_numpy_array_equal(codes, exp)
  192:         tm.assert_index_equal(uniques, PeriodIndex([v1, v2]))
  193: 
  194:         codes, uniques = algos.factorize(x, sort=True)
  195:         exp = np.array([0, 0, 0, 1, 1, 0], dtype=np.intp)
  196:         tm.assert_numpy_array_equal(codes, exp)
  197:         tm.assert_index_equal(uniques, PeriodIndex([v1, v2]))
  198: 
  199:     def test_factorize_timedelta(self):
  200:         # GH 5986
  201:         v1 = to_timedelta("1 day 1 min")
  202:         v2 = to_timedelta("1 day")
  203:         x = Series([v1, v2, v1, v1, v2, v2, v1])
  204:         codes, uniques = algos.factorize(x)
  205:         exp = np.array([0, 1, 0, 0, 1, 1, 0], dtype=np.intp)
  206:         tm.assert_numpy_array_equal(codes, exp)
  207:         tm.assert_index_equal(uniques, to_timedelta([v1, v2]))
  208: 
  209:         codes, uniques = algos.factorize(x, sort=True)
  210:         exp = np.array([1, 0, 1, 1, 0, 0, 1], dtype=np.intp)
  211:         tm.assert_numpy_array_equal(codes, exp)
  212:         tm.assert_index_equal(uniques, to_timedelta([v2, v1]))
  213: 
  214:     def test_factorize_nan(self):
  215:         # nan should map to na_sentinel, not reverse_indexer[na_sentinel]
  216:         # rizer.factorize should not raise an exception if na_sentinel indexes
  217:         # outside of reverse_indexer
  218:         key = np.array([1, 2, 1, np.nan], dtype="O")
  219:         rizer = ht.ObjectFactorizer(len(key))
  220:         for na_sentinel in (-1, 20):
  221:             ids = rizer.factorize(key, na_sentinel=na_sentinel)
  222:             expected = np.array([0, 1, 0, na_sentinel], dtype=np.intp)
  223:             assert len(set(key)) == len(set(expected))
  224:             tm.assert_numpy_array_equal(pd.isna(key), expected == na_sentinel)
  225:             tm.assert_numpy_array_equal(ids, expected)
  226: 
  227:     def test_factorizer_with_mask(self):
  228:         # GH#49549
  229:         data = np.array([1, 2, 3, 1, 1, 0], dtype="int64")
  230:         mask = np.array([False, False, False, False, False, True])
  231:         rizer = ht.Int64Factorizer(len(data))
  232:         result = rizer.factorize(data, mask=mask)
  233:         expected = np.array([0, 1, 2, 0, 0, -1], dtype=np.intp)
  234:         tm.assert_numpy_array_equal(result, expected)
  235:         expected_uniques = np.array([1, 2, 3], dtype="int64")
  236:         tm.assert_numpy_array_equal(rizer.uniques.to_array(), expected_uniques)
  237: 
  238:     def test_factorizer_object_with_nan(self):
  239:         # GH#49549
  240:         data = np.array([1, 2, 3, 1, np.nan])
  241:         rizer = ht.ObjectFactorizer(len(data))
  242:         result = rizer.factorize(data.astype(object))
  243:         expected = np.array([0, 1, 2, 0, -1], dtype=np.intp)
  244:         tm.assert_numpy_array_equal(result, expected)
  245:         expected_uniques = np.array([1, 2, 3], dtype=object)
  246:         tm.assert_numpy_array_equal(rizer.uniques.to_array(), expected_uniques)
  247: 
  248:     @pytest.mark.parametrize(
  249:         "data, expected_codes, expected_uniques",
  250:         [
  251:             (
  252:                 [(1, 1), (1, 2), (0, 0), (1, 2), "nonsense"],
  253:                 [0, 1, 2, 1, 3],
  254:                 [(1, 1), (1, 2), (0, 0), "nonsense"],
  255:             ),
  256:             (
  257:                 [(1, 1), (1, 2), (0, 0), (1, 2), (1, 2, 3)],
  258:                 [0, 1, 2, 1, 3],
  259:                 [(1, 1), (1, 2), (0, 0), (1, 2, 3)],
  260:             ),
  261:             ([(1, 1), (1, 2), (0, 0), (1, 2)], [0, 1, 2, 1], [(1, 1), (1, 2), (0, 0)]),
  262:         ],
  263:     )
  264:     def test_factorize_tuple_list(self, data, expected_codes, expected_uniques):
  265:         # GH9454
  266:         msg = "factorize with argument that is not not a Series"
  267:         with tm.assert_produces_warning(FutureWarning, match=msg):
  268:             codes, uniques = pd.factorize(data)
  269: 
  270:         tm.assert_numpy_array_equal(codes, np.array(expected_codes, dtype=np.intp))
  271: 
  272:         expected_uniques_array = com.asarray_tuplesafe(expected_uniques, dtype=object)
  273:         tm.assert_numpy_array_equal(uniques, expected_uniques_array)
  274: 
  275:     def test_complex_sorting(self):
  276:         # gh 12666 - check no segfault
  277:         x17 = np.array([complex(i) for i in range(17)], dtype=object)
  278: 
  279:         msg = "'[<>]' not supported between instances of .*"
  280:         with pytest.raises(TypeError, match=msg):
  281:             algos.factorize(x17[::-1], sort=True)
  282: 
  283:     def test_numeric_dtype_factorize(self, any_real_numpy_dtype):
  284:         # GH41132
  285:         dtype = any_real_numpy_dtype
  286:         data = np.array([1, 2, 2, 1], dtype=dtype)
  287:         expected_codes = np.array([0, 1, 1, 0], dtype=np.intp)
  288:         expected_uniques = np.array([1, 2], dtype=dtype)
  289: 
  290:         codes, uniques = algos.factorize(data)
  291:         tm.assert_numpy_array_equal(codes, expected_codes)
  292:         tm.assert_numpy_array_equal(uniques, expected_uniques)
  293: 
  294:     def test_float64_factorize(self, writable):
  295:         data = np.array([1.0, 1e8, 1.0, 1e-8, 1e8, 1.0], dtype=np.float64)
  296:         data.setflags(write=writable)
  297:         expected_codes = np.array([0, 1, 0, 2, 1, 0], dtype=np.intp)
  298:         expected_uniques = np.array([1.0, 1e8, 1e-8], dtype=np.float64)
  299: 
  300:         codes, uniques = algos.factorize(data)
  301:         tm.assert_numpy_array_equal(codes, expected_codes)
  302:         tm.assert_numpy_array_equal(uniques, expected_uniques)
  303: 
  304:     def test_uint64_factorize(self, writable):
  305:         data = np.array([2**64 - 1, 1, 2**64 - 1], dtype=np.uint64)
  306:         data.setflags(write=writable)
  307:         expected_codes = np.array([0, 1, 0], dtype=np.intp)
  308:         expected_uniques = np.array([2**64 - 1, 1], dtype=np.uint64)
  309: 
  310:         codes, uniques = algos.factorize(data)
  311:         tm.assert_numpy_array_equal(codes, expected_codes)
  312:         tm.assert_numpy_array_equal(uniques, expected_uniques)
  313: 
  314:     def test_int64_factorize(self, writable):
  315:         data = np.array([2**63 - 1, -(2**63), 2**63 - 1], dtype=np.int64)
  316:         data.setflags(write=writable)
  317:         expected_codes = np.array([0, 1, 0], dtype=np.intp)
  318:         expected_uniques = np.array([2**63 - 1, -(2**63)], dtype=np.int64)
  319: 
  320:         codes, uniques = algos.factorize(data)
  321:         tm.assert_numpy_array_equal(codes, expected_codes)
  322:         tm.assert_numpy_array_equal(uniques, expected_uniques)
  323: 
  324:     def test_string_factorize(self, writable):
  325:         data = np.array(["a", "c", "a", "b", "c"], dtype=object)
  326:         data.setflags(write=writable)
  327:         expected_codes = np.array([0, 1, 0, 2, 1], dtype=np.intp)
  328:         expected_uniques = np.array(["a", "c", "b"], dtype=object)
  329: 
  330:         codes, uniques = algos.factorize(data)
  331:         tm.assert_numpy_array_equal(codes, expected_codes)
  332:         tm.assert_numpy_array_equal(uniques, expected_uniques)
  333: 
  334:     def test_object_factorize(self, writable):
  335:         data = np.array(["a", "c", None, np.nan, "a", "b", NaT, "c"], dtype=object)
  336:         data.setflags(write=writable)
  337:         expected_codes = np.array([0, 1, -1, -1, 0, 2, -1, 1], dtype=np.intp)
  338:         expected_uniques = np.array(["a", "c", "b"], dtype=object)
  339: 
  340:         codes, uniques = algos.factorize(data)
  341:         tm.assert_numpy_array_equal(codes, expected_codes)
  342:         tm.assert_numpy_array_equal(uniques, expected_uniques)
  343: 
  344:     def test_datetime64_factorize(self, writable):
  345:         # GH35650 Verify whether read-only datetime64 array can be factorized
  346:         data = np.array([np.datetime64("2020-01-01T00:00:00.000")], dtype="M8[ns]")
  347:         data.setflags(write=writable)
  348:         expected_codes = np.array([0], dtype=np.intp)
  349:         expected_uniques = np.array(
  350:             ["2020-01-01T00:00:00.000000000"], dtype="datetime64[ns]"
  351:         )
  352: 
  353:         codes, uniques = pd.factorize(data)
  354:         tm.assert_numpy_array_equal(codes, expected_codes)
  355:         tm.assert_numpy_array_equal(uniques, expected_uniques)
  356: 
  357:     @pytest.mark.parametrize("sort", [True, False])
  358:     def test_factorize_rangeindex(self, sort):
  359:         # increasing -> sort doesn't matter
  360:         ri = pd.RangeIndex.from_range(range(10))
  361:         expected = np.arange(10, dtype=np.intp), ri
  362: 
  363:         result = algos.factorize(ri, sort=sort)
  364:         tm.assert_numpy_array_equal(result[0], expected[0])
  365:         tm.assert_index_equal(result[1], expected[1], exact=True)
  366: 
  367:         result = ri.factorize(sort=sort)
  368:         tm.assert_numpy_array_equal(result[0], expected[0])
  369:         tm.assert_index_equal(result[1], expected[1], exact=True)
  370: 
  371:     @pytest.mark.parametrize("sort", [True, False])
  372:     def test_factorize_rangeindex_decreasing(self, sort):
  373:         # decreasing -> sort matters
  374:         ri = pd.RangeIndex.from_range(range(10))
  375:         expected = np.arange(10, dtype=np.intp), ri
  376: 
  377:         ri2 = ri[::-1]
  378:         expected = expected[0], ri2
  379:         if sort:
  380:             expected = expected[0][::-1], expected[1][::-1]
  381: 
  382:         result = algos.factorize(ri2, sort=sort)
  383:         tm.assert_numpy_array_equal(result[0], expected[0])
  384:         tm.assert_index_equal(result[1], expected[1], exact=True)
  385: 
  386:         result = ri2.factorize(sort=sort)
  387:         tm.assert_numpy_array_equal(result[0], expected[0])
  388:         tm.assert_index_equal(result[1], expected[1], exact=True)
  389: 
  390:     def test_deprecate_order(self):
  391:         # gh 19727 - check warning is raised for deprecated keyword, order.
  392:         # Test not valid once order keyword is removed.
  393:         data = np.array([2**63, 1, 2**63], dtype=np.uint64)
  394:         with pytest.raises(TypeError, match="got an unexpected keyword"):
  395:             algos.factorize(data, order=True)
  396:         with tm.assert_produces_warning(False):
  397:             algos.factorize(data)
  398: 
  399:     @pytest.mark.parametrize(
  400:         "data",
  401:         [
  402:             np.array([0, 1, 0], dtype="u8"),
  403:             np.array([-(2**63), 1, -(2**63)], dtype="i8"),
  404:             np.array(["__nan__", "foo", "__nan__"], dtype="object"),
  405:         ],
  406:     )
  407:     def test_parametrized_factorize_na_value_default(self, data):
  408:         # arrays that include the NA default for that type, but isn't used.
  409:         codes, uniques = algos.factorize(data)
  410:         expected_uniques = data[[0, 1]]
  411:         expected_codes = np.array([0, 1, 0], dtype=np.intp)
  412:         tm.assert_numpy_array_equal(codes, expected_codes)
  413:         tm.assert_numpy_array_equal(uniques, expected_uniques)
  414: 
  415:     @pytest.mark.parametrize(
  416:         "data, na_value",
  417:         [
  418:             (np.array([0, 1, 0, 2], dtype="u8"), 0),
  419:             (np.array([1, 0, 1, 2], dtype="u8"), 1),
  420:             (np.array([-(2**63), 1, -(2**63), 0], dtype="i8"), -(2**63)),
  421:             (np.array([1, -(2**63), 1, 0], dtype="i8"), 1),
  422:             (np.array(["a", "", "a", "b"], dtype=object), "a"),
  423:             (np.array([(), ("a", 1), (), ("a", 2)], dtype=object), ()),
  424:             (np.array([("a", 1), (), ("a", 1), ("a", 2)], dtype=object), ("a", 1)),
  425:         ],
  426:     )
  427:     def test_parametrized_factorize_na_value(self, data, na_value):
  428:         codes, uniques = algos.factorize_array(data, na_value=na_value)
  429:         expected_uniques = data[[1, 3]]
  430:         expected_codes = np.array([-1, 0, -1, 1], dtype=np.intp)
  431:         tm.assert_numpy_array_equal(codes, expected_codes)
  432:         tm.assert_numpy_array_equal(uniques, expected_uniques)
  433: 
  434:     @pytest.mark.parametrize("sort", [True, False])
  435:     @pytest.mark.parametrize(
  436:         "data, uniques",
  437:         [
  438:             (
  439:                 np.array(["b", "a", None, "b"], dtype=object),
  440:                 np.array(["b", "a"], dtype=object),
  441:             ),
  442:             (
  443:                 pd.array([2, 1, np.nan, 2], dtype="Int64"),
  444:                 pd.array([2, 1], dtype="Int64"),
  445:             ),
  446:         ],
  447:         ids=["numpy_array", "extension_array"],
  448:     )
  449:     def test_factorize_use_na_sentinel(self, sort, data, uniques):
  450:         codes, uniques = algos.factorize(data, sort=sort, use_na_sentinel=True)
  451:         if sort:
  452:             expected_codes = np.array([1, 0, -1, 1], dtype=np.intp)
  453:             expected_uniques = algos.safe_sort(uniques)
  454:         else:
  455:             expected_codes = np.array([0, 1, -1, 0], dtype=np.intp)
  456:             expected_uniques = uniques
  457:         tm.assert_numpy_array_equal(codes, expected_codes)
  458:         if isinstance(data, np.ndarray):
  459:             tm.assert_numpy_array_equal(uniques, expected_uniques)
  460:         else:
  461:             tm.assert_extension_array_equal(uniques, expected_uniques)
  462: 
  463:     @pytest.mark.parametrize(
  464:         "data, expected_codes, expected_uniques",
  465:         [
  466:             (
  467:                 ["a", None, "b", "a"],
  468:                 np.array([0, 1, 2, 0], dtype=np.dtype("intp")),
  469:                 np.array(["a", np.nan, "b"], dtype=object),
  470:             ),
  471:             (
  472:                 ["a", np.nan, "b", "a"],
  473:                 np.array([0, 1, 2, 0], dtype=np.dtype("intp")),
  474:                 np.array(["a", np.nan, "b"], dtype=object),
  475:             ),
  476:         ],
  477:     )
  478:     def test_object_factorize_use_na_sentinel_false(
  479:         self, data, expected_codes, expected_uniques
  480:     ):
  481:         codes, uniques = algos.factorize(
  482:             np.array(data, dtype=object), use_na_sentinel=False
  483:         )
  484: 
  485:         tm.assert_numpy_array_equal(uniques, expected_uniques, strict_nan=True)
  486:         tm.assert_numpy_array_equal(codes, expected_codes, strict_nan=True)
  487: 
  488:     @pytest.mark.parametrize(
  489:         "data, expected_codes, expected_uniques",
  490:         [
  491:             (
  492:                 [1, None, 1, 2],
  493:                 np.array([0, 1, 0, 2], dtype=np.dtype("intp")),
  494:                 np.array([1, np.nan, 2], dtype="O"),
  495:             ),
  496:             (
  497:                 [1, np.nan, 1, 2],
  498:                 np.array([0, 1, 0, 2], dtype=np.dtype("intp")),
  499:                 np.array([1, np.nan, 2], dtype=np.float64),
  500:             ),
  501:         ],
  502:     )
  503:     def test_int_factorize_use_na_sentinel_false(
  504:         self, data, expected_codes, expected_uniques
  505:     ):
  506:         msg = "factorize with argument that is not not a Series"
  507:         with tm.assert_produces_warning(FutureWarning, match=msg):
  508:             codes, uniques = algos.factorize(data, use_na_sentinel=False)
  509: 
  510:         tm.assert_numpy_array_equal(uniques, expected_uniques, strict_nan=True)
  511:         tm.assert_numpy_array_equal(codes, expected_codes, strict_nan=True)
  512: 
  513:     @pytest.mark.parametrize(
  514:         "data, expected_codes, expected_uniques",
  515:         [
  516:             (
  517:                 Index(Categorical(["a", "a", "b"])),
  518:                 np.array([0, 0, 1], dtype=np.intp),
  519:                 CategoricalIndex(["a", "b"], categories=["a", "b"], dtype="category"),
  520:             ),
  521:             (
  522:                 Series(Categorical(["a", "a", "b"])),
  523:                 np.array([0, 0, 1], dtype=np.intp),
  524:                 CategoricalIndex(["a", "b"], categories=["a", "b"], dtype="category"),
  525:             ),
  526:             (
  527:                 Series(DatetimeIndex(["2017", "2017"], tz="US/Eastern")),
  528:                 np.array([0, 0], dtype=np.intp),
  529:                 DatetimeIndex(["2017"], tz="US/Eastern"),
  530:             ),
  531:         ],
  532:     )
  533:     def test_factorize_mixed_values(self, data, expected_codes, expected_uniques):
  534:         # GH 19721
  535:         codes, uniques = algos.factorize(data)
  536:         tm.assert_numpy_array_equal(codes, expected_codes)
  537:         tm.assert_index_equal(uniques, expected_uniques)
  538: 
  539:     def test_factorize_interval_non_nano(self, unit):
  540:         # GH#56099
  541:         left = DatetimeIndex(["2016-01-01", np.nan, "2015-10-11"]).as_unit(unit)
  542:         right = DatetimeIndex(["2016-01-02", np.nan, "2015-10-15"]).as_unit(unit)
  543:         idx = IntervalIndex.from_arrays(left, right)
  544:         codes, cats = idx.factorize()
  545:         assert cats.dtype == f"interval[datetime64[{unit}], right]"
  546: 
  547:         ts = Timestamp(0).as_unit(unit)
  548:         idx2 = IntervalIndex.from_arrays(left - ts, right - ts)
  549:         codes2, cats2 = idx2.factorize()
  550:         assert cats2.dtype == f"interval[timedelta64[{unit}], right]"
  551: 
  552:         idx3 = IntervalIndex.from_arrays(
  553:             left.tz_localize("US/Pacific"), right.tz_localize("US/Pacific")
  554:         )
  555:         codes3, cats3 = idx3.factorize()
  556:         assert cats3.dtype == f"interval[datetime64[{unit}, US/Pacific], right]"
  557: 
  558: 
  559: class TestUnique:
  560:     def test_ints(self):
  561:         arr = np.random.default_rng(2).integers(0, 100, size=50)
  562: 
  563:         result = algos.unique(arr)
  564:         assert isinstance(result, np.ndarray)
  565: 
  566:     def test_objects(self):
  567:         arr = np.random.default_rng(2).integers(0, 100, size=50).astype("O")
  568: 
  569:         result = algos.unique(arr)
  570:         assert isinstance(result, np.ndarray)
  571: 
  572:     def test_object_refcount_bug(self):
  573:         lst = np.array(["A", "B", "C", "D", "E"], dtype=object)
  574:         for i in range(1000):
  575:             len(algos.unique(lst))
  576: 
  577:     def test_on_index_object(self):
  578:         mindex = MultiIndex.from_arrays(
  579:             [np.arange(5).repeat(5), np.tile(np.arange(5), 5)]
  580:         )
  581:         expected = mindex.values
  582:         expected.sort()
  583: 
  584:         mindex = mindex.repeat(2)
  585: 
  586:         result = pd.unique(mindex)
  587:         result.sort()
  588: 
  589:         tm.assert_almost_equal(result, expected)
  590: 
  591:     def test_dtype_preservation(self, any_numpy_dtype):
  592:         # GH 15442
  593:         if any_numpy_dtype in (tm.BYTES_DTYPES + tm.STRING_DTYPES):
  594:             data = [1, 2, 2]
  595:             uniques = [1, 2]
  596:         elif is_integer_dtype(any_numpy_dtype):
  597:             data = [1, 2, 2]
  598:             uniques = [1, 2]
  599:         elif is_float_dtype(any_numpy_dtype):
  600:             data = [1, 2, 2]
  601:             uniques = [1.0, 2.0]
  602:         elif is_complex_dtype(any_numpy_dtype):
  603:             data = [complex(1, 0), complex(2, 0), complex(2, 0)]
  604:             uniques = [complex(1, 0), complex(2, 0)]
  605:         elif is_bool_dtype(any_numpy_dtype):
  606:             data = [True, True, False]
  607:             uniques = [True, False]
  608:         elif is_object_dtype(any_numpy_dtype):
  609:             data = ["A", "B", "B"]
  610:             uniques = ["A", "B"]
  611:         else:
  612:             # datetime64[ns]/M8[ns]/timedelta64[ns]/m8[ns] tested elsewhere
  613:             data = [1, 2, 2]
  614:             uniques = [1, 2]
  615: 
  616:         result = Series(data, dtype=any_numpy_dtype).unique()
  617:         expected = np.array(uniques, dtype=any_numpy_dtype)
  618: 
  619:         if any_numpy_dtype in tm.STRING_DTYPES:
  620:             expected = expected.astype(object)
  621: 
  622:         if expected.dtype.kind in ["m", "M"]:
  623:             # We get TimedeltaArray/DatetimeArray
  624:             assert isinstance(result, (DatetimeArray, TimedeltaArray))
  625:             result = np.array(result)
  626:         tm.assert_numpy_array_equal(result, expected)
  627: 
  628:     def test_datetime64_dtype_array_returned(self):
  629:         # GH 9431
  630:         expected = np.array(
  631:             [
  632:                 "2015-01-03T00:00:00.000000000",
  633:                 "2015-01-01T00:00:00.000000000",
  634:             ],
  635:             dtype="M8[ns]",
  636:         )
  637: 
  638:         dt_index = to_datetime(
  639:             [
  640:                 "2015-01-03T00:00:00.000000000",
  641:                 "2015-01-01T00:00:00.000000000",
  642:                 "2015-01-01T00:00:00.000000000",
  643:             ]
  644:         )
  645:         result = algos.unique(dt_index)
  646:         tm.assert_numpy_array_equal(result, expected)
  647:         assert result.dtype == expected.dtype
  648: 
  649:         s = Series(dt_index)
  650:         result = algos.unique(s)
  651:         tm.assert_numpy_array_equal(result, expected)
  652:         assert result.dtype == expected.dtype
  653: 
  654:         arr = s.values
  655:         result = algos.unique(arr)
  656:         tm.assert_numpy_array_equal(result, expected)
  657:         assert result.dtype == expected.dtype
  658: 
  659:     def test_datetime_non_ns(self):
  660:         a = np.array(["2000", "2000", "2001"], dtype="datetime64[s]")
  661:         result = pd.unique(a)
  662:         expected = np.array(["2000", "2001"], dtype="datetime64[s]")
  663:         tm.assert_numpy_array_equal(result, expected)
  664: 
  665:     def test_timedelta_non_ns(self):
  666:         a = np.array(["2000", "2000", "2001"], dtype="timedelta64[s]")
  667:         result = pd.unique(a)
  668:         expected = np.array([2000, 2001], dtype="timedelta64[s]")
  669:         tm.assert_numpy_array_equal(result, expected)
  670: 
  671:     def test_timedelta64_dtype_array_returned(self):
  672:         # GH 9431
  673:         expected = np.array([31200, 45678, 10000], dtype="m8[ns]")
  674: 
  675:         td_index = to_timedelta([31200, 45678, 31200, 10000, 45678])
  676:         result = algos.unique(td_index)
  677:         tm.assert_numpy_array_equal(result, expected)
  678:         assert result.dtype == expected.dtype
  679: 
  680:         s = Series(td_index)
  681:         result = algos.unique(s)
  682:         tm.assert_numpy_array_equal(result, expected)
  683:         assert result.dtype == expected.dtype
  684: 
  685:         arr = s.values
  686:         result = algos.unique(arr)
  687:         tm.assert_numpy_array_equal(result, expected)
  688:         assert result.dtype == expected.dtype
  689: 
  690:     def test_uint64_overflow(self):
  691:         s = Series([1, 2, 2**63, 2**63], dtype=np.uint64)
  692:         exp = np.array([1, 2, 2**63], dtype=np.uint64)
  693:         tm.assert_numpy_array_equal(algos.unique(s), exp)
  694: 
  695:     def test_nan_in_object_array(self):
  696:         duplicated_items = ["a", np.nan, "c", "c"]
  697:         result = pd.unique(np.array(duplicated_items, dtype=object))
  698:         expected = np.array(["a", np.nan, "c"], dtype=object)
  699:         tm.assert_numpy_array_equal(result, expected)
  700: 
  701:     def test_categorical(self):
  702:         # we are expecting to return in the order
  703:         # of appearance
  704:         expected = Categorical(list("bac"))
  705: 
  706:         # we are expecting to return in the order
  707:         # of the categories
  708:         expected_o = Categorical(list("bac"), categories=list("abc"), ordered=True)
  709: 
  710:         # GH 15939
  711:         c = Categorical(list("baabc"))
  712:         result = c.unique()
  713:         tm.assert_categorical_equal(result, expected)
  714: 
  715:         result = algos.unique(c)
  716:         tm.assert_categorical_equal(result, expected)
  717: 
  718:         c = Categorical(list("baabc"), ordered=True)
  719:         result = c.unique()
  720:         tm.assert_categorical_equal(result, expected_o)
  721: 
  722:         result = algos.unique(c)
  723:         tm.assert_categorical_equal(result, expected_o)
  724: 
  725:         # Series of categorical dtype
  726:         s = Series(Categorical(list("baabc")), name="foo")
  727:         result = s.unique()
  728:         tm.assert_categorical_equal(result, expected)
  729: 
  730:         result = pd.unique(s)
  731:         tm.assert_categorical_equal(result, expected)
  732: 
  733:         # CI -> return CI
  734:         ci = CategoricalIndex(Categorical(list("baabc"), categories=list("abc")))
  735:         expected = CategoricalIndex(expected)
  736:         result = ci.unique()
  737:         tm.assert_index_equal(result, expected)
  738: 
  739:         result = pd.unique(ci)
  740:         tm.assert_index_equal(result, expected)
  741: 
  742:     def test_datetime64tz_aware(self, unit):
  743:         # GH 15939
  744: 
  745:         dti = Index(
  746:             [
  747:                 Timestamp("20160101", tz="US/Eastern"),
  748:                 Timestamp("20160101", tz="US/Eastern"),
  749:             ]
  750:         ).as_unit(unit)
  751:         ser = Series(dti)
  752: 
  753:         result = ser.unique()
  754:         expected = dti[:1]._data
  755:         tm.assert_extension_array_equal(result, expected)
  756: 
  757:         result = dti.unique()
  758:         expected = dti[:1]
  759:         tm.assert_index_equal(result, expected)
  760: 
  761:         result = pd.unique(ser)
  762:         expected = dti[:1]._data
  763:         tm.assert_extension_array_equal(result, expected)
  764: 
  765:         result = pd.unique(dti)
  766:         expected = dti[:1]
  767:         tm.assert_index_equal(result, expected)
  768: 
  769:     def test_order_of_appearance(self):
  770:         # 9346
  771:         # light testing of guarantee of order of appearance
  772:         # these also are the doc-examples
  773:         result = pd.unique(Series([2, 1, 3, 3]))
  774:         tm.assert_numpy_array_equal(result, np.array([2, 1, 3], dtype="int64"))
  775: 
  776:         result = pd.unique(Series([2] + [1] * 5))
  777:         tm.assert_numpy_array_equal(result, np.array([2, 1], dtype="int64"))
  778: 
  779:         msg = "unique with argument that is not not a Series, Index,"
  780:         with tm.assert_produces_warning(FutureWarning, match=msg):
  781:             result = pd.unique(list("aabc"))
  782:         expected = np.array(["a", "b", "c"], dtype=object)
  783:         tm.assert_numpy_array_equal(result, expected)
  784: 
  785:         result = pd.unique(Series(Categorical(list("aabc"))))
  786:         expected = Categorical(list("abc"))
  787:         tm.assert_categorical_equal(result, expected)
  788: 
  789:     def test_order_of_appearance_dt64(self, unit):
  790:         ser = Series([Timestamp("20160101"), Timestamp("20160101")]).dt.as_unit(unit)
  791:         result = pd.unique(ser)
  792:         expected = np.array(["2016-01-01T00:00:00.000000000"], dtype=f"M8[{unit}]")
  793:         tm.assert_numpy_array_equal(result, expected)
  794: 
  795:     def test_order_of_appearance_dt64tz(self, unit):
  796:         dti = DatetimeIndex(
  797:             [
  798:                 Timestamp("20160101", tz="US/Eastern"),
  799:                 Timestamp("20160101", tz="US/Eastern"),
  800:             ]
  801:         ).as_unit(unit)
  802:         result = pd.unique(dti)
  803:         expected = DatetimeIndex(
  804:             ["2016-01-01 00:00:00"], dtype=f"datetime64[{unit}, US/Eastern]", freq=None
  805:         )
  806:         tm.assert_index_equal(result, expected)
  807: 
  808:     @pytest.mark.parametrize(
  809:         "arg ,expected",
  810:         [
  811:             (("1", "1", "2"), np.array(["1", "2"], dtype=object)),
  812:             (("foo",), np.array(["foo"], dtype=object)),
  813:         ],
  814:     )
  815:     def test_tuple_with_strings(self, arg, expected):
  816:         # see GH 17108
  817:         msg = "unique with argument that is not not a Series"
  818:         with tm.assert_produces_warning(FutureWarning, match=msg):
  819:             result = pd.unique(arg)
  820:         tm.assert_numpy_array_equal(result, expected)
  821: 
  822:     def test_obj_none_preservation(self):
  823:         # GH 20866
  824:         arr = np.array(["foo", None], dtype=object)
  825:         result = pd.unique(arr)
  826:         expected = np.array(["foo", None], dtype=object)
  827: 
  828:         tm.assert_numpy_array_equal(result, expected, strict_nan=True)
  829: 
  830:     def test_signed_zero(self):
  831:         # GH 21866
  832:         a = np.array([-0.0, 0.0])
  833:         result = pd.unique(a)
  834:         expected = np.array([-0.0])  # 0.0 and -0.0 are equivalent
  835:         tm.assert_numpy_array_equal(result, expected)
  836: 
  837:     def test_different_nans(self):
  838:         # GH 21866
  839:         # create different nans from bit-patterns:
  840:         NAN1 = struct.unpack("d", struct.pack("=Q", 0x7FF8000000000000))[0]
  841:         NAN2 = struct.unpack("d", struct.pack("=Q", 0x7FF8000000000001))[0]
  842:         assert NAN1 != NAN1
  843:         assert NAN2 != NAN2
  844:         a = np.array([NAN1, NAN2])  # NAN1 and NAN2 are equivalent
  845:         result = pd.unique(a)
  846:         expected = np.array([np.nan])
  847:         tm.assert_numpy_array_equal(result, expected)
  848: 
  849:     @pytest.mark.parametrize("el_type", [np.float64, object])
  850:     def test_first_nan_kept(self, el_type):
  851:         # GH 22295
  852:         # create different nans from bit-patterns:
  853:         bits_for_nan1 = 0xFFF8000000000001
  854:         bits_for_nan2 = 0x7FF8000000000001
  855:         NAN1 = struct.unpack("d", struct.pack("=Q", bits_for_nan1))[0]
  856:         NAN2 = struct.unpack("d", struct.pack("=Q", bits_for_nan2))[0]
  857:         assert NAN1 != NAN1
  858:         assert NAN2 != NAN2
  859:         a = np.array([NAN1, NAN2], dtype=el_type)
  860:         result = pd.unique(a)
  861:         assert result.size == 1
  862:         # use bit patterns to identify which nan was kept:
  863:         result_nan_bits = struct.unpack("=Q", struct.pack("d", result[0]))[0]
  864:         assert result_nan_bits == bits_for_nan1
  865: 
  866:     def test_do_not_mangle_na_values(self, unique_nulls_fixture, unique_nulls_fixture2):
  867:         # GH 22295
  868:         if unique_nulls_fixture is unique_nulls_fixture2:
  869:             return  # skip it, values not unique
  870:         a = np.array([unique_nulls_fixture, unique_nulls_fixture2], dtype=object)
  871:         result = pd.unique(a)
  872:         assert result.size == 2
  873:         assert a[0] is unique_nulls_fixture
  874:         assert a[1] is unique_nulls_fixture2
  875: 
  876:     def test_unique_masked(self, any_numeric_ea_dtype):
  877:         # GH#48019
  878:         ser = Series([1, pd.NA, 2] * 3, dtype=any_numeric_ea_dtype)
  879:         result = pd.unique(ser)
  880:         expected = pd.array([1, pd.NA, 2], dtype=any_numeric_ea_dtype)
  881:         tm.assert_extension_array_equal(result, expected)
  882: 
  883: 
  884: def test_nunique_ints(index_or_series_or_array):
  885:     # GH#36327
  886:     values = index_or_series_or_array(np.random.default_rng(2).integers(0, 20, 30))
  887:     result = algos.nunique_ints(values)
  888:     expected = len(algos.unique(values))
  889:     assert result == expected
  890: 
  891: 
  892: class TestIsin:
  893:     def test_invalid(self):
  894:         msg = (
  895:             r"only list-like objects are allowed to be passed to isin\(\), "
  896:             r"you passed a `int`"
  897:         )
  898:         with pytest.raises(TypeError, match=msg):
  899:             algos.isin(1, 1)
  900:         with pytest.raises(TypeError, match=msg):
  901:             algos.isin(1, [1])
  902:         with pytest.raises(TypeError, match=msg):
  903:             algos.isin([1], 1)
  904: 
  905:     def test_basic(self):
  906:         msg = "isin with argument that is not not a Series"
  907:         with tm.assert_produces_warning(FutureWarning, match=msg):
  908:             result = algos.isin([1, 2], [1])
  909:         expected = np.array([True, False])
  910:         tm.assert_numpy_array_equal(result, expected)
  911: 
  912:         result = algos.isin(np.array([1, 2]), [1])
  913:         expected = np.array([True, False])
  914:         tm.assert_numpy_array_equal(result, expected)
  915: 
  916:         result = algos.isin(Series([1, 2]), [1])
  917:         expected = np.array([True, False])
  918:         tm.assert_numpy_array_equal(result, expected)
  919: 
  920:         result = algos.isin(Series([1, 2]), Series([1]))
  921:         expected = np.array([True, False])
  922:         tm.assert_numpy_array_equal(result, expected)
  923: 
  924:         result = algos.isin(Series([1, 2]), {1})
  925:         expected = np.array([True, False])
  926:         tm.assert_numpy_array_equal(result, expected)
  927: 
  928:         with tm.assert_produces_warning(FutureWarning, match=msg):
  929:             result = algos.isin(["a", "b"], ["a"])
  930:         expected = np.array([True, False])
  931:         tm.assert_numpy_array_equal(result, expected)
  932: 
  933:         result = algos.isin(Series(["a", "b"]), Series(["a"]))
  934:         expected = np.array([True, False])
  935:         tm.assert_numpy_array_equal(result, expected)
  936: 
  937:         result = algos.isin(Series(["a", "b"]), {"a"})
  938:         expected = np.array([True, False])
  939:         tm.assert_numpy_array_equal(result, expected)
  940: 
  941:         with tm.assert_produces_warning(FutureWarning, match=msg):
  942:             result = algos.isin(["a", "b"], [1])
  943:         expected = np.array([False, False])
  944:         tm.assert_numpy_array_equal(result, expected)
  945: 
  946:     def test_i8(self):
  947:         arr = date_range("20130101", periods=3).values
  948:         result = algos.isin(arr, [arr[0]])
  949:         expected = np.array([True, False, False])
  950:         tm.assert_numpy_array_equal(result, expected)
  951: 
  952:         result = algos.isin(arr, arr[0:2])
  953:         expected = np.array([True, True, False])
  954:         tm.assert_numpy_array_equal(result, expected)
  955: 
  956:         result = algos.isin(arr, set(arr[0:2]))
  957:         expected = np.array([True, True, False])
  958:         tm.assert_numpy_array_equal(result, expected)
  959: 
  960:         arr = timedelta_range("1 day", periods=3).values
  961:         result = algos.isin(arr, [arr[0]])
  962:         expected = np.array([True, False, False])
  963:         tm.assert_numpy_array_equal(result, expected)
  964: 
  965:         result = algos.isin(arr, arr[0:2])
  966:         expected = np.array([True, True, False])
  967:         tm.assert_numpy_array_equal(result, expected)
  968: 
  969:         result = algos.isin(arr, set(arr[0:2]))
  970:         expected = np.array([True, True, False])
  971:         tm.assert_numpy_array_equal(result, expected)
  972: 
  973:     @pytest.mark.parametrize("dtype1", ["m8[ns]", "M8[ns]", "M8[ns, UTC]", "period[D]"])
  974:     @pytest.mark.parametrize("dtype", ["i8", "f8", "u8"])
  975:     def test_isin_datetimelike_values_numeric_comps(self, dtype, dtype1):
  976:         # Anything but object and we get all-False shortcut
  977: 
  978:         dta = date_range("2013-01-01", periods=3)._values
  979:         arr = Series(dta.view("i8")).array.view(dtype1)
  980: 
  981:         comps = arr.view("i8").astype(dtype)
  982: 
  983:         result = algos.isin(comps, arr)
  984:         expected = np.zeros(comps.shape, dtype=bool)
  985:         tm.assert_numpy_array_equal(result, expected)
  986: 
  987:     def test_large(self):
  988:         s = date_range("20000101", periods=2000000, freq="s").values
  989:         result = algos.isin(s, s[0:2])
  990:         expected = np.zeros(len(s), dtype=bool)
  991:         expected[0] = True
  992:         expected[1] = True
  993:         tm.assert_numpy_array_equal(result, expected)
  994: 
  995:     @pytest.mark.parametrize("dtype", ["m8[ns]", "M8[ns]", "M8[ns, UTC]", "period[D]"])
  996:     def test_isin_datetimelike_all_nat(self, dtype):
  997:         # GH#56427
  998:         dta = date_range("2013-01-01", periods=3)._values
  999:         arr = Series(dta.view("i8")).array.view(dtype)
 1000: 
 1001:         arr[0] = NaT
 1002:         result = algos.isin(arr, [NaT])
 1003:         expected = np.array([True, False, False], dtype=bool)
 1004:         tm.assert_numpy_array_equal(result, expected)
 1005: 
 1006:     @pytest.mark.parametrize("dtype", ["m8[ns]", "M8[ns]", "M8[ns, UTC]"])
 1007:     def test_isin_datetimelike_strings_deprecated(self, dtype):
 1008:         # GH#53111
 1009:         dta = date_range("2013-01-01", periods=3)._values
 1010:         arr = Series(dta.view("i8")).array.view(dtype)
 1011: 
 1012:         vals = [str(x) for x in arr]
 1013:         msg = "The behavior of 'isin' with dtype=.* is deprecated"
 1014:         with tm.assert_produces_warning(FutureWarning, match=msg):
 1015:             res = algos.isin(arr, vals)
 1016:         assert res.all()
 1017: 
 1018:         vals2 = np.array(vals, dtype=str)
 1019:         with tm.assert_produces_warning(FutureWarning, match=msg):
 1020:             res2 = algos.isin(arr, vals2)
 1021:         assert res2.all()
 1022: 
 1023:     def test_isin_dt64tz_with_nat(self):
 1024:         # the all-NaT values used to get inferred to tznaive, which was evaluated
 1025:         #  as non-matching GH#56427
 1026:         dti = date_range("2016-01-01", periods=3, tz="UTC")
 1027:         ser = Series(dti)
 1028:         ser[0] = NaT
 1029: 
 1030:         res = algos.isin(ser._values, [NaT])
 1031:         exp = np.array([True, False, False], dtype=bool)
 1032:         tm.assert_numpy_array_equal(res, exp)
 1033: 
 1034:     def test_categorical_from_codes(self):
 1035:         # GH 16639
 1036:         vals = np.array([0, 1, 2, 0])
 1037:         cats = ["a", "b", "c"]
 1038:         Sd = Series(Categorical([1]).from_codes(vals, cats))
 1039:         St = Series(Categorical([1]).from_codes(np.array([0, 1]), cats))
 1040:         expected = np.array([True, True, False, True])
 1041:         result = algos.isin(Sd, St)
 1042:         tm.assert_numpy_array_equal(expected, result)
 1043: 
 1044:     def test_categorical_isin(self):
 1045:         vals = np.array([0, 1, 2, 0])
 1046:         cats = ["a", "b", "c"]
 1047:         cat = Categorical([1]).from_codes(vals, cats)
 1048:         other = Categorical([1]).from_codes(np.array([0, 1]), cats)
 1049: 
 1050:         expected = np.array([True, True, False, True])
 1051:         result = algos.isin(cat, other)
 1052:         tm.assert_numpy_array_equal(expected, result)
 1053: 
 1054:     def test_same_nan_is_in(self):
 1055:         # GH 22160
 1056:         # nan is special, because from " a is b" doesn't follow "a == b"
 1057:         # at least, isin() should follow python's "np.nan in [nan] == True"
 1058:         # casting to -> np.float64 -> another float-object somewhere on
 1059:         # the way could lead jeopardize this behavior
 1060:         comps = [np.nan]  # could be casted to float64
 1061:         values = [np.nan]
 1062:         expected = np.array([True])
 1063:         msg = "isin with argument that is not not a Series"
 1064:         with tm.assert_produces_warning(FutureWarning, match=msg):
 1065:             result = algos.isin(comps, values)
 1066:         tm.assert_numpy_array_equal(expected, result)
 1067: 
 1068:     def test_same_nan_is_in_large(self):
 1069:         # https://github.com/pandas-dev/pandas/issues/22205
 1070:         s = np.tile(1.0, 1_000_001)
 1071:         s[0] = np.nan
 1072:         result = algos.isin(s, np.array([np.nan, 1]))
 1073:         expected = np.ones(len(s), dtype=bool)
 1074:         tm.assert_numpy_array_equal(result, expected)
 1075: 
 1076:     def test_same_nan_is_in_large_series(self):
 1077:         # https://github.com/pandas-dev/pandas/issues/22205
 1078:         s = np.tile(1.0, 1_000_001)
 1079:         series = Series(s)
 1080:         s[0] = np.nan
 1081:         result = series.isin(np.array([np.nan, 1]))
 1082:         expected = Series(np.ones(len(s), dtype=bool))
 1083:         tm.assert_series_equal(result, expected)
 1084: 
 1085:     def test_same_object_is_in(self):
 1086:         # GH 22160
 1087:         # there could be special treatment for nans
 1088:         # the user however could define a custom class
 1089:         # with similar behavior, then we at least should
 1090:         # fall back to usual python's behavior: "a in [a] == True"
 1091:         class LikeNan:
 1092:             def __eq__(self, other) -> bool:
 1093:                 return False
 1094: 
 1095:             def __hash__(self):
 1096:                 return 0
 1097: 
 1098:         a, b = LikeNan(), LikeNan()
 1099: 
 1100:         msg = "isin with argument that is not not a Series"
 1101:         with tm.assert_produces_warning(FutureWarning, match=msg):
 1102:             # same object -> True
 1103:             tm.assert_numpy_array_equal(algos.isin([a], [a]), np.array([True]))
 1104:             # different objects -> False
 1105:             tm.assert_numpy_array_equal(algos.isin([a], [b]), np.array([False]))
 1106: 
 1107:     def test_different_nans(self):
 1108:         # GH 22160
 1109:         # all nans are handled as equivalent
 1110: 
 1111:         comps = [float("nan")]
 1112:         values = [float("nan")]
 1113:         assert comps[0] is not values[0]  # different nan-objects
 1114: 
 1115:         # as list of python-objects:
 1116:         result = algos.isin(np.array(comps), values)
 1117:         tm.assert_numpy_array_equal(np.array([True]), result)
 1118: 
 1119:         # as object-array:
 1120:         result = algos.isin(
 1121:             np.asarray(comps, dtype=object), np.asarray(values, dtype=object)
 1122:         )
 1123:         tm.assert_numpy_array_equal(np.array([True]), result)
 1124: 
 1125:         # as float64-array:
 1126:         result = algos.isin(
 1127:             np.asarray(comps, dtype=np.float64), np.asarray(values, dtype=np.float64)
 1128:         )
 1129:         tm.assert_numpy_array_equal(np.array([True]), result)
 1130: 
 1131:     def test_no_cast(self):
 1132:         # GH 22160
 1133:         # ensure 42 is not casted to a string
 1134:         comps = ["ss", 42]
 1135:         values = ["42"]
 1136:         expected = np.array([False, False])
 1137:         msg = "isin with argument that is not not a Series, Index"
 1138:         with tm.assert_produces_warning(FutureWarning, match=msg):
 1139:             result = algos.isin(comps, values)
 1140:         tm.assert_numpy_array_equal(expected, result)
 1141: 
 1142:     @pytest.mark.parametrize("empty", [[], Series(dtype=object), np.array([])])
 1143:     def test_empty(self, empty):
 1144:         # see gh-16991
 1145:         vals = Index(["a", "b"])
 1146:         expected = np.array([False, False])
 1147: 
 1148:         result = algos.isin(vals, empty)
 1149:         tm.assert_numpy_array_equal(expected, result)
 1150: 
 1151:     def test_different_nan_objects(self):
 1152:         # GH 22119
 1153:         comps = np.array(["nan", np.nan * 1j, float("nan")], dtype=object)
 1154:         vals = np.array([float("nan")], dtype=object)
 1155:         expected = np.array([False, False, True])
 1156:         result = algos.isin(comps, vals)
 1157:         tm.assert_numpy_array_equal(expected, result)
 1158: 
 1159:     def test_different_nans_as_float64(self):
 1160:         # GH 21866
 1161:         # create different nans from bit-patterns,
 1162:         # these nans will land in different buckets in the hash-table
 1163:         # if no special care is taken
 1164:         NAN1 = struct.unpack("d", struct.pack("=Q", 0x7FF8000000000000))[0]
 1165:         NAN2 = struct.unpack("d", struct.pack("=Q", 0x7FF8000000000001))[0]
 1166:         assert NAN1 != NAN1
 1167:         assert NAN2 != NAN2
 1168: 
 1169:         # check that NAN1 and NAN2 are equivalent:
 1170:         arr = np.array([NAN1, NAN2], dtype=np.float64)
 1171:         lookup1 = np.array([NAN1], dtype=np.float64)
 1172:         result = algos.isin(arr, lookup1)
 1173:         expected = np.array([True, True])
 1174:         tm.assert_numpy_array_equal(result, expected)
 1175: 
 1176:         lookup2 = np.array([NAN2], dtype=np.float64)
 1177:         result = algos.isin(arr, lookup2)
 1178:         expected = np.array([True, True])
 1179:         tm.assert_numpy_array_equal(result, expected)
 1180: 
 1181:     def test_isin_int_df_string_search(self):
 1182:         """Comparing df with int`s (1,2) with a string at isin() ("1")
 1183:         -> should not match values because int 1 is not equal str 1"""
 1184:         df = DataFrame({"values": [1, 2]})
 1185:         result = df.isin(["1"])
 1186:         expected_false = DataFrame({"values": [False, False]})
 1187:         tm.assert_frame_equal(result, expected_false)
 1188: 
 1189:     def test_isin_nan_df_string_search(self):
 1190:         """Comparing df with nan value (np.nan,2) with a string at isin() ("NaN")
 1191:         -> should not match values because np.nan is not equal str NaN"""
 1192:         df = DataFrame({"values": [np.nan, 2]})
 1193:         result = df.isin(np.array(["NaN"], dtype=object))
 1194:         expected_false = DataFrame({"values": [False, False]})
 1195:         tm.assert_frame_equal(result, expected_false)
 1196: 
 1197:     def test_isin_float_df_string_search(self):
 1198:         """Comparing df with floats (1.4245,2.32441) with a string at isin() ("1.4245")
 1199:         -> should not match values because float 1.4245 is not equal str 1.4245"""
 1200:         df = DataFrame({"values": [1.4245, 2.32441]})
 1201:         result = df.isin(np.array(["1.4245"], dtype=object))
 1202:         expected_false = DataFrame({"values": [False, False]})
 1203:         tm.assert_frame_equal(result, expected_false)
 1204: 
 1205:     def test_isin_unsigned_dtype(self):
 1206:         # GH#46485
 1207:         ser = Series([1378774140726870442], dtype=np.uint64)
 1208:         result = ser.isin([1378774140726870528])
 1209:         expected = Series(False)
 1210:         tm.assert_series_equal(result, expected)
 1211: 
 1212: 
 1213: class TestValueCounts:
 1214:     def test_value_counts(self):
 1215:         arr = np.random.default_rng(1234).standard_normal(4)
 1216:         factor = cut(arr, 4)
 1217: 
 1218:         # assert isinstance(factor, n)
 1219:         msg = "pandas.value_counts is deprecated"
 1220:         with tm.assert_produces_warning(FutureWarning, match=msg):
 1221:             result = algos.value_counts(factor)
 1222:         breaks = [-1.606, -1.018, -0.431, 0.155, 0.741]
 1223:         index = IntervalIndex.from_breaks(breaks).astype(CategoricalDtype(ordered=True))
 1224:         expected = Series([1, 0, 2, 1], index=index, name="count")
 1225:         tm.assert_series_equal(result.sort_index(), expected.sort_index())
 1226: 
 1227:     def test_value_counts_bins(self):
 1228:         s = [1, 2, 3, 4]
 1229:         msg = "pandas.value_counts is deprecated"
 1230:         with tm.assert_produces_warning(FutureWarning, match=msg):
 1231:             result = algos.value_counts(s, bins=1)
 1232:         expected = Series(
 1233:             [4], index=IntervalIndex.from_tuples([(0.996, 4.0)]), name="count"
 1234:         )
 1235:         tm.assert_series_equal(result, expected)
 1236: 
 1237:         with tm.assert_produces_warning(FutureWarning, match=msg):
 1238:             result = algos.value_counts(s, bins=2, sort=False)
 1239:         expected = Series(
 1240:             [2, 2],
 1241:             index=IntervalIndex.from_tuples([(0.996, 2.5), (2.5, 4.0)]),
 1242:             name="count",
 1243:         )
 1244:         tm.assert_series_equal(result, expected)
 1245: 
 1246:     def test_value_counts_dtypes(self):
 1247:         msg2 = "pandas.value_counts is deprecated"
 1248:         with tm.assert_produces_warning(FutureWarning, match=msg2):
 1249:             result = algos.value_counts(np.array([1, 1.0]))
 1250:         assert len(result) == 1
 1251: 
 1252:         with tm.assert_produces_warning(FutureWarning, match=msg2):
 1253:             result = algos.value_counts(np.array([1, 1.0]), bins=1)
 1254:         assert len(result) == 1
 1255: 
 1256:         with tm.assert_produces_warning(FutureWarning, match=msg2):
 1257:             result = algos.value_counts(Series([1, 1.0, "1"]))  # object
 1258:         assert len(result) == 2
 1259: 
 1260:         msg = "bins argument only works with numeric data"
 1261:         with pytest.raises(TypeError, match=msg):
 1262:             with tm.assert_produces_warning(FutureWarning, match=msg2):
 1263:                 algos.value_counts(np.array(["1", 1], dtype=object), bins=1)
 1264: 
 1265:     def test_value_counts_nat(self):
 1266:         td = Series([np.timedelta64(10000), NaT], dtype="timedelta64[ns]")
 1267:         dt = to_datetime(["NaT", "2014-01-01"])
 1268: 
 1269:         msg = "pandas.value_counts is deprecated"
 1270: 
 1271:         for ser in [td, dt]:
 1272:             with tm.assert_produces_warning(FutureWarning, match=msg):
 1273:                 vc = algos.value_counts(ser)
 1274:                 vc_with_na = algos.value_counts(ser, dropna=False)
 1275:             assert len(vc) == 1
 1276:             assert len(vc_with_na) == 2
 1277: 
 1278:         exp_dt = Series({Timestamp("2014-01-01 00:00:00"): 1}, name="count")
 1279:         with tm.assert_produces_warning(FutureWarning, match=msg):
 1280:             result_dt = algos.value_counts(dt)
 1281:         tm.assert_series_equal(result_dt, exp_dt)
 1282: 
 1283:         exp_td = Series({np.timedelta64(10000): 1}, name="count")
 1284:         with tm.assert_produces_warning(FutureWarning, match=msg):
 1285:             result_td = algos.value_counts(td)
 1286:         tm.assert_series_equal(result_td, exp_td)
 1287: 
 1288:     @pytest.mark.parametrize("dtype", [object, "M8[us]"])
 1289:     def test_value_counts_datetime_outofbounds(self, dtype):
 1290:         # GH 13663
 1291:         ser = Series(
 1292:             [
 1293:                 datetime(3000, 1, 1),
 1294:                 datetime(5000, 1, 1),
 1295:                 datetime(5000, 1, 1),
 1296:                 datetime(6000, 1, 1),
 1297:                 datetime(3000, 1, 1),
 1298:                 datetime(3000, 1, 1),
 1299:             ],
 1300:             dtype=dtype,
 1301:         )
 1302:         res = ser.value_counts()
 1303: 
 1304:         exp_index = Index(
 1305:             [datetime(3000, 1, 1), datetime(5000, 1, 1), datetime(6000, 1, 1)],
 1306:             dtype=dtype,
 1307:         )
 1308:         exp = Series([3, 2, 1], index=exp_index, name="count")
 1309:         tm.assert_series_equal(res, exp)
 1310: 
 1311:     def test_categorical(self):
 1312:         s = Series(Categorical(list("aaabbc")))
 1313:         result = s.value_counts()
 1314:         expected = Series(
 1315:             [3, 2, 1], index=CategoricalIndex(["a", "b", "c"]), name="count"
 1316:         )
 1317: 
 1318:         tm.assert_series_equal(result, expected, check_index_type=True)
 1319: 
 1320:         # preserve order?
 1321:         s = s.cat.as_ordered()
 1322:         result = s.value_counts()
 1323:         expected.index = expected.index.as_ordered()
 1324:         tm.assert_series_equal(result, expected, check_index_type=True)
 1325: 
 1326:     def test_categorical_nans(self):
 1327:         s = Series(Categorical(list("aaaaabbbcc")))  # 4,3,2,1 (nan)
 1328:         s.iloc[1] = np.nan
 1329:         result = s.value_counts()
 1330:         expected = Series(
 1331:             [4, 3, 2],
 1332:             index=CategoricalIndex(["a", "b", "c"], categories=["a", "b", "c"]),
 1333:             name="count",
 1334:         )
 1335:         tm.assert_series_equal(result, expected, check_index_type=True)
 1336:         result = s.value_counts(dropna=False)
 1337:         expected = Series(
 1338:             [4, 3, 2, 1], index=CategoricalIndex(["a", "b", "c", np.nan]), name="count"
 1339:         )
 1340:         tm.assert_series_equal(result, expected, check_index_type=True)
 1341: 
 1342:         # out of order
 1343:         s = Series(
 1344:             Categorical(list("aaaaabbbcc"), ordered=True, categories=["b", "a", "c"])
 1345:         )
 1346:         s.iloc[1] = np.nan
 1347:         result = s.value_counts()
 1348:         expected = Series(
 1349:             [4, 3, 2],
 1350:             index=CategoricalIndex(
 1351:                 ["a", "b", "c"],
 1352:                 categories=["b", "a", "c"],
 1353:                 ordered=True,
 1354:             ),
 1355:             name="count",
 1356:         )
 1357:         tm.assert_series_equal(result, expected, check_index_type=True)
 1358: 
 1359:         result = s.value_counts(dropna=False)
 1360:         expected = Series(
 1361:             [4, 3, 2, 1],
 1362:             index=CategoricalIndex(
 1363:                 ["a", "b", "c", np.nan], categories=["b", "a", "c"], ordered=True
 1364:             ),
 1365:             name="count",
 1366:         )
 1367:         tm.assert_series_equal(result, expected, check_index_type=True)
 1368: 
 1369:     def test_categorical_zeroes(self):
 1370:         # keep the `d` category with 0
 1371:         s = Series(Categorical(list("bbbaac"), categories=list("abcd"), ordered=True))
 1372:         result = s.value_counts()
 1373:         expected = Series(
 1374:             [3, 2, 1, 0],
 1375:             index=Categorical(
 1376:                 ["b", "a", "c", "d"], categories=list("abcd"), ordered=True
 1377:             ),
 1378:             name="count",
 1379:         )
 1380:         tm.assert_series_equal(result, expected, check_index_type=True)
 1381: 
 1382:     def test_value_counts_dropna(self):
 1383:         # https://github.com/pandas-dev/pandas/issues/9443#issuecomment-73719328
 1384: 
 1385:         tm.assert_series_equal(
 1386:             Series([True, True, False]).value_counts(dropna=True),
 1387:             Series([2, 1], index=[True, False], name="count"),
 1388:         )
 1389:         tm.assert_series_equal(
 1390:             Series([True, True, False]).value_counts(dropna=False),
 1391:             Series([2, 1], index=[True, False], name="count"),
 1392:         )
 1393: 
 1394:         tm.assert_series_equal(
 1395:             Series([True] * 3 + [False] * 2 + [None] * 5).value_counts(dropna=True),
 1396:             Series([3, 2], index=Index([True, False], dtype=object), name="count"),
 1397:         )
 1398:         tm.assert_series_equal(
 1399:             Series([True] * 5 + [False] * 3 + [None] * 2).value_counts(dropna=False),
 1400:             Series([5, 3, 2], index=[True, False, None], name="count"),
 1401:         )
 1402:         tm.assert_series_equal(
 1403:             Series([10.3, 5.0, 5.0]).value_counts(dropna=True),
 1404:             Series([2, 1], index=[5.0, 10.3], name="count"),
 1405:         )
 1406:         tm.assert_series_equal(
 1407:             Series([10.3, 5.0, 5.0]).value_counts(dropna=False),
 1408:             Series([2, 1], index=[5.0, 10.3], name="count"),
 1409:         )
 1410: 
 1411:         tm.assert_series_equal(
 1412:             Series([10.3, 5.0, 5.0, None]).value_counts(dropna=True),
 1413:             Series([2, 1], index=[5.0, 10.3], name="count"),
 1414:         )
 1415: 
 1416:         result = Series([10.3, 10.3, 5.0, 5.0, 5.0, None]).value_counts(dropna=False)
 1417:         expected = Series([3, 2, 1], index=[5.0, 10.3, None], name="count")
 1418:         tm.assert_series_equal(result, expected)
 1419: 
 1420:     @pytest.mark.parametrize("dtype", (np.float64, object, "M8[ns]"))
 1421:     def test_value_counts_normalized(self, dtype):
 1422:         # GH12558
 1423:         s = Series([1] * 2 + [2] * 3 + [np.nan] * 5)
 1424:         s_typed = s.astype(dtype)
 1425:         result = s_typed.value_counts(normalize=True, dropna=False)
 1426:         expected = Series(
 1427:             [0.5, 0.3, 0.2],
 1428:             index=Series([np.nan, 2.0, 1.0], dtype=dtype),
 1429:             name="proportion",
 1430:         )
 1431:         tm.assert_series_equal(result, expected)
 1432: 
 1433:         result = s_typed.value_counts(normalize=True, dropna=True)
 1434:         expected = Series(
 1435:             [0.6, 0.4], index=Series([2.0, 1.0], dtype=dtype), name="proportion"
 1436:         )
 1437:         tm.assert_series_equal(result, expected)
 1438: 
 1439:     def test_value_counts_uint64(self):
 1440:         arr = np.array([2**63], dtype=np.uint64)
 1441:         expected = Series([1], index=[2**63], name="count")
 1442:         msg = "pandas.value_counts is deprecated"
 1443:         with tm.assert_produces_warning(FutureWarning, match=msg):
 1444:             result = algos.value_counts(arr)
 1445: 
 1446:         tm.assert_series_equal(result, expected)
 1447: 
 1448:         arr = np.array([-1, 2**63], dtype=object)
 1449:         expected = Series([1, 1], index=[-1, 2**63], name="count")
 1450:         with tm.assert_produces_warning(FutureWarning, match=msg):
 1451:             result = algos.value_counts(arr)
 1452: 
 1453:         tm.assert_series_equal(result, expected)
 1454: 
 1455:     def test_value_counts_series(self):
 1456:         # GH#54857
 1457:         values = np.array([3, 1, 2, 3, 4, np.nan])
 1458:         result = Series(values).value_counts(bins=3)
 1459:         expected = Series(
 1460:             [2, 2, 1],
 1461:             index=IntervalIndex.from_tuples(
 1462:                 [(0.996, 2.0), (2.0, 3.0), (3.0, 4.0)], dtype="interval[float64, right]"
 1463:             ),
 1464:             name="count",
 1465:         )
 1466:         tm.assert_series_equal(result, expected)
 1467: 
 1468: 
 1469: class TestDuplicated:
 1470:     def test_duplicated_with_nas(self):
 1471:         keys = np.array([0, 1, np.nan, 0, 2, np.nan], dtype=object)
 1472: 
 1473:         result = algos.duplicated(keys)
 1474:         expected = np.array([False, False, False, True, False, True])
 1475:         tm.assert_numpy_array_equal(result, expected)
 1476: 
 1477:         result = algos.duplicated(keys, keep="first")
 1478:         expected = np.array([False, False, False, True, False, True])
 1479:         tm.assert_numpy_array_equal(result, expected)
 1480: 
 1481:         result = algos.duplicated(keys, keep="last")
 1482:         expected = np.array([True, False, True, False, False, False])
 1483:         tm.assert_numpy_array_equal(result, expected)
 1484: 
 1485:         result = algos.duplicated(keys, keep=False)
 1486:         expected = np.array([True, False, True, True, False, True])
 1487:         tm.assert_numpy_array_equal(result, expected)
 1488: 
 1489:         keys = np.empty(8, dtype=object)
 1490:         for i, t in enumerate(
 1491:             zip([0, 0, np.nan, np.nan] * 2, [0, np.nan, 0, np.nan] * 2)
 1492:         ):
 1493:             keys[i] = t
 1494: 
 1495:         result = algos.duplicated(keys)
 1496:         falses = [False] * 4
 1497:         trues = [True] * 4
 1498:         expected = np.array(falses + trues)
 1499:         tm.assert_numpy_array_equal(result, expected)
 1500: 
 1501:         result = algos.duplicated(keys, keep="last")
 1502:         expected = np.array(trues + falses)
 1503:         tm.assert_numpy_array_equal(result, expected)
 1504: 
 1505:         result = algos.duplicated(keys, keep=False)
 1506:         expected = np.array(trues + trues)
 1507:         tm.assert_numpy_array_equal(result, expected)
 1508: 
 1509:     @pytest.mark.parametrize(
 1510:         "case",
 1511:         [
 1512:             np.array([1, 2, 1, 5, 3, 2, 4, 1, 5, 6]),
 1513:             np.array([1.1, 2.2, 1.1, np.nan, 3.3, 2.2, 4.4, 1.1, np.nan, 6.6]),
 1514:             np.array(
 1515:                 [
 1516:                     1 + 1j,
 1517:                     2 + 2j,
 1518:                     1 + 1j,
 1519:                     5 + 5j,
 1520:                     3 + 3j,
 1521:                     2 + 2j,
 1522:                     4 + 4j,
 1523:                     1 + 1j,
 1524:                     5 + 5j,
 1525:                     6 + 6j,
 1526:                 ]
 1527:             ),
 1528:             np.array(["a", "b", "a", "e", "c", "b", "d", "a", "e", "f"], dtype=object),
 1529:             np.array(
 1530:                 [1, 2**63, 1, 3**5, 10, 2**63, 39, 1, 3**5, 7], dtype=np.uint64
 1531:             ),
 1532:         ],
 1533:     )
 1534:     def test_numeric_object_likes(self, case):
 1535:         exp_first = np.array(
 1536:             [False, False, True, False, False, True, False, True, True, False]
 1537:         )
 1538:         exp_last = np.array(
 1539:             [True, True, True, True, False, False, False, False, False, False]
 1540:         )
 1541:         exp_false = exp_first | exp_last
 1542: 
 1543:         res_first = algos.duplicated(case, keep="first")
 1544:         tm.assert_numpy_array_equal(res_first, exp_first)
 1545: 
 1546:         res_last = algos.duplicated(case, keep="last")
 1547:         tm.assert_numpy_array_equal(res_last, exp_last)
 1548: 
 1549:         res_false = algos.duplicated(case, keep=False)
 1550:         tm.assert_numpy_array_equal(res_false, exp_false)
 1551: 
 1552:         # index
 1553:         for idx in [Index(case), Index(case, dtype="category")]:
 1554:             res_first = idx.duplicated(keep="first")
 1555:             tm.assert_numpy_array_equal(res_first, exp_first)
 1556: 
 1557:             res_last = idx.duplicated(keep="last")
 1558:             tm.assert_numpy_array_equal(res_last, exp_last)
 1559: 
 1560:             res_false = idx.duplicated(keep=False)
 1561:             tm.assert_numpy_array_equal(res_false, exp_false)
 1562: 
 1563:         # series
 1564:         for s in [Series(case), Series(case, dtype="category")]:
 1565:             res_first = s.duplicated(keep="first")
 1566:             tm.assert_series_equal(res_first, Series(exp_first))
 1567: 
 1568:             res_last = s.duplicated(keep="last")
 1569:             tm.assert_series_equal(res_last, Series(exp_last))
 1570: 
 1571:             res_false = s.duplicated(keep=False)
 1572:             tm.assert_series_equal(res_false, Series(exp_false))
 1573: 
 1574:     def test_datetime_likes(self):
 1575:         dt = [
 1576:             "2011-01-01",
 1577:             "2011-01-02",
 1578:             "2011-01-01",
 1579:             "NaT",
 1580:             "2011-01-03",
 1581:             "2011-01-02",
 1582:             "2011-01-04",
 1583:             "2011-01-01",
 1584:             "NaT",
 1585:             "2011-01-06",
 1586:         ]
 1587:         td = [
 1588:             "1 days",
 1589:             "2 days",
 1590:             "1 days",
 1591:             "NaT",
 1592:             "3 days",
 1593:             "2 days",
 1594:             "4 days",
 1595:             "1 days",
 1596:             "NaT",
 1597:             "6 days",
 1598:         ]
 1599: 
 1600:         cases = [
 1601:             np.array([Timestamp(d) for d in dt]),
 1602:             np.array([Timestamp(d, tz="US/Eastern") for d in dt]),
 1603:             np.array([Period(d, freq="D") for d in dt]),
 1604:             np.array([np.datetime64(d) for d in dt]),
 1605:             np.array([Timedelta(d) for d in td]),
 1606:         ]
 1607: 
 1608:         exp_first = np.array(
 1609:             [False, False, True, False, False, True, False, True, True, False]
 1610:         )
 1611:         exp_last = np.array(
 1612:             [True, True, True, True, False, False, False, False, False, False]
 1613:         )
 1614:         exp_false = exp_first | exp_last
 1615: 
 1616:         for case in cases:
 1617:             res_first = algos.duplicated(case, keep="first")
 1618:             tm.assert_numpy_array_equal(res_first, exp_first)
 1619: 
 1620:             res_last = algos.duplicated(case, keep="last")
 1621:             tm.assert_numpy_array_equal(res_last, exp_last)
 1622: 
 1623:             res_false = algos.duplicated(case, keep=False)
 1624:             tm.assert_numpy_array_equal(res_false, exp_false)
 1625: 
 1626:             # index
 1627:             for idx in [
 1628:                 Index(case),
 1629:                 Index(case, dtype="category"),
 1630:                 Index(case, dtype=object),
 1631:             ]:
 1632:                 res_first = idx.duplicated(keep="first")
 1633:                 tm.assert_numpy_array_equal(res_first, exp_first)
 1634: 
 1635:                 res_last = idx.duplicated(keep="last")
 1636:                 tm.assert_numpy_array_equal(res_last, exp_last)
 1637: 
 1638:                 res_false = idx.duplicated(keep=False)
 1639:                 tm.assert_numpy_array_equal(res_false, exp_false)
 1640: 
 1641:             # series
 1642:             for s in [
 1643:                 Series(case),
 1644:                 Series(case, dtype="category"),
 1645:                 Series(case, dtype=object),
 1646:             ]:
 1647:                 res_first = s.duplicated(keep="first")
 1648:                 tm.assert_series_equal(res_first, Series(exp_first))
 1649: 
 1650:                 res_last = s.duplicated(keep="last")
 1651:                 tm.assert_series_equal(res_last, Series(exp_last))
 1652: 
 1653:                 res_false = s.duplicated(keep=False)
 1654:                 tm.assert_series_equal(res_false, Series(exp_false))
 1655: 
 1656:     @pytest.mark.parametrize("case", [Index([1, 2, 3]), pd.RangeIndex(0, 3)])
 1657:     def test_unique_index(self, case):
 1658:         assert case.is_unique is True
 1659:         tm.assert_numpy_array_equal(case.duplicated(), np.array([False, False, False]))
 1660: 
 1661:     @pytest.mark.parametrize(
 1662:         "arr, uniques",
 1663:         [
 1664:             (
 1665:                 [(0, 0), (0, 1), (1, 0), (1, 1), (0, 0), (0, 1), (1, 0), (1, 1)],
 1666:                 [(0, 0), (0, 1), (1, 0), (1, 1)],
 1667:             ),
 1668:             (
 1669:                 [("b", "c"), ("a", "b"), ("a", "b"), ("b", "c")],
 1670:                 [("b", "c"), ("a", "b")],
 1671:             ),
 1672:             ([("a", 1), ("b", 2), ("a", 3), ("a", 1)], [("a", 1), ("b", 2), ("a", 3)]),
 1673:         ],
 1674:     )
 1675:     def test_unique_tuples(self, arr, uniques):
 1676:         # https://github.com/pandas-dev/pandas/issues/16519
 1677:         expected = np.empty(len(uniques), dtype=object)
 1678:         expected[:] = uniques
 1679: 
 1680:         msg = "unique with argument that is not not a Series"
 1681:         with tm.assert_produces_warning(FutureWarning, match=msg):
 1682:             result = pd.unique(arr)
 1683:         tm.assert_numpy_array_equal(result, expected)
 1684: 
 1685:     @pytest.mark.parametrize(
 1686:         "array,expected",
 1687:         [
 1688:             (
 1689:                 [1 + 1j, 0, 1, 1j, 1 + 2j, 1 + 2j],
 1690:                 # Should return a complex dtype in the future
 1691:                 np.array([(1 + 1j), 0j, (1 + 0j), 1j, (1 + 2j)], dtype=object),
 1692:             )
 1693:         ],
 1694:     )
 1695:     def test_unique_complex_numbers(self, array, expected):
 1696:         # GH 17927
 1697:         msg = "unique with argument that is not not a Series"
 1698:         with tm.assert_produces_warning(FutureWarning, match=msg):
 1699:             result = pd.unique(array)
 1700:         tm.assert_numpy_array_equal(result, expected)
 1701: 
 1702: 
 1703: class TestHashTable:
 1704:     @pytest.mark.parametrize(
 1705:         "htable, data",
 1706:         [
 1707:             (ht.PyObjectHashTable, [f"foo_{i}" for i in range(1000)]),
 1708:             (ht.StringHashTable, [f"foo_{i}" for i in range(1000)]),
 1709:             (ht.Float64HashTable, np.arange(1000, dtype=np.float64)),
 1710:             (ht.Int64HashTable, np.arange(1000, dtype=np.int64)),
 1711:             (ht.UInt64HashTable, np.arange(1000, dtype=np.uint64)),
 1712:         ],
 1713:     )
 1714:     def test_hashtable_unique(self, htable, data, writable):
 1715:         # output of maker has guaranteed unique elements
 1716:         s = Series(data)
 1717:         if htable == ht.Float64HashTable:
 1718:             # add NaN for float column
 1719:             s.loc[500] = np.nan
 1720:         elif htable == ht.PyObjectHashTable:
 1721:             # use different NaN types for object column
 1722:             s.loc[500:502] = [np.nan, None, NaT]
 1723: 
 1724:         # create duplicated selection
 1725:         s_duplicated = s.sample(frac=3, replace=True).reset_index(drop=True)
 1726:         s_duplicated.values.setflags(write=writable)
 1727: 
 1728:         # drop_duplicates has own cython code (hash_table_func_helper.pxi)
 1729:         # and is tested separately; keeps first occurrence like ht.unique()
 1730:         expected_unique = s_duplicated.drop_duplicates(keep="first").values
 1731:         result_unique = htable().unique(s_duplicated.values)
 1732:         tm.assert_numpy_array_equal(result_unique, expected_unique)
 1733: 
 1734:         # test return_inverse=True
 1735:         # reconstruction can only succeed if the inverse is correct
 1736:         result_unique, result_inverse = htable().unique(
 1737:             s_duplicated.values, return_inverse=True
 1738:         )
 1739:         tm.assert_numpy_array_equal(result_unique, expected_unique)
 1740:         reconstr = result_unique[result_inverse]
 1741:         tm.assert_numpy_array_equal(reconstr, s_duplicated.values)
 1742: 
 1743:     @pytest.mark.parametrize(
 1744:         "htable, data",
 1745:         [
 1746:             (ht.PyObjectHashTable, [f"foo_{i}" for i in range(1000)]),
 1747:             (ht.StringHashTable, [f"foo_{i}" for i in range(1000)]),
 1748:             (ht.Float64HashTable, np.arange(1000, dtype=np.float64)),
 1749:             (ht.Int64HashTable, np.arange(1000, dtype=np.int64)),
 1750:             (ht.UInt64HashTable, np.arange(1000, dtype=np.uint64)),
 1751:         ],
 1752:     )
 1753:     def test_hashtable_factorize(self, htable, writable, data):
 1754:         # output of maker has guaranteed unique elements
 1755:         s = Series(data)
 1756:         if htable == ht.Float64HashTable:
 1757:             # add NaN for float column
 1758:             s.loc[500] = np.nan
 1759:         elif htable == ht.PyObjectHashTable:
 1760:             # use different NaN types for object column
 1761:             s.loc[500:502] = [np.nan, None, NaT]
 1762: 
 1763:         # create duplicated selection
 1764:         s_duplicated = s.sample(frac=3, replace=True).reset_index(drop=True)
 1765:         s_duplicated.values.setflags(write=writable)
 1766:         na_mask = s_duplicated.isna().values
 1767: 
 1768:         result_unique, result_inverse = htable().factorize(s_duplicated.values)
 1769: 
 1770:         # drop_duplicates has own cython code (hash_table_func_helper.pxi)
 1771:         # and is tested separately; keeps first occurrence like ht.factorize()
 1772:         # since factorize removes all NaNs, we do the same here
 1773:         expected_unique = s_duplicated.dropna().drop_duplicates().values
 1774:         tm.assert_numpy_array_equal(result_unique, expected_unique)
 1775: 
 1776:         # reconstruction can only succeed if the inverse is correct. Since
 1777:         # factorize removes the NaNs, those have to be excluded here as well
 1778:         result_reconstruct = result_unique[result_inverse[~na_mask]]
 1779:         expected_reconstruct = s_duplicated.dropna().values
 1780:         tm.assert_numpy_array_equal(result_reconstruct, expected_reconstruct)
 1781: 
 1782: 
 1783: class TestRank:
 1784:     @pytest.mark.parametrize(
 1785:         "arr",
 1786:         [
 1787:             [np.nan, np.nan, 5.0, 5.0, 5.0, np.nan, 1, 2, 3, np.nan],
 1788:             [4.0, np.nan, 5.0, 5.0, 5.0, np.nan, 1, 2, 4.0, np.nan],
 1789:         ],
 1790:     )
 1791:     def test_scipy_compat(self, arr):
 1792:         sp_stats = pytest.importorskip("scipy.stats")
 1793: 
 1794:         arr = np.array(arr)
 1795: 
 1796:         mask = ~np.isfinite(arr)
 1797:         arr = arr.copy()
 1798:         result = libalgos.rank_1d(arr)
 1799:         arr[mask] = np.inf
 1800:         exp = sp_stats.rankdata(arr)
 1801:         exp[mask] = np.nan
 1802:         tm.assert_almost_equal(result, exp)
 1803: 
 1804:     @pytest.mark.parametrize("dtype", np.typecodes["AllInteger"])
 1805:     def test_basic(self, writable, dtype):
 1806:         exp = np.array([1, 2], dtype=np.float64)
 1807: 
 1808:         data = np.array([1, 100], dtype=dtype)
 1809:         data.setflags(write=writable)
 1810:         ser = Series(data)
 1811:         result = algos.rank(ser)
 1812:         tm.assert_numpy_array_equal(result, exp)
 1813: 
 1814:     @pytest.mark.parametrize("dtype", [np.float64, np.uint64])
 1815:     def test_uint64_overflow(self, dtype):
 1816:         exp = np.array([1, 2], dtype=np.float64)
 1817: 
 1818:         s = Series([1, 2**63], dtype=dtype)
 1819:         tm.assert_numpy_array_equal(algos.rank(s), exp)
 1820: 
 1821:     def test_too_many_ndims(self):
 1822:         arr = np.array([[[1, 2, 3], [4, 5, 6], [7, 8, 9]]])
 1823:         msg = "Array with ndim > 2 are not supported"
 1824: 
 1825:         with pytest.raises(TypeError, match=msg):
 1826:             algos.rank(arr)
 1827: 
 1828:     @pytest.mark.single_cpu
 1829:     def test_pct_max_many_rows(self):
 1830:         # GH 18271
 1831:         values = np.arange(2**24 + 1)
 1832:         result = algos.rank(values, pct=True).max()
 1833:         assert result == 1
 1834: 
 1835:         values = np.arange(2**25 + 2).reshape(2**24 + 1, 2)
 1836:         result = algos.rank(values, pct=True).max()
 1837:         assert result == 1
 1838: 
 1839: 
 1840: class TestMode:
 1841:     def test_no_mode(self):
 1842:         exp = Series([], dtype=np.float64, index=Index([], dtype=int))
 1843:         tm.assert_numpy_array_equal(algos.mode(np.array([])), exp.values)
 1844: 
 1845:     @pytest.mark.parametrize("dt", np.typecodes["AllInteger"] + np.typecodes["Float"])
 1846:     def test_mode_single(self, dt):
 1847:         # GH 15714
 1848:         exp_single = [1]
 1849:         data_single = [1]
 1850: 
 1851:         exp_multi = [1]
 1852:         data_multi = [1, 1]
 1853: 
 1854:         ser = Series(data_single, dtype=dt)
 1855:         exp = Series(exp_single, dtype=dt)
 1856:         tm.assert_numpy_array_equal(algos.mode(ser.values), exp.values)
 1857:         tm.assert_series_equal(ser.mode(), exp)
 1858: 
 1859:         ser = Series(data_multi, dtype=dt)
 1860:         exp = Series(exp_multi, dtype=dt)
 1861:         tm.assert_numpy_array_equal(algos.mode(ser.values), exp.values)
 1862:         tm.assert_series_equal(ser.mode(), exp)
 1863: 
 1864:     def test_mode_obj_int(self):
 1865:         exp = Series([1], dtype=int)
 1866:         tm.assert_numpy_array_equal(algos.mode(exp.values), exp.values)
 1867: 
 1868:         exp = Series(["a", "b", "c"], dtype=object)
 1869:         tm.assert_numpy_array_equal(algos.mode(exp.values), exp.values)
 1870: 
 1871:     @pytest.mark.parametrize("dt", np.typecodes["AllInteger"] + np.typecodes["Float"])
 1872:     def test_number_mode(self, dt):
 1873:         exp_single = [1]
 1874:         data_single = [1] * 5 + [2] * 3
 1875: 
 1876:         exp_multi = [1, 3]
 1877:         data_multi = [1] * 5 + [2] * 3 + [3] * 5
 1878: 
 1879:         ser = Series(data_single, dtype=dt)
 1880:         exp = Series(exp_single, dtype=dt)
 1881:         tm.assert_numpy_array_equal(algos.mode(ser.values), exp.values)
 1882:         tm.assert_series_equal(ser.mode(), exp)
 1883: 
 1884:         ser = Series(data_multi, dtype=dt)
 1885:         exp = Series(exp_multi, dtype=dt)
 1886:         tm.assert_numpy_array_equal(algos.mode(ser.values), exp.values)
 1887:         tm.assert_series_equal(ser.mode(), exp)
 1888: 
 1889:     def test_strobj_mode(self):
 1890:         exp = ["b"]
 1891:         data = ["a"] * 2 + ["b"] * 3
 1892: 
 1893:         ser = Series(data, dtype="c")
 1894:         exp = Series(exp, dtype="c")
 1895:         tm.assert_numpy_array_equal(algos.mode(ser.values), exp.values)
 1896:         tm.assert_series_equal(ser.mode(), exp)
 1897: 
 1898:     @pytest.mark.parametrize("dt", [str, object])
 1899:     def test_strobj_multi_char(self, dt):
 1900:         exp = ["bar"]
 1901:         data = ["foo"] * 2 + ["bar"] * 3
 1902: 
 1903:         ser = Series(data, dtype=dt)
 1904:         exp = Series(exp, dtype=dt)
 1905:         tm.assert_numpy_array_equal(algos.mode(ser.values), exp.values)
 1906:         tm.assert_series_equal(ser.mode(), exp)
 1907: 
 1908:     def test_datelike_mode(self):
 1909:         exp = Series(["1900-05-03", "2011-01-03", "2013-01-02"], dtype="M8[ns]")
 1910:         ser = Series(["2011-01-03", "2013-01-02", "1900-05-03"], dtype="M8[ns]")
 1911:         tm.assert_extension_array_equal(algos.mode(ser.values), exp._values)
 1912:         tm.assert_series_equal(ser.mode(), exp)
 1913: 
 1914:         exp = Series(["2011-01-03", "2013-01-02"], dtype="M8[ns]")
 1915:         ser = Series(
 1916:             ["2011-01-03", "2013-01-02", "1900-05-03", "2011-01-03", "2013-01-02"],
 1917:             dtype="M8[ns]",
 1918:         )
 1919:         tm.assert_extension_array_equal(algos.mode(ser.values), exp._values)
 1920:         tm.assert_series_equal(ser.mode(), exp)
 1921: 
 1922:     def test_timedelta_mode(self):
 1923:         exp = Series(["-1 days", "0 days", "1 days"], dtype="timedelta64[ns]")
 1924:         ser = Series(["1 days", "-1 days", "0 days"], dtype="timedelta64[ns]")
 1925:         tm.assert_extension_array_equal(algos.mode(ser.values), exp._values)
 1926:         tm.assert_series_equal(ser.mode(), exp)
 1927: 
 1928:         exp = Series(["2 min", "1 day"], dtype="timedelta64[ns]")
 1929:         ser = Series(
 1930:             ["1 day", "1 day", "-1 day", "-1 day 2 min", "2 min", "2 min"],
 1931:             dtype="timedelta64[ns]",
 1932:         )
 1933:         tm.assert_extension_array_equal(algos.mode(ser.values), exp._values)
 1934:         tm.assert_series_equal(ser.mode(), exp)
 1935: 
 1936:     def test_mixed_dtype(self):
 1937:         exp = Series(["foo"], dtype=object)
 1938:         ser = Series([1, "foo", "foo"])
 1939:         tm.assert_numpy_array_equal(algos.mode(ser.values), exp.values)
 1940:         tm.assert_series_equal(ser.mode(), exp)
 1941: 
 1942:     def test_uint64_overflow(self):
 1943:         exp = Series([2**63], dtype=np.uint64)
 1944:         ser = Series([1, 2**63, 2**63], dtype=np.uint64)
 1945:         tm.assert_numpy_array_equal(algos.mode(ser.values), exp.values)
 1946:         tm.assert_series_equal(ser.mode(), exp)
 1947: 
 1948:         exp = Series([1, 2**63], dtype=np.uint64)
 1949:         ser = Series([1, 2**63], dtype=np.uint64)
 1950:         tm.assert_numpy_array_equal(algos.mode(ser.values), exp.values)
 1951:         tm.assert_series_equal(ser.mode(), exp)
 1952: 
 1953:     def test_categorical(self):
 1954:         c = Categorical([1, 2])
 1955:         exp = c
 1956:         res = Series(c).mode()._values
 1957:         tm.assert_categorical_equal(res, exp)
 1958: 
 1959:         c = Categorical([1, "a", "a"])
 1960:         exp = Categorical(["a"], categories=[1, "a"])
 1961:         res = Series(c).mode()._values
 1962:         tm.assert_categorical_equal(res, exp)
 1963: 
 1964:         c = Categorical([1, 1, 2, 3, 3])
 1965:         exp = Categorical([1, 3], categories=[1, 2, 3])
 1966:         res = Series(c).mode()._values
 1967:         tm.assert_categorical_equal(res, exp)
 1968: 
 1969:     def test_index(self):
 1970:         idx = Index([1, 2, 3])
 1971:         exp = Series([1, 2, 3], dtype=np.int64)
 1972:         tm.assert_numpy_array_equal(algos.mode(idx), exp.values)
 1973: 
 1974:         idx = Index([1, "a", "a"])
 1975:         exp = Series(["a"], dtype=object)
 1976:         tm.assert_numpy_array_equal(algos.mode(idx), exp.values)
 1977: 
 1978:         idx = Index([1, 1, 2, 3, 3])
 1979:         exp = Series([1, 3], dtype=np.int64)
 1980:         tm.assert_numpy_array_equal(algos.mode(idx), exp.values)
 1981: 
 1982:         idx = Index(
 1983:             ["1 day", "1 day", "-1 day", "-1 day 2 min", "2 min", "2 min"],
 1984:             dtype="timedelta64[ns]",
 1985:         )
 1986:         with pytest.raises(AttributeError, match="TimedeltaIndex"):
 1987:             # algos.mode expects Arraylike, does *not* unwrap TimedeltaIndex
 1988:             algos.mode(idx)
 1989: 
 1990:     def test_ser_mode_with_name(self):
 1991:         # GH 46737
 1992:         ser = Series([1, 1, 3], name="foo")
 1993:         result = ser.mode()
 1994:         expected = Series([1], name="foo")
 1995:         tm.assert_series_equal(result, expected)
 1996: 
 1997: 
 1998: class TestDiff:
 1999:     @pytest.mark.parametrize("dtype", ["M8[ns]", "m8[ns]"])
 2000:     def test_diff_datetimelike_nat(self, dtype):
 2001:         # NaT - NaT is NaT, not 0
 2002:         arr = np.arange(12).astype(np.int64).view(dtype).reshape(3, 4)
 2003:         arr[:, 2] = arr.dtype.type("NaT", "ns")
 2004:         result = algos.diff(arr, 1, axis=0)
 2005: 
 2006:         expected = np.ones(arr.shape, dtype="timedelta64[ns]") * 4
 2007:         expected[:, 2] = np.timedelta64("NaT", "ns")
 2008:         expected[0, :] = np.timedelta64("NaT", "ns")
 2009: 
 2010:         tm.assert_numpy_array_equal(result, expected)
 2011: 
 2012:         result = algos.diff(arr.T, 1, axis=1)
 2013:         tm.assert_numpy_array_equal(result, expected.T)
 2014: 
 2015:     def test_diff_ea_axis(self):
 2016:         dta = date_range("2016-01-01", periods=3, tz="US/Pacific")._data
 2017: 
 2018:         msg = "cannot diff DatetimeArray on axis=1"
 2019:         with pytest.raises(ValueError, match=msg):
 2020:             algos.diff(dta, 1, axis=1)
 2021: 
 2022:     @pytest.mark.parametrize("dtype", ["int8", "int16"])
 2023:     def test_diff_low_precision_int(self, dtype):
 2024:         arr = np.array([0, 1, 1, 0, 0], dtype=dtype)
 2025:         result = algos.diff(arr, 1)
 2026:         expected = np.array([np.nan, 1, 0, -1, 0], dtype="float32")
 2027:         tm.assert_numpy_array_equal(result, expected)
 2028: 
 2029: 
 2030: @pytest.mark.parametrize("op", [np.array, pd.array])
 2031: def test_union_with_duplicates(op):
 2032:     # GH#36289
 2033:     lvals = op([3, 1, 3, 4])
 2034:     rvals = op([2, 3, 1, 1])
 2035:     expected = op([3, 3, 1, 1, 4, 2])
 2036:     if isinstance(expected, np.ndarray):
 2037:         result = algos.union_with_duplicates(lvals, rvals)
 2038:         tm.assert_numpy_array_equal(result, expected)
 2039:     else:
 2040:         result = algos.union_with_duplicates(lvals, rvals)
 2041:         tm.assert_extension_array_equal(result, expected)
