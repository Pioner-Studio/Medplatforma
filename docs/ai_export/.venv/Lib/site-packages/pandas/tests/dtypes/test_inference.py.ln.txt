    1: """
    2: These the test the public routines exposed in types/common.py
    3: related to inference and not otherwise tested in types/test_common.py
    4: 
    5: """
    6: import collections
    7: from collections import namedtuple
    8: from collections.abc import Iterator
    9: from datetime import (
   10:     date,
   11:     datetime,
   12:     time,
   13:     timedelta,
   14: )
   15: from decimal import Decimal
   16: from fractions import Fraction
   17: from io import StringIO
   18: import itertools
   19: from numbers import Number
   20: import re
   21: import sys
   22: from typing import (
   23:     Generic,
   24:     TypeVar,
   25: )
   26: 
   27: import numpy as np
   28: import pytest
   29: import pytz
   30: 
   31: from pandas._libs import (
   32:     lib,
   33:     missing as libmissing,
   34:     ops as libops,
   35: )
   36: from pandas.compat.numpy import np_version_gt2
   37: 
   38: from pandas.core.dtypes import inference
   39: from pandas.core.dtypes.cast import find_result_type
   40: from pandas.core.dtypes.common import (
   41:     ensure_int32,
   42:     is_bool,
   43:     is_complex,
   44:     is_datetime64_any_dtype,
   45:     is_datetime64_dtype,
   46:     is_datetime64_ns_dtype,
   47:     is_datetime64tz_dtype,
   48:     is_float,
   49:     is_integer,
   50:     is_number,
   51:     is_scalar,
   52:     is_scipy_sparse,
   53:     is_timedelta64_dtype,
   54:     is_timedelta64_ns_dtype,
   55: )
   56: 
   57: import pandas as pd
   58: from pandas import (
   59:     Categorical,
   60:     DataFrame,
   61:     DateOffset,
   62:     DatetimeIndex,
   63:     Index,
   64:     Interval,
   65:     Period,
   66:     PeriodIndex,
   67:     Series,
   68:     Timedelta,
   69:     TimedeltaIndex,
   70:     Timestamp,
   71: )
   72: import pandas._testing as tm
   73: from pandas.core.arrays import (
   74:     BooleanArray,
   75:     FloatingArray,
   76:     IntegerArray,
   77: )
   78: 
   79: 
   80: @pytest.fixture(params=[True, False], ids=str)
   81: def coerce(request):
   82:     return request.param
   83: 
   84: 
   85: class MockNumpyLikeArray:
   86:     """
   87:     A class which is numpy-like (e.g. Pint's Quantity) but not actually numpy
   88: 
   89:     The key is that it is not actually a numpy array so
   90:     ``util.is_array(mock_numpy_like_array_instance)`` returns ``False``. Other
   91:     important properties are that the class defines a :meth:`__iter__` method
   92:     (so that ``isinstance(abc.Iterable)`` returns ``True``) and has a
   93:     :meth:`ndim` property, as pandas special-cases 0-dimensional arrays in some
   94:     cases.
   95: 
   96:     We expect pandas to behave with respect to such duck arrays exactly as
   97:     with real numpy arrays. In particular, a 0-dimensional duck array is *NOT*
   98:     a scalar (`is_scalar(np.array(1)) == False`), but it is not list-like either.
   99:     """
  100: 
  101:     def __init__(self, values) -> None:
  102:         self._values = values
  103: 
  104:     def __iter__(self) -> Iterator:
  105:         iter_values = iter(self._values)
  106: 
  107:         def it_outer():
  108:             yield from iter_values
  109: 
  110:         return it_outer()
  111: 
  112:     def __len__(self) -> int:
  113:         return len(self._values)
  114: 
  115:     def __array__(self, dtype=None, copy=None):
  116:         return np.asarray(self._values, dtype=dtype)
  117: 
  118:     @property
  119:     def ndim(self):
  120:         return self._values.ndim
  121: 
  122:     @property
  123:     def dtype(self):
  124:         return self._values.dtype
  125: 
  126:     @property
  127:     def size(self):
  128:         return self._values.size
  129: 
  130:     @property
  131:     def shape(self):
  132:         return self._values.shape
  133: 
  134: 
  135: # collect all objects to be tested for list-like-ness; use tuples of objects,
  136: # whether they are list-like or not (special casing for sets), and their ID
  137: ll_params = [
  138:     ([1], True, "list"),
  139:     ([], True, "list-empty"),
  140:     ((1,), True, "tuple"),
  141:     ((), True, "tuple-empty"),
  142:     ({"a": 1}, True, "dict"),
  143:     ({}, True, "dict-empty"),
  144:     ({"a", 1}, "set", "set"),
  145:     (set(), "set", "set-empty"),
  146:     (frozenset({"a", 1}), "set", "frozenset"),
  147:     (frozenset(), "set", "frozenset-empty"),
  148:     (iter([1, 2]), True, "iterator"),
  149:     (iter([]), True, "iterator-empty"),
  150:     ((x for x in [1, 2]), True, "generator"),
  151:     ((_ for _ in []), True, "generator-empty"),
  152:     (Series([1]), True, "Series"),
  153:     (Series([], dtype=object), True, "Series-empty"),
  154:     # Series.str will still raise a TypeError if iterated
  155:     (Series(["a"]).str, True, "StringMethods"),
  156:     (Series([], dtype="O").str, True, "StringMethods-empty"),
  157:     (Index([1]), True, "Index"),
  158:     (Index([]), True, "Index-empty"),
  159:     (DataFrame([[1]]), True, "DataFrame"),
  160:     (DataFrame(), True, "DataFrame-empty"),
  161:     (np.ndarray((2,) * 1), True, "ndarray-1d"),
  162:     (np.array([]), True, "ndarray-1d-empty"),
  163:     (np.ndarray((2,) * 2), True, "ndarray-2d"),
  164:     (np.array([[]]), True, "ndarray-2d-empty"),
  165:     (np.ndarray((2,) * 3), True, "ndarray-3d"),
  166:     (np.array([[[]]]), True, "ndarray-3d-empty"),
  167:     (np.ndarray((2,) * 4), True, "ndarray-4d"),
  168:     (np.array([[[[]]]]), True, "ndarray-4d-empty"),
  169:     (np.array(2), False, "ndarray-0d"),
  170:     (MockNumpyLikeArray(np.ndarray((2,) * 1)), True, "duck-ndarray-1d"),
  171:     (MockNumpyLikeArray(np.array([])), True, "duck-ndarray-1d-empty"),
  172:     (MockNumpyLikeArray(np.ndarray((2,) * 2)), True, "duck-ndarray-2d"),
  173:     (MockNumpyLikeArray(np.array([[]])), True, "duck-ndarray-2d-empty"),
  174:     (MockNumpyLikeArray(np.ndarray((2,) * 3)), True, "duck-ndarray-3d"),
  175:     (MockNumpyLikeArray(np.array([[[]]])), True, "duck-ndarray-3d-empty"),
  176:     (MockNumpyLikeArray(np.ndarray((2,) * 4)), True, "duck-ndarray-4d"),
  177:     (MockNumpyLikeArray(np.array([[[[]]]])), True, "duck-ndarray-4d-empty"),
  178:     (MockNumpyLikeArray(np.array(2)), False, "duck-ndarray-0d"),
  179:     (1, False, "int"),
  180:     (b"123", False, "bytes"),
  181:     (b"", False, "bytes-empty"),
  182:     ("123", False, "string"),
  183:     ("", False, "string-empty"),
  184:     (str, False, "string-type"),
  185:     (object(), False, "object"),
  186:     (np.nan, False, "NaN"),
  187:     (None, False, "None"),
  188: ]
  189: objs, expected, ids = zip(*ll_params)
  190: 
  191: 
  192: @pytest.fixture(params=zip(objs, expected), ids=ids)
  193: def maybe_list_like(request):
  194:     return request.param
  195: 
  196: 
  197: def test_is_list_like(maybe_list_like):
  198:     obj, expected = maybe_list_like
  199:     expected = True if expected == "set" else expected
  200:     assert inference.is_list_like(obj) == expected
  201: 
  202: 
  203: def test_is_list_like_disallow_sets(maybe_list_like):
  204:     obj, expected = maybe_list_like
  205:     expected = False if expected == "set" else expected
  206:     assert inference.is_list_like(obj, allow_sets=False) == expected
  207: 
  208: 
  209: def test_is_list_like_recursion():
  210:     # GH 33721
  211:     # interpreter would crash with SIGABRT
  212:     def list_like():
  213:         inference.is_list_like([])
  214:         list_like()
  215: 
  216:     rec_limit = sys.getrecursionlimit()
  217:     try:
  218:         # Limit to avoid stack overflow on Windows CI
  219:         sys.setrecursionlimit(100)
  220:         with tm.external_error_raised(RecursionError):
  221:             list_like()
  222:     finally:
  223:         sys.setrecursionlimit(rec_limit)
  224: 
  225: 
  226: def test_is_list_like_iter_is_none():
  227:     # GH 43373
  228:     # is_list_like was yielding false positives with __iter__ == None
  229:     class NotListLike:
  230:         def __getitem__(self, item):
  231:             return self
  232: 
  233:         __iter__ = None
  234: 
  235:     assert not inference.is_list_like(NotListLike())
  236: 
  237: 
  238: def test_is_list_like_generic():
  239:     # GH 49649
  240:     # is_list_like was yielding false positives for Generic classes in python 3.11
  241:     T = TypeVar("T")
  242: 
  243:     class MyDataFrame(DataFrame, Generic[T]):
  244:         ...
  245: 
  246:     tstc = MyDataFrame[int]
  247:     tst = MyDataFrame[int]({"x": [1, 2, 3]})
  248: 
  249:     assert not inference.is_list_like(tstc)
  250:     assert isinstance(tst, DataFrame)
  251:     assert inference.is_list_like(tst)
  252: 
  253: 
  254: def test_is_sequence():
  255:     is_seq = inference.is_sequence
  256:     assert is_seq((1, 2))
  257:     assert is_seq([1, 2])
  258:     assert not is_seq("abcd")
  259:     assert not is_seq(np.int64)
  260: 
  261:     class A:
  262:         def __getitem__(self, item):
  263:             return 1
  264: 
  265:     assert not is_seq(A())
  266: 
  267: 
  268: def test_is_array_like():
  269:     assert inference.is_array_like(Series([], dtype=object))
  270:     assert inference.is_array_like(Series([1, 2]))
  271:     assert inference.is_array_like(np.array(["a", "b"]))
  272:     assert inference.is_array_like(Index(["2016-01-01"]))
  273:     assert inference.is_array_like(np.array([2, 3]))
  274:     assert inference.is_array_like(MockNumpyLikeArray(np.array([2, 3])))
  275: 
  276:     class DtypeList(list):
  277:         dtype = "special"
  278: 
  279:     assert inference.is_array_like(DtypeList())
  280: 
  281:     assert not inference.is_array_like([1, 2, 3])
  282:     assert not inference.is_array_like(())
  283:     assert not inference.is_array_like("foo")
  284:     assert not inference.is_array_like(123)
  285: 
  286: 
  287: @pytest.mark.parametrize(
  288:     "inner",
  289:     [
  290:         [],
  291:         [1],
  292:         (1,),
  293:         (1, 2),
  294:         {"a": 1},
  295:         {1, "a"},
  296:         Series([1]),
  297:         Series([], dtype=object),
  298:         Series(["a"]).str,
  299:         (x for x in range(5)),
  300:     ],
  301: )
  302: @pytest.mark.parametrize("outer", [list, Series, np.array, tuple])
  303: def test_is_nested_list_like_passes(inner, outer):
  304:     result = outer([inner for _ in range(5)])
  305:     assert inference.is_list_like(result)
  306: 
  307: 
  308: @pytest.mark.parametrize(
  309:     "obj",
  310:     [
  311:         "abc",
  312:         [],
  313:         [1],
  314:         (1,),
  315:         ["a"],
  316:         "a",
  317:         {"a"},
  318:         [1, 2, 3],
  319:         Series([1]),
  320:         DataFrame({"A": [1]}),
  321:         ([1, 2] for _ in range(5)),
  322:     ],
  323: )
  324: def test_is_nested_list_like_fails(obj):
  325:     assert not inference.is_nested_list_like(obj)
  326: 
  327: 
  328: @pytest.mark.parametrize("ll", [{}, {"A": 1}, Series([1]), collections.defaultdict()])
  329: def test_is_dict_like_passes(ll):
  330:     assert inference.is_dict_like(ll)
  331: 
  332: 
  333: @pytest.mark.parametrize(
  334:     "ll",
  335:     [
  336:         "1",
  337:         1,
  338:         [1, 2],
  339:         (1, 2),
  340:         range(2),
  341:         Index([1]),
  342:         dict,
  343:         collections.defaultdict,
  344:         Series,
  345:     ],
  346: )
  347: def test_is_dict_like_fails(ll):
  348:     assert not inference.is_dict_like(ll)
  349: 
  350: 
  351: @pytest.mark.parametrize("has_keys", [True, False])
  352: @pytest.mark.parametrize("has_getitem", [True, False])
  353: @pytest.mark.parametrize("has_contains", [True, False])
  354: def test_is_dict_like_duck_type(has_keys, has_getitem, has_contains):
  355:     class DictLike:
  356:         def __init__(self, d) -> None:
  357:             self.d = d
  358: 
  359:         if has_keys:
  360: 
  361:             def keys(self):
  362:                 return self.d.keys()
  363: 
  364:         if has_getitem:
  365: 
  366:             def __getitem__(self, key):
  367:                 return self.d.__getitem__(key)
  368: 
  369:         if has_contains:
  370: 
  371:             def __contains__(self, key) -> bool:
  372:                 return self.d.__contains__(key)
  373: 
  374:     d = DictLike({1: 2})
  375:     result = inference.is_dict_like(d)
  376:     expected = has_keys and has_getitem and has_contains
  377: 
  378:     assert result is expected
  379: 
  380: 
  381: def test_is_file_like():
  382:     class MockFile:
  383:         pass
  384: 
  385:     is_file = inference.is_file_like
  386: 
  387:     data = StringIO("data")
  388:     assert is_file(data)
  389: 
  390:     # No read / write attributes
  391:     # No iterator attributes
  392:     m = MockFile()
  393:     assert not is_file(m)
  394: 
  395:     MockFile.write = lambda self: 0
  396: 
  397:     # Write attribute but not an iterator
  398:     m = MockFile()
  399:     assert not is_file(m)
  400: 
  401:     # gh-16530: Valid iterator just means we have the
  402:     # __iter__ attribute for our purposes.
  403:     MockFile.__iter__ = lambda self: self
  404: 
  405:     # Valid write-only file
  406:     m = MockFile()
  407:     assert is_file(m)
  408: 
  409:     del MockFile.write
  410:     MockFile.read = lambda self: 0
  411: 
  412:     # Valid read-only file
  413:     m = MockFile()
  414:     assert is_file(m)
  415: 
  416:     # Iterator but no read / write attributes
  417:     data = [1, 2, 3]
  418:     assert not is_file(data)
  419: 
  420: 
  421: test_tuple = collections.namedtuple("test_tuple", ["a", "b", "c"])
  422: 
  423: 
  424: @pytest.mark.parametrize("ll", [test_tuple(1, 2, 3)])
  425: def test_is_names_tuple_passes(ll):
  426:     assert inference.is_named_tuple(ll)
  427: 
  428: 
  429: @pytest.mark.parametrize("ll", [(1, 2, 3), "a", Series({"pi": 3.14})])
  430: def test_is_names_tuple_fails(ll):
  431:     assert not inference.is_named_tuple(ll)
  432: 
  433: 
  434: def test_is_hashable():
  435:     # all new-style classes are hashable by default
  436:     class HashableClass:
  437:         pass
  438: 
  439:     class UnhashableClass1:
  440:         __hash__ = None
  441: 
  442:     class UnhashableClass2:
  443:         def __hash__(self):
  444:             raise TypeError("Not hashable")
  445: 
  446:     hashable = (1, 3.14, np.float64(3.14), "a", (), (1,), HashableClass())
  447:     not_hashable = ([], UnhashableClass1())
  448:     abc_hashable_not_really_hashable = (([],), UnhashableClass2())
  449: 
  450:     for i in hashable:
  451:         assert inference.is_hashable(i)
  452:     for i in not_hashable:
  453:         assert not inference.is_hashable(i)
  454:     for i in abc_hashable_not_really_hashable:
  455:         assert not inference.is_hashable(i)
  456: 
  457:     # numpy.array is no longer collections.abc.Hashable as of
  458:     # https://github.com/numpy/numpy/pull/5326, just test
  459:     # is_hashable()
  460:     assert not inference.is_hashable(np.array([]))
  461: 
  462: 
  463: @pytest.mark.parametrize("ll", [re.compile("ad")])
  464: def test_is_re_passes(ll):
  465:     assert inference.is_re(ll)
  466: 
  467: 
  468: @pytest.mark.parametrize("ll", ["x", 2, 3, object()])
  469: def test_is_re_fails(ll):
  470:     assert not inference.is_re(ll)
  471: 
  472: 
  473: @pytest.mark.parametrize(
  474:     "ll", [r"a", "x", r"asdf", re.compile("adsf"), r"\u2233\s*", re.compile(r"")]
  475: )
  476: def test_is_recompilable_passes(ll):
  477:     assert inference.is_re_compilable(ll)
  478: 
  479: 
  480: @pytest.mark.parametrize("ll", [1, [], object()])
  481: def test_is_recompilable_fails(ll):
  482:     assert not inference.is_re_compilable(ll)
  483: 
  484: 
  485: class TestInference:
  486:     @pytest.mark.parametrize(
  487:         "arr",
  488:         [
  489:             np.array(list("abc"), dtype="S1"),
  490:             np.array(list("abc"), dtype="S1").astype(object),
  491:             [b"a", np.nan, b"c"],
  492:         ],
  493:     )
  494:     def test_infer_dtype_bytes(self, arr):
  495:         result = lib.infer_dtype(arr, skipna=True)
  496:         assert result == "bytes"
  497: 
  498:     @pytest.mark.parametrize(
  499:         "value, expected",
  500:         [
  501:             (float("inf"), True),
  502:             (np.inf, True),
  503:             (-np.inf, False),
  504:             (1, False),
  505:             ("a", False),
  506:         ],
  507:     )
  508:     def test_isposinf_scalar(self, value, expected):
  509:         # GH 11352
  510:         result = libmissing.isposinf_scalar(value)
  511:         assert result is expected
  512: 
  513:     @pytest.mark.parametrize(
  514:         "value, expected",
  515:         [
  516:             (float("-inf"), True),
  517:             (-np.inf, True),
  518:             (np.inf, False),
  519:             (1, False),
  520:             ("a", False),
  521:         ],
  522:     )
  523:     def test_isneginf_scalar(self, value, expected):
  524:         result = libmissing.isneginf_scalar(value)
  525:         assert result is expected
  526: 
  527:     @pytest.mark.parametrize(
  528:         "convert_to_masked_nullable, exp",
  529:         [
  530:             (
  531:                 True,
  532:                 BooleanArray(
  533:                     np.array([True, False], dtype="bool"), np.array([False, True])
  534:                 ),
  535:             ),
  536:             (False, np.array([True, np.nan], dtype="object")),
  537:         ],
  538:     )
  539:     def test_maybe_convert_nullable_boolean(self, convert_to_masked_nullable, exp):
  540:         # GH 40687
  541:         arr = np.array([True, np.nan], dtype=object)
  542:         result = libops.maybe_convert_bool(
  543:             arr, set(), convert_to_masked_nullable=convert_to_masked_nullable
  544:         )
  545:         if convert_to_masked_nullable:
  546:             tm.assert_extension_array_equal(BooleanArray(*result), exp)
  547:         else:
  548:             result = result[0]
  549:             tm.assert_numpy_array_equal(result, exp)
  550: 
  551:     @pytest.mark.parametrize("convert_to_masked_nullable", [True, False])
  552:     @pytest.mark.parametrize("coerce_numeric", [True, False])
  553:     @pytest.mark.parametrize(
  554:         "infinity", ["inf", "inF", "iNf", "Inf", "iNF", "InF", "INf", "INF"]
  555:     )
  556:     @pytest.mark.parametrize("prefix", ["", "-", "+"])
  557:     def test_maybe_convert_numeric_infinities(
  558:         self, coerce_numeric, infinity, prefix, convert_to_masked_nullable
  559:     ):
  560:         # see gh-13274
  561:         result, _ = lib.maybe_convert_numeric(
  562:             np.array([prefix + infinity], dtype=object),
  563:             na_values={"", "NULL", "nan"},
  564:             coerce_numeric=coerce_numeric,
  565:             convert_to_masked_nullable=convert_to_masked_nullable,
  566:         )
  567:         expected = np.array([np.inf if prefix in ["", "+"] else -np.inf])
  568:         tm.assert_numpy_array_equal(result, expected)
  569: 
  570:     @pytest.mark.parametrize("convert_to_masked_nullable", [True, False])
  571:     def test_maybe_convert_numeric_infinities_raises(self, convert_to_masked_nullable):
  572:         msg = "Unable to parse string"
  573:         with pytest.raises(ValueError, match=msg):
  574:             lib.maybe_convert_numeric(
  575:                 np.array(["foo_inf"], dtype=object),
  576:                 na_values={"", "NULL", "nan"},
  577:                 coerce_numeric=False,
  578:                 convert_to_masked_nullable=convert_to_masked_nullable,
  579:             )
  580: 
  581:     @pytest.mark.parametrize("convert_to_masked_nullable", [True, False])
  582:     def test_maybe_convert_numeric_post_floatify_nan(
  583:         self, coerce, convert_to_masked_nullable
  584:     ):
  585:         # see gh-13314
  586:         data = np.array(["1.200", "-999.000", "4.500"], dtype=object)
  587:         expected = np.array([1.2, np.nan, 4.5], dtype=np.float64)
  588:         nan_values = {-999, -999.0}
  589: 
  590:         out = lib.maybe_convert_numeric(
  591:             data,
  592:             nan_values,
  593:             coerce,
  594:             convert_to_masked_nullable=convert_to_masked_nullable,
  595:         )
  596:         if convert_to_masked_nullable:
  597:             expected = FloatingArray(expected, np.isnan(expected))
  598:             tm.assert_extension_array_equal(expected, FloatingArray(*out))
  599:         else:
  600:             out = out[0]
  601:             tm.assert_numpy_array_equal(out, expected)
  602: 
  603:     def test_convert_infs(self):
  604:         arr = np.array(["inf", "inf", "inf"], dtype="O")
  605:         result, _ = lib.maybe_convert_numeric(arr, set(), False)
  606:         assert result.dtype == np.float64
  607: 
  608:         arr = np.array(["-inf", "-inf", "-inf"], dtype="O")
  609:         result, _ = lib.maybe_convert_numeric(arr, set(), False)
  610:         assert result.dtype == np.float64
  611: 
  612:     def test_scientific_no_exponent(self):
  613:         # See PR 12215
  614:         arr = np.array(["42E", "2E", "99e", "6e"], dtype="O")
  615:         result, _ = lib.maybe_convert_numeric(arr, set(), False, True)
  616:         assert np.all(np.isnan(result))
  617: 
  618:     def test_convert_non_hashable(self):
  619:         # GH13324
  620:         # make sure that we are handing non-hashables
  621:         arr = np.array([[10.0, 2], 1.0, "apple"], dtype=object)
  622:         result, _ = lib.maybe_convert_numeric(arr, set(), False, True)
  623:         tm.assert_numpy_array_equal(result, np.array([np.nan, 1.0, np.nan]))
  624: 
  625:     def test_convert_numeric_uint64(self):
  626:         arr = np.array([2**63], dtype=object)
  627:         exp = np.array([2**63], dtype=np.uint64)
  628:         tm.assert_numpy_array_equal(lib.maybe_convert_numeric(arr, set())[0], exp)
  629: 
  630:         arr = np.array([str(2**63)], dtype=object)
  631:         exp = np.array([2**63], dtype=np.uint64)
  632:         tm.assert_numpy_array_equal(lib.maybe_convert_numeric(arr, set())[0], exp)
  633: 
  634:         arr = np.array([np.uint64(2**63)], dtype=object)
  635:         exp = np.array([2**63], dtype=np.uint64)
  636:         tm.assert_numpy_array_equal(lib.maybe_convert_numeric(arr, set())[0], exp)
  637: 
  638:     @pytest.mark.parametrize(
  639:         "arr",
  640:         [
  641:             np.array([2**63, np.nan], dtype=object),
  642:             np.array([str(2**63), np.nan], dtype=object),
  643:             np.array([np.nan, 2**63], dtype=object),
  644:             np.array([np.nan, str(2**63)], dtype=object),
  645:         ],
  646:     )
  647:     def test_convert_numeric_uint64_nan(self, coerce, arr):
  648:         expected = arr.astype(float) if coerce else arr.copy()
  649:         result, _ = lib.maybe_convert_numeric(arr, set(), coerce_numeric=coerce)
  650:         tm.assert_almost_equal(result, expected)
  651: 
  652:     @pytest.mark.parametrize("convert_to_masked_nullable", [True, False])
  653:     def test_convert_numeric_uint64_nan_values(
  654:         self, coerce, convert_to_masked_nullable
  655:     ):
  656:         arr = np.array([2**63, 2**63 + 1], dtype=object)
  657:         na_values = {2**63}
  658: 
  659:         expected = (
  660:             np.array([np.nan, 2**63 + 1], dtype=float) if coerce else arr.copy()
  661:         )
  662:         result = lib.maybe_convert_numeric(
  663:             arr,
  664:             na_values,
  665:             coerce_numeric=coerce,
  666:             convert_to_masked_nullable=convert_to_masked_nullable,
  667:         )
  668:         if convert_to_masked_nullable and coerce:
  669:             expected = IntegerArray(
  670:                 np.array([0, 2**63 + 1], dtype="u8"),
  671:                 np.array([True, False], dtype="bool"),
  672:             )
  673:             result = IntegerArray(*result)
  674:         else:
  675:             result = result[0]  # discard mask
  676:         tm.assert_almost_equal(result, expected)
  677: 
  678:     @pytest.mark.parametrize(
  679:         "case",
  680:         [
  681:             np.array([2**63, -1], dtype=object),
  682:             np.array([str(2**63), -1], dtype=object),
  683:             np.array([str(2**63), str(-1)], dtype=object),
  684:             np.array([-1, 2**63], dtype=object),
  685:             np.array([-1, str(2**63)], dtype=object),
  686:             np.array([str(-1), str(2**63)], dtype=object),
  687:         ],
  688:     )
  689:     @pytest.mark.parametrize("convert_to_masked_nullable", [True, False])
  690:     def test_convert_numeric_int64_uint64(
  691:         self, case, coerce, convert_to_masked_nullable
  692:     ):
  693:         expected = case.astype(float) if coerce else case.copy()
  694:         result, _ = lib.maybe_convert_numeric(
  695:             case,
  696:             set(),
  697:             coerce_numeric=coerce,
  698:             convert_to_masked_nullable=convert_to_masked_nullable,
  699:         )
  700: 
  701:         tm.assert_almost_equal(result, expected)
  702: 
  703:     @pytest.mark.parametrize("convert_to_masked_nullable", [True, False])
  704:     def test_convert_numeric_string_uint64(self, convert_to_masked_nullable):
  705:         # GH32394
  706:         result = lib.maybe_convert_numeric(
  707:             np.array(["uint64"], dtype=object),
  708:             set(),
  709:             coerce_numeric=True,
  710:             convert_to_masked_nullable=convert_to_masked_nullable,
  711:         )
  712:         if convert_to_masked_nullable:
  713:             result = FloatingArray(*result)
  714:         else:
  715:             result = result[0]
  716:         assert np.isnan(result)
  717: 
  718:     @pytest.mark.parametrize("value", [-(2**63) - 1, 2**64])
  719:     def test_convert_int_overflow(self, value):
  720:         # see gh-18584
  721:         arr = np.array([value], dtype=object)
  722:         result = lib.maybe_convert_objects(arr)
  723:         tm.assert_numpy_array_equal(arr, result)
  724: 
  725:     @pytest.mark.parametrize("val", [None, np.nan, float("nan")])
  726:     @pytest.mark.parametrize("dtype", ["M8[ns]", "m8[ns]"])
  727:     def test_maybe_convert_objects_nat_inference(self, val, dtype):
  728:         dtype = np.dtype(dtype)
  729:         vals = np.array([pd.NaT, val], dtype=object)
  730:         result = lib.maybe_convert_objects(
  731:             vals,
  732:             convert_non_numeric=True,
  733:             dtype_if_all_nat=dtype,
  734:         )
  735:         assert result.dtype == dtype
  736:         assert np.isnat(result).all()
  737: 
  738:         result = lib.maybe_convert_objects(
  739:             vals[::-1],
  740:             convert_non_numeric=True,
  741:             dtype_if_all_nat=dtype,
  742:         )
  743:         assert result.dtype == dtype
  744:         assert np.isnat(result).all()
  745: 
  746:     @pytest.mark.parametrize(
  747:         "value, expected_dtype",
  748:         [
  749:             # see gh-4471
  750:             ([2**63], np.uint64),
  751:             # NumPy bug: can't compare uint64 to int64, as that
  752:             # results in both casting to float64, so we should
  753:             # make sure that this function is robust against it
  754:             ([np.uint64(2**63)], np.uint64),
  755:             ([2, -1], np.int64),
  756:             ([2**63, -1], object),
  757:             # GH#47294
  758:             ([np.uint8(1)], np.uint8),
  759:             ([np.uint16(1)], np.uint16),
  760:             ([np.uint32(1)], np.uint32),
  761:             ([np.uint64(1)], np.uint64),
  762:             ([np.uint8(2), np.uint16(1)], np.uint16),
  763:             ([np.uint32(2), np.uint16(1)], np.uint32),
  764:             ([np.uint32(2), -1], object),
  765:             ([np.uint32(2), 1], np.uint64),
  766:             ([np.uint32(2), np.int32(1)], object),
  767:         ],
  768:     )
  769:     def test_maybe_convert_objects_uint(self, value, expected_dtype):
  770:         arr = np.array(value, dtype=object)
  771:         exp = np.array(value, dtype=expected_dtype)
  772:         tm.assert_numpy_array_equal(lib.maybe_convert_objects(arr), exp)
  773: 
  774:     def test_maybe_convert_objects_datetime(self):
  775:         # GH27438
  776:         arr = np.array(
  777:             [np.datetime64("2000-01-01"), np.timedelta64(1, "s")], dtype=object
  778:         )
  779:         exp = arr.copy()
  780:         out = lib.maybe_convert_objects(arr, convert_non_numeric=True)
  781:         tm.assert_numpy_array_equal(out, exp)
  782: 
  783:         arr = np.array([pd.NaT, np.timedelta64(1, "s")], dtype=object)
  784:         exp = np.array([np.timedelta64("NaT"), np.timedelta64(1, "s")], dtype="m8[ns]")
  785:         out = lib.maybe_convert_objects(arr, convert_non_numeric=True)
  786:         tm.assert_numpy_array_equal(out, exp)
  787: 
  788:         # with convert_non_numeric=True, the nan is a valid NA value for td64
  789:         arr = np.array([np.timedelta64(1, "s"), np.nan], dtype=object)
  790:         exp = exp[::-1]
  791:         out = lib.maybe_convert_objects(arr, convert_non_numeric=True)
  792:         tm.assert_numpy_array_equal(out, exp)
  793: 
  794:     def test_maybe_convert_objects_dtype_if_all_nat(self):
  795:         arr = np.array([pd.NaT, pd.NaT], dtype=object)
  796:         out = lib.maybe_convert_objects(arr, convert_non_numeric=True)
  797:         # no dtype_if_all_nat passed -> we dont guess
  798:         tm.assert_numpy_array_equal(out, arr)
  799: 
  800:         out = lib.maybe_convert_objects(
  801:             arr,
  802:             convert_non_numeric=True,
  803:             dtype_if_all_nat=np.dtype("timedelta64[ns]"),
  804:         )
  805:         exp = np.array(["NaT", "NaT"], dtype="timedelta64[ns]")
  806:         tm.assert_numpy_array_equal(out, exp)
  807: 
  808:         out = lib.maybe_convert_objects(
  809:             arr,
  810:             convert_non_numeric=True,
  811:             dtype_if_all_nat=np.dtype("datetime64[ns]"),
  812:         )
  813:         exp = np.array(["NaT", "NaT"], dtype="datetime64[ns]")
  814:         tm.assert_numpy_array_equal(out, exp)
  815: 
  816:     def test_maybe_convert_objects_dtype_if_all_nat_invalid(self):
  817:         # we accept datetime64[ns], timedelta64[ns], and EADtype
  818:         arr = np.array([pd.NaT, pd.NaT], dtype=object)
  819: 
  820:         with pytest.raises(ValueError, match="int64"):
  821:             lib.maybe_convert_objects(
  822:                 arr,
  823:                 convert_non_numeric=True,
  824:                 dtype_if_all_nat=np.dtype("int64"),
  825:             )
  826: 
  827:     @pytest.mark.parametrize("dtype", ["datetime64[ns]", "timedelta64[ns]"])
  828:     def test_maybe_convert_objects_datetime_overflow_safe(self, dtype):
  829:         stamp = datetime(2363, 10, 4)  # Enterprise-D launch date
  830:         if dtype == "timedelta64[ns]":
  831:             stamp = stamp - datetime(1970, 1, 1)
  832:         arr = np.array([stamp], dtype=object)
  833: 
  834:         out = lib.maybe_convert_objects(arr, convert_non_numeric=True)
  835:         # no OutOfBoundsDatetime/OutOfBoundsTimedeltas
  836:         tm.assert_numpy_array_equal(out, arr)
  837: 
  838:     def test_maybe_convert_objects_mixed_datetimes(self):
  839:         ts = Timestamp("now")
  840:         vals = [ts, ts.to_pydatetime(), ts.to_datetime64(), pd.NaT, np.nan, None]
  841: 
  842:         for data in itertools.permutations(vals):
  843:             data = np.array(list(data), dtype=object)
  844:             expected = DatetimeIndex(data)._data._ndarray
  845:             result = lib.maybe_convert_objects(data, convert_non_numeric=True)
  846:             tm.assert_numpy_array_equal(result, expected)
  847: 
  848:     def test_maybe_convert_objects_timedelta64_nat(self):
  849:         obj = np.timedelta64("NaT", "ns")
  850:         arr = np.array([obj], dtype=object)
  851:         assert arr[0] is obj
  852: 
  853:         result = lib.maybe_convert_objects(arr, convert_non_numeric=True)
  854: 
  855:         expected = np.array([obj], dtype="m8[ns]")
  856:         tm.assert_numpy_array_equal(result, expected)
  857: 
  858:     @pytest.mark.parametrize(
  859:         "exp",
  860:         [
  861:             IntegerArray(np.array([2, 0], dtype="i8"), np.array([False, True])),
  862:             IntegerArray(np.array([2, 0], dtype="int64"), np.array([False, True])),
  863:         ],
  864:     )
  865:     def test_maybe_convert_objects_nullable_integer(self, exp):
  866:         # GH27335
  867:         arr = np.array([2, np.nan], dtype=object)
  868:         result = lib.maybe_convert_objects(arr, convert_to_nullable_dtype=True)
  869: 
  870:         tm.assert_extension_array_equal(result, exp)
  871: 
  872:     @pytest.mark.parametrize(
  873:         "dtype, val", [("int64", 1), ("uint64", np.iinfo(np.int64).max + 1)]
  874:     )
  875:     def test_maybe_convert_objects_nullable_none(self, dtype, val):
  876:         # GH#50043
  877:         arr = np.array([val, None, 3], dtype="object")
  878:         result = lib.maybe_convert_objects(arr, convert_to_nullable_dtype=True)
  879:         expected = IntegerArray(
  880:             np.array([val, 0, 3], dtype=dtype), np.array([False, True, False])
  881:         )
  882:         tm.assert_extension_array_equal(result, expected)
  883: 
  884:     @pytest.mark.parametrize(
  885:         "convert_to_masked_nullable, exp",
  886:         [
  887:             (True, IntegerArray(np.array([2, 0], dtype="i8"), np.array([False, True]))),
  888:             (False, np.array([2, np.nan], dtype="float64")),
  889:         ],
  890:     )
  891:     def test_maybe_convert_numeric_nullable_integer(
  892:         self, convert_to_masked_nullable, exp
  893:     ):
  894:         # GH 40687
  895:         arr = np.array([2, np.nan], dtype=object)
  896:         result = lib.maybe_convert_numeric(
  897:             arr, set(), convert_to_masked_nullable=convert_to_masked_nullable
  898:         )
  899:         if convert_to_masked_nullable:
  900:             result = IntegerArray(*result)
  901:             tm.assert_extension_array_equal(result, exp)
  902:         else:
  903:             result = result[0]
  904:             tm.assert_numpy_array_equal(result, exp)
  905: 
  906:     @pytest.mark.parametrize(
  907:         "convert_to_masked_nullable, exp",
  908:         [
  909:             (
  910:                 True,
  911:                 FloatingArray(
  912:                     np.array([2.0, 0.0], dtype="float64"), np.array([False, True])
  913:                 ),
  914:             ),
  915:             (False, np.array([2.0, np.nan], dtype="float64")),
  916:         ],
  917:     )
  918:     def test_maybe_convert_numeric_floating_array(
  919:         self, convert_to_masked_nullable, exp
  920:     ):
  921:         # GH 40687
  922:         arr = np.array([2.0, np.nan], dtype=object)
  923:         result = lib.maybe_convert_numeric(
  924:             arr, set(), convert_to_masked_nullable=convert_to_masked_nullable
  925:         )
  926:         if convert_to_masked_nullable:
  927:             tm.assert_extension_array_equal(FloatingArray(*result), exp)
  928:         else:
  929:             result = result[0]
  930:             tm.assert_numpy_array_equal(result, exp)
  931: 
  932:     def test_maybe_convert_objects_bool_nan(self):
  933:         # GH32146
  934:         ind = Index([True, False, np.nan], dtype=object)
  935:         exp = np.array([True, False, np.nan], dtype=object)
  936:         out = lib.maybe_convert_objects(ind.values, safe=1)
  937:         tm.assert_numpy_array_equal(out, exp)
  938: 
  939:     def test_maybe_convert_objects_nullable_boolean(self):
  940:         # GH50047
  941:         arr = np.array([True, False], dtype=object)
  942:         exp = np.array([True, False])
  943:         out = lib.maybe_convert_objects(arr, convert_to_nullable_dtype=True)
  944:         tm.assert_numpy_array_equal(out, exp)
  945: 
  946:         arr = np.array([True, False, pd.NaT], dtype=object)
  947:         exp = np.array([True, False, pd.NaT], dtype=object)
  948:         out = lib.maybe_convert_objects(arr, convert_to_nullable_dtype=True)
  949:         tm.assert_numpy_array_equal(out, exp)
  950: 
  951:     @pytest.mark.parametrize("val", [None, np.nan])
  952:     def test_maybe_convert_objects_nullable_boolean_na(self, val):
  953:         # GH50047
  954:         arr = np.array([True, False, val], dtype=object)
  955:         exp = BooleanArray(
  956:             np.array([True, False, False]), np.array([False, False, True])
  957:         )
  958:         out = lib.maybe_convert_objects(arr, convert_to_nullable_dtype=True)
  959:         tm.assert_extension_array_equal(out, exp)
  960: 
  961:     @pytest.mark.parametrize(
  962:         "data0",
  963:         [
  964:             True,
  965:             1,
  966:             1.0,
  967:             1.0 + 1.0j,
  968:             np.int8(1),
  969:             np.int16(1),
  970:             np.int32(1),
  971:             np.int64(1),
  972:             np.float16(1),
  973:             np.float32(1),
  974:             np.float64(1),
  975:             np.complex64(1),
  976:             np.complex128(1),
  977:         ],
  978:     )
  979:     @pytest.mark.parametrize(
  980:         "data1",
  981:         [
  982:             True,
  983:             1,
  984:             1.0,
  985:             1.0 + 1.0j,
  986:             np.int8(1),
  987:             np.int16(1),
  988:             np.int32(1),
  989:             np.int64(1),
  990:             np.float16(1),
  991:             np.float32(1),
  992:             np.float64(1),
  993:             np.complex64(1),
  994:             np.complex128(1),
  995:         ],
  996:     )
  997:     def test_maybe_convert_objects_itemsize(self, data0, data1):
  998:         # GH 40908
  999:         data = [data0, data1]
 1000:         arr = np.array(data, dtype="object")
 1001: 
 1002:         common_kind = np.result_type(type(data0), type(data1)).kind
 1003:         kind0 = "python" if not hasattr(data0, "dtype") else data0.dtype.kind
 1004:         kind1 = "python" if not hasattr(data1, "dtype") else data1.dtype.kind
 1005:         if kind0 != "python" and kind1 != "python":
 1006:             kind = common_kind
 1007:             itemsize = max(data0.dtype.itemsize, data1.dtype.itemsize)
 1008:         elif is_bool(data0) or is_bool(data1):
 1009:             kind = "bool" if (is_bool(data0) and is_bool(data1)) else "object"
 1010:             itemsize = ""
 1011:         elif is_complex(data0) or is_complex(data1):
 1012:             kind = common_kind
 1013:             itemsize = 16
 1014:         else:
 1015:             kind = common_kind
 1016:             itemsize = 8
 1017: 
 1018:         expected = np.array(data, dtype=f"{kind}{itemsize}")
 1019:         result = lib.maybe_convert_objects(arr)
 1020:         tm.assert_numpy_array_equal(result, expected)
 1021: 
 1022:     def test_mixed_dtypes_remain_object_array(self):
 1023:         # GH14956
 1024:         arr = np.array([datetime(2015, 1, 1, tzinfo=pytz.utc), 1], dtype=object)
 1025:         result = lib.maybe_convert_objects(arr, convert_non_numeric=True)
 1026:         tm.assert_numpy_array_equal(result, arr)
 1027: 
 1028:     @pytest.mark.parametrize(
 1029:         "idx",
 1030:         [
 1031:             pd.IntervalIndex.from_breaks(range(5), closed="both"),
 1032:             pd.period_range("2016-01-01", periods=3, freq="D"),
 1033:         ],
 1034:     )
 1035:     def test_maybe_convert_objects_ea(self, idx):
 1036:         result = lib.maybe_convert_objects(
 1037:             np.array(idx, dtype=object),
 1038:             convert_non_numeric=True,
 1039:         )
 1040:         tm.assert_extension_array_equal(result, idx._data)
 1041: 
 1042: 
 1043: class TestTypeInference:
 1044:     # Dummy class used for testing with Python objects
 1045:     class Dummy:
 1046:         pass
 1047: 
 1048:     def test_inferred_dtype_fixture(self, any_skipna_inferred_dtype):
 1049:         # see pandas/conftest.py
 1050:         inferred_dtype, values = any_skipna_inferred_dtype
 1051: 
 1052:         # make sure the inferred dtype of the fixture is as requested
 1053:         assert inferred_dtype == lib.infer_dtype(values, skipna=True)
 1054: 
 1055:     @pytest.mark.parametrize("skipna", [True, False])
 1056:     def test_length_zero(self, skipna):
 1057:         result = lib.infer_dtype(np.array([], dtype="i4"), skipna=skipna)
 1058:         assert result == "integer"
 1059: 
 1060:         result = lib.infer_dtype([], skipna=skipna)
 1061:         assert result == "empty"
 1062: 
 1063:         # GH 18004
 1064:         arr = np.array([np.array([], dtype=object), np.array([], dtype=object)])
 1065:         result = lib.infer_dtype(arr, skipna=skipna)
 1066:         assert result == "empty"
 1067: 
 1068:     def test_integers(self):
 1069:         arr = np.array([1, 2, 3, np.int64(4), np.int32(5)], dtype="O")
 1070:         result = lib.infer_dtype(arr, skipna=True)
 1071:         assert result == "integer"
 1072: 
 1073:         arr = np.array([1, 2, 3, np.int64(4), np.int32(5), "foo"], dtype="O")
 1074:         result = lib.infer_dtype(arr, skipna=True)
 1075:         assert result == "mixed-integer"
 1076: 
 1077:         arr = np.array([1, 2, 3, 4, 5], dtype="i4")
 1078:         result = lib.infer_dtype(arr, skipna=True)
 1079:         assert result == "integer"
 1080: 
 1081:     @pytest.mark.parametrize(
 1082:         "arr, skipna",
 1083:         [
 1084:             (np.array([1, 2, np.nan, np.nan, 3], dtype="O"), False),
 1085:             (np.array([1, 2, np.nan, np.nan, 3], dtype="O"), True),
 1086:             (np.array([1, 2, 3, np.int64(4), np.int32(5), np.nan], dtype="O"), False),
 1087:             (np.array([1, 2, 3, np.int64(4), np.int32(5), np.nan], dtype="O"), True),
 1088:         ],
 1089:     )
 1090:     def test_integer_na(self, arr, skipna):
 1091:         # GH 27392
 1092:         result = lib.infer_dtype(arr, skipna=skipna)
 1093:         expected = "integer" if skipna else "integer-na"
 1094:         assert result == expected
 1095: 
 1096:     def test_infer_dtype_skipna_default(self):
 1097:         # infer_dtype `skipna` default deprecated in GH#24050,
 1098:         #  changed to True in GH#29876
 1099:         arr = np.array([1, 2, 3, np.nan], dtype=object)
 1100: 
 1101:         result = lib.infer_dtype(arr)
 1102:         assert result == "integer"
 1103: 
 1104:     def test_bools(self):
 1105:         arr = np.array([True, False, True, True, True], dtype="O")
 1106:         result = lib.infer_dtype(arr, skipna=True)
 1107:         assert result == "boolean"
 1108: 
 1109:         arr = np.array([np.bool_(True), np.bool_(False)], dtype="O")
 1110:         result = lib.infer_dtype(arr, skipna=True)
 1111:         assert result == "boolean"
 1112: 
 1113:         arr = np.array([True, False, True, "foo"], dtype="O")
 1114:         result = lib.infer_dtype(arr, skipna=True)
 1115:         assert result == "mixed"
 1116: 
 1117:         arr = np.array([True, False, True], dtype=bool)
 1118:         result = lib.infer_dtype(arr, skipna=True)
 1119:         assert result == "boolean"
 1120: 
 1121:         arr = np.array([True, np.nan, False], dtype="O")
 1122:         result = lib.infer_dtype(arr, skipna=True)
 1123:         assert result == "boolean"
 1124: 
 1125:         result = lib.infer_dtype(arr, skipna=False)
 1126:         assert result == "mixed"
 1127: 
 1128:     def test_floats(self):
 1129:         arr = np.array([1.0, 2.0, 3.0, np.float64(4), np.float32(5)], dtype="O")
 1130:         result = lib.infer_dtype(arr, skipna=True)
 1131:         assert result == "floating"
 1132: 
 1133:         arr = np.array([1, 2, 3, np.float64(4), np.float32(5), "foo"], dtype="O")
 1134:         result = lib.infer_dtype(arr, skipna=True)
 1135:         assert result == "mixed-integer"
 1136: 
 1137:         arr = np.array([1, 2, 3, 4, 5], dtype="f4")
 1138:         result = lib.infer_dtype(arr, skipna=True)
 1139:         assert result == "floating"
 1140: 
 1141:         arr = np.array([1, 2, 3, 4, 5], dtype="f8")
 1142:         result = lib.infer_dtype(arr, skipna=True)
 1143:         assert result == "floating"
 1144: 
 1145:     def test_decimals(self):
 1146:         # GH15690
 1147:         arr = np.array([Decimal(1), Decimal(2), Decimal(3)])
 1148:         result = lib.infer_dtype(arr, skipna=True)
 1149:         assert result == "decimal"
 1150: 
 1151:         arr = np.array([1.0, 2.0, Decimal(3)])
 1152:         result = lib.infer_dtype(arr, skipna=True)
 1153:         assert result == "mixed"
 1154: 
 1155:         result = lib.infer_dtype(arr[::-1], skipna=True)
 1156:         assert result == "mixed"
 1157: 
 1158:         arr = np.array([Decimal(1), Decimal("NaN"), Decimal(3)])
 1159:         result = lib.infer_dtype(arr, skipna=True)
 1160:         assert result == "decimal"
 1161: 
 1162:         arr = np.array([Decimal(1), np.nan, Decimal(3)], dtype="O")
 1163:         result = lib.infer_dtype(arr, skipna=True)
 1164:         assert result == "decimal"
 1165: 
 1166:     # complex is compatible with nan, so skipna has no effect
 1167:     @pytest.mark.parametrize("skipna", [True, False])
 1168:     def test_complex(self, skipna):
 1169:         # gets cast to complex on array construction
 1170:         arr = np.array([1.0, 2.0, 1 + 1j])
 1171:         result = lib.infer_dtype(arr, skipna=skipna)
 1172:         assert result == "complex"
 1173: 
 1174:         arr = np.array([1.0, 2.0, 1 + 1j], dtype="O")
 1175:         result = lib.infer_dtype(arr, skipna=skipna)
 1176:         assert result == "mixed"
 1177: 
 1178:         result = lib.infer_dtype(arr[::-1], skipna=skipna)
 1179:         assert result == "mixed"
 1180: 
 1181:         # gets cast to complex on array construction
 1182:         arr = np.array([1, np.nan, 1 + 1j])
 1183:         result = lib.infer_dtype(arr, skipna=skipna)
 1184:         assert result == "complex"
 1185: 
 1186:         arr = np.array([1.0, np.nan, 1 + 1j], dtype="O")
 1187:         result = lib.infer_dtype(arr, skipna=skipna)
 1188:         assert result == "mixed"
 1189: 
 1190:         # complex with nans stays complex
 1191:         arr = np.array([1 + 1j, np.nan, 3 + 3j], dtype="O")
 1192:         result = lib.infer_dtype(arr, skipna=skipna)
 1193:         assert result == "complex"
 1194: 
 1195:         # test smaller complex dtype; will pass through _try_infer_map fastpath
 1196:         arr = np.array([1 + 1j, np.nan, 3 + 3j], dtype=np.complex64)
 1197:         result = lib.infer_dtype(arr, skipna=skipna)
 1198:         assert result == "complex"
 1199: 
 1200:     def test_string(self):
 1201:         pass
 1202: 
 1203:     def test_unicode(self):
 1204:         arr = ["a", np.nan, "c"]
 1205:         result = lib.infer_dtype(arr, skipna=False)
 1206:         # This currently returns "mixed", but it's not clear that's optimal.
 1207:         # This could also return "string" or "mixed-string"
 1208:         assert result == "mixed"
 1209: 
 1210:         # even though we use skipna, we are only skipping those NAs that are
 1211:         #  considered matching by is_string_array
 1212:         arr = ["a", np.nan, "c"]
 1213:         result = lib.infer_dtype(arr, skipna=True)
 1214:         assert result == "string"
 1215: 
 1216:         arr = ["a", pd.NA, "c"]
 1217:         result = lib.infer_dtype(arr, skipna=True)
 1218:         assert result == "string"
 1219: 
 1220:         arr = ["a", pd.NaT, "c"]
 1221:         result = lib.infer_dtype(arr, skipna=True)
 1222:         assert result == "mixed"
 1223: 
 1224:         arr = ["a", "c"]
 1225:         result = lib.infer_dtype(arr, skipna=False)
 1226:         assert result == "string"
 1227: 
 1228:     @pytest.mark.parametrize(
 1229:         "dtype, missing, skipna, expected",
 1230:         [
 1231:             (float, np.nan, False, "floating"),
 1232:             (float, np.nan, True, "floating"),
 1233:             (object, np.nan, False, "floating"),
 1234:             (object, np.nan, True, "empty"),
 1235:             (object, None, False, "mixed"),
 1236:             (object, None, True, "empty"),
 1237:         ],
 1238:     )
 1239:     @pytest.mark.parametrize("box", [Series, np.array])
 1240:     def test_object_empty(self, box, missing, dtype, skipna, expected):
 1241:         # GH 23421
 1242:         arr = box([missing, missing], dtype=dtype)
 1243: 
 1244:         result = lib.infer_dtype(arr, skipna=skipna)
 1245:         assert result == expected
 1246: 
 1247:     def test_datetime(self):
 1248:         dates = [datetime(2012, 1, x) for x in range(1, 20)]
 1249:         index = Index(dates)
 1250:         assert index.inferred_type == "datetime64"
 1251: 
 1252:     def test_infer_dtype_datetime64(self):
 1253:         arr = np.array(
 1254:             [np.datetime64("2011-01-01"), np.datetime64("2011-01-01")], dtype=object
 1255:         )
 1256:         assert lib.infer_dtype(arr, skipna=True) == "datetime64"
 1257: 
 1258:     @pytest.mark.parametrize("na_value", [pd.NaT, np.nan])
 1259:     def test_infer_dtype_datetime64_with_na(self, na_value):
 1260:         # starts with nan
 1261:         arr = np.array([na_value, np.datetime64("2011-01-02")])
 1262:         assert lib.infer_dtype(arr, skipna=True) == "datetime64"
 1263: 
 1264:         arr = np.array([na_value, np.datetime64("2011-01-02"), na_value])
 1265:         assert lib.infer_dtype(arr, skipna=True) == "datetime64"
 1266: 
 1267:     @pytest.mark.parametrize(
 1268:         "arr",
 1269:         [
 1270:             np.array(
 1271:                 [np.timedelta64("nat"), np.datetime64("2011-01-02")], dtype=object
 1272:             ),
 1273:             np.array(
 1274:                 [np.datetime64("2011-01-02"), np.timedelta64("nat")], dtype=object
 1275:             ),
 1276:             np.array([np.datetime64("2011-01-01"), Timestamp("2011-01-02")]),
 1277:             np.array([Timestamp("2011-01-02"), np.datetime64("2011-01-01")]),
 1278:             np.array([np.nan, Timestamp("2011-01-02"), 1.1]),
 1279:             np.array([np.nan, "2011-01-01", Timestamp("2011-01-02")], dtype=object),
 1280:             np.array([np.datetime64("nat"), np.timedelta64(1, "D")], dtype=object),
 1281:             np.array([np.timedelta64(1, "D"), np.datetime64("nat")], dtype=object),
 1282:         ],
 1283:     )
 1284:     def test_infer_datetimelike_dtype_mixed(self, arr):
 1285:         assert lib.infer_dtype(arr, skipna=False) == "mixed"
 1286: 
 1287:     def test_infer_dtype_mixed_integer(self):
 1288:         arr = np.array([np.nan, Timestamp("2011-01-02"), 1])
 1289:         assert lib.infer_dtype(arr, skipna=True) == "mixed-integer"
 1290: 
 1291:     @pytest.mark.parametrize(
 1292:         "arr",
 1293:         [
 1294:             np.array([Timestamp("2011-01-01"), Timestamp("2011-01-02")]),
 1295:             np.array([datetime(2011, 1, 1), datetime(2012, 2, 1)]),
 1296:             np.array([datetime(2011, 1, 1), Timestamp("2011-01-02")]),
 1297:         ],
 1298:     )
 1299:     def test_infer_dtype_datetime(self, arr):
 1300:         assert lib.infer_dtype(arr, skipna=True) == "datetime"
 1301: 
 1302:     @pytest.mark.parametrize("na_value", [pd.NaT, np.nan])
 1303:     @pytest.mark.parametrize(
 1304:         "time_stamp", [Timestamp("2011-01-01"), datetime(2011, 1, 1)]
 1305:     )
 1306:     def test_infer_dtype_datetime_with_na(self, na_value, time_stamp):
 1307:         # starts with nan
 1308:         arr = np.array([na_value, time_stamp])
 1309:         assert lib.infer_dtype(arr, skipna=True) == "datetime"
 1310: 
 1311:         arr = np.array([na_value, time_stamp, na_value])
 1312:         assert lib.infer_dtype(arr, skipna=True) == "datetime"
 1313: 
 1314:     @pytest.mark.parametrize(
 1315:         "arr",
 1316:         [
 1317:             np.array([Timedelta("1 days"), Timedelta("2 days")]),
 1318:             np.array([np.timedelta64(1, "D"), np.timedelta64(2, "D")], dtype=object),
 1319:             np.array([timedelta(1), timedelta(2)]),
 1320:         ],
 1321:     )
 1322:     def test_infer_dtype_timedelta(self, arr):
 1323:         assert lib.infer_dtype(arr, skipna=True) == "timedelta"
 1324: 
 1325:     @pytest.mark.parametrize("na_value", [pd.NaT, np.nan])
 1326:     @pytest.mark.parametrize(
 1327:         "delta", [Timedelta("1 days"), np.timedelta64(1, "D"), timedelta(1)]
 1328:     )
 1329:     def test_infer_dtype_timedelta_with_na(self, na_value, delta):
 1330:         # starts with nan
 1331:         arr = np.array([na_value, delta])
 1332:         assert lib.infer_dtype(arr, skipna=True) == "timedelta"
 1333: 
 1334:         arr = np.array([na_value, delta, na_value])
 1335:         assert lib.infer_dtype(arr, skipna=True) == "timedelta"
 1336: 
 1337:     def test_infer_dtype_period(self):
 1338:         # GH 13664
 1339:         arr = np.array([Period("2011-01", freq="D"), Period("2011-02", freq="D")])
 1340:         assert lib.infer_dtype(arr, skipna=True) == "period"
 1341: 
 1342:         # non-homogeneous freqs -> mixed
 1343:         arr = np.array([Period("2011-01", freq="D"), Period("2011-02", freq="M")])
 1344:         assert lib.infer_dtype(arr, skipna=True) == "mixed"
 1345: 
 1346:     @pytest.mark.parametrize("klass", [pd.array, Series, Index])
 1347:     @pytest.mark.parametrize("skipna", [True, False])
 1348:     def test_infer_dtype_period_array(self, klass, skipna):
 1349:         # https://github.com/pandas-dev/pandas/issues/23553
 1350:         values = klass(
 1351:             [
 1352:                 Period("2011-01-01", freq="D"),
 1353:                 Period("2011-01-02", freq="D"),
 1354:                 pd.NaT,
 1355:             ]
 1356:         )
 1357:         assert lib.infer_dtype(values, skipna=skipna) == "period"
 1358: 
 1359:         # periods but mixed freq
 1360:         values = klass(
 1361:             [
 1362:                 Period("2011-01-01", freq="D"),
 1363:                 Period("2011-01-02", freq="M"),
 1364:                 pd.NaT,
 1365:             ]
 1366:         )
 1367:         # with pd.array this becomes NumpyExtensionArray which ends up
 1368:         #  as "unknown-array"
 1369:         exp = "unknown-array" if klass is pd.array else "mixed"
 1370:         assert lib.infer_dtype(values, skipna=skipna) == exp
 1371: 
 1372:     def test_infer_dtype_period_mixed(self):
 1373:         arr = np.array(
 1374:             [Period("2011-01", freq="M"), np.datetime64("nat")], dtype=object
 1375:         )
 1376:         assert lib.infer_dtype(arr, skipna=False) == "mixed"
 1377: 
 1378:         arr = np.array(
 1379:             [np.datetime64("nat"), Period("2011-01", freq="M")], dtype=object
 1380:         )
 1381:         assert lib.infer_dtype(arr, skipna=False) == "mixed"
 1382: 
 1383:     @pytest.mark.parametrize("na_value", [pd.NaT, np.nan])
 1384:     def test_infer_dtype_period_with_na(self, na_value):
 1385:         # starts with nan
 1386:         arr = np.array([na_value, Period("2011-01", freq="D")])
 1387:         assert lib.infer_dtype(arr, skipna=True) == "period"
 1388: 
 1389:         arr = np.array([na_value, Period("2011-01", freq="D"), na_value])
 1390:         assert lib.infer_dtype(arr, skipna=True) == "period"
 1391: 
 1392:     def test_infer_dtype_all_nan_nat_like(self):
 1393:         arr = np.array([np.nan, np.nan])
 1394:         assert lib.infer_dtype(arr, skipna=True) == "floating"
 1395: 
 1396:         # nan and None mix are result in mixed
 1397:         arr = np.array([np.nan, np.nan, None])
 1398:         assert lib.infer_dtype(arr, skipna=True) == "empty"
 1399:         assert lib.infer_dtype(arr, skipna=False) == "mixed"
 1400: 
 1401:         arr = np.array([None, np.nan, np.nan])
 1402:         assert lib.infer_dtype(arr, skipna=True) == "empty"
 1403:         assert lib.infer_dtype(arr, skipna=False) == "mixed"
 1404: 
 1405:         # pd.NaT
 1406:         arr = np.array([pd.NaT])
 1407:         assert lib.infer_dtype(arr, skipna=False) == "datetime"
 1408: 
 1409:         arr = np.array([pd.NaT, np.nan])
 1410:         assert lib.infer_dtype(arr, skipna=False) == "datetime"
 1411: 
 1412:         arr = np.array([np.nan, pd.NaT])
 1413:         assert lib.infer_dtype(arr, skipna=False) == "datetime"
 1414: 
 1415:         arr = np.array([np.nan, pd.NaT, np.nan])
 1416:         assert lib.infer_dtype(arr, skipna=False) == "datetime"
 1417: 
 1418:         arr = np.array([None, pd.NaT, None])
 1419:         assert lib.infer_dtype(arr, skipna=False) == "datetime"
 1420: 
 1421:         # np.datetime64(nat)
 1422:         arr = np.array([np.datetime64("nat")])
 1423:         assert lib.infer_dtype(arr, skipna=False) == "datetime64"
 1424: 
 1425:         for n in [np.nan, pd.NaT, None]:
 1426:             arr = np.array([n, np.datetime64("nat"), n])
 1427:             assert lib.infer_dtype(arr, skipna=False) == "datetime64"
 1428: 
 1429:             arr = np.array([pd.NaT, n, np.datetime64("nat"), n])
 1430:             assert lib.infer_dtype(arr, skipna=False) == "datetime64"
 1431: 
 1432:         arr = np.array([np.timedelta64("nat")], dtype=object)
 1433:         assert lib.infer_dtype(arr, skipna=False) == "timedelta"
 1434: 
 1435:         for n in [np.nan, pd.NaT, None]:
 1436:             arr = np.array([n, np.timedelta64("nat"), n])
 1437:             assert lib.infer_dtype(arr, skipna=False) == "timedelta"
 1438: 
 1439:             arr = np.array([pd.NaT, n, np.timedelta64("nat"), n])
 1440:             assert lib.infer_dtype(arr, skipna=False) == "timedelta"
 1441: 
 1442:         # datetime / timedelta mixed
 1443:         arr = np.array([pd.NaT, np.datetime64("nat"), np.timedelta64("nat"), np.nan])
 1444:         assert lib.infer_dtype(arr, skipna=False) == "mixed"
 1445: 
 1446:         arr = np.array([np.timedelta64("nat"), np.datetime64("nat")], dtype=object)
 1447:         assert lib.infer_dtype(arr, skipna=False) == "mixed"
 1448: 
 1449:     def test_is_datetimelike_array_all_nan_nat_like(self):
 1450:         arr = np.array([np.nan, pd.NaT, np.datetime64("nat")])
 1451:         assert lib.is_datetime_array(arr)
 1452:         assert lib.is_datetime64_array(arr)
 1453:         assert not lib.is_timedelta_or_timedelta64_array(arr)
 1454: 
 1455:         arr = np.array([np.nan, pd.NaT, np.timedelta64("nat")])
 1456:         assert not lib.is_datetime_array(arr)
 1457:         assert not lib.is_datetime64_array(arr)
 1458:         assert lib.is_timedelta_or_timedelta64_array(arr)
 1459: 
 1460:         arr = np.array([np.nan, pd.NaT, np.datetime64("nat"), np.timedelta64("nat")])
 1461:         assert not lib.is_datetime_array(arr)
 1462:         assert not lib.is_datetime64_array(arr)
 1463:         assert not lib.is_timedelta_or_timedelta64_array(arr)
 1464: 
 1465:         arr = np.array([np.nan, pd.NaT])
 1466:         assert lib.is_datetime_array(arr)
 1467:         assert lib.is_datetime64_array(arr)
 1468:         assert lib.is_timedelta_or_timedelta64_array(arr)
 1469: 
 1470:         arr = np.array([np.nan, np.nan], dtype=object)
 1471:         assert not lib.is_datetime_array(arr)
 1472:         assert not lib.is_datetime64_array(arr)
 1473:         assert not lib.is_timedelta_or_timedelta64_array(arr)
 1474: 
 1475:         assert lib.is_datetime_with_singletz_array(
 1476:             np.array(
 1477:                 [
 1478:                     Timestamp("20130101", tz="US/Eastern"),
 1479:                     Timestamp("20130102", tz="US/Eastern"),
 1480:                 ],
 1481:                 dtype=object,
 1482:             )
 1483:         )
 1484:         assert not lib.is_datetime_with_singletz_array(
 1485:             np.array(
 1486:                 [
 1487:                     Timestamp("20130101", tz="US/Eastern"),
 1488:                     Timestamp("20130102", tz="CET"),
 1489:                 ],
 1490:                 dtype=object,
 1491:             )
 1492:         )
 1493: 
 1494:     @pytest.mark.parametrize(
 1495:         "func",
 1496:         [
 1497:             "is_datetime_array",
 1498:             "is_datetime64_array",
 1499:             "is_bool_array",
 1500:             "is_timedelta_or_timedelta64_array",
 1501:             "is_date_array",
 1502:             "is_time_array",
 1503:             "is_interval_array",
 1504:         ],
 1505:     )
 1506:     def test_other_dtypes_for_array(self, func):
 1507:         func = getattr(lib, func)
 1508:         arr = np.array(["foo", "bar"])
 1509:         assert not func(arr)
 1510:         assert not func(arr.reshape(2, 1))
 1511: 
 1512:         arr = np.array([1, 2])
 1513:         assert not func(arr)
 1514:         assert not func(arr.reshape(2, 1))
 1515: 
 1516:     def test_date(self):
 1517:         dates = [date(2012, 1, day) for day in range(1, 20)]
 1518:         index = Index(dates)
 1519:         assert index.inferred_type == "date"
 1520: 
 1521:         dates = [date(2012, 1, day) for day in range(1, 20)] + [np.nan]
 1522:         result = lib.infer_dtype(dates, skipna=False)
 1523:         assert result == "mixed"
 1524: 
 1525:         result = lib.infer_dtype(dates, skipna=True)
 1526:         assert result == "date"
 1527: 
 1528:     @pytest.mark.parametrize(
 1529:         "values",
 1530:         [
 1531:             [date(2020, 1, 1), Timestamp("2020-01-01")],
 1532:             [Timestamp("2020-01-01"), date(2020, 1, 1)],
 1533:             [date(2020, 1, 1), pd.NaT],
 1534:             [pd.NaT, date(2020, 1, 1)],
 1535:         ],
 1536:     )
 1537:     @pytest.mark.parametrize("skipna", [True, False])
 1538:     def test_infer_dtype_date_order_invariant(self, values, skipna):
 1539:         # https://github.com/pandas-dev/pandas/issues/33741
 1540:         result = lib.infer_dtype(values, skipna=skipna)
 1541:         assert result == "date"
 1542: 
 1543:     def test_is_numeric_array(self):
 1544:         assert lib.is_float_array(np.array([1, 2.0]))
 1545:         assert lib.is_float_array(np.array([1, 2.0, np.nan]))
 1546:         assert not lib.is_float_array(np.array([1, 2]))
 1547: 
 1548:         assert lib.is_integer_array(np.array([1, 2]))
 1549:         assert not lib.is_integer_array(np.array([1, 2.0]))
 1550: 
 1551:     def test_is_string_array(self):
 1552:         # We should only be accepting pd.NA, np.nan,
 1553:         # other floating point nans e.g. float('nan')]
 1554:         # when skipna is True.
 1555:         assert lib.is_string_array(np.array(["foo", "bar"]))
 1556:         assert not lib.is_string_array(
 1557:             np.array(["foo", "bar", pd.NA], dtype=object), skipna=False
 1558:         )
 1559:         assert lib.is_string_array(
 1560:             np.array(["foo", "bar", pd.NA], dtype=object), skipna=True
 1561:         )
 1562:         # we allow NaN/None in the StringArray constructor, so its allowed here
 1563:         assert lib.is_string_array(
 1564:             np.array(["foo", "bar", None], dtype=object), skipna=True
 1565:         )
 1566:         assert lib.is_string_array(
 1567:             np.array(["foo", "bar", np.nan], dtype=object), skipna=True
 1568:         )
 1569:         # But not e.g. datetimelike or Decimal NAs
 1570:         assert not lib.is_string_array(
 1571:             np.array(["foo", "bar", pd.NaT], dtype=object), skipna=True
 1572:         )
 1573:         assert not lib.is_string_array(
 1574:             np.array(["foo", "bar", np.datetime64("NaT")], dtype=object), skipna=True
 1575:         )
 1576:         assert not lib.is_string_array(
 1577:             np.array(["foo", "bar", Decimal("NaN")], dtype=object), skipna=True
 1578:         )
 1579: 
 1580:         assert not lib.is_string_array(
 1581:             np.array(["foo", "bar", None], dtype=object), skipna=False
 1582:         )
 1583:         assert not lib.is_string_array(
 1584:             np.array(["foo", "bar", np.nan], dtype=object), skipna=False
 1585:         )
 1586:         assert not lib.is_string_array(np.array([1, 2]))
 1587: 
 1588:     def test_to_object_array_tuples(self):
 1589:         r = (5, 6)
 1590:         values = [r]
 1591:         lib.to_object_array_tuples(values)
 1592: 
 1593:         # make sure record array works
 1594:         record = namedtuple("record", "x y")
 1595:         r = record(5, 6)
 1596:         values = [r]
 1597:         lib.to_object_array_tuples(values)
 1598: 
 1599:     def test_object(self):
 1600:         # GH 7431
 1601:         # cannot infer more than this as only a single element
 1602:         arr = np.array([None], dtype="O")
 1603:         result = lib.infer_dtype(arr, skipna=False)
 1604:         assert result == "mixed"
 1605:         result = lib.infer_dtype(arr, skipna=True)
 1606:         assert result == "empty"
 1607: 
 1608:     def test_to_object_array_width(self):
 1609:         # see gh-13320
 1610:         rows = [[1, 2, 3], [4, 5, 6]]
 1611: 
 1612:         expected = np.array(rows, dtype=object)
 1613:         out = lib.to_object_array(rows)
 1614:         tm.assert_numpy_array_equal(out, expected)
 1615: 
 1616:         expected = np.array(rows, dtype=object)
 1617:         out = lib.to_object_array(rows, min_width=1)
 1618:         tm.assert_numpy_array_equal(out, expected)
 1619: 
 1620:         expected = np.array(
 1621:             [[1, 2, 3, None, None], [4, 5, 6, None, None]], dtype=object
 1622:         )
 1623:         out = lib.to_object_array(rows, min_width=5)
 1624:         tm.assert_numpy_array_equal(out, expected)
 1625: 
 1626:     def test_is_period(self):
 1627:         # GH#55264
 1628:         msg = "is_period is deprecated and will be removed in a future version"
 1629:         with tm.assert_produces_warning(FutureWarning, match=msg):
 1630:             assert lib.is_period(Period("2011-01", freq="M"))
 1631:             assert not lib.is_period(PeriodIndex(["2011-01"], freq="M"))
 1632:             assert not lib.is_period(Timestamp("2011-01"))
 1633:             assert not lib.is_period(1)
 1634:             assert not lib.is_period(np.nan)
 1635: 
 1636:     def test_is_interval(self):
 1637:         # GH#55264
 1638:         msg = "is_interval is deprecated and will be removed in a future version"
 1639:         item = Interval(1, 2)
 1640:         with tm.assert_produces_warning(FutureWarning, match=msg):
 1641:             assert lib.is_interval(item)
 1642:             assert not lib.is_interval(pd.IntervalIndex([item]))
 1643:             assert not lib.is_interval(pd.IntervalIndex([item])._engine)
 1644: 
 1645:     def test_categorical(self):
 1646:         # GH 8974
 1647:         arr = Categorical(list("abc"))
 1648:         result = lib.infer_dtype(arr, skipna=True)
 1649:         assert result == "categorical"
 1650: 
 1651:         result = lib.infer_dtype(Series(arr), skipna=True)
 1652:         assert result == "categorical"
 1653: 
 1654:         arr = Categorical(list("abc"), categories=["cegfab"], ordered=True)
 1655:         result = lib.infer_dtype(arr, skipna=True)
 1656:         assert result == "categorical"
 1657: 
 1658:         result = lib.infer_dtype(Series(arr), skipna=True)
 1659:         assert result == "categorical"
 1660: 
 1661:     @pytest.mark.parametrize("asobject", [True, False])
 1662:     def test_interval(self, asobject):
 1663:         idx = pd.IntervalIndex.from_breaks(range(5), closed="both")
 1664:         if asobject:
 1665:             idx = idx.astype(object)
 1666: 
 1667:         inferred = lib.infer_dtype(idx, skipna=False)
 1668:         assert inferred == "interval"
 1669: 
 1670:         inferred = lib.infer_dtype(idx._data, skipna=False)
 1671:         assert inferred == "interval"
 1672: 
 1673:         inferred = lib.infer_dtype(Series(idx, dtype=idx.dtype), skipna=False)
 1674:         assert inferred == "interval"
 1675: 
 1676:     @pytest.mark.parametrize("value", [Timestamp(0), Timedelta(0), 0, 0.0])
 1677:     def test_interval_mismatched_closed(self, value):
 1678:         first = Interval(value, value, closed="left")
 1679:         second = Interval(value, value, closed="right")
 1680: 
 1681:         # if closed match, we should infer "interval"
 1682:         arr = np.array([first, first], dtype=object)
 1683:         assert lib.infer_dtype(arr, skipna=False) == "interval"
 1684: 
 1685:         # if closed dont match, we should _not_ get "interval"
 1686:         arr2 = np.array([first, second], dtype=object)
 1687:         assert lib.infer_dtype(arr2, skipna=False) == "mixed"
 1688: 
 1689:     def test_interval_mismatched_subtype(self):
 1690:         first = Interval(0, 1, closed="left")
 1691:         second = Interval(Timestamp(0), Timestamp(1), closed="left")
 1692:         third = Interval(Timedelta(0), Timedelta(1), closed="left")
 1693: 
 1694:         arr = np.array([first, second])
 1695:         assert lib.infer_dtype(arr, skipna=False) == "mixed"
 1696: 
 1697:         arr = np.array([second, third])
 1698:         assert lib.infer_dtype(arr, skipna=False) == "mixed"
 1699: 
 1700:         arr = np.array([first, third])
 1701:         assert lib.infer_dtype(arr, skipna=False) == "mixed"
 1702: 
 1703:         # float vs int subdtype are compatible
 1704:         flt_interval = Interval(1.5, 2.5, closed="left")
 1705:         arr = np.array([first, flt_interval], dtype=object)
 1706:         assert lib.infer_dtype(arr, skipna=False) == "interval"
 1707: 
 1708:     @pytest.mark.parametrize("klass", [pd.array, Series])
 1709:     @pytest.mark.parametrize("skipna", [True, False])
 1710:     @pytest.mark.parametrize("data", [["a", "b", "c"], ["a", "b", pd.NA]])
 1711:     def test_string_dtype(self, data, skipna, klass, nullable_string_dtype):
 1712:         # StringArray
 1713:         val = klass(data, dtype=nullable_string_dtype)
 1714:         inferred = lib.infer_dtype(val, skipna=skipna)
 1715:         assert inferred == "string"
 1716: 
 1717:     @pytest.mark.parametrize("klass", [pd.array, Series])
 1718:     @pytest.mark.parametrize("skipna", [True, False])
 1719:     @pytest.mark.parametrize("data", [[True, False, True], [True, False, pd.NA]])
 1720:     def test_boolean_dtype(self, data, skipna, klass):
 1721:         # BooleanArray
 1722:         val = klass(data, dtype="boolean")
 1723:         inferred = lib.infer_dtype(val, skipna=skipna)
 1724:         assert inferred == "boolean"
 1725: 
 1726: 
 1727: class TestNumberScalar:
 1728:     def test_is_number(self):
 1729:         assert is_number(True)
 1730:         assert is_number(1)
 1731:         assert is_number(1.1)
 1732:         assert is_number(1 + 3j)
 1733:         assert is_number(np.int64(1))
 1734:         assert is_number(np.float64(1.1))
 1735:         assert is_number(np.complex128(1 + 3j))
 1736:         assert is_number(np.nan)
 1737: 
 1738:         assert not is_number(None)
 1739:         assert not is_number("x")
 1740:         assert not is_number(datetime(2011, 1, 1))
 1741:         assert not is_number(np.datetime64("2011-01-01"))
 1742:         assert not is_number(Timestamp("2011-01-01"))
 1743:         assert not is_number(Timestamp("2011-01-01", tz="US/Eastern"))
 1744:         assert not is_number(timedelta(1000))
 1745:         assert not is_number(Timedelta("1 days"))
 1746: 
 1747:         # questionable
 1748:         assert not is_number(np.bool_(False))
 1749:         assert is_number(np.timedelta64(1, "D"))
 1750: 
 1751:     def test_is_bool(self):
 1752:         assert is_bool(True)
 1753:         assert is_bool(False)
 1754:         assert is_bool(np.bool_(False))
 1755: 
 1756:         assert not is_bool(1)
 1757:         assert not is_bool(1.1)
 1758:         assert not is_bool(1 + 3j)
 1759:         assert not is_bool(np.int64(1))
 1760:         assert not is_bool(np.float64(1.1))
 1761:         assert not is_bool(np.complex128(1 + 3j))
 1762:         assert not is_bool(np.nan)
 1763:         assert not is_bool(None)
 1764:         assert not is_bool("x")
 1765:         assert not is_bool(datetime(2011, 1, 1))
 1766:         assert not is_bool(np.datetime64("2011-01-01"))
 1767:         assert not is_bool(Timestamp("2011-01-01"))
 1768:         assert not is_bool(Timestamp("2011-01-01", tz="US/Eastern"))
 1769:         assert not is_bool(timedelta(1000))
 1770:         assert not is_bool(np.timedelta64(1, "D"))
 1771:         assert not is_bool(Timedelta("1 days"))
 1772: 
 1773:     def test_is_integer(self):
 1774:         assert is_integer(1)
 1775:         assert is_integer(np.int64(1))
 1776: 
 1777:         assert not is_integer(True)
 1778:         assert not is_integer(1.1)
 1779:         assert not is_integer(1 + 3j)
 1780:         assert not is_integer(False)
 1781:         assert not is_integer(np.bool_(False))
 1782:         assert not is_integer(np.float64(1.1))
 1783:         assert not is_integer(np.complex128(1 + 3j))
 1784:         assert not is_integer(np.nan)
 1785:         assert not is_integer(None)
 1786:         assert not is_integer("x")
 1787:         assert not is_integer(datetime(2011, 1, 1))
 1788:         assert not is_integer(np.datetime64("2011-01-01"))
 1789:         assert not is_integer(Timestamp("2011-01-01"))
 1790:         assert not is_integer(Timestamp("2011-01-01", tz="US/Eastern"))
 1791:         assert not is_integer(timedelta(1000))
 1792:         assert not is_integer(Timedelta("1 days"))
 1793:         assert not is_integer(np.timedelta64(1, "D"))
 1794: 
 1795:     def test_is_float(self):
 1796:         assert is_float(1.1)
 1797:         assert is_float(np.float64(1.1))
 1798:         assert is_float(np.nan)
 1799: 
 1800:         assert not is_float(True)
 1801:         assert not is_float(1)
 1802:         assert not is_float(1 + 3j)
 1803:         assert not is_float(False)
 1804:         assert not is_float(np.bool_(False))
 1805:         assert not is_float(np.int64(1))
 1806:         assert not is_float(np.complex128(1 + 3j))
 1807:         assert not is_float(None)
 1808:         assert not is_float("x")
 1809:         assert not is_float(datetime(2011, 1, 1))
 1810:         assert not is_float(np.datetime64("2011-01-01"))
 1811:         assert not is_float(Timestamp("2011-01-01"))
 1812:         assert not is_float(Timestamp("2011-01-01", tz="US/Eastern"))
 1813:         assert not is_float(timedelta(1000))
 1814:         assert not is_float(np.timedelta64(1, "D"))
 1815:         assert not is_float(Timedelta("1 days"))
 1816: 
 1817:     def test_is_datetime_dtypes(self):
 1818:         ts = pd.date_range("20130101", periods=3)
 1819:         tsa = pd.date_range("20130101", periods=3, tz="US/Eastern")
 1820: 
 1821:         msg = "is_datetime64tz_dtype is deprecated"
 1822: 
 1823:         assert is_datetime64_dtype("datetime64")
 1824:         assert is_datetime64_dtype("datetime64[ns]")
 1825:         assert is_datetime64_dtype(ts)
 1826:         assert not is_datetime64_dtype(tsa)
 1827: 
 1828:         assert not is_datetime64_ns_dtype("datetime64")
 1829:         assert is_datetime64_ns_dtype("datetime64[ns]")
 1830:         assert is_datetime64_ns_dtype(ts)
 1831:         assert is_datetime64_ns_dtype(tsa)
 1832: 
 1833:         assert is_datetime64_any_dtype("datetime64")
 1834:         assert is_datetime64_any_dtype("datetime64[ns]")
 1835:         assert is_datetime64_any_dtype(ts)
 1836:         assert is_datetime64_any_dtype(tsa)
 1837: 
 1838:         with tm.assert_produces_warning(DeprecationWarning, match=msg):
 1839:             assert not is_datetime64tz_dtype("datetime64")
 1840:             assert not is_datetime64tz_dtype("datetime64[ns]")
 1841:             assert not is_datetime64tz_dtype(ts)
 1842:             assert is_datetime64tz_dtype(tsa)
 1843: 
 1844:     @pytest.mark.parametrize("tz", ["US/Eastern", "UTC"])
 1845:     def test_is_datetime_dtypes_with_tz(self, tz):
 1846:         dtype = f"datetime64[ns, {tz}]"
 1847:         assert not is_datetime64_dtype(dtype)
 1848: 
 1849:         msg = "is_datetime64tz_dtype is deprecated"
 1850:         with tm.assert_produces_warning(DeprecationWarning, match=msg):
 1851:             assert is_datetime64tz_dtype(dtype)
 1852:         assert is_datetime64_ns_dtype(dtype)
 1853:         assert is_datetime64_any_dtype(dtype)
 1854: 
 1855:     def test_is_timedelta(self):
 1856:         assert is_timedelta64_dtype("timedelta64")
 1857:         assert is_timedelta64_dtype("timedelta64[ns]")
 1858:         assert not is_timedelta64_ns_dtype("timedelta64")
 1859:         assert is_timedelta64_ns_dtype("timedelta64[ns]")
 1860: 
 1861:         tdi = TimedeltaIndex([1e14, 2e14], dtype="timedelta64[ns]")
 1862:         assert is_timedelta64_dtype(tdi)
 1863:         assert is_timedelta64_ns_dtype(tdi)
 1864:         assert is_timedelta64_ns_dtype(tdi.astype("timedelta64[ns]"))
 1865: 
 1866:         assert not is_timedelta64_ns_dtype(Index([], dtype=np.float64))
 1867:         assert not is_timedelta64_ns_dtype(Index([], dtype=np.int64))
 1868: 
 1869: 
 1870: class TestIsScalar:
 1871:     def test_is_scalar_builtin_scalars(self):
 1872:         assert is_scalar(None)
 1873:         assert is_scalar(True)
 1874:         assert is_scalar(False)
 1875:         assert is_scalar(Fraction())
 1876:         assert is_scalar(0.0)
 1877:         assert is_scalar(1)
 1878:         assert is_scalar(complex(2))
 1879:         assert is_scalar(float("NaN"))
 1880:         assert is_scalar(np.nan)
 1881:         assert is_scalar("foobar")
 1882:         assert is_scalar(b"foobar")
 1883:         assert is_scalar(datetime(2014, 1, 1))
 1884:         assert is_scalar(date(2014, 1, 1))
 1885:         assert is_scalar(time(12, 0))
 1886:         assert is_scalar(timedelta(hours=1))
 1887:         assert is_scalar(pd.NaT)
 1888:         assert is_scalar(pd.NA)
 1889: 
 1890:     def test_is_scalar_builtin_nonscalars(self):
 1891:         assert not is_scalar({})
 1892:         assert not is_scalar([])
 1893:         assert not is_scalar([1])
 1894:         assert not is_scalar(())
 1895:         assert not is_scalar((1,))
 1896:         assert not is_scalar(slice(None))
 1897:         assert not is_scalar(Ellipsis)
 1898: 
 1899:     def test_is_scalar_numpy_array_scalars(self):
 1900:         assert is_scalar(np.int64(1))
 1901:         assert is_scalar(np.float64(1.0))
 1902:         assert is_scalar(np.int32(1))
 1903:         assert is_scalar(np.complex64(2))
 1904:         assert is_scalar(np.object_("foobar"))
 1905:         assert is_scalar(np.str_("foobar"))
 1906:         assert is_scalar(np.bytes_(b"foobar"))
 1907:         assert is_scalar(np.datetime64("2014-01-01"))
 1908:         assert is_scalar(np.timedelta64(1, "h"))
 1909: 
 1910:     @pytest.mark.parametrize(
 1911:         "zerodim",
 1912:         [
 1913:             np.array(1),
 1914:             np.array("foobar"),
 1915:             np.array(np.datetime64("2014-01-01")),
 1916:             np.array(np.timedelta64(1, "h")),
 1917:             np.array(np.datetime64("NaT")),
 1918:         ],
 1919:     )
 1920:     def test_is_scalar_numpy_zerodim_arrays(self, zerodim):
 1921:         assert not is_scalar(zerodim)
 1922:         assert is_scalar(lib.item_from_zerodim(zerodim))
 1923: 
 1924:     @pytest.mark.parametrize("arr", [np.array([]), np.array([[]])])
 1925:     def test_is_scalar_numpy_arrays(self, arr):
 1926:         assert not is_scalar(arr)
 1927:         assert not is_scalar(MockNumpyLikeArray(arr))
 1928: 
 1929:     def test_is_scalar_pandas_scalars(self):
 1930:         assert is_scalar(Timestamp("2014-01-01"))
 1931:         assert is_scalar(Timedelta(hours=1))
 1932:         assert is_scalar(Period("2014-01-01"))
 1933:         assert is_scalar(Interval(left=0, right=1))
 1934:         assert is_scalar(DateOffset(days=1))
 1935:         assert is_scalar(pd.offsets.Minute(3))
 1936: 
 1937:     def test_is_scalar_pandas_containers(self):
 1938:         assert not is_scalar(Series(dtype=object))
 1939:         assert not is_scalar(Series([1]))
 1940:         assert not is_scalar(DataFrame())
 1941:         assert not is_scalar(DataFrame([[1]]))
 1942:         assert not is_scalar(Index([]))
 1943:         assert not is_scalar(Index([1]))
 1944:         assert not is_scalar(Categorical([]))
 1945:         assert not is_scalar(DatetimeIndex([])._data)
 1946:         assert not is_scalar(TimedeltaIndex([])._data)
 1947:         assert not is_scalar(DatetimeIndex([])._data.to_period("D"))
 1948:         assert not is_scalar(pd.array([1, 2, 3]))
 1949: 
 1950:     def test_is_scalar_number(self):
 1951:         # Number() is not recognied by PyNumber_Check, so by extension
 1952:         #  is not recognized by is_scalar, but instances of non-abstract
 1953:         #  subclasses are.
 1954: 
 1955:         class Numeric(Number):
 1956:             def __init__(self, value) -> None:
 1957:                 self.value = value
 1958: 
 1959:             def __int__(self) -> int:
 1960:                 return self.value
 1961: 
 1962:         num = Numeric(1)
 1963:         assert is_scalar(num)
 1964: 
 1965: 
 1966: @pytest.mark.parametrize("unit", ["ms", "us", "ns"])
 1967: def test_datetimeindex_from_empty_datetime64_array(unit):
 1968:     idx = DatetimeIndex(np.array([], dtype=f"datetime64[{unit}]"))
 1969:     assert len(idx) == 0
 1970: 
 1971: 
 1972: def test_nan_to_nat_conversions():
 1973:     df = DataFrame(
 1974:         {"A": np.asarray(range(10), dtype="float64"), "B": Timestamp("20010101")}
 1975:     )
 1976:     df.iloc[3:6, :] = np.nan
 1977:     result = df.loc[4, "B"]
 1978:     assert result is pd.NaT
 1979: 
 1980:     s = df["B"].copy()
 1981:     s[8:9] = np.nan
 1982:     assert s[8] is pd.NaT
 1983: 
 1984: 
 1985: @pytest.mark.filterwarnings("ignore::PendingDeprecationWarning")
 1986: def test_is_scipy_sparse(spmatrix):
 1987:     pytest.importorskip("scipy")
 1988:     assert is_scipy_sparse(spmatrix([[0, 1]]))
 1989:     assert not is_scipy_sparse(np.array([1]))
 1990: 
 1991: 
 1992: def test_ensure_int32():
 1993:     values = np.arange(10, dtype=np.int32)
 1994:     result = ensure_int32(values)
 1995:     assert result.dtype == np.int32
 1996: 
 1997:     values = np.arange(10, dtype=np.int64)
 1998:     result = ensure_int32(values)
 1999:     assert result.dtype == np.int32
 2000: 
 2001: 
 2002: @pytest.mark.parametrize(
 2003:     "right,result",
 2004:     [
 2005:         (0, np.uint8),
 2006:         (-1, np.int16),
 2007:         (300, np.uint16),
 2008:         # For floats, we just upcast directly to float64 instead of trying to
 2009:         # find a smaller floating dtype
 2010:         (300.0, np.uint16),  # for integer floats, we convert them to ints
 2011:         (300.1, np.float64),
 2012:         (np.int16(300), np.int16 if np_version_gt2 else np.uint16),
 2013:     ],
 2014: )
 2015: def test_find_result_type_uint_int(right, result):
 2016:     left_dtype = np.dtype("uint8")
 2017:     assert find_result_type(left_dtype, right) == result
 2018: 
 2019: 
 2020: @pytest.mark.parametrize(
 2021:     "right,result",
 2022:     [
 2023:         (0, np.int8),
 2024:         (-1, np.int8),
 2025:         (300, np.int16),
 2026:         # For floats, we just upcast directly to float64 instead of trying to
 2027:         # find a smaller floating dtype
 2028:         (300.0, np.int16),  # for integer floats, we convert them to ints
 2029:         (300.1, np.float64),
 2030:         (np.int16(300), np.int16),
 2031:     ],
 2032: )
 2033: def test_find_result_type_int_int(right, result):
 2034:     left_dtype = np.dtype("int8")
 2035:     assert find_result_type(left_dtype, right) == result
 2036: 
 2037: 
 2038: @pytest.mark.parametrize(
 2039:     "right,result",
 2040:     [
 2041:         (300.0, np.float64),
 2042:         (np.float32(300), np.float32),
 2043:     ],
 2044: )
 2045: def test_find_result_type_floats(right, result):
 2046:     left_dtype = np.dtype("float16")
 2047:     assert find_result_type(left_dtype, right) == result
