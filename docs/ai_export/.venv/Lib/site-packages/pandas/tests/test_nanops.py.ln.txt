    1: from functools import partial
    2: 
    3: import numpy as np
    4: import pytest
    5: 
    6: import pandas.util._test_decorators as td
    7: 
    8: from pandas.core.dtypes.common import is_integer_dtype
    9: 
   10: import pandas as pd
   11: from pandas import (
   12:     Series,
   13:     isna,
   14: )
   15: import pandas._testing as tm
   16: from pandas.core import nanops
   17: 
   18: use_bn = nanops._USE_BOTTLENECK
   19: 
   20: 
   21: @pytest.fixture
   22: def disable_bottleneck(monkeypatch):
   23:     with monkeypatch.context() as m:
   24:         m.setattr(nanops, "_USE_BOTTLENECK", False)
   25:         yield
   26: 
   27: 
   28: @pytest.fixture
   29: def arr_shape():
   30:     return 11, 7
   31: 
   32: 
   33: @pytest.fixture
   34: def arr_float(arr_shape):
   35:     return np.random.default_rng(2).standard_normal(arr_shape)
   36: 
   37: 
   38: @pytest.fixture
   39: def arr_complex(arr_float):
   40:     return arr_float + arr_float * 1j
   41: 
   42: 
   43: @pytest.fixture
   44: def arr_int(arr_shape):
   45:     return np.random.default_rng(2).integers(-10, 10, arr_shape)
   46: 
   47: 
   48: @pytest.fixture
   49: def arr_bool(arr_shape):
   50:     return np.random.default_rng(2).integers(0, 2, arr_shape) == 0
   51: 
   52: 
   53: @pytest.fixture
   54: def arr_str(arr_float):
   55:     return np.abs(arr_float).astype("S")
   56: 
   57: 
   58: @pytest.fixture
   59: def arr_utf(arr_float):
   60:     return np.abs(arr_float).astype("U")
   61: 
   62: 
   63: @pytest.fixture
   64: def arr_date(arr_shape):
   65:     return np.random.default_rng(2).integers(0, 20000, arr_shape).astype("M8[ns]")
   66: 
   67: 
   68: @pytest.fixture
   69: def arr_tdelta(arr_shape):
   70:     return np.random.default_rng(2).integers(0, 20000, arr_shape).astype("m8[ns]")
   71: 
   72: 
   73: @pytest.fixture
   74: def arr_nan(arr_shape):
   75:     return np.tile(np.nan, arr_shape)
   76: 
   77: 
   78: @pytest.fixture
   79: def arr_float_nan(arr_float, arr_nan):
   80:     return np.vstack([arr_float, arr_nan])
   81: 
   82: 
   83: @pytest.fixture
   84: def arr_nan_float1(arr_nan, arr_float):
   85:     return np.vstack([arr_nan, arr_float])
   86: 
   87: 
   88: @pytest.fixture
   89: def arr_nan_nan(arr_nan):
   90:     return np.vstack([arr_nan, arr_nan])
   91: 
   92: 
   93: @pytest.fixture
   94: def arr_inf(arr_float):
   95:     return arr_float * np.inf
   96: 
   97: 
   98: @pytest.fixture
   99: def arr_float_inf(arr_float, arr_inf):
  100:     return np.vstack([arr_float, arr_inf])
  101: 
  102: 
  103: @pytest.fixture
  104: def arr_nan_inf(arr_nan, arr_inf):
  105:     return np.vstack([arr_nan, arr_inf])
  106: 
  107: 
  108: @pytest.fixture
  109: def arr_float_nan_inf(arr_float, arr_nan, arr_inf):
  110:     return np.vstack([arr_float, arr_nan, arr_inf])
  111: 
  112: 
  113: @pytest.fixture
  114: def arr_nan_nan_inf(arr_nan, arr_inf):
  115:     return np.vstack([arr_nan, arr_nan, arr_inf])
  116: 
  117: 
  118: @pytest.fixture
  119: def arr_obj(
  120:     arr_float, arr_int, arr_bool, arr_complex, arr_str, arr_utf, arr_date, arr_tdelta
  121: ):
  122:     return np.vstack(
  123:         [
  124:             arr_float.astype("O"),
  125:             arr_int.astype("O"),
  126:             arr_bool.astype("O"),
  127:             arr_complex.astype("O"),
  128:             arr_str.astype("O"),
  129:             arr_utf.astype("O"),
  130:             arr_date.astype("O"),
  131:             arr_tdelta.astype("O"),
  132:         ]
  133:     )
  134: 
  135: 
  136: @pytest.fixture
  137: def arr_nan_nanj(arr_nan):
  138:     with np.errstate(invalid="ignore"):
  139:         return arr_nan + arr_nan * 1j
  140: 
  141: 
  142: @pytest.fixture
  143: def arr_complex_nan(arr_complex, arr_nan_nanj):
  144:     with np.errstate(invalid="ignore"):
  145:         return np.vstack([arr_complex, arr_nan_nanj])
  146: 
  147: 
  148: @pytest.fixture
  149: def arr_nan_infj(arr_inf):
  150:     with np.errstate(invalid="ignore"):
  151:         return arr_inf * 1j
  152: 
  153: 
  154: @pytest.fixture
  155: def arr_complex_nan_infj(arr_complex, arr_nan_infj):
  156:     with np.errstate(invalid="ignore"):
  157:         return np.vstack([arr_complex, arr_nan_infj])
  158: 
  159: 
  160: @pytest.fixture
  161: def arr_float_1d(arr_float):
  162:     return arr_float[:, 0]
  163: 
  164: 
  165: @pytest.fixture
  166: def arr_nan_1d(arr_nan):
  167:     return arr_nan[:, 0]
  168: 
  169: 
  170: @pytest.fixture
  171: def arr_float_nan_1d(arr_float_nan):
  172:     return arr_float_nan[:, 0]
  173: 
  174: 
  175: @pytest.fixture
  176: def arr_float1_nan_1d(arr_float1_nan):
  177:     return arr_float1_nan[:, 0]
  178: 
  179: 
  180: @pytest.fixture
  181: def arr_nan_float1_1d(arr_nan_float1):
  182:     return arr_nan_float1[:, 0]
  183: 
  184: 
  185: class TestnanopsDataFrame:
  186:     def setup_method(self):
  187:         nanops._USE_BOTTLENECK = False
  188: 
  189:         arr_shape = (11, 7)
  190: 
  191:         self.arr_float = np.random.default_rng(2).standard_normal(arr_shape)
  192:         self.arr_float1 = np.random.default_rng(2).standard_normal(arr_shape)
  193:         self.arr_complex = self.arr_float + self.arr_float1 * 1j
  194:         self.arr_int = np.random.default_rng(2).integers(-10, 10, arr_shape)
  195:         self.arr_bool = np.random.default_rng(2).integers(0, 2, arr_shape) == 0
  196:         self.arr_str = np.abs(self.arr_float).astype("S")
  197:         self.arr_utf = np.abs(self.arr_float).astype("U")
  198:         self.arr_date = (
  199:             np.random.default_rng(2).integers(0, 20000, arr_shape).astype("M8[ns]")
  200:         )
  201:         self.arr_tdelta = (
  202:             np.random.default_rng(2).integers(0, 20000, arr_shape).astype("m8[ns]")
  203:         )
  204: 
  205:         self.arr_nan = np.tile(np.nan, arr_shape)
  206:         self.arr_float_nan = np.vstack([self.arr_float, self.arr_nan])
  207:         self.arr_float1_nan = np.vstack([self.arr_float1, self.arr_nan])
  208:         self.arr_nan_float1 = np.vstack([self.arr_nan, self.arr_float1])
  209:         self.arr_nan_nan = np.vstack([self.arr_nan, self.arr_nan])
  210: 
  211:         self.arr_inf = self.arr_float * np.inf
  212:         self.arr_float_inf = np.vstack([self.arr_float, self.arr_inf])
  213: 
  214:         self.arr_nan_inf = np.vstack([self.arr_nan, self.arr_inf])
  215:         self.arr_float_nan_inf = np.vstack([self.arr_float, self.arr_nan, self.arr_inf])
  216:         self.arr_nan_nan_inf = np.vstack([self.arr_nan, self.arr_nan, self.arr_inf])
  217:         self.arr_obj = np.vstack(
  218:             [
  219:                 self.arr_float.astype("O"),
  220:                 self.arr_int.astype("O"),
  221:                 self.arr_bool.astype("O"),
  222:                 self.arr_complex.astype("O"),
  223:                 self.arr_str.astype("O"),
  224:                 self.arr_utf.astype("O"),
  225:                 self.arr_date.astype("O"),
  226:                 self.arr_tdelta.astype("O"),
  227:             ]
  228:         )
  229: 
  230:         with np.errstate(invalid="ignore"):
  231:             self.arr_nan_nanj = self.arr_nan + self.arr_nan * 1j
  232:             self.arr_complex_nan = np.vstack([self.arr_complex, self.arr_nan_nanj])
  233: 
  234:             self.arr_nan_infj = self.arr_inf * 1j
  235:             self.arr_complex_nan_infj = np.vstack([self.arr_complex, self.arr_nan_infj])
  236: 
  237:         self.arr_float_2d = self.arr_float
  238:         self.arr_float1_2d = self.arr_float1
  239: 
  240:         self.arr_nan_2d = self.arr_nan
  241:         self.arr_float_nan_2d = self.arr_float_nan
  242:         self.arr_float1_nan_2d = self.arr_float1_nan
  243:         self.arr_nan_float1_2d = self.arr_nan_float1
  244: 
  245:         self.arr_float_1d = self.arr_float[:, 0]
  246:         self.arr_float1_1d = self.arr_float1[:, 0]
  247: 
  248:         self.arr_nan_1d = self.arr_nan[:, 0]
  249:         self.arr_float_nan_1d = self.arr_float_nan[:, 0]
  250:         self.arr_float1_nan_1d = self.arr_float1_nan[:, 0]
  251:         self.arr_nan_float1_1d = self.arr_nan_float1[:, 0]
  252: 
  253:     def teardown_method(self):
  254:         nanops._USE_BOTTLENECK = use_bn
  255: 
  256:     def check_results(self, targ, res, axis, check_dtype=True):
  257:         res = getattr(res, "asm8", res)
  258: 
  259:         if (
  260:             axis != 0
  261:             and hasattr(targ, "shape")
  262:             and targ.ndim
  263:             and targ.shape != res.shape
  264:         ):
  265:             res = np.split(res, [targ.shape[0]], axis=0)[0]
  266: 
  267:         try:
  268:             tm.assert_almost_equal(targ, res, check_dtype=check_dtype)
  269:         except AssertionError:
  270:             # handle timedelta dtypes
  271:             if hasattr(targ, "dtype") and targ.dtype == "m8[ns]":
  272:                 raise
  273: 
  274:             # There are sometimes rounding errors with
  275:             # complex and object dtypes.
  276:             # If it isn't one of those, re-raise the error.
  277:             if not hasattr(res, "dtype") or res.dtype.kind not in ["c", "O"]:
  278:                 raise
  279:             # convert object dtypes to something that can be split into
  280:             # real and imaginary parts
  281:             if res.dtype.kind == "O":
  282:                 if targ.dtype.kind != "O":
  283:                     res = res.astype(targ.dtype)
  284:                 else:
  285:                     cast_dtype = "c16" if hasattr(np, "complex128") else "f8"
  286:                     res = res.astype(cast_dtype)
  287:                     targ = targ.astype(cast_dtype)
  288:             # there should never be a case where numpy returns an object
  289:             # but nanops doesn't, so make that an exception
  290:             elif targ.dtype.kind == "O":
  291:                 raise
  292:             tm.assert_almost_equal(np.real(targ), np.real(res), check_dtype=check_dtype)
  293:             tm.assert_almost_equal(np.imag(targ), np.imag(res), check_dtype=check_dtype)
  294: 
  295:     def check_fun_data(
  296:         self,
  297:         testfunc,
  298:         targfunc,
  299:         testarval,
  300:         targarval,
  301:         skipna,
  302:         check_dtype=True,
  303:         empty_targfunc=None,
  304:         **kwargs,
  305:     ):
  306:         for axis in list(range(targarval.ndim)) + [None]:
  307:             targartempval = targarval if skipna else testarval
  308:             if skipna and empty_targfunc and isna(targartempval).all():
  309:                 targ = empty_targfunc(targartempval, axis=axis, **kwargs)
  310:             else:
  311:                 targ = targfunc(targartempval, axis=axis, **kwargs)
  312: 
  313:             if targartempval.dtype == object and (
  314:                 targfunc is np.any or targfunc is np.all
  315:             ):
  316:                 # GH#12863 the numpy functions will retain e.g. floatiness
  317:                 if isinstance(targ, np.ndarray):
  318:                     targ = targ.astype(bool)
  319:                 else:
  320:                     targ = bool(targ)
  321: 
  322:             res = testfunc(testarval, axis=axis, skipna=skipna, **kwargs)
  323: 
  324:             if (
  325:                 isinstance(targ, np.complex128)
  326:                 and isinstance(res, float)
  327:                 and np.isnan(targ)
  328:                 and np.isnan(res)
  329:             ):
  330:                 # GH#18463
  331:                 targ = res
  332: 
  333:             self.check_results(targ, res, axis, check_dtype=check_dtype)
  334:             if skipna:
  335:                 res = testfunc(testarval, axis=axis, **kwargs)
  336:                 self.check_results(targ, res, axis, check_dtype=check_dtype)
  337:             if axis is None:
  338:                 res = testfunc(testarval, skipna=skipna, **kwargs)
  339:                 self.check_results(targ, res, axis, check_dtype=check_dtype)
  340:             if skipna and axis is None:
  341:                 res = testfunc(testarval, **kwargs)
  342:                 self.check_results(targ, res, axis, check_dtype=check_dtype)
  343: 
  344:         if testarval.ndim <= 1:
  345:             return
  346: 
  347:         # Recurse on lower-dimension
  348:         testarval2 = np.take(testarval, 0, axis=-1)
  349:         targarval2 = np.take(targarval, 0, axis=-1)
  350:         self.check_fun_data(
  351:             testfunc,
  352:             targfunc,
  353:             testarval2,
  354:             targarval2,
  355:             skipna=skipna,
  356:             check_dtype=check_dtype,
  357:             empty_targfunc=empty_targfunc,
  358:             **kwargs,
  359:         )
  360: 
  361:     def check_fun(
  362:         self, testfunc, targfunc, testar, skipna, empty_targfunc=None, **kwargs
  363:     ):
  364:         targar = testar
  365:         if testar.endswith("_nan") and hasattr(self, testar[:-4]):
  366:             targar = testar[:-4]
  367: 
  368:         testarval = getattr(self, testar)
  369:         targarval = getattr(self, targar)
  370:         self.check_fun_data(
  371:             testfunc,
  372:             targfunc,
  373:             testarval,
  374:             targarval,
  375:             skipna=skipna,
  376:             empty_targfunc=empty_targfunc,
  377:             **kwargs,
  378:         )
  379: 
  380:     def check_funs(
  381:         self,
  382:         testfunc,
  383:         targfunc,
  384:         skipna,
  385:         allow_complex=True,
  386:         allow_all_nan=True,
  387:         allow_date=True,
  388:         allow_tdelta=True,
  389:         allow_obj=True,
  390:         **kwargs,
  391:     ):
  392:         self.check_fun(testfunc, targfunc, "arr_float", skipna, **kwargs)
  393:         self.check_fun(testfunc, targfunc, "arr_float_nan", skipna, **kwargs)
  394:         self.check_fun(testfunc, targfunc, "arr_int", skipna, **kwargs)
  395:         self.check_fun(testfunc, targfunc, "arr_bool", skipna, **kwargs)
  396:         objs = [
  397:             self.arr_float.astype("O"),
  398:             self.arr_int.astype("O"),
  399:             self.arr_bool.astype("O"),
  400:         ]
  401: 
  402:         if allow_all_nan:
  403:             self.check_fun(testfunc, targfunc, "arr_nan", skipna, **kwargs)
  404: 
  405:         if allow_complex:
  406:             self.check_fun(testfunc, targfunc, "arr_complex", skipna, **kwargs)
  407:             self.check_fun(testfunc, targfunc, "arr_complex_nan", skipna, **kwargs)
  408:             if allow_all_nan:
  409:                 self.check_fun(testfunc, targfunc, "arr_nan_nanj", skipna, **kwargs)
  410:             objs += [self.arr_complex.astype("O")]
  411: 
  412:         if allow_date:
  413:             targfunc(self.arr_date)
  414:             self.check_fun(testfunc, targfunc, "arr_date", skipna, **kwargs)
  415:             objs += [self.arr_date.astype("O")]
  416: 
  417:         if allow_tdelta:
  418:             try:
  419:                 targfunc(self.arr_tdelta)
  420:             except TypeError:
  421:                 pass
  422:             else:
  423:                 self.check_fun(testfunc, targfunc, "arr_tdelta", skipna, **kwargs)
  424:                 objs += [self.arr_tdelta.astype("O")]
  425: 
  426:         if allow_obj:
  427:             self.arr_obj = np.vstack(objs)
  428:             # some nanops handle object dtypes better than their numpy
  429:             # counterparts, so the numpy functions need to be given something
  430:             # else
  431:             if allow_obj == "convert":
  432:                 targfunc = partial(
  433:                     self._badobj_wrap, func=targfunc, allow_complex=allow_complex
  434:                 )
  435:             self.check_fun(testfunc, targfunc, "arr_obj", skipna, **kwargs)
  436: 
  437:     def _badobj_wrap(self, value, func, allow_complex=True, **kwargs):
  438:         if value.dtype.kind == "O":
  439:             if allow_complex:
  440:                 value = value.astype("c16")
  441:             else:
  442:                 value = value.astype("f8")
  443:         return func(value, **kwargs)
  444: 
  445:     @pytest.mark.parametrize(
  446:         "nan_op,np_op", [(nanops.nanany, np.any), (nanops.nanall, np.all)]
  447:     )
  448:     def test_nan_funcs(self, nan_op, np_op, skipna):
  449:         self.check_funs(nan_op, np_op, skipna, allow_all_nan=False, allow_date=False)
  450: 
  451:     def test_nansum(self, skipna):
  452:         self.check_funs(
  453:             nanops.nansum,
  454:             np.sum,
  455:             skipna,
  456:             allow_date=False,
  457:             check_dtype=False,
  458:             empty_targfunc=np.nansum,
  459:         )
  460: 
  461:     def test_nanmean(self, skipna):
  462:         self.check_funs(
  463:             nanops.nanmean, np.mean, skipna, allow_obj=False, allow_date=False
  464:         )
  465: 
  466:     @pytest.mark.filterwarnings("ignore::RuntimeWarning")
  467:     def test_nanmedian(self, skipna):
  468:         self.check_funs(
  469:             nanops.nanmedian,
  470:             np.median,
  471:             skipna,
  472:             allow_complex=False,
  473:             allow_date=False,
  474:             allow_obj="convert",
  475:         )
  476: 
  477:     @pytest.mark.parametrize("ddof", range(3))
  478:     def test_nanvar(self, ddof, skipna):
  479:         self.check_funs(
  480:             nanops.nanvar,
  481:             np.var,
  482:             skipna,
  483:             allow_complex=False,
  484:             allow_date=False,
  485:             allow_obj="convert",
  486:             ddof=ddof,
  487:         )
  488: 
  489:     @pytest.mark.parametrize("ddof", range(3))
  490:     def test_nanstd(self, ddof, skipna):
  491:         self.check_funs(
  492:             nanops.nanstd,
  493:             np.std,
  494:             skipna,
  495:             allow_complex=False,
  496:             allow_date=False,
  497:             allow_obj="convert",
  498:             ddof=ddof,
  499:         )
  500: 
  501:     @pytest.mark.parametrize("ddof", range(3))
  502:     def test_nansem(self, ddof, skipna):
  503:         sp_stats = pytest.importorskip("scipy.stats")
  504: 
  505:         with np.errstate(invalid="ignore"):
  506:             self.check_funs(
  507:                 nanops.nansem,
  508:                 sp_stats.sem,
  509:                 skipna,
  510:                 allow_complex=False,
  511:                 allow_date=False,
  512:                 allow_tdelta=False,
  513:                 allow_obj="convert",
  514:                 ddof=ddof,
  515:             )
  516: 
  517:     @pytest.mark.filterwarnings("ignore::RuntimeWarning")
  518:     @pytest.mark.parametrize(
  519:         "nan_op,np_op", [(nanops.nanmin, np.min), (nanops.nanmax, np.max)]
  520:     )
  521:     def test_nanops_with_warnings(self, nan_op, np_op, skipna):
  522:         self.check_funs(nan_op, np_op, skipna, allow_obj=False)
  523: 
  524:     def _argminmax_wrap(self, value, axis=None, func=None):
  525:         res = func(value, axis)
  526:         nans = np.min(value, axis)
  527:         nullnan = isna(nans)
  528:         if res.ndim:
  529:             res[nullnan] = -1
  530:         elif (
  531:             hasattr(nullnan, "all")
  532:             and nullnan.all()
  533:             or not hasattr(nullnan, "all")
  534:             and nullnan
  535:         ):
  536:             res = -1
  537:         return res
  538: 
  539:     @pytest.mark.filterwarnings("ignore::RuntimeWarning")
  540:     def test_nanargmax(self, skipna):
  541:         func = partial(self._argminmax_wrap, func=np.argmax)
  542:         self.check_funs(nanops.nanargmax, func, skipna, allow_obj=False)
  543: 
  544:     @pytest.mark.filterwarnings("ignore::RuntimeWarning")
  545:     def test_nanargmin(self, skipna):
  546:         func = partial(self._argminmax_wrap, func=np.argmin)
  547:         self.check_funs(nanops.nanargmin, func, skipna, allow_obj=False)
  548: 
  549:     def _skew_kurt_wrap(self, values, axis=None, func=None):
  550:         if not isinstance(values.dtype.type, np.floating):
  551:             values = values.astype("f8")
  552:         result = func(values, axis=axis, bias=False)
  553:         # fix for handling cases where all elements in an axis are the same
  554:         if isinstance(result, np.ndarray):
  555:             result[np.max(values, axis=axis) == np.min(values, axis=axis)] = 0
  556:             return result
  557:         elif np.max(values) == np.min(values):
  558:             return 0.0
  559:         return result
  560: 
  561:     def test_nanskew(self, skipna):
  562:         sp_stats = pytest.importorskip("scipy.stats")
  563: 
  564:         func = partial(self._skew_kurt_wrap, func=sp_stats.skew)
  565:         with np.errstate(invalid="ignore"):
  566:             self.check_funs(
  567:                 nanops.nanskew,
  568:                 func,
  569:                 skipna,
  570:                 allow_complex=False,
  571:                 allow_date=False,
  572:                 allow_tdelta=False,
  573:             )
  574: 
  575:     def test_nankurt(self, skipna):
  576:         sp_stats = pytest.importorskip("scipy.stats")
  577: 
  578:         func1 = partial(sp_stats.kurtosis, fisher=True)
  579:         func = partial(self._skew_kurt_wrap, func=func1)
  580:         with np.errstate(invalid="ignore"):
  581:             self.check_funs(
  582:                 nanops.nankurt,
  583:                 func,
  584:                 skipna,
  585:                 allow_complex=False,
  586:                 allow_date=False,
  587:                 allow_tdelta=False,
  588:             )
  589: 
  590:     def test_nanprod(self, skipna):
  591:         self.check_funs(
  592:             nanops.nanprod,
  593:             np.prod,
  594:             skipna,
  595:             allow_date=False,
  596:             allow_tdelta=False,
  597:             empty_targfunc=np.nanprod,
  598:         )
  599: 
  600:     def check_nancorr_nancov_2d(self, checkfun, targ0, targ1, **kwargs):
  601:         res00 = checkfun(self.arr_float_2d, self.arr_float1_2d, **kwargs)
  602:         res01 = checkfun(
  603:             self.arr_float_2d,
  604:             self.arr_float1_2d,
  605:             min_periods=len(self.arr_float_2d) - 1,
  606:             **kwargs,
  607:         )
  608:         tm.assert_almost_equal(targ0, res00)
  609:         tm.assert_almost_equal(targ0, res01)
  610: 
  611:         res10 = checkfun(self.arr_float_nan_2d, self.arr_float1_nan_2d, **kwargs)
  612:         res11 = checkfun(
  613:             self.arr_float_nan_2d,
  614:             self.arr_float1_nan_2d,
  615:             min_periods=len(self.arr_float_2d) - 1,
  616:             **kwargs,
  617:         )
  618:         tm.assert_almost_equal(targ1, res10)
  619:         tm.assert_almost_equal(targ1, res11)
  620: 
  621:         targ2 = np.nan
  622:         res20 = checkfun(self.arr_nan_2d, self.arr_float1_2d, **kwargs)
  623:         res21 = checkfun(self.arr_float_2d, self.arr_nan_2d, **kwargs)
  624:         res22 = checkfun(self.arr_nan_2d, self.arr_nan_2d, **kwargs)
  625:         res23 = checkfun(self.arr_float_nan_2d, self.arr_nan_float1_2d, **kwargs)
  626:         res24 = checkfun(
  627:             self.arr_float_nan_2d,
  628:             self.arr_nan_float1_2d,
  629:             min_periods=len(self.arr_float_2d) - 1,
  630:             **kwargs,
  631:         )
  632:         res25 = checkfun(
  633:             self.arr_float_2d,
  634:             self.arr_float1_2d,
  635:             min_periods=len(self.arr_float_2d) + 1,
  636:             **kwargs,
  637:         )
  638:         tm.assert_almost_equal(targ2, res20)
  639:         tm.assert_almost_equal(targ2, res21)
  640:         tm.assert_almost_equal(targ2, res22)
  641:         tm.assert_almost_equal(targ2, res23)
  642:         tm.assert_almost_equal(targ2, res24)
  643:         tm.assert_almost_equal(targ2, res25)
  644: 
  645:     def check_nancorr_nancov_1d(self, checkfun, targ0, targ1, **kwargs):
  646:         res00 = checkfun(self.arr_float_1d, self.arr_float1_1d, **kwargs)
  647:         res01 = checkfun(
  648:             self.arr_float_1d,
  649:             self.arr_float1_1d,
  650:             min_periods=len(self.arr_float_1d) - 1,
  651:             **kwargs,
  652:         )
  653:         tm.assert_almost_equal(targ0, res00)
  654:         tm.assert_almost_equal(targ0, res01)
  655: 
  656:         res10 = checkfun(self.arr_float_nan_1d, self.arr_float1_nan_1d, **kwargs)
  657:         res11 = checkfun(
  658:             self.arr_float_nan_1d,
  659:             self.arr_float1_nan_1d,
  660:             min_periods=len(self.arr_float_1d) - 1,
  661:             **kwargs,
  662:         )
  663:         tm.assert_almost_equal(targ1, res10)
  664:         tm.assert_almost_equal(targ1, res11)
  665: 
  666:         targ2 = np.nan
  667:         res20 = checkfun(self.arr_nan_1d, self.arr_float1_1d, **kwargs)
  668:         res21 = checkfun(self.arr_float_1d, self.arr_nan_1d, **kwargs)
  669:         res22 = checkfun(self.arr_nan_1d, self.arr_nan_1d, **kwargs)
  670:         res23 = checkfun(self.arr_float_nan_1d, self.arr_nan_float1_1d, **kwargs)
  671:         res24 = checkfun(
  672:             self.arr_float_nan_1d,
  673:             self.arr_nan_float1_1d,
  674:             min_periods=len(self.arr_float_1d) - 1,
  675:             **kwargs,
  676:         )
  677:         res25 = checkfun(
  678:             self.arr_float_1d,
  679:             self.arr_float1_1d,
  680:             min_periods=len(self.arr_float_1d) + 1,
  681:             **kwargs,
  682:         )
  683:         tm.assert_almost_equal(targ2, res20)
  684:         tm.assert_almost_equal(targ2, res21)
  685:         tm.assert_almost_equal(targ2, res22)
  686:         tm.assert_almost_equal(targ2, res23)
  687:         tm.assert_almost_equal(targ2, res24)
  688:         tm.assert_almost_equal(targ2, res25)
  689: 
  690:     def test_nancorr(self):
  691:         targ0 = np.corrcoef(self.arr_float_2d, self.arr_float1_2d)[0, 1]
  692:         targ1 = np.corrcoef(self.arr_float_2d.flat, self.arr_float1_2d.flat)[0, 1]
  693:         self.check_nancorr_nancov_2d(nanops.nancorr, targ0, targ1)
  694:         targ0 = np.corrcoef(self.arr_float_1d, self.arr_float1_1d)[0, 1]
  695:         targ1 = np.corrcoef(self.arr_float_1d.flat, self.arr_float1_1d.flat)[0, 1]
  696:         self.check_nancorr_nancov_1d(nanops.nancorr, targ0, targ1, method="pearson")
  697: 
  698:     def test_nancorr_pearson(self):
  699:         targ0 = np.corrcoef(self.arr_float_2d, self.arr_float1_2d)[0, 1]
  700:         targ1 = np.corrcoef(self.arr_float_2d.flat, self.arr_float1_2d.flat)[0, 1]
  701:         self.check_nancorr_nancov_2d(nanops.nancorr, targ0, targ1, method="pearson")
  702:         targ0 = np.corrcoef(self.arr_float_1d, self.arr_float1_1d)[0, 1]
  703:         targ1 = np.corrcoef(self.arr_float_1d.flat, self.arr_float1_1d.flat)[0, 1]
  704:         self.check_nancorr_nancov_1d(nanops.nancorr, targ0, targ1, method="pearson")
  705: 
  706:     def test_nancorr_kendall(self):
  707:         sp_stats = pytest.importorskip("scipy.stats")
  708: 
  709:         targ0 = sp_stats.kendalltau(self.arr_float_2d, self.arr_float1_2d)[0]
  710:         targ1 = sp_stats.kendalltau(self.arr_float_2d.flat, self.arr_float1_2d.flat)[0]
  711:         self.check_nancorr_nancov_2d(nanops.nancorr, targ0, targ1, method="kendall")
  712:         targ0 = sp_stats.kendalltau(self.arr_float_1d, self.arr_float1_1d)[0]
  713:         targ1 = sp_stats.kendalltau(self.arr_float_1d.flat, self.arr_float1_1d.flat)[0]
  714:         self.check_nancorr_nancov_1d(nanops.nancorr, targ0, targ1, method="kendall")
  715: 
  716:     def test_nancorr_spearman(self):
  717:         sp_stats = pytest.importorskip("scipy.stats")
  718: 
  719:         targ0 = sp_stats.spearmanr(self.arr_float_2d, self.arr_float1_2d)[0]
  720:         targ1 = sp_stats.spearmanr(self.arr_float_2d.flat, self.arr_float1_2d.flat)[0]
  721:         self.check_nancorr_nancov_2d(nanops.nancorr, targ0, targ1, method="spearman")
  722:         targ0 = sp_stats.spearmanr(self.arr_float_1d, self.arr_float1_1d)[0]
  723:         targ1 = sp_stats.spearmanr(self.arr_float_1d.flat, self.arr_float1_1d.flat)[0]
  724:         self.check_nancorr_nancov_1d(nanops.nancorr, targ0, targ1, method="spearman")
  725: 
  726:     def test_invalid_method(self):
  727:         pytest.importorskip("scipy")
  728:         targ0 = np.corrcoef(self.arr_float_2d, self.arr_float1_2d)[0, 1]
  729:         targ1 = np.corrcoef(self.arr_float_2d.flat, self.arr_float1_2d.flat)[0, 1]
  730:         msg = "Unknown method 'foo', expected one of 'kendall', 'spearman'"
  731:         with pytest.raises(ValueError, match=msg):
  732:             self.check_nancorr_nancov_1d(nanops.nancorr, targ0, targ1, method="foo")
  733: 
  734:     def test_nancov(self):
  735:         targ0 = np.cov(self.arr_float_2d, self.arr_float1_2d)[0, 1]
  736:         targ1 = np.cov(self.arr_float_2d.flat, self.arr_float1_2d.flat)[0, 1]
  737:         self.check_nancorr_nancov_2d(nanops.nancov, targ0, targ1)
  738:         targ0 = np.cov(self.arr_float_1d, self.arr_float1_1d)[0, 1]
  739:         targ1 = np.cov(self.arr_float_1d.flat, self.arr_float1_1d.flat)[0, 1]
  740:         self.check_nancorr_nancov_1d(nanops.nancov, targ0, targ1)
  741: 
  742: 
  743: @pytest.mark.parametrize(
  744:     "arr, correct",
  745:     [
  746:         ("arr_complex", False),
  747:         ("arr_int", False),
  748:         ("arr_bool", False),
  749:         ("arr_str", False),
  750:         ("arr_utf", False),
  751:         ("arr_complex", False),
  752:         ("arr_complex_nan", False),
  753:         ("arr_nan_nanj", False),
  754:         ("arr_nan_infj", True),
  755:         ("arr_complex_nan_infj", True),
  756:     ],
  757: )
  758: def test_has_infs_non_float(request, arr, correct, disable_bottleneck):
  759:     val = request.getfixturevalue(arr)
  760:     while getattr(val, "ndim", True):
  761:         res0 = nanops._has_infs(val)
  762:         if correct:
  763:             assert res0
  764:         else:
  765:             assert not res0
  766: 
  767:         if not hasattr(val, "ndim"):
  768:             break
  769: 
  770:         # Reduce dimension for next step in the loop
  771:         val = np.take(val, 0, axis=-1)
  772: 
  773: 
  774: @pytest.mark.parametrize(
  775:     "arr, correct",
  776:     [
  777:         ("arr_float", False),
  778:         ("arr_nan", False),
  779:         ("arr_float_nan", False),
  780:         ("arr_nan_nan", False),
  781:         ("arr_float_inf", True),
  782:         ("arr_inf", True),
  783:         ("arr_nan_inf", True),
  784:         ("arr_float_nan_inf", True),
  785:         ("arr_nan_nan_inf", True),
  786:     ],
  787: )
  788: @pytest.mark.parametrize("astype", [None, "f4", "f2"])
  789: def test_has_infs_floats(request, arr, correct, astype, disable_bottleneck):
  790:     val = request.getfixturevalue(arr)
  791:     if astype is not None:
  792:         val = val.astype(astype)
  793:     while getattr(val, "ndim", True):
  794:         res0 = nanops._has_infs(val)
  795:         if correct:
  796:             assert res0
  797:         else:
  798:             assert not res0
  799: 
  800:         if not hasattr(val, "ndim"):
  801:             break
  802: 
  803:         # Reduce dimension for next step in the loop
  804:         val = np.take(val, 0, axis=-1)
  805: 
  806: 
  807: @pytest.mark.parametrize(
  808:     "fixture", ["arr_float", "arr_complex", "arr_int", "arr_bool", "arr_str", "arr_utf"]
  809: )
  810: def test_bn_ok_dtype(fixture, request, disable_bottleneck):
  811:     obj = request.getfixturevalue(fixture)
  812:     assert nanops._bn_ok_dtype(obj.dtype, "test")
  813: 
  814: 
  815: @pytest.mark.parametrize(
  816:     "fixture",
  817:     [
  818:         "arr_date",
  819:         "arr_tdelta",
  820:         "arr_obj",
  821:     ],
  822: )
  823: def test_bn_not_ok_dtype(fixture, request, disable_bottleneck):
  824:     obj = request.getfixturevalue(fixture)
  825:     assert not nanops._bn_ok_dtype(obj.dtype, "test")
  826: 
  827: 
  828: class TestEnsureNumeric:
  829:     def test_numeric_values(self):
  830:         # Test integer
  831:         assert nanops._ensure_numeric(1) == 1
  832: 
  833:         # Test float
  834:         assert nanops._ensure_numeric(1.1) == 1.1
  835: 
  836:         # Test complex
  837:         assert nanops._ensure_numeric(1 + 2j) == 1 + 2j
  838: 
  839:     def test_ndarray(self):
  840:         # Test numeric ndarray
  841:         values = np.array([1, 2, 3])
  842:         assert np.allclose(nanops._ensure_numeric(values), values)
  843: 
  844:         # Test object ndarray
  845:         o_values = values.astype(object)
  846:         assert np.allclose(nanops._ensure_numeric(o_values), values)
  847: 
  848:         # Test convertible string ndarray
  849:         s_values = np.array(["1", "2", "3"], dtype=object)
  850:         msg = r"Could not convert \['1' '2' '3'\] to numeric"
  851:         with pytest.raises(TypeError, match=msg):
  852:             nanops._ensure_numeric(s_values)
  853: 
  854:         # Test non-convertible string ndarray
  855:         s_values = np.array(["foo", "bar", "baz"], dtype=object)
  856:         msg = r"Could not convert .* to numeric"
  857:         with pytest.raises(TypeError, match=msg):
  858:             nanops._ensure_numeric(s_values)
  859: 
  860:     def test_convertable_values(self):
  861:         with pytest.raises(TypeError, match="Could not convert string '1' to numeric"):
  862:             nanops._ensure_numeric("1")
  863:         with pytest.raises(
  864:             TypeError, match="Could not convert string '1.1' to numeric"
  865:         ):
  866:             nanops._ensure_numeric("1.1")
  867:         with pytest.raises(
  868:             TypeError, match=r"Could not convert string '1\+1j' to numeric"
  869:         ):
  870:             nanops._ensure_numeric("1+1j")
  871: 
  872:     def test_non_convertable_values(self):
  873:         msg = "Could not convert string 'foo' to numeric"
  874:         with pytest.raises(TypeError, match=msg):
  875:             nanops._ensure_numeric("foo")
  876: 
  877:         # with the wrong type, python raises TypeError for us
  878:         msg = "argument must be a string or a number"
  879:         with pytest.raises(TypeError, match=msg):
  880:             nanops._ensure_numeric({})
  881:         with pytest.raises(TypeError, match=msg):
  882:             nanops._ensure_numeric([])
  883: 
  884: 
  885: class TestNanvarFixedValues:
  886:     # xref GH10242
  887:     # Samples from a normal distribution.
  888:     @pytest.fixture
  889:     def variance(self):
  890:         return 3.0
  891: 
  892:     @pytest.fixture
  893:     def samples(self, variance):
  894:         return self.prng.normal(scale=variance**0.5, size=100000)
  895: 
  896:     def test_nanvar_all_finite(self, samples, variance):
  897:         actual_variance = nanops.nanvar(samples)
  898:         tm.assert_almost_equal(actual_variance, variance, rtol=1e-2)
  899: 
  900:     def test_nanvar_nans(self, samples, variance):
  901:         samples_test = np.nan * np.ones(2 * samples.shape[0])
  902:         samples_test[::2] = samples
  903: 
  904:         actual_variance = nanops.nanvar(samples_test, skipna=True)
  905:         tm.assert_almost_equal(actual_variance, variance, rtol=1e-2)
  906: 
  907:         actual_variance = nanops.nanvar(samples_test, skipna=False)
  908:         tm.assert_almost_equal(actual_variance, np.nan, rtol=1e-2)
  909: 
  910:     def test_nanstd_nans(self, samples, variance):
  911:         samples_test = np.nan * np.ones(2 * samples.shape[0])
  912:         samples_test[::2] = samples
  913: 
  914:         actual_std = nanops.nanstd(samples_test, skipna=True)
  915:         tm.assert_almost_equal(actual_std, variance**0.5, rtol=1e-2)
  916: 
  917:         actual_std = nanops.nanvar(samples_test, skipna=False)
  918:         tm.assert_almost_equal(actual_std, np.nan, rtol=1e-2)
  919: 
  920:     def test_nanvar_axis(self, samples, variance):
  921:         # Generate some sample data.
  922:         samples_unif = self.prng.uniform(size=samples.shape[0])
  923:         samples = np.vstack([samples, samples_unif])
  924: 
  925:         actual_variance = nanops.nanvar(samples, axis=1)
  926:         tm.assert_almost_equal(
  927:             actual_variance, np.array([variance, 1.0 / 12]), rtol=1e-2
  928:         )
  929: 
  930:     def test_nanvar_ddof(self):
  931:         n = 5
  932:         samples = self.prng.uniform(size=(10000, n + 1))
  933:         samples[:, -1] = np.nan  # Force use of our own algorithm.
  934: 
  935:         variance_0 = nanops.nanvar(samples, axis=1, skipna=True, ddof=0).mean()
  936:         variance_1 = nanops.nanvar(samples, axis=1, skipna=True, ddof=1).mean()
  937:         variance_2 = nanops.nanvar(samples, axis=1, skipna=True, ddof=2).mean()
  938: 
  939:         # The unbiased estimate.
  940:         var = 1.0 / 12
  941:         tm.assert_almost_equal(variance_1, var, rtol=1e-2)
  942: 
  943:         # The underestimated variance.
  944:         tm.assert_almost_equal(variance_0, (n - 1.0) / n * var, rtol=1e-2)
  945: 
  946:         # The overestimated variance.
  947:         tm.assert_almost_equal(variance_2, (n - 1.0) / (n - 2.0) * var, rtol=1e-2)
  948: 
  949:     @pytest.mark.parametrize("axis", range(2))
  950:     @pytest.mark.parametrize("ddof", range(3))
  951:     def test_ground_truth(self, axis, ddof):
  952:         # Test against values that were precomputed with Numpy.
  953:         samples = np.empty((4, 4))
  954:         samples[:3, :3] = np.array(
  955:             [
  956:                 [0.97303362, 0.21869576, 0.55560287],
  957:                 [0.72980153, 0.03109364, 0.99155171],
  958:                 [0.09317602, 0.60078248, 0.15871292],
  959:             ]
  960:         )
  961:         samples[3] = samples[:, 3] = np.nan
  962: 
  963:         # Actual variances along axis=0, 1 for ddof=0, 1, 2
  964:         variance = np.array(
  965:             [
  966:                 [
  967:                     [0.13762259, 0.05619224, 0.11568816],
  968:                     [0.20643388, 0.08428837, 0.17353224],
  969:                     [0.41286776, 0.16857673, 0.34706449],
  970:                 ],
  971:                 [
  972:                     [0.09519783, 0.16435395, 0.05082054],
  973:                     [0.14279674, 0.24653093, 0.07623082],
  974:                     [0.28559348, 0.49306186, 0.15246163],
  975:                 ],
  976:             ]
  977:         )
  978: 
  979:         # Test nanvar.
  980:         var = nanops.nanvar(samples, skipna=True, axis=axis, ddof=ddof)
  981:         tm.assert_almost_equal(var[:3], variance[axis, ddof])
  982:         assert np.isnan(var[3])
  983: 
  984:         # Test nanstd.
  985:         std = nanops.nanstd(samples, skipna=True, axis=axis, ddof=ddof)
  986:         tm.assert_almost_equal(std[:3], variance[axis, ddof] ** 0.5)
  987:         assert np.isnan(std[3])
  988: 
  989:     @pytest.mark.parametrize("ddof", range(3))
  990:     def test_nanstd_roundoff(self, ddof):
  991:         # Regression test for GH 10242 (test data taken from GH 10489). Ensure
  992:         # that variance is stable.
  993:         data = Series(766897346 * np.ones(10))
  994:         result = data.std(ddof=ddof)
  995:         assert result == 0.0
  996: 
  997:     @property
  998:     def prng(self):
  999:         return np.random.default_rng(2)
 1000: 
 1001: 
 1002: class TestNanskewFixedValues:
 1003:     # xref GH 11974
 1004:     # Test data + skewness value (computed with scipy.stats.skew)
 1005:     @pytest.fixture
 1006:     def samples(self):
 1007:         return np.sin(np.linspace(0, 1, 200))
 1008: 
 1009:     @pytest.fixture
 1010:     def actual_skew(self):
 1011:         return -0.1875895205961754
 1012: 
 1013:     @pytest.mark.parametrize("val", [3075.2, 3075.3, 3075.5])
 1014:     def test_constant_series(self, val):
 1015:         # xref GH 11974
 1016:         data = val * np.ones(300)
 1017:         skew = nanops.nanskew(data)
 1018:         assert skew == 0.0
 1019: 
 1020:     def test_all_finite(self):
 1021:         alpha, beta = 0.3, 0.1
 1022:         left_tailed = self.prng.beta(alpha, beta, size=100)
 1023:         assert nanops.nanskew(left_tailed) < 0
 1024: 
 1025:         alpha, beta = 0.1, 0.3
 1026:         right_tailed = self.prng.beta(alpha, beta, size=100)
 1027:         assert nanops.nanskew(right_tailed) > 0
 1028: 
 1029:     def test_ground_truth(self, samples, actual_skew):
 1030:         skew = nanops.nanskew(samples)
 1031:         tm.assert_almost_equal(skew, actual_skew)
 1032: 
 1033:     def test_axis(self, samples, actual_skew):
 1034:         samples = np.vstack([samples, np.nan * np.ones(len(samples))])
 1035:         skew = nanops.nanskew(samples, axis=1)
 1036:         tm.assert_almost_equal(skew, np.array([actual_skew, np.nan]))
 1037: 
 1038:     def test_nans(self, samples):
 1039:         samples = np.hstack([samples, np.nan])
 1040:         skew = nanops.nanskew(samples, skipna=False)
 1041:         assert np.isnan(skew)
 1042: 
 1043:     def test_nans_skipna(self, samples, actual_skew):
 1044:         samples = np.hstack([samples, np.nan])
 1045:         skew = nanops.nanskew(samples, skipna=True)
 1046:         tm.assert_almost_equal(skew, actual_skew)
 1047: 
 1048:     @property
 1049:     def prng(self):
 1050:         return np.random.default_rng(2)
 1051: 
 1052: 
 1053: class TestNankurtFixedValues:
 1054:     # xref GH 11974
 1055:     # Test data + kurtosis value (computed with scipy.stats.kurtosis)
 1056:     @pytest.fixture
 1057:     def samples(self):
 1058:         return np.sin(np.linspace(0, 1, 200))
 1059: 
 1060:     @pytest.fixture
 1061:     def actual_kurt(self):
 1062:         return -1.2058303433799713
 1063: 
 1064:     @pytest.mark.parametrize("val", [3075.2, 3075.3, 3075.5])
 1065:     def test_constant_series(self, val):
 1066:         # xref GH 11974
 1067:         data = val * np.ones(300)
 1068:         kurt = nanops.nankurt(data)
 1069:         assert kurt == 0.0
 1070: 
 1071:     def test_all_finite(self):
 1072:         alpha, beta = 0.3, 0.1
 1073:         left_tailed = self.prng.beta(alpha, beta, size=100)
 1074:         assert nanops.nankurt(left_tailed) < 2
 1075: 
 1076:         alpha, beta = 0.1, 0.3
 1077:         right_tailed = self.prng.beta(alpha, beta, size=100)
 1078:         assert nanops.nankurt(right_tailed) < 0
 1079: 
 1080:     def test_ground_truth(self, samples, actual_kurt):
 1081:         kurt = nanops.nankurt(samples)
 1082:         tm.assert_almost_equal(kurt, actual_kurt)
 1083: 
 1084:     def test_axis(self, samples, actual_kurt):
 1085:         samples = np.vstack([samples, np.nan * np.ones(len(samples))])
 1086:         kurt = nanops.nankurt(samples, axis=1)
 1087:         tm.assert_almost_equal(kurt, np.array([actual_kurt, np.nan]))
 1088: 
 1089:     def test_nans(self, samples):
 1090:         samples = np.hstack([samples, np.nan])
 1091:         kurt = nanops.nankurt(samples, skipna=False)
 1092:         assert np.isnan(kurt)
 1093: 
 1094:     def test_nans_skipna(self, samples, actual_kurt):
 1095:         samples = np.hstack([samples, np.nan])
 1096:         kurt = nanops.nankurt(samples, skipna=True)
 1097:         tm.assert_almost_equal(kurt, actual_kurt)
 1098: 
 1099:     @property
 1100:     def prng(self):
 1101:         return np.random.default_rng(2)
 1102: 
 1103: 
 1104: class TestDatetime64NaNOps:
 1105:     @pytest.fixture(params=["s", "ms", "us", "ns"])
 1106:     def unit(self, request):
 1107:         return request.param
 1108: 
 1109:     # Enabling mean changes the behavior of DataFrame.mean
 1110:     # See https://github.com/pandas-dev/pandas/issues/24752
 1111:     def test_nanmean(self, unit):
 1112:         dti = pd.date_range("2016-01-01", periods=3).as_unit(unit)
 1113:         expected = dti[1]
 1114: 
 1115:         for obj in [dti, dti._data]:
 1116:             result = nanops.nanmean(obj)
 1117:             assert result == expected
 1118: 
 1119:         dti2 = dti.insert(1, pd.NaT)
 1120: 
 1121:         for obj in [dti2, dti2._data]:
 1122:             result = nanops.nanmean(obj)
 1123:             assert result == expected
 1124: 
 1125:     @pytest.mark.parametrize("constructor", ["M8", "m8"])
 1126:     def test_nanmean_skipna_false(self, constructor, unit):
 1127:         dtype = f"{constructor}[{unit}]"
 1128:         arr = np.arange(12).astype(np.int64).view(dtype).reshape(4, 3)
 1129: 
 1130:         arr[-1, -1] = "NaT"
 1131: 
 1132:         result = nanops.nanmean(arr, skipna=False)
 1133:         assert np.isnat(result)
 1134:         assert result.dtype == dtype
 1135: 
 1136:         result = nanops.nanmean(arr, axis=0, skipna=False)
 1137:         expected = np.array([4, 5, "NaT"], dtype=arr.dtype)
 1138:         tm.assert_numpy_array_equal(result, expected)
 1139: 
 1140:         result = nanops.nanmean(arr, axis=1, skipna=False)
 1141:         expected = np.array([arr[0, 1], arr[1, 1], arr[2, 1], arr[-1, -1]])
 1142:         tm.assert_numpy_array_equal(result, expected)
 1143: 
 1144: 
 1145: def test_use_bottleneck():
 1146:     if nanops._BOTTLENECK_INSTALLED:
 1147:         with pd.option_context("use_bottleneck", True):
 1148:             assert pd.get_option("use_bottleneck")
 1149: 
 1150:         with pd.option_context("use_bottleneck", False):
 1151:             assert not pd.get_option("use_bottleneck")
 1152: 
 1153: 
 1154: @pytest.mark.parametrize(
 1155:     "numpy_op, expected",
 1156:     [
 1157:         (np.sum, 10),
 1158:         (np.nansum, 10),
 1159:         (np.mean, 2.5),
 1160:         (np.nanmean, 2.5),
 1161:         (np.median, 2.5),
 1162:         (np.nanmedian, 2.5),
 1163:         (np.min, 1),
 1164:         (np.max, 4),
 1165:         (np.nanmin, 1),
 1166:         (np.nanmax, 4),
 1167:     ],
 1168: )
 1169: def test_numpy_ops(numpy_op, expected):
 1170:     # GH8383
 1171:     result = numpy_op(Series([1, 2, 3, 4]))
 1172:     assert result == expected
 1173: 
 1174: 
 1175: @pytest.mark.parametrize(
 1176:     "operation",
 1177:     [
 1178:         nanops.nanany,
 1179:         nanops.nanall,
 1180:         nanops.nansum,
 1181:         nanops.nanmean,
 1182:         nanops.nanmedian,
 1183:         nanops.nanstd,
 1184:         nanops.nanvar,
 1185:         nanops.nansem,
 1186:         nanops.nanargmax,
 1187:         nanops.nanargmin,
 1188:         nanops.nanmax,
 1189:         nanops.nanmin,
 1190:         nanops.nanskew,
 1191:         nanops.nankurt,
 1192:         nanops.nanprod,
 1193:     ],
 1194: )
 1195: def test_nanops_independent_of_mask_param(operation):
 1196:     # GH22764
 1197:     ser = Series([1, 2, np.nan, 3, np.nan, 4])
 1198:     mask = ser.isna()
 1199:     median_expected = operation(ser._values)
 1200:     median_result = operation(ser._values, mask=mask)
 1201:     assert median_expected == median_result
 1202: 
 1203: 
 1204: @pytest.mark.parametrize("min_count", [-1, 0])
 1205: def test_check_below_min_count_negative_or_zero_min_count(min_count):
 1206:     # GH35227
 1207:     result = nanops.check_below_min_count((21, 37), None, min_count)
 1208:     expected_result = False
 1209:     assert result == expected_result
 1210: 
 1211: 
 1212: @pytest.mark.parametrize(
 1213:     "mask", [None, np.array([False, False, True]), np.array([True] + 9 * [False])]
 1214: )
 1215: @pytest.mark.parametrize("min_count, expected_result", [(1, False), (101, True)])
 1216: def test_check_below_min_count_positive_min_count(mask, min_count, expected_result):
 1217:     # GH35227
 1218:     shape = (10, 10)
 1219:     result = nanops.check_below_min_count(shape, mask, min_count)
 1220:     assert result == expected_result
 1221: 
 1222: 
 1223: @td.skip_if_windows
 1224: @td.skip_if_32bit
 1225: @pytest.mark.parametrize("min_count, expected_result", [(1, False), (2812191852, True)])
 1226: def test_check_below_min_count_large_shape(min_count, expected_result):
 1227:     # GH35227 large shape used to show that the issue is fixed
 1228:     shape = (2244367, 1253)
 1229:     result = nanops.check_below_min_count(shape, mask=None, min_count=min_count)
 1230:     assert result == expected_result
 1231: 
 1232: 
 1233: @pytest.mark.parametrize("func", ["nanmean", "nansum"])
 1234: def test_check_bottleneck_disallow(any_real_numpy_dtype, func):
 1235:     # GH 42878 bottleneck sometimes produces unreliable results for mean and sum
 1236:     assert not nanops._bn_ok_dtype(np.dtype(any_real_numpy_dtype).type, func)
 1237: 
 1238: 
 1239: @pytest.mark.parametrize("val", [2**55, -(2**55), 20150515061816532])
 1240: def test_nanmean_overflow(disable_bottleneck, val):
 1241:     # GH 10155
 1242:     # In the previous implementation mean can overflow for int dtypes, it
 1243:     # is now consistent with numpy
 1244: 
 1245:     ser = Series(val, index=range(500), dtype=np.int64)
 1246:     result = ser.mean()
 1247:     np_result = ser.values.mean()
 1248:     assert result == val
 1249:     assert result == np_result
 1250:     assert result.dtype == np.float64
 1251: 
 1252: 
 1253: @pytest.mark.parametrize(
 1254:     "dtype",
 1255:     [
 1256:         np.int16,
 1257:         np.int32,
 1258:         np.int64,
 1259:         np.float32,
 1260:         np.float64,
 1261:         getattr(np, "float128", None),
 1262:     ],
 1263: )
 1264: @pytest.mark.parametrize("method", ["mean", "std", "var", "skew", "kurt", "min", "max"])
 1265: def test_returned_dtype(disable_bottleneck, dtype, method):
 1266:     if dtype is None:
 1267:         pytest.skip("np.float128 not available")
 1268: 
 1269:     ser = Series(range(10), dtype=dtype)
 1270:     result = getattr(ser, method)()
 1271:     if is_integer_dtype(dtype) and method not in ["min", "max"]:
 1272:         assert result.dtype == np.float64
 1273:     else:
 1274:         assert result.dtype == dtype
