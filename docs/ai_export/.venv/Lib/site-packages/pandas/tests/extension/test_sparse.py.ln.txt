    1: """
    2: This file contains a minimal set of tests for compliance with the extension
    3: array interface test suite, and should contain no other tests.
    4: The test suite for the full functionality of the array is located in
    5: `pandas/tests/arrays/`.
    6: 
    7: The tests in this file are inherited from the BaseExtensionTests, and only
    8: minimal tweaks should be applied to get the tests passing (by overwriting a
    9: parent method).
   10: 
   11: Additional tests should either be added to one of the BaseExtensionTests
   12: classes (if they are relevant for the extension interface for all dtypes), or
   13: be added to the array-specific tests in `pandas/tests/arrays/`.
   14: 
   15: """
   16: 
   17: import numpy as np
   18: import pytest
   19: 
   20: from pandas.errors import PerformanceWarning
   21: 
   22: import pandas as pd
   23: from pandas import SparseDtype
   24: import pandas._testing as tm
   25: from pandas.arrays import SparseArray
   26: from pandas.tests.extension import base
   27: 
   28: 
   29: def make_data(fill_value):
   30:     rng = np.random.default_rng(2)
   31:     if np.isnan(fill_value):
   32:         data = rng.uniform(size=100)
   33:     else:
   34:         data = rng.integers(1, 100, size=100, dtype=int)
   35:         if data[0] == data[1]:
   36:             data[0] += 1
   37: 
   38:     data[2::3] = fill_value
   39:     return data
   40: 
   41: 
   42: @pytest.fixture
   43: def dtype():
   44:     return SparseDtype()
   45: 
   46: 
   47: @pytest.fixture(params=[0, np.nan])
   48: def data(request):
   49:     """Length-100 PeriodArray for semantics test."""
   50:     res = SparseArray(make_data(request.param), fill_value=request.param)
   51:     return res
   52: 
   53: 
   54: @pytest.fixture
   55: def data_for_twos():
   56:     return SparseArray(np.ones(100) * 2)
   57: 
   58: 
   59: @pytest.fixture(params=[0, np.nan])
   60: def data_missing(request):
   61:     """Length 2 array with [NA, Valid]"""
   62:     return SparseArray([np.nan, 1], fill_value=request.param)
   63: 
   64: 
   65: @pytest.fixture(params=[0, np.nan])
   66: def data_repeated(request):
   67:     """Return different versions of data for count times"""
   68: 
   69:     def gen(count):
   70:         for _ in range(count):
   71:             yield SparseArray(make_data(request.param), fill_value=request.param)
   72: 
   73:     yield gen
   74: 
   75: 
   76: @pytest.fixture(params=[0, np.nan])
   77: def data_for_sorting(request):
   78:     return SparseArray([2, 3, 1], fill_value=request.param)
   79: 
   80: 
   81: @pytest.fixture(params=[0, np.nan])
   82: def data_missing_for_sorting(request):
   83:     return SparseArray([2, np.nan, 1], fill_value=request.param)
   84: 
   85: 
   86: @pytest.fixture
   87: def na_cmp():
   88:     return lambda left, right: pd.isna(left) and pd.isna(right)
   89: 
   90: 
   91: @pytest.fixture(params=[0, np.nan])
   92: def data_for_grouping(request):
   93:     return SparseArray([1, 1, np.nan, np.nan, 2, 2, 1, 3], fill_value=request.param)
   94: 
   95: 
   96: @pytest.fixture(params=[0, np.nan])
   97: def data_for_compare(request):
   98:     return SparseArray([0, 0, np.nan, -2, -1, 4, 2, 3, 0, 0], fill_value=request.param)
   99: 
  100: 
  101: class TestSparseArray(base.ExtensionTests):
  102:     def _supports_reduction(self, obj, op_name: str) -> bool:
  103:         return True
  104: 
  105:     @pytest.mark.parametrize("skipna", [True, False])
  106:     def test_reduce_series_numeric(self, data, all_numeric_reductions, skipna, request):
  107:         if all_numeric_reductions in [
  108:             "prod",
  109:             "median",
  110:             "var",
  111:             "std",
  112:             "sem",
  113:             "skew",
  114:             "kurt",
  115:         ]:
  116:             mark = pytest.mark.xfail(
  117:                 reason="This should be viable but is not implemented"
  118:             )
  119:             request.node.add_marker(mark)
  120:         elif (
  121:             all_numeric_reductions in ["sum", "max", "min", "mean"]
  122:             and data.dtype.kind == "f"
  123:             and not skipna
  124:         ):
  125:             mark = pytest.mark.xfail(reason="getting a non-nan float")
  126:             request.node.add_marker(mark)
  127: 
  128:         super().test_reduce_series_numeric(data, all_numeric_reductions, skipna)
  129: 
  130:     @pytest.mark.parametrize("skipna", [True, False])
  131:     def test_reduce_frame(self, data, all_numeric_reductions, skipna, request):
  132:         if all_numeric_reductions in [
  133:             "prod",
  134:             "median",
  135:             "var",
  136:             "std",
  137:             "sem",
  138:             "skew",
  139:             "kurt",
  140:         ]:
  141:             mark = pytest.mark.xfail(
  142:                 reason="This should be viable but is not implemented"
  143:             )
  144:             request.node.add_marker(mark)
  145:         elif (
  146:             all_numeric_reductions in ["sum", "max", "min", "mean"]
  147:             and data.dtype.kind == "f"
  148:             and not skipna
  149:         ):
  150:             mark = pytest.mark.xfail(reason="ExtensionArray NA mask are different")
  151:             request.node.add_marker(mark)
  152: 
  153:         super().test_reduce_frame(data, all_numeric_reductions, skipna)
  154: 
  155:     def _check_unsupported(self, data):
  156:         if data.dtype == SparseDtype(int, 0):
  157:             pytest.skip("Can't store nan in int array.")
  158: 
  159:     def test_concat_mixed_dtypes(self, data):
  160:         # https://github.com/pandas-dev/pandas/issues/20762
  161:         # This should be the same, aside from concat([sparse, float])
  162:         df1 = pd.DataFrame({"A": data[:3]})
  163:         df2 = pd.DataFrame({"A": [1, 2, 3]})
  164:         df3 = pd.DataFrame({"A": ["a", "b", "c"]}).astype("category")
  165:         dfs = [df1, df2, df3]
  166: 
  167:         # dataframes
  168:         result = pd.concat(dfs)
  169:         expected = pd.concat(
  170:             [x.apply(lambda s: np.asarray(s).astype(object)) for x in dfs]
  171:         )
  172:         tm.assert_frame_equal(result, expected)
  173: 
  174:     @pytest.mark.filterwarnings(
  175:         "ignore:The previous implementation of stack is deprecated"
  176:     )
  177:     @pytest.mark.parametrize(
  178:         "columns",
  179:         [
  180:             ["A", "B"],
  181:             pd.MultiIndex.from_tuples(
  182:                 [("A", "a"), ("A", "b")], names=["outer", "inner"]
  183:             ),
  184:         ],
  185:     )
  186:     @pytest.mark.parametrize("future_stack", [True, False])
  187:     def test_stack(self, data, columns, future_stack):
  188:         super().test_stack(data, columns, future_stack)
  189: 
  190:     def test_concat_columns(self, data, na_value):
  191:         self._check_unsupported(data)
  192:         super().test_concat_columns(data, na_value)
  193: 
  194:     def test_concat_extension_arrays_copy_false(self, data, na_value):
  195:         self._check_unsupported(data)
  196:         super().test_concat_extension_arrays_copy_false(data, na_value)
  197: 
  198:     def test_align(self, data, na_value):
  199:         self._check_unsupported(data)
  200:         super().test_align(data, na_value)
  201: 
  202:     def test_align_frame(self, data, na_value):
  203:         self._check_unsupported(data)
  204:         super().test_align_frame(data, na_value)
  205: 
  206:     def test_align_series_frame(self, data, na_value):
  207:         self._check_unsupported(data)
  208:         super().test_align_series_frame(data, na_value)
  209: 
  210:     def test_merge(self, data, na_value):
  211:         self._check_unsupported(data)
  212:         super().test_merge(data, na_value)
  213: 
  214:     def test_get(self, data):
  215:         ser = pd.Series(data, index=[2 * i for i in range(len(data))])
  216:         if np.isnan(ser.values.fill_value):
  217:             assert np.isnan(ser.get(4)) and np.isnan(ser.iloc[2])
  218:         else:
  219:             assert ser.get(4) == ser.iloc[2]
  220:         assert ser.get(2) == ser.iloc[1]
  221: 
  222:     def test_reindex(self, data, na_value):
  223:         self._check_unsupported(data)
  224:         super().test_reindex(data, na_value)
  225: 
  226:     def test_isna(self, data_missing):
  227:         sarr = SparseArray(data_missing)
  228:         expected_dtype = SparseDtype(bool, pd.isna(data_missing.dtype.fill_value))
  229:         expected = SparseArray([True, False], dtype=expected_dtype)
  230:         result = sarr.isna()
  231:         tm.assert_sp_array_equal(result, expected)
  232: 
  233:         # test isna for arr without na
  234:         sarr = sarr.fillna(0)
  235:         expected_dtype = SparseDtype(bool, pd.isna(data_missing.dtype.fill_value))
  236:         expected = SparseArray([False, False], fill_value=False, dtype=expected_dtype)
  237:         tm.assert_equal(sarr.isna(), expected)
  238: 
  239:     def test_fillna_limit_backfill(self, data_missing):
  240:         warns = (PerformanceWarning, FutureWarning)
  241:         with tm.assert_produces_warning(warns, check_stacklevel=False):
  242:             super().test_fillna_limit_backfill(data_missing)
  243: 
  244:     def test_fillna_no_op_returns_copy(self, data, request):
  245:         if np.isnan(data.fill_value):
  246:             request.applymarker(
  247:                 pytest.mark.xfail(reason="returns array with different fill value")
  248:             )
  249:         super().test_fillna_no_op_returns_copy(data)
  250: 
  251:     @pytest.mark.xfail(reason="Unsupported")
  252:     def test_fillna_series(self, data_missing):
  253:         # this one looks doable.
  254:         # TODO: this fails bc we do not pass through data_missing. If we did,
  255:         #  the 0-fill case would xpass
  256:         super().test_fillna_series()
  257: 
  258:     def test_fillna_frame(self, data_missing):
  259:         # Have to override to specify that fill_value will change.
  260:         fill_value = data_missing[1]
  261: 
  262:         result = pd.DataFrame({"A": data_missing, "B": [1, 2]}).fillna(fill_value)
  263: 
  264:         if pd.isna(data_missing.fill_value):
  265:             dtype = SparseDtype(data_missing.dtype, fill_value)
  266:         else:
  267:             dtype = data_missing.dtype
  268: 
  269:         expected = pd.DataFrame(
  270:             {
  271:                 "A": data_missing._from_sequence([fill_value, fill_value], dtype=dtype),
  272:                 "B": [1, 2],
  273:             }
  274:         )
  275: 
  276:         tm.assert_frame_equal(result, expected)
  277: 
  278:     _combine_le_expected_dtype = "Sparse[bool]"
  279: 
  280:     def test_fillna_copy_frame(self, data_missing, using_copy_on_write):
  281:         arr = data_missing.take([1, 1])
  282:         df = pd.DataFrame({"A": arr}, copy=False)
  283: 
  284:         filled_val = df.iloc[0, 0]
  285:         result = df.fillna(filled_val)
  286: 
  287:         if hasattr(df._mgr, "blocks"):
  288:             if using_copy_on_write:
  289:                 assert df.values.base is result.values.base
  290:             else:
  291:                 assert df.values.base is not result.values.base
  292:         assert df.A._values.to_dense() is arr.to_dense()
  293: 
  294:     def test_fillna_copy_series(self, data_missing, using_copy_on_write):
  295:         arr = data_missing.take([1, 1])
  296:         ser = pd.Series(arr, copy=False)
  297: 
  298:         filled_val = ser[0]
  299:         result = ser.fillna(filled_val)
  300: 
  301:         if using_copy_on_write:
  302:             assert ser._values is result._values
  303: 
  304:         else:
  305:             assert ser._values is not result._values
  306:         assert ser._values.to_dense() is arr.to_dense()
  307: 
  308:     @pytest.mark.xfail(reason="Not Applicable")
  309:     def test_fillna_length_mismatch(self, data_missing):
  310:         super().test_fillna_length_mismatch(data_missing)
  311: 
  312:     def test_where_series(self, data, na_value):
  313:         assert data[0] != data[1]
  314:         cls = type(data)
  315:         a, b = data[:2]
  316: 
  317:         ser = pd.Series(cls._from_sequence([a, a, b, b], dtype=data.dtype))
  318: 
  319:         cond = np.array([True, True, False, False])
  320:         result = ser.where(cond)
  321: 
  322:         new_dtype = SparseDtype("float", 0.0)
  323:         expected = pd.Series(
  324:             cls._from_sequence([a, a, na_value, na_value], dtype=new_dtype)
  325:         )
  326:         tm.assert_series_equal(result, expected)
  327: 
  328:         other = cls._from_sequence([a, b, a, b], dtype=data.dtype)
  329:         cond = np.array([True, False, True, True])
  330:         result = ser.where(cond, other)
  331:         expected = pd.Series(cls._from_sequence([a, b, b, b], dtype=data.dtype))
  332:         tm.assert_series_equal(result, expected)
  333: 
  334:     def test_searchsorted(self, data_for_sorting, as_series):
  335:         with tm.assert_produces_warning(PerformanceWarning, check_stacklevel=False):
  336:             super().test_searchsorted(data_for_sorting, as_series)
  337: 
  338:     def test_shift_0_periods(self, data):
  339:         # GH#33856 shifting with periods=0 should return a copy, not same obj
  340:         result = data.shift(0)
  341: 
  342:         data._sparse_values[0] = data._sparse_values[1]
  343:         assert result._sparse_values[0] != result._sparse_values[1]
  344: 
  345:     @pytest.mark.parametrize("method", ["argmax", "argmin"])
  346:     def test_argmin_argmax_all_na(self, method, data, na_value):
  347:         # overriding because Sparse[int64, 0] cannot handle na_value
  348:         self._check_unsupported(data)
  349:         super().test_argmin_argmax_all_na(method, data, na_value)
  350: 
  351:     @pytest.mark.parametrize("box", [pd.array, pd.Series, pd.DataFrame])
  352:     def test_equals(self, data, na_value, as_series, box):
  353:         self._check_unsupported(data)
  354:         super().test_equals(data, na_value, as_series, box)
  355: 
  356:     @pytest.mark.parametrize(
  357:         "func, na_action, expected",
  358:         [
  359:             (lambda x: x, None, SparseArray([1.0, np.nan])),
  360:             (lambda x: x, "ignore", SparseArray([1.0, np.nan])),
  361:             (str, None, SparseArray(["1.0", "nan"], fill_value="nan")),
  362:             (str, "ignore", SparseArray(["1.0", np.nan])),
  363:         ],
  364:     )
  365:     def test_map(self, func, na_action, expected):
  366:         # GH52096
  367:         data = SparseArray([1, np.nan])
  368:         result = data.map(func, na_action=na_action)
  369:         tm.assert_extension_array_equal(result, expected)
  370: 
  371:     @pytest.mark.parametrize("na_action", [None, "ignore"])
  372:     def test_map_raises(self, data, na_action):
  373:         # GH52096
  374:         msg = "fill value in the sparse values not supported"
  375:         with pytest.raises(ValueError, match=msg):
  376:             data.map(lambda x: np.nan, na_action=na_action)
  377: 
  378:     @pytest.mark.xfail(raises=TypeError, reason="no sparse StringDtype")
  379:     def test_astype_string(self, data, nullable_string_dtype):
  380:         # TODO: this fails bc we do not pass through nullable_string_dtype;
  381:         #  If we did, the 0-cases would xpass
  382:         super().test_astype_string(data)
  383: 
  384:     series_scalar_exc = None
  385:     frame_scalar_exc = None
  386:     divmod_exc = None
  387:     series_array_exc = None
  388: 
  389:     def _skip_if_different_combine(self, data):
  390:         if data.fill_value == 0:
  391:             # arith ops call on dtype.fill_value so that the sparsity
  392:             # is maintained. Combine can't be called on a dtype in
  393:             # general, so we can't make the expected. This is tested elsewhere
  394:             pytest.skip("Incorrected expected from Series.combine and tested elsewhere")
  395: 
  396:     def test_arith_series_with_scalar(self, data, all_arithmetic_operators):
  397:         self._skip_if_different_combine(data)
  398:         super().test_arith_series_with_scalar(data, all_arithmetic_operators)
  399: 
  400:     def test_arith_series_with_array(self, data, all_arithmetic_operators):
  401:         self._skip_if_different_combine(data)
  402:         super().test_arith_series_with_array(data, all_arithmetic_operators)
  403: 
  404:     def test_arith_frame_with_scalar(self, data, all_arithmetic_operators, request):
  405:         if data.dtype.fill_value != 0:
  406:             pass
  407:         elif all_arithmetic_operators.strip("_") not in [
  408:             "mul",
  409:             "rmul",
  410:             "floordiv",
  411:             "rfloordiv",
  412:             "pow",
  413:             "mod",
  414:             "rmod",
  415:         ]:
  416:             mark = pytest.mark.xfail(reason="result dtype.fill_value mismatch")
  417:             request.applymarker(mark)
  418:         super().test_arith_frame_with_scalar(data, all_arithmetic_operators)
  419: 
  420:     def _compare_other(
  421:         self, ser: pd.Series, data_for_compare: SparseArray, comparison_op, other
  422:     ):
  423:         op = comparison_op
  424: 
  425:         result = op(data_for_compare, other)
  426:         if isinstance(other, pd.Series):
  427:             assert isinstance(result, pd.Series)
  428:             assert isinstance(result.dtype, SparseDtype)
  429:         else:
  430:             assert isinstance(result, SparseArray)
  431:         assert result.dtype.subtype == np.bool_
  432: 
  433:         if isinstance(other, pd.Series):
  434:             fill_value = op(data_for_compare.fill_value, other._values.fill_value)
  435:             expected = SparseArray(
  436:                 op(data_for_compare.to_dense(), np.asarray(other)),
  437:                 fill_value=fill_value,
  438:                 dtype=np.bool_,
  439:             )
  440: 
  441:         else:
  442:             fill_value = np.all(
  443:                 op(np.asarray(data_for_compare.fill_value), np.asarray(other))
  444:             )
  445: 
  446:             expected = SparseArray(
  447:                 op(data_for_compare.to_dense(), np.asarray(other)),
  448:                 fill_value=fill_value,
  449:                 dtype=np.bool_,
  450:             )
  451:         if isinstance(other, pd.Series):
  452:             # error: Incompatible types in assignment
  453:             expected = pd.Series(expected)  # type: ignore[assignment]
  454:         tm.assert_equal(result, expected)
  455: 
  456:     def test_scalar(self, data_for_compare: SparseArray, comparison_op):
  457:         ser = pd.Series(data_for_compare)
  458:         self._compare_other(ser, data_for_compare, comparison_op, 0)
  459:         self._compare_other(ser, data_for_compare, comparison_op, 1)
  460:         self._compare_other(ser, data_for_compare, comparison_op, -1)
  461:         self._compare_other(ser, data_for_compare, comparison_op, np.nan)
  462: 
  463:     def test_array(self, data_for_compare: SparseArray, comparison_op, request):
  464:         if data_for_compare.dtype.fill_value == 0 and comparison_op.__name__ in [
  465:             "eq",
  466:             "ge",
  467:             "le",
  468:         ]:
  469:             mark = pytest.mark.xfail(reason="Wrong fill_value")
  470:             request.applymarker(mark)
  471: 
  472:         arr = np.linspace(-4, 5, 10)
  473:         ser = pd.Series(data_for_compare)
  474:         self._compare_other(ser, data_for_compare, comparison_op, arr)
  475: 
  476:     def test_sparse_array(self, data_for_compare: SparseArray, comparison_op, request):
  477:         if data_for_compare.dtype.fill_value == 0 and comparison_op.__name__ != "gt":
  478:             mark = pytest.mark.xfail(reason="Wrong fill_value")
  479:             request.applymarker(mark)
  480: 
  481:         ser = pd.Series(data_for_compare)
  482:         arr = data_for_compare + 1
  483:         self._compare_other(ser, data_for_compare, comparison_op, arr)
  484:         arr = data_for_compare * 2
  485:         self._compare_other(ser, data_for_compare, comparison_op, arr)
  486: 
  487:     @pytest.mark.xfail(reason="Different repr")
  488:     def test_array_repr(self, data, size):
  489:         super().test_array_repr(data, size)
  490: 
  491:     @pytest.mark.xfail(reason="result does not match expected")
  492:     @pytest.mark.parametrize("as_index", [True, False])
  493:     def test_groupby_extension_agg(self, as_index, data_for_grouping):
  494:         super().test_groupby_extension_agg(as_index, data_for_grouping)
  495: 
  496: 
  497: def test_array_type_with_arg(dtype):
  498:     assert dtype.construct_array_type() is SparseArray
