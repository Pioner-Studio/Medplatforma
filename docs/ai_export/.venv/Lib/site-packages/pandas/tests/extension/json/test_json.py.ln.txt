    1: import collections
    2: import operator
    3: import sys
    4: 
    5: import numpy as np
    6: import pytest
    7: 
    8: import pandas as pd
    9: import pandas._testing as tm
   10: from pandas.tests.extension import base
   11: from pandas.tests.extension.json.array import (
   12:     JSONArray,
   13:     JSONDtype,
   14:     make_data,
   15: )
   16: 
   17: # We intentionally don't run base.BaseSetitemTests because pandas'
   18: # internals has trouble setting sequences of values into scalar positions.
   19: unhashable = pytest.mark.xfail(reason="Unhashable")
   20: 
   21: 
   22: @pytest.fixture
   23: def dtype():
   24:     return JSONDtype()
   25: 
   26: 
   27: @pytest.fixture
   28: def data():
   29:     """Length-100 PeriodArray for semantics test."""
   30:     data = make_data()
   31: 
   32:     # Why the while loop? NumPy is unable to construct an ndarray from
   33:     # equal-length ndarrays. Many of our operations involve coercing the
   34:     # EA to an ndarray of objects. To avoid random test failures, we ensure
   35:     # that our data is coercible to an ndarray. Several tests deal with only
   36:     # the first two elements, so that's what we'll check.
   37: 
   38:     while len(data[0]) == len(data[1]):
   39:         data = make_data()
   40: 
   41:     return JSONArray(data)
   42: 
   43: 
   44: @pytest.fixture
   45: def data_missing():
   46:     """Length 2 array with [NA, Valid]"""
   47:     return JSONArray([{}, {"a": 10}])
   48: 
   49: 
   50: @pytest.fixture
   51: def data_for_sorting():
   52:     return JSONArray([{"b": 1}, {"c": 4}, {"a": 2, "c": 3}])
   53: 
   54: 
   55: @pytest.fixture
   56: def data_missing_for_sorting():
   57:     return JSONArray([{"b": 1}, {}, {"a": 4}])
   58: 
   59: 
   60: @pytest.fixture
   61: def na_cmp():
   62:     return operator.eq
   63: 
   64: 
   65: @pytest.fixture
   66: def data_for_grouping():
   67:     return JSONArray(
   68:         [
   69:             {"b": 1},
   70:             {"b": 1},
   71:             {},
   72:             {},
   73:             {"a": 0, "c": 2},
   74:             {"a": 0, "c": 2},
   75:             {"b": 1},
   76:             {"c": 2},
   77:         ]
   78:     )
   79: 
   80: 
   81: class TestJSONArray(base.ExtensionTests):
   82:     @pytest.mark.xfail(
   83:         reason="comparison method not implemented for JSONArray (GH-37867)"
   84:     )
   85:     def test_contains(self, data):
   86:         # GH-37867
   87:         super().test_contains(data)
   88: 
   89:     @pytest.mark.xfail(reason="not implemented constructor from dtype")
   90:     def test_from_dtype(self, data):
   91:         # construct from our dtype & string dtype
   92:         super().test_from_dtype(data)
   93: 
   94:     @pytest.mark.xfail(reason="RecursionError, GH-33900")
   95:     def test_series_constructor_no_data_with_index(self, dtype, na_value):
   96:         # RecursionError: maximum recursion depth exceeded in comparison
   97:         rec_limit = sys.getrecursionlimit()
   98:         try:
   99:             # Limit to avoid stack overflow on Windows CI
  100:             sys.setrecursionlimit(100)
  101:             super().test_series_constructor_no_data_with_index(dtype, na_value)
  102:         finally:
  103:             sys.setrecursionlimit(rec_limit)
  104: 
  105:     @pytest.mark.xfail(reason="RecursionError, GH-33900")
  106:     def test_series_constructor_scalar_na_with_index(self, dtype, na_value):
  107:         # RecursionError: maximum recursion depth exceeded in comparison
  108:         rec_limit = sys.getrecursionlimit()
  109:         try:
  110:             # Limit to avoid stack overflow on Windows CI
  111:             sys.setrecursionlimit(100)
  112:             super().test_series_constructor_scalar_na_with_index(dtype, na_value)
  113:         finally:
  114:             sys.setrecursionlimit(rec_limit)
  115: 
  116:     @pytest.mark.xfail(reason="collection as scalar, GH-33901")
  117:     def test_series_constructor_scalar_with_index(self, data, dtype):
  118:         # TypeError: All values must be of type <class 'collections.abc.Mapping'>
  119:         rec_limit = sys.getrecursionlimit()
  120:         try:
  121:             # Limit to avoid stack overflow on Windows CI
  122:             sys.setrecursionlimit(100)
  123:             super().test_series_constructor_scalar_with_index(data, dtype)
  124:         finally:
  125:             sys.setrecursionlimit(rec_limit)
  126: 
  127:     @pytest.mark.xfail(reason="Different definitions of NA")
  128:     def test_stack(self):
  129:         """
  130:         The test does .astype(object).stack(future_stack=True). If we happen to have
  131:         any missing values in `data`, then we'll end up with different
  132:         rows since we consider `{}` NA, but `.astype(object)` doesn't.
  133:         """
  134:         super().test_stack()
  135: 
  136:     @pytest.mark.xfail(reason="dict for NA")
  137:     def test_unstack(self, data, index):
  138:         # The base test has NaN for the expected NA value.
  139:         # this matches otherwise
  140:         return super().test_unstack(data, index)
  141: 
  142:     @pytest.mark.xfail(reason="Setting a dict as a scalar")
  143:     def test_fillna_series(self):
  144:         """We treat dictionaries as a mapping in fillna, not a scalar."""
  145:         super().test_fillna_series()
  146: 
  147:     @pytest.mark.xfail(reason="Setting a dict as a scalar")
  148:     def test_fillna_frame(self):
  149:         """We treat dictionaries as a mapping in fillna, not a scalar."""
  150:         super().test_fillna_frame()
  151: 
  152:     @pytest.mark.parametrize(
  153:         "limit_area, input_ilocs, expected_ilocs",
  154:         [
  155:             ("outside", [1, 0, 0, 0, 1], [1, 0, 0, 0, 1]),
  156:             ("outside", [1, 0, 1, 0, 1], [1, 0, 1, 0, 1]),
  157:             ("outside", [0, 1, 1, 1, 0], [0, 1, 1, 1, 1]),
  158:             ("outside", [0, 1, 0, 1, 0], [0, 1, 0, 1, 1]),
  159:             ("inside", [1, 0, 0, 0, 1], [1, 1, 1, 1, 1]),
  160:             ("inside", [1, 0, 1, 0, 1], [1, 1, 1, 1, 1]),
  161:             ("inside", [0, 1, 1, 1, 0], [0, 1, 1, 1, 0]),
  162:             ("inside", [0, 1, 0, 1, 0], [0, 1, 1, 1, 0]),
  163:         ],
  164:     )
  165:     def test_ffill_limit_area(
  166:         self, data_missing, limit_area, input_ilocs, expected_ilocs
  167:     ):
  168:         # GH#56616
  169:         msg = "JSONArray does not implement limit_area"
  170:         with pytest.raises(NotImplementedError, match=msg):
  171:             super().test_ffill_limit_area(
  172:                 data_missing, limit_area, input_ilocs, expected_ilocs
  173:             )
  174: 
  175:     @unhashable
  176:     def test_value_counts(self, all_data, dropna):
  177:         super().test_value_counts(all_data, dropna)
  178: 
  179:     @unhashable
  180:     def test_value_counts_with_normalize(self, data):
  181:         super().test_value_counts_with_normalize(data)
  182: 
  183:     @unhashable
  184:     def test_sort_values_frame(self):
  185:         # TODO (EA.factorize): see if _values_for_factorize allows this.
  186:         super().test_sort_values_frame()
  187: 
  188:     @pytest.mark.parametrize("ascending", [True, False])
  189:     def test_sort_values(self, data_for_sorting, ascending, sort_by_key):
  190:         super().test_sort_values(data_for_sorting, ascending, sort_by_key)
  191: 
  192:     @pytest.mark.parametrize("ascending", [True, False])
  193:     def test_sort_values_missing(
  194:         self, data_missing_for_sorting, ascending, sort_by_key
  195:     ):
  196:         super().test_sort_values_missing(
  197:             data_missing_for_sorting, ascending, sort_by_key
  198:         )
  199: 
  200:     @pytest.mark.xfail(reason="combine for JSONArray not supported")
  201:     def test_combine_le(self, data_repeated):
  202:         super().test_combine_le(data_repeated)
  203: 
  204:     @pytest.mark.xfail(
  205:         reason="combine for JSONArray not supported - "
  206:         "may pass depending on random data",
  207:         strict=False,
  208:         raises=AssertionError,
  209:     )
  210:     def test_combine_first(self, data):
  211:         super().test_combine_first(data)
  212: 
  213:     @pytest.mark.xfail(reason="broadcasting error")
  214:     def test_where_series(self, data, na_value):
  215:         # Fails with
  216:         # *** ValueError: operands could not be broadcast together
  217:         # with shapes (4,) (4,) (0,)
  218:         super().test_where_series(data, na_value)
  219: 
  220:     @pytest.mark.xfail(reason="Can't compare dicts.")
  221:     def test_searchsorted(self, data_for_sorting):
  222:         super().test_searchsorted(data_for_sorting)
  223: 
  224:     @pytest.mark.xfail(reason="Can't compare dicts.")
  225:     def test_equals(self, data, na_value, as_series):
  226:         super().test_equals(data, na_value, as_series)
  227: 
  228:     @pytest.mark.skip("fill-value is interpreted as a dict of values")
  229:     def test_fillna_copy_frame(self, data_missing):
  230:         super().test_fillna_copy_frame(data_missing)
  231: 
  232:     def test_equals_same_data_different_object(
  233:         self, data, using_copy_on_write, request
  234:     ):
  235:         if using_copy_on_write:
  236:             mark = pytest.mark.xfail(reason="Fails with CoW")
  237:             request.applymarker(mark)
  238:         super().test_equals_same_data_different_object(data)
  239: 
  240:     @pytest.mark.xfail(reason="failing on np.array(self, dtype=str)")
  241:     def test_astype_str(self):
  242:         """This currently fails in NumPy on np.array(self, dtype=str) with
  243: 
  244:         *** ValueError: setting an array element with a sequence
  245:         """
  246:         super().test_astype_str()
  247: 
  248:     @unhashable
  249:     def test_groupby_extension_transform(self):
  250:         """
  251:         This currently fails in Series.name.setter, since the
  252:         name must be hashable, but the value is a dictionary.
  253:         I think this is what we want, i.e. `.name` should be the original
  254:         values, and not the values for factorization.
  255:         """
  256:         super().test_groupby_extension_transform()
  257: 
  258:     @unhashable
  259:     def test_groupby_extension_apply(self):
  260:         """
  261:         This fails in Index._do_unique_check with
  262: 
  263:         >   hash(val)
  264:         E   TypeError: unhashable type: 'UserDict' with
  265: 
  266:         I suspect that once we support Index[ExtensionArray],
  267:         we'll be able to dispatch unique.
  268:         """
  269:         super().test_groupby_extension_apply()
  270: 
  271:     @unhashable
  272:     def test_groupby_extension_agg(self):
  273:         """
  274:         This fails when we get to tm.assert_series_equal when left.index
  275:         contains dictionaries, which are not hashable.
  276:         """
  277:         super().test_groupby_extension_agg()
  278: 
  279:     @unhashable
  280:     def test_groupby_extension_no_sort(self):
  281:         """
  282:         This fails when we get to tm.assert_series_equal when left.index
  283:         contains dictionaries, which are not hashable.
  284:         """
  285:         super().test_groupby_extension_no_sort()
  286: 
  287:     def test_arith_frame_with_scalar(self, data, all_arithmetic_operators, request):
  288:         if len(data[0]) != 1:
  289:             mark = pytest.mark.xfail(reason="raises in coercing to Series")
  290:             request.applymarker(mark)
  291:         super().test_arith_frame_with_scalar(data, all_arithmetic_operators)
  292: 
  293:     def test_compare_array(self, data, comparison_op, request):
  294:         if comparison_op.__name__ in ["eq", "ne"]:
  295:             mark = pytest.mark.xfail(reason="Comparison methods not implemented")
  296:             request.applymarker(mark)
  297:         super().test_compare_array(data, comparison_op)
  298: 
  299:     @pytest.mark.xfail(reason="ValueError: Must have equal len keys and value")
  300:     def test_setitem_loc_scalar_mixed(self, data):
  301:         super().test_setitem_loc_scalar_mixed(data)
  302: 
  303:     @pytest.mark.xfail(reason="ValueError: Must have equal len keys and value")
  304:     def test_setitem_loc_scalar_multiple_homogoneous(self, data):
  305:         super().test_setitem_loc_scalar_multiple_homogoneous(data)
  306: 
  307:     @pytest.mark.xfail(reason="ValueError: Must have equal len keys and value")
  308:     def test_setitem_iloc_scalar_mixed(self, data):
  309:         super().test_setitem_iloc_scalar_mixed(data)
  310: 
  311:     @pytest.mark.xfail(reason="ValueError: Must have equal len keys and value")
  312:     def test_setitem_iloc_scalar_multiple_homogoneous(self, data):
  313:         super().test_setitem_iloc_scalar_multiple_homogoneous(data)
  314: 
  315:     @pytest.mark.parametrize(
  316:         "mask",
  317:         [
  318:             np.array([True, True, True, False, False]),
  319:             pd.array([True, True, True, False, False], dtype="boolean"),
  320:             pd.array([True, True, True, pd.NA, pd.NA], dtype="boolean"),
  321:         ],
  322:         ids=["numpy-array", "boolean-array", "boolean-array-na"],
  323:     )
  324:     def test_setitem_mask(self, data, mask, box_in_series, request):
  325:         if box_in_series:
  326:             mark = pytest.mark.xfail(
  327:                 reason="cannot set using a list-like indexer with a different length"
  328:             )
  329:             request.applymarker(mark)
  330:         elif not isinstance(mask, np.ndarray):
  331:             mark = pytest.mark.xfail(reason="Issues unwanted DeprecationWarning")
  332:             request.applymarker(mark)
  333:         super().test_setitem_mask(data, mask, box_in_series)
  334: 
  335:     def test_setitem_mask_raises(self, data, box_in_series, request):
  336:         if not box_in_series:
  337:             mark = pytest.mark.xfail(reason="Fails to raise")
  338:             request.applymarker(mark)
  339: 
  340:         super().test_setitem_mask_raises(data, box_in_series)
  341: 
  342:     @pytest.mark.xfail(
  343:         reason="cannot set using a list-like indexer with a different length"
  344:     )
  345:     def test_setitem_mask_boolean_array_with_na(self, data, box_in_series):
  346:         super().test_setitem_mask_boolean_array_with_na(data, box_in_series)
  347: 
  348:     @pytest.mark.parametrize(
  349:         "idx",
  350:         [[0, 1, 2], pd.array([0, 1, 2], dtype="Int64"), np.array([0, 1, 2])],
  351:         ids=["list", "integer-array", "numpy-array"],
  352:     )
  353:     def test_setitem_integer_array(self, data, idx, box_in_series, request):
  354:         if box_in_series:
  355:             mark = pytest.mark.xfail(
  356:                 reason="cannot set using a list-like indexer with a different length"
  357:             )
  358:             request.applymarker(mark)
  359:         super().test_setitem_integer_array(data, idx, box_in_series)
  360: 
  361:     @pytest.mark.xfail(reason="list indices must be integers or slices, not NAType")
  362:     @pytest.mark.parametrize(
  363:         "idx, box_in_series",
  364:         [
  365:             ([0, 1, 2, pd.NA], False),
  366:             pytest.param(
  367:                 [0, 1, 2, pd.NA], True, marks=pytest.mark.xfail(reason="GH-31948")
  368:             ),
  369:             (pd.array([0, 1, 2, pd.NA], dtype="Int64"), False),
  370:             (pd.array([0, 1, 2, pd.NA], dtype="Int64"), False),
  371:         ],
  372:         ids=["list-False", "list-True", "integer-array-False", "integer-array-True"],
  373:     )
  374:     def test_setitem_integer_with_missing_raises(self, data, idx, box_in_series):
  375:         super().test_setitem_integer_with_missing_raises(data, idx, box_in_series)
  376: 
  377:     @pytest.mark.xfail(reason="Fails to raise")
  378:     def test_setitem_scalar_key_sequence_raise(self, data):
  379:         super().test_setitem_scalar_key_sequence_raise(data)
  380: 
  381:     def test_setitem_with_expansion_dataframe_column(self, data, full_indexer, request):
  382:         if "full_slice" in request.node.name:
  383:             mark = pytest.mark.xfail(reason="slice is not iterable")
  384:             request.applymarker(mark)
  385:         super().test_setitem_with_expansion_dataframe_column(data, full_indexer)
  386: 
  387:     @pytest.mark.xfail(reason="slice is not iterable")
  388:     def test_setitem_frame_2d_values(self, data):
  389:         super().test_setitem_frame_2d_values(data)
  390: 
  391:     @pytest.mark.xfail(
  392:         reason="cannot set using a list-like indexer with a different length"
  393:     )
  394:     @pytest.mark.parametrize("setter", ["loc", None])
  395:     def test_setitem_mask_broadcast(self, data, setter):
  396:         super().test_setitem_mask_broadcast(data, setter)
  397: 
  398:     @pytest.mark.xfail(
  399:         reason="cannot set using a slice indexer with a different length"
  400:     )
  401:     def test_setitem_slice(self, data, box_in_series):
  402:         super().test_setitem_slice(data, box_in_series)
  403: 
  404:     @pytest.mark.xfail(reason="slice object is not iterable")
  405:     def test_setitem_loc_iloc_slice(self, data):
  406:         super().test_setitem_loc_iloc_slice(data)
  407: 
  408:     @pytest.mark.xfail(reason="slice object is not iterable")
  409:     def test_setitem_slice_mismatch_length_raises(self, data):
  410:         super().test_setitem_slice_mismatch_length_raises(data)
  411: 
  412:     @pytest.mark.xfail(reason="slice object is not iterable")
  413:     def test_setitem_slice_array(self, data):
  414:         super().test_setitem_slice_array(data)
  415: 
  416:     @pytest.mark.xfail(reason="Fail to raise")
  417:     def test_setitem_invalid(self, data, invalid_scalar):
  418:         super().test_setitem_invalid(data, invalid_scalar)
  419: 
  420:     @pytest.mark.xfail(reason="only integer scalar arrays can be converted")
  421:     def test_setitem_2d_values(self, data):
  422:         super().test_setitem_2d_values(data)
  423: 
  424:     @pytest.mark.xfail(reason="data type 'json' not understood")
  425:     @pytest.mark.parametrize("engine", ["c", "python"])
  426:     def test_EA_types(self, engine, data, request):
  427:         super().test_EA_types(engine, data, request)
  428: 
  429: 
  430: def custom_assert_series_equal(left, right, *args, **kwargs):
  431:     # NumPy doesn't handle an array of equal-length UserDicts.
  432:     # The default assert_series_equal eventually does a
  433:     # Series.values, which raises. We work around it by
  434:     # converting the UserDicts to dicts.
  435:     if left.dtype.name == "json":
  436:         assert left.dtype == right.dtype
  437:         left = pd.Series(
  438:             JSONArray(left.values.astype(object)), index=left.index, name=left.name
  439:         )
  440:         right = pd.Series(
  441:             JSONArray(right.values.astype(object)),
  442:             index=right.index,
  443:             name=right.name,
  444:         )
  445:     tm.assert_series_equal(left, right, *args, **kwargs)
  446: 
  447: 
  448: def custom_assert_frame_equal(left, right, *args, **kwargs):
  449:     obj_type = kwargs.get("obj", "DataFrame")
  450:     tm.assert_index_equal(
  451:         left.columns,
  452:         right.columns,
  453:         exact=kwargs.get("check_column_type", "equiv"),
  454:         check_names=kwargs.get("check_names", True),
  455:         check_exact=kwargs.get("check_exact", False),
  456:         check_categorical=kwargs.get("check_categorical", True),
  457:         obj=f"{obj_type}.columns",
  458:     )
  459: 
  460:     jsons = (left.dtypes == "json").index
  461: 
  462:     for col in jsons:
  463:         custom_assert_series_equal(left[col], right[col], *args, **kwargs)
  464: 
  465:     left = left.drop(columns=jsons)
  466:     right = right.drop(columns=jsons)
  467:     tm.assert_frame_equal(left, right, *args, **kwargs)
  468: 
  469: 
  470: def test_custom_asserts():
  471:     # This would always trigger the KeyError from trying to put
  472:     # an array of equal-length UserDicts inside an ndarray.
  473:     data = JSONArray(
  474:         [
  475:             collections.UserDict({"a": 1}),
  476:             collections.UserDict({"b": 2}),
  477:             collections.UserDict({"c": 3}),
  478:         ]
  479:     )
  480:     a = pd.Series(data)
  481:     custom_assert_series_equal(a, a)
  482:     custom_assert_frame_equal(a.to_frame(), a.to_frame())
  483: 
  484:     b = pd.Series(data.take([0, 0, 1]))
  485:     msg = r"Series are different"
  486:     with pytest.raises(AssertionError, match=msg):
  487:         custom_assert_series_equal(a, b)
  488: 
  489:     with pytest.raises(AssertionError, match=msg):
  490:         custom_assert_frame_equal(a.to_frame(), b.to_frame())
