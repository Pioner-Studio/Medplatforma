    1: import inspect
    2: import operator
    3: 
    4: import numpy as np
    5: import pytest
    6: 
    7: from pandas._typing import Dtype
    8: 
    9: from pandas.core.dtypes.common import is_bool_dtype
   10: from pandas.core.dtypes.dtypes import NumpyEADtype
   11: from pandas.core.dtypes.missing import na_value_for_dtype
   12: 
   13: import pandas as pd
   14: import pandas._testing as tm
   15: from pandas.core.sorting import nargsort
   16: 
   17: 
   18: class BaseMethodsTests:
   19:     """Various Series and DataFrame methods."""
   20: 
   21:     def test_hash_pandas_object(self, data):
   22:         # _hash_pandas_object should return a uint64 ndarray of the same length
   23:         # as the data
   24:         from pandas.core.util.hashing import _default_hash_key
   25: 
   26:         res = data._hash_pandas_object(
   27:             encoding="utf-8", hash_key=_default_hash_key, categorize=False
   28:         )
   29:         assert res.dtype == np.uint64
   30:         assert res.shape == data.shape
   31: 
   32:     def test_value_counts_default_dropna(self, data):
   33:         # make sure we have consistent default dropna kwarg
   34:         if not hasattr(data, "value_counts"):
   35:             pytest.skip(f"value_counts is not implemented for {type(data)}")
   36:         sig = inspect.signature(data.value_counts)
   37:         kwarg = sig.parameters["dropna"]
   38:         assert kwarg.default is True
   39: 
   40:     @pytest.mark.parametrize("dropna", [True, False])
   41:     def test_value_counts(self, all_data, dropna):
   42:         all_data = all_data[:10]
   43:         if dropna:
   44:             other = all_data[~all_data.isna()]
   45:         else:
   46:             other = all_data
   47: 
   48:         result = pd.Series(all_data).value_counts(dropna=dropna).sort_index()
   49:         expected = pd.Series(other).value_counts(dropna=dropna).sort_index()
   50: 
   51:         tm.assert_series_equal(result, expected)
   52: 
   53:     def test_value_counts_with_normalize(self, data):
   54:         # GH 33172
   55:         data = data[:10].unique()
   56:         values = np.array(data[~data.isna()])
   57:         ser = pd.Series(data, dtype=data.dtype)
   58: 
   59:         result = ser.value_counts(normalize=True).sort_index()
   60: 
   61:         if not isinstance(data, pd.Categorical):
   62:             expected = pd.Series(
   63:                 [1 / len(values)] * len(values), index=result.index, name="proportion"
   64:             )
   65:         else:
   66:             expected = pd.Series(0.0, index=result.index, name="proportion")
   67:             expected[result > 0] = 1 / len(values)
   68: 
   69:         if getattr(data.dtype, "storage", "") == "pyarrow" or isinstance(
   70:             data.dtype, pd.ArrowDtype
   71:         ):
   72:             # TODO: avoid special-casing
   73:             expected = expected.astype("double[pyarrow]")
   74:         elif getattr(data.dtype, "storage", "") == "pyarrow_numpy":
   75:             # TODO: avoid special-casing
   76:             expected = expected.astype("float64")
   77:         elif na_value_for_dtype(data.dtype) is pd.NA:
   78:             # TODO(GH#44692): avoid special-casing
   79:             expected = expected.astype("Float64")
   80: 
   81:         tm.assert_series_equal(result, expected)
   82: 
   83:     def test_count(self, data_missing):
   84:         df = pd.DataFrame({"A": data_missing})
   85:         result = df.count(axis="columns")
   86:         expected = pd.Series([0, 1])
   87:         tm.assert_series_equal(result, expected)
   88: 
   89:     def test_series_count(self, data_missing):
   90:         # GH#26835
   91:         ser = pd.Series(data_missing)
   92:         result = ser.count()
   93:         expected = 1
   94:         assert result == expected
   95: 
   96:     def test_apply_simple_series(self, data):
   97:         result = pd.Series(data).apply(id)
   98:         assert isinstance(result, pd.Series)
   99: 
  100:     @pytest.mark.parametrize("na_action", [None, "ignore"])
  101:     def test_map(self, data_missing, na_action):
  102:         result = data_missing.map(lambda x: x, na_action=na_action)
  103:         expected = data_missing.to_numpy()
  104:         tm.assert_numpy_array_equal(result, expected)
  105: 
  106:     def test_argsort(self, data_for_sorting):
  107:         result = pd.Series(data_for_sorting).argsort()
  108:         # argsort result gets passed to take, so should be np.intp
  109:         expected = pd.Series(np.array([2, 0, 1], dtype=np.intp))
  110:         tm.assert_series_equal(result, expected)
  111: 
  112:     def test_argsort_missing_array(self, data_missing_for_sorting):
  113:         result = data_missing_for_sorting.argsort()
  114:         # argsort result gets passed to take, so should be np.intp
  115:         expected = np.array([2, 0, 1], dtype=np.intp)
  116:         tm.assert_numpy_array_equal(result, expected)
  117: 
  118:     def test_argsort_missing(self, data_missing_for_sorting):
  119:         msg = "The behavior of Series.argsort in the presence of NA values"
  120:         with tm.assert_produces_warning(FutureWarning, match=msg):
  121:             result = pd.Series(data_missing_for_sorting).argsort()
  122:         expected = pd.Series(np.array([1, -1, 0], dtype=np.intp))
  123:         tm.assert_series_equal(result, expected)
  124: 
  125:     def test_argmin_argmax(self, data_for_sorting, data_missing_for_sorting, na_value):
  126:         # GH 24382
  127:         is_bool = data_for_sorting.dtype._is_boolean
  128: 
  129:         exp_argmax = 1
  130:         exp_argmax_repeated = 3
  131:         if is_bool:
  132:             # See data_for_sorting docstring
  133:             exp_argmax = 0
  134:             exp_argmax_repeated = 1
  135: 
  136:         # data_for_sorting -> [B, C, A] with A < B < C
  137:         assert data_for_sorting.argmax() == exp_argmax
  138:         assert data_for_sorting.argmin() == 2
  139: 
  140:         # with repeated values -> first occurrence
  141:         data = data_for_sorting.take([2, 0, 0, 1, 1, 2])
  142:         assert data.argmax() == exp_argmax_repeated
  143:         assert data.argmin() == 0
  144: 
  145:         # with missing values
  146:         # data_missing_for_sorting -> [B, NA, A] with A < B and NA missing.
  147:         assert data_missing_for_sorting.argmax() == 0
  148:         assert data_missing_for_sorting.argmin() == 2
  149: 
  150:     @pytest.mark.parametrize("method", ["argmax", "argmin"])
  151:     def test_argmin_argmax_empty_array(self, method, data):
  152:         # GH 24382
  153:         err_msg = "attempt to get"
  154:         with pytest.raises(ValueError, match=err_msg):
  155:             getattr(data[:0], method)()
  156: 
  157:     @pytest.mark.parametrize("method", ["argmax", "argmin"])
  158:     def test_argmin_argmax_all_na(self, method, data, na_value):
  159:         # all missing with skipna=True is the same as empty
  160:         err_msg = "attempt to get"
  161:         data_na = type(data)._from_sequence([na_value, na_value], dtype=data.dtype)
  162:         with pytest.raises(ValueError, match=err_msg):
  163:             getattr(data_na, method)()
  164: 
  165:     @pytest.mark.parametrize(
  166:         "op_name, skipna, expected",
  167:         [
  168:             ("idxmax", True, 0),
  169:             ("idxmin", True, 2),
  170:             ("argmax", True, 0),
  171:             ("argmin", True, 2),
  172:             ("idxmax", False, np.nan),
  173:             ("idxmin", False, np.nan),
  174:             ("argmax", False, -1),
  175:             ("argmin", False, -1),
  176:         ],
  177:     )
  178:     def test_argreduce_series(
  179:         self, data_missing_for_sorting, op_name, skipna, expected
  180:     ):
  181:         # data_missing_for_sorting -> [B, NA, A] with A < B and NA missing.
  182:         warn = None
  183:         msg = "The behavior of Series.argmax/argmin"
  184:         if op_name.startswith("arg") and expected == -1:
  185:             warn = FutureWarning
  186:         if op_name.startswith("idx") and np.isnan(expected):
  187:             warn = FutureWarning
  188:             msg = f"The behavior of Series.{op_name}"
  189:         ser = pd.Series(data_missing_for_sorting)
  190:         with tm.assert_produces_warning(warn, match=msg):
  191:             result = getattr(ser, op_name)(skipna=skipna)
  192:         tm.assert_almost_equal(result, expected)
  193: 
  194:     def test_argmax_argmin_no_skipna_notimplemented(self, data_missing_for_sorting):
  195:         # GH#38733
  196:         data = data_missing_for_sorting
  197: 
  198:         with pytest.raises(NotImplementedError, match=""):
  199:             data.argmin(skipna=False)
  200: 
  201:         with pytest.raises(NotImplementedError, match=""):
  202:             data.argmax(skipna=False)
  203: 
  204:     @pytest.mark.parametrize(
  205:         "na_position, expected",
  206:         [
  207:             ("last", np.array([2, 0, 1], dtype=np.dtype("intp"))),
  208:             ("first", np.array([1, 2, 0], dtype=np.dtype("intp"))),
  209:         ],
  210:     )
  211:     def test_nargsort(self, data_missing_for_sorting, na_position, expected):
  212:         # GH 25439
  213:         result = nargsort(data_missing_for_sorting, na_position=na_position)
  214:         tm.assert_numpy_array_equal(result, expected)
  215: 
  216:     @pytest.mark.parametrize("ascending", [True, False])
  217:     def test_sort_values(self, data_for_sorting, ascending, sort_by_key):
  218:         ser = pd.Series(data_for_sorting)
  219:         result = ser.sort_values(ascending=ascending, key=sort_by_key)
  220:         expected = ser.iloc[[2, 0, 1]]
  221:         if not ascending:
  222:             # GH 35922. Expect stable sort
  223:             if ser.nunique() == 2:
  224:                 expected = ser.iloc[[0, 1, 2]]
  225:             else:
  226:                 expected = ser.iloc[[1, 0, 2]]
  227: 
  228:         tm.assert_series_equal(result, expected)
  229: 
  230:     @pytest.mark.parametrize("ascending", [True, False])
  231:     def test_sort_values_missing(
  232:         self, data_missing_for_sorting, ascending, sort_by_key
  233:     ):
  234:         ser = pd.Series(data_missing_for_sorting)
  235:         result = ser.sort_values(ascending=ascending, key=sort_by_key)
  236:         if ascending:
  237:             expected = ser.iloc[[2, 0, 1]]
  238:         else:
  239:             expected = ser.iloc[[0, 2, 1]]
  240:         tm.assert_series_equal(result, expected)
  241: 
  242:     @pytest.mark.parametrize("ascending", [True, False])
  243:     def test_sort_values_frame(self, data_for_sorting, ascending):
  244:         df = pd.DataFrame({"A": [1, 2, 1], "B": data_for_sorting})
  245:         result = df.sort_values(["A", "B"])
  246:         expected = pd.DataFrame(
  247:             {"A": [1, 1, 2], "B": data_for_sorting.take([2, 0, 1])}, index=[2, 0, 1]
  248:         )
  249:         tm.assert_frame_equal(result, expected)
  250: 
  251:     @pytest.mark.parametrize("keep", ["first", "last", False])
  252:     def test_duplicated(self, data, keep):
  253:         arr = data.take([0, 1, 0, 1])
  254:         result = arr.duplicated(keep=keep)
  255:         if keep == "first":
  256:             expected = np.array([False, False, True, True])
  257:         elif keep == "last":
  258:             expected = np.array([True, True, False, False])
  259:         else:
  260:             expected = np.array([True, True, True, True])
  261:         tm.assert_numpy_array_equal(result, expected)
  262: 
  263:     @pytest.mark.parametrize("box", [pd.Series, lambda x: x])
  264:     @pytest.mark.parametrize("method", [lambda x: x.unique(), pd.unique])
  265:     def test_unique(self, data, box, method):
  266:         duplicated = box(data._from_sequence([data[0], data[0]], dtype=data.dtype))
  267: 
  268:         result = method(duplicated)
  269: 
  270:         assert len(result) == 1
  271:         assert isinstance(result, type(data))
  272:         assert result[0] == duplicated[0]
  273: 
  274:     def test_factorize(self, data_for_grouping):
  275:         codes, uniques = pd.factorize(data_for_grouping, use_na_sentinel=True)
  276: 
  277:         is_bool = data_for_grouping.dtype._is_boolean
  278:         if is_bool:
  279:             # only 2 unique values
  280:             expected_codes = np.array([0, 0, -1, -1, 1, 1, 0, 0], dtype=np.intp)
  281:             expected_uniques = data_for_grouping.take([0, 4])
  282:         else:
  283:             expected_codes = np.array([0, 0, -1, -1, 1, 1, 0, 2], dtype=np.intp)
  284:             expected_uniques = data_for_grouping.take([0, 4, 7])
  285: 
  286:         tm.assert_numpy_array_equal(codes, expected_codes)
  287:         tm.assert_extension_array_equal(uniques, expected_uniques)
  288: 
  289:     def test_factorize_equivalence(self, data_for_grouping):
  290:         codes_1, uniques_1 = pd.factorize(data_for_grouping, use_na_sentinel=True)
  291:         codes_2, uniques_2 = data_for_grouping.factorize(use_na_sentinel=True)
  292: 
  293:         tm.assert_numpy_array_equal(codes_1, codes_2)
  294:         tm.assert_extension_array_equal(uniques_1, uniques_2)
  295:         assert len(uniques_1) == len(pd.unique(uniques_1))
  296:         assert uniques_1.dtype == data_for_grouping.dtype
  297: 
  298:     def test_factorize_empty(self, data):
  299:         codes, uniques = pd.factorize(data[:0])
  300:         expected_codes = np.array([], dtype=np.intp)
  301:         expected_uniques = type(data)._from_sequence([], dtype=data[:0].dtype)
  302: 
  303:         tm.assert_numpy_array_equal(codes, expected_codes)
  304:         tm.assert_extension_array_equal(uniques, expected_uniques)
  305: 
  306:     def test_fillna_copy_frame(self, data_missing):
  307:         arr = data_missing.take([1, 1])
  308:         df = pd.DataFrame({"A": arr})
  309:         df_orig = df.copy()
  310: 
  311:         filled_val = df.iloc[0, 0]
  312:         result = df.fillna(filled_val)
  313: 
  314:         result.iloc[0, 0] = filled_val
  315: 
  316:         tm.assert_frame_equal(df, df_orig)
  317: 
  318:     def test_fillna_copy_series(self, data_missing):
  319:         arr = data_missing.take([1, 1])
  320:         ser = pd.Series(arr, copy=False)
  321:         ser_orig = ser.copy()
  322: 
  323:         filled_val = ser[0]
  324:         result = ser.fillna(filled_val)
  325:         result.iloc[0] = filled_val
  326: 
  327:         tm.assert_series_equal(ser, ser_orig)
  328: 
  329:     def test_fillna_length_mismatch(self, data_missing):
  330:         msg = "Length of 'value' does not match."
  331:         with pytest.raises(ValueError, match=msg):
  332:             data_missing.fillna(data_missing.take([1]))
  333: 
  334:     # Subclasses can override if we expect e.g Sparse[bool], boolean, pyarrow[bool]
  335:     _combine_le_expected_dtype: Dtype = NumpyEADtype("bool")
  336: 
  337:     def test_combine_le(self, data_repeated):
  338:         # GH 20825
  339:         # Test that combine works when doing a <= (le) comparison
  340:         orig_data1, orig_data2 = data_repeated(2)
  341:         s1 = pd.Series(orig_data1)
  342:         s2 = pd.Series(orig_data2)
  343:         result = s1.combine(s2, lambda x1, x2: x1 <= x2)
  344:         expected = pd.Series(
  345:             pd.array(
  346:                 [a <= b for (a, b) in zip(list(orig_data1), list(orig_data2))],
  347:                 dtype=self._combine_le_expected_dtype,
  348:             )
  349:         )
  350:         tm.assert_series_equal(result, expected)
  351: 
  352:         val = s1.iloc[0]
  353:         result = s1.combine(val, lambda x1, x2: x1 <= x2)
  354:         expected = pd.Series(
  355:             pd.array(
  356:                 [a <= val for a in list(orig_data1)],
  357:                 dtype=self._combine_le_expected_dtype,
  358:             )
  359:         )
  360:         tm.assert_series_equal(result, expected)
  361: 
  362:     def test_combine_add(self, data_repeated):
  363:         # GH 20825
  364:         orig_data1, orig_data2 = data_repeated(2)
  365:         s1 = pd.Series(orig_data1)
  366:         s2 = pd.Series(orig_data2)
  367: 
  368:         # Check if the operation is supported pointwise for our scalars. If not,
  369:         #  we will expect Series.combine to raise as well.
  370:         try:
  371:             with np.errstate(over="ignore"):
  372:                 expected = pd.Series(
  373:                     orig_data1._from_sequence(
  374:                         [a + b for (a, b) in zip(list(orig_data1), list(orig_data2))]
  375:                     )
  376:                 )
  377:         except TypeError:
  378:             # If the operation is not supported pointwise for our scalars,
  379:             #  then Series.combine should also raise
  380:             with pytest.raises(TypeError):
  381:                 s1.combine(s2, lambda x1, x2: x1 + x2)
  382:             return
  383: 
  384:         result = s1.combine(s2, lambda x1, x2: x1 + x2)
  385:         tm.assert_series_equal(result, expected)
  386: 
  387:         val = s1.iloc[0]
  388:         result = s1.combine(val, lambda x1, x2: x1 + x2)
  389:         expected = pd.Series(
  390:             orig_data1._from_sequence([a + val for a in list(orig_data1)])
  391:         )
  392:         tm.assert_series_equal(result, expected)
  393: 
  394:     def test_combine_first(self, data):
  395:         # https://github.com/pandas-dev/pandas/issues/24147
  396:         a = pd.Series(data[:3])
  397:         b = pd.Series(data[2:5], index=[2, 3, 4])
  398:         result = a.combine_first(b)
  399:         expected = pd.Series(data[:5])
  400:         tm.assert_series_equal(result, expected)
  401: 
  402:     @pytest.mark.parametrize("frame", [True, False])
  403:     @pytest.mark.parametrize(
  404:         "periods, indices",
  405:         [(-2, [2, 3, 4, -1, -1]), (0, [0, 1, 2, 3, 4]), (2, [-1, -1, 0, 1, 2])],
  406:     )
  407:     def test_container_shift(self, data, frame, periods, indices):
  408:         # https://github.com/pandas-dev/pandas/issues/22386
  409:         subset = data[:5]
  410:         data = pd.Series(subset, name="A")
  411:         expected = pd.Series(subset.take(indices, allow_fill=True), name="A")
  412: 
  413:         if frame:
  414:             result = data.to_frame(name="A").assign(B=1).shift(periods)
  415:             expected = pd.concat(
  416:                 [expected, pd.Series([1] * 5, name="B").shift(periods)], axis=1
  417:             )
  418:             compare = tm.assert_frame_equal
  419:         else:
  420:             result = data.shift(periods)
  421:             compare = tm.assert_series_equal
  422: 
  423:         compare(result, expected)
  424: 
  425:     def test_shift_0_periods(self, data):
  426:         # GH#33856 shifting with periods=0 should return a copy, not same obj
  427:         result = data.shift(0)
  428:         assert data[0] != data[1]  # otherwise below is invalid
  429:         data[0] = data[1]
  430:         assert result[0] != result[1]  # i.e. not the same object/view
  431: 
  432:     @pytest.mark.parametrize("periods", [1, -2])
  433:     def test_diff(self, data, periods):
  434:         data = data[:5]
  435:         if is_bool_dtype(data.dtype):
  436:             op = operator.xor
  437:         else:
  438:             op = operator.sub
  439:         try:
  440:             # does this array implement ops?
  441:             op(data, data)
  442:         except Exception:
  443:             pytest.skip(f"{type(data)} does not support diff")
  444:         s = pd.Series(data)
  445:         result = s.diff(periods)
  446:         expected = pd.Series(op(data, data.shift(periods)))
  447:         tm.assert_series_equal(result, expected)
  448: 
  449:         df = pd.DataFrame({"A": data, "B": [1.0] * 5})
  450:         result = df.diff(periods)
  451:         if periods == 1:
  452:             b = [np.nan, 0, 0, 0, 0]
  453:         else:
  454:             b = [0, 0, 0, np.nan, np.nan]
  455:         expected = pd.DataFrame({"A": expected, "B": b})
  456:         tm.assert_frame_equal(result, expected)
  457: 
  458:     @pytest.mark.parametrize(
  459:         "periods, indices",
  460:         [[-4, [-1, -1]], [-1, [1, -1]], [0, [0, 1]], [1, [-1, 0]], [4, [-1, -1]]],
  461:     )
  462:     def test_shift_non_empty_array(self, data, periods, indices):
  463:         # https://github.com/pandas-dev/pandas/issues/23911
  464:         subset = data[:2]
  465:         result = subset.shift(periods)
  466:         expected = subset.take(indices, allow_fill=True)
  467:         tm.assert_extension_array_equal(result, expected)
  468: 
  469:     @pytest.mark.parametrize("periods", [-4, -1, 0, 1, 4])
  470:     def test_shift_empty_array(self, data, periods):
  471:         # https://github.com/pandas-dev/pandas/issues/23911
  472:         empty = data[:0]
  473:         result = empty.shift(periods)
  474:         expected = empty
  475:         tm.assert_extension_array_equal(result, expected)
  476: 
  477:     def test_shift_zero_copies(self, data):
  478:         # GH#31502
  479:         result = data.shift(0)
  480:         assert result is not data
  481: 
  482:         result = data[:0].shift(2)
  483:         assert result is not data
  484: 
  485:     def test_shift_fill_value(self, data):
  486:         arr = data[:4]
  487:         fill_value = data[0]
  488:         result = arr.shift(1, fill_value=fill_value)
  489:         expected = data.take([0, 0, 1, 2])
  490:         tm.assert_extension_array_equal(result, expected)
  491: 
  492:         result = arr.shift(-2, fill_value=fill_value)
  493:         expected = data.take([2, 3, 0, 0])
  494:         tm.assert_extension_array_equal(result, expected)
  495: 
  496:     def test_not_hashable(self, data):
  497:         # We are in general mutable, so not hashable
  498:         with pytest.raises(TypeError, match="unhashable type"):
  499:             hash(data)
  500: 
  501:     def test_hash_pandas_object_works(self, data, as_frame):
  502:         # https://github.com/pandas-dev/pandas/issues/23066
  503:         data = pd.Series(data)
  504:         if as_frame:
  505:             data = data.to_frame()
  506:         a = pd.util.hash_pandas_object(data)
  507:         b = pd.util.hash_pandas_object(data)
  508:         tm.assert_equal(a, b)
  509: 
  510:     def test_searchsorted(self, data_for_sorting, as_series):
  511:         if data_for_sorting.dtype._is_boolean:
  512:             return self._test_searchsorted_bool_dtypes(data_for_sorting, as_series)
  513: 
  514:         b, c, a = data_for_sorting
  515:         arr = data_for_sorting.take([2, 0, 1])  # to get [a, b, c]
  516: 
  517:         if as_series:
  518:             arr = pd.Series(arr)
  519:         assert arr.searchsorted(a) == 0
  520:         assert arr.searchsorted(a, side="right") == 1
  521: 
  522:         assert arr.searchsorted(b) == 1
  523:         assert arr.searchsorted(b, side="right") == 2
  524: 
  525:         assert arr.searchsorted(c) == 2
  526:         assert arr.searchsorted(c, side="right") == 3
  527: 
  528:         result = arr.searchsorted(arr.take([0, 2]))
  529:         expected = np.array([0, 2], dtype=np.intp)
  530: 
  531:         tm.assert_numpy_array_equal(result, expected)
  532: 
  533:         # sorter
  534:         sorter = np.array([1, 2, 0])
  535:         assert data_for_sorting.searchsorted(a, sorter=sorter) == 0
  536: 
  537:     def _test_searchsorted_bool_dtypes(self, data_for_sorting, as_series):
  538:         # We call this from test_searchsorted in cases where we have a
  539:         #  boolean-like dtype. The non-bool test assumes we have more than 2
  540:         #  unique values.
  541:         dtype = data_for_sorting.dtype
  542:         data_for_sorting = pd.array([True, False], dtype=dtype)
  543:         b, a = data_for_sorting
  544:         arr = type(data_for_sorting)._from_sequence([a, b])
  545: 
  546:         if as_series:
  547:             arr = pd.Series(arr)
  548:         assert arr.searchsorted(a) == 0
  549:         assert arr.searchsorted(a, side="right") == 1
  550: 
  551:         assert arr.searchsorted(b) == 1
  552:         assert arr.searchsorted(b, side="right") == 2
  553: 
  554:         result = arr.searchsorted(arr.take([0, 1]))
  555:         expected = np.array([0, 1], dtype=np.intp)
  556: 
  557:         tm.assert_numpy_array_equal(result, expected)
  558: 
  559:         # sorter
  560:         sorter = np.array([1, 0])
  561:         assert data_for_sorting.searchsorted(a, sorter=sorter) == 0
  562: 
  563:     def test_where_series(self, data, na_value, as_frame):
  564:         assert data[0] != data[1]
  565:         cls = type(data)
  566:         a, b = data[:2]
  567: 
  568:         orig = pd.Series(cls._from_sequence([a, a, b, b], dtype=data.dtype))
  569:         ser = orig.copy()
  570:         cond = np.array([True, True, False, False])
  571: 
  572:         if as_frame:
  573:             ser = ser.to_frame(name="a")
  574:             cond = cond.reshape(-1, 1)
  575: 
  576:         result = ser.where(cond)
  577:         expected = pd.Series(
  578:             cls._from_sequence([a, a, na_value, na_value], dtype=data.dtype)
  579:         )
  580: 
  581:         if as_frame:
  582:             expected = expected.to_frame(name="a")
  583:         tm.assert_equal(result, expected)
  584: 
  585:         ser.mask(~cond, inplace=True)
  586:         tm.assert_equal(ser, expected)
  587: 
  588:         # array other
  589:         ser = orig.copy()
  590:         if as_frame:
  591:             ser = ser.to_frame(name="a")
  592:         cond = np.array([True, False, True, True])
  593:         other = cls._from_sequence([a, b, a, b], dtype=data.dtype)
  594:         if as_frame:
  595:             other = pd.DataFrame({"a": other})
  596:             cond = pd.DataFrame({"a": cond})
  597:         result = ser.where(cond, other)
  598:         expected = pd.Series(cls._from_sequence([a, b, b, b], dtype=data.dtype))
  599:         if as_frame:
  600:             expected = expected.to_frame(name="a")
  601:         tm.assert_equal(result, expected)
  602: 
  603:         ser.mask(~cond, other, inplace=True)
  604:         tm.assert_equal(ser, expected)
  605: 
  606:     @pytest.mark.parametrize("repeats", [0, 1, 2, [1, 2, 3]])
  607:     def test_repeat(self, data, repeats, as_series, use_numpy):
  608:         arr = type(data)._from_sequence(data[:3], dtype=data.dtype)
  609:         if as_series:
  610:             arr = pd.Series(arr)
  611: 
  612:         result = np.repeat(arr, repeats) if use_numpy else arr.repeat(repeats)
  613: 
  614:         repeats = [repeats] * 3 if isinstance(repeats, int) else repeats
  615:         expected = [x for x, n in zip(arr, repeats) for _ in range(n)]
  616:         expected = type(data)._from_sequence(expected, dtype=data.dtype)
  617:         if as_series:
  618:             expected = pd.Series(expected, index=arr.index.repeat(repeats))
  619: 
  620:         tm.assert_equal(result, expected)
  621: 
  622:     @pytest.mark.parametrize(
  623:         "repeats, kwargs, error, msg",
  624:         [
  625:             (2, {"axis": 1}, ValueError, "axis"),
  626:             (-1, {}, ValueError, "negative"),
  627:             ([1, 2], {}, ValueError, "shape"),
  628:             (2, {"foo": "bar"}, TypeError, "'foo'"),
  629:         ],
  630:     )
  631:     def test_repeat_raises(self, data, repeats, kwargs, error, msg, use_numpy):
  632:         with pytest.raises(error, match=msg):
  633:             if use_numpy:
  634:                 np.repeat(data, repeats, **kwargs)
  635:             else:
  636:                 data.repeat(repeats, **kwargs)
  637: 
  638:     def test_delete(self, data):
  639:         result = data.delete(0)
  640:         expected = data[1:]
  641:         tm.assert_extension_array_equal(result, expected)
  642: 
  643:         result = data.delete([1, 3])
  644:         expected = data._concat_same_type([data[[0]], data[[2]], data[4:]])
  645:         tm.assert_extension_array_equal(result, expected)
  646: 
  647:     def test_insert(self, data):
  648:         # insert at the beginning
  649:         result = data[1:].insert(0, data[0])
  650:         tm.assert_extension_array_equal(result, data)
  651: 
  652:         result = data[1:].insert(-len(data[1:]), data[0])
  653:         tm.assert_extension_array_equal(result, data)
  654: 
  655:         # insert at the middle
  656:         result = data[:-1].insert(4, data[-1])
  657: 
  658:         taker = np.arange(len(data))
  659:         taker[5:] = taker[4:-1]
  660:         taker[4] = len(data) - 1
  661:         expected = data.take(taker)
  662:         tm.assert_extension_array_equal(result, expected)
  663: 
  664:     def test_insert_invalid(self, data, invalid_scalar):
  665:         item = invalid_scalar
  666: 
  667:         with pytest.raises((TypeError, ValueError)):
  668:             data.insert(0, item)
  669: 
  670:         with pytest.raises((TypeError, ValueError)):
  671:             data.insert(4, item)
  672: 
  673:         with pytest.raises((TypeError, ValueError)):
  674:             data.insert(len(data) - 1, item)
  675: 
  676:     def test_insert_invalid_loc(self, data):
  677:         ub = len(data)
  678: 
  679:         with pytest.raises(IndexError):
  680:             data.insert(ub + 1, data[0])
  681: 
  682:         with pytest.raises(IndexError):
  683:             data.insert(-ub - 1, data[0])
  684: 
  685:         with pytest.raises(TypeError):
  686:             # we expect TypeError here instead of IndexError to match np.insert
  687:             data.insert(1.5, data[0])
  688: 
  689:     @pytest.mark.parametrize("box", [pd.array, pd.Series, pd.DataFrame])
  690:     def test_equals(self, data, na_value, as_series, box):
  691:         data2 = type(data)._from_sequence([data[0]] * len(data), dtype=data.dtype)
  692:         data_na = type(data)._from_sequence([na_value] * len(data), dtype=data.dtype)
  693: 
  694:         data = tm.box_expected(data, box, transpose=False)
  695:         data2 = tm.box_expected(data2, box, transpose=False)
  696:         data_na = tm.box_expected(data_na, box, transpose=False)
  697: 
  698:         # we are asserting with `is True/False` explicitly, to test that the
  699:         # result is an actual Python bool, and not something "truthy"
  700: 
  701:         assert data.equals(data) is True
  702:         assert data.equals(data.copy()) is True
  703: 
  704:         # unequal other data
  705:         assert data.equals(data2) is False
  706:         assert data.equals(data_na) is False
  707: 
  708:         # different length
  709:         assert data[:2].equals(data[:3]) is False
  710: 
  711:         # empty are equal
  712:         assert data[:0].equals(data[:0]) is True
  713: 
  714:         # other types
  715:         assert data.equals(None) is False
  716:         assert data[[0]].equals(data[0]) is False
  717: 
  718:     def test_equals_same_data_different_object(self, data):
  719:         # https://github.com/pandas-dev/pandas/issues/34660
  720:         assert pd.Series(data).equals(pd.Series(data))
