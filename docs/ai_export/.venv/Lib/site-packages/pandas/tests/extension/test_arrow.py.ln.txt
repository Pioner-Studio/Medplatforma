    1: """
    2: This file contains a minimal set of tests for compliance with the extension
    3: array interface test suite, and should contain no other tests.
    4: The test suite for the full functionality of the array is located in
    5: `pandas/tests/arrays/`.
    6: The tests in this file are inherited from the BaseExtensionTests, and only
    7: minimal tweaks should be applied to get the tests passing (by overwriting a
    8: parent method).
    9: Additional tests should either be added to one of the BaseExtensionTests
   10: classes (if they are relevant for the extension interface for all dtypes), or
   11: be added to the array-specific tests in `pandas/tests/arrays/`.
   12: """
   13: from __future__ import annotations
   14: 
   15: from datetime import (
   16:     date,
   17:     datetime,
   18:     time,
   19:     timedelta,
   20: )
   21: from decimal import Decimal
   22: from io import (
   23:     BytesIO,
   24:     StringIO,
   25: )
   26: import operator
   27: import pickle
   28: import re
   29: 
   30: import numpy as np
   31: import pytest
   32: 
   33: from pandas._libs import lib
   34: from pandas._libs.tslibs import timezones
   35: from pandas.compat import (
   36:     PY311,
   37:     PY312,
   38:     is_ci_environment,
   39:     is_platform_windows,
   40:     pa_version_under11p0,
   41:     pa_version_under13p0,
   42:     pa_version_under14p0,
   43: )
   44: import pandas.util._test_decorators as td
   45: 
   46: from pandas.core.dtypes.dtypes import (
   47:     ArrowDtype,
   48:     CategoricalDtypeType,
   49: )
   50: 
   51: import pandas as pd
   52: import pandas._testing as tm
   53: from pandas.api.extensions import no_default
   54: from pandas.api.types import (
   55:     is_bool_dtype,
   56:     is_float_dtype,
   57:     is_integer_dtype,
   58:     is_numeric_dtype,
   59:     is_signed_integer_dtype,
   60:     is_string_dtype,
   61:     is_unsigned_integer_dtype,
   62: )
   63: from pandas.tests.extension import base
   64: 
   65: pa = pytest.importorskip("pyarrow")
   66: 
   67: from pandas.core.arrays.arrow.array import ArrowExtensionArray
   68: from pandas.core.arrays.arrow.extension_types import ArrowPeriodType
   69: 
   70: 
   71: def _require_timezone_database(request):
   72:     if is_platform_windows() and is_ci_environment():
   73:         mark = pytest.mark.xfail(
   74:             raises=pa.ArrowInvalid,
   75:             reason=(
   76:                 "TODO: Set ARROW_TIMEZONE_DATABASE environment variable "
   77:                 "on CI to path to the tzdata for pyarrow."
   78:             ),
   79:         )
   80:         request.applymarker(mark)
   81: 
   82: 
   83: @pytest.fixture(params=tm.ALL_PYARROW_DTYPES, ids=str)
   84: def dtype(request):
   85:     return ArrowDtype(pyarrow_dtype=request.param)
   86: 
   87: 
   88: @pytest.fixture
   89: def data(dtype):
   90:     pa_dtype = dtype.pyarrow_dtype
   91:     if pa.types.is_boolean(pa_dtype):
   92:         data = [True, False] * 4 + [None] + [True, False] * 44 + [None] + [True, False]
   93:     elif pa.types.is_floating(pa_dtype):
   94:         data = [1.0, 0.0] * 4 + [None] + [-2.0, -1.0] * 44 + [None] + [0.5, 99.5]
   95:     elif pa.types.is_signed_integer(pa_dtype):
   96:         data = [1, 0] * 4 + [None] + [-2, -1] * 44 + [None] + [1, 99]
   97:     elif pa.types.is_unsigned_integer(pa_dtype):
   98:         data = [1, 0] * 4 + [None] + [2, 1] * 44 + [None] + [1, 99]
   99:     elif pa.types.is_decimal(pa_dtype):
  100:         data = (
  101:             [Decimal("1"), Decimal("0.0")] * 4
  102:             + [None]
  103:             + [Decimal("-2.0"), Decimal("-1.0")] * 44
  104:             + [None]
  105:             + [Decimal("0.5"), Decimal("33.123")]
  106:         )
  107:     elif pa.types.is_date(pa_dtype):
  108:         data = (
  109:             [date(2022, 1, 1), date(1999, 12, 31)] * 4
  110:             + [None]
  111:             + [date(2022, 1, 1), date(2022, 1, 1)] * 44
  112:             + [None]
  113:             + [date(1999, 12, 31), date(1999, 12, 31)]
  114:         )
  115:     elif pa.types.is_timestamp(pa_dtype):
  116:         data = (
  117:             [datetime(2020, 1, 1, 1, 1, 1, 1), datetime(1999, 1, 1, 1, 1, 1, 1)] * 4
  118:             + [None]
  119:             + [datetime(2020, 1, 1, 1), datetime(1999, 1, 1, 1)] * 44
  120:             + [None]
  121:             + [datetime(2020, 1, 1), datetime(1999, 1, 1)]
  122:         )
  123:     elif pa.types.is_duration(pa_dtype):
  124:         data = (
  125:             [timedelta(1), timedelta(1, 1)] * 4
  126:             + [None]
  127:             + [timedelta(-1), timedelta(0)] * 44
  128:             + [None]
  129:             + [timedelta(-10), timedelta(10)]
  130:         )
  131:     elif pa.types.is_time(pa_dtype):
  132:         data = (
  133:             [time(12, 0), time(0, 12)] * 4
  134:             + [None]
  135:             + [time(0, 0), time(1, 1)] * 44
  136:             + [None]
  137:             + [time(0, 5), time(5, 0)]
  138:         )
  139:     elif pa.types.is_string(pa_dtype):
  140:         data = ["a", "b"] * 4 + [None] + ["1", "2"] * 44 + [None] + ["!", ">"]
  141:     elif pa.types.is_binary(pa_dtype):
  142:         data = [b"a", b"b"] * 4 + [None] + [b"1", b"2"] * 44 + [None] + [b"!", b">"]
  143:     else:
  144:         raise NotImplementedError
  145:     return pd.array(data, dtype=dtype)
  146: 
  147: 
  148: @pytest.fixture
  149: def data_missing(data):
  150:     """Length-2 array with [NA, Valid]"""
  151:     return type(data)._from_sequence([None, data[0]], dtype=data.dtype)
  152: 
  153: 
  154: @pytest.fixture(params=["data", "data_missing"])
  155: def all_data(request, data, data_missing):
  156:     """Parametrized fixture returning 'data' or 'data_missing' integer arrays.
  157: 
  158:     Used to test dtype conversion with and without missing values.
  159:     """
  160:     if request.param == "data":
  161:         return data
  162:     elif request.param == "data_missing":
  163:         return data_missing
  164: 
  165: 
  166: @pytest.fixture
  167: def data_for_grouping(dtype):
  168:     """
  169:     Data for factorization, grouping, and unique tests.
  170: 
  171:     Expected to be like [B, B, NA, NA, A, A, B, C]
  172: 
  173:     Where A < B < C and NA is missing
  174:     """
  175:     pa_dtype = dtype.pyarrow_dtype
  176:     if pa.types.is_boolean(pa_dtype):
  177:         A = False
  178:         B = True
  179:         C = True
  180:     elif pa.types.is_floating(pa_dtype):
  181:         A = -1.1
  182:         B = 0.0
  183:         C = 1.1
  184:     elif pa.types.is_signed_integer(pa_dtype):
  185:         A = -1
  186:         B = 0
  187:         C = 1
  188:     elif pa.types.is_unsigned_integer(pa_dtype):
  189:         A = 0
  190:         B = 1
  191:         C = 10
  192:     elif pa.types.is_date(pa_dtype):
  193:         A = date(1999, 12, 31)
  194:         B = date(2010, 1, 1)
  195:         C = date(2022, 1, 1)
  196:     elif pa.types.is_timestamp(pa_dtype):
  197:         A = datetime(1999, 1, 1, 1, 1, 1, 1)
  198:         B = datetime(2020, 1, 1)
  199:         C = datetime(2020, 1, 1, 1)
  200:     elif pa.types.is_duration(pa_dtype):
  201:         A = timedelta(-1)
  202:         B = timedelta(0)
  203:         C = timedelta(1, 4)
  204:     elif pa.types.is_time(pa_dtype):
  205:         A = time(0, 0)
  206:         B = time(0, 12)
  207:         C = time(12, 12)
  208:     elif pa.types.is_string(pa_dtype):
  209:         A = "a"
  210:         B = "b"
  211:         C = "c"
  212:     elif pa.types.is_binary(pa_dtype):
  213:         A = b"a"
  214:         B = b"b"
  215:         C = b"c"
  216:     elif pa.types.is_decimal(pa_dtype):
  217:         A = Decimal("-1.1")
  218:         B = Decimal("0.0")
  219:         C = Decimal("1.1")
  220:     else:
  221:         raise NotImplementedError
  222:     return pd.array([B, B, None, None, A, A, B, C], dtype=dtype)
  223: 
  224: 
  225: @pytest.fixture
  226: def data_for_sorting(data_for_grouping):
  227:     """
  228:     Length-3 array with a known sort order.
  229: 
  230:     This should be three items [B, C, A] with
  231:     A < B < C
  232:     """
  233:     return type(data_for_grouping)._from_sequence(
  234:         [data_for_grouping[0], data_for_grouping[7], data_for_grouping[4]],
  235:         dtype=data_for_grouping.dtype,
  236:     )
  237: 
  238: 
  239: @pytest.fixture
  240: def data_missing_for_sorting(data_for_grouping):
  241:     """
  242:     Length-3 array with a known sort order.
  243: 
  244:     This should be three items [B, NA, A] with
  245:     A < B and NA missing.
  246:     """
  247:     return type(data_for_grouping)._from_sequence(
  248:         [data_for_grouping[0], data_for_grouping[2], data_for_grouping[4]],
  249:         dtype=data_for_grouping.dtype,
  250:     )
  251: 
  252: 
  253: @pytest.fixture
  254: def data_for_twos(data):
  255:     """Length-100 array in which all the elements are two."""
  256:     pa_dtype = data.dtype.pyarrow_dtype
  257:     if (
  258:         pa.types.is_integer(pa_dtype)
  259:         or pa.types.is_floating(pa_dtype)
  260:         or pa.types.is_decimal(pa_dtype)
  261:         or pa.types.is_duration(pa_dtype)
  262:     ):
  263:         return pd.array([2] * 100, dtype=data.dtype)
  264:     # tests will be xfailed where 2 is not a valid scalar for pa_dtype
  265:     return data
  266:     # TODO: skip otherwise?
  267: 
  268: 
  269: class TestArrowArray(base.ExtensionTests):
  270:     def test_compare_scalar(self, data, comparison_op):
  271:         ser = pd.Series(data)
  272:         self._compare_other(ser, data, comparison_op, data[0])
  273: 
  274:     @pytest.mark.parametrize("na_action", [None, "ignore"])
  275:     def test_map(self, data_missing, na_action):
  276:         if data_missing.dtype.kind in "mM":
  277:             result = data_missing.map(lambda x: x, na_action=na_action)
  278:             expected = data_missing.to_numpy(dtype=object)
  279:             tm.assert_numpy_array_equal(result, expected)
  280:         else:
  281:             result = data_missing.map(lambda x: x, na_action=na_action)
  282:             if data_missing.dtype == "float32[pyarrow]":
  283:                 # map roundtrips through objects, which converts to float64
  284:                 expected = data_missing.to_numpy(dtype="float64", na_value=np.nan)
  285:             else:
  286:                 expected = data_missing.to_numpy()
  287:             tm.assert_numpy_array_equal(result, expected)
  288: 
  289:     def test_astype_str(self, data, request):
  290:         pa_dtype = data.dtype.pyarrow_dtype
  291:         if pa.types.is_binary(pa_dtype):
  292:             request.applymarker(
  293:                 pytest.mark.xfail(
  294:                     reason=f"For {pa_dtype} .astype(str) decodes.",
  295:                 )
  296:             )
  297:         elif (
  298:             pa.types.is_timestamp(pa_dtype) and pa_dtype.tz is None
  299:         ) or pa.types.is_duration(pa_dtype):
  300:             request.applymarker(
  301:                 pytest.mark.xfail(
  302:                     reason="pd.Timestamp/pd.Timedelta repr different from numpy repr",
  303:                 )
  304:             )
  305:         super().test_astype_str(data)
  306: 
  307:     @pytest.mark.parametrize(
  308:         "nullable_string_dtype",
  309:         [
  310:             "string[python]",
  311:             pytest.param("string[pyarrow]", marks=td.skip_if_no("pyarrow")),
  312:         ],
  313:     )
  314:     def test_astype_string(self, data, nullable_string_dtype, request):
  315:         pa_dtype = data.dtype.pyarrow_dtype
  316:         if (
  317:             pa.types.is_timestamp(pa_dtype) and pa_dtype.tz is None
  318:         ) or pa.types.is_duration(pa_dtype):
  319:             request.applymarker(
  320:                 pytest.mark.xfail(
  321:                     reason="pd.Timestamp/pd.Timedelta repr different from numpy repr",
  322:                 )
  323:             )
  324:         super().test_astype_string(data, nullable_string_dtype)
  325: 
  326:     def test_from_dtype(self, data, request):
  327:         pa_dtype = data.dtype.pyarrow_dtype
  328:         if pa.types.is_string(pa_dtype) or pa.types.is_decimal(pa_dtype):
  329:             if pa.types.is_string(pa_dtype):
  330:                 reason = "ArrowDtype(pa.string()) != StringDtype('pyarrow')"
  331:             else:
  332:                 reason = f"pyarrow.type_for_alias cannot infer {pa_dtype}"
  333: 
  334:             request.applymarker(
  335:                 pytest.mark.xfail(
  336:                     reason=reason,
  337:                 )
  338:             )
  339:         super().test_from_dtype(data)
  340: 
  341:     def test_from_sequence_pa_array(self, data):
  342:         # https://github.com/pandas-dev/pandas/pull/47034#discussion_r955500784
  343:         # data._pa_array = pa.ChunkedArray
  344:         result = type(data)._from_sequence(data._pa_array, dtype=data.dtype)
  345:         tm.assert_extension_array_equal(result, data)
  346:         assert isinstance(result._pa_array, pa.ChunkedArray)
  347: 
  348:         result = type(data)._from_sequence(
  349:             data._pa_array.combine_chunks(), dtype=data.dtype
  350:         )
  351:         tm.assert_extension_array_equal(result, data)
  352:         assert isinstance(result._pa_array, pa.ChunkedArray)
  353: 
  354:     def test_from_sequence_pa_array_notimplemented(self, request):
  355:         with pytest.raises(NotImplementedError, match="Converting strings to"):
  356:             ArrowExtensionArray._from_sequence_of_strings(
  357:                 ["12-1"], dtype=pa.month_day_nano_interval()
  358:             )
  359: 
  360:     def test_from_sequence_of_strings_pa_array(self, data, request):
  361:         pa_dtype = data.dtype.pyarrow_dtype
  362:         if pa.types.is_time64(pa_dtype) and pa_dtype.equals("time64[ns]") and not PY311:
  363:             request.applymarker(
  364:                 pytest.mark.xfail(
  365:                     reason="Nanosecond time parsing not supported.",
  366:                 )
  367:             )
  368:         elif pa_version_under11p0 and (
  369:             pa.types.is_duration(pa_dtype) or pa.types.is_decimal(pa_dtype)
  370:         ):
  371:             request.applymarker(
  372:                 pytest.mark.xfail(
  373:                     raises=pa.ArrowNotImplementedError,
  374:                     reason=f"pyarrow doesn't support parsing {pa_dtype}",
  375:                 )
  376:             )
  377:         elif pa.types.is_timestamp(pa_dtype) and pa_dtype.tz is not None:
  378:             _require_timezone_database(request)
  379: 
  380:         pa_array = data._pa_array.cast(pa.string())
  381:         result = type(data)._from_sequence_of_strings(pa_array, dtype=data.dtype)
  382:         tm.assert_extension_array_equal(result, data)
  383: 
  384:         pa_array = pa_array.combine_chunks()
  385:         result = type(data)._from_sequence_of_strings(pa_array, dtype=data.dtype)
  386:         tm.assert_extension_array_equal(result, data)
  387: 
  388:     def check_accumulate(self, ser, op_name, skipna):
  389:         result = getattr(ser, op_name)(skipna=skipna)
  390: 
  391:         pa_type = ser.dtype.pyarrow_dtype
  392:         if pa.types.is_temporal(pa_type):
  393:             # Just check that we match the integer behavior.
  394:             if pa_type.bit_width == 32:
  395:                 int_type = "int32[pyarrow]"
  396:             else:
  397:                 int_type = "int64[pyarrow]"
  398:             ser = ser.astype(int_type)
  399:             result = result.astype(int_type)
  400: 
  401:         result = result.astype("Float64")
  402:         expected = getattr(ser.astype("Float64"), op_name)(skipna=skipna)
  403:         tm.assert_series_equal(result, expected, check_dtype=False)
  404: 
  405:     def _supports_accumulation(self, ser: pd.Series, op_name: str) -> bool:
  406:         # error: Item "dtype[Any]" of "dtype[Any] | ExtensionDtype" has no
  407:         # attribute "pyarrow_dtype"
  408:         pa_type = ser.dtype.pyarrow_dtype  # type: ignore[union-attr]
  409: 
  410:         if (
  411:             pa.types.is_string(pa_type)
  412:             or pa.types.is_binary(pa_type)
  413:             or pa.types.is_decimal(pa_type)
  414:         ):
  415:             if op_name in ["cumsum", "cumprod", "cummax", "cummin"]:
  416:                 return False
  417:         elif pa.types.is_boolean(pa_type):
  418:             if op_name in ["cumprod", "cummax", "cummin"]:
  419:                 return False
  420:         elif pa.types.is_temporal(pa_type):
  421:             if op_name == "cumsum" and not pa.types.is_duration(pa_type):
  422:                 return False
  423:             elif op_name == "cumprod":
  424:                 return False
  425:         return True
  426: 
  427:     @pytest.mark.parametrize("skipna", [True, False])
  428:     def test_accumulate_series(self, data, all_numeric_accumulations, skipna, request):
  429:         pa_type = data.dtype.pyarrow_dtype
  430:         op_name = all_numeric_accumulations
  431:         ser = pd.Series(data)
  432: 
  433:         if not self._supports_accumulation(ser, op_name):
  434:             # The base class test will check that we raise
  435:             return super().test_accumulate_series(
  436:                 data, all_numeric_accumulations, skipna
  437:             )
  438: 
  439:         if pa_version_under13p0 and all_numeric_accumulations != "cumsum":
  440:             # xfailing takes a long time to run because pytest
  441:             # renders the exception messages even when not showing them
  442:             opt = request.config.option
  443:             if opt.markexpr and "not slow" in opt.markexpr:
  444:                 pytest.skip(
  445:                     f"{all_numeric_accumulations} not implemented for pyarrow < 9"
  446:                 )
  447:             mark = pytest.mark.xfail(
  448:                 reason=f"{all_numeric_accumulations} not implemented for pyarrow < 9"
  449:             )
  450:             request.applymarker(mark)
  451: 
  452:         elif all_numeric_accumulations == "cumsum" and (
  453:             pa.types.is_boolean(pa_type) or pa.types.is_decimal(pa_type)
  454:         ):
  455:             request.applymarker(
  456:                 pytest.mark.xfail(
  457:                     reason=f"{all_numeric_accumulations} not implemented for {pa_type}",
  458:                     raises=NotImplementedError,
  459:                 )
  460:             )
  461: 
  462:         self.check_accumulate(ser, op_name, skipna)
  463: 
  464:     def _supports_reduction(self, ser: pd.Series, op_name: str) -> bool:
  465:         dtype = ser.dtype
  466:         # error: Item "dtype[Any]" of "dtype[Any] | ExtensionDtype" has
  467:         # no attribute "pyarrow_dtype"
  468:         pa_dtype = dtype.pyarrow_dtype  # type: ignore[union-attr]
  469:         if pa.types.is_temporal(pa_dtype) and op_name in [
  470:             "sum",
  471:             "var",
  472:             "skew",
  473:             "kurt",
  474:             "prod",
  475:         ]:
  476:             if pa.types.is_duration(pa_dtype) and op_name in ["sum"]:
  477:                 # summing timedeltas is one case that *is* well-defined
  478:                 pass
  479:             else:
  480:                 return False
  481:         elif (
  482:             pa.types.is_string(pa_dtype) or pa.types.is_binary(pa_dtype)
  483:         ) and op_name in [
  484:             "sum",
  485:             "mean",
  486:             "median",
  487:             "prod",
  488:             "std",
  489:             "sem",
  490:             "var",
  491:             "skew",
  492:             "kurt",
  493:         ]:
  494:             return False
  495: 
  496:         if (
  497:             pa.types.is_temporal(pa_dtype)
  498:             and not pa.types.is_duration(pa_dtype)
  499:             and op_name in ["any", "all"]
  500:         ):
  501:             # xref GH#34479 we support this in our non-pyarrow datetime64 dtypes,
  502:             #  but it isn't obvious we _should_.  For now, we keep the pyarrow
  503:             #  behavior which does not support this.
  504:             return False
  505: 
  506:         return True
  507: 
  508:     def check_reduce(self, ser: pd.Series, op_name: str, skipna: bool):
  509:         # error: Item "dtype[Any]" of "dtype[Any] | ExtensionDtype" has no
  510:         # attribute "pyarrow_dtype"
  511:         pa_dtype = ser.dtype.pyarrow_dtype  # type: ignore[union-attr]
  512:         if pa.types.is_integer(pa_dtype) or pa.types.is_floating(pa_dtype):
  513:             alt = ser.astype("Float64")
  514:         else:
  515:             # TODO: in the opposite case, aren't we testing... nothing? For
  516:             # e.g. date/time dtypes trying to calculate 'expected' by converting
  517:             # to object will raise for mean, std etc
  518:             alt = ser
  519: 
  520:         # TODO: in the opposite case, aren't we testing... nothing?
  521:         if op_name == "count":
  522:             result = getattr(ser, op_name)()
  523:             expected = getattr(alt, op_name)()
  524:         else:
  525:             result = getattr(ser, op_name)(skipna=skipna)
  526:             expected = getattr(alt, op_name)(skipna=skipna)
  527:         tm.assert_almost_equal(result, expected)
  528: 
  529:     @pytest.mark.parametrize("skipna", [True, False])
  530:     def test_reduce_series_numeric(self, data, all_numeric_reductions, skipna, request):
  531:         dtype = data.dtype
  532:         pa_dtype = dtype.pyarrow_dtype
  533: 
  534:         xfail_mark = pytest.mark.xfail(
  535:             raises=TypeError,
  536:             reason=(
  537:                 f"{all_numeric_reductions} is not implemented in "
  538:                 f"pyarrow={pa.__version__} for {pa_dtype}"
  539:             ),
  540:         )
  541:         if all_numeric_reductions in {"skew", "kurt"} and (
  542:             dtype._is_numeric or dtype.kind == "b"
  543:         ):
  544:             request.applymarker(xfail_mark)
  545: 
  546:         elif pa.types.is_boolean(pa_dtype) and all_numeric_reductions in {
  547:             "sem",
  548:             "std",
  549:             "var",
  550:             "median",
  551:         }:
  552:             request.applymarker(xfail_mark)
  553:         super().test_reduce_series_numeric(data, all_numeric_reductions, skipna)
  554: 
  555:     @pytest.mark.parametrize("skipna", [True, False])
  556:     def test_reduce_series_boolean(
  557:         self, data, all_boolean_reductions, skipna, na_value, request
  558:     ):
  559:         pa_dtype = data.dtype.pyarrow_dtype
  560:         xfail_mark = pytest.mark.xfail(
  561:             raises=TypeError,
  562:             reason=(
  563:                 f"{all_boolean_reductions} is not implemented in "
  564:                 f"pyarrow={pa.__version__} for {pa_dtype}"
  565:             ),
  566:         )
  567:         if pa.types.is_string(pa_dtype) or pa.types.is_binary(pa_dtype):
  568:             # We *might* want to make this behave like the non-pyarrow cases,
  569:             #  but have not yet decided.
  570:             request.applymarker(xfail_mark)
  571: 
  572:         return super().test_reduce_series_boolean(data, all_boolean_reductions, skipna)
  573: 
  574:     def _get_expected_reduction_dtype(self, arr, op_name: str, skipna: bool):
  575:         if op_name in ["max", "min"]:
  576:             cmp_dtype = arr.dtype
  577:         elif arr.dtype.name == "decimal128(7, 3)[pyarrow]":
  578:             if op_name not in ["median", "var", "std"]:
  579:                 cmp_dtype = arr.dtype
  580:             else:
  581:                 cmp_dtype = "float64[pyarrow]"
  582:         elif op_name in ["median", "var", "std", "mean", "skew"]:
  583:             cmp_dtype = "float64[pyarrow]"
  584:         else:
  585:             cmp_dtype = {
  586:                 "i": "int64[pyarrow]",
  587:                 "u": "uint64[pyarrow]",
  588:                 "f": "float64[pyarrow]",
  589:             }[arr.dtype.kind]
  590:         return cmp_dtype
  591: 
  592:     @pytest.mark.parametrize("skipna", [True, False])
  593:     def test_reduce_frame(self, data, all_numeric_reductions, skipna, request):
  594:         op_name = all_numeric_reductions
  595:         if op_name == "skew":
  596:             if data.dtype._is_numeric:
  597:                 mark = pytest.mark.xfail(reason="skew not implemented")
  598:                 request.applymarker(mark)
  599:         return super().test_reduce_frame(data, all_numeric_reductions, skipna)
  600: 
  601:     @pytest.mark.parametrize("typ", ["int64", "uint64", "float64"])
  602:     def test_median_not_approximate(self, typ):
  603:         # GH 52679
  604:         result = pd.Series([1, 2], dtype=f"{typ}[pyarrow]").median()
  605:         assert result == 1.5
  606: 
  607:     def test_in_numeric_groupby(self, data_for_grouping):
  608:         dtype = data_for_grouping.dtype
  609:         if is_string_dtype(dtype):
  610:             df = pd.DataFrame(
  611:                 {
  612:                     "A": [1, 1, 2, 2, 3, 3, 1, 4],
  613:                     "B": data_for_grouping,
  614:                     "C": [1, 1, 1, 1, 1, 1, 1, 1],
  615:                 }
  616:             )
  617: 
  618:             expected = pd.Index(["C"])
  619:             msg = re.escape(f"agg function failed [how->sum,dtype->{dtype}")
  620:             with pytest.raises(TypeError, match=msg):
  621:                 df.groupby("A").sum()
  622:             result = df.groupby("A").sum(numeric_only=True).columns
  623:             tm.assert_index_equal(result, expected)
  624:         else:
  625:             super().test_in_numeric_groupby(data_for_grouping)
  626: 
  627:     def test_construct_from_string_own_name(self, dtype, request):
  628:         pa_dtype = dtype.pyarrow_dtype
  629:         if pa.types.is_decimal(pa_dtype):
  630:             request.applymarker(
  631:                 pytest.mark.xfail(
  632:                     raises=NotImplementedError,
  633:                     reason=f"pyarrow.type_for_alias cannot infer {pa_dtype}",
  634:                 )
  635:             )
  636: 
  637:         if pa.types.is_string(pa_dtype):
  638:             # We still support StringDtype('pyarrow') over ArrowDtype(pa.string())
  639:             msg = r"string\[pyarrow\] should be constructed by StringDtype"
  640:             with pytest.raises(TypeError, match=msg):
  641:                 dtype.construct_from_string(dtype.name)
  642: 
  643:             return
  644: 
  645:         super().test_construct_from_string_own_name(dtype)
  646: 
  647:     def test_is_dtype_from_name(self, dtype, request):
  648:         pa_dtype = dtype.pyarrow_dtype
  649:         if pa.types.is_string(pa_dtype):
  650:             # We still support StringDtype('pyarrow') over ArrowDtype(pa.string())
  651:             assert not type(dtype).is_dtype(dtype.name)
  652:         else:
  653:             if pa.types.is_decimal(pa_dtype):
  654:                 request.applymarker(
  655:                     pytest.mark.xfail(
  656:                         raises=NotImplementedError,
  657:                         reason=f"pyarrow.type_for_alias cannot infer {pa_dtype}",
  658:                     )
  659:                 )
  660:             super().test_is_dtype_from_name(dtype)
  661: 
  662:     def test_construct_from_string_another_type_raises(self, dtype):
  663:         msg = r"'another_type' must end with '\[pyarrow\]'"
  664:         with pytest.raises(TypeError, match=msg):
  665:             type(dtype).construct_from_string("another_type")
  666: 
  667:     def test_get_common_dtype(self, dtype, request):
  668:         pa_dtype = dtype.pyarrow_dtype
  669:         if (
  670:             pa.types.is_date(pa_dtype)
  671:             or pa.types.is_time(pa_dtype)
  672:             or (pa.types.is_timestamp(pa_dtype) and pa_dtype.tz is not None)
  673:             or pa.types.is_binary(pa_dtype)
  674:             or pa.types.is_decimal(pa_dtype)
  675:         ):
  676:             request.applymarker(
  677:                 pytest.mark.xfail(
  678:                     reason=(
  679:                         f"{pa_dtype} does not have associated numpy "
  680:                         f"dtype findable by find_common_type"
  681:                     )
  682:                 )
  683:             )
  684:         super().test_get_common_dtype(dtype)
  685: 
  686:     def test_is_not_string_type(self, dtype):
  687:         pa_dtype = dtype.pyarrow_dtype
  688:         if pa.types.is_string(pa_dtype):
  689:             assert is_string_dtype(dtype)
  690:         else:
  691:             super().test_is_not_string_type(dtype)
  692: 
  693:     @pytest.mark.xfail(
  694:         reason="GH 45419: pyarrow.ChunkedArray does not support views.", run=False
  695:     )
  696:     def test_view(self, data):
  697:         super().test_view(data)
  698: 
  699:     def test_fillna_no_op_returns_copy(self, data):
  700:         data = data[~data.isna()]
  701: 
  702:         valid = data[0]
  703:         result = data.fillna(valid)
  704:         assert result is not data
  705:         tm.assert_extension_array_equal(result, data)
  706: 
  707:         result = data.fillna(method="backfill")
  708:         assert result is not data
  709:         tm.assert_extension_array_equal(result, data)
  710: 
  711:     @pytest.mark.xfail(
  712:         reason="GH 45419: pyarrow.ChunkedArray does not support views", run=False
  713:     )
  714:     def test_transpose(self, data):
  715:         super().test_transpose(data)
  716: 
  717:     @pytest.mark.xfail(
  718:         reason="GH 45419: pyarrow.ChunkedArray does not support views", run=False
  719:     )
  720:     def test_setitem_preserves_views(self, data):
  721:         super().test_setitem_preserves_views(data)
  722: 
  723:     @pytest.mark.parametrize("dtype_backend", ["pyarrow", no_default])
  724:     @pytest.mark.parametrize("engine", ["c", "python"])
  725:     def test_EA_types(self, engine, data, dtype_backend, request):
  726:         pa_dtype = data.dtype.pyarrow_dtype
  727:         if pa.types.is_decimal(pa_dtype):
  728:             request.applymarker(
  729:                 pytest.mark.xfail(
  730:                     raises=NotImplementedError,
  731:                     reason=f"Parameterized types {pa_dtype} not supported.",
  732:                 )
  733:             )
  734:         elif pa.types.is_timestamp(pa_dtype) and pa_dtype.unit in ("us", "ns"):
  735:             request.applymarker(
  736:                 pytest.mark.xfail(
  737:                     raises=ValueError,
  738:                     reason="https://github.com/pandas-dev/pandas/issues/49767",
  739:                 )
  740:             )
  741:         elif pa.types.is_binary(pa_dtype):
  742:             request.applymarker(
  743:                 pytest.mark.xfail(reason="CSV parsers don't correctly handle binary")
  744:             )
  745:         df = pd.DataFrame({"with_dtype": pd.Series(data, dtype=str(data.dtype))})
  746:         csv_output = df.to_csv(index=False, na_rep=np.nan)
  747:         if pa.types.is_binary(pa_dtype):
  748:             csv_output = BytesIO(csv_output)
  749:         else:
  750:             csv_output = StringIO(csv_output)
  751:         result = pd.read_csv(
  752:             csv_output,
  753:             dtype={"with_dtype": str(data.dtype)},
  754:             engine=engine,
  755:             dtype_backend=dtype_backend,
  756:         )
  757:         expected = df
  758:         tm.assert_frame_equal(result, expected)
  759: 
  760:     def test_invert(self, data, request):
  761:         pa_dtype = data.dtype.pyarrow_dtype
  762:         if not (
  763:             pa.types.is_boolean(pa_dtype)
  764:             or pa.types.is_integer(pa_dtype)
  765:             or pa.types.is_string(pa_dtype)
  766:         ):
  767:             request.applymarker(
  768:                 pytest.mark.xfail(
  769:                     raises=pa.ArrowNotImplementedError,
  770:                     reason=f"pyarrow.compute.invert does support {pa_dtype}",
  771:                 )
  772:             )
  773:         if PY312 and pa.types.is_boolean(pa_dtype):
  774:             with tm.assert_produces_warning(
  775:                 DeprecationWarning, match="Bitwise inversion", check_stacklevel=False
  776:             ):
  777:                 super().test_invert(data)
  778:         else:
  779:             super().test_invert(data)
  780: 
  781:     @pytest.mark.parametrize("periods", [1, -2])
  782:     def test_diff(self, data, periods, request):
  783:         pa_dtype = data.dtype.pyarrow_dtype
  784:         if pa.types.is_unsigned_integer(pa_dtype) and periods == 1:
  785:             request.applymarker(
  786:                 pytest.mark.xfail(
  787:                     raises=pa.ArrowInvalid,
  788:                     reason=(
  789:                         f"diff with {pa_dtype} and periods={periods} will overflow"
  790:                     ),
  791:                 )
  792:             )
  793:         super().test_diff(data, periods)
  794: 
  795:     def test_value_counts_returns_pyarrow_int64(self, data):
  796:         # GH 51462
  797:         data = data[:10]
  798:         result = data.value_counts()
  799:         assert result.dtype == ArrowDtype(pa.int64())
  800: 
  801:     _combine_le_expected_dtype = "bool[pyarrow]"
  802: 
  803:     divmod_exc = NotImplementedError
  804: 
  805:     def get_op_from_name(self, op_name):
  806:         short_opname = op_name.strip("_")
  807:         if short_opname == "rtruediv":
  808:             # use the numpy version that won't raise on division by zero
  809: 
  810:             def rtruediv(x, y):
  811:                 return np.divide(y, x)
  812: 
  813:             return rtruediv
  814:         elif short_opname == "rfloordiv":
  815:             return lambda x, y: np.floor_divide(y, x)
  816: 
  817:         return tm.get_op_from_name(op_name)
  818: 
  819:     def _cast_pointwise_result(self, op_name: str, obj, other, pointwise_result):
  820:         # BaseOpsUtil._combine can upcast expected dtype
  821:         # (because it generates expected on python scalars)
  822:         # while ArrowExtensionArray maintains original type
  823:         expected = pointwise_result
  824: 
  825:         if op_name in ["eq", "ne", "lt", "le", "gt", "ge"]:
  826:             return pointwise_result.astype("boolean[pyarrow]")
  827: 
  828:         was_frame = False
  829:         if isinstance(expected, pd.DataFrame):
  830:             was_frame = True
  831:             expected_data = expected.iloc[:, 0]
  832:             original_dtype = obj.iloc[:, 0].dtype
  833:         else:
  834:             expected_data = expected
  835:             original_dtype = obj.dtype
  836: 
  837:         orig_pa_type = original_dtype.pyarrow_dtype
  838:         if not was_frame and isinstance(other, pd.Series):
  839:             # i.e. test_arith_series_with_array
  840:             if not (
  841:                 pa.types.is_floating(orig_pa_type)
  842:                 or (
  843:                     pa.types.is_integer(orig_pa_type)
  844:                     and op_name not in ["__truediv__", "__rtruediv__"]
  845:                 )
  846:                 or pa.types.is_duration(orig_pa_type)
  847:                 or pa.types.is_timestamp(orig_pa_type)
  848:                 or pa.types.is_date(orig_pa_type)
  849:                 or pa.types.is_decimal(orig_pa_type)
  850:             ):
  851:                 # base class _combine always returns int64, while
  852:                 #  ArrowExtensionArray does not upcast
  853:                 return expected
  854:         elif not (
  855:             (op_name == "__floordiv__" and pa.types.is_integer(orig_pa_type))
  856:             or pa.types.is_duration(orig_pa_type)
  857:             or pa.types.is_timestamp(orig_pa_type)
  858:             or pa.types.is_date(orig_pa_type)
  859:             or pa.types.is_decimal(orig_pa_type)
  860:         ):
  861:             # base class _combine always returns int64, while
  862:             #  ArrowExtensionArray does not upcast
  863:             return expected
  864: 
  865:         pa_expected = pa.array(expected_data._values)
  866: 
  867:         if pa.types.is_duration(pa_expected.type):
  868:             if pa.types.is_date(orig_pa_type):
  869:                 if pa.types.is_date64(orig_pa_type):
  870:                     # TODO: why is this different vs date32?
  871:                     unit = "ms"
  872:                 else:
  873:                     unit = "s"
  874:             else:
  875:                 # pyarrow sees sequence of datetime/timedelta objects and defaults
  876:                 #  to "us" but the non-pointwise op retains unit
  877:                 # timestamp or duration
  878:                 unit = orig_pa_type.unit
  879:                 if type(other) in [datetime, timedelta] and unit in ["s", "ms"]:
  880:                     # pydatetime/pytimedelta objects have microsecond reso, so we
  881:                     #  take the higher reso of the original and microsecond. Note
  882:                     #  this matches what we would do with DatetimeArray/TimedeltaArray
  883:                     unit = "us"
  884: 
  885:             pa_expected = pa_expected.cast(f"duration[{unit}]")
  886: 
  887:         elif pa.types.is_decimal(pa_expected.type) and pa.types.is_decimal(
  888:             orig_pa_type
  889:         ):
  890:             # decimal precision can resize in the result type depending on data
  891:             # just compare the float values
  892:             alt = getattr(obj, op_name)(other)
  893:             alt_dtype = tm.get_dtype(alt)
  894:             assert isinstance(alt_dtype, ArrowDtype)
  895:             if op_name == "__pow__" and isinstance(other, Decimal):
  896:                 # TODO: would it make more sense to retain Decimal here?
  897:                 alt_dtype = ArrowDtype(pa.float64())
  898:             elif (
  899:                 op_name == "__pow__"
  900:                 and isinstance(other, pd.Series)
  901:                 and other.dtype == original_dtype
  902:             ):
  903:                 # TODO: would it make more sense to retain Decimal here?
  904:                 alt_dtype = ArrowDtype(pa.float64())
  905:             else:
  906:                 assert pa.types.is_decimal(alt_dtype.pyarrow_dtype)
  907:             return expected.astype(alt_dtype)
  908: 
  909:         else:
  910:             pa_expected = pa_expected.cast(orig_pa_type)
  911: 
  912:         pd_expected = type(expected_data._values)(pa_expected)
  913:         if was_frame:
  914:             expected = pd.DataFrame(
  915:                 pd_expected, index=expected.index, columns=expected.columns
  916:             )
  917:         else:
  918:             expected = pd.Series(pd_expected)
  919:         return expected
  920: 
  921:     def _is_temporal_supported(self, opname, pa_dtype):
  922:         return (
  923:             (
  924:                 opname in ("__add__", "__radd__")
  925:                 or (
  926:                     opname
  927:                     in ("__truediv__", "__rtruediv__", "__floordiv__", "__rfloordiv__")
  928:                     and not pa_version_under14p0
  929:                 )
  930:             )
  931:             and pa.types.is_duration(pa_dtype)
  932:             or opname in ("__sub__", "__rsub__")
  933:             and pa.types.is_temporal(pa_dtype)
  934:         )
  935: 
  936:     def _get_expected_exception(
  937:         self, op_name: str, obj, other
  938:     ) -> type[Exception] | None:
  939:         if op_name in ("__divmod__", "__rdivmod__"):
  940:             return self.divmod_exc
  941: 
  942:         dtype = tm.get_dtype(obj)
  943:         # error: Item "dtype[Any]" of "dtype[Any] | ExtensionDtype" has no
  944:         # attribute "pyarrow_dtype"
  945:         pa_dtype = dtype.pyarrow_dtype  # type: ignore[union-attr]
  946: 
  947:         arrow_temporal_supported = self._is_temporal_supported(op_name, pa_dtype)
  948:         if op_name in {
  949:             "__mod__",
  950:             "__rmod__",
  951:         }:
  952:             exc = NotImplementedError
  953:         elif arrow_temporal_supported:
  954:             exc = None
  955:         elif op_name in ["__add__", "__radd__"] and (
  956:             pa.types.is_string(pa_dtype) or pa.types.is_binary(pa_dtype)
  957:         ):
  958:             exc = None
  959:         elif not (
  960:             pa.types.is_floating(pa_dtype)
  961:             or pa.types.is_integer(pa_dtype)
  962:             or pa.types.is_decimal(pa_dtype)
  963:         ):
  964:             # TODO: in many of these cases, e.g. non-duration temporal,
  965:             #  these will *never* be allowed. Would it make more sense to
  966:             #  re-raise as TypeError, more consistent with non-pyarrow cases?
  967:             exc = pa.ArrowNotImplementedError
  968:         else:
  969:             exc = None
  970:         return exc
  971: 
  972:     def _get_arith_xfail_marker(self, opname, pa_dtype):
  973:         mark = None
  974: 
  975:         arrow_temporal_supported = self._is_temporal_supported(opname, pa_dtype)
  976: 
  977:         if opname == "__rpow__" and (
  978:             pa.types.is_floating(pa_dtype)
  979:             or pa.types.is_integer(pa_dtype)
  980:             or pa.types.is_decimal(pa_dtype)
  981:         ):
  982:             mark = pytest.mark.xfail(
  983:                 reason=(
  984:                     f"GH#29997: 1**pandas.NA == 1 while 1**pyarrow.NA == NULL "
  985:                     f"for {pa_dtype}"
  986:                 )
  987:             )
  988:         elif arrow_temporal_supported and (
  989:             pa.types.is_time(pa_dtype)
  990:             or (
  991:                 opname
  992:                 in ("__truediv__", "__rtruediv__", "__floordiv__", "__rfloordiv__")
  993:                 and pa.types.is_duration(pa_dtype)
  994:             )
  995:         ):
  996:             mark = pytest.mark.xfail(
  997:                 raises=TypeError,
  998:                 reason=(
  999:                     f"{opname} not supported between"
 1000:                     f"pd.NA and {pa_dtype} Python scalar"
 1001:                 ),
 1002:             )
 1003:         elif opname == "__rfloordiv__" and (
 1004:             pa.types.is_integer(pa_dtype) or pa.types.is_decimal(pa_dtype)
 1005:         ):
 1006:             mark = pytest.mark.xfail(
 1007:                 raises=pa.ArrowInvalid,
 1008:                 reason="divide by 0",
 1009:             )
 1010:         elif opname == "__rtruediv__" and pa.types.is_decimal(pa_dtype):
 1011:             mark = pytest.mark.xfail(
 1012:                 raises=pa.ArrowInvalid,
 1013:                 reason="divide by 0",
 1014:             )
 1015: 
 1016:         return mark
 1017: 
 1018:     def test_arith_series_with_scalar(self, data, all_arithmetic_operators, request):
 1019:         pa_dtype = data.dtype.pyarrow_dtype
 1020: 
 1021:         if all_arithmetic_operators == "__rmod__" and pa.types.is_binary(pa_dtype):
 1022:             pytest.skip("Skip testing Python string formatting")
 1023:         elif all_arithmetic_operators in ("__rmul__", "__mul__") and (
 1024:             pa.types.is_binary(pa_dtype) or pa.types.is_string(pa_dtype)
 1025:         ):
 1026:             request.applymarker(
 1027:                 pytest.mark.xfail(
 1028:                     raises=TypeError, reason="Can only string multiply by an integer."
 1029:                 )
 1030:             )
 1031: 
 1032:         mark = self._get_arith_xfail_marker(all_arithmetic_operators, pa_dtype)
 1033:         if mark is not None:
 1034:             request.applymarker(mark)
 1035: 
 1036:         super().test_arith_series_with_scalar(data, all_arithmetic_operators)
 1037: 
 1038:     def test_arith_frame_with_scalar(self, data, all_arithmetic_operators, request):
 1039:         pa_dtype = data.dtype.pyarrow_dtype
 1040: 
 1041:         if all_arithmetic_operators == "__rmod__" and (
 1042:             pa.types.is_string(pa_dtype) or pa.types.is_binary(pa_dtype)
 1043:         ):
 1044:             pytest.skip("Skip testing Python string formatting")
 1045:         elif all_arithmetic_operators in ("__rmul__", "__mul__") and (
 1046:             pa.types.is_binary(pa_dtype) or pa.types.is_string(pa_dtype)
 1047:         ):
 1048:             request.applymarker(
 1049:                 pytest.mark.xfail(
 1050:                     raises=TypeError, reason="Can only string multiply by an integer."
 1051:                 )
 1052:             )
 1053: 
 1054:         mark = self._get_arith_xfail_marker(all_arithmetic_operators, pa_dtype)
 1055:         if mark is not None:
 1056:             request.applymarker(mark)
 1057: 
 1058:         super().test_arith_frame_with_scalar(data, all_arithmetic_operators)
 1059: 
 1060:     def test_arith_series_with_array(self, data, all_arithmetic_operators, request):
 1061:         pa_dtype = data.dtype.pyarrow_dtype
 1062: 
 1063:         if all_arithmetic_operators in (
 1064:             "__sub__",
 1065:             "__rsub__",
 1066:         ) and pa.types.is_unsigned_integer(pa_dtype):
 1067:             request.applymarker(
 1068:                 pytest.mark.xfail(
 1069:                     raises=pa.ArrowInvalid,
 1070:                     reason=(
 1071:                         f"Implemented pyarrow.compute.subtract_checked "
 1072:                         f"which raises on overflow for {pa_dtype}"
 1073:                     ),
 1074:                 )
 1075:             )
 1076:         elif all_arithmetic_operators in ("__rmul__", "__mul__") and (
 1077:             pa.types.is_binary(pa_dtype) or pa.types.is_string(pa_dtype)
 1078:         ):
 1079:             request.applymarker(
 1080:                 pytest.mark.xfail(
 1081:                     raises=TypeError, reason="Can only string multiply by an integer."
 1082:                 )
 1083:             )
 1084: 
 1085:         mark = self._get_arith_xfail_marker(all_arithmetic_operators, pa_dtype)
 1086:         if mark is not None:
 1087:             request.applymarker(mark)
 1088: 
 1089:         op_name = all_arithmetic_operators
 1090:         ser = pd.Series(data)
 1091:         # pd.Series([ser.iloc[0]] * len(ser)) may not return ArrowExtensionArray
 1092:         # since ser.iloc[0] is a python scalar
 1093:         other = pd.Series(pd.array([ser.iloc[0]] * len(ser), dtype=data.dtype))
 1094: 
 1095:         self.check_opname(ser, op_name, other)
 1096: 
 1097:     def test_add_series_with_extension_array(self, data, request):
 1098:         pa_dtype = data.dtype.pyarrow_dtype
 1099: 
 1100:         if pa_dtype.equals("int8"):
 1101:             request.applymarker(
 1102:                 pytest.mark.xfail(
 1103:                     raises=pa.ArrowInvalid,
 1104:                     reason=f"raises on overflow for {pa_dtype}",
 1105:                 )
 1106:             )
 1107:         super().test_add_series_with_extension_array(data)
 1108: 
 1109:     def test_invalid_other_comp(self, data, comparison_op):
 1110:         # GH 48833
 1111:         with pytest.raises(
 1112:             NotImplementedError, match=".* not implemented for <class 'object'>"
 1113:         ):
 1114:             comparison_op(data, object())
 1115: 
 1116:     @pytest.mark.parametrize("masked_dtype", ["boolean", "Int64", "Float64"])
 1117:     def test_comp_masked_numpy(self, masked_dtype, comparison_op):
 1118:         # GH 52625
 1119:         data = [1, 0, None]
 1120:         ser_masked = pd.Series(data, dtype=masked_dtype)
 1121:         ser_pa = pd.Series(data, dtype=f"{masked_dtype.lower()}[pyarrow]")
 1122:         result = comparison_op(ser_pa, ser_masked)
 1123:         if comparison_op in [operator.lt, operator.gt, operator.ne]:
 1124:             exp = [False, False, None]
 1125:         else:
 1126:             exp = [True, True, None]
 1127:         expected = pd.Series(exp, dtype=ArrowDtype(pa.bool_()))
 1128:         tm.assert_series_equal(result, expected)
 1129: 
 1130: 
 1131: class TestLogicalOps:
 1132:     """Various Series and DataFrame logical ops methods."""
 1133: 
 1134:     def test_kleene_or(self):
 1135:         a = pd.Series([True] * 3 + [False] * 3 + [None] * 3, dtype="boolean[pyarrow]")
 1136:         b = pd.Series([True, False, None] * 3, dtype="boolean[pyarrow]")
 1137:         result = a | b
 1138:         expected = pd.Series(
 1139:             [True, True, True, True, False, None, True, None, None],
 1140:             dtype="boolean[pyarrow]",
 1141:         )
 1142:         tm.assert_series_equal(result, expected)
 1143: 
 1144:         result = b | a
 1145:         tm.assert_series_equal(result, expected)
 1146: 
 1147:         # ensure we haven't mutated anything inplace
 1148:         tm.assert_series_equal(
 1149:             a,
 1150:             pd.Series([True] * 3 + [False] * 3 + [None] * 3, dtype="boolean[pyarrow]"),
 1151:         )
 1152:         tm.assert_series_equal(
 1153:             b, pd.Series([True, False, None] * 3, dtype="boolean[pyarrow]")
 1154:         )
 1155: 
 1156:     @pytest.mark.parametrize(
 1157:         "other, expected",
 1158:         [
 1159:             (None, [True, None, None]),
 1160:             (pd.NA, [True, None, None]),
 1161:             (True, [True, True, True]),
 1162:             (np.bool_(True), [True, True, True]),
 1163:             (False, [True, False, None]),
 1164:             (np.bool_(False), [True, False, None]),
 1165:         ],
 1166:     )
 1167:     def test_kleene_or_scalar(self, other, expected):
 1168:         a = pd.Series([True, False, None], dtype="boolean[pyarrow]")
 1169:         result = a | other
 1170:         expected = pd.Series(expected, dtype="boolean[pyarrow]")
 1171:         tm.assert_series_equal(result, expected)
 1172: 
 1173:         result = other | a
 1174:         tm.assert_series_equal(result, expected)
 1175: 
 1176:         # ensure we haven't mutated anything inplace
 1177:         tm.assert_series_equal(
 1178:             a, pd.Series([True, False, None], dtype="boolean[pyarrow]")
 1179:         )
 1180: 
 1181:     def test_kleene_and(self):
 1182:         a = pd.Series([True] * 3 + [False] * 3 + [None] * 3, dtype="boolean[pyarrow]")
 1183:         b = pd.Series([True, False, None] * 3, dtype="boolean[pyarrow]")
 1184:         result = a & b
 1185:         expected = pd.Series(
 1186:             [True, False, None, False, False, False, None, False, None],
 1187:             dtype="boolean[pyarrow]",
 1188:         )
 1189:         tm.assert_series_equal(result, expected)
 1190: 
 1191:         result = b & a
 1192:         tm.assert_series_equal(result, expected)
 1193: 
 1194:         # ensure we haven't mutated anything inplace
 1195:         tm.assert_series_equal(
 1196:             a,
 1197:             pd.Series([True] * 3 + [False] * 3 + [None] * 3, dtype="boolean[pyarrow]"),
 1198:         )
 1199:         tm.assert_series_equal(
 1200:             b, pd.Series([True, False, None] * 3, dtype="boolean[pyarrow]")
 1201:         )
 1202: 
 1203:     @pytest.mark.parametrize(
 1204:         "other, expected",
 1205:         [
 1206:             (None, [None, False, None]),
 1207:             (pd.NA, [None, False, None]),
 1208:             (True, [True, False, None]),
 1209:             (False, [False, False, False]),
 1210:             (np.bool_(True), [True, False, None]),
 1211:             (np.bool_(False), [False, False, False]),
 1212:         ],
 1213:     )
 1214:     def test_kleene_and_scalar(self, other, expected):
 1215:         a = pd.Series([True, False, None], dtype="boolean[pyarrow]")
 1216:         result = a & other
 1217:         expected = pd.Series(expected, dtype="boolean[pyarrow]")
 1218:         tm.assert_series_equal(result, expected)
 1219: 
 1220:         result = other & a
 1221:         tm.assert_series_equal(result, expected)
 1222: 
 1223:         # ensure we haven't mutated anything inplace
 1224:         tm.assert_series_equal(
 1225:             a, pd.Series([True, False, None], dtype="boolean[pyarrow]")
 1226:         )
 1227: 
 1228:     def test_kleene_xor(self):
 1229:         a = pd.Series([True] * 3 + [False] * 3 + [None] * 3, dtype="boolean[pyarrow]")
 1230:         b = pd.Series([True, False, None] * 3, dtype="boolean[pyarrow]")
 1231:         result = a ^ b
 1232:         expected = pd.Series(
 1233:             [False, True, None, True, False, None, None, None, None],
 1234:             dtype="boolean[pyarrow]",
 1235:         )
 1236:         tm.assert_series_equal(result, expected)
 1237: 
 1238:         result = b ^ a
 1239:         tm.assert_series_equal(result, expected)
 1240: 
 1241:         # ensure we haven't mutated anything inplace
 1242:         tm.assert_series_equal(
 1243:             a,
 1244:             pd.Series([True] * 3 + [False] * 3 + [None] * 3, dtype="boolean[pyarrow]"),
 1245:         )
 1246:         tm.assert_series_equal(
 1247:             b, pd.Series([True, False, None] * 3, dtype="boolean[pyarrow]")
 1248:         )
 1249: 
 1250:     @pytest.mark.parametrize(
 1251:         "other, expected",
 1252:         [
 1253:             (None, [None, None, None]),
 1254:             (pd.NA, [None, None, None]),
 1255:             (True, [False, True, None]),
 1256:             (np.bool_(True), [False, True, None]),
 1257:             (np.bool_(False), [True, False, None]),
 1258:         ],
 1259:     )
 1260:     def test_kleene_xor_scalar(self, other, expected):
 1261:         a = pd.Series([True, False, None], dtype="boolean[pyarrow]")
 1262:         result = a ^ other
 1263:         expected = pd.Series(expected, dtype="boolean[pyarrow]")
 1264:         tm.assert_series_equal(result, expected)
 1265: 
 1266:         result = other ^ a
 1267:         tm.assert_series_equal(result, expected)
 1268: 
 1269:         # ensure we haven't mutated anything inplace
 1270:         tm.assert_series_equal(
 1271:             a, pd.Series([True, False, None], dtype="boolean[pyarrow]")
 1272:         )
 1273: 
 1274:     @pytest.mark.parametrize(
 1275:         "op, exp",
 1276:         [
 1277:             ["__and__", True],
 1278:             ["__or__", True],
 1279:             ["__xor__", False],
 1280:         ],
 1281:     )
 1282:     def test_logical_masked_numpy(self, op, exp):
 1283:         # GH 52625
 1284:         data = [True, False, None]
 1285:         ser_masked = pd.Series(data, dtype="boolean")
 1286:         ser_pa = pd.Series(data, dtype="boolean[pyarrow]")
 1287:         result = getattr(ser_pa, op)(ser_masked)
 1288:         expected = pd.Series([exp, False, None], dtype=ArrowDtype(pa.bool_()))
 1289:         tm.assert_series_equal(result, expected)
 1290: 
 1291: 
 1292: @pytest.mark.parametrize("pa_type", tm.ALL_INT_PYARROW_DTYPES)
 1293: def test_bitwise(pa_type):
 1294:     # GH 54495
 1295:     dtype = ArrowDtype(pa_type)
 1296:     left = pd.Series([1, None, 3, 4], dtype=dtype)
 1297:     right = pd.Series([None, 3, 5, 4], dtype=dtype)
 1298: 
 1299:     result = left | right
 1300:     expected = pd.Series([None, None, 3 | 5, 4 | 4], dtype=dtype)
 1301:     tm.assert_series_equal(result, expected)
 1302: 
 1303:     result = left & right
 1304:     expected = pd.Series([None, None, 3 & 5, 4 & 4], dtype=dtype)
 1305:     tm.assert_series_equal(result, expected)
 1306: 
 1307:     result = left ^ right
 1308:     expected = pd.Series([None, None, 3 ^ 5, 4 ^ 4], dtype=dtype)
 1309:     tm.assert_series_equal(result, expected)
 1310: 
 1311:     result = ~left
 1312:     expected = ~(left.fillna(0).to_numpy())
 1313:     expected = pd.Series(expected, dtype=dtype).mask(left.isnull())
 1314:     tm.assert_series_equal(result, expected)
 1315: 
 1316: 
 1317: def test_arrowdtype_construct_from_string_type_with_unsupported_parameters():
 1318:     with pytest.raises(NotImplementedError, match="Passing pyarrow type"):
 1319:         ArrowDtype.construct_from_string("not_a_real_dype[s, tz=UTC][pyarrow]")
 1320: 
 1321:     with pytest.raises(NotImplementedError, match="Passing pyarrow type"):
 1322:         ArrowDtype.construct_from_string("decimal(7, 2)[pyarrow]")
 1323: 
 1324: 
 1325: def test_arrowdtype_construct_from_string_supports_dt64tz():
 1326:     # as of GH#50689, timestamptz is supported
 1327:     dtype = ArrowDtype.construct_from_string("timestamp[s, tz=UTC][pyarrow]")
 1328:     expected = ArrowDtype(pa.timestamp("s", "UTC"))
 1329:     assert dtype == expected
 1330: 
 1331: 
 1332: def test_arrowdtype_construct_from_string_type_only_one_pyarrow():
 1333:     # GH#51225
 1334:     invalid = "int64[pyarrow]foobar[pyarrow]"
 1335:     msg = (
 1336:         r"Passing pyarrow type specific parameters \(\[pyarrow\]\) in the "
 1337:         r"string is not supported\."
 1338:     )
 1339:     with pytest.raises(NotImplementedError, match=msg):
 1340:         pd.Series(range(3), dtype=invalid)
 1341: 
 1342: 
 1343: def test_arrow_string_multiplication():
 1344:     # GH 56537
 1345:     binary = pd.Series(["abc", "defg"], dtype=ArrowDtype(pa.string()))
 1346:     repeat = pd.Series([2, -2], dtype="int64[pyarrow]")
 1347:     result = binary * repeat
 1348:     expected = pd.Series(["abcabc", ""], dtype=ArrowDtype(pa.string()))
 1349:     tm.assert_series_equal(result, expected)
 1350:     reflected_result = repeat * binary
 1351:     tm.assert_series_equal(result, reflected_result)
 1352: 
 1353: 
 1354: def test_arrow_string_multiplication_scalar_repeat():
 1355:     binary = pd.Series(["abc", "defg"], dtype=ArrowDtype(pa.string()))
 1356:     result = binary * 2
 1357:     expected = pd.Series(["abcabc", "defgdefg"], dtype=ArrowDtype(pa.string()))
 1358:     tm.assert_series_equal(result, expected)
 1359:     reflected_result = 2 * binary
 1360:     tm.assert_series_equal(reflected_result, expected)
 1361: 
 1362: 
 1363: @pytest.mark.parametrize(
 1364:     "interpolation", ["linear", "lower", "higher", "nearest", "midpoint"]
 1365: )
 1366: @pytest.mark.parametrize("quantile", [0.5, [0.5, 0.5]])
 1367: def test_quantile(data, interpolation, quantile, request):
 1368:     pa_dtype = data.dtype.pyarrow_dtype
 1369: 
 1370:     data = data.take([0, 0, 0])
 1371:     ser = pd.Series(data)
 1372: 
 1373:     if (
 1374:         pa.types.is_string(pa_dtype)
 1375:         or pa.types.is_binary(pa_dtype)
 1376:         or pa.types.is_boolean(pa_dtype)
 1377:     ):
 1378:         # For string, bytes, and bool, we don't *expect* to have quantile work
 1379:         # Note this matches the non-pyarrow behavior
 1380:         msg = r"Function 'quantile' has no kernel matching input types \(.*\)"
 1381:         with pytest.raises(pa.ArrowNotImplementedError, match=msg):
 1382:             ser.quantile(q=quantile, interpolation=interpolation)
 1383:         return
 1384: 
 1385:     if (
 1386:         pa.types.is_integer(pa_dtype)
 1387:         or pa.types.is_floating(pa_dtype)
 1388:         or pa.types.is_decimal(pa_dtype)
 1389:     ):
 1390:         pass
 1391:     elif pa.types.is_temporal(data._pa_array.type):
 1392:         pass
 1393:     else:
 1394:         request.applymarker(
 1395:             pytest.mark.xfail(
 1396:                 raises=pa.ArrowNotImplementedError,
 1397:                 reason=f"quantile not supported by pyarrow for {pa_dtype}",
 1398:             )
 1399:         )
 1400:     data = data.take([0, 0, 0])
 1401:     ser = pd.Series(data)
 1402:     result = ser.quantile(q=quantile, interpolation=interpolation)
 1403: 
 1404:     if pa.types.is_timestamp(pa_dtype) and interpolation not in ["lower", "higher"]:
 1405:         # rounding error will make the check below fail
 1406:         #  (e.g. '2020-01-01 01:01:01.000001' vs '2020-01-01 01:01:01.000001024'),
 1407:         #  so we'll check for now that we match the numpy analogue
 1408:         if pa_dtype.tz:
 1409:             pd_dtype = f"M8[{pa_dtype.unit}, {pa_dtype.tz}]"
 1410:         else:
 1411:             pd_dtype = f"M8[{pa_dtype.unit}]"
 1412:         ser_np = ser.astype(pd_dtype)
 1413: 
 1414:         expected = ser_np.quantile(q=quantile, interpolation=interpolation)
 1415:         if quantile == 0.5:
 1416:             if pa_dtype.unit == "us":
 1417:                 expected = expected.to_pydatetime(warn=False)
 1418:             assert result == expected
 1419:         else:
 1420:             if pa_dtype.unit == "us":
 1421:                 expected = expected.dt.floor("us")
 1422:             tm.assert_series_equal(result, expected.astype(data.dtype))
 1423:         return
 1424: 
 1425:     if quantile == 0.5:
 1426:         assert result == data[0]
 1427:     else:
 1428:         # Just check the values
 1429:         expected = pd.Series(data.take([0, 0]), index=[0.5, 0.5])
 1430:         if (
 1431:             pa.types.is_integer(pa_dtype)
 1432:             or pa.types.is_floating(pa_dtype)
 1433:             or pa.types.is_decimal(pa_dtype)
 1434:         ):
 1435:             expected = expected.astype("float64[pyarrow]")
 1436:             result = result.astype("float64[pyarrow]")
 1437:         tm.assert_series_equal(result, expected)
 1438: 
 1439: 
 1440: @pytest.mark.parametrize(
 1441:     "take_idx, exp_idx",
 1442:     [[[0, 0, 2, 2, 4, 4], [4, 0]], [[0, 0, 0, 2, 4, 4], [0]]],
 1443:     ids=["multi_mode", "single_mode"],
 1444: )
 1445: def test_mode_dropna_true(data_for_grouping, take_idx, exp_idx):
 1446:     data = data_for_grouping.take(take_idx)
 1447:     ser = pd.Series(data)
 1448:     result = ser.mode(dropna=True)
 1449:     expected = pd.Series(data_for_grouping.take(exp_idx))
 1450:     tm.assert_series_equal(result, expected)
 1451: 
 1452: 
 1453: def test_mode_dropna_false_mode_na(data):
 1454:     # GH 50982
 1455:     more_nans = pd.Series([None, None, data[0]], dtype=data.dtype)
 1456:     result = more_nans.mode(dropna=False)
 1457:     expected = pd.Series([None], dtype=data.dtype)
 1458:     tm.assert_series_equal(result, expected)
 1459: 
 1460:     expected = pd.Series([data[0], None], dtype=data.dtype)
 1461:     result = expected.mode(dropna=False)
 1462:     tm.assert_series_equal(result, expected)
 1463: 
 1464: 
 1465: @pytest.mark.parametrize(
 1466:     "arrow_dtype, expected_type",
 1467:     [
 1468:         [pa.binary(), bytes],
 1469:         [pa.binary(16), bytes],
 1470:         [pa.large_binary(), bytes],
 1471:         [pa.large_string(), str],
 1472:         [pa.list_(pa.int64()), list],
 1473:         [pa.large_list(pa.int64()), list],
 1474:         [pa.map_(pa.string(), pa.int64()), list],
 1475:         [pa.struct([("f1", pa.int8()), ("f2", pa.string())]), dict],
 1476:         [pa.dictionary(pa.int64(), pa.int64()), CategoricalDtypeType],
 1477:     ],
 1478: )
 1479: def test_arrow_dtype_type(arrow_dtype, expected_type):
 1480:     # GH 51845
 1481:     # TODO: Redundant with test_getitem_scalar once arrow_dtype exists in data fixture
 1482:     assert ArrowDtype(arrow_dtype).type == expected_type
 1483: 
 1484: 
 1485: def test_is_bool_dtype():
 1486:     # GH 22667
 1487:     data = ArrowExtensionArray(pa.array([True, False, True]))
 1488:     assert is_bool_dtype(data)
 1489:     assert pd.core.common.is_bool_indexer(data)
 1490:     s = pd.Series(range(len(data)))
 1491:     result = s[data]
 1492:     expected = s[np.asarray(data)]
 1493:     tm.assert_series_equal(result, expected)
 1494: 
 1495: 
 1496: def test_is_numeric_dtype(data):
 1497:     # GH 50563
 1498:     pa_type = data.dtype.pyarrow_dtype
 1499:     if (
 1500:         pa.types.is_floating(pa_type)
 1501:         or pa.types.is_integer(pa_type)
 1502:         or pa.types.is_decimal(pa_type)
 1503:     ):
 1504:         assert is_numeric_dtype(data)
 1505:     else:
 1506:         assert not is_numeric_dtype(data)
 1507: 
 1508: 
 1509: def test_is_integer_dtype(data):
 1510:     # GH 50667
 1511:     pa_type = data.dtype.pyarrow_dtype
 1512:     if pa.types.is_integer(pa_type):
 1513:         assert is_integer_dtype(data)
 1514:     else:
 1515:         assert not is_integer_dtype(data)
 1516: 
 1517: 
 1518: def test_is_signed_integer_dtype(data):
 1519:     pa_type = data.dtype.pyarrow_dtype
 1520:     if pa.types.is_signed_integer(pa_type):
 1521:         assert is_signed_integer_dtype(data)
 1522:     else:
 1523:         assert not is_signed_integer_dtype(data)
 1524: 
 1525: 
 1526: def test_is_unsigned_integer_dtype(data):
 1527:     pa_type = data.dtype.pyarrow_dtype
 1528:     if pa.types.is_unsigned_integer(pa_type):
 1529:         assert is_unsigned_integer_dtype(data)
 1530:     else:
 1531:         assert not is_unsigned_integer_dtype(data)
 1532: 
 1533: 
 1534: def test_is_float_dtype(data):
 1535:     pa_type = data.dtype.pyarrow_dtype
 1536:     if pa.types.is_floating(pa_type):
 1537:         assert is_float_dtype(data)
 1538:     else:
 1539:         assert not is_float_dtype(data)
 1540: 
 1541: 
 1542: def test_pickle_roundtrip(data):
 1543:     # GH 42600
 1544:     expected = pd.Series(data)
 1545:     expected_sliced = expected.head(2)
 1546:     full_pickled = pickle.dumps(expected)
 1547:     sliced_pickled = pickle.dumps(expected_sliced)
 1548: 
 1549:     assert len(full_pickled) > len(sliced_pickled)
 1550: 
 1551:     result = pickle.loads(full_pickled)
 1552:     tm.assert_series_equal(result, expected)
 1553: 
 1554:     result_sliced = pickle.loads(sliced_pickled)
 1555:     tm.assert_series_equal(result_sliced, expected_sliced)
 1556: 
 1557: 
 1558: def test_astype_from_non_pyarrow(data):
 1559:     # GH49795
 1560:     pd_array = data._pa_array.to_pandas().array
 1561:     result = pd_array.astype(data.dtype)
 1562:     assert not isinstance(pd_array.dtype, ArrowDtype)
 1563:     assert isinstance(result.dtype, ArrowDtype)
 1564:     tm.assert_extension_array_equal(result, data)
 1565: 
 1566: 
 1567: def test_astype_float_from_non_pyarrow_str():
 1568:     # GH50430
 1569:     ser = pd.Series(["1.0"])
 1570:     result = ser.astype("float64[pyarrow]")
 1571:     expected = pd.Series([1.0], dtype="float64[pyarrow]")
 1572:     tm.assert_series_equal(result, expected)
 1573: 
 1574: 
 1575: def test_astype_errors_ignore():
 1576:     # GH 55399
 1577:     expected = pd.DataFrame({"col": [17000000]}, dtype="int32[pyarrow]")
 1578:     result = expected.astype("float[pyarrow]", errors="ignore")
 1579:     tm.assert_frame_equal(result, expected)
 1580: 
 1581: 
 1582: def test_to_numpy_with_defaults(data):
 1583:     # GH49973
 1584:     result = data.to_numpy()
 1585: 
 1586:     pa_type = data._pa_array.type
 1587:     if pa.types.is_duration(pa_type) or pa.types.is_timestamp(pa_type):
 1588:         pytest.skip("Tested in test_to_numpy_temporal")
 1589:     elif pa.types.is_date(pa_type):
 1590:         expected = np.array(list(data))
 1591:     else:
 1592:         expected = np.array(data._pa_array)
 1593: 
 1594:     if data._hasna and not is_numeric_dtype(data.dtype):
 1595:         expected = expected.astype(object)
 1596:         expected[pd.isna(data)] = pd.NA
 1597: 
 1598:     tm.assert_numpy_array_equal(result, expected)
 1599: 
 1600: 
 1601: def test_to_numpy_int_with_na():
 1602:     # GH51227: ensure to_numpy does not convert int to float
 1603:     data = [1, None]
 1604:     arr = pd.array(data, dtype="int64[pyarrow]")
 1605:     result = arr.to_numpy()
 1606:     expected = np.array([1, np.nan])
 1607:     assert isinstance(result[0], float)
 1608:     tm.assert_numpy_array_equal(result, expected)
 1609: 
 1610: 
 1611: @pytest.mark.parametrize("na_val, exp", [(lib.no_default, np.nan), (1, 1)])
 1612: def test_to_numpy_null_array(na_val, exp):
 1613:     # GH#52443
 1614:     arr = pd.array([pd.NA, pd.NA], dtype="null[pyarrow]")
 1615:     result = arr.to_numpy(dtype="float64", na_value=na_val)
 1616:     expected = np.array([exp] * 2, dtype="float64")
 1617:     tm.assert_numpy_array_equal(result, expected)
 1618: 
 1619: 
 1620: def test_to_numpy_null_array_no_dtype():
 1621:     # GH#52443
 1622:     arr = pd.array([pd.NA, pd.NA], dtype="null[pyarrow]")
 1623:     result = arr.to_numpy(dtype=None)
 1624:     expected = np.array([pd.NA] * 2, dtype="object")
 1625:     tm.assert_numpy_array_equal(result, expected)
 1626: 
 1627: 
 1628: def test_to_numpy_without_dtype():
 1629:     # GH 54808
 1630:     arr = pd.array([True, pd.NA], dtype="boolean[pyarrow]")
 1631:     result = arr.to_numpy(na_value=False)
 1632:     expected = np.array([True, False], dtype=np.bool_)
 1633:     tm.assert_numpy_array_equal(result, expected)
 1634: 
 1635:     arr = pd.array([1.0, pd.NA], dtype="float32[pyarrow]")
 1636:     result = arr.to_numpy(na_value=0.0)
 1637:     expected = np.array([1.0, 0.0], dtype=np.float32)
 1638:     tm.assert_numpy_array_equal(result, expected)
 1639: 
 1640: 
 1641: def test_setitem_null_slice(data):
 1642:     # GH50248
 1643:     orig = data.copy()
 1644: 
 1645:     result = orig.copy()
 1646:     result[:] = data[0]
 1647:     expected = ArrowExtensionArray._from_sequence(
 1648:         [data[0]] * len(data),
 1649:         dtype=data.dtype,
 1650:     )
 1651:     tm.assert_extension_array_equal(result, expected)
 1652: 
 1653:     result = orig.copy()
 1654:     result[:] = data[::-1]
 1655:     expected = data[::-1]
 1656:     tm.assert_extension_array_equal(result, expected)
 1657: 
 1658:     result = orig.copy()
 1659:     result[:] = data.tolist()
 1660:     expected = data
 1661:     tm.assert_extension_array_equal(result, expected)
 1662: 
 1663: 
 1664: def test_setitem_invalid_dtype(data):
 1665:     # GH50248
 1666:     pa_type = data._pa_array.type
 1667:     if pa.types.is_string(pa_type) or pa.types.is_binary(pa_type):
 1668:         fill_value = 123
 1669:         err = TypeError
 1670:         msg = "Invalid value '123' for dtype"
 1671:     elif (
 1672:         pa.types.is_integer(pa_type)
 1673:         or pa.types.is_floating(pa_type)
 1674:         or pa.types.is_boolean(pa_type)
 1675:     ):
 1676:         fill_value = "foo"
 1677:         err = pa.ArrowInvalid
 1678:         msg = "Could not convert"
 1679:     else:
 1680:         fill_value = "foo"
 1681:         err = TypeError
 1682:         msg = "Invalid value 'foo' for dtype"
 1683:     with pytest.raises(err, match=msg):
 1684:         data[:] = fill_value
 1685: 
 1686: 
 1687: def test_from_arrow_respecting_given_dtype():
 1688:     date_array = pa.array(
 1689:         [pd.Timestamp("2019-12-31"), pd.Timestamp("2019-12-31")], type=pa.date32()
 1690:     )
 1691:     result = date_array.to_pandas(
 1692:         types_mapper={pa.date32(): ArrowDtype(pa.date64())}.get
 1693:     )
 1694:     expected = pd.Series(
 1695:         [pd.Timestamp("2019-12-31"), pd.Timestamp("2019-12-31")],
 1696:         dtype=ArrowDtype(pa.date64()),
 1697:     )
 1698:     tm.assert_series_equal(result, expected)
 1699: 
 1700: 
 1701: def test_from_arrow_respecting_given_dtype_unsafe():
 1702:     array = pa.array([1.5, 2.5], type=pa.float64())
 1703:     with pytest.raises(pa.ArrowInvalid, match="Float value 1.5 was truncated"):
 1704:         array.to_pandas(types_mapper={pa.float64(): ArrowDtype(pa.int64())}.get)
 1705: 
 1706: 
 1707: def test_round():
 1708:     dtype = "float64[pyarrow]"
 1709: 
 1710:     ser = pd.Series([0.0, 1.23, 2.56, pd.NA], dtype=dtype)
 1711:     result = ser.round(1)
 1712:     expected = pd.Series([0.0, 1.2, 2.6, pd.NA], dtype=dtype)
 1713:     tm.assert_series_equal(result, expected)
 1714: 
 1715:     ser = pd.Series([123.4, pd.NA, 56.78], dtype=dtype)
 1716:     result = ser.round(-1)
 1717:     expected = pd.Series([120.0, pd.NA, 60.0], dtype=dtype)
 1718:     tm.assert_series_equal(result, expected)
 1719: 
 1720: 
 1721: def test_searchsorted_with_na_raises(data_for_sorting, as_series):
 1722:     # GH50447
 1723:     b, c, a = data_for_sorting
 1724:     arr = data_for_sorting.take([2, 0, 1])  # to get [a, b, c]
 1725:     arr[-1] = pd.NA
 1726: 
 1727:     if as_series:
 1728:         arr = pd.Series(arr)
 1729: 
 1730:     msg = (
 1731:         "searchsorted requires array to be sorted, "
 1732:         "which is impossible with NAs present."
 1733:     )
 1734:     with pytest.raises(ValueError, match=msg):
 1735:         arr.searchsorted(b)
 1736: 
 1737: 
 1738: def test_sort_values_dictionary():
 1739:     df = pd.DataFrame(
 1740:         {
 1741:             "a": pd.Series(
 1742:                 ["x", "y"], dtype=ArrowDtype(pa.dictionary(pa.int32(), pa.string()))
 1743:             ),
 1744:             "b": [1, 2],
 1745:         },
 1746:     )
 1747:     expected = df.copy()
 1748:     result = df.sort_values(by=["a", "b"])
 1749:     tm.assert_frame_equal(result, expected)
 1750: 
 1751: 
 1752: @pytest.mark.parametrize("pat", ["abc", "a[a-z]{2}"])
 1753: def test_str_count(pat):
 1754:     ser = pd.Series(["abc", None], dtype=ArrowDtype(pa.string()))
 1755:     result = ser.str.count(pat)
 1756:     expected = pd.Series([1, None], dtype=ArrowDtype(pa.int32()))
 1757:     tm.assert_series_equal(result, expected)
 1758: 
 1759: 
 1760: def test_str_count_flags_unsupported():
 1761:     ser = pd.Series(["abc", None], dtype=ArrowDtype(pa.string()))
 1762:     with pytest.raises(NotImplementedError, match="count not"):
 1763:         ser.str.count("abc", flags=1)
 1764: 
 1765: 
 1766: @pytest.mark.parametrize(
 1767:     "side, str_func", [["left", "rjust"], ["right", "ljust"], ["both", "center"]]
 1768: )
 1769: def test_str_pad(side, str_func):
 1770:     ser = pd.Series(["a", None], dtype=ArrowDtype(pa.string()))
 1771:     result = ser.str.pad(width=3, side=side, fillchar="x")
 1772:     expected = pd.Series(
 1773:         [getattr("a", str_func)(3, "x"), None], dtype=ArrowDtype(pa.string())
 1774:     )
 1775:     tm.assert_series_equal(result, expected)
 1776: 
 1777: 
 1778: def test_str_pad_invalid_side():
 1779:     ser = pd.Series(["a", None], dtype=ArrowDtype(pa.string()))
 1780:     with pytest.raises(ValueError, match="Invalid side: foo"):
 1781:         ser.str.pad(3, "foo", "x")
 1782: 
 1783: 
 1784: @pytest.mark.parametrize(
 1785:     "pat, case, na, regex, exp",
 1786:     [
 1787:         ["ab", False, None, False, [True, None]],
 1788:         ["Ab", True, None, False, [False, None]],
 1789:         ["ab", False, True, False, [True, True]],
 1790:         ["a[a-z]{1}", False, None, True, [True, None]],
 1791:         ["A[a-z]{1}", True, None, True, [False, None]],
 1792:     ],
 1793: )
 1794: def test_str_contains(pat, case, na, regex, exp):
 1795:     ser = pd.Series(["abc", None], dtype=ArrowDtype(pa.string()))
 1796:     result = ser.str.contains(pat, case=case, na=na, regex=regex)
 1797:     expected = pd.Series(exp, dtype=ArrowDtype(pa.bool_()))
 1798:     tm.assert_series_equal(result, expected)
 1799: 
 1800: 
 1801: def test_str_contains_flags_unsupported():
 1802:     ser = pd.Series(["abc", None], dtype=ArrowDtype(pa.string()))
 1803:     with pytest.raises(NotImplementedError, match="contains not"):
 1804:         ser.str.contains("a", flags=1)
 1805: 
 1806: 
 1807: @pytest.mark.parametrize(
 1808:     "side, pat, na, exp",
 1809:     [
 1810:         ["startswith", "ab", None, [True, None, False]],
 1811:         ["startswith", "b", False, [False, False, False]],
 1812:         ["endswith", "b", True, [False, True, False]],
 1813:         ["endswith", "bc", None, [True, None, False]],
 1814:         ["startswith", ("a", "e", "g"), None, [True, None, True]],
 1815:         ["endswith", ("a", "c", "g"), None, [True, None, True]],
 1816:         ["startswith", (), None, [False, None, False]],
 1817:         ["endswith", (), None, [False, None, False]],
 1818:     ],
 1819: )
 1820: def test_str_start_ends_with(side, pat, na, exp):
 1821:     ser = pd.Series(["abc", None, "efg"], dtype=ArrowDtype(pa.string()))
 1822:     result = getattr(ser.str, side)(pat, na=na)
 1823:     expected = pd.Series(exp, dtype=ArrowDtype(pa.bool_()))
 1824:     tm.assert_series_equal(result, expected)
 1825: 
 1826: 
 1827: @pytest.mark.parametrize("side", ("startswith", "endswith"))
 1828: def test_str_starts_ends_with_all_nulls_empty_tuple(side):
 1829:     ser = pd.Series([None, None], dtype=ArrowDtype(pa.string()))
 1830:     result = getattr(ser.str, side)(())
 1831: 
 1832:     # bool datatype preserved for all nulls.
 1833:     expected = pd.Series([None, None], dtype=ArrowDtype(pa.bool_()))
 1834:     tm.assert_series_equal(result, expected)
 1835: 
 1836: 
 1837: @pytest.mark.parametrize(
 1838:     "arg_name, arg",
 1839:     [["pat", re.compile("b")], ["repl", str], ["case", False], ["flags", 1]],
 1840: )
 1841: def test_str_replace_unsupported(arg_name, arg):
 1842:     ser = pd.Series(["abc", None], dtype=ArrowDtype(pa.string()))
 1843:     kwargs = {"pat": "b", "repl": "x", "regex": True}
 1844:     kwargs[arg_name] = arg
 1845:     with pytest.raises(NotImplementedError, match="replace is not supported"):
 1846:         ser.str.replace(**kwargs)
 1847: 
 1848: 
 1849: @pytest.mark.parametrize(
 1850:     "pat, repl, n, regex, exp",
 1851:     [
 1852:         ["a", "x", -1, False, ["xbxc", None]],
 1853:         ["a", "x", 1, False, ["xbac", None]],
 1854:         ["[a-b]", "x", -1, True, ["xxxc", None]],
 1855:     ],
 1856: )
 1857: def test_str_replace(pat, repl, n, regex, exp):
 1858:     ser = pd.Series(["abac", None], dtype=ArrowDtype(pa.string()))
 1859:     result = ser.str.replace(pat, repl, n=n, regex=regex)
 1860:     expected = pd.Series(exp, dtype=ArrowDtype(pa.string()))
 1861:     tm.assert_series_equal(result, expected)
 1862: 
 1863: 
 1864: def test_str_replace_negative_n():
 1865:     # GH 56404
 1866:     ser = pd.Series(["abc", "aaaaaa"], dtype=ArrowDtype(pa.string()))
 1867:     actual = ser.str.replace("a", "", -3, True)
 1868:     expected = pd.Series(["bc", ""], dtype=ArrowDtype(pa.string()))
 1869:     tm.assert_series_equal(expected, actual)
 1870: 
 1871: 
 1872: def test_str_repeat_unsupported():
 1873:     ser = pd.Series(["abc", None], dtype=ArrowDtype(pa.string()))
 1874:     with pytest.raises(NotImplementedError, match="repeat is not"):
 1875:         ser.str.repeat([1, 2])
 1876: 
 1877: 
 1878: def test_str_repeat():
 1879:     ser = pd.Series(["abc", None], dtype=ArrowDtype(pa.string()))
 1880:     result = ser.str.repeat(2)
 1881:     expected = pd.Series(["abcabc", None], dtype=ArrowDtype(pa.string()))
 1882:     tm.assert_series_equal(result, expected)
 1883: 
 1884: 
 1885: @pytest.mark.parametrize(
 1886:     "pat, case, na, exp",
 1887:     [
 1888:         ["ab", False, None, [True, None]],
 1889:         ["Ab", True, None, [False, None]],
 1890:         ["bc", True, None, [False, None]],
 1891:         ["ab", False, True, [True, True]],
 1892:         ["a[a-z]{1}", False, None, [True, None]],
 1893:         ["A[a-z]{1}", True, None, [False, None]],
 1894:     ],
 1895: )
 1896: def test_str_match(pat, case, na, exp):
 1897:     ser = pd.Series(["abc", None], dtype=ArrowDtype(pa.string()))
 1898:     result = ser.str.match(pat, case=case, na=na)
 1899:     expected = pd.Series(exp, dtype=ArrowDtype(pa.bool_()))
 1900:     tm.assert_series_equal(result, expected)
 1901: 
 1902: 
 1903: @pytest.mark.parametrize(
 1904:     "pat, case, na, exp",
 1905:     [
 1906:         ["abc", False, None, [True, True, False, None]],
 1907:         ["Abc", True, None, [False, False, False, None]],
 1908:         ["bc", True, None, [False, False, False, None]],
 1909:         ["ab", False, None, [True, True, False, None]],
 1910:         ["a[a-z]{2}", False, None, [True, True, False, None]],
 1911:         ["A[a-z]{1}", True, None, [False, False, False, None]],
 1912:         # GH Issue: #56652
 1913:         ["abc$", False, None, [True, False, False, None]],
 1914:         ["abc\\$", False, None, [False, True, False, None]],
 1915:         ["Abc$", True, None, [False, False, False, None]],
 1916:         ["Abc\\$", True, None, [False, False, False, None]],
 1917:     ],
 1918: )
 1919: def test_str_fullmatch(pat, case, na, exp):
 1920:     ser = pd.Series(["abc", "abc$", "$abc", None], dtype=ArrowDtype(pa.string()))
 1921:     result = ser.str.match(pat, case=case, na=na)
 1922:     expected = pd.Series(exp, dtype=ArrowDtype(pa.bool_()))
 1923:     tm.assert_series_equal(result, expected)
 1924: 
 1925: 
 1926: @pytest.mark.parametrize(
 1927:     "sub, start, end, exp, exp_typ",
 1928:     [["ab", 0, None, [0, None], pa.int32()], ["bc", 1, 3, [1, None], pa.int64()]],
 1929: )
 1930: def test_str_find(sub, start, end, exp, exp_typ):
 1931:     ser = pd.Series(["abc", None], dtype=ArrowDtype(pa.string()))
 1932:     result = ser.str.find(sub, start=start, end=end)
 1933:     expected = pd.Series(exp, dtype=ArrowDtype(exp_typ))
 1934:     tm.assert_series_equal(result, expected)
 1935: 
 1936: 
 1937: def test_str_find_negative_start():
 1938:     # GH 56411
 1939:     ser = pd.Series(["abc", None], dtype=ArrowDtype(pa.string()))
 1940:     result = ser.str.find(sub="b", start=-1000, end=3)
 1941:     expected = pd.Series([1, None], dtype=ArrowDtype(pa.int64()))
 1942:     tm.assert_series_equal(result, expected)
 1943: 
 1944: 
 1945: def test_str_find_notimplemented():
 1946:     ser = pd.Series(["abc", None], dtype=ArrowDtype(pa.string()))
 1947:     with pytest.raises(NotImplementedError, match="find not implemented"):
 1948:         ser.str.find("ab", start=1)
 1949: 
 1950: 
 1951: @pytest.mark.parametrize(
 1952:     "i, exp",
 1953:     [
 1954:         [1, ["b", "e", None]],
 1955:         [-1, ["c", "e", None]],
 1956:         [2, ["c", None, None]],
 1957:         [-3, ["a", None, None]],
 1958:         [4, [None, None, None]],
 1959:     ],
 1960: )
 1961: def test_str_get(i, exp):
 1962:     ser = pd.Series(["abc", "de", None], dtype=ArrowDtype(pa.string()))
 1963:     result = ser.str.get(i)
 1964:     expected = pd.Series(exp, dtype=ArrowDtype(pa.string()))
 1965:     tm.assert_series_equal(result, expected)
 1966: 
 1967: 
 1968: @pytest.mark.xfail(
 1969:     reason="TODO: StringMethods._validate should support Arrow list types",
 1970:     raises=AttributeError,
 1971: )
 1972: def test_str_join():
 1973:     ser = pd.Series(ArrowExtensionArray(pa.array([list("abc"), list("123"), None])))
 1974:     result = ser.str.join("=")
 1975:     expected = pd.Series(["a=b=c", "1=2=3", None], dtype=ArrowDtype(pa.string()))
 1976:     tm.assert_series_equal(result, expected)
 1977: 
 1978: 
 1979: def test_str_join_string_type():
 1980:     ser = pd.Series(ArrowExtensionArray(pa.array(["abc", "123", None])))
 1981:     result = ser.str.join("=")
 1982:     expected = pd.Series(["a=b=c", "1=2=3", None], dtype=ArrowDtype(pa.string()))
 1983:     tm.assert_series_equal(result, expected)
 1984: 
 1985: 
 1986: @pytest.mark.parametrize(
 1987:     "start, stop, step, exp",
 1988:     [
 1989:         [None, 2, None, ["ab", None]],
 1990:         [None, 2, 1, ["ab", None]],
 1991:         [1, 3, 1, ["bc", None]],
 1992:     ],
 1993: )
 1994: def test_str_slice(start, stop, step, exp):
 1995:     ser = pd.Series(["abcd", None], dtype=ArrowDtype(pa.string()))
 1996:     result = ser.str.slice(start, stop, step)
 1997:     expected = pd.Series(exp, dtype=ArrowDtype(pa.string()))
 1998:     tm.assert_series_equal(result, expected)
 1999: 
 2000: 
 2001: @pytest.mark.parametrize(
 2002:     "start, stop, repl, exp",
 2003:     [
 2004:         [1, 2, "x", ["axcd", None]],
 2005:         [None, 2, "x", ["xcd", None]],
 2006:         [None, 2, None, ["cd", None]],
 2007:     ],
 2008: )
 2009: def test_str_slice_replace(start, stop, repl, exp):
 2010:     ser = pd.Series(["abcd", None], dtype=ArrowDtype(pa.string()))
 2011:     result = ser.str.slice_replace(start, stop, repl)
 2012:     expected = pd.Series(exp, dtype=ArrowDtype(pa.string()))
 2013:     tm.assert_series_equal(result, expected)
 2014: 
 2015: 
 2016: @pytest.mark.parametrize(
 2017:     "value, method, exp",
 2018:     [
 2019:         ["a1c", "isalnum", True],
 2020:         ["!|,", "isalnum", False],
 2021:         ["aaa", "isalpha", True],
 2022:         ["!!!", "isalpha", False],
 2023:         ["Щ ", "isdecimal", True],  # noqa: RUF001
 2024:         ["~!", "isdecimal", False],
 2025:         ["2", "isdigit", True],
 2026:         ["~", "isdigit", False],
 2027:         ["aaa", "islower", True],
 2028:         ["aaA", "islower", False],
 2029:         ["123", "isnumeric", True],
 2030:         ["11I", "isnumeric", False],
 2031:         [" ", "isspace", True],
 2032:         ["", "isspace", False],
 2033:         ["The That", "istitle", True],
 2034:         ["the That", "istitle", False],
 2035:         ["AAA", "isupper", True],
 2036:         ["AAc", "isupper", False],
 2037:     ],
 2038: )
 2039: def test_str_is_functions(value, method, exp):
 2040:     ser = pd.Series([value, None], dtype=ArrowDtype(pa.string()))
 2041:     result = getattr(ser.str, method)()
 2042:     expected = pd.Series([exp, None], dtype=ArrowDtype(pa.bool_()))
 2043:     tm.assert_series_equal(result, expected)
 2044: 
 2045: 
 2046: @pytest.mark.parametrize(
 2047:     "method, exp",
 2048:     [
 2049:         ["capitalize", "Abc def"],
 2050:         ["title", "Abc Def"],
 2051:         ["swapcase", "AbC Def"],
 2052:         ["lower", "abc def"],
 2053:         ["upper", "ABC DEF"],
 2054:         ["casefold", "abc def"],
 2055:     ],
 2056: )
 2057: def test_str_transform_functions(method, exp):
 2058:     ser = pd.Series(["aBc dEF", None], dtype=ArrowDtype(pa.string()))
 2059:     result = getattr(ser.str, method)()
 2060:     expected = pd.Series([exp, None], dtype=ArrowDtype(pa.string()))
 2061:     tm.assert_series_equal(result, expected)
 2062: 
 2063: 
 2064: def test_str_len():
 2065:     ser = pd.Series(["abcd", None], dtype=ArrowDtype(pa.string()))
 2066:     result = ser.str.len()
 2067:     expected = pd.Series([4, None], dtype=ArrowDtype(pa.int32()))
 2068:     tm.assert_series_equal(result, expected)
 2069: 
 2070: 
 2071: @pytest.mark.parametrize(
 2072:     "method, to_strip, val",
 2073:     [
 2074:         ["strip", None, " abc "],
 2075:         ["strip", "x", "xabcx"],
 2076:         ["lstrip", None, " abc"],
 2077:         ["lstrip", "x", "xabc"],
 2078:         ["rstrip", None, "abc "],
 2079:         ["rstrip", "x", "abcx"],
 2080:     ],
 2081: )
 2082: def test_str_strip(method, to_strip, val):
 2083:     ser = pd.Series([val, None], dtype=ArrowDtype(pa.string()))
 2084:     result = getattr(ser.str, method)(to_strip=to_strip)
 2085:     expected = pd.Series(["abc", None], dtype=ArrowDtype(pa.string()))
 2086:     tm.assert_series_equal(result, expected)
 2087: 
 2088: 
 2089: @pytest.mark.parametrize("val", ["abc123", "abc"])
 2090: def test_str_removesuffix(val):
 2091:     ser = pd.Series([val, None], dtype=ArrowDtype(pa.string()))
 2092:     result = ser.str.removesuffix("123")
 2093:     expected = pd.Series(["abc", None], dtype=ArrowDtype(pa.string()))
 2094:     tm.assert_series_equal(result, expected)
 2095: 
 2096: 
 2097: @pytest.mark.parametrize("val", ["123abc", "abc"])
 2098: def test_str_removeprefix(val):
 2099:     ser = pd.Series([val, None], dtype=ArrowDtype(pa.string()))
 2100:     result = ser.str.removeprefix("123")
 2101:     expected = pd.Series(["abc", None], dtype=ArrowDtype(pa.string()))
 2102:     tm.assert_series_equal(result, expected)
 2103: 
 2104: 
 2105: @pytest.mark.parametrize("errors", ["ignore", "strict"])
 2106: @pytest.mark.parametrize(
 2107:     "encoding, exp",
 2108:     [
 2109:         ["utf8", b"abc"],
 2110:         ["utf32", b"\xff\xfe\x00\x00a\x00\x00\x00b\x00\x00\x00c\x00\x00\x00"],
 2111:     ],
 2112: )
 2113: def test_str_encode(errors, encoding, exp):
 2114:     ser = pd.Series(["abc", None], dtype=ArrowDtype(pa.string()))
 2115:     result = ser.str.encode(encoding, errors)
 2116:     expected = pd.Series([exp, None], dtype=ArrowDtype(pa.binary()))
 2117:     tm.assert_series_equal(result, expected)
 2118: 
 2119: 
 2120: @pytest.mark.parametrize("flags", [0, 2])
 2121: def test_str_findall(flags):
 2122:     ser = pd.Series(["abc", "efg", None], dtype=ArrowDtype(pa.string()))
 2123:     result = ser.str.findall("b", flags=flags)
 2124:     expected = pd.Series([["b"], [], None], dtype=ArrowDtype(pa.list_(pa.string())))
 2125:     tm.assert_series_equal(result, expected)
 2126: 
 2127: 
 2128: @pytest.mark.parametrize("method", ["index", "rindex"])
 2129: @pytest.mark.parametrize(
 2130:     "start, end",
 2131:     [
 2132:         [0, None],
 2133:         [1, 4],
 2134:     ],
 2135: )
 2136: def test_str_r_index(method, start, end):
 2137:     ser = pd.Series(["abcba", None], dtype=ArrowDtype(pa.string()))
 2138:     result = getattr(ser.str, method)("c", start, end)
 2139:     expected = pd.Series([2, None], dtype=ArrowDtype(pa.int64()))
 2140:     tm.assert_series_equal(result, expected)
 2141: 
 2142:     with pytest.raises(ValueError, match="substring not found"):
 2143:         getattr(ser.str, method)("foo", start, end)
 2144: 
 2145: 
 2146: @pytest.mark.parametrize("form", ["NFC", "NFKC"])
 2147: def test_str_normalize(form):
 2148:     ser = pd.Series(["abc", None], dtype=ArrowDtype(pa.string()))
 2149:     result = ser.str.normalize(form)
 2150:     expected = ser.copy()
 2151:     tm.assert_series_equal(result, expected)
 2152: 
 2153: 
 2154: @pytest.mark.parametrize(
 2155:     "start, end",
 2156:     [
 2157:         [0, None],
 2158:         [1, 4],
 2159:     ],
 2160: )
 2161: def test_str_rfind(start, end):
 2162:     ser = pd.Series(["abcba", "foo", None], dtype=ArrowDtype(pa.string()))
 2163:     result = ser.str.rfind("c", start, end)
 2164:     expected = pd.Series([2, -1, None], dtype=ArrowDtype(pa.int64()))
 2165:     tm.assert_series_equal(result, expected)
 2166: 
 2167: 
 2168: def test_str_translate():
 2169:     ser = pd.Series(["abcba", None], dtype=ArrowDtype(pa.string()))
 2170:     result = ser.str.translate({97: "b"})
 2171:     expected = pd.Series(["bbcbb", None], dtype=ArrowDtype(pa.string()))
 2172:     tm.assert_series_equal(result, expected)
 2173: 
 2174: 
 2175: def test_str_wrap():
 2176:     ser = pd.Series(["abcba", None], dtype=ArrowDtype(pa.string()))
 2177:     result = ser.str.wrap(3)
 2178:     expected = pd.Series(["abc\nba", None], dtype=ArrowDtype(pa.string()))
 2179:     tm.assert_series_equal(result, expected)
 2180: 
 2181: 
 2182: def test_get_dummies():
 2183:     ser = pd.Series(["a|b", None, "a|c"], dtype=ArrowDtype(pa.string()))
 2184:     result = ser.str.get_dummies()
 2185:     expected = pd.DataFrame(
 2186:         [[True, True, False], [False, False, False], [True, False, True]],
 2187:         dtype=ArrowDtype(pa.bool_()),
 2188:         columns=["a", "b", "c"],
 2189:     )
 2190:     tm.assert_frame_equal(result, expected)
 2191: 
 2192: 
 2193: def test_str_partition():
 2194:     ser = pd.Series(["abcba", None], dtype=ArrowDtype(pa.string()))
 2195:     result = ser.str.partition("b")
 2196:     expected = pd.DataFrame(
 2197:         [["a", "b", "cba"], [None, None, None]], dtype=ArrowDtype(pa.string())
 2198:     )
 2199:     tm.assert_frame_equal(result, expected)
 2200: 
 2201:     result = ser.str.partition("b", expand=False)
 2202:     expected = pd.Series(ArrowExtensionArray(pa.array([["a", "b", "cba"], None])))
 2203:     tm.assert_series_equal(result, expected)
 2204: 
 2205:     result = ser.str.rpartition("b")
 2206:     expected = pd.DataFrame(
 2207:         [["abc", "b", "a"], [None, None, None]], dtype=ArrowDtype(pa.string())
 2208:     )
 2209:     tm.assert_frame_equal(result, expected)
 2210: 
 2211:     result = ser.str.rpartition("b", expand=False)
 2212:     expected = pd.Series(ArrowExtensionArray(pa.array([["abc", "b", "a"], None])))
 2213:     tm.assert_series_equal(result, expected)
 2214: 
 2215: 
 2216: @pytest.mark.parametrize("method", ["rsplit", "split"])
 2217: def test_str_split_pat_none(method):
 2218:     # GH 56271
 2219:     ser = pd.Series(["a1 cbc\nb", None], dtype=ArrowDtype(pa.string()))
 2220:     result = getattr(ser.str, method)()
 2221:     expected = pd.Series(ArrowExtensionArray(pa.array([["a1", "cbc", "b"], None])))
 2222:     tm.assert_series_equal(result, expected)
 2223: 
 2224: 
 2225: def test_str_split():
 2226:     # GH 52401
 2227:     ser = pd.Series(["a1cbcb", "a2cbcb", None], dtype=ArrowDtype(pa.string()))
 2228:     result = ser.str.split("c")
 2229:     expected = pd.Series(
 2230:         ArrowExtensionArray(pa.array([["a1", "b", "b"], ["a2", "b", "b"], None]))
 2231:     )
 2232:     tm.assert_series_equal(result, expected)
 2233: 
 2234:     result = ser.str.split("c", n=1)
 2235:     expected = pd.Series(
 2236:         ArrowExtensionArray(pa.array([["a1", "bcb"], ["a2", "bcb"], None]))
 2237:     )
 2238:     tm.assert_series_equal(result, expected)
 2239: 
 2240:     result = ser.str.split("[1-2]", regex=True)
 2241:     expected = pd.Series(
 2242:         ArrowExtensionArray(pa.array([["a", "cbcb"], ["a", "cbcb"], None]))
 2243:     )
 2244:     tm.assert_series_equal(result, expected)
 2245: 
 2246:     result = ser.str.split("[1-2]", regex=True, expand=True)
 2247:     expected = pd.DataFrame(
 2248:         {
 2249:             0: ArrowExtensionArray(pa.array(["a", "a", None])),
 2250:             1: ArrowExtensionArray(pa.array(["cbcb", "cbcb", None])),
 2251:         }
 2252:     )
 2253:     tm.assert_frame_equal(result, expected)
 2254: 
 2255:     result = ser.str.split("1", expand=True)
 2256:     expected = pd.DataFrame(
 2257:         {
 2258:             0: ArrowExtensionArray(pa.array(["a", "a2cbcb", None])),
 2259:             1: ArrowExtensionArray(pa.array(["cbcb", None, None])),
 2260:         }
 2261:     )
 2262:     tm.assert_frame_equal(result, expected)
 2263: 
 2264: 
 2265: def test_str_rsplit():
 2266:     # GH 52401
 2267:     ser = pd.Series(["a1cbcb", "a2cbcb", None], dtype=ArrowDtype(pa.string()))
 2268:     result = ser.str.rsplit("c")
 2269:     expected = pd.Series(
 2270:         ArrowExtensionArray(pa.array([["a1", "b", "b"], ["a2", "b", "b"], None]))
 2271:     )
 2272:     tm.assert_series_equal(result, expected)
 2273: 
 2274:     result = ser.str.rsplit("c", n=1)
 2275:     expected = pd.Series(
 2276:         ArrowExtensionArray(pa.array([["a1cb", "b"], ["a2cb", "b"], None]))
 2277:     )
 2278:     tm.assert_series_equal(result, expected)
 2279: 
 2280:     result = ser.str.rsplit("c", n=1, expand=True)
 2281:     expected = pd.DataFrame(
 2282:         {
 2283:             0: ArrowExtensionArray(pa.array(["a1cb", "a2cb", None])),
 2284:             1: ArrowExtensionArray(pa.array(["b", "b", None])),
 2285:         }
 2286:     )
 2287:     tm.assert_frame_equal(result, expected)
 2288: 
 2289:     result = ser.str.rsplit("1", expand=True)
 2290:     expected = pd.DataFrame(
 2291:         {
 2292:             0: ArrowExtensionArray(pa.array(["a", "a2cbcb", None])),
 2293:             1: ArrowExtensionArray(pa.array(["cbcb", None, None])),
 2294:         }
 2295:     )
 2296:     tm.assert_frame_equal(result, expected)
 2297: 
 2298: 
 2299: def test_str_extract_non_symbolic():
 2300:     ser = pd.Series(["a1", "b2", "c3"], dtype=ArrowDtype(pa.string()))
 2301:     with pytest.raises(ValueError, match="pat=.* must contain a symbolic group name."):
 2302:         ser.str.extract(r"[ab](\d)")
 2303: 
 2304: 
 2305: @pytest.mark.parametrize("expand", [True, False])
 2306: def test_str_extract(expand):
 2307:     ser = pd.Series(["a1", "b2", "c3"], dtype=ArrowDtype(pa.string()))
 2308:     result = ser.str.extract(r"(?P<letter>[ab])(?P<digit>\d)", expand=expand)
 2309:     expected = pd.DataFrame(
 2310:         {
 2311:             "letter": ArrowExtensionArray(pa.array(["a", "b", None])),
 2312:             "digit": ArrowExtensionArray(pa.array(["1", "2", None])),
 2313:         }
 2314:     )
 2315:     tm.assert_frame_equal(result, expected)
 2316: 
 2317: 
 2318: def test_str_extract_expand():
 2319:     ser = pd.Series(["a1", "b2", "c3"], dtype=ArrowDtype(pa.string()))
 2320:     result = ser.str.extract(r"[ab](?P<digit>\d)", expand=True)
 2321:     expected = pd.DataFrame(
 2322:         {
 2323:             "digit": ArrowExtensionArray(pa.array(["1", "2", None])),
 2324:         }
 2325:     )
 2326:     tm.assert_frame_equal(result, expected)
 2327: 
 2328:     result = ser.str.extract(r"[ab](?P<digit>\d)", expand=False)
 2329:     expected = pd.Series(ArrowExtensionArray(pa.array(["1", "2", None])), name="digit")
 2330:     tm.assert_series_equal(result, expected)
 2331: 
 2332: 
 2333: @pytest.mark.parametrize("unit", ["ns", "us", "ms", "s"])
 2334: def test_duration_from_strings_with_nat(unit):
 2335:     # GH51175
 2336:     strings = ["1000", "NaT"]
 2337:     pa_type = pa.duration(unit)
 2338:     result = ArrowExtensionArray._from_sequence_of_strings(strings, dtype=pa_type)
 2339:     expected = ArrowExtensionArray(pa.array([1000, None], type=pa_type))
 2340:     tm.assert_extension_array_equal(result, expected)
 2341: 
 2342: 
 2343: def test_unsupported_dt(data):
 2344:     pa_dtype = data.dtype.pyarrow_dtype
 2345:     if not pa.types.is_temporal(pa_dtype):
 2346:         with pytest.raises(
 2347:             AttributeError, match="Can only use .dt accessor with datetimelike values"
 2348:         ):
 2349:             pd.Series(data).dt
 2350: 
 2351: 
 2352: @pytest.mark.parametrize(
 2353:     "prop, expected",
 2354:     [
 2355:         ["year", 2023],
 2356:         ["day", 2],
 2357:         ["day_of_week", 0],
 2358:         ["dayofweek", 0],
 2359:         ["weekday", 0],
 2360:         ["day_of_year", 2],
 2361:         ["dayofyear", 2],
 2362:         ["hour", 3],
 2363:         ["minute", 4],
 2364:         ["is_leap_year", False],
 2365:         ["microsecond", 5],
 2366:         ["month", 1],
 2367:         ["nanosecond", 6],
 2368:         ["quarter", 1],
 2369:         ["second", 7],
 2370:         ["date", date(2023, 1, 2)],
 2371:         ["time", time(3, 4, 7, 5)],
 2372:     ],
 2373: )
 2374: def test_dt_properties(prop, expected):
 2375:     ser = pd.Series(
 2376:         [
 2377:             pd.Timestamp(
 2378:                 year=2023,
 2379:                 month=1,
 2380:                 day=2,
 2381:                 hour=3,
 2382:                 minute=4,
 2383:                 second=7,
 2384:                 microsecond=5,
 2385:                 nanosecond=6,
 2386:             ),
 2387:             None,
 2388:         ],
 2389:         dtype=ArrowDtype(pa.timestamp("ns")),
 2390:     )
 2391:     result = getattr(ser.dt, prop)
 2392:     exp_type = None
 2393:     if isinstance(expected, date):
 2394:         exp_type = pa.date32()
 2395:     elif isinstance(expected, time):
 2396:         exp_type = pa.time64("ns")
 2397:     expected = pd.Series(ArrowExtensionArray(pa.array([expected, None], type=exp_type)))
 2398:     tm.assert_series_equal(result, expected)
 2399: 
 2400: 
 2401: def test_dt_is_month_start_end():
 2402:     ser = pd.Series(
 2403:         [
 2404:             datetime(year=2023, month=12, day=2, hour=3),
 2405:             datetime(year=2023, month=1, day=1, hour=3),
 2406:             datetime(year=2023, month=3, day=31, hour=3),
 2407:             None,
 2408:         ],
 2409:         dtype=ArrowDtype(pa.timestamp("us")),
 2410:     )
 2411:     result = ser.dt.is_month_start
 2412:     expected = pd.Series([False, True, False, None], dtype=ArrowDtype(pa.bool_()))
 2413:     tm.assert_series_equal(result, expected)
 2414: 
 2415:     result = ser.dt.is_month_end
 2416:     expected = pd.Series([False, False, True, None], dtype=ArrowDtype(pa.bool_()))
 2417:     tm.assert_series_equal(result, expected)
 2418: 
 2419: 
 2420: def test_dt_is_year_start_end():
 2421:     ser = pd.Series(
 2422:         [
 2423:             datetime(year=2023, month=12, day=31, hour=3),
 2424:             datetime(year=2023, month=1, day=1, hour=3),
 2425:             datetime(year=2023, month=3, day=31, hour=3),
 2426:             None,
 2427:         ],
 2428:         dtype=ArrowDtype(pa.timestamp("us")),
 2429:     )
 2430:     result = ser.dt.is_year_start
 2431:     expected = pd.Series([False, True, False, None], dtype=ArrowDtype(pa.bool_()))
 2432:     tm.assert_series_equal(result, expected)
 2433: 
 2434:     result = ser.dt.is_year_end
 2435:     expected = pd.Series([True, False, False, None], dtype=ArrowDtype(pa.bool_()))
 2436:     tm.assert_series_equal(result, expected)
 2437: 
 2438: 
 2439: def test_dt_is_quarter_start_end():
 2440:     ser = pd.Series(
 2441:         [
 2442:             datetime(year=2023, month=11, day=30, hour=3),
 2443:             datetime(year=2023, month=1, day=1, hour=3),
 2444:             datetime(year=2023, month=3, day=31, hour=3),
 2445:             None,
 2446:         ],
 2447:         dtype=ArrowDtype(pa.timestamp("us")),
 2448:     )
 2449:     result = ser.dt.is_quarter_start
 2450:     expected = pd.Series([False, True, False, None], dtype=ArrowDtype(pa.bool_()))
 2451:     tm.assert_series_equal(result, expected)
 2452: 
 2453:     result = ser.dt.is_quarter_end
 2454:     expected = pd.Series([False, False, True, None], dtype=ArrowDtype(pa.bool_()))
 2455:     tm.assert_series_equal(result, expected)
 2456: 
 2457: 
 2458: @pytest.mark.parametrize("method", ["days_in_month", "daysinmonth"])
 2459: def test_dt_days_in_month(method):
 2460:     ser = pd.Series(
 2461:         [
 2462:             datetime(year=2023, month=3, day=30, hour=3),
 2463:             datetime(year=2023, month=4, day=1, hour=3),
 2464:             datetime(year=2023, month=2, day=3, hour=3),
 2465:             None,
 2466:         ],
 2467:         dtype=ArrowDtype(pa.timestamp("us")),
 2468:     )
 2469:     result = getattr(ser.dt, method)
 2470:     expected = pd.Series([31, 30, 28, None], dtype=ArrowDtype(pa.int64()))
 2471:     tm.assert_series_equal(result, expected)
 2472: 
 2473: 
 2474: def test_dt_normalize():
 2475:     ser = pd.Series(
 2476:         [
 2477:             datetime(year=2023, month=3, day=30),
 2478:             datetime(year=2023, month=4, day=1, hour=3),
 2479:             datetime(year=2023, month=2, day=3, hour=23, minute=59, second=59),
 2480:             None,
 2481:         ],
 2482:         dtype=ArrowDtype(pa.timestamp("us")),
 2483:     )
 2484:     result = ser.dt.normalize()
 2485:     expected = pd.Series(
 2486:         [
 2487:             datetime(year=2023, month=3, day=30),
 2488:             datetime(year=2023, month=4, day=1),
 2489:             datetime(year=2023, month=2, day=3),
 2490:             None,
 2491:         ],
 2492:         dtype=ArrowDtype(pa.timestamp("us")),
 2493:     )
 2494:     tm.assert_series_equal(result, expected)
 2495: 
 2496: 
 2497: @pytest.mark.parametrize("unit", ["us", "ns"])
 2498: def test_dt_time_preserve_unit(unit):
 2499:     ser = pd.Series(
 2500:         [datetime(year=2023, month=1, day=2, hour=3), None],
 2501:         dtype=ArrowDtype(pa.timestamp(unit)),
 2502:     )
 2503:     assert ser.dt.unit == unit
 2504: 
 2505:     result = ser.dt.time
 2506:     expected = pd.Series(
 2507:         ArrowExtensionArray(pa.array([time(3, 0), None], type=pa.time64(unit)))
 2508:     )
 2509:     tm.assert_series_equal(result, expected)
 2510: 
 2511: 
 2512: @pytest.mark.parametrize("tz", [None, "UTC", "US/Pacific"])
 2513: def test_dt_tz(tz):
 2514:     ser = pd.Series(
 2515:         [datetime(year=2023, month=1, day=2, hour=3), None],
 2516:         dtype=ArrowDtype(pa.timestamp("ns", tz=tz)),
 2517:     )
 2518:     result = ser.dt.tz
 2519:     assert result == timezones.maybe_get_tz(tz)
 2520: 
 2521: 
 2522: def test_dt_isocalendar():
 2523:     ser = pd.Series(
 2524:         [datetime(year=2023, month=1, day=2, hour=3), None],
 2525:         dtype=ArrowDtype(pa.timestamp("ns")),
 2526:     )
 2527:     result = ser.dt.isocalendar()
 2528:     expected = pd.DataFrame(
 2529:         [[2023, 1, 1], [0, 0, 0]],
 2530:         columns=["year", "week", "day"],
 2531:         dtype="int64[pyarrow]",
 2532:     )
 2533:     tm.assert_frame_equal(result, expected)
 2534: 
 2535: 
 2536: @pytest.mark.parametrize(
 2537:     "method, exp", [["day_name", "Sunday"], ["month_name", "January"]]
 2538: )
 2539: def test_dt_day_month_name(method, exp, request):
 2540:     # GH 52388
 2541:     _require_timezone_database(request)
 2542: 
 2543:     ser = pd.Series([datetime(2023, 1, 1), None], dtype=ArrowDtype(pa.timestamp("ms")))
 2544:     result = getattr(ser.dt, method)()
 2545:     expected = pd.Series([exp, None], dtype=ArrowDtype(pa.string()))
 2546:     tm.assert_series_equal(result, expected)
 2547: 
 2548: 
 2549: def test_dt_strftime(request):
 2550:     _require_timezone_database(request)
 2551: 
 2552:     ser = pd.Series(
 2553:         [datetime(year=2023, month=1, day=2, hour=3), None],
 2554:         dtype=ArrowDtype(pa.timestamp("ns")),
 2555:     )
 2556:     result = ser.dt.strftime("%Y-%m-%dT%H:%M:%S")
 2557:     expected = pd.Series(
 2558:         ["2023-01-02T03:00:00.000000000", None], dtype=ArrowDtype(pa.string())
 2559:     )
 2560:     tm.assert_series_equal(result, expected)
 2561: 
 2562: 
 2563: @pytest.mark.parametrize("method", ["ceil", "floor", "round"])
 2564: def test_dt_roundlike_tz_options_not_supported(method):
 2565:     ser = pd.Series(
 2566:         [datetime(year=2023, month=1, day=2, hour=3), None],
 2567:         dtype=ArrowDtype(pa.timestamp("ns")),
 2568:     )
 2569:     with pytest.raises(NotImplementedError, match="ambiguous is not supported."):
 2570:         getattr(ser.dt, method)("1h", ambiguous="NaT")
 2571: 
 2572:     with pytest.raises(NotImplementedError, match="nonexistent is not supported."):
 2573:         getattr(ser.dt, method)("1h", nonexistent="NaT")
 2574: 
 2575: 
 2576: @pytest.mark.parametrize("method", ["ceil", "floor", "round"])
 2577: def test_dt_roundlike_unsupported_freq(method):
 2578:     ser = pd.Series(
 2579:         [datetime(year=2023, month=1, day=2, hour=3), None],
 2580:         dtype=ArrowDtype(pa.timestamp("ns")),
 2581:     )
 2582:     with pytest.raises(ValueError, match="freq='1B' is not supported"):
 2583:         getattr(ser.dt, method)("1B")
 2584: 
 2585:     with pytest.raises(ValueError, match="Must specify a valid frequency: None"):
 2586:         getattr(ser.dt, method)(None)
 2587: 
 2588: 
 2589: @pytest.mark.parametrize("freq", ["D", "h", "min", "s", "ms", "us", "ns"])
 2590: @pytest.mark.parametrize("method", ["ceil", "floor", "round"])
 2591: def test_dt_ceil_year_floor(freq, method):
 2592:     ser = pd.Series(
 2593:         [datetime(year=2023, month=1, day=1), None],
 2594:     )
 2595:     pa_dtype = ArrowDtype(pa.timestamp("ns"))
 2596:     expected = getattr(ser.dt, method)(f"1{freq}").astype(pa_dtype)
 2597:     result = getattr(ser.astype(pa_dtype).dt, method)(f"1{freq}")
 2598:     tm.assert_series_equal(result, expected)
 2599: 
 2600: 
 2601: def test_dt_to_pydatetime():
 2602:     # GH 51859
 2603:     data = [datetime(2022, 1, 1), datetime(2023, 1, 1)]
 2604:     ser = pd.Series(data, dtype=ArrowDtype(pa.timestamp("ns")))
 2605: 
 2606:     msg = "The behavior of ArrowTemporalProperties.to_pydatetime is deprecated"
 2607:     with tm.assert_produces_warning(FutureWarning, match=msg):
 2608:         result = ser.dt.to_pydatetime()
 2609:     expected = np.array(data, dtype=object)
 2610:     tm.assert_numpy_array_equal(result, expected)
 2611:     assert all(type(res) is datetime for res in result)
 2612: 
 2613:     msg = "The behavior of DatetimeProperties.to_pydatetime is deprecated"
 2614:     with tm.assert_produces_warning(FutureWarning, match=msg):
 2615:         expected = ser.astype("datetime64[ns]").dt.to_pydatetime()
 2616:     tm.assert_numpy_array_equal(result, expected)
 2617: 
 2618: 
 2619: @pytest.mark.parametrize("date_type", [32, 64])
 2620: def test_dt_to_pydatetime_date_error(date_type):
 2621:     # GH 52812
 2622:     ser = pd.Series(
 2623:         [date(2022, 12, 31)],
 2624:         dtype=ArrowDtype(getattr(pa, f"date{date_type}")()),
 2625:     )
 2626:     msg = "The behavior of ArrowTemporalProperties.to_pydatetime is deprecated"
 2627:     with tm.assert_produces_warning(FutureWarning, match=msg):
 2628:         with pytest.raises(ValueError, match="to_pydatetime cannot be called with"):
 2629:             ser.dt.to_pydatetime()
 2630: 
 2631: 
 2632: def test_dt_tz_localize_unsupported_tz_options():
 2633:     ser = pd.Series(
 2634:         [datetime(year=2023, month=1, day=2, hour=3), None],
 2635:         dtype=ArrowDtype(pa.timestamp("ns")),
 2636:     )
 2637:     with pytest.raises(NotImplementedError, match="ambiguous='NaT' is not supported"):
 2638:         ser.dt.tz_localize("UTC", ambiguous="NaT")
 2639: 
 2640:     with pytest.raises(NotImplementedError, match="nonexistent='NaT' is not supported"):
 2641:         ser.dt.tz_localize("UTC", nonexistent="NaT")
 2642: 
 2643: 
 2644: def test_dt_tz_localize_none():
 2645:     ser = pd.Series(
 2646:         [datetime(year=2023, month=1, day=2, hour=3), None],
 2647:         dtype=ArrowDtype(pa.timestamp("ns", tz="US/Pacific")),
 2648:     )
 2649:     result = ser.dt.tz_localize(None)
 2650:     expected = pd.Series(
 2651:         [datetime(year=2023, month=1, day=2, hour=3), None],
 2652:         dtype=ArrowDtype(pa.timestamp("ns")),
 2653:     )
 2654:     tm.assert_series_equal(result, expected)
 2655: 
 2656: 
 2657: @pytest.mark.parametrize("unit", ["us", "ns"])
 2658: def test_dt_tz_localize(unit, request):
 2659:     _require_timezone_database(request)
 2660: 
 2661:     ser = pd.Series(
 2662:         [datetime(year=2023, month=1, day=2, hour=3), None],
 2663:         dtype=ArrowDtype(pa.timestamp(unit)),
 2664:     )
 2665:     result = ser.dt.tz_localize("US/Pacific")
 2666:     exp_data = pa.array(
 2667:         [datetime(year=2023, month=1, day=2, hour=3), None], type=pa.timestamp(unit)
 2668:     )
 2669:     exp_data = pa.compute.assume_timezone(exp_data, "US/Pacific")
 2670:     expected = pd.Series(ArrowExtensionArray(exp_data))
 2671:     tm.assert_series_equal(result, expected)
 2672: 
 2673: 
 2674: @pytest.mark.parametrize(
 2675:     "nonexistent, exp_date",
 2676:     [
 2677:         ["shift_forward", datetime(year=2023, month=3, day=12, hour=3)],
 2678:         ["shift_backward", pd.Timestamp("2023-03-12 01:59:59.999999999")],
 2679:     ],
 2680: )
 2681: def test_dt_tz_localize_nonexistent(nonexistent, exp_date, request):
 2682:     _require_timezone_database(request)
 2683: 
 2684:     ser = pd.Series(
 2685:         [datetime(year=2023, month=3, day=12, hour=2, minute=30), None],
 2686:         dtype=ArrowDtype(pa.timestamp("ns")),
 2687:     )
 2688:     result = ser.dt.tz_localize("US/Pacific", nonexistent=nonexistent)
 2689:     exp_data = pa.array([exp_date, None], type=pa.timestamp("ns"))
 2690:     exp_data = pa.compute.assume_timezone(exp_data, "US/Pacific")
 2691:     expected = pd.Series(ArrowExtensionArray(exp_data))
 2692:     tm.assert_series_equal(result, expected)
 2693: 
 2694: 
 2695: def test_dt_tz_convert_not_tz_raises():
 2696:     ser = pd.Series(
 2697:         [datetime(year=2023, month=1, day=2, hour=3), None],
 2698:         dtype=ArrowDtype(pa.timestamp("ns")),
 2699:     )
 2700:     with pytest.raises(TypeError, match="Cannot convert tz-naive timestamps"):
 2701:         ser.dt.tz_convert("UTC")
 2702: 
 2703: 
 2704: def test_dt_tz_convert_none():
 2705:     ser = pd.Series(
 2706:         [datetime(year=2023, month=1, day=2, hour=3), None],
 2707:         dtype=ArrowDtype(pa.timestamp("ns", "US/Pacific")),
 2708:     )
 2709:     result = ser.dt.tz_convert(None)
 2710:     expected = pd.Series(
 2711:         [datetime(year=2023, month=1, day=2, hour=3), None],
 2712:         dtype=ArrowDtype(pa.timestamp("ns")),
 2713:     )
 2714:     tm.assert_series_equal(result, expected)
 2715: 
 2716: 
 2717: @pytest.mark.parametrize("unit", ["us", "ns"])
 2718: def test_dt_tz_convert(unit):
 2719:     ser = pd.Series(
 2720:         [datetime(year=2023, month=1, day=2, hour=3), None],
 2721:         dtype=ArrowDtype(pa.timestamp(unit, "US/Pacific")),
 2722:     )
 2723:     result = ser.dt.tz_convert("US/Eastern")
 2724:     expected = pd.Series(
 2725:         [datetime(year=2023, month=1, day=2, hour=3), None],
 2726:         dtype=ArrowDtype(pa.timestamp(unit, "US/Eastern")),
 2727:     )
 2728:     tm.assert_series_equal(result, expected)
 2729: 
 2730: 
 2731: @pytest.mark.parametrize("dtype", ["timestamp[ms][pyarrow]", "duration[ms][pyarrow]"])
 2732: def test_as_unit(dtype):
 2733:     # GH 52284
 2734:     ser = pd.Series([1000, None], dtype=dtype)
 2735:     result = ser.dt.as_unit("ns")
 2736:     expected = ser.astype(dtype.replace("ms", "ns"))
 2737:     tm.assert_series_equal(result, expected)
 2738: 
 2739: 
 2740: @pytest.mark.parametrize(
 2741:     "prop, expected",
 2742:     [
 2743:         ["days", 1],
 2744:         ["seconds", 2],
 2745:         ["microseconds", 3],
 2746:         ["nanoseconds", 4],
 2747:     ],
 2748: )
 2749: def test_dt_timedelta_properties(prop, expected):
 2750:     # GH 52284
 2751:     ser = pd.Series(
 2752:         [
 2753:             pd.Timedelta(
 2754:                 days=1,
 2755:                 seconds=2,
 2756:                 microseconds=3,
 2757:                 nanoseconds=4,
 2758:             ),
 2759:             None,
 2760:         ],
 2761:         dtype=ArrowDtype(pa.duration("ns")),
 2762:     )
 2763:     result = getattr(ser.dt, prop)
 2764:     expected = pd.Series(
 2765:         ArrowExtensionArray(pa.array([expected, None], type=pa.int32()))
 2766:     )
 2767:     tm.assert_series_equal(result, expected)
 2768: 
 2769: 
 2770: def test_dt_timedelta_total_seconds():
 2771:     # GH 52284
 2772:     ser = pd.Series(
 2773:         [
 2774:             pd.Timedelta(
 2775:                 days=1,
 2776:                 seconds=2,
 2777:                 microseconds=3,
 2778:                 nanoseconds=4,
 2779:             ),
 2780:             None,
 2781:         ],
 2782:         dtype=ArrowDtype(pa.duration("ns")),
 2783:     )
 2784:     result = ser.dt.total_seconds()
 2785:     expected = pd.Series(
 2786:         ArrowExtensionArray(pa.array([86402.000003, None], type=pa.float64()))
 2787:     )
 2788:     tm.assert_series_equal(result, expected)
 2789: 
 2790: 
 2791: def test_dt_to_pytimedelta():
 2792:     # GH 52284
 2793:     data = [timedelta(1, 2, 3), timedelta(1, 2, 4)]
 2794:     ser = pd.Series(data, dtype=ArrowDtype(pa.duration("ns")))
 2795: 
 2796:     result = ser.dt.to_pytimedelta()
 2797:     expected = np.array(data, dtype=object)
 2798:     tm.assert_numpy_array_equal(result, expected)
 2799:     assert all(type(res) is timedelta for res in result)
 2800: 
 2801:     expected = ser.astype("timedelta64[ns]").dt.to_pytimedelta()
 2802:     tm.assert_numpy_array_equal(result, expected)
 2803: 
 2804: 
 2805: def test_dt_components():
 2806:     # GH 52284
 2807:     ser = pd.Series(
 2808:         [
 2809:             pd.Timedelta(
 2810:                 days=1,
 2811:                 seconds=2,
 2812:                 microseconds=3,
 2813:                 nanoseconds=4,
 2814:             ),
 2815:             None,
 2816:         ],
 2817:         dtype=ArrowDtype(pa.duration("ns")),
 2818:     )
 2819:     result = ser.dt.components
 2820:     expected = pd.DataFrame(
 2821:         [[1, 0, 0, 2, 0, 3, 4], [None, None, None, None, None, None, None]],
 2822:         columns=[
 2823:             "days",
 2824:             "hours",
 2825:             "minutes",
 2826:             "seconds",
 2827:             "milliseconds",
 2828:             "microseconds",
 2829:             "nanoseconds",
 2830:         ],
 2831:         dtype="int32[pyarrow]",
 2832:     )
 2833:     tm.assert_frame_equal(result, expected)
 2834: 
 2835: 
 2836: @pytest.mark.parametrize("skipna", [True, False])
 2837: def test_boolean_reduce_series_all_null(all_boolean_reductions, skipna):
 2838:     # GH51624
 2839:     ser = pd.Series([None], dtype="float64[pyarrow]")
 2840:     result = getattr(ser, all_boolean_reductions)(skipna=skipna)
 2841:     if skipna:
 2842:         expected = all_boolean_reductions == "all"
 2843:     else:
 2844:         expected = pd.NA
 2845:     assert result is expected
 2846: 
 2847: 
 2848: def test_from_sequence_of_strings_boolean():
 2849:     true_strings = ["true", "TRUE", "True", "1", "1.0"]
 2850:     false_strings = ["false", "FALSE", "False", "0", "0.0"]
 2851:     nulls = [None]
 2852:     strings = true_strings + false_strings + nulls
 2853:     bools = (
 2854:         [True] * len(true_strings) + [False] * len(false_strings) + [None] * len(nulls)
 2855:     )
 2856: 
 2857:     result = ArrowExtensionArray._from_sequence_of_strings(strings, dtype=pa.bool_())
 2858:     expected = pd.array(bools, dtype="boolean[pyarrow]")
 2859:     tm.assert_extension_array_equal(result, expected)
 2860: 
 2861:     strings = ["True", "foo"]
 2862:     with pytest.raises(pa.ArrowInvalid, match="Failed to parse"):
 2863:         ArrowExtensionArray._from_sequence_of_strings(strings, dtype=pa.bool_())
 2864: 
 2865: 
 2866: def test_concat_empty_arrow_backed_series(dtype):
 2867:     # GH#51734
 2868:     ser = pd.Series([], dtype=dtype)
 2869:     expected = ser.copy()
 2870:     result = pd.concat([ser[np.array([], dtype=np.bool_)]])
 2871:     tm.assert_series_equal(result, expected)
 2872: 
 2873: 
 2874: @pytest.mark.parametrize("dtype", ["string", "string[pyarrow]"])
 2875: def test_series_from_string_array(dtype):
 2876:     arr = pa.array("the quick brown fox".split())
 2877:     ser = pd.Series(arr, dtype=dtype)
 2878:     expected = pd.Series(ArrowExtensionArray(arr), dtype=dtype)
 2879:     tm.assert_series_equal(ser, expected)
 2880: 
 2881: 
 2882: # _data was renamed to _pa_data
 2883: class OldArrowExtensionArray(ArrowExtensionArray):
 2884:     def __getstate__(self):
 2885:         state = super().__getstate__()
 2886:         state["_data"] = state.pop("_pa_array")
 2887:         return state
 2888: 
 2889: 
 2890: def test_pickle_old_arrowextensionarray():
 2891:     data = pa.array([1])
 2892:     expected = OldArrowExtensionArray(data)
 2893:     result = pickle.loads(pickle.dumps(expected))
 2894:     tm.assert_extension_array_equal(result, expected)
 2895:     assert result._pa_array == pa.chunked_array(data)
 2896:     assert not hasattr(result, "_data")
 2897: 
 2898: 
 2899: def test_setitem_boolean_replace_with_mask_segfault():
 2900:     # GH#52059
 2901:     N = 145_000
 2902:     arr = ArrowExtensionArray(pa.chunked_array([np.ones((N,), dtype=np.bool_)]))
 2903:     expected = arr.copy()
 2904:     arr[np.zeros((N,), dtype=np.bool_)] = False
 2905:     assert arr._pa_array == expected._pa_array
 2906: 
 2907: 
 2908: @pytest.mark.parametrize(
 2909:     "data, arrow_dtype",
 2910:     [
 2911:         ([b"a", b"b"], pa.large_binary()),
 2912:         (["a", "b"], pa.large_string()),
 2913:     ],
 2914: )
 2915: def test_conversion_large_dtypes_from_numpy_array(data, arrow_dtype):
 2916:     dtype = ArrowDtype(arrow_dtype)
 2917:     result = pd.array(np.array(data), dtype=dtype)
 2918:     expected = pd.array(data, dtype=dtype)
 2919:     tm.assert_extension_array_equal(result, expected)
 2920: 
 2921: 
 2922: def test_concat_null_array():
 2923:     df = pd.DataFrame({"a": [None, None]}, dtype=ArrowDtype(pa.null()))
 2924:     df2 = pd.DataFrame({"a": [0, 1]}, dtype="int64[pyarrow]")
 2925: 
 2926:     result = pd.concat([df, df2], ignore_index=True)
 2927:     expected = pd.DataFrame({"a": [None, None, 0, 1]}, dtype="int64[pyarrow]")
 2928:     tm.assert_frame_equal(result, expected)
 2929: 
 2930: 
 2931: @pytest.mark.parametrize("pa_type", tm.ALL_INT_PYARROW_DTYPES + tm.FLOAT_PYARROW_DTYPES)
 2932: def test_describe_numeric_data(pa_type):
 2933:     # GH 52470
 2934:     data = pd.Series([1, 2, 3], dtype=ArrowDtype(pa_type))
 2935:     result = data.describe()
 2936:     expected = pd.Series(
 2937:         [3, 2, 1, 1, 1.5, 2.0, 2.5, 3],
 2938:         dtype=ArrowDtype(pa.float64()),
 2939:         index=["count", "mean", "std", "min", "25%", "50%", "75%", "max"],
 2940:     )
 2941:     tm.assert_series_equal(result, expected)
 2942: 
 2943: 
 2944: @pytest.mark.parametrize("pa_type", tm.TIMEDELTA_PYARROW_DTYPES)
 2945: def test_describe_timedelta_data(pa_type):
 2946:     # GH53001
 2947:     data = pd.Series(range(1, 10), dtype=ArrowDtype(pa_type))
 2948:     result = data.describe()
 2949:     expected = pd.Series(
 2950:         [9] + pd.to_timedelta([5, 2, 1, 3, 5, 7, 9], unit=pa_type.unit).tolist(),
 2951:         dtype=object,
 2952:         index=["count", "mean", "std", "min", "25%", "50%", "75%", "max"],
 2953:     )
 2954:     tm.assert_series_equal(result, expected)
 2955: 
 2956: 
 2957: @pytest.mark.parametrize("pa_type", tm.DATETIME_PYARROW_DTYPES)
 2958: def test_describe_datetime_data(pa_type):
 2959:     # GH53001
 2960:     data = pd.Series(range(1, 10), dtype=ArrowDtype(pa_type))
 2961:     result = data.describe()
 2962:     expected = pd.Series(
 2963:         [9]
 2964:         + [
 2965:             pd.Timestamp(v, tz=pa_type.tz, unit=pa_type.unit)
 2966:             for v in [5, 1, 3, 5, 7, 9]
 2967:         ],
 2968:         dtype=object,
 2969:         index=["count", "mean", "min", "25%", "50%", "75%", "max"],
 2970:     )
 2971:     tm.assert_series_equal(result, expected)
 2972: 
 2973: 
 2974: @pytest.mark.parametrize(
 2975:     "pa_type", tm.DATETIME_PYARROW_DTYPES + tm.TIMEDELTA_PYARROW_DTYPES
 2976: )
 2977: def test_quantile_temporal(pa_type):
 2978:     # GH52678
 2979:     data = [1, 2, 3]
 2980:     ser = pd.Series(data, dtype=ArrowDtype(pa_type))
 2981:     result = ser.quantile(0.1)
 2982:     expected = ser[0]
 2983:     assert result == expected
 2984: 
 2985: 
 2986: def test_date32_repr():
 2987:     # GH48238
 2988:     arrow_dt = pa.array([date.fromisoformat("2020-01-01")], type=pa.date32())
 2989:     ser = pd.Series(arrow_dt, dtype=ArrowDtype(arrow_dt.type))
 2990:     assert repr(ser) == "0    2020-01-01\ndtype: date32[day][pyarrow]"
 2991: 
 2992: 
 2993: def test_duration_overflow_from_ndarray_containing_nat():
 2994:     # GH52843
 2995:     data_ts = pd.to_datetime([1, None])
 2996:     data_td = pd.to_timedelta([1, None])
 2997:     ser_ts = pd.Series(data_ts, dtype=ArrowDtype(pa.timestamp("ns")))
 2998:     ser_td = pd.Series(data_td, dtype=ArrowDtype(pa.duration("ns")))
 2999:     result = ser_ts + ser_td
 3000:     expected = pd.Series([2, None], dtype=ArrowDtype(pa.timestamp("ns")))
 3001:     tm.assert_series_equal(result, expected)
 3002: 
 3003: 
 3004: def test_infer_dtype_pyarrow_dtype(data, request):
 3005:     res = lib.infer_dtype(data)
 3006:     assert res != "unknown-array"
 3007: 
 3008:     if data._hasna and res in ["floating", "datetime64", "timedelta64"]:
 3009:         mark = pytest.mark.xfail(
 3010:             reason="in infer_dtype pd.NA is not ignored in these cases "
 3011:             "even with skipna=True in the list(data) check below"
 3012:         )
 3013:         request.applymarker(mark)
 3014: 
 3015:     assert res == lib.infer_dtype(list(data), skipna=True)
 3016: 
 3017: 
 3018: @pytest.mark.parametrize(
 3019:     "pa_type", tm.DATETIME_PYARROW_DTYPES + tm.TIMEDELTA_PYARROW_DTYPES
 3020: )
 3021: def test_from_sequence_temporal(pa_type):
 3022:     # GH 53171
 3023:     val = 3
 3024:     unit = pa_type.unit
 3025:     if pa.types.is_duration(pa_type):
 3026:         seq = [pd.Timedelta(val, unit=unit).as_unit(unit)]
 3027:     else:
 3028:         seq = [pd.Timestamp(val, unit=unit, tz=pa_type.tz).as_unit(unit)]
 3029: 
 3030:     result = ArrowExtensionArray._from_sequence(seq, dtype=pa_type)
 3031:     expected = ArrowExtensionArray(pa.array([val], type=pa_type))
 3032:     tm.assert_extension_array_equal(result, expected)
 3033: 
 3034: 
 3035: @pytest.mark.parametrize(
 3036:     "pa_type", tm.DATETIME_PYARROW_DTYPES + tm.TIMEDELTA_PYARROW_DTYPES
 3037: )
 3038: def test_setitem_temporal(pa_type):
 3039:     # GH 53171
 3040:     unit = pa_type.unit
 3041:     if pa.types.is_duration(pa_type):
 3042:         val = pd.Timedelta(1, unit=unit).as_unit(unit)
 3043:     else:
 3044:         val = pd.Timestamp(1, unit=unit, tz=pa_type.tz).as_unit(unit)
 3045: 
 3046:     arr = ArrowExtensionArray(pa.array([1, 2, 3], type=pa_type))
 3047: 
 3048:     result = arr.copy()
 3049:     result[:] = val
 3050:     expected = ArrowExtensionArray(pa.array([1, 1, 1], type=pa_type))
 3051:     tm.assert_extension_array_equal(result, expected)
 3052: 
 3053: 
 3054: @pytest.mark.parametrize(
 3055:     "pa_type", tm.DATETIME_PYARROW_DTYPES + tm.TIMEDELTA_PYARROW_DTYPES
 3056: )
 3057: def test_arithmetic_temporal(pa_type, request):
 3058:     # GH 53171
 3059:     arr = ArrowExtensionArray(pa.array([1, 2, 3], type=pa_type))
 3060:     unit = pa_type.unit
 3061:     result = arr - pd.Timedelta(1, unit=unit).as_unit(unit)
 3062:     expected = ArrowExtensionArray(pa.array([0, 1, 2], type=pa_type))
 3063:     tm.assert_extension_array_equal(result, expected)
 3064: 
 3065: 
 3066: @pytest.mark.parametrize(
 3067:     "pa_type", tm.DATETIME_PYARROW_DTYPES + tm.TIMEDELTA_PYARROW_DTYPES
 3068: )
 3069: def test_comparison_temporal(pa_type):
 3070:     # GH 53171
 3071:     unit = pa_type.unit
 3072:     if pa.types.is_duration(pa_type):
 3073:         val = pd.Timedelta(1, unit=unit).as_unit(unit)
 3074:     else:
 3075:         val = pd.Timestamp(1, unit=unit, tz=pa_type.tz).as_unit(unit)
 3076: 
 3077:     arr = ArrowExtensionArray(pa.array([1, 2, 3], type=pa_type))
 3078: 
 3079:     result = arr > val
 3080:     expected = ArrowExtensionArray(pa.array([False, True, True], type=pa.bool_()))
 3081:     tm.assert_extension_array_equal(result, expected)
 3082: 
 3083: 
 3084: @pytest.mark.parametrize(
 3085:     "pa_type", tm.DATETIME_PYARROW_DTYPES + tm.TIMEDELTA_PYARROW_DTYPES
 3086: )
 3087: def test_getitem_temporal(pa_type):
 3088:     # GH 53326
 3089:     arr = ArrowExtensionArray(pa.array([1, 2, 3], type=pa_type))
 3090:     result = arr[1]
 3091:     if pa.types.is_duration(pa_type):
 3092:         expected = pd.Timedelta(2, unit=pa_type.unit).as_unit(pa_type.unit)
 3093:         assert isinstance(result, pd.Timedelta)
 3094:     else:
 3095:         expected = pd.Timestamp(2, unit=pa_type.unit, tz=pa_type.tz).as_unit(
 3096:             pa_type.unit
 3097:         )
 3098:         assert isinstance(result, pd.Timestamp)
 3099:     assert result.unit == expected.unit
 3100:     assert result == expected
 3101: 
 3102: 
 3103: @pytest.mark.parametrize(
 3104:     "pa_type", tm.DATETIME_PYARROW_DTYPES + tm.TIMEDELTA_PYARROW_DTYPES
 3105: )
 3106: def test_iter_temporal(pa_type):
 3107:     # GH 53326
 3108:     arr = ArrowExtensionArray(pa.array([1, None], type=pa_type))
 3109:     result = list(arr)
 3110:     if pa.types.is_duration(pa_type):
 3111:         expected = [
 3112:             pd.Timedelta(1, unit=pa_type.unit).as_unit(pa_type.unit),
 3113:             pd.NA,
 3114:         ]
 3115:         assert isinstance(result[0], pd.Timedelta)
 3116:     else:
 3117:         expected = [
 3118:             pd.Timestamp(1, unit=pa_type.unit, tz=pa_type.tz).as_unit(pa_type.unit),
 3119:             pd.NA,
 3120:         ]
 3121:         assert isinstance(result[0], pd.Timestamp)
 3122:     assert result[0].unit == expected[0].unit
 3123:     assert result == expected
 3124: 
 3125: 
 3126: def test_groupby_series_size_returns_pa_int(data):
 3127:     # GH 54132
 3128:     ser = pd.Series(data[:3], index=["a", "a", "b"])
 3129:     result = ser.groupby(level=0).size()
 3130:     expected = pd.Series([2, 1], dtype="int64[pyarrow]", index=["a", "b"])
 3131:     tm.assert_series_equal(result, expected)
 3132: 
 3133: 
 3134: @pytest.mark.parametrize(
 3135:     "pa_type", tm.DATETIME_PYARROW_DTYPES + tm.TIMEDELTA_PYARROW_DTYPES, ids=repr
 3136: )
 3137: @pytest.mark.parametrize("dtype", [None, object])
 3138: def test_to_numpy_temporal(pa_type, dtype):
 3139:     # GH 53326
 3140:     # GH 55997: Return datetime64/timedelta64 types with NaT if possible
 3141:     arr = ArrowExtensionArray(pa.array([1, None], type=pa_type))
 3142:     result = arr.to_numpy(dtype=dtype)
 3143:     if pa.types.is_duration(pa_type):
 3144:         value = pd.Timedelta(1, unit=pa_type.unit).as_unit(pa_type.unit)
 3145:     else:
 3146:         value = pd.Timestamp(1, unit=pa_type.unit, tz=pa_type.tz).as_unit(pa_type.unit)
 3147: 
 3148:     if dtype == object or (pa.types.is_timestamp(pa_type) and pa_type.tz is not None):
 3149:         if dtype == object:
 3150:             na = pd.NA
 3151:         else:
 3152:             na = pd.NaT
 3153:         expected = np.array([value, na], dtype=object)
 3154:         assert result[0].unit == value.unit
 3155:     else:
 3156:         na = pa_type.to_pandas_dtype().type("nat", pa_type.unit)
 3157:         value = value.to_numpy()
 3158:         expected = np.array([value, na])
 3159:         assert np.datetime_data(result[0])[0] == pa_type.unit
 3160:     tm.assert_numpy_array_equal(result, expected)
 3161: 
 3162: 
 3163: def test_groupby_count_return_arrow_dtype(data_missing):
 3164:     df = pd.DataFrame({"A": [1, 1], "B": data_missing, "C": data_missing})
 3165:     result = df.groupby("A").count()
 3166:     expected = pd.DataFrame(
 3167:         [[1, 1]],
 3168:         index=pd.Index([1], name="A"),
 3169:         columns=["B", "C"],
 3170:         dtype="int64[pyarrow]",
 3171:     )
 3172:     tm.assert_frame_equal(result, expected)
 3173: 
 3174: 
 3175: def test_fixed_size_list():
 3176:     # GH#55000
 3177:     ser = pd.Series(
 3178:         [[1, 2], [3, 4]], dtype=ArrowDtype(pa.list_(pa.int64(), list_size=2))
 3179:     )
 3180:     result = ser.dtype.type
 3181:     assert result == list
 3182: 
 3183: 
 3184: def test_arrowextensiondtype_dataframe_repr():
 3185:     # GH 54062
 3186:     df = pd.DataFrame(
 3187:         pd.period_range("2012", periods=3),
 3188:         columns=["col"],
 3189:         dtype=ArrowDtype(ArrowPeriodType("D")),
 3190:     )
 3191:     result = repr(df)
 3192:     # TODO: repr value may not be expected; address how
 3193:     # pyarrow.ExtensionType values are displayed
 3194:     expected = "     col\n0  15340\n1  15341\n2  15342"
 3195:     assert result == expected
 3196: 
 3197: 
 3198: def test_pow_missing_operand():
 3199:     # GH 55512
 3200:     k = pd.Series([2, None], dtype="int64[pyarrow]")
 3201:     result = k.pow(None, fill_value=3)
 3202:     expected = pd.Series([8, None], dtype="int64[pyarrow]")
 3203:     tm.assert_series_equal(result, expected)
 3204: 
 3205: 
 3206: @pytest.mark.parametrize("pa_type", tm.TIMEDELTA_PYARROW_DTYPES)
 3207: def test_duration_fillna_numpy(pa_type):
 3208:     # GH 54707
 3209:     ser1 = pd.Series([None, 2], dtype=ArrowDtype(pa_type))
 3210:     ser2 = pd.Series(np.array([1, 3], dtype=f"m8[{pa_type.unit}]"))
 3211:     result = ser1.fillna(ser2)
 3212:     expected = pd.Series([1, 2], dtype=ArrowDtype(pa_type))
 3213:     tm.assert_series_equal(result, expected)
 3214: 
 3215: 
 3216: def test_comparison_not_propagating_arrow_error():
 3217:     # GH#54944
 3218:     a = pd.Series([1 << 63], dtype="uint64[pyarrow]")
 3219:     b = pd.Series([None], dtype="int64[pyarrow]")
 3220:     with pytest.raises(pa.lib.ArrowInvalid, match="Integer value"):
 3221:         a < b
 3222: 
 3223: 
 3224: def test_factorize_chunked_dictionary():
 3225:     # GH 54844
 3226:     pa_array = pa.chunked_array(
 3227:         [pa.array(["a"]).dictionary_encode(), pa.array(["b"]).dictionary_encode()]
 3228:     )
 3229:     ser = pd.Series(ArrowExtensionArray(pa_array))
 3230:     res_indices, res_uniques = ser.factorize()
 3231:     exp_indicies = np.array([0, 1], dtype=np.intp)
 3232:     exp_uniques = pd.Index(ArrowExtensionArray(pa_array.combine_chunks()))
 3233:     tm.assert_numpy_array_equal(res_indices, exp_indicies)
 3234:     tm.assert_index_equal(res_uniques, exp_uniques)
 3235: 
 3236: 
 3237: def test_dictionary_astype_categorical():
 3238:     # GH#56672
 3239:     arrs = [
 3240:         pa.array(np.array(["a", "x", "c", "a"])).dictionary_encode(),
 3241:         pa.array(np.array(["a", "d", "c"])).dictionary_encode(),
 3242:     ]
 3243:     ser = pd.Series(ArrowExtensionArray(pa.chunked_array(arrs)))
 3244:     result = ser.astype("category")
 3245:     categories = pd.Index(["a", "x", "c", "d"], dtype=ArrowDtype(pa.string()))
 3246:     expected = pd.Series(
 3247:         ["a", "x", "c", "a", "a", "d", "c"],
 3248:         dtype=pd.CategoricalDtype(categories=categories),
 3249:     )
 3250:     tm.assert_series_equal(result, expected)
 3251: 
 3252: 
 3253: def test_arrow_floordiv():
 3254:     # GH 55561
 3255:     a = pd.Series([-7], dtype="int64[pyarrow]")
 3256:     b = pd.Series([4], dtype="int64[pyarrow]")
 3257:     expected = pd.Series([-2], dtype="int64[pyarrow]")
 3258:     result = a // b
 3259:     tm.assert_series_equal(result, expected)
 3260: 
 3261: 
 3262: def test_arrow_floordiv_large_values():
 3263:     # GH 56645
 3264:     a = pd.Series([1425801600000000000], dtype="int64[pyarrow]")
 3265:     expected = pd.Series([1425801600000], dtype="int64[pyarrow]")
 3266:     result = a // 1_000_000
 3267:     tm.assert_series_equal(result, expected)
 3268: 
 3269: 
 3270: @pytest.mark.parametrize("dtype", ["int64[pyarrow]", "uint64[pyarrow]"])
 3271: def test_arrow_floordiv_large_integral_result(dtype):
 3272:     # GH 56676
 3273:     a = pd.Series([18014398509481983], dtype=dtype)
 3274:     result = a // 1
 3275:     tm.assert_series_equal(result, a)
 3276: 
 3277: 
 3278: @pytest.mark.parametrize("pa_type", tm.SIGNED_INT_PYARROW_DTYPES)
 3279: def test_arrow_floordiv_larger_divisor(pa_type):
 3280:     # GH 56676
 3281:     dtype = ArrowDtype(pa_type)
 3282:     a = pd.Series([-23], dtype=dtype)
 3283:     result = a // 24
 3284:     expected = pd.Series([-1], dtype=dtype)
 3285:     tm.assert_series_equal(result, expected)
 3286: 
 3287: 
 3288: @pytest.mark.parametrize("pa_type", tm.SIGNED_INT_PYARROW_DTYPES)
 3289: def test_arrow_floordiv_integral_invalid(pa_type):
 3290:     # GH 56676
 3291:     min_value = np.iinfo(pa_type.to_pandas_dtype()).min
 3292:     a = pd.Series([min_value], dtype=ArrowDtype(pa_type))
 3293:     with pytest.raises(pa.lib.ArrowInvalid, match="overflow|not in range"):
 3294:         a // -1
 3295:     with pytest.raises(pa.lib.ArrowInvalid, match="divide by zero"):
 3296:         a // 0
 3297: 
 3298: 
 3299: @pytest.mark.parametrize("dtype", tm.FLOAT_PYARROW_DTYPES_STR_REPR)
 3300: def test_arrow_floordiv_floating_0_divisor(dtype):
 3301:     # GH 56676
 3302:     a = pd.Series([2], dtype=dtype)
 3303:     result = a // 0
 3304:     expected = pd.Series([float("inf")], dtype=dtype)
 3305:     tm.assert_series_equal(result, expected)
 3306: 
 3307: 
 3308: @pytest.mark.parametrize("dtype", ["float64", "datetime64[ns]", "timedelta64[ns]"])
 3309: def test_astype_int_with_null_to_numpy_dtype(dtype):
 3310:     # GH 57093
 3311:     ser = pd.Series([1, None], dtype="int64[pyarrow]")
 3312:     result = ser.astype(dtype)
 3313:     expected = pd.Series([1, None], dtype=dtype)
 3314:     tm.assert_series_equal(result, expected)
 3315: 
 3316: 
 3317: @pytest.mark.parametrize("pa_type", tm.ALL_INT_PYARROW_DTYPES)
 3318: def test_arrow_integral_floordiv_large_values(pa_type):
 3319:     # GH 56676
 3320:     max_value = np.iinfo(pa_type.to_pandas_dtype()).max
 3321:     dtype = ArrowDtype(pa_type)
 3322:     a = pd.Series([max_value], dtype=dtype)
 3323:     b = pd.Series([1], dtype=dtype)
 3324:     result = a // b
 3325:     tm.assert_series_equal(result, a)
 3326: 
 3327: 
 3328: @pytest.mark.parametrize("dtype", ["int64[pyarrow]", "uint64[pyarrow]"])
 3329: def test_arrow_true_division_large_divisor(dtype):
 3330:     # GH 56706
 3331:     a = pd.Series([0], dtype=dtype)
 3332:     b = pd.Series([18014398509481983], dtype=dtype)
 3333:     expected = pd.Series([0], dtype="float64[pyarrow]")
 3334:     result = a / b
 3335:     tm.assert_series_equal(result, expected)
 3336: 
 3337: 
 3338: @pytest.mark.parametrize("dtype", ["int64[pyarrow]", "uint64[pyarrow]"])
 3339: def test_arrow_floor_division_large_divisor(dtype):
 3340:     # GH 56706
 3341:     a = pd.Series([0], dtype=dtype)
 3342:     b = pd.Series([18014398509481983], dtype=dtype)
 3343:     expected = pd.Series([0], dtype=dtype)
 3344:     result = a // b
 3345:     tm.assert_series_equal(result, expected)
 3346: 
 3347: 
 3348: def test_string_to_datetime_parsing_cast():
 3349:     # GH 56266
 3350:     string_dates = ["2020-01-01 04:30:00", "2020-01-02 00:00:00", "2020-01-03 00:00:00"]
 3351:     result = pd.Series(string_dates, dtype="timestamp[ns][pyarrow]")
 3352:     expected = pd.Series(
 3353:         ArrowExtensionArray(pa.array(pd.to_datetime(string_dates), from_pandas=True))
 3354:     )
 3355:     tm.assert_series_equal(result, expected)
 3356: 
 3357: 
 3358: def test_string_to_time_parsing_cast():
 3359:     # GH 56463
 3360:     string_times = ["11:41:43.076160"]
 3361:     result = pd.Series(string_times, dtype="time64[us][pyarrow]")
 3362:     expected = pd.Series(
 3363:         ArrowExtensionArray(pa.array([time(11, 41, 43, 76160)], from_pandas=True))
 3364:     )
 3365:     tm.assert_series_equal(result, expected)
 3366: 
 3367: 
 3368: def test_to_numpy_float():
 3369:     # GH#56267
 3370:     ser = pd.Series([32, 40, None], dtype="float[pyarrow]")
 3371:     result = ser.astype("float64")
 3372:     expected = pd.Series([32, 40, np.nan], dtype="float64")
 3373:     tm.assert_series_equal(result, expected)
 3374: 
 3375: 
 3376: def test_to_numpy_timestamp_to_int():
 3377:     # GH 55997
 3378:     ser = pd.Series(["2020-01-01 04:30:00"], dtype="timestamp[ns][pyarrow]")
 3379:     result = ser.to_numpy(dtype=np.int64)
 3380:     expected = np.array([1577853000000000000])
 3381:     tm.assert_numpy_array_equal(result, expected)
 3382: 
 3383: 
 3384: def test_map_numeric_na_action():
 3385:     ser = pd.Series([32, 40, None], dtype="int64[pyarrow]")
 3386:     result = ser.map(lambda x: 42, na_action="ignore")
 3387:     expected = pd.Series([42.0, 42.0, np.nan], dtype="float64")
 3388:     tm.assert_series_equal(result, expected)
