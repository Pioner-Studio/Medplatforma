    1: from __future__ import annotations
    2: 
    3: import errno
    4: import math
    5: import os.path
    6: import re
    7: import shlex
    8: import stat
    9: import string
   10: import sys
   11: from typing import IO
   12: 
   13: from identify import extensions
   14: from identify import interpreters
   15: from identify.vendor import licenses
   16: 
   17: 
   18: printable = frozenset(string.printable)
   19: 
   20: DIRECTORY = 'directory'
   21: SYMLINK = 'symlink'
   22: SOCKET = 'socket'
   23: FILE = 'file'
   24: EXECUTABLE = 'executable'
   25: NON_EXECUTABLE = 'non-executable'
   26: TEXT = 'text'
   27: BINARY = 'binary'
   28: 
   29: TYPE_TAGS = frozenset((DIRECTORY, FILE, SYMLINK, SOCKET))
   30: MODE_TAGS = frozenset((EXECUTABLE, NON_EXECUTABLE))
   31: ENCODING_TAGS = frozenset((BINARY, TEXT))
   32: _ALL_TAGS = {*TYPE_TAGS, *MODE_TAGS, *ENCODING_TAGS}
   33: _ALL_TAGS.update(*extensions.EXTENSIONS.values())
   34: _ALL_TAGS.update(*extensions.EXTENSIONS_NEED_BINARY_CHECK.values())
   35: _ALL_TAGS.update(*extensions.NAMES.values())
   36: _ALL_TAGS.update(*interpreters.INTERPRETERS.values())
   37: ALL_TAGS = frozenset(_ALL_TAGS)
   38: 
   39: 
   40: def tags_from_path(path: str) -> set[str]:
   41:     try:
   42:         sr = os.lstat(path)
   43:     except (OSError, ValueError):  # same error-handling as `os.lexists()`
   44:         raise ValueError(f'{path} does not exist.')
   45: 
   46:     mode = sr.st_mode
   47:     if stat.S_ISDIR(mode):
   48:         return {DIRECTORY}
   49:     if stat.S_ISLNK(mode):
   50:         return {SYMLINK}
   51:     if stat.S_ISSOCK(mode):
   52:         return {SOCKET}
   53: 
   54:     tags = {FILE}
   55: 
   56:     executable = os.access(path, os.X_OK)
   57:     if executable:
   58:         tags.add(EXECUTABLE)
   59:     else:
   60:         tags.add(NON_EXECUTABLE)
   61: 
   62:     # As an optimization, if we're able to read tags from the filename, then we
   63:     # don't peek at the file contents.
   64:     t = tags_from_filename(os.path.basename(path))
   65:     if len(t) > 0:
   66:         tags.update(t)
   67:     else:
   68:         if executable:
   69:             shebang = parse_shebang_from_file(path)
   70:             if len(shebang) > 0:
   71:                 tags.update(tags_from_interpreter(shebang[0]))
   72: 
   73:     # some extensions can be both binary and text
   74:     # see EXTENSIONS_NEED_BINARY_CHECK
   75:     if not ENCODING_TAGS & tags:
   76:         if file_is_text(path):
   77:             tags.add(TEXT)
   78:         else:
   79:             tags.add(BINARY)
   80: 
   81:     assert ENCODING_TAGS & tags, tags
   82:     assert MODE_TAGS & tags, tags
   83:     return tags
   84: 
   85: 
   86: def tags_from_filename(path: str) -> set[str]:
   87:     _, filename = os.path.split(path)
   88:     _, ext = os.path.splitext(filename)
   89: 
   90:     ret = set()
   91: 
   92:     # Allow e.g. "Dockerfile.xenial" to match "Dockerfile"
   93:     for part in [filename] + filename.split('.'):
   94:         if part in extensions.NAMES:
   95:             ret.update(extensions.NAMES[part])
   96:             break
   97: 
   98:     if len(ext) > 0:
   99:         ext = ext[1:].lower()
  100:         if ext in extensions.EXTENSIONS:
  101:             ret.update(extensions.EXTENSIONS[ext])
  102:         elif ext in extensions.EXTENSIONS_NEED_BINARY_CHECK:
  103:             ret.update(extensions.EXTENSIONS_NEED_BINARY_CHECK[ext])
  104: 
  105:     return ret
  106: 
  107: 
  108: def tags_from_interpreter(interpreter: str) -> set[str]:
  109:     _, _, interpreter = interpreter.rpartition('/')
  110: 
  111:     # Try "python3.5.2" => "python3.5" => "python3" until one matches.
  112:     while interpreter:
  113:         if interpreter in interpreters.INTERPRETERS:
  114:             return interpreters.INTERPRETERS[interpreter]
  115:         else:
  116:             interpreter, _, _ = interpreter.rpartition('.')
  117: 
  118:     return set()
  119: 
  120: 
  121: def is_text(bytesio: IO[bytes]) -> bool:
  122:     """Return whether the first KB of contents seems to be binary.
  123: 
  124:     This is roughly based on libmagic's binary/text detection:
  125:     https://github.com/file/file/blob/df74b09b9027676088c797528edcaae5a9ce9ad0/src/encoding.c#L203-L228
  126:     """
  127:     text_chars = (
  128:         bytearray([7, 8, 9, 10, 11, 12, 13, 27]) +
  129:         bytearray(range(0x20, 0x7F)) +
  130:         bytearray(range(0x80, 0X100))
  131:     )
  132:     return not bool(bytesio.read(1024).translate(None, text_chars))
  133: 
  134: 
  135: def file_is_text(path: str) -> bool:
  136:     if not os.path.lexists(path):
  137:         raise ValueError(f'{path} does not exist.')
  138:     with open(path, 'rb') as f:
  139:         return is_text(f)
  140: 
  141: 
  142: def _shebang_split(line: str) -> list[str]:
  143:     try:
  144:         # shebangs aren't supposed to be quoted, though some tools such as
  145:         # setuptools will write them with quotes so we'll best-guess parse
  146:         # with shlex first
  147:         return shlex.split(line)
  148:     except ValueError:
  149:         # failing that, we'll do a more "traditional" shebang parsing which
  150:         # just involves splitting by whitespace
  151:         return line.split()
  152: 
  153: 
  154: def _parse_nix_shebang(
  155:         bytesio: IO[bytes],
  156:         cmd: tuple[str, ...],
  157: ) -> tuple[str, ...]:
  158:     while bytesio.read(2) == b'#!':
  159:         next_line_b = bytesio.readline()
  160:         try:
  161:             next_line = next_line_b.decode('UTF-8')
  162:         except UnicodeDecodeError:
  163:             return cmd
  164: 
  165:         for c in next_line:
  166:             if c not in printable:
  167:                 return cmd
  168: 
  169:         line_tokens = tuple(_shebang_split(next_line.strip()))
  170:         for i, token in enumerate(line_tokens[:-1]):
  171:             if token != '-i':
  172:                 continue
  173:             # the argument to -i flag
  174:             cmd = (line_tokens[i + 1],)
  175:     return cmd
  176: 
  177: 
  178: def parse_shebang(bytesio: IO[bytes]) -> tuple[str, ...]:
  179:     """Parse the shebang from a file opened for reading binary."""
  180:     if bytesio.read(2) != b'#!':
  181:         return ()
  182:     first_line_b = bytesio.readline()
  183:     try:
  184:         first_line = first_line_b.decode('UTF-8')
  185:     except UnicodeDecodeError:
  186:         return ()
  187: 
  188:     # Require only printable ascii
  189:     for c in first_line:
  190:         if c not in printable:
  191:             return ()
  192: 
  193:     cmd = tuple(_shebang_split(first_line.strip()))
  194:     if cmd[:2] == ('/usr/bin/env', '-S'):
  195:         cmd = cmd[2:]
  196:     elif cmd[:1] == ('/usr/bin/env',):
  197:         cmd = cmd[1:]
  198: 
  199:     if cmd == ('nix-shell',):
  200:         return _parse_nix_shebang(bytesio, cmd)
  201: 
  202:     return cmd
  203: 
  204: 
  205: def parse_shebang_from_file(path: str) -> tuple[str, ...]:
  206:     """Parse the shebang given a file path."""
  207:     if not os.path.lexists(path):
  208:         raise ValueError(f'{path} does not exist.')
  209:     if not os.access(path, os.X_OK):
  210:         return ()
  211: 
  212:     try:
  213:         with open(path, 'rb') as f:
  214:             return parse_shebang(f)
  215:     except OSError as e:
  216:         if e.errno == errno.EINVAL:
  217:             return ()
  218:         else:
  219:             raise
  220: 
  221: 
  222: COPYRIGHT_RE = re.compile(r'^\s*(Copyright|\(C\)) .*$', re.I | re.MULTILINE)
  223: WS_RE = re.compile(r'\s+')
  224: 
  225: 
  226: def _norm_license(s: str) -> str:
  227:     s = COPYRIGHT_RE.sub('', s)
  228:     s = WS_RE.sub(' ', s)
  229:     return s.strip()
  230: 
  231: 
  232: def license_id(filename: str) -> str | None:
  233:     """Return the spdx id for the license contained in `filename`.  If no
  234:     license is detected, returns `None`.
  235: 
  236:     spdx: https://spdx.org/licenses/
  237:     licenses from choosealicense.com: https://github.com/choosealicense.com
  238: 
  239:     Approximate algorithm:
  240: 
  241:     1. strip copyright line
  242:     2. normalize whitespace (replace all whitespace with a single space)
  243:     3. check exact text match with existing licenses
  244:     4. failing that use edit distance
  245:     """
  246:     import ukkonen  # `pip install identify[license]`
  247: 
  248:     with open(filename, encoding='UTF-8') as f:
  249:         contents = f.read()
  250: 
  251:     norm = _norm_license(contents)
  252: 
  253:     min_edit_dist = sys.maxsize
  254:     min_edit_dist_spdx = ''
  255: 
  256:     cutoff = math.ceil(.05 * len(norm))
  257: 
  258:     # try exact matches
  259:     for spdx, text in licenses.LICENSES:
  260:         norm_license = _norm_license(text)
  261:         if norm == norm_license:
  262:             return spdx
  263: 
  264:         # skip the slow calculation if the lengths are very different
  265:         if norm and abs(len(norm) - len(norm_license)) / len(norm) > .05:
  266:             continue
  267: 
  268:         edit_dist = ukkonen.distance(norm, norm_license, cutoff)
  269:         if edit_dist < cutoff and edit_dist < min_edit_dist:
  270:             min_edit_dist = edit_dist
  271:             min_edit_dist_spdx = spdx
  272: 
  273:     # if there's less than 5% edited from the license, we found our match
  274:     if norm and min_edit_dist < cutoff:
  275:         return min_edit_dist_spdx
  276:     else:
  277:         # no matches :'(
  278:         return None
