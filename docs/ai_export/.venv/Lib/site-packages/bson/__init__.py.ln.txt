    1: # Copyright 2009-present MongoDB, Inc.
    2: #
    3: # Licensed under the Apache License, Version 2.0 (the "License");
    4: # you may not use this file except in compliance with the License.
    5: # You may obtain a copy of the License at
    6: #
    7: # http://www.apache.org/licenses/LICENSE-2.0
    8: #
    9: # Unless required by applicable law or agreed to in writing, software
   10: # distributed under the License is distributed on an "AS IS" BASIS,
   11: # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   12: # See the License for the specific language governing permissions and
   13: # limitations under the License.
   14: 
   15: """BSON (Binary JSON) encoding and decoding.
   16: 
   17: The mapping from Python types to BSON types is as follows:
   18: 
   19: =======================================  =============  ===================
   20: Python Type                              BSON Type      Supported Direction
   21: =======================================  =============  ===================
   22: None                                     null           both
   23: bool                                     boolean        both
   24: int [#int]_                              int32 / int64  py -> bson
   25: `bson.int64.Int64`                       int64          both
   26: float                                    number (real)  both
   27: str                                      string         both
   28: list                                     array          both
   29: dict / `SON`                             object         both
   30: datetime.datetime [#dt]_ [#dt2]_         date           both
   31: `bson.regex.Regex`                       regex          both
   32: compiled re [#re]_                       regex          py -> bson
   33: `bson.binary.Binary`                     binary         both
   34: `bson.objectid.ObjectId`                 oid            both
   35: `bson.dbref.DBRef`                       dbref          both
   36: None                                     undefined      bson -> py
   37: `bson.code.Code`                         code           both
   38: str                                      symbol         bson -> py
   39: bytes [#bytes]_                          binary         both
   40: =======================================  =============  ===================
   41: 
   42: .. [#int] A Python int will be saved as a BSON int32 or BSON int64 depending
   43:    on its size. A BSON int32 will always decode to a Python int. A BSON
   44:    int64 will always decode to a :class:`~bson.int64.Int64`.
   45: .. [#dt] datetime.datetime instances will be rounded to the nearest
   46:    millisecond when saved
   47: .. [#dt2] all datetime.datetime instances are treated as *naive*. clients
   48:    should always use UTC.
   49: .. [#re] :class:`~bson.regex.Regex` instances and regular expression
   50:    objects from ``re.compile()`` are both saved as BSON regular expressions.
   51:    BSON regular expressions are decoded as :class:`~bson.regex.Regex`
   52:    instances.
   53: .. [#bytes] The bytes type is encoded as BSON binary with
   54:    subtype 0. It will be decoded back to bytes.
   55: """
   56: from __future__ import annotations
   57: 
   58: import datetime
   59: import itertools
   60: import os
   61: import re
   62: import struct
   63: import sys
   64: import uuid
   65: from codecs import utf_8_decode as _utf_8_decode
   66: from codecs import utf_8_encode as _utf_8_encode
   67: from collections import abc as _abc
   68: from typing import (
   69:     IO,
   70:     TYPE_CHECKING,
   71:     Any,
   72:     BinaryIO,
   73:     Callable,
   74:     Generator,
   75:     Iterator,
   76:     Mapping,
   77:     MutableMapping,
   78:     NoReturn,
   79:     Optional,
   80:     Sequence,
   81:     Tuple,
   82:     Type,
   83:     TypeVar,
   84:     Union,
   85:     cast,
   86:     overload,
   87: )
   88: 
   89: from bson.binary import (
   90:     ALL_UUID_SUBTYPES,
   91:     CSHARP_LEGACY,
   92:     JAVA_LEGACY,
   93:     OLD_UUID_SUBTYPE,
   94:     STANDARD,
   95:     UUID_SUBTYPE,
   96:     Binary,
   97:     UuidRepresentation,
   98: )
   99: from bson.code import Code
  100: from bson.codec_options import (
  101:     DEFAULT_CODEC_OPTIONS,
  102:     CodecOptions,
  103:     DatetimeConversion,
  104:     _raw_document_class,
  105: )
  106: from bson.datetime_ms import (
  107:     EPOCH_AWARE,
  108:     EPOCH_NAIVE,
  109:     DatetimeMS,
  110:     _datetime_to_millis,
  111:     _millis_to_datetime,
  112: )
  113: from bson.dbref import DBRef
  114: from bson.decimal128 import Decimal128
  115: from bson.errors import InvalidBSON, InvalidDocument, InvalidStringData
  116: from bson.int64 import Int64
  117: from bson.max_key import MaxKey
  118: from bson.min_key import MinKey
  119: from bson.objectid import ObjectId
  120: from bson.regex import Regex
  121: from bson.son import RE_TYPE, SON
  122: from bson.timestamp import Timestamp
  123: from bson.tz_util import utc
  124: 
  125: # Import some modules for type-checking only.
  126: if TYPE_CHECKING:
  127:     from bson.raw_bson import RawBSONDocument
  128:     from bson.typings import _DocumentType, _ReadableBuffer
  129: 
  130: try:
  131:     from bson import _cbson  # type: ignore[attr-defined]
  132: 
  133:     _USE_C = True
  134: except ImportError:
  135:     _USE_C = False
  136: 
  137: __all__ = [
  138:     "ALL_UUID_SUBTYPES",
  139:     "CSHARP_LEGACY",
  140:     "JAVA_LEGACY",
  141:     "OLD_UUID_SUBTYPE",
  142:     "STANDARD",
  143:     "UUID_SUBTYPE",
  144:     "Binary",
  145:     "UuidRepresentation",
  146:     "Code",
  147:     "DEFAULT_CODEC_OPTIONS",
  148:     "CodecOptions",
  149:     "DBRef",
  150:     "Decimal128",
  151:     "InvalidBSON",
  152:     "InvalidDocument",
  153:     "InvalidStringData",
  154:     "Int64",
  155:     "MaxKey",
  156:     "MinKey",
  157:     "ObjectId",
  158:     "Regex",
  159:     "RE_TYPE",
  160:     "SON",
  161:     "Timestamp",
  162:     "utc",
  163:     "EPOCH_AWARE",
  164:     "EPOCH_NAIVE",
  165:     "BSONNUM",
  166:     "BSONSTR",
  167:     "BSONOBJ",
  168:     "BSONARR",
  169:     "BSONBIN",
  170:     "BSONUND",
  171:     "BSONOID",
  172:     "BSONBOO",
  173:     "BSONDAT",
  174:     "BSONNUL",
  175:     "BSONRGX",
  176:     "BSONREF",
  177:     "BSONCOD",
  178:     "BSONSYM",
  179:     "BSONCWS",
  180:     "BSONINT",
  181:     "BSONTIM",
  182:     "BSONLON",
  183:     "BSONDEC",
  184:     "BSONMIN",
  185:     "BSONMAX",
  186:     "get_data_and_view",
  187:     "gen_list_name",
  188:     "encode",
  189:     "decode",
  190:     "decode_all",
  191:     "decode_iter",
  192:     "decode_file_iter",
  193:     "is_valid",
  194:     "BSON",
  195:     "has_c",
  196:     "DatetimeConversion",
  197:     "DatetimeMS",
  198: ]
  199: 
  200: BSONNUM = b"\x01"  # Floating point
  201: BSONSTR = b"\x02"  # UTF-8 string
  202: BSONOBJ = b"\x03"  # Embedded document
  203: BSONARR = b"\x04"  # Array
  204: BSONBIN = b"\x05"  # Binary
  205: BSONUND = b"\x06"  # Undefined
  206: BSONOID = b"\x07"  # ObjectId
  207: BSONBOO = b"\x08"  # Boolean
  208: BSONDAT = b"\x09"  # UTC Datetime
  209: BSONNUL = b"\x0A"  # Null
  210: BSONRGX = b"\x0B"  # Regex
  211: BSONREF = b"\x0C"  # DBRef
  212: BSONCOD = b"\x0D"  # Javascript code
  213: BSONSYM = b"\x0E"  # Symbol
  214: BSONCWS = b"\x0F"  # Javascript code with scope
  215: BSONINT = b"\x10"  # 32bit int
  216: BSONTIM = b"\x11"  # Timestamp
  217: BSONLON = b"\x12"  # 64bit int
  218: BSONDEC = b"\x13"  # Decimal128
  219: BSONMIN = b"\xFF"  # Min key
  220: BSONMAX = b"\x7F"  # Max key
  221: 
  222: 
  223: _UNPACK_FLOAT_FROM = struct.Struct("<d").unpack_from
  224: _UNPACK_INT = struct.Struct("<i").unpack
  225: _UNPACK_INT_FROM = struct.Struct("<i").unpack_from
  226: _UNPACK_LENGTH_SUBTYPE_FROM = struct.Struct("<iB").unpack_from
  227: _UNPACK_LONG_FROM = struct.Struct("<q").unpack_from
  228: _UNPACK_TIMESTAMP_FROM = struct.Struct("<II").unpack_from
  229: 
  230: 
  231: def get_data_and_view(data: Any) -> Tuple[Any, memoryview]:
  232:     if isinstance(data, (bytes, bytearray)):
  233:         return data, memoryview(data)
  234:     view = memoryview(data)
  235:     return view.tobytes(), view
  236: 
  237: 
  238: def _raise_unknown_type(element_type: int, element_name: str) -> NoReturn:
  239:     """Unknown type helper."""
  240:     raise InvalidBSON(
  241:         "Detected unknown BSON type {!r} for fieldname '{}'. Are "
  242:         "you using the latest driver version?".format(chr(element_type).encode(), element_name)
  243:     )
  244: 
  245: 
  246: def _get_int(
  247:     data: Any, _view: Any, position: int, dummy0: Any, dummy1: Any, dummy2: Any
  248: ) -> Tuple[int, int]:
  249:     """Decode a BSON int32 to python int."""
  250:     return _UNPACK_INT_FROM(data, position)[0], position + 4
  251: 
  252: 
  253: def _get_c_string(data: Any, view: Any, position: int, opts: CodecOptions[Any]) -> Tuple[str, int]:
  254:     """Decode a BSON 'C' string to python str."""
  255:     end = data.index(b"\x00", position)
  256:     return _utf_8_decode(view[position:end], opts.unicode_decode_error_handler, True)[0], end + 1
  257: 
  258: 
  259: def _get_float(
  260:     data: Any, _view: Any, position: int, dummy0: Any, dummy1: Any, dummy2: Any
  261: ) -> Tuple[float, int]:
  262:     """Decode a BSON double to python float."""
  263:     return _UNPACK_FLOAT_FROM(data, position)[0], position + 8
  264: 
  265: 
  266: def _get_string(
  267:     data: Any, view: Any, position: int, obj_end: int, opts: CodecOptions[Any], dummy: Any
  268: ) -> Tuple[str, int]:
  269:     """Decode a BSON string to python str."""
  270:     length = _UNPACK_INT_FROM(data, position)[0]
  271:     position += 4
  272:     if length < 1 or obj_end - position < length:
  273:         raise InvalidBSON("invalid string length")
  274:     end = position + length - 1
  275:     if data[end] != 0:
  276:         raise InvalidBSON("invalid end of string")
  277:     return _utf_8_decode(view[position:end], opts.unicode_decode_error_handler, True)[0], end + 1
  278: 
  279: 
  280: def _get_object_size(data: Any, position: int, obj_end: int) -> Tuple[int, int]:
  281:     """Validate and return a BSON document's size."""
  282:     try:
  283:         obj_size = _UNPACK_INT_FROM(data, position)[0]
  284:     except struct.error as exc:
  285:         raise InvalidBSON(str(exc)) from None
  286:     end = position + obj_size - 1
  287:     if data[end] != 0:
  288:         raise InvalidBSON("bad eoo")
  289:     if end >= obj_end:
  290:         raise InvalidBSON("invalid object length")
  291:     # If this is the top-level document, validate the total size too.
  292:     if position == 0 and obj_size != obj_end:
  293:         raise InvalidBSON("invalid object length")
  294:     return obj_size, end
  295: 
  296: 
  297: def _get_object(
  298:     data: Any, view: Any, position: int, obj_end: int, opts: CodecOptions[Any], dummy: Any
  299: ) -> Tuple[Any, int]:
  300:     """Decode a BSON subdocument to opts.document_class or bson.dbref.DBRef."""
  301:     obj_size, end = _get_object_size(data, position, obj_end)
  302:     if _raw_document_class(opts.document_class):
  303:         return (opts.document_class(data[position : end + 1], opts), position + obj_size)
  304: 
  305:     obj = _elements_to_dict(data, view, position + 4, end, opts)
  306: 
  307:     position += obj_size
  308:     # If DBRef validation fails, return a normal doc.
  309:     if (
  310:         isinstance(obj.get("$ref"), str)
  311:         and "$id" in obj
  312:         and isinstance(obj.get("$db"), (str, type(None)))
  313:     ):
  314:         return (DBRef(obj.pop("$ref"), obj.pop("$id", None), obj.pop("$db", None), obj), position)
  315:     return obj, position
  316: 
  317: 
  318: def _get_array(
  319:     data: Any, view: Any, position: int, obj_end: int, opts: CodecOptions[Any], element_name: str
  320: ) -> Tuple[Any, int]:
  321:     """Decode a BSON array to python list."""
  322:     size = _UNPACK_INT_FROM(data, position)[0]
  323:     end = position + size - 1
  324:     if data[end] != 0:
  325:         raise InvalidBSON("bad eoo")
  326: 
  327:     position += 4
  328:     end -= 1
  329:     result: list[Any] = []
  330: 
  331:     # Avoid doing global and attribute lookups in the loop.
  332:     append = result.append
  333:     index = data.index
  334:     getter = _ELEMENT_GETTER
  335:     decoder_map = opts.type_registry._decoder_map
  336: 
  337:     while position < end:
  338:         element_type = data[position]
  339:         # Just skip the keys.
  340:         position = index(b"\x00", position) + 1
  341:         try:
  342:             value, position = getter[element_type](
  343:                 data, view, position, obj_end, opts, element_name
  344:             )
  345:         except KeyError:
  346:             _raise_unknown_type(element_type, element_name)
  347: 
  348:         if decoder_map:
  349:             custom_decoder = decoder_map.get(type(value))
  350:             if custom_decoder is not None:
  351:                 value = custom_decoder(value)
  352: 
  353:         append(value)
  354: 
  355:     if position != end + 1:
  356:         raise InvalidBSON("bad array length")
  357:     return result, position + 1
  358: 
  359: 
  360: def _get_binary(
  361:     data: Any, _view: Any, position: int, obj_end: int, opts: CodecOptions[Any], dummy1: Any
  362: ) -> Tuple[Union[Binary, uuid.UUID], int]:
  363:     """Decode a BSON binary to bson.binary.Binary or python UUID."""
  364:     length, subtype = _UNPACK_LENGTH_SUBTYPE_FROM(data, position)
  365:     position += 5
  366:     if subtype == 2:
  367:         length2 = _UNPACK_INT_FROM(data, position)[0]
  368:         position += 4
  369:         if length2 != length - 4:
  370:             raise InvalidBSON("invalid binary (st 2) - lengths don't match!")
  371:         length = length2
  372:     end = position + length
  373:     if length < 0 or end > obj_end:
  374:         raise InvalidBSON("bad binary object length")
  375: 
  376:     # Convert UUID subtypes to native UUIDs.
  377:     if subtype in ALL_UUID_SUBTYPES:
  378:         uuid_rep = opts.uuid_representation
  379:         binary_value = Binary(data[position:end], subtype)
  380:         if (
  381:             (uuid_rep == UuidRepresentation.UNSPECIFIED)
  382:             or (subtype == UUID_SUBTYPE and uuid_rep != STANDARD)
  383:             or (subtype == OLD_UUID_SUBTYPE and uuid_rep == STANDARD)
  384:         ):
  385:             return binary_value, end
  386:         return binary_value.as_uuid(uuid_rep), end
  387: 
  388:     # Decode subtype 0 to 'bytes'.
  389:     if subtype == 0:
  390:         value = data[position:end]
  391:     else:
  392:         value = Binary(data[position:end], subtype)
  393: 
  394:     return value, end
  395: 
  396: 
  397: def _get_oid(
  398:     data: Any, _view: Any, position: int, dummy0: Any, dummy1: Any, dummy2: Any
  399: ) -> Tuple[ObjectId, int]:
  400:     """Decode a BSON ObjectId to bson.objectid.ObjectId."""
  401:     end = position + 12
  402:     return ObjectId(data[position:end]), end
  403: 
  404: 
  405: def _get_boolean(
  406:     data: Any, _view: Any, position: int, dummy0: Any, dummy1: Any, dummy2: Any
  407: ) -> Tuple[bool, int]:
  408:     """Decode a BSON true/false to python True/False."""
  409:     end = position + 1
  410:     boolean_byte = data[position:end]
  411:     if boolean_byte == b"\x00":
  412:         return False, end
  413:     elif boolean_byte == b"\x01":
  414:         return True, end
  415:     raise InvalidBSON("invalid boolean value: %r" % boolean_byte)
  416: 
  417: 
  418: def _get_date(
  419:     data: Any, _view: Any, position: int, dummy0: int, opts: CodecOptions[Any], dummy1: Any
  420: ) -> Tuple[Union[datetime.datetime, DatetimeMS], int]:
  421:     """Decode a BSON datetime to python datetime.datetime."""
  422:     return _millis_to_datetime(_UNPACK_LONG_FROM(data, position)[0], opts), position + 8
  423: 
  424: 
  425: def _get_code(
  426:     data: Any, view: Any, position: int, obj_end: int, opts: CodecOptions[Any], element_name: str
  427: ) -> Tuple[Code, int]:
  428:     """Decode a BSON code to bson.code.Code."""
  429:     code, position = _get_string(data, view, position, obj_end, opts, element_name)
  430:     return Code(code), position
  431: 
  432: 
  433: def _get_code_w_scope(
  434:     data: Any, view: Any, position: int, _obj_end: int, opts: CodecOptions[Any], element_name: str
  435: ) -> Tuple[Code, int]:
  436:     """Decode a BSON code_w_scope to bson.code.Code."""
  437:     code_end = position + _UNPACK_INT_FROM(data, position)[0]
  438:     code, position = _get_string(data, view, position + 4, code_end, opts, element_name)
  439:     scope, position = _get_object(data, view, position, code_end, opts, element_name)
  440:     if position != code_end:
  441:         raise InvalidBSON("scope outside of javascript code boundaries")
  442:     return Code(code, scope), position
  443: 
  444: 
  445: def _get_regex(
  446:     data: Any, view: Any, position: int, dummy0: Any, opts: CodecOptions[Any], dummy1: Any
  447: ) -> Tuple[Regex[Any], int]:
  448:     """Decode a BSON regex to bson.regex.Regex or a python pattern object."""
  449:     pattern, position = _get_c_string(data, view, position, opts)
  450:     bson_flags, position = _get_c_string(data, view, position, opts)
  451:     bson_re = Regex(pattern, bson_flags)
  452:     return bson_re, position
  453: 
  454: 
  455: def _get_ref(
  456:     data: Any, view: Any, position: int, obj_end: int, opts: CodecOptions[Any], element_name: str
  457: ) -> Tuple[DBRef, int]:
  458:     """Decode (deprecated) BSON DBPointer to bson.dbref.DBRef."""
  459:     collection, position = _get_string(data, view, position, obj_end, opts, element_name)
  460:     oid, position = _get_oid(data, view, position, obj_end, opts, element_name)
  461:     return DBRef(collection, oid), position
  462: 
  463: 
  464: def _get_timestamp(
  465:     data: Any, _view: Any, position: int, dummy0: Any, dummy1: Any, dummy2: Any
  466: ) -> Tuple[Timestamp, int]:
  467:     """Decode a BSON timestamp to bson.timestamp.Timestamp."""
  468:     inc, timestamp = _UNPACK_TIMESTAMP_FROM(data, position)
  469:     return Timestamp(timestamp, inc), position + 8
  470: 
  471: 
  472: def _get_int64(
  473:     data: Any, _view: Any, position: int, dummy0: Any, dummy1: Any, dummy2: Any
  474: ) -> Tuple[Int64, int]:
  475:     """Decode a BSON int64 to bson.int64.Int64."""
  476:     return Int64(_UNPACK_LONG_FROM(data, position)[0]), position + 8
  477: 
  478: 
  479: def _get_decimal128(
  480:     data: Any, _view: Any, position: int, dummy0: Any, dummy1: Any, dummy2: Any
  481: ) -> Tuple[Decimal128, int]:
  482:     """Decode a BSON decimal128 to bson.decimal128.Decimal128."""
  483:     end = position + 16
  484:     return Decimal128.from_bid(data[position:end]), end
  485: 
  486: 
  487: # Each decoder function's signature is:
  488: #   - data: bytes
  489: #   - view: memoryview that references `data`
  490: #   - position: int, beginning of object in 'data' to decode
  491: #   - obj_end: int, end of object to decode in 'data' if variable-length type
  492: #   - opts: a CodecOptions
  493: _ELEMENT_GETTER: dict[int, Callable[..., Tuple[Any, int]]] = {
  494:     ord(BSONNUM): _get_float,
  495:     ord(BSONSTR): _get_string,
  496:     ord(BSONOBJ): _get_object,
  497:     ord(BSONARR): _get_array,
  498:     ord(BSONBIN): _get_binary,
  499:     ord(BSONUND): lambda u, v, w, x, y, z: (None, w),  # noqa: ARG005 # Deprecated undefined
  500:     ord(BSONOID): _get_oid,
  501:     ord(BSONBOO): _get_boolean,
  502:     ord(BSONDAT): _get_date,
  503:     ord(BSONNUL): lambda u, v, w, x, y, z: (None, w),  # noqa: ARG005
  504:     ord(BSONRGX): _get_regex,
  505:     ord(BSONREF): _get_ref,  # Deprecated DBPointer
  506:     ord(BSONCOD): _get_code,
  507:     ord(BSONSYM): _get_string,  # Deprecated symbol
  508:     ord(BSONCWS): _get_code_w_scope,
  509:     ord(BSONINT): _get_int,
  510:     ord(BSONTIM): _get_timestamp,
  511:     ord(BSONLON): _get_int64,
  512:     ord(BSONDEC): _get_decimal128,
  513:     ord(BSONMIN): lambda u, v, w, x, y, z: (MinKey(), w),  # noqa: ARG005
  514:     ord(BSONMAX): lambda u, v, w, x, y, z: (MaxKey(), w),  # noqa: ARG005
  515: }
  516: 
  517: 
  518: if _USE_C:
  519: 
  520:     def _element_to_dict(
  521:         data: Any,
  522:         view: Any,  # noqa: ARG001
  523:         position: int,
  524:         obj_end: int,
  525:         opts: CodecOptions[Any],
  526:         raw_array: bool = False,
  527:     ) -> Tuple[str, Any, int]:
  528:         return cast(
  529:             "Tuple[str, Any, int]",
  530:             _cbson._element_to_dict(data, position, obj_end, opts, raw_array),
  531:         )
  532: 
  533: else:
  534: 
  535:     def _element_to_dict(
  536:         data: Any,
  537:         view: Any,
  538:         position: int,
  539:         obj_end: int,
  540:         opts: CodecOptions[Any],
  541:         raw_array: bool = False,
  542:     ) -> Tuple[str, Any, int]:
  543:         """Decode a single key, value pair."""
  544:         element_type = data[position]
  545:         position += 1
  546:         element_name, position = _get_c_string(data, view, position, opts)
  547:         if raw_array and element_type == ord(BSONARR):
  548:             _, end = _get_object_size(data, position, len(data))
  549:             return element_name, view[position : end + 1], end + 1
  550:         try:
  551:             value, position = _ELEMENT_GETTER[element_type](
  552:                 data, view, position, obj_end, opts, element_name
  553:             )
  554:         except KeyError:
  555:             _raise_unknown_type(element_type, element_name)
  556: 
  557:         if opts.type_registry._decoder_map:
  558:             custom_decoder = opts.type_registry._decoder_map.get(type(value))
  559:             if custom_decoder is not None:
  560:                 value = custom_decoder(value)
  561: 
  562:         return element_name, value, position
  563: 
  564: 
  565: _T = TypeVar("_T", bound=MutableMapping[str, Any])
  566: 
  567: 
  568: def _raw_to_dict(
  569:     data: Any,
  570:     position: int,
  571:     obj_end: int,
  572:     opts: CodecOptions[RawBSONDocument],
  573:     result: _T,
  574:     raw_array: bool = False,
  575: ) -> _T:
  576:     data, view = get_data_and_view(data)
  577:     return cast(
  578:         _T, _elements_to_dict(data, view, position, obj_end, opts, result, raw_array=raw_array)
  579:     )
  580: 
  581: 
  582: def _elements_to_dict(
  583:     data: Any,
  584:     view: Any,
  585:     position: int,
  586:     obj_end: int,
  587:     opts: CodecOptions[Any],
  588:     result: Any = None,
  589:     raw_array: bool = False,
  590: ) -> Any:
  591:     """Decode a BSON document into result."""
  592:     if result is None:
  593:         result = opts.document_class()
  594:     end = obj_end - 1
  595:     while position < end:
  596:         key, value, position = _element_to_dict(
  597:             data, view, position, obj_end, opts, raw_array=raw_array
  598:         )
  599:         result[key] = value
  600:     if position != obj_end:
  601:         raise InvalidBSON("bad object or element length")
  602:     return result
  603: 
  604: 
  605: def _bson_to_dict(data: Any, opts: CodecOptions[_DocumentType]) -> _DocumentType:
  606:     """Decode a BSON string to document_class."""
  607:     data, view = get_data_and_view(data)
  608:     try:
  609:         if _raw_document_class(opts.document_class):
  610:             return opts.document_class(data, opts)  # type:ignore[call-arg]
  611:         _, end = _get_object_size(data, 0, len(data))
  612:         return cast("_DocumentType", _elements_to_dict(data, view, 4, end, opts))
  613:     except InvalidBSON:
  614:         raise
  615:     except Exception:
  616:         # Change exception type to InvalidBSON but preserve traceback.
  617:         _, exc_value, exc_tb = sys.exc_info()
  618:         raise InvalidBSON(str(exc_value)).with_traceback(exc_tb) from None
  619: 
  620: 
  621: if _USE_C:
  622:     _bson_to_dict = _cbson._bson_to_dict
  623: 
  624: 
  625: _PACK_FLOAT = struct.Struct("<d").pack
  626: _PACK_INT = struct.Struct("<i").pack
  627: _PACK_LENGTH_SUBTYPE = struct.Struct("<iB").pack
  628: _PACK_LONG = struct.Struct("<q").pack
  629: _PACK_TIMESTAMP = struct.Struct("<II").pack
  630: _LIST_NAMES = tuple((str(i) + "\x00").encode("utf8") for i in range(1000))
  631: 
  632: 
  633: def gen_list_name() -> Generator[bytes, None, None]:
  634:     """Generate "keys" for encoded lists in the sequence
  635:     b"0\x00", b"1\x00", b"2\x00", ...
  636: 
  637:     The first 1000 keys are returned from a pre-built cache. All
  638:     subsequent keys are generated on the fly.
  639:     """
  640:     yield from _LIST_NAMES
  641: 
  642:     counter = itertools.count(1000)
  643:     while True:
  644:         yield (str(next(counter)) + "\x00").encode("utf8")
  645: 
  646: 
  647: def _make_c_string_check(string: Union[str, bytes]) -> bytes:
  648:     """Make a 'C' string, checking for embedded NUL characters."""
  649:     if isinstance(string, bytes):
  650:         if b"\x00" in string:
  651:             raise InvalidDocument("BSON keys / regex patterns must not contain a NUL character")
  652:         try:
  653:             _utf_8_decode(string, None, True)
  654:             return string + b"\x00"
  655:         except UnicodeError:
  656:             raise InvalidStringData(
  657:                 "strings in documents must be valid UTF-8: %r" % string
  658:             ) from None
  659:     else:
  660:         if "\x00" in string:
  661:             raise InvalidDocument("BSON keys / regex patterns must not contain a NUL character")
  662:         return _utf_8_encode(string)[0] + b"\x00"
  663: 
  664: 
  665: def _make_c_string(string: Union[str, bytes]) -> bytes:
  666:     """Make a 'C' string."""
  667:     if isinstance(string, bytes):
  668:         try:
  669:             _utf_8_decode(string, None, True)
  670:             return string + b"\x00"
  671:         except UnicodeError:
  672:             raise InvalidStringData(
  673:                 "strings in documents must be valid UTF-8: %r" % string
  674:             ) from None
  675:     else:
  676:         return _utf_8_encode(string)[0] + b"\x00"
  677: 
  678: 
  679: def _make_name(string: str) -> bytes:
  680:     """Make a 'C' string suitable for a BSON key."""
  681:     if "\x00" in string:
  682:         raise InvalidDocument("BSON keys must not contain a NUL character")
  683:     return _utf_8_encode(string)[0] + b"\x00"
  684: 
  685: 
  686: def _encode_float(name: bytes, value: float, dummy0: Any, dummy1: Any) -> bytes:
  687:     """Encode a float."""
  688:     return b"\x01" + name + _PACK_FLOAT(value)
  689: 
  690: 
  691: def _encode_bytes(name: bytes, value: bytes, dummy0: Any, dummy1: Any) -> bytes:
  692:     """Encode a python bytes."""
  693:     # Python3 special case. Store 'bytes' as BSON binary subtype 0.
  694:     return b"\x05" + name + _PACK_INT(len(value)) + b"\x00" + value
  695: 
  696: 
  697: def _encode_mapping(name: bytes, value: Any, check_keys: bool, opts: CodecOptions[Any]) -> bytes:
  698:     """Encode a mapping type."""
  699:     if _raw_document_class(value):
  700:         return b"\x03" + name + cast(bytes, value.raw)
  701:     data = b"".join([_element_to_bson(key, val, check_keys, opts) for key, val in value.items()])
  702:     return b"\x03" + name + _PACK_INT(len(data) + 5) + data + b"\x00"
  703: 
  704: 
  705: def _encode_dbref(name: bytes, value: DBRef, check_keys: bool, opts: CodecOptions[Any]) -> bytes:
  706:     """Encode bson.dbref.DBRef."""
  707:     buf = bytearray(b"\x03" + name + b"\x00\x00\x00\x00")
  708:     begin = len(buf) - 4
  709: 
  710:     buf += _name_value_to_bson(b"$ref\x00", value.collection, check_keys, opts)
  711:     buf += _name_value_to_bson(b"$id\x00", value.id, check_keys, opts)
  712:     if value.database is not None:
  713:         buf += _name_value_to_bson(b"$db\x00", value.database, check_keys, opts)
  714:     for key, val in value._DBRef__kwargs.items():
  715:         buf += _element_to_bson(key, val, check_keys, opts)
  716: 
  717:     buf += b"\x00"
  718:     buf[begin : begin + 4] = _PACK_INT(len(buf) - begin)
  719:     return bytes(buf)
  720: 
  721: 
  722: def _encode_list(
  723:     name: bytes, value: Sequence[Any], check_keys: bool, opts: CodecOptions[Any]
  724: ) -> bytes:
  725:     """Encode a list/tuple."""
  726:     lname = gen_list_name()
  727:     data = b"".join([_name_value_to_bson(next(lname), item, check_keys, opts) for item in value])
  728:     return b"\x04" + name + _PACK_INT(len(data) + 5) + data + b"\x00"
  729: 
  730: 
  731: def _encode_text(name: bytes, value: str, dummy0: Any, dummy1: Any) -> bytes:
  732:     """Encode a python str."""
  733:     bvalue = _utf_8_encode(value)[0]
  734:     return b"\x02" + name + _PACK_INT(len(bvalue) + 1) + bvalue + b"\x00"
  735: 
  736: 
  737: def _encode_binary(name: bytes, value: Binary, dummy0: Any, dummy1: Any) -> bytes:
  738:     """Encode bson.binary.Binary."""
  739:     subtype = value.subtype
  740:     if subtype == 2:
  741:         value = _PACK_INT(len(value)) + value  # type: ignore
  742:     return b"\x05" + name + _PACK_LENGTH_SUBTYPE(len(value), subtype) + value
  743: 
  744: 
  745: def _encode_uuid(name: bytes, value: uuid.UUID, dummy: Any, opts: CodecOptions[Any]) -> bytes:
  746:     """Encode uuid.UUID."""
  747:     uuid_representation = opts.uuid_representation
  748:     binval = Binary.from_uuid(value, uuid_representation=uuid_representation)
  749:     return _encode_binary(name, binval, dummy, opts)
  750: 
  751: 
  752: def _encode_objectid(name: bytes, value: ObjectId, dummy: Any, dummy1: Any) -> bytes:
  753:     """Encode bson.objectid.ObjectId."""
  754:     return b"\x07" + name + value.binary
  755: 
  756: 
  757: def _encode_bool(name: bytes, value: bool, dummy0: Any, dummy1: Any) -> bytes:
  758:     """Encode a python boolean (True/False)."""
  759:     return b"\x08" + name + (value and b"\x01" or b"\x00")
  760: 
  761: 
  762: def _encode_datetime(name: bytes, value: datetime.datetime, dummy0: Any, dummy1: Any) -> bytes:
  763:     """Encode datetime.datetime."""
  764:     millis = _datetime_to_millis(value)
  765:     return b"\x09" + name + _PACK_LONG(millis)
  766: 
  767: 
  768: def _encode_datetime_ms(name: bytes, value: DatetimeMS, dummy0: Any, dummy1: Any) -> bytes:
  769:     """Encode datetime.datetime."""
  770:     millis = int(value)
  771:     return b"\x09" + name + _PACK_LONG(millis)
  772: 
  773: 
  774: def _encode_none(name: bytes, dummy0: Any, dummy1: Any, dummy2: Any) -> bytes:
  775:     """Encode python None."""
  776:     return b"\x0A" + name
  777: 
  778: 
  779: def _encode_regex(name: bytes, value: Regex[Any], dummy0: Any, dummy1: Any) -> bytes:
  780:     """Encode a python regex or bson.regex.Regex."""
  781:     flags = value.flags
  782:     # Python 3 common case
  783:     if flags == re.UNICODE:
  784:         return b"\x0B" + name + _make_c_string_check(value.pattern) + b"u\x00"
  785:     elif flags == 0:
  786:         return b"\x0B" + name + _make_c_string_check(value.pattern) + b"\x00"
  787:     else:
  788:         sflags = b""
  789:         if flags & re.IGNORECASE:
  790:             sflags += b"i"
  791:         if flags & re.LOCALE:
  792:             sflags += b"l"
  793:         if flags & re.MULTILINE:
  794:             sflags += b"m"
  795:         if flags & re.DOTALL:
  796:             sflags += b"s"
  797:         if flags & re.UNICODE:
  798:             sflags += b"u"
  799:         if flags & re.VERBOSE:
  800:             sflags += b"x"
  801:         sflags += b"\x00"
  802:         return b"\x0B" + name + _make_c_string_check(value.pattern) + sflags
  803: 
  804: 
  805: def _encode_code(name: bytes, value: Code, dummy: Any, opts: CodecOptions[Any]) -> bytes:
  806:     """Encode bson.code.Code."""
  807:     cstring = _make_c_string(value)
  808:     cstrlen = len(cstring)
  809:     if value.scope is None:
  810:         return b"\x0D" + name + _PACK_INT(cstrlen) + cstring
  811:     scope = _dict_to_bson(value.scope, False, opts, False)
  812:     full_length = _PACK_INT(8 + cstrlen + len(scope))
  813:     return b"\x0F" + name + full_length + _PACK_INT(cstrlen) + cstring + scope
  814: 
  815: 
  816: def _encode_int(name: bytes, value: int, dummy0: Any, dummy1: Any) -> bytes:
  817:     """Encode a python int."""
  818:     if -2147483648 <= value <= 2147483647:
  819:         return b"\x10" + name + _PACK_INT(value)
  820:     else:
  821:         try:
  822:             return b"\x12" + name + _PACK_LONG(value)
  823:         except struct.error:
  824:             raise OverflowError("BSON can only handle up to 8-byte ints") from None
  825: 
  826: 
  827: def _encode_timestamp(name: bytes, value: Any, dummy0: Any, dummy1: Any) -> bytes:
  828:     """Encode bson.timestamp.Timestamp."""
  829:     return b"\x11" + name + _PACK_TIMESTAMP(value.inc, value.time)
  830: 
  831: 
  832: def _encode_long(name: bytes, value: Any, dummy0: Any, dummy1: Any) -> bytes:
  833:     """Encode a bson.int64.Int64."""
  834:     try:
  835:         return b"\x12" + name + _PACK_LONG(value)
  836:     except struct.error:
  837:         raise OverflowError("BSON can only handle up to 8-byte ints") from None
  838: 
  839: 
  840: def _encode_decimal128(name: bytes, value: Decimal128, dummy0: Any, dummy1: Any) -> bytes:
  841:     """Encode bson.decimal128.Decimal128."""
  842:     return b"\x13" + name + value.bid
  843: 
  844: 
  845: def _encode_minkey(name: bytes, dummy0: Any, dummy1: Any, dummy2: Any) -> bytes:
  846:     """Encode bson.min_key.MinKey."""
  847:     return b"\xFF" + name
  848: 
  849: 
  850: def _encode_maxkey(name: bytes, dummy0: Any, dummy1: Any, dummy2: Any) -> bytes:
  851:     """Encode bson.max_key.MaxKey."""
  852:     return b"\x7F" + name
  853: 
  854: 
  855: # Each encoder function's signature is:
  856: #   - name: utf-8 bytes
  857: #   - value: a Python data type, e.g. a Python int for _encode_int
  858: #   - check_keys: bool, whether to check for invalid names
  859: #   - opts: a CodecOptions
  860: _ENCODERS = {
  861:     bool: _encode_bool,
  862:     bytes: _encode_bytes,
  863:     datetime.datetime: _encode_datetime,
  864:     DatetimeMS: _encode_datetime_ms,
  865:     dict: _encode_mapping,
  866:     float: _encode_float,
  867:     int: _encode_int,
  868:     list: _encode_list,
  869:     str: _encode_text,
  870:     tuple: _encode_list,
  871:     type(None): _encode_none,
  872:     uuid.UUID: _encode_uuid,
  873:     Binary: _encode_binary,
  874:     Int64: _encode_long,
  875:     Code: _encode_code,
  876:     DBRef: _encode_dbref,
  877:     MaxKey: _encode_maxkey,
  878:     MinKey: _encode_minkey,
  879:     ObjectId: _encode_objectid,
  880:     Regex: _encode_regex,
  881:     RE_TYPE: _encode_regex,
  882:     SON: _encode_mapping,
  883:     Timestamp: _encode_timestamp,
  884:     Decimal128: _encode_decimal128,
  885:     # Special case. This will never be looked up directly.
  886:     _abc.Mapping: _encode_mapping,
  887: }
  888: 
  889: # Map each _type_marker to its encoder for faster lookup.
  890: _MARKERS = {}
  891: for _typ in _ENCODERS:
  892:     if hasattr(_typ, "_type_marker"):
  893:         _MARKERS[_typ._type_marker] = _ENCODERS[_typ]
  894: 
  895: 
  896: _BUILT_IN_TYPES = tuple(t for t in _ENCODERS)
  897: 
  898: 
  899: def _name_value_to_bson(
  900:     name: bytes,
  901:     value: Any,
  902:     check_keys: bool,
  903:     opts: CodecOptions[Any],
  904:     in_custom_call: bool = False,
  905:     in_fallback_call: bool = False,
  906: ) -> bytes:
  907:     """Encode a single name, value pair."""
  908: 
  909:     was_integer_overflow = False
  910: 
  911:     # First see if the type is already cached. KeyError will only ever
  912:     # happen once per subtype.
  913:     try:
  914:         return _ENCODERS[type(value)](name, value, check_keys, opts)  # type: ignore
  915:     except KeyError:
  916:         pass
  917:     except OverflowError:
  918:         if not isinstance(value, int):
  919:             raise
  920: 
  921:         # Give the fallback_encoder a chance
  922:         was_integer_overflow = True
  923: 
  924:     # Second, fall back to trying _type_marker. This has to be done
  925:     # before the loop below since users could subclass one of our
  926:     # custom types that subclasses a python built-in (e.g. Binary)
  927:     marker = getattr(value, "_type_marker", None)
  928:     if isinstance(marker, int) and marker in _MARKERS:
  929:         func = _MARKERS[marker]
  930:         # Cache this type for faster subsequent lookup.
  931:         _ENCODERS[type(value)] = func
  932:         return func(name, value, check_keys, opts)  # type: ignore
  933: 
  934:     # Third, check if a type encoder is registered for this type.
  935:     # Note that subtypes of registered custom types are not auto-encoded.
  936:     if not in_custom_call and opts.type_registry._encoder_map:
  937:         custom_encoder = opts.type_registry._encoder_map.get(type(value))
  938:         if custom_encoder is not None:
  939:             return _name_value_to_bson(
  940:                 name, custom_encoder(value), check_keys, opts, in_custom_call=True
  941:             )
  942: 
  943:     # Fourth, test each base type. This will only happen once for
  944:     # a subtype of a supported base type. Unlike in the C-extensions, this
  945:     # is done after trying the custom type encoder because checking for each
  946:     # subtype is expensive.
  947:     for base in _BUILT_IN_TYPES:
  948:         if not was_integer_overflow and isinstance(value, base):
  949:             func = _ENCODERS[base]
  950:             # Cache this type for faster subsequent lookup.
  951:             _ENCODERS[type(value)] = func
  952:             return func(name, value, check_keys, opts)  # type: ignore
  953: 
  954:     # As a last resort, try using the fallback encoder, if the user has
  955:     # provided one.
  956:     fallback_encoder = opts.type_registry._fallback_encoder
  957:     if not in_fallback_call and fallback_encoder is not None:
  958:         return _name_value_to_bson(
  959:             name, fallback_encoder(value), check_keys, opts, in_fallback_call=True
  960:         )
  961: 
  962:     if was_integer_overflow:
  963:         raise OverflowError("BSON can only handle up to 8-byte ints")
  964:     raise InvalidDocument(f"cannot encode object: {value!r}, of type: {type(value)!r}")
  965: 
  966: 
  967: def _element_to_bson(key: Any, value: Any, check_keys: bool, opts: CodecOptions[Any]) -> bytes:
  968:     """Encode a single key, value pair."""
  969:     if not isinstance(key, str):
  970:         raise InvalidDocument(f"documents must have only string keys, key was {key!r}")
  971:     if check_keys:
  972:         if key.startswith("$"):
  973:             raise InvalidDocument(f"key {key!r} must not start with '$'")
  974:         if "." in key:
  975:             raise InvalidDocument(f"key {key!r} must not contain '.'")
  976: 
  977:     name = _make_name(key)
  978:     return _name_value_to_bson(name, value, check_keys, opts)
  979: 
  980: 
  981: def _dict_to_bson(
  982:     doc: Any, check_keys: bool, opts: CodecOptions[Any], top_level: bool = True
  983: ) -> bytes:
  984:     """Encode a document to BSON."""
  985:     if _raw_document_class(doc):
  986:         return cast(bytes, doc.raw)
  987:     try:
  988:         elements = []
  989:         if top_level and "_id" in doc:
  990:             elements.append(_name_value_to_bson(b"_id\x00", doc["_id"], check_keys, opts))
  991:         for key, value in doc.items():
  992:             if not top_level or key != "_id":
  993:                 elements.append(_element_to_bson(key, value, check_keys, opts))
  994:     except AttributeError:
  995:         raise TypeError(f"encoder expected a mapping type but got: {doc!r}") from None
  996: 
  997:     encoded = b"".join(elements)
  998:     return _PACK_INT(len(encoded) + 5) + encoded + b"\x00"
  999: 
 1000: 
 1001: if _USE_C:
 1002:     _dict_to_bson = _cbson._dict_to_bson
 1003: 
 1004: 
 1005: _CODEC_OPTIONS_TYPE_ERROR = TypeError("codec_options must be an instance of CodecOptions")
 1006: 
 1007: 
 1008: def encode(
 1009:     document: Mapping[str, Any],
 1010:     check_keys: bool = False,
 1011:     codec_options: CodecOptions[Any] = DEFAULT_CODEC_OPTIONS,
 1012: ) -> bytes:
 1013:     """Encode a document to BSON.
 1014: 
 1015:     A document can be any mapping type (like :class:`dict`).
 1016: 
 1017:     Raises :class:`TypeError` if `document` is not a mapping type,
 1018:     or contains keys that are not instances of :class:`str`. Raises
 1019:     :class:`~bson.errors.InvalidDocument` if `document` cannot be
 1020:     converted to :class:`BSON`.
 1021: 
 1022:     :param document: mapping type representing a document
 1023:     :param check_keys: check if keys start with '$' or
 1024:         contain '.', raising :class:`~bson.errors.InvalidDocument` in
 1025:         either case
 1026:     :param codec_options: An instance of
 1027:         :class:`~bson.codec_options.CodecOptions`.
 1028: 
 1029:     .. versionadded:: 3.9
 1030:     """
 1031:     if not isinstance(codec_options, CodecOptions):
 1032:         raise _CODEC_OPTIONS_TYPE_ERROR
 1033: 
 1034:     return _dict_to_bson(document, check_keys, codec_options)
 1035: 
 1036: 
 1037: @overload
 1038: def decode(data: _ReadableBuffer, codec_options: None = None) -> dict[str, Any]:
 1039:     ...
 1040: 
 1041: 
 1042: @overload
 1043: def decode(data: _ReadableBuffer, codec_options: CodecOptions[_DocumentType]) -> _DocumentType:
 1044:     ...
 1045: 
 1046: 
 1047: def decode(
 1048:     data: _ReadableBuffer, codec_options: Optional[CodecOptions[_DocumentType]] = None
 1049: ) -> Union[dict[str, Any], _DocumentType]:
 1050:     """Decode BSON to a document.
 1051: 
 1052:     By default, returns a BSON document represented as a Python
 1053:     :class:`dict`. To use a different :class:`MutableMapping` class,
 1054:     configure a :class:`~bson.codec_options.CodecOptions`::
 1055: 
 1056:         >>> import collections  # From Python standard library.
 1057:         >>> import bson
 1058:         >>> from bson.codec_options import CodecOptions
 1059:         >>> data = bson.encode({'a': 1})
 1060:         >>> decoded_doc = bson.decode(data)
 1061:         <type 'dict'>
 1062:         >>> options = CodecOptions(document_class=collections.OrderedDict)
 1063:         >>> decoded_doc = bson.decode(data, codec_options=options)
 1064:         >>> type(decoded_doc)
 1065:         <class 'collections.OrderedDict'>
 1066: 
 1067:     :param data: the BSON to decode. Any bytes-like object that implements
 1068:         the buffer protocol.
 1069:     :param codec_options: An instance of
 1070:         :class:`~bson.codec_options.CodecOptions`.
 1071: 
 1072:     .. versionadded:: 3.9
 1073:     """
 1074:     opts: CodecOptions[Any] = codec_options or DEFAULT_CODEC_OPTIONS
 1075:     if not isinstance(opts, CodecOptions):
 1076:         raise _CODEC_OPTIONS_TYPE_ERROR
 1077: 
 1078:     return cast("Union[dict[str, Any], _DocumentType]", _bson_to_dict(data, opts))
 1079: 
 1080: 
 1081: def _decode_all(data: _ReadableBuffer, opts: CodecOptions[_DocumentType]) -> list[_DocumentType]:
 1082:     """Decode a BSON data to multiple documents."""
 1083:     data, view = get_data_and_view(data)
 1084:     data_len = len(data)
 1085:     docs: list[_DocumentType] = []
 1086:     position = 0
 1087:     end = data_len - 1
 1088:     use_raw = _raw_document_class(opts.document_class)
 1089:     try:
 1090:         while position < end:
 1091:             obj_size = _UNPACK_INT_FROM(data, position)[0]
 1092:             if data_len - position < obj_size:
 1093:                 raise InvalidBSON("invalid object size")
 1094:             obj_end = position + obj_size - 1
 1095:             if data[obj_end] != 0:
 1096:                 raise InvalidBSON("bad eoo")
 1097:             if use_raw:
 1098:                 docs.append(opts.document_class(data[position : obj_end + 1], opts))  # type: ignore
 1099:             else:
 1100:                 docs.append(_elements_to_dict(data, view, position + 4, obj_end, opts))
 1101:             position += obj_size
 1102:         return docs
 1103:     except InvalidBSON:
 1104:         raise
 1105:     except Exception:
 1106:         # Change exception type to InvalidBSON but preserve traceback.
 1107:         _, exc_value, exc_tb = sys.exc_info()
 1108:         raise InvalidBSON(str(exc_value)).with_traceback(exc_tb) from None
 1109: 
 1110: 
 1111: if _USE_C:
 1112:     _decode_all = _cbson._decode_all
 1113: 
 1114: 
 1115: @overload
 1116: def decode_all(data: _ReadableBuffer, codec_options: None = None) -> list[dict[str, Any]]:
 1117:     ...
 1118: 
 1119: 
 1120: @overload
 1121: def decode_all(
 1122:     data: _ReadableBuffer, codec_options: CodecOptions[_DocumentType]
 1123: ) -> list[_DocumentType]:
 1124:     ...
 1125: 
 1126: 
 1127: def decode_all(
 1128:     data: _ReadableBuffer, codec_options: Optional[CodecOptions[_DocumentType]] = None
 1129: ) -> Union[list[dict[str, Any]], list[_DocumentType]]:
 1130:     """Decode BSON data to multiple documents.
 1131: 
 1132:     `data` must be a bytes-like object implementing the buffer protocol that
 1133:     provides concatenated, valid, BSON-encoded documents.
 1134: 
 1135:     :param data: BSON data
 1136:     :param codec_options: An instance of
 1137:         :class:`~bson.codec_options.CodecOptions`.
 1138: 
 1139:     .. versionchanged:: 3.9
 1140:        Supports bytes-like objects that implement the buffer protocol.
 1141: 
 1142:     .. versionchanged:: 3.0
 1143:        Removed `compile_re` option: PyMongo now always represents BSON regular
 1144:        expressions as :class:`~bson.regex.Regex` objects. Use
 1145:        :meth:`~bson.regex.Regex.try_compile` to attempt to convert from a
 1146:        BSON regular expression to a Python regular expression object.
 1147: 
 1148:        Replaced `as_class`, `tz_aware`, and `uuid_subtype` options with
 1149:        `codec_options`.
 1150:     """
 1151:     if codec_options is None:
 1152:         return _decode_all(data, DEFAULT_CODEC_OPTIONS)
 1153: 
 1154:     if not isinstance(codec_options, CodecOptions):
 1155:         raise _CODEC_OPTIONS_TYPE_ERROR
 1156: 
 1157:     return _decode_all(data, codec_options)
 1158: 
 1159: 
 1160: def _decode_selective(
 1161:     rawdoc: Any, fields: Any, codec_options: CodecOptions[_DocumentType]
 1162: ) -> _DocumentType:
 1163:     if _raw_document_class(codec_options.document_class):
 1164:         # If document_class is RawBSONDocument, use vanilla dictionary for
 1165:         # decoding command response.
 1166:         doc: _DocumentType = {}  # type:ignore[assignment]
 1167:     else:
 1168:         # Else, use the specified document_class.
 1169:         doc = codec_options.document_class()
 1170:     for key, value in rawdoc.items():
 1171:         if key in fields:
 1172:             if fields[key] == 1:
 1173:                 doc[key] = _bson_to_dict(rawdoc.raw, codec_options)[key]  # type:ignore[index]
 1174:             else:
 1175:                 doc[key] = _decode_selective(  # type:ignore[index]
 1176:                     value, fields[key], codec_options
 1177:                 )
 1178:         else:
 1179:             doc[key] = value  # type:ignore[index]
 1180:     return doc
 1181: 
 1182: 
 1183: def _array_of_documents_to_buffer(view: memoryview) -> bytes:
 1184:     # Extract the raw bytes of each document.
 1185:     position = 0
 1186:     _, end = _get_object_size(view, position, len(view))
 1187:     position += 4
 1188:     buffers: list[memoryview] = []
 1189:     append = buffers.append
 1190:     while position < end - 1:
 1191:         # Just skip the keys.
 1192:         while view[position] != 0:
 1193:             position += 1
 1194:         position += 1
 1195:         obj_size, _ = _get_object_size(view, position, end)
 1196:         append(view[position : position + obj_size])
 1197:         position += obj_size
 1198:     if position != end:
 1199:         raise InvalidBSON("bad object or element length")
 1200:     return b"".join(buffers)
 1201: 
 1202: 
 1203: if _USE_C:
 1204:     _array_of_documents_to_buffer = _cbson._array_of_documents_to_buffer
 1205: 
 1206: 
 1207: def _convert_raw_document_lists_to_streams(document: Any) -> None:
 1208:     """Convert raw array of documents to a stream of BSON documents."""
 1209:     cursor = document.get("cursor")
 1210:     if not cursor:
 1211:         return
 1212:     for key in ("firstBatch", "nextBatch"):
 1213:         batch = cursor.get(key)
 1214:         if not batch:
 1215:             continue
 1216:         data = _array_of_documents_to_buffer(batch)
 1217:         if data:
 1218:             cursor[key] = [data]
 1219:         else:
 1220:             cursor[key] = []
 1221: 
 1222: 
 1223: def _decode_all_selective(
 1224:     data: Any, codec_options: CodecOptions[_DocumentType], fields: Any
 1225: ) -> list[_DocumentType]:
 1226:     """Decode BSON data to a single document while using user-provided
 1227:     custom decoding logic.
 1228: 
 1229:     `data` must be a string representing a valid, BSON-encoded document.
 1230: 
 1231:     :param data: BSON data
 1232:     :param codec_options: An instance of
 1233:         :class:`~bson.codec_options.CodecOptions` with user-specified type
 1234:         decoders. If no decoders are found, this method is the same as
 1235:         ``decode_all``.
 1236:     :param fields: Map of document namespaces where data that needs
 1237:         to be custom decoded lives or None. For example, to custom decode a
 1238:         list of objects in 'field1.subfield1', the specified value should be
 1239:         ``{'field1': {'subfield1': 1}}``. If ``fields``  is an empty map or
 1240:         None, this method is the same as ``decode_all``.
 1241: 
 1242:     :return: Single-member list containing the decoded document.
 1243: 
 1244:     .. versionadded:: 3.8
 1245:     """
 1246:     if not codec_options.type_registry._decoder_map:
 1247:         return decode_all(data, codec_options)
 1248: 
 1249:     if not fields:
 1250:         return decode_all(data, codec_options.with_options(type_registry=None))
 1251: 
 1252:     # Decode documents for internal use.
 1253:     from bson.raw_bson import RawBSONDocument
 1254: 
 1255:     internal_codec_options: CodecOptions[RawBSONDocument] = codec_options.with_options(
 1256:         document_class=RawBSONDocument, type_registry=None
 1257:     )
 1258:     _doc = _bson_to_dict(data, internal_codec_options)
 1259:     return [
 1260:         _decode_selective(
 1261:             _doc,
 1262:             fields,
 1263:             codec_options,
 1264:         )
 1265:     ]
 1266: 
 1267: 
 1268: @overload
 1269: def decode_iter(data: bytes, codec_options: None = None) -> Iterator[dict[str, Any]]:
 1270:     ...
 1271: 
 1272: 
 1273: @overload
 1274: def decode_iter(data: bytes, codec_options: CodecOptions[_DocumentType]) -> Iterator[_DocumentType]:
 1275:     ...
 1276: 
 1277: 
 1278: def decode_iter(
 1279:     data: bytes, codec_options: Optional[CodecOptions[_DocumentType]] = None
 1280: ) -> Union[Iterator[dict[str, Any]], Iterator[_DocumentType]]:
 1281:     """Decode BSON data to multiple documents as a generator.
 1282: 
 1283:     Works similarly to the decode_all function, but yields one document at a
 1284:     time.
 1285: 
 1286:     `data` must be a string of concatenated, valid, BSON-encoded
 1287:     documents.
 1288: 
 1289:     :param data: BSON data
 1290:     :param codec_options: An instance of
 1291:         :class:`~bson.codec_options.CodecOptions`.
 1292: 
 1293:     .. versionchanged:: 3.0
 1294:        Replaced `as_class`, `tz_aware`, and `uuid_subtype` options with
 1295:        `codec_options`.
 1296: 
 1297:     .. versionadded:: 2.8
 1298:     """
 1299:     opts = codec_options or DEFAULT_CODEC_OPTIONS
 1300:     if not isinstance(opts, CodecOptions):
 1301:         raise _CODEC_OPTIONS_TYPE_ERROR
 1302: 
 1303:     position = 0
 1304:     end = len(data) - 1
 1305:     while position < end:
 1306:         obj_size = _UNPACK_INT_FROM(data, position)[0]
 1307:         elements = data[position : position + obj_size]
 1308:         position += obj_size
 1309: 
 1310:         yield _bson_to_dict(elements, opts)  # type:ignore[misc, type-var]
 1311: 
 1312: 
 1313: @overload
 1314: def decode_file_iter(
 1315:     file_obj: Union[BinaryIO, IO[bytes]], codec_options: None = None
 1316: ) -> Iterator[dict[str, Any]]:
 1317:     ...
 1318: 
 1319: 
 1320: @overload
 1321: def decode_file_iter(
 1322:     file_obj: Union[BinaryIO, IO[bytes]], codec_options: CodecOptions[_DocumentType]
 1323: ) -> Iterator[_DocumentType]:
 1324:     ...
 1325: 
 1326: 
 1327: def decode_file_iter(
 1328:     file_obj: Union[BinaryIO, IO[bytes]],
 1329:     codec_options: Optional[CodecOptions[_DocumentType]] = None,
 1330: ) -> Union[Iterator[dict[str, Any]], Iterator[_DocumentType]]:
 1331:     """Decode bson data from a file to multiple documents as a generator.
 1332: 
 1333:     Works similarly to the decode_all function, but reads from the file object
 1334:     in chunks and parses bson in chunks, yielding one document at a time.
 1335: 
 1336:     :param file_obj: A file object containing BSON data.
 1337:     :param codec_options: An instance of
 1338:         :class:`~bson.codec_options.CodecOptions`.
 1339: 
 1340:     .. versionchanged:: 3.0
 1341:        Replaced `as_class`, `tz_aware`, and `uuid_subtype` options with
 1342:        `codec_options`.
 1343: 
 1344:     .. versionadded:: 2.8
 1345:     """
 1346:     opts = codec_options or DEFAULT_CODEC_OPTIONS
 1347:     while True:
 1348:         # Read size of next object.
 1349:         size_data: Any = file_obj.read(4)
 1350:         if not size_data:
 1351:             break  # Finished with file normally.
 1352:         elif len(size_data) != 4:
 1353:             raise InvalidBSON("cut off in middle of objsize")
 1354:         obj_size = _UNPACK_INT_FROM(size_data, 0)[0] - 4
 1355:         elements = size_data + file_obj.read(max(0, obj_size))
 1356:         yield _bson_to_dict(elements, opts)  # type:ignore[type-var, arg-type, misc]
 1357: 
 1358: 
 1359: def is_valid(bson: bytes) -> bool:
 1360:     """Check that the given string represents valid :class:`BSON` data.
 1361: 
 1362:     Raises :class:`TypeError` if `bson` is not an instance of
 1363:     :class:`bytes`. Returns ``True``
 1364:     if `bson` is valid :class:`BSON`, ``False`` otherwise.
 1365: 
 1366:     :param bson: the data to be validated
 1367:     """
 1368:     if not isinstance(bson, bytes):
 1369:         raise TypeError("BSON data must be an instance of a subclass of bytes")
 1370: 
 1371:     try:
 1372:         _bson_to_dict(bson, DEFAULT_CODEC_OPTIONS)
 1373:         return True
 1374:     except Exception:
 1375:         return False
 1376: 
 1377: 
 1378: class BSON(bytes):
 1379:     """BSON (Binary JSON) data.
 1380: 
 1381:     .. warning:: Using this class to encode and decode BSON adds a performance
 1382:        cost. For better performance use the module level functions
 1383:        :func:`encode` and :func:`decode` instead.
 1384:     """
 1385: 
 1386:     @classmethod
 1387:     def encode(
 1388:         cls: Type[BSON],
 1389:         document: Mapping[str, Any],
 1390:         check_keys: bool = False,
 1391:         codec_options: CodecOptions[Any] = DEFAULT_CODEC_OPTIONS,
 1392:     ) -> BSON:
 1393:         """Encode a document to a new :class:`BSON` instance.
 1394: 
 1395:         A document can be any mapping type (like :class:`dict`).
 1396: 
 1397:         Raises :class:`TypeError` if `document` is not a mapping type,
 1398:         or contains keys that are not instances of
 1399:         :class:`str'. Raises :class:`~bson.errors.InvalidDocument`
 1400:         if `document` cannot be converted to :class:`BSON`.
 1401: 
 1402:         :param document: mapping type representing a document
 1403:         :param check_keys: check if keys start with '$' or
 1404:             contain '.', raising :class:`~bson.errors.InvalidDocument` in
 1405:             either case
 1406:         :param codec_options: An instance of
 1407:             :class:`~bson.codec_options.CodecOptions`.
 1408: 
 1409:         .. versionchanged:: 3.0
 1410:            Replaced `uuid_subtype` option with `codec_options`.
 1411:         """
 1412:         return cls(encode(document, check_keys, codec_options))
 1413: 
 1414:     def decode(  # type:ignore[override]
 1415:         self, codec_options: CodecOptions[Any] = DEFAULT_CODEC_OPTIONS
 1416:     ) -> dict[str, Any]:
 1417:         """Decode this BSON data.
 1418: 
 1419:         By default, returns a BSON document represented as a Python
 1420:         :class:`dict`. To use a different :class:`MutableMapping` class,
 1421:         configure a :class:`~bson.codec_options.CodecOptions`::
 1422: 
 1423:             >>> import collections  # From Python standard library.
 1424:             >>> import bson
 1425:             >>> from bson.codec_options import CodecOptions
 1426:             >>> data = bson.BSON.encode({'a': 1})
 1427:             >>> decoded_doc = bson.BSON(data).decode()
 1428:             <type 'dict'>
 1429:             >>> options = CodecOptions(document_class=collections.OrderedDict)
 1430:             >>> decoded_doc = bson.BSON(data).decode(codec_options=options)
 1431:             >>> type(decoded_doc)
 1432:             <class 'collections.OrderedDict'>
 1433: 
 1434:         :param codec_options: An instance of
 1435:             :class:`~bson.codec_options.CodecOptions`.
 1436: 
 1437:         .. versionchanged:: 3.0
 1438:            Removed `compile_re` option: PyMongo now always represents BSON
 1439:            regular expressions as :class:`~bson.regex.Regex` objects. Use
 1440:            :meth:`~bson.regex.Regex.try_compile` to attempt to convert from a
 1441:            BSON regular expression to a Python regular expression object.
 1442: 
 1443:            Replaced `as_class`, `tz_aware`, and `uuid_subtype` options with
 1444:            `codec_options`.
 1445:         """
 1446:         return decode(self, codec_options)
 1447: 
 1448: 
 1449: def has_c() -> bool:
 1450:     """Is the C extension installed?"""
 1451:     return _USE_C
 1452: 
 1453: 
 1454: def _after_fork() -> None:
 1455:     """Releases the ObjectID lock child."""
 1456:     if ObjectId._inc_lock.locked():
 1457:         ObjectId._inc_lock.release()
 1458: 
 1459: 
 1460: if hasattr(os, "register_at_fork"):
 1461:     # This will run in the same thread as the fork was called.
 1462:     # If we fork in a critical region on the same thread, it should break.
 1463:     # This is fine since we would never call fork directly from a critical region.
 1464:     os.register_at_fork(after_in_child=_after_fork)
