    1: from __future__ import annotations
    2: 
    3: import concurrent.futures
    4: import contextlib
    5: import math
    6: import multiprocessing
    7: import os
    8: import subprocess
    9: import sys
   10: from collections.abc import Generator
   11: from collections.abc import Iterable
   12: from collections.abc import MutableMapping
   13: from collections.abc import Sequence
   14: from typing import Any
   15: from typing import Callable
   16: from typing import TypeVar
   17: 
   18: from pre_commit import parse_shebang
   19: from pre_commit.util import cmd_output_b
   20: from pre_commit.util import cmd_output_p
   21: 
   22: TArg = TypeVar('TArg')
   23: TRet = TypeVar('TRet')
   24: 
   25: 
   26: def cpu_count() -> int:
   27:     try:
   28:         # On systems that support it, this will return a more accurate count of
   29:         # usable CPUs for the current process, which will take into account
   30:         # cgroup limits
   31:         return len(os.sched_getaffinity(0))
   32:     except AttributeError:
   33:         pass
   34: 
   35:     try:
   36:         return multiprocessing.cpu_count()
   37:     except NotImplementedError:
   38:         return 1
   39: 
   40: 
   41: def _environ_size(_env: MutableMapping[str, str] | None = None) -> int:
   42:     environ = _env if _env is not None else getattr(os, 'environb', os.environ)
   43:     size = 8 * len(environ)  # number of pointers in `envp`
   44:     for k, v in environ.items():
   45:         size += len(k) + len(v) + 2  # c strings in `envp`
   46:     return size
   47: 
   48: 
   49: def _get_platform_max_length() -> int:  # pragma: no cover (platform specific)
   50:     if os.name == 'posix':
   51:         maximum = os.sysconf('SC_ARG_MAX') - 2048 - _environ_size()
   52:         maximum = max(min(maximum, 2 ** 17), 2 ** 12)
   53:         return maximum
   54:     elif os.name == 'nt':
   55:         return 2 ** 15 - 2048  # UNICODE_STRING max - headroom
   56:     else:
   57:         # posix minimum
   58:         return 2 ** 12
   59: 
   60: 
   61: def _command_length(*cmd: str) -> int:
   62:     full_cmd = ' '.join(cmd)
   63: 
   64:     # win32 uses the amount of characters, more details at:
   65:     # https://github.com/pre-commit/pre-commit/pull/839
   66:     if sys.platform == 'win32':
   67:         return len(full_cmd.encode('utf-16le')) // 2
   68:     else:
   69:         return len(full_cmd.encode(sys.getfilesystemencoding()))
   70: 
   71: 
   72: class ArgumentTooLongError(RuntimeError):
   73:     pass
   74: 
   75: 
   76: def partition(
   77:         cmd: Sequence[str],
   78:         varargs: Sequence[str],
   79:         target_concurrency: int,
   80:         _max_length: int | None = None,
   81: ) -> tuple[tuple[str, ...], ...]:
   82:     _max_length = _max_length or _get_platform_max_length()
   83: 
   84:     # Generally, we try to partition evenly into at least `target_concurrency`
   85:     # partitions, but we don't want a bunch of tiny partitions.
   86:     max_args = max(4, math.ceil(len(varargs) / target_concurrency))
   87: 
   88:     cmd = tuple(cmd)
   89:     ret = []
   90: 
   91:     ret_cmd: list[str] = []
   92:     # Reversed so arguments are in order
   93:     varargs = list(reversed(varargs))
   94: 
   95:     total_length = _command_length(*cmd) + 1
   96:     while varargs:
   97:         arg = varargs.pop()
   98: 
   99:         arg_length = _command_length(arg) + 1
  100:         if (
  101:                 total_length + arg_length <= _max_length and
  102:                 len(ret_cmd) < max_args
  103:         ):
  104:             ret_cmd.append(arg)
  105:             total_length += arg_length
  106:         elif not ret_cmd:
  107:             raise ArgumentTooLongError(arg)
  108:         else:
  109:             # We've exceeded the length, yield a command
  110:             ret.append(cmd + tuple(ret_cmd))
  111:             ret_cmd = []
  112:             total_length = _command_length(*cmd) + 1
  113:             varargs.append(arg)
  114: 
  115:     ret.append(cmd + tuple(ret_cmd))
  116: 
  117:     return tuple(ret)
  118: 
  119: 
  120: @contextlib.contextmanager
  121: def _thread_mapper(maxsize: int) -> Generator[
  122:     Callable[[Callable[[TArg], TRet], Iterable[TArg]], Iterable[TRet]],
  123: ]:
  124:     if maxsize == 1:
  125:         yield map
  126:     else:
  127:         with concurrent.futures.ThreadPoolExecutor(maxsize) as ex:
  128:             yield ex.map
  129: 
  130: 
  131: def xargs(
  132:         cmd: tuple[str, ...],
  133:         varargs: Sequence[str],
  134:         *,
  135:         color: bool = False,
  136:         target_concurrency: int = 1,
  137:         _max_length: int = _get_platform_max_length(),
  138:         **kwargs: Any,
  139: ) -> tuple[int, bytes]:
  140:     """A simplified implementation of xargs.
  141: 
  142:     color: Make a pty if on a platform that supports it
  143:     target_concurrency: Target number of partitions to run concurrently
  144:     """
  145:     cmd_fn = cmd_output_p if color else cmd_output_b
  146:     retcode = 0
  147:     stdout = b''
  148: 
  149:     try:
  150:         cmd = parse_shebang.normalize_cmd(cmd)
  151:     except parse_shebang.ExecutableNotFoundError as e:
  152:         return e.to_output()[:2]
  153: 
  154:     # on windows, batch files have a separate length limit than windows itself
  155:     if (
  156:             sys.platform == 'win32' and
  157:             cmd[0].lower().endswith(('.bat', '.cmd'))
  158:     ):  # pragma: win32 cover
  159:         # this is implementation details but the command gets translated into
  160:         # full/path/to/cmd.exe /c *cmd
  161:         cmd_exe = parse_shebang.find_executable('cmd.exe')
  162:         # 1024 is additionally subtracted to give headroom for further
  163:         # expansion inside the batch file
  164:         _max_length = 8192 - len(cmd_exe) - len(' /c ') - 1024
  165: 
  166:     partitions = partition(cmd, varargs, target_concurrency, _max_length)
  167: 
  168:     def run_cmd_partition(
  169:             run_cmd: tuple[str, ...],
  170:     ) -> tuple[int, bytes, bytes | None]:
  171:         return cmd_fn(
  172:             *run_cmd, check=False, stderr=subprocess.STDOUT, **kwargs,
  173:         )
  174: 
  175:     threads = min(len(partitions), target_concurrency)
  176:     with _thread_mapper(threads) as thread_map:
  177:         results = thread_map(run_cmd_partition, partitions)
  178: 
  179:         for proc_retcode, proc_out, _ in results:
  180:             if abs(proc_retcode) > abs(retcode):
  181:                 retcode = proc_retcode
  182:             stdout += proc_out
  183: 
  184:     return retcode, stdout
