    1: import warnings
    2: 
    3: from collections import Counter, defaultdict, deque, abc
    4: from collections.abc import Sequence
    5: from functools import partial, reduce, wraps
    6: from heapq import merge, heapify, heapreplace, heappop
    7: from itertools import (
    8:     chain,
    9:     compress,
   10:     count,
   11:     cycle,
   12:     dropwhile,
   13:     groupby,
   14:     islice,
   15:     repeat,
   16:     starmap,
   17:     takewhile,
   18:     tee,
   19:     zip_longest,
   20: )
   21: from math import exp, factorial, floor, log
   22: from queue import Empty, Queue
   23: from random import random, randrange, uniform
   24: from operator import itemgetter, mul, sub, gt, lt, ge, le
   25: from sys import hexversion, maxsize
   26: from time import monotonic
   27: 
   28: from .recipes import (
   29:     consume,
   30:     flatten,
   31:     pairwise,
   32:     powerset,
   33:     take,
   34:     unique_everseen,
   35: )
   36: 
   37: __all__ = [
   38:     'AbortThread',
   39:     'SequenceView',
   40:     'UnequalIterablesError',
   41:     'adjacent',
   42:     'all_unique',
   43:     'always_iterable',
   44:     'always_reversible',
   45:     'bucket',
   46:     'callback_iter',
   47:     'chunked',
   48:     'chunked_even',
   49:     'circular_shifts',
   50:     'collapse',
   51:     'collate',
   52:     'combination_index',
   53:     'consecutive_groups',
   54:     'consumer',
   55:     'count_cycle',
   56:     'countable',
   57:     'difference',
   58:     'distinct_combinations',
   59:     'distinct_permutations',
   60:     'distribute',
   61:     'divide',
   62:     'duplicates_everseen',
   63:     'duplicates_justseen',
   64:     'exactly_n',
   65:     'filter_except',
   66:     'first',
   67:     'groupby_transform',
   68:     'ichunked',
   69:     'ilen',
   70:     'interleave',
   71:     'interleave_evenly',
   72:     'interleave_longest',
   73:     'intersperse',
   74:     'is_sorted',
   75:     'islice_extended',
   76:     'iterate',
   77:     'last',
   78:     'locate',
   79:     'lstrip',
   80:     'make_decorator',
   81:     'map_except',
   82:     'map_if',
   83:     'map_reduce',
   84:     'mark_ends',
   85:     'minmax',
   86:     'nth_or_last',
   87:     'nth_permutation',
   88:     'nth_product',
   89:     'numeric_range',
   90:     'one',
   91:     'only',
   92:     'padded',
   93:     'partitions',
   94:     'peekable',
   95:     'permutation_index',
   96:     'product_index',
   97:     'raise_',
   98:     'repeat_each',
   99:     'repeat_last',
  100:     'replace',
  101:     'rlocate',
  102:     'rstrip',
  103:     'run_length',
  104:     'sample',
  105:     'seekable',
  106:     'set_partitions',
  107:     'side_effect',
  108:     'sliced',
  109:     'sort_together',
  110:     'split_after',
  111:     'split_at',
  112:     'split_before',
  113:     'split_into',
  114:     'split_when',
  115:     'spy',
  116:     'stagger',
  117:     'strip',
  118:     'strictly_n',
  119:     'substrings',
  120:     'substrings_indexes',
  121:     'time_limited',
  122:     'unique_in_window',
  123:     'unique_to_each',
  124:     'unzip',
  125:     'value_chain',
  126:     'windowed',
  127:     'windowed_complete',
  128:     'with_iter',
  129:     'zip_broadcast',
  130:     'zip_equal',
  131:     'zip_offset',
  132: ]
  133: 
  134: 
  135: _marker = object()
  136: 
  137: 
  138: def chunked(iterable, n, strict=False):
  139:     """Break *iterable* into lists of length *n*:
  140: 
  141:         >>> list(chunked([1, 2, 3, 4, 5, 6], 3))
  142:         [[1, 2, 3], [4, 5, 6]]
  143: 
  144:     By the default, the last yielded list will have fewer than *n* elements
  145:     if the length of *iterable* is not divisible by *n*:
  146: 
  147:         >>> list(chunked([1, 2, 3, 4, 5, 6, 7, 8], 3))
  148:         [[1, 2, 3], [4, 5, 6], [7, 8]]
  149: 
  150:     To use a fill-in value instead, see the :func:`grouper` recipe.
  151: 
  152:     If the length of *iterable* is not divisible by *n* and *strict* is
  153:     ``True``, then ``ValueError`` will be raised before the last
  154:     list is yielded.
  155: 
  156:     """
  157:     iterator = iter(partial(take, n, iter(iterable)), [])
  158:     if strict:
  159:         if n is None:
  160:             raise ValueError('n must not be None when using strict mode.')
  161: 
  162:         def ret():
  163:             for chunk in iterator:
  164:                 if len(chunk) != n:
  165:                     raise ValueError('iterable is not divisible by n.')
  166:                 yield chunk
  167: 
  168:         return iter(ret())
  169:     else:
  170:         return iterator
  171: 
  172: 
  173: def first(iterable, default=_marker):
  174:     """Return the first item of *iterable*, or *default* if *iterable* is
  175:     empty.
  176: 
  177:         >>> first([0, 1, 2, 3])
  178:         0
  179:         >>> first([], 'some default')
  180:         'some default'
  181: 
  182:     If *default* is not provided and there are no items in the iterable,
  183:     raise ``ValueError``.
  184: 
  185:     :func:`first` is useful when you have a generator of expensive-to-retrieve
  186:     values and want any arbitrary one. It is marginally shorter than
  187:     ``next(iter(iterable), default)``.
  188: 
  189:     """
  190:     try:
  191:         return next(iter(iterable))
  192:     except StopIteration as e:
  193:         if default is _marker:
  194:             raise ValueError(
  195:                 'first() was called on an empty iterable, and no '
  196:                 'default value was provided.'
  197:             ) from e
  198:         return default
  199: 
  200: 
  201: def last(iterable, default=_marker):
  202:     """Return the last item of *iterable*, or *default* if *iterable* is
  203:     empty.
  204: 
  205:         >>> last([0, 1, 2, 3])
  206:         3
  207:         >>> last([], 'some default')
  208:         'some default'
  209: 
  210:     If *default* is not provided and there are no items in the iterable,
  211:     raise ``ValueError``.
  212:     """
  213:     try:
  214:         if isinstance(iterable, Sequence):
  215:             return iterable[-1]
  216:         # Work around https://bugs.python.org/issue38525
  217:         elif hasattr(iterable, '__reversed__') and (hexversion != 0x030800F0):
  218:             return next(reversed(iterable))
  219:         else:
  220:             return deque(iterable, maxlen=1)[-1]
  221:     except (IndexError, TypeError, StopIteration):
  222:         if default is _marker:
  223:             raise ValueError(
  224:                 'last() was called on an empty iterable, and no default was '
  225:                 'provided.'
  226:             )
  227:         return default
  228: 
  229: 
  230: def nth_or_last(iterable, n, default=_marker):
  231:     """Return the nth or the last item of *iterable*,
  232:     or *default* if *iterable* is empty.
  233: 
  234:         >>> nth_or_last([0, 1, 2, 3], 2)
  235:         2
  236:         >>> nth_or_last([0, 1], 2)
  237:         1
  238:         >>> nth_or_last([], 0, 'some default')
  239:         'some default'
  240: 
  241:     If *default* is not provided and there are no items in the iterable,
  242:     raise ``ValueError``.
  243:     """
  244:     return last(islice(iterable, n + 1), default=default)
  245: 
  246: 
  247: class peekable:
  248:     """Wrap an iterator to allow lookahead and prepending elements.
  249: 
  250:     Call :meth:`peek` on the result to get the value that will be returned
  251:     by :func:`next`. This won't advance the iterator:
  252: 
  253:         >>> p = peekable(['a', 'b'])
  254:         >>> p.peek()
  255:         'a'
  256:         >>> next(p)
  257:         'a'
  258: 
  259:     Pass :meth:`peek` a default value to return that instead of raising
  260:     ``StopIteration`` when the iterator is exhausted.
  261: 
  262:         >>> p = peekable([])
  263:         >>> p.peek('hi')
  264:         'hi'
  265: 
  266:     peekables also offer a :meth:`prepend` method, which "inserts" items
  267:     at the head of the iterable:
  268: 
  269:         >>> p = peekable([1, 2, 3])
  270:         >>> p.prepend(10, 11, 12)
  271:         >>> next(p)
  272:         10
  273:         >>> p.peek()
  274:         11
  275:         >>> list(p)
  276:         [11, 12, 1, 2, 3]
  277: 
  278:     peekables can be indexed. Index 0 is the item that will be returned by
  279:     :func:`next`, index 1 is the item after that, and so on:
  280:     The values up to the given index will be cached.
  281: 
  282:         >>> p = peekable(['a', 'b', 'c', 'd'])
  283:         >>> p[0]
  284:         'a'
  285:         >>> p[1]
  286:         'b'
  287:         >>> next(p)
  288:         'a'
  289: 
  290:     Negative indexes are supported, but be aware that they will cache the
  291:     remaining items in the source iterator, which may require significant
  292:     storage.
  293: 
  294:     To check whether a peekable is exhausted, check its truth value:
  295: 
  296:         >>> p = peekable(['a', 'b'])
  297:         >>> if p:  # peekable has items
  298:         ...     list(p)
  299:         ['a', 'b']
  300:         >>> if not p:  # peekable is exhausted
  301:         ...     list(p)
  302:         []
  303: 
  304:     """
  305: 
  306:     def __init__(self, iterable):
  307:         self._it = iter(iterable)
  308:         self._cache = deque()
  309: 
  310:     def __iter__(self):
  311:         return self
  312: 
  313:     def __bool__(self):
  314:         try:
  315:             self.peek()
  316:         except StopIteration:
  317:             return False
  318:         return True
  319: 
  320:     def peek(self, default=_marker):
  321:         """Return the item that will be next returned from ``next()``.
  322: 
  323:         Return ``default`` if there are no items left. If ``default`` is not
  324:         provided, raise ``StopIteration``.
  325: 
  326:         """
  327:         if not self._cache:
  328:             try:
  329:                 self._cache.append(next(self._it))
  330:             except StopIteration:
  331:                 if default is _marker:
  332:                     raise
  333:                 return default
  334:         return self._cache[0]
  335: 
  336:     def prepend(self, *items):
  337:         """Stack up items to be the next ones returned from ``next()`` or
  338:         ``self.peek()``. The items will be returned in
  339:         first in, first out order::
  340: 
  341:             >>> p = peekable([1, 2, 3])
  342:             >>> p.prepend(10, 11, 12)
  343:             >>> next(p)
  344:             10
  345:             >>> list(p)
  346:             [11, 12, 1, 2, 3]
  347: 
  348:         It is possible, by prepending items, to "resurrect" a peekable that
  349:         previously raised ``StopIteration``.
  350: 
  351:             >>> p = peekable([])
  352:             >>> next(p)
  353:             Traceback (most recent call last):
  354:               ...
  355:             StopIteration
  356:             >>> p.prepend(1)
  357:             >>> next(p)
  358:             1
  359:             >>> next(p)
  360:             Traceback (most recent call last):
  361:               ...
  362:             StopIteration
  363: 
  364:         """
  365:         self._cache.extendleft(reversed(items))
  366: 
  367:     def __next__(self):
  368:         if self._cache:
  369:             return self._cache.popleft()
  370: 
  371:         return next(self._it)
  372: 
  373:     def _get_slice(self, index):
  374:         # Normalize the slice's arguments
  375:         step = 1 if (index.step is None) else index.step
  376:         if step > 0:
  377:             start = 0 if (index.start is None) else index.start
  378:             stop = maxsize if (index.stop is None) else index.stop
  379:         elif step < 0:
  380:             start = -1 if (index.start is None) else index.start
  381:             stop = (-maxsize - 1) if (index.stop is None) else index.stop
  382:         else:
  383:             raise ValueError('slice step cannot be zero')
  384: 
  385:         # If either the start or stop index is negative, we'll need to cache
  386:         # the rest of the iterable in order to slice from the right side.
  387:         if (start < 0) or (stop < 0):
  388:             self._cache.extend(self._it)
  389:         # Otherwise we'll need to find the rightmost index and cache to that
  390:         # point.
  391:         else:
  392:             n = min(max(start, stop) + 1, maxsize)
  393:             cache_len = len(self._cache)
  394:             if n >= cache_len:
  395:                 self._cache.extend(islice(self._it, n - cache_len))
  396: 
  397:         return list(self._cache)[index]
  398: 
  399:     def __getitem__(self, index):
  400:         if isinstance(index, slice):
  401:             return self._get_slice(index)
  402: 
  403:         cache_len = len(self._cache)
  404:         if index < 0:
  405:             self._cache.extend(self._it)
  406:         elif index >= cache_len:
  407:             self._cache.extend(islice(self._it, index + 1 - cache_len))
  408: 
  409:         return self._cache[index]
  410: 
  411: 
  412: def collate(*iterables, **kwargs):
  413:     """Return a sorted merge of the items from each of several already-sorted
  414:     *iterables*.
  415: 
  416:         >>> list(collate('ACDZ', 'AZ', 'JKL'))
  417:         ['A', 'A', 'C', 'D', 'J', 'K', 'L', 'Z', 'Z']
  418: 
  419:     Works lazily, keeping only the next value from each iterable in memory. Use
  420:     :func:`collate` to, for example, perform a n-way mergesort of items that
  421:     don't fit in memory.
  422: 
  423:     If a *key* function is specified, the iterables will be sorted according
  424:     to its result:
  425: 
  426:         >>> key = lambda s: int(s)  # Sort by numeric value, not by string
  427:         >>> list(collate(['1', '10'], ['2', '11'], key=key))
  428:         ['1', '2', '10', '11']
  429: 
  430: 
  431:     If the *iterables* are sorted in descending order, set *reverse* to
  432:     ``True``:
  433: 
  434:         >>> list(collate([5, 3, 1], [4, 2, 0], reverse=True))
  435:         [5, 4, 3, 2, 1, 0]
  436: 
  437:     If the elements of the passed-in iterables are out of order, you might get
  438:     unexpected results.
  439: 
  440:     On Python 3.5+, this function is an alias for :func:`heapq.merge`.
  441: 
  442:     """
  443:     warnings.warn(
  444:         "collate is no longer part of more_itertools, use heapq.merge",
  445:         DeprecationWarning,
  446:     )
  447:     return merge(*iterables, **kwargs)
  448: 
  449: 
  450: def consumer(func):
  451:     """Decorator that automatically advances a PEP-342-style "reverse iterator"
  452:     to its first yield point so you don't have to call ``next()`` on it
  453:     manually.
  454: 
  455:         >>> @consumer
  456:         ... def tally():
  457:         ...     i = 0
  458:         ...     while True:
  459:         ...         print('Thing number %s is %s.' % (i, (yield)))
  460:         ...         i += 1
  461:         ...
  462:         >>> t = tally()
  463:         >>> t.send('red')
  464:         Thing number 0 is red.
  465:         >>> t.send('fish')
  466:         Thing number 1 is fish.
  467: 
  468:     Without the decorator, you would have to call ``next(t)`` before
  469:     ``t.send()`` could be used.
  470: 
  471:     """
  472: 
  473:     @wraps(func)
  474:     def wrapper(*args, **kwargs):
  475:         gen = func(*args, **kwargs)
  476:         next(gen)
  477:         return gen
  478: 
  479:     return wrapper
  480: 
  481: 
  482: def ilen(iterable):
  483:     """Return the number of items in *iterable*.
  484: 
  485:         >>> ilen(x for x in range(1000000) if x % 3 == 0)
  486:         333334
  487: 
  488:     This consumes the iterable, so handle with care.
  489: 
  490:     """
  491:     # This approach was selected because benchmarks showed it's likely the
  492:     # fastest of the known implementations at the time of writing.
  493:     # See GitHub tracker: #236, #230.
  494:     counter = count()
  495:     deque(zip(iterable, counter), maxlen=0)
  496:     return next(counter)
  497: 
  498: 
  499: def iterate(func, start):
  500:     """Return ``start``, ``func(start)``, ``func(func(start))``, ...
  501: 
  502:     >>> from itertools import islice
  503:     >>> list(islice(iterate(lambda x: 2*x, 1), 10))
  504:     [1, 2, 4, 8, 16, 32, 64, 128, 256, 512]
  505: 
  506:     """
  507:     while True:
  508:         yield start
  509:         start = func(start)
  510: 
  511: 
  512: def with_iter(context_manager):
  513:     """Wrap an iterable in a ``with`` statement, so it closes once exhausted.
  514: 
  515:     For example, this will close the file when the iterator is exhausted::
  516: 
  517:         upper_lines = (line.upper() for line in with_iter(open('foo')))
  518: 
  519:     Any context manager which returns an iterable is a candidate for
  520:     ``with_iter``.
  521: 
  522:     """
  523:     with context_manager as iterable:
  524:         yield from iterable
  525: 
  526: 
  527: def one(iterable, too_short=None, too_long=None):
  528:     """Return the first item from *iterable*, which is expected to contain only
  529:     that item. Raise an exception if *iterable* is empty or has more than one
  530:     item.
  531: 
  532:     :func:`one` is useful for ensuring that an iterable contains only one item.
  533:     For example, it can be used to retrieve the result of a database query
  534:     that is expected to return a single row.
  535: 
  536:     If *iterable* is empty, ``ValueError`` will be raised. You may specify a
  537:     different exception with the *too_short* keyword:
  538: 
  539:         >>> it = []
  540:         >>> one(it)  # doctest: +IGNORE_EXCEPTION_DETAIL
  541:         Traceback (most recent call last):
  542:         ...
  543:         ValueError: too many items in iterable (expected 1)'
  544:         >>> too_short = IndexError('too few items')
  545:         >>> one(it, too_short=too_short)  # doctest: +IGNORE_EXCEPTION_DETAIL
  546:         Traceback (most recent call last):
  547:         ...
  548:         IndexError: too few items
  549: 
  550:     Similarly, if *iterable* contains more than one item, ``ValueError`` will
  551:     be raised. You may specify a different exception with the *too_long*
  552:     keyword:
  553: 
  554:         >>> it = ['too', 'many']
  555:         >>> one(it)  # doctest: +IGNORE_EXCEPTION_DETAIL
  556:         Traceback (most recent call last):
  557:         ...
  558:         ValueError: Expected exactly one item in iterable, but got 'too',
  559:         'many', and perhaps more.
  560:         >>> too_long = RuntimeError
  561:         >>> one(it, too_long=too_long)  # doctest: +IGNORE_EXCEPTION_DETAIL
  562:         Traceback (most recent call last):
  563:         ...
  564:         RuntimeError
  565: 
  566:     Note that :func:`one` attempts to advance *iterable* twice to ensure there
  567:     is only one item. See :func:`spy` or :func:`peekable` to check iterable
  568:     contents less destructively.
  569: 
  570:     """
  571:     it = iter(iterable)
  572: 
  573:     try:
  574:         first_value = next(it)
  575:     except StopIteration as e:
  576:         raise (
  577:             too_short or ValueError('too few items in iterable (expected 1)')
  578:         ) from e
  579: 
  580:     try:
  581:         second_value = next(it)
  582:     except StopIteration:
  583:         pass
  584:     else:
  585:         msg = (
  586:             'Expected exactly one item in iterable, but got {!r}, {!r}, '
  587:             'and perhaps more.'.format(first_value, second_value)
  588:         )
  589:         raise too_long or ValueError(msg)
  590: 
  591:     return first_value
  592: 
  593: 
  594: def raise_(exception, *args):
  595:     raise exception(*args)
  596: 
  597: 
  598: def strictly_n(iterable, n, too_short=None, too_long=None):
  599:     """Validate that *iterable* has exactly *n* items and return them if
  600:     it does. If it has fewer than *n* items, call function *too_short*
  601:     with those items. If it has more than *n* items, call function
  602:     *too_long* with the first ``n + 1`` items.
  603: 
  604:         >>> iterable = ['a', 'b', 'c', 'd']
  605:         >>> n = 4
  606:         >>> list(strictly_n(iterable, n))
  607:         ['a', 'b', 'c', 'd']
  608: 
  609:     By default, *too_short* and *too_long* are functions that raise
  610:     ``ValueError``.
  611: 
  612:         >>> list(strictly_n('ab', 3))  # doctest: +IGNORE_EXCEPTION_DETAIL
  613:         Traceback (most recent call last):
  614:         ...
  615:         ValueError: too few items in iterable (got 2)
  616: 
  617:         >>> list(strictly_n('abc', 2))  # doctest: +IGNORE_EXCEPTION_DETAIL
  618:         Traceback (most recent call last):
  619:         ...
  620:         ValueError: too many items in iterable (got at least 3)
  621: 
  622:     You can instead supply functions that do something else.
  623:     *too_short* will be called with the number of items in *iterable*.
  624:     *too_long* will be called with `n + 1`.
  625: 
  626:         >>> def too_short(item_count):
  627:         ...     raise RuntimeError
  628:         >>> it = strictly_n('abcd', 6, too_short=too_short)
  629:         >>> list(it)  # doctest: +IGNORE_EXCEPTION_DETAIL
  630:         Traceback (most recent call last):
  631:         ...
  632:         RuntimeError
  633: 
  634:         >>> def too_long(item_count):
  635:         ...     print('The boss is going to hear about this')
  636:         >>> it = strictly_n('abcdef', 4, too_long=too_long)
  637:         >>> list(it)
  638:         The boss is going to hear about this
  639:         ['a', 'b', 'c', 'd']
  640: 
  641:     """
  642:     if too_short is None:
  643:         too_short = lambda item_count: raise_(
  644:             ValueError,
  645:             'Too few items in iterable (got {})'.format(item_count),
  646:         )
  647: 
  648:     if too_long is None:
  649:         too_long = lambda item_count: raise_(
  650:             ValueError,
  651:             'Too many items in iterable (got at least {})'.format(item_count),
  652:         )
  653: 
  654:     it = iter(iterable)
  655:     for i in range(n):
  656:         try:
  657:             item = next(it)
  658:         except StopIteration:
  659:             too_short(i)
  660:             return
  661:         else:
  662:             yield item
  663: 
  664:     try:
  665:         next(it)
  666:     except StopIteration:
  667:         pass
  668:     else:
  669:         too_long(n + 1)
  670: 
  671: 
  672: def distinct_permutations(iterable, r=None):
  673:     """Yield successive distinct permutations of the elements in *iterable*.
  674: 
  675:         >>> sorted(distinct_permutations([1, 0, 1]))
  676:         [(0, 1, 1), (1, 0, 1), (1, 1, 0)]
  677: 
  678:     Equivalent to ``set(permutations(iterable))``, except duplicates are not
  679:     generated and thrown away. For larger input sequences this is much more
  680:     efficient.
  681: 
  682:     Duplicate permutations arise when there are duplicated elements in the
  683:     input iterable. The number of items returned is
  684:     `n! / (x_1! * x_2! * ... * x_n!)`, where `n` is the total number of
  685:     items input, and each `x_i` is the count of a distinct item in the input
  686:     sequence.
  687: 
  688:     If *r* is given, only the *r*-length permutations are yielded.
  689: 
  690:         >>> sorted(distinct_permutations([1, 0, 1], r=2))
  691:         [(0, 1), (1, 0), (1, 1)]
  692:         >>> sorted(distinct_permutations(range(3), r=2))
  693:         [(0, 1), (0, 2), (1, 0), (1, 2), (2, 0), (2, 1)]
  694: 
  695:     """
  696:     # Algorithm: https://w.wiki/Qai
  697:     def _full(A):
  698:         while True:
  699:             # Yield the permutation we have
  700:             yield tuple(A)
  701: 
  702:             # Find the largest index i such that A[i] < A[i + 1]
  703:             for i in range(size - 2, -1, -1):
  704:                 if A[i] < A[i + 1]:
  705:                     break
  706:             #  If no such index exists, this permutation is the last one
  707:             else:
  708:                 return
  709: 
  710:             # Find the largest index j greater than j such that A[i] < A[j]
  711:             for j in range(size - 1, i, -1):
  712:                 if A[i] < A[j]:
  713:                     break
  714: 
  715:             # Swap the value of A[i] with that of A[j], then reverse the
  716:             # sequence from A[i + 1] to form the new permutation
  717:             A[i], A[j] = A[j], A[i]
  718:             A[i + 1 :] = A[: i - size : -1]  # A[i + 1:][::-1]
  719: 
  720:     # Algorithm: modified from the above
  721:     def _partial(A, r):
  722:         # Split A into the first r items and the last r items
  723:         head, tail = A[:r], A[r:]
  724:         right_head_indexes = range(r - 1, -1, -1)
  725:         left_tail_indexes = range(len(tail))
  726: 
  727:         while True:
  728:             # Yield the permutation we have
  729:             yield tuple(head)
  730: 
  731:             # Starting from the right, find the first index of the head with
  732:             # value smaller than the maximum value of the tail - call it i.
  733:             pivot = tail[-1]
  734:             for i in right_head_indexes:
  735:                 if head[i] < pivot:
  736:                     break
  737:                 pivot = head[i]
  738:             else:
  739:                 return
  740: 
  741:             # Starting from the left, find the first value of the tail
  742:             # with a value greater than head[i] and swap.
  743:             for j in left_tail_indexes:
  744:                 if tail[j] > head[i]:
  745:                     head[i], tail[j] = tail[j], head[i]
  746:                     break
  747:             # If we didn't find one, start from the right and find the first
  748:             # index of the head with a value greater than head[i] and swap.
  749:             else:
  750:                 for j in right_head_indexes:
  751:                     if head[j] > head[i]:
  752:                         head[i], head[j] = head[j], head[i]
  753:                         break
  754: 
  755:             # Reverse head[i + 1:] and swap it with tail[:r - (i + 1)]
  756:             tail += head[: i - r : -1]  # head[i + 1:][::-1]
  757:             i += 1
  758:             head[i:], tail[:] = tail[: r - i], tail[r - i :]
  759: 
  760:     items = sorted(iterable)
  761: 
  762:     size = len(items)
  763:     if r is None:
  764:         r = size
  765: 
  766:     if 0 < r <= size:
  767:         return _full(items) if (r == size) else _partial(items, r)
  768: 
  769:     return iter(() if r else ((),))
  770: 
  771: 
  772: def intersperse(e, iterable, n=1):
  773:     """Intersperse filler element *e* among the items in *iterable*, leaving
  774:     *n* items between each filler element.
  775: 
  776:         >>> list(intersperse('!', [1, 2, 3, 4, 5]))
  777:         [1, '!', 2, '!', 3, '!', 4, '!', 5]
  778: 
  779:         >>> list(intersperse(None, [1, 2, 3, 4, 5], n=2))
  780:         [1, 2, None, 3, 4, None, 5]
  781: 
  782:     """
  783:     if n == 0:
  784:         raise ValueError('n must be > 0')
  785:     elif n == 1:
  786:         # interleave(repeat(e), iterable) -> e, x_0, e, x_1, e, x_2...
  787:         # islice(..., 1, None) -> x_0, e, x_1, e, x_2...
  788:         return islice(interleave(repeat(e), iterable), 1, None)
  789:     else:
  790:         # interleave(filler, chunks) -> [e], [x_0, x_1], [e], [x_2, x_3]...
  791:         # islice(..., 1, None) -> [x_0, x_1], [e], [x_2, x_3]...
  792:         # flatten(...) -> x_0, x_1, e, x_2, x_3...
  793:         filler = repeat([e])
  794:         chunks = chunked(iterable, n)
  795:         return flatten(islice(interleave(filler, chunks), 1, None))
  796: 
  797: 
  798: def unique_to_each(*iterables):
  799:     """Return the elements from each of the input iterables that aren't in the
  800:     other input iterables.
  801: 
  802:     For example, suppose you have a set of packages, each with a set of
  803:     dependencies::
  804: 
  805:         {'pkg_1': {'A', 'B'}, 'pkg_2': {'B', 'C'}, 'pkg_3': {'B', 'D'}}
  806: 
  807:     If you remove one package, which dependencies can also be removed?
  808: 
  809:     If ``pkg_1`` is removed, then ``A`` is no longer necessary - it is not
  810:     associated with ``pkg_2`` or ``pkg_3``. Similarly, ``C`` is only needed for
  811:     ``pkg_2``, and ``D`` is only needed for ``pkg_3``::
  812: 
  813:         >>> unique_to_each({'A', 'B'}, {'B', 'C'}, {'B', 'D'})
  814:         [['A'], ['C'], ['D']]
  815: 
  816:     If there are duplicates in one input iterable that aren't in the others
  817:     they will be duplicated in the output. Input order is preserved::
  818: 
  819:         >>> unique_to_each("mississippi", "missouri")
  820:         [['p', 'p'], ['o', 'u', 'r']]
  821: 
  822:     It is assumed that the elements of each iterable are hashable.
  823: 
  824:     """
  825:     pool = [list(it) for it in iterables]
  826:     counts = Counter(chain.from_iterable(map(set, pool)))
  827:     uniques = {element for element in counts if counts[element] == 1}
  828:     return [list(filter(uniques.__contains__, it)) for it in pool]
  829: 
  830: 
  831: def windowed(seq, n, fillvalue=None, step=1):
  832:     """Return a sliding window of width *n* over the given iterable.
  833: 
  834:         >>> all_windows = windowed([1, 2, 3, 4, 5], 3)
  835:         >>> list(all_windows)
  836:         [(1, 2, 3), (2, 3, 4), (3, 4, 5)]
  837: 
  838:     When the window is larger than the iterable, *fillvalue* is used in place
  839:     of missing values:
  840: 
  841:         >>> list(windowed([1, 2, 3], 4))
  842:         [(1, 2, 3, None)]
  843: 
  844:     Each window will advance in increments of *step*:
  845: 
  846:         >>> list(windowed([1, 2, 3, 4, 5, 6], 3, fillvalue='!', step=2))
  847:         [(1, 2, 3), (3, 4, 5), (5, 6, '!')]
  848: 
  849:     To slide into the iterable's items, use :func:`chain` to add filler items
  850:     to the left:
  851: 
  852:         >>> iterable = [1, 2, 3, 4]
  853:         >>> n = 3
  854:         >>> padding = [None] * (n - 1)
  855:         >>> list(windowed(chain(padding, iterable), 3))
  856:         [(None, None, 1), (None, 1, 2), (1, 2, 3), (2, 3, 4)]
  857:     """
  858:     if n < 0:
  859:         raise ValueError('n must be >= 0')
  860:     if n == 0:
  861:         yield tuple()
  862:         return
  863:     if step < 1:
  864:         raise ValueError('step must be >= 1')
  865: 
  866:     window = deque(maxlen=n)
  867:     i = n
  868:     for _ in map(window.append, seq):
  869:         i -= 1
  870:         if not i:
  871:             i = step
  872:             yield tuple(window)
  873: 
  874:     size = len(window)
  875:     if size < n:
  876:         yield tuple(chain(window, repeat(fillvalue, n - size)))
  877:     elif 0 < i < min(step, n):
  878:         window += (fillvalue,) * i
  879:         yield tuple(window)
  880: 
  881: 
  882: def substrings(iterable):
  883:     """Yield all of the substrings of *iterable*.
  884: 
  885:         >>> [''.join(s) for s in substrings('more')]
  886:         ['m', 'o', 'r', 'e', 'mo', 'or', 're', 'mor', 'ore', 'more']
  887: 
  888:     Note that non-string iterables can also be subdivided.
  889: 
  890:         >>> list(substrings([0, 1, 2]))
  891:         [(0,), (1,), (2,), (0, 1), (1, 2), (0, 1, 2)]
  892: 
  893:     """
  894:     # The length-1 substrings
  895:     seq = []
  896:     for item in iter(iterable):
  897:         seq.append(item)
  898:         yield (item,)
  899:     seq = tuple(seq)
  900:     item_count = len(seq)
  901: 
  902:     # And the rest
  903:     for n in range(2, item_count + 1):
  904:         for i in range(item_count - n + 1):
  905:             yield seq[i : i + n]
  906: 
  907: 
  908: def substrings_indexes(seq, reverse=False):
  909:     """Yield all substrings and their positions in *seq*
  910: 
  911:     The items yielded will be a tuple of the form ``(substr, i, j)``, where
  912:     ``substr == seq[i:j]``.
  913: 
  914:     This function only works for iterables that support slicing, such as
  915:     ``str`` objects.
  916: 
  917:     >>> for item in substrings_indexes('more'):
  918:     ...    print(item)
  919:     ('m', 0, 1)
  920:     ('o', 1, 2)
  921:     ('r', 2, 3)
  922:     ('e', 3, 4)
  923:     ('mo', 0, 2)
  924:     ('or', 1, 3)
  925:     ('re', 2, 4)
  926:     ('mor', 0, 3)
  927:     ('ore', 1, 4)
  928:     ('more', 0, 4)
  929: 
  930:     Set *reverse* to ``True`` to yield the same items in the opposite order.
  931: 
  932: 
  933:     """
  934:     r = range(1, len(seq) + 1)
  935:     if reverse:
  936:         r = reversed(r)
  937:     return (
  938:         (seq[i : i + L], i, i + L) for L in r for i in range(len(seq) - L + 1)
  939:     )
  940: 
  941: 
  942: class bucket:
  943:     """Wrap *iterable* and return an object that buckets it iterable into
  944:     child iterables based on a *key* function.
  945: 
  946:         >>> iterable = ['a1', 'b1', 'c1', 'a2', 'b2', 'c2', 'b3']
  947:         >>> s = bucket(iterable, key=lambda x: x[0])  # Bucket by 1st character
  948:         >>> sorted(list(s))  # Get the keys
  949:         ['a', 'b', 'c']
  950:         >>> a_iterable = s['a']
  951:         >>> next(a_iterable)
  952:         'a1'
  953:         >>> next(a_iterable)
  954:         'a2'
  955:         >>> list(s['b'])
  956:         ['b1', 'b2', 'b3']
  957: 
  958:     The original iterable will be advanced and its items will be cached until
  959:     they are used by the child iterables. This may require significant storage.
  960: 
  961:     By default, attempting to select a bucket to which no items belong  will
  962:     exhaust the iterable and cache all values.
  963:     If you specify a *validator* function, selected buckets will instead be
  964:     checked against it.
  965: 
  966:         >>> from itertools import count
  967:         >>> it = count(1, 2)  # Infinite sequence of odd numbers
  968:         >>> key = lambda x: x % 10  # Bucket by last digit
  969:         >>> validator = lambda x: x in {1, 3, 5, 7, 9}  # Odd digits only
  970:         >>> s = bucket(it, key=key, validator=validator)
  971:         >>> 2 in s
  972:         False
  973:         >>> list(s[2])
  974:         []
  975: 
  976:     """
  977: 
  978:     def __init__(self, iterable, key, validator=None):
  979:         self._it = iter(iterable)
  980:         self._key = key
  981:         self._cache = defaultdict(deque)
  982:         self._validator = validator or (lambda x: True)
  983: 
  984:     def __contains__(self, value):
  985:         if not self._validator(value):
  986:             return False
  987: 
  988:         try:
  989:             item = next(self[value])
  990:         except StopIteration:
  991:             return False
  992:         else:
  993:             self._cache[value].appendleft(item)
  994: 
  995:         return True
  996: 
  997:     def _get_values(self, value):
  998:         """
  999:         Helper to yield items from the parent iterator that match *value*.
 1000:         Items that don't match are stored in the local cache as they
 1001:         are encountered.
 1002:         """
 1003:         while True:
 1004:             # If we've cached some items that match the target value, emit
 1005:             # the first one and evict it from the cache.
 1006:             if self._cache[value]:
 1007:                 yield self._cache[value].popleft()
 1008:             # Otherwise we need to advance the parent iterator to search for
 1009:             # a matching item, caching the rest.
 1010:             else:
 1011:                 while True:
 1012:                     try:
 1013:                         item = next(self._it)
 1014:                     except StopIteration:
 1015:                         return
 1016:                     item_value = self._key(item)
 1017:                     if item_value == value:
 1018:                         yield item
 1019:                         break
 1020:                     elif self._validator(item_value):
 1021:                         self._cache[item_value].append(item)
 1022: 
 1023:     def __iter__(self):
 1024:         for item in self._it:
 1025:             item_value = self._key(item)
 1026:             if self._validator(item_value):
 1027:                 self._cache[item_value].append(item)
 1028: 
 1029:         yield from self._cache.keys()
 1030: 
 1031:     def __getitem__(self, value):
 1032:         if not self._validator(value):
 1033:             return iter(())
 1034: 
 1035:         return self._get_values(value)
 1036: 
 1037: 
 1038: def spy(iterable, n=1):
 1039:     """Return a 2-tuple with a list containing the first *n* elements of
 1040:     *iterable*, and an iterator with the same items as *iterable*.
 1041:     This allows you to "look ahead" at the items in the iterable without
 1042:     advancing it.
 1043: 
 1044:     There is one item in the list by default:
 1045: 
 1046:         >>> iterable = 'abcdefg'
 1047:         >>> head, iterable = spy(iterable)
 1048:         >>> head
 1049:         ['a']
 1050:         >>> list(iterable)
 1051:         ['a', 'b', 'c', 'd', 'e', 'f', 'g']
 1052: 
 1053:     You may use unpacking to retrieve items instead of lists:
 1054: 
 1055:         >>> (head,), iterable = spy('abcdefg')
 1056:         >>> head
 1057:         'a'
 1058:         >>> (first, second), iterable = spy('abcdefg', 2)
 1059:         >>> first
 1060:         'a'
 1061:         >>> second
 1062:         'b'
 1063: 
 1064:     The number of items requested can be larger than the number of items in
 1065:     the iterable:
 1066: 
 1067:         >>> iterable = [1, 2, 3, 4, 5]
 1068:         >>> head, iterable = spy(iterable, 10)
 1069:         >>> head
 1070:         [1, 2, 3, 4, 5]
 1071:         >>> list(iterable)
 1072:         [1, 2, 3, 4, 5]
 1073: 
 1074:     """
 1075:     it = iter(iterable)
 1076:     head = take(n, it)
 1077: 
 1078:     return head.copy(), chain(head, it)
 1079: 
 1080: 
 1081: def interleave(*iterables):
 1082:     """Return a new iterable yielding from each iterable in turn,
 1083:     until the shortest is exhausted.
 1084: 
 1085:         >>> list(interleave([1, 2, 3], [4, 5], [6, 7, 8]))
 1086:         [1, 4, 6, 2, 5, 7]
 1087: 
 1088:     For a version that doesn't terminate after the shortest iterable is
 1089:     exhausted, see :func:`interleave_longest`.
 1090: 
 1091:     """
 1092:     return chain.from_iterable(zip(*iterables))
 1093: 
 1094: 
 1095: def interleave_longest(*iterables):
 1096:     """Return a new iterable yielding from each iterable in turn,
 1097:     skipping any that are exhausted.
 1098: 
 1099:         >>> list(interleave_longest([1, 2, 3], [4, 5], [6, 7, 8]))
 1100:         [1, 4, 6, 2, 5, 7, 3, 8]
 1101: 
 1102:     This function produces the same output as :func:`roundrobin`, but may
 1103:     perform better for some inputs (in particular when the number of iterables
 1104:     is large).
 1105: 
 1106:     """
 1107:     i = chain.from_iterable(zip_longest(*iterables, fillvalue=_marker))
 1108:     return (x for x in i if x is not _marker)
 1109: 
 1110: 
 1111: def interleave_evenly(iterables, lengths=None):
 1112:     """
 1113:     Interleave multiple iterables so that their elements are evenly distributed
 1114:     throughout the output sequence.
 1115: 
 1116:     >>> iterables = [1, 2, 3, 4, 5], ['a', 'b']
 1117:     >>> list(interleave_evenly(iterables))
 1118:     [1, 2, 'a', 3, 4, 'b', 5]
 1119: 
 1120:     >>> iterables = [[1, 2, 3], [4, 5], [6, 7, 8]]
 1121:     >>> list(interleave_evenly(iterables))
 1122:     [1, 6, 4, 2, 7, 3, 8, 5]
 1123: 
 1124:     This function requires iterables of known length. Iterables without
 1125:     ``__len__()`` can be used by manually specifying lengths with *lengths*:
 1126: 
 1127:     >>> from itertools import combinations, repeat
 1128:     >>> iterables = [combinations(range(4), 2), ['a', 'b', 'c']]
 1129:     >>> lengths = [4 * (4 - 1) // 2, 3]
 1130:     >>> list(interleave_evenly(iterables, lengths=lengths))
 1131:     [(0, 1), (0, 2), 'a', (0, 3), (1, 2), 'b', (1, 3), (2, 3), 'c']
 1132: 
 1133:     Based on Bresenham's algorithm.
 1134:     """
 1135:     if lengths is None:
 1136:         try:
 1137:             lengths = [len(it) for it in iterables]
 1138:         except TypeError:
 1139:             raise ValueError(
 1140:                 'Iterable lengths could not be determined automatically. '
 1141:                 'Specify them with the lengths keyword.'
 1142:             )
 1143:     elif len(iterables) != len(lengths):
 1144:         raise ValueError('Mismatching number of iterables and lengths.')
 1145: 
 1146:     dims = len(lengths)
 1147: 
 1148:     # sort iterables by length, descending
 1149:     lengths_permute = sorted(
 1150:         range(dims), key=lambda i: lengths[i], reverse=True
 1151:     )
 1152:     lengths_desc = [lengths[i] for i in lengths_permute]
 1153:     iters_desc = [iter(iterables[i]) for i in lengths_permute]
 1154: 
 1155:     # the longest iterable is the primary one (Bresenham: the longest
 1156:     # distance along an axis)
 1157:     delta_primary, deltas_secondary = lengths_desc[0], lengths_desc[1:]
 1158:     iter_primary, iters_secondary = iters_desc[0], iters_desc[1:]
 1159:     errors = [delta_primary // dims] * len(deltas_secondary)
 1160: 
 1161:     to_yield = sum(lengths)
 1162:     while to_yield:
 1163:         yield next(iter_primary)
 1164:         to_yield -= 1
 1165:         # update errors for each secondary iterable
 1166:         errors = [e - delta for e, delta in zip(errors, deltas_secondary)]
 1167: 
 1168:         # those iterables for which the error is negative are yielded
 1169:         # ("diagonal step" in Bresenham)
 1170:         for i, e in enumerate(errors):
 1171:             if e < 0:
 1172:                 yield next(iters_secondary[i])
 1173:                 to_yield -= 1
 1174:                 errors[i] += delta_primary
 1175: 
 1176: 
 1177: def collapse(iterable, base_type=None, levels=None):
 1178:     """Flatten an iterable with multiple levels of nesting (e.g., a list of
 1179:     lists of tuples) into non-iterable types.
 1180: 
 1181:         >>> iterable = [(1, 2), ([3, 4], [[5], [6]])]
 1182:         >>> list(collapse(iterable))
 1183:         [1, 2, 3, 4, 5, 6]
 1184: 
 1185:     Binary and text strings are not considered iterable and
 1186:     will not be collapsed.
 1187: 
 1188:     To avoid collapsing other types, specify *base_type*:
 1189: 
 1190:         >>> iterable = ['ab', ('cd', 'ef'), ['gh', 'ij']]
 1191:         >>> list(collapse(iterable, base_type=tuple))
 1192:         ['ab', ('cd', 'ef'), 'gh', 'ij']
 1193: 
 1194:     Specify *levels* to stop flattening after a certain level:
 1195: 
 1196:     >>> iterable = [('a', ['b']), ('c', ['d'])]
 1197:     >>> list(collapse(iterable))  # Fully flattened
 1198:     ['a', 'b', 'c', 'd']
 1199:     >>> list(collapse(iterable, levels=1))  # Only one level flattened
 1200:     ['a', ['b'], 'c', ['d']]
 1201: 
 1202:     """
 1203: 
 1204:     def walk(node, level):
 1205:         if (
 1206:             ((levels is not None) and (level > levels))
 1207:             or isinstance(node, (str, bytes))
 1208:             or ((base_type is not None) and isinstance(node, base_type))
 1209:         ):
 1210:             yield node
 1211:             return
 1212: 
 1213:         try:
 1214:             tree = iter(node)
 1215:         except TypeError:
 1216:             yield node
 1217:             return
 1218:         else:
 1219:             for child in tree:
 1220:                 yield from walk(child, level + 1)
 1221: 
 1222:     yield from walk(iterable, 0)
 1223: 
 1224: 
 1225: def side_effect(func, iterable, chunk_size=None, before=None, after=None):
 1226:     """Invoke *func* on each item in *iterable* (or on each *chunk_size* group
 1227:     of items) before yielding the item.
 1228: 
 1229:     `func` must be a function that takes a single argument. Its return value
 1230:     will be discarded.
 1231: 
 1232:     *before* and *after* are optional functions that take no arguments. They
 1233:     will be executed before iteration starts and after it ends, respectively.
 1234: 
 1235:     `side_effect` can be used for logging, updating progress bars, or anything
 1236:     that is not functionally "pure."
 1237: 
 1238:     Emitting a status message:
 1239: 
 1240:         >>> from more_itertools import consume
 1241:         >>> func = lambda item: print('Received {}'.format(item))
 1242:         >>> consume(side_effect(func, range(2)))
 1243:         Received 0
 1244:         Received 1
 1245: 
 1246:     Operating on chunks of items:
 1247: 
 1248:         >>> pair_sums = []
 1249:         >>> func = lambda chunk: pair_sums.append(sum(chunk))
 1250:         >>> list(side_effect(func, [0, 1, 2, 3, 4, 5], 2))
 1251:         [0, 1, 2, 3, 4, 5]
 1252:         >>> list(pair_sums)
 1253:         [1, 5, 9]
 1254: 
 1255:     Writing to a file-like object:
 1256: 
 1257:         >>> from io import StringIO
 1258:         >>> from more_itertools import consume
 1259:         >>> f = StringIO()
 1260:         >>> func = lambda x: print(x, file=f)
 1261:         >>> before = lambda: print(u'HEADER', file=f)
 1262:         >>> after = f.close
 1263:         >>> it = [u'a', u'b', u'c']
 1264:         >>> consume(side_effect(func, it, before=before, after=after))
 1265:         >>> f.closed
 1266:         True
 1267: 
 1268:     """
 1269:     try:
 1270:         if before is not None:
 1271:             before()
 1272: 
 1273:         if chunk_size is None:
 1274:             for item in iterable:
 1275:                 func(item)
 1276:                 yield item
 1277:         else:
 1278:             for chunk in chunked(iterable, chunk_size):
 1279:                 func(chunk)
 1280:                 yield from chunk
 1281:     finally:
 1282:         if after is not None:
 1283:             after()
 1284: 
 1285: 
 1286: def sliced(seq, n, strict=False):
 1287:     """Yield slices of length *n* from the sequence *seq*.
 1288: 
 1289:     >>> list(sliced((1, 2, 3, 4, 5, 6), 3))
 1290:     [(1, 2, 3), (4, 5, 6)]
 1291: 
 1292:     By the default, the last yielded slice will have fewer than *n* elements
 1293:     if the length of *seq* is not divisible by *n*:
 1294: 
 1295:     >>> list(sliced((1, 2, 3, 4, 5, 6, 7, 8), 3))
 1296:     [(1, 2, 3), (4, 5, 6), (7, 8)]
 1297: 
 1298:     If the length of *seq* is not divisible by *n* and *strict* is
 1299:     ``True``, then ``ValueError`` will be raised before the last
 1300:     slice is yielded.
 1301: 
 1302:     This function will only work for iterables that support slicing.
 1303:     For non-sliceable iterables, see :func:`chunked`.
 1304: 
 1305:     """
 1306:     iterator = takewhile(len, (seq[i : i + n] for i in count(0, n)))
 1307:     if strict:
 1308: 
 1309:         def ret():
 1310:             for _slice in iterator:
 1311:                 if len(_slice) != n:
 1312:                     raise ValueError("seq is not divisible by n.")
 1313:                 yield _slice
 1314: 
 1315:         return iter(ret())
 1316:     else:
 1317:         return iterator
 1318: 
 1319: 
 1320: def split_at(iterable, pred, maxsplit=-1, keep_separator=False):
 1321:     """Yield lists of items from *iterable*, where each list is delimited by
 1322:     an item where callable *pred* returns ``True``.
 1323: 
 1324:         >>> list(split_at('abcdcba', lambda x: x == 'b'))
 1325:         [['a'], ['c', 'd', 'c'], ['a']]
 1326: 
 1327:         >>> list(split_at(range(10), lambda n: n % 2 == 1))
 1328:         [[0], [2], [4], [6], [8], []]
 1329: 
 1330:     At most *maxsplit* splits are done. If *maxsplit* is not specified or -1,
 1331:     then there is no limit on the number of splits:
 1332: 
 1333:         >>> list(split_at(range(10), lambda n: n % 2 == 1, maxsplit=2))
 1334:         [[0], [2], [4, 5, 6, 7, 8, 9]]
 1335: 
 1336:     By default, the delimiting items are not included in the output.
 1337:     The include them, set *keep_separator* to ``True``.
 1338: 
 1339:         >>> list(split_at('abcdcba', lambda x: x == 'b', keep_separator=True))
 1340:         [['a'], ['b'], ['c', 'd', 'c'], ['b'], ['a']]
 1341: 
 1342:     """
 1343:     if maxsplit == 0:
 1344:         yield list(iterable)
 1345:         return
 1346: 
 1347:     buf = []
 1348:     it = iter(iterable)
 1349:     for item in it:
 1350:         if pred(item):
 1351:             yield buf
 1352:             if keep_separator:
 1353:                 yield [item]
 1354:             if maxsplit == 1:
 1355:                 yield list(it)
 1356:                 return
 1357:             buf = []
 1358:             maxsplit -= 1
 1359:         else:
 1360:             buf.append(item)
 1361:     yield buf
 1362: 
 1363: 
 1364: def split_before(iterable, pred, maxsplit=-1):
 1365:     """Yield lists of items from *iterable*, where each list ends just before
 1366:     an item for which callable *pred* returns ``True``:
 1367: 
 1368:         >>> list(split_before('OneTwo', lambda s: s.isupper()))
 1369:         [['O', 'n', 'e'], ['T', 'w', 'o']]
 1370: 
 1371:         >>> list(split_before(range(10), lambda n: n % 3 == 0))
 1372:         [[0, 1, 2], [3, 4, 5], [6, 7, 8], [9]]
 1373: 
 1374:     At most *maxsplit* splits are done. If *maxsplit* is not specified or -1,
 1375:     then there is no limit on the number of splits:
 1376: 
 1377:         >>> list(split_before(range(10), lambda n: n % 3 == 0, maxsplit=2))
 1378:         [[0, 1, 2], [3, 4, 5], [6, 7, 8, 9]]
 1379:     """
 1380:     if maxsplit == 0:
 1381:         yield list(iterable)
 1382:         return
 1383: 
 1384:     buf = []
 1385:     it = iter(iterable)
 1386:     for item in it:
 1387:         if pred(item) and buf:
 1388:             yield buf
 1389:             if maxsplit == 1:
 1390:                 yield [item] + list(it)
 1391:                 return
 1392:             buf = []
 1393:             maxsplit -= 1
 1394:         buf.append(item)
 1395:     if buf:
 1396:         yield buf
 1397: 
 1398: 
 1399: def split_after(iterable, pred, maxsplit=-1):
 1400:     """Yield lists of items from *iterable*, where each list ends with an
 1401:     item where callable *pred* returns ``True``:
 1402: 
 1403:         >>> list(split_after('one1two2', lambda s: s.isdigit()))
 1404:         [['o', 'n', 'e', '1'], ['t', 'w', 'o', '2']]
 1405: 
 1406:         >>> list(split_after(range(10), lambda n: n % 3 == 0))
 1407:         [[0], [1, 2, 3], [4, 5, 6], [7, 8, 9]]
 1408: 
 1409:     At most *maxsplit* splits are done. If *maxsplit* is not specified or -1,
 1410:     then there is no limit on the number of splits:
 1411: 
 1412:         >>> list(split_after(range(10), lambda n: n % 3 == 0, maxsplit=2))
 1413:         [[0], [1, 2, 3], [4, 5, 6, 7, 8, 9]]
 1414: 
 1415:     """
 1416:     if maxsplit == 0:
 1417:         yield list(iterable)
 1418:         return
 1419: 
 1420:     buf = []
 1421:     it = iter(iterable)
 1422:     for item in it:
 1423:         buf.append(item)
 1424:         if pred(item) and buf:
 1425:             yield buf
 1426:             if maxsplit == 1:
 1427:                 yield list(it)
 1428:                 return
 1429:             buf = []
 1430:             maxsplit -= 1
 1431:     if buf:
 1432:         yield buf
 1433: 
 1434: 
 1435: def split_when(iterable, pred, maxsplit=-1):
 1436:     """Split *iterable* into pieces based on the output of *pred*.
 1437:     *pred* should be a function that takes successive pairs of items and
 1438:     returns ``True`` if the iterable should be split in between them.
 1439: 
 1440:     For example, to find runs of increasing numbers, split the iterable when
 1441:     element ``i`` is larger than element ``i + 1``:
 1442: 
 1443:         >>> list(split_when([1, 2, 3, 3, 2, 5, 2, 4, 2], lambda x, y: x > y))
 1444:         [[1, 2, 3, 3], [2, 5], [2, 4], [2]]
 1445: 
 1446:     At most *maxsplit* splits are done. If *maxsplit* is not specified or -1,
 1447:     then there is no limit on the number of splits:
 1448: 
 1449:         >>> list(split_when([1, 2, 3, 3, 2, 5, 2, 4, 2],
 1450:         ...                 lambda x, y: x > y, maxsplit=2))
 1451:         [[1, 2, 3, 3], [2, 5], [2, 4, 2]]
 1452: 
 1453:     """
 1454:     if maxsplit == 0:
 1455:         yield list(iterable)
 1456:         return
 1457: 
 1458:     it = iter(iterable)
 1459:     try:
 1460:         cur_item = next(it)
 1461:     except StopIteration:
 1462:         return
 1463: 
 1464:     buf = [cur_item]
 1465:     for next_item in it:
 1466:         if pred(cur_item, next_item):
 1467:             yield buf
 1468:             if maxsplit == 1:
 1469:                 yield [next_item] + list(it)
 1470:                 return
 1471:             buf = []
 1472:             maxsplit -= 1
 1473: 
 1474:         buf.append(next_item)
 1475:         cur_item = next_item
 1476: 
 1477:     yield buf
 1478: 
 1479: 
 1480: def split_into(iterable, sizes):
 1481:     """Yield a list of sequential items from *iterable* of length 'n' for each
 1482:     integer 'n' in *sizes*.
 1483: 
 1484:         >>> list(split_into([1,2,3,4,5,6], [1,2,3]))
 1485:         [[1], [2, 3], [4, 5, 6]]
 1486: 
 1487:     If the sum of *sizes* is smaller than the length of *iterable*, then the
 1488:     remaining items of *iterable* will not be returned.
 1489: 
 1490:         >>> list(split_into([1,2,3,4,5,6], [2,3]))
 1491:         [[1, 2], [3, 4, 5]]
 1492: 
 1493:     If the sum of *sizes* is larger than the length of *iterable*, fewer items
 1494:     will be returned in the iteration that overruns *iterable* and further
 1495:     lists will be empty:
 1496: 
 1497:         >>> list(split_into([1,2,3,4], [1,2,3,4]))
 1498:         [[1], [2, 3], [4], []]
 1499: 
 1500:     When a ``None`` object is encountered in *sizes*, the returned list will
 1501:     contain items up to the end of *iterable* the same way that itertools.slice
 1502:     does:
 1503: 
 1504:         >>> list(split_into([1,2,3,4,5,6,7,8,9,0], [2,3,None]))
 1505:         [[1, 2], [3, 4, 5], [6, 7, 8, 9, 0]]
 1506: 
 1507:     :func:`split_into` can be useful for grouping a series of items where the
 1508:     sizes of the groups are not uniform. An example would be where in a row
 1509:     from a table, multiple columns represent elements of the same feature
 1510:     (e.g. a point represented by x,y,z) but, the format is not the same for
 1511:     all columns.
 1512:     """
 1513:     # convert the iterable argument into an iterator so its contents can
 1514:     # be consumed by islice in case it is a generator
 1515:     it = iter(iterable)
 1516: 
 1517:     for size in sizes:
 1518:         if size is None:
 1519:             yield list(it)
 1520:             return
 1521:         else:
 1522:             yield list(islice(it, size))
 1523: 
 1524: 
 1525: def padded(iterable, fillvalue=None, n=None, next_multiple=False):
 1526:     """Yield the elements from *iterable*, followed by *fillvalue*, such that
 1527:     at least *n* items are emitted.
 1528: 
 1529:         >>> list(padded([1, 2, 3], '?', 5))
 1530:         [1, 2, 3, '?', '?']
 1531: 
 1532:     If *next_multiple* is ``True``, *fillvalue* will be emitted until the
 1533:     number of items emitted is a multiple of *n*::
 1534: 
 1535:         >>> list(padded([1, 2, 3, 4], n=3, next_multiple=True))
 1536:         [1, 2, 3, 4, None, None]
 1537: 
 1538:     If *n* is ``None``, *fillvalue* will be emitted indefinitely.
 1539: 
 1540:     """
 1541:     it = iter(iterable)
 1542:     if n is None:
 1543:         yield from chain(it, repeat(fillvalue))
 1544:     elif n < 1:
 1545:         raise ValueError('n must be at least 1')
 1546:     else:
 1547:         item_count = 0
 1548:         for item in it:
 1549:             yield item
 1550:             item_count += 1
 1551: 
 1552:         remaining = (n - item_count) % n if next_multiple else n - item_count
 1553:         for _ in range(remaining):
 1554:             yield fillvalue
 1555: 
 1556: 
 1557: def repeat_each(iterable, n=2):
 1558:     """Repeat each element in *iterable* *n* times.
 1559: 
 1560:     >>> list(repeat_each('ABC', 3))
 1561:     ['A', 'A', 'A', 'B', 'B', 'B', 'C', 'C', 'C']
 1562:     """
 1563:     return chain.from_iterable(map(repeat, iterable, repeat(n)))
 1564: 
 1565: 
 1566: def repeat_last(iterable, default=None):
 1567:     """After the *iterable* is exhausted, keep yielding its last element.
 1568: 
 1569:         >>> list(islice(repeat_last(range(3)), 5))
 1570:         [0, 1, 2, 2, 2]
 1571: 
 1572:     If the iterable is empty, yield *default* forever::
 1573: 
 1574:         >>> list(islice(repeat_last(range(0), 42), 5))
 1575:         [42, 42, 42, 42, 42]
 1576: 
 1577:     """
 1578:     item = _marker
 1579:     for item in iterable:
 1580:         yield item
 1581:     final = default if item is _marker else item
 1582:     yield from repeat(final)
 1583: 
 1584: 
 1585: def distribute(n, iterable):
 1586:     """Distribute the items from *iterable* among *n* smaller iterables.
 1587: 
 1588:         >>> group_1, group_2 = distribute(2, [1, 2, 3, 4, 5, 6])
 1589:         >>> list(group_1)
 1590:         [1, 3, 5]
 1591:         >>> list(group_2)
 1592:         [2, 4, 6]
 1593: 
 1594:     If the length of *iterable* is not evenly divisible by *n*, then the
 1595:     length of the returned iterables will not be identical:
 1596: 
 1597:         >>> children = distribute(3, [1, 2, 3, 4, 5, 6, 7])
 1598:         >>> [list(c) for c in children]
 1599:         [[1, 4, 7], [2, 5], [3, 6]]
 1600: 
 1601:     If the length of *iterable* is smaller than *n*, then the last returned
 1602:     iterables will be empty:
 1603: 
 1604:         >>> children = distribute(5, [1, 2, 3])
 1605:         >>> [list(c) for c in children]
 1606:         [[1], [2], [3], [], []]
 1607: 
 1608:     This function uses :func:`itertools.tee` and may require significant
 1609:     storage. If you need the order items in the smaller iterables to match the
 1610:     original iterable, see :func:`divide`.
 1611: 
 1612:     """
 1613:     if n < 1:
 1614:         raise ValueError('n must be at least 1')
 1615: 
 1616:     children = tee(iterable, n)
 1617:     return [islice(it, index, None, n) for index, it in enumerate(children)]
 1618: 
 1619: 
 1620: def stagger(iterable, offsets=(-1, 0, 1), longest=False, fillvalue=None):
 1621:     """Yield tuples whose elements are offset from *iterable*.
 1622:     The amount by which the `i`-th item in each tuple is offset is given by
 1623:     the `i`-th item in *offsets*.
 1624: 
 1625:         >>> list(stagger([0, 1, 2, 3]))
 1626:         [(None, 0, 1), (0, 1, 2), (1, 2, 3)]
 1627:         >>> list(stagger(range(8), offsets=(0, 2, 4)))
 1628:         [(0, 2, 4), (1, 3, 5), (2, 4, 6), (3, 5, 7)]
 1629: 
 1630:     By default, the sequence will end when the final element of a tuple is the
 1631:     last item in the iterable. To continue until the first element of a tuple
 1632:     is the last item in the iterable, set *longest* to ``True``::
 1633: 
 1634:         >>> list(stagger([0, 1, 2, 3], longest=True))
 1635:         [(None, 0, 1), (0, 1, 2), (1, 2, 3), (2, 3, None), (3, None, None)]
 1636: 
 1637:     By default, ``None`` will be used to replace offsets beyond the end of the
 1638:     sequence. Specify *fillvalue* to use some other value.
 1639: 
 1640:     """
 1641:     children = tee(iterable, len(offsets))
 1642: 
 1643:     return zip_offset(
 1644:         *children, offsets=offsets, longest=longest, fillvalue=fillvalue
 1645:     )
 1646: 
 1647: 
 1648: class UnequalIterablesError(ValueError):
 1649:     def __init__(self, details=None):
 1650:         msg = 'Iterables have different lengths'
 1651:         if details is not None:
 1652:             msg += (': index 0 has length {}; index {} has length {}').format(
 1653:                 *details
 1654:             )
 1655: 
 1656:         super().__init__(msg)
 1657: 
 1658: 
 1659: def _zip_equal_generator(iterables):
 1660:     for combo in zip_longest(*iterables, fillvalue=_marker):
 1661:         for val in combo:
 1662:             if val is _marker:
 1663:                 raise UnequalIterablesError()
 1664:         yield combo
 1665: 
 1666: 
 1667: def _zip_equal(*iterables):
 1668:     # Check whether the iterables are all the same size.
 1669:     try:
 1670:         first_size = len(iterables[0])
 1671:         for i, it in enumerate(iterables[1:], 1):
 1672:             size = len(it)
 1673:             if size != first_size:
 1674:                 break
 1675:         else:
 1676:             # If we didn't break out, we can use the built-in zip.
 1677:             return zip(*iterables)
 1678: 
 1679:         # If we did break out, there was a mismatch.
 1680:         raise UnequalIterablesError(details=(first_size, i, size))
 1681:     # If any one of the iterables didn't have a length, start reading
 1682:     # them until one runs out.
 1683:     except TypeError:
 1684:         return _zip_equal_generator(iterables)
 1685: 
 1686: 
 1687: def zip_equal(*iterables):
 1688:     """``zip`` the input *iterables* together, but raise
 1689:     ``UnequalIterablesError`` if they aren't all the same length.
 1690: 
 1691:         >>> it_1 = range(3)
 1692:         >>> it_2 = iter('abc')
 1693:         >>> list(zip_equal(it_1, it_2))
 1694:         [(0, 'a'), (1, 'b'), (2, 'c')]
 1695: 
 1696:         >>> it_1 = range(3)
 1697:         >>> it_2 = iter('abcd')
 1698:         >>> list(zip_equal(it_1, it_2)) # doctest: +IGNORE_EXCEPTION_DETAIL
 1699:         Traceback (most recent call last):
 1700:         ...
 1701:         more_itertools.more.UnequalIterablesError: Iterables have different
 1702:         lengths
 1703: 
 1704:     """
 1705:     if hexversion >= 0x30A00A6:
 1706:         warnings.warn(
 1707:             (
 1708:                 'zip_equal will be removed in a future version of '
 1709:                 'more-itertools. Use the builtin zip function with '
 1710:                 'strict=True instead.'
 1711:             ),
 1712:             DeprecationWarning,
 1713:         )
 1714: 
 1715:     return _zip_equal(*iterables)
 1716: 
 1717: 
 1718: def zip_offset(*iterables, offsets, longest=False, fillvalue=None):
 1719:     """``zip`` the input *iterables* together, but offset the `i`-th iterable
 1720:     by the `i`-th item in *offsets*.
 1721: 
 1722:         >>> list(zip_offset('0123', 'abcdef', offsets=(0, 1)))
 1723:         [('0', 'b'), ('1', 'c'), ('2', 'd'), ('3', 'e')]
 1724: 
 1725:     This can be used as a lightweight alternative to SciPy or pandas to analyze
 1726:     data sets in which some series have a lead or lag relationship.
 1727: 
 1728:     By default, the sequence will end when the shortest iterable is exhausted.
 1729:     To continue until the longest iterable is exhausted, set *longest* to
 1730:     ``True``.
 1731: 
 1732:         >>> list(zip_offset('0123', 'abcdef', offsets=(0, 1), longest=True))
 1733:         [('0', 'b'), ('1', 'c'), ('2', 'd'), ('3', 'e'), (None, 'f')]
 1734: 
 1735:     By default, ``None`` will be used to replace offsets beyond the end of the
 1736:     sequence. Specify *fillvalue* to use some other value.
 1737: 
 1738:     """
 1739:     if len(iterables) != len(offsets):
 1740:         raise ValueError("Number of iterables and offsets didn't match")
 1741: 
 1742:     staggered = []
 1743:     for it, n in zip(iterables, offsets):
 1744:         if n < 0:
 1745:             staggered.append(chain(repeat(fillvalue, -n), it))
 1746:         elif n > 0:
 1747:             staggered.append(islice(it, n, None))
 1748:         else:
 1749:             staggered.append(it)
 1750: 
 1751:     if longest:
 1752:         return zip_longest(*staggered, fillvalue=fillvalue)
 1753: 
 1754:     return zip(*staggered)
 1755: 
 1756: 
 1757: def sort_together(iterables, key_list=(0,), key=None, reverse=False):
 1758:     """Return the input iterables sorted together, with *key_list* as the
 1759:     priority for sorting. All iterables are trimmed to the length of the
 1760:     shortest one.
 1761: 
 1762:     This can be used like the sorting function in a spreadsheet. If each
 1763:     iterable represents a column of data, the key list determines which
 1764:     columns are used for sorting.
 1765: 
 1766:     By default, all iterables are sorted using the ``0``-th iterable::
 1767: 
 1768:         >>> iterables = [(4, 3, 2, 1), ('a', 'b', 'c', 'd')]
 1769:         >>> sort_together(iterables)
 1770:         [(1, 2, 3, 4), ('d', 'c', 'b', 'a')]
 1771: 
 1772:     Set a different key list to sort according to another iterable.
 1773:     Specifying multiple keys dictates how ties are broken::
 1774: 
 1775:         >>> iterables = [(3, 1, 2), (0, 1, 0), ('c', 'b', 'a')]
 1776:         >>> sort_together(iterables, key_list=(1, 2))
 1777:         [(2, 3, 1), (0, 0, 1), ('a', 'c', 'b')]
 1778: 
 1779:     To sort by a function of the elements of the iterable, pass a *key*
 1780:     function. Its arguments are the elements of the iterables corresponding to
 1781:     the key list::
 1782: 
 1783:         >>> names = ('a', 'b', 'c')
 1784:         >>> lengths = (1, 2, 3)
 1785:         >>> widths = (5, 2, 1)
 1786:         >>> def area(length, width):
 1787:         ...     return length * width
 1788:         >>> sort_together([names, lengths, widths], key_list=(1, 2), key=area)
 1789:         [('c', 'b', 'a'), (3, 2, 1), (1, 2, 5)]
 1790: 
 1791:     Set *reverse* to ``True`` to sort in descending order.
 1792: 
 1793:         >>> sort_together([(1, 2, 3), ('c', 'b', 'a')], reverse=True)
 1794:         [(3, 2, 1), ('a', 'b', 'c')]
 1795: 
 1796:     """
 1797:     if key is None:
 1798:         # if there is no key function, the key argument to sorted is an
 1799:         # itemgetter
 1800:         key_argument = itemgetter(*key_list)
 1801:     else:
 1802:         # if there is a key function, call it with the items at the offsets
 1803:         # specified by the key function as arguments
 1804:         key_list = list(key_list)
 1805:         if len(key_list) == 1:
 1806:             # if key_list contains a single item, pass the item at that offset
 1807:             # as the only argument to the key function
 1808:             key_offset = key_list[0]
 1809:             key_argument = lambda zipped_items: key(zipped_items[key_offset])
 1810:         else:
 1811:             # if key_list contains multiple items, use itemgetter to return a
 1812:             # tuple of items, which we pass as *args to the key function
 1813:             get_key_items = itemgetter(*key_list)
 1814:             key_argument = lambda zipped_items: key(
 1815:                 *get_key_items(zipped_items)
 1816:             )
 1817: 
 1818:     return list(
 1819:         zip(*sorted(zip(*iterables), key=key_argument, reverse=reverse))
 1820:     )
 1821: 
 1822: 
 1823: def unzip(iterable):
 1824:     """The inverse of :func:`zip`, this function disaggregates the elements
 1825:     of the zipped *iterable*.
 1826: 
 1827:     The ``i``-th iterable contains the ``i``-th element from each element
 1828:     of the zipped iterable. The first element is used to to determine the
 1829:     length of the remaining elements.
 1830: 
 1831:         >>> iterable = [('a', 1), ('b', 2), ('c', 3), ('d', 4)]
 1832:         >>> letters, numbers = unzip(iterable)
 1833:         >>> list(letters)
 1834:         ['a', 'b', 'c', 'd']
 1835:         >>> list(numbers)
 1836:         [1, 2, 3, 4]
 1837: 
 1838:     This is similar to using ``zip(*iterable)``, but it avoids reading
 1839:     *iterable* into memory. Note, however, that this function uses
 1840:     :func:`itertools.tee` and thus may require significant storage.
 1841: 
 1842:     """
 1843:     head, iterable = spy(iter(iterable))
 1844:     if not head:
 1845:         # empty iterable, e.g. zip([], [], [])
 1846:         return ()
 1847:     # spy returns a one-length iterable as head
 1848:     head = head[0]
 1849:     iterables = tee(iterable, len(head))
 1850: 
 1851:     def itemgetter(i):
 1852:         def getter(obj):
 1853:             try:
 1854:                 return obj[i]
 1855:             except IndexError:
 1856:                 # basically if we have an iterable like
 1857:                 # iter([(1, 2, 3), (4, 5), (6,)])
 1858:                 # the second unzipped iterable would fail at the third tuple
 1859:                 # since it would try to access tup[1]
 1860:                 # same with the third unzipped iterable and the second tuple
 1861:                 # to support these "improperly zipped" iterables,
 1862:                 # we create a custom itemgetter
 1863:                 # which just stops the unzipped iterables
 1864:                 # at first length mismatch
 1865:                 raise StopIteration
 1866: 
 1867:         return getter
 1868: 
 1869:     return tuple(map(itemgetter(i), it) for i, it in enumerate(iterables))
 1870: 
 1871: 
 1872: def divide(n, iterable):
 1873:     """Divide the elements from *iterable* into *n* parts, maintaining
 1874:     order.
 1875: 
 1876:         >>> group_1, group_2 = divide(2, [1, 2, 3, 4, 5, 6])
 1877:         >>> list(group_1)
 1878:         [1, 2, 3]
 1879:         >>> list(group_2)
 1880:         [4, 5, 6]
 1881: 
 1882:     If the length of *iterable* is not evenly divisible by *n*, then the
 1883:     length of the returned iterables will not be identical:
 1884: 
 1885:         >>> children = divide(3, [1, 2, 3, 4, 5, 6, 7])
 1886:         >>> [list(c) for c in children]
 1887:         [[1, 2, 3], [4, 5], [6, 7]]
 1888: 
 1889:     If the length of the iterable is smaller than n, then the last returned
 1890:     iterables will be empty:
 1891: 
 1892:         >>> children = divide(5, [1, 2, 3])
 1893:         >>> [list(c) for c in children]
 1894:         [[1], [2], [3], [], []]
 1895: 
 1896:     This function will exhaust the iterable before returning and may require
 1897:     significant storage. If order is not important, see :func:`distribute`,
 1898:     which does not first pull the iterable into memory.
 1899: 
 1900:     """
 1901:     if n < 1:
 1902:         raise ValueError('n must be at least 1')
 1903: 
 1904:     try:
 1905:         iterable[:0]
 1906:     except TypeError:
 1907:         seq = tuple(iterable)
 1908:     else:
 1909:         seq = iterable
 1910: 
 1911:     q, r = divmod(len(seq), n)
 1912: 
 1913:     ret = []
 1914:     stop = 0
 1915:     for i in range(1, n + 1):
 1916:         start = stop
 1917:         stop += q + 1 if i <= r else q
 1918:         ret.append(iter(seq[start:stop]))
 1919: 
 1920:     return ret
 1921: 
 1922: 
 1923: def always_iterable(obj, base_type=(str, bytes)):
 1924:     """If *obj* is iterable, return an iterator over its items::
 1925: 
 1926:         >>> obj = (1, 2, 3)
 1927:         >>> list(always_iterable(obj))
 1928:         [1, 2, 3]
 1929: 
 1930:     If *obj* is not iterable, return a one-item iterable containing *obj*::
 1931: 
 1932:         >>> obj = 1
 1933:         >>> list(always_iterable(obj))
 1934:         [1]
 1935: 
 1936:     If *obj* is ``None``, return an empty iterable:
 1937: 
 1938:         >>> obj = None
 1939:         >>> list(always_iterable(None))
 1940:         []
 1941: 
 1942:     By default, binary and text strings are not considered iterable::
 1943: 
 1944:         >>> obj = 'foo'
 1945:         >>> list(always_iterable(obj))
 1946:         ['foo']
 1947: 
 1948:     If *base_type* is set, objects for which ``isinstance(obj, base_type)``
 1949:     returns ``True`` won't be considered iterable.
 1950: 
 1951:         >>> obj = {'a': 1}
 1952:         >>> list(always_iterable(obj))  # Iterate over the dict's keys
 1953:         ['a']
 1954:         >>> list(always_iterable(obj, base_type=dict))  # Treat dicts as a unit
 1955:         [{'a': 1}]
 1956: 
 1957:     Set *base_type* to ``None`` to avoid any special handling and treat objects
 1958:     Python considers iterable as iterable:
 1959: 
 1960:         >>> obj = 'foo'
 1961:         >>> list(always_iterable(obj, base_type=None))
 1962:         ['f', 'o', 'o']
 1963:     """
 1964:     if obj is None:
 1965:         return iter(())
 1966: 
 1967:     if (base_type is not None) and isinstance(obj, base_type):
 1968:         return iter((obj,))
 1969: 
 1970:     try:
 1971:         return iter(obj)
 1972:     except TypeError:
 1973:         return iter((obj,))
 1974: 
 1975: 
 1976: def adjacent(predicate, iterable, distance=1):
 1977:     """Return an iterable over `(bool, item)` tuples where the `item` is
 1978:     drawn from *iterable* and the `bool` indicates whether
 1979:     that item satisfies the *predicate* or is adjacent to an item that does.
 1980: 
 1981:     For example, to find whether items are adjacent to a ``3``::
 1982: 
 1983:         >>> list(adjacent(lambda x: x == 3, range(6)))
 1984:         [(False, 0), (False, 1), (True, 2), (True, 3), (True, 4), (False, 5)]
 1985: 
 1986:     Set *distance* to change what counts as adjacent. For example, to find
 1987:     whether items are two places away from a ``3``:
 1988: 
 1989:         >>> list(adjacent(lambda x: x == 3, range(6), distance=2))
 1990:         [(False, 0), (True, 1), (True, 2), (True, 3), (True, 4), (True, 5)]
 1991: 
 1992:     This is useful for contextualizing the results of a search function.
 1993:     For example, a code comparison tool might want to identify lines that
 1994:     have changed, but also surrounding lines to give the viewer of the diff
 1995:     context.
 1996: 
 1997:     The predicate function will only be called once for each item in the
 1998:     iterable.
 1999: 
 2000:     See also :func:`groupby_transform`, which can be used with this function
 2001:     to group ranges of items with the same `bool` value.
 2002: 
 2003:     """
 2004:     # Allow distance=0 mainly for testing that it reproduces results with map()
 2005:     if distance < 0:
 2006:         raise ValueError('distance must be at least 0')
 2007: 
 2008:     i1, i2 = tee(iterable)
 2009:     padding = [False] * distance
 2010:     selected = chain(padding, map(predicate, i1), padding)
 2011:     adjacent_to_selected = map(any, windowed(selected, 2 * distance + 1))
 2012:     return zip(adjacent_to_selected, i2)
 2013: 
 2014: 
 2015: def groupby_transform(iterable, keyfunc=None, valuefunc=None, reducefunc=None):
 2016:     """An extension of :func:`itertools.groupby` that can apply transformations
 2017:     to the grouped data.
 2018: 
 2019:     * *keyfunc* is a function computing a key value for each item in *iterable*
 2020:     * *valuefunc* is a function that transforms the individual items from
 2021:       *iterable* after grouping
 2022:     * *reducefunc* is a function that transforms each group of items
 2023: 
 2024:     >>> iterable = 'aAAbBBcCC'
 2025:     >>> keyfunc = lambda k: k.upper()
 2026:     >>> valuefunc = lambda v: v.lower()
 2027:     >>> reducefunc = lambda g: ''.join(g)
 2028:     >>> list(groupby_transform(iterable, keyfunc, valuefunc, reducefunc))
 2029:     [('A', 'aaa'), ('B', 'bbb'), ('C', 'ccc')]
 2030: 
 2031:     Each optional argument defaults to an identity function if not specified.
 2032: 
 2033:     :func:`groupby_transform` is useful when grouping elements of an iterable
 2034:     using a separate iterable as the key. To do this, :func:`zip` the iterables
 2035:     and pass a *keyfunc* that extracts the first element and a *valuefunc*
 2036:     that extracts the second element::
 2037: 
 2038:         >>> from operator import itemgetter
 2039:         >>> keys = [0, 0, 1, 1, 1, 2, 2, 2, 3]
 2040:         >>> values = 'abcdefghi'
 2041:         >>> iterable = zip(keys, values)
 2042:         >>> grouper = groupby_transform(iterable, itemgetter(0), itemgetter(1))
 2043:         >>> [(k, ''.join(g)) for k, g in grouper]
 2044:         [(0, 'ab'), (1, 'cde'), (2, 'fgh'), (3, 'i')]
 2045: 
 2046:     Note that the order of items in the iterable is significant.
 2047:     Only adjacent items are grouped together, so if you don't want any
 2048:     duplicate groups, you should sort the iterable by the key function.
 2049: 
 2050:     """
 2051:     ret = groupby(iterable, keyfunc)
 2052:     if valuefunc:
 2053:         ret = ((k, map(valuefunc, g)) for k, g in ret)
 2054:     if reducefunc:
 2055:         ret = ((k, reducefunc(g)) for k, g in ret)
 2056: 
 2057:     return ret
 2058: 
 2059: 
 2060: class numeric_range(abc.Sequence, abc.Hashable):
 2061:     """An extension of the built-in ``range()`` function whose arguments can
 2062:     be any orderable numeric type.
 2063: 
 2064:     With only *stop* specified, *start* defaults to ``0`` and *step*
 2065:     defaults to ``1``. The output items will match the type of *stop*:
 2066: 
 2067:         >>> list(numeric_range(3.5))
 2068:         [0.0, 1.0, 2.0, 3.0]
 2069: 
 2070:     With only *start* and *stop* specified, *step* defaults to ``1``. The
 2071:     output items will match the type of *start*:
 2072: 
 2073:         >>> from decimal import Decimal
 2074:         >>> start = Decimal('2.1')
 2075:         >>> stop = Decimal('5.1')
 2076:         >>> list(numeric_range(start, stop))
 2077:         [Decimal('2.1'), Decimal('3.1'), Decimal('4.1')]
 2078: 
 2079:     With *start*, *stop*, and *step*  specified the output items will match
 2080:     the type of ``start + step``:
 2081: 
 2082:         >>> from fractions import Fraction
 2083:         >>> start = Fraction(1, 2)  # Start at 1/2
 2084:         >>> stop = Fraction(5, 2)  # End at 5/2
 2085:         >>> step = Fraction(1, 2)  # Count by 1/2
 2086:         >>> list(numeric_range(start, stop, step))
 2087:         [Fraction(1, 2), Fraction(1, 1), Fraction(3, 2), Fraction(2, 1)]
 2088: 
 2089:     If *step* is zero, ``ValueError`` is raised. Negative steps are supported:
 2090: 
 2091:         >>> list(numeric_range(3, -1, -1.0))
 2092:         [3.0, 2.0, 1.0, 0.0]
 2093: 
 2094:     Be aware of the limitations of floating point numbers; the representation
 2095:     of the yielded numbers may be surprising.
 2096: 
 2097:     ``datetime.datetime`` objects can be used for *start* and *stop*, if *step*
 2098:     is a ``datetime.timedelta`` object:
 2099: 
 2100:         >>> import datetime
 2101:         >>> start = datetime.datetime(2019, 1, 1)
 2102:         >>> stop = datetime.datetime(2019, 1, 3)
 2103:         >>> step = datetime.timedelta(days=1)
 2104:         >>> items = iter(numeric_range(start, stop, step))
 2105:         >>> next(items)
 2106:         datetime.datetime(2019, 1, 1, 0, 0)
 2107:         >>> next(items)
 2108:         datetime.datetime(2019, 1, 2, 0, 0)
 2109: 
 2110:     """
 2111: 
 2112:     _EMPTY_HASH = hash(range(0, 0))
 2113: 
 2114:     def __init__(self, *args):
 2115:         argc = len(args)
 2116:         if argc == 1:
 2117:             (self._stop,) = args
 2118:             self._start = type(self._stop)(0)
 2119:             self._step = type(self._stop - self._start)(1)
 2120:         elif argc == 2:
 2121:             self._start, self._stop = args
 2122:             self._step = type(self._stop - self._start)(1)
 2123:         elif argc == 3:
 2124:             self._start, self._stop, self._step = args
 2125:         elif argc == 0:
 2126:             raise TypeError(
 2127:                 'numeric_range expected at least '
 2128:                 '1 argument, got {}'.format(argc)
 2129:             )
 2130:         else:
 2131:             raise TypeError(
 2132:                 'numeric_range expected at most '
 2133:                 '3 arguments, got {}'.format(argc)
 2134:             )
 2135: 
 2136:         self._zero = type(self._step)(0)
 2137:         if self._step == self._zero:
 2138:             raise ValueError('numeric_range() arg 3 must not be zero')
 2139:         self._growing = self._step > self._zero
 2140:         self._init_len()
 2141: 
 2142:     def __bool__(self):
 2143:         if self._growing:
 2144:             return self._start < self._stop
 2145:         else:
 2146:             return self._start > self._stop
 2147: 
 2148:     def __contains__(self, elem):
 2149:         if self._growing:
 2150:             if self._start <= elem < self._stop:
 2151:                 return (elem - self._start) % self._step == self._zero
 2152:         else:
 2153:             if self._start >= elem > self._stop:
 2154:                 return (self._start - elem) % (-self._step) == self._zero
 2155: 
 2156:         return False
 2157: 
 2158:     def __eq__(self, other):
 2159:         if isinstance(other, numeric_range):
 2160:             empty_self = not bool(self)
 2161:             empty_other = not bool(other)
 2162:             if empty_self or empty_other:
 2163:                 return empty_self and empty_other  # True if both empty
 2164:             else:
 2165:                 return (
 2166:                     self._start == other._start
 2167:                     and self._step == other._step
 2168:                     and self._get_by_index(-1) == other._get_by_index(-1)
 2169:                 )
 2170:         else:
 2171:             return False
 2172: 
 2173:     def __getitem__(self, key):
 2174:         if isinstance(key, int):
 2175:             return self._get_by_index(key)
 2176:         elif isinstance(key, slice):
 2177:             step = self._step if key.step is None else key.step * self._step
 2178: 
 2179:             if key.start is None or key.start <= -self._len:
 2180:                 start = self._start
 2181:             elif key.start >= self._len:
 2182:                 start = self._stop
 2183:             else:  # -self._len < key.start < self._len
 2184:                 start = self._get_by_index(key.start)
 2185: 
 2186:             if key.stop is None or key.stop >= self._len:
 2187:                 stop = self._stop
 2188:             elif key.stop <= -self._len:
 2189:                 stop = self._start
 2190:             else:  # -self._len < key.stop < self._len
 2191:                 stop = self._get_by_index(key.stop)
 2192: 
 2193:             return numeric_range(start, stop, step)
 2194:         else:
 2195:             raise TypeError(
 2196:                 'numeric range indices must be '
 2197:                 'integers or slices, not {}'.format(type(key).__name__)
 2198:             )
 2199: 
 2200:     def __hash__(self):
 2201:         if self:
 2202:             return hash((self._start, self._get_by_index(-1), self._step))
 2203:         else:
 2204:             return self._EMPTY_HASH
 2205: 
 2206:     def __iter__(self):
 2207:         values = (self._start + (n * self._step) for n in count())
 2208:         if self._growing:
 2209:             return takewhile(partial(gt, self._stop), values)
 2210:         else:
 2211:             return takewhile(partial(lt, self._stop), values)
 2212: 
 2213:     def __len__(self):
 2214:         return self._len
 2215: 
 2216:     def _init_len(self):
 2217:         if self._growing:
 2218:             start = self._start
 2219:             stop = self._stop
 2220:             step = self._step
 2221:         else:
 2222:             start = self._stop
 2223:             stop = self._start
 2224:             step = -self._step
 2225:         distance = stop - start
 2226:         if distance <= self._zero:
 2227:             self._len = 0
 2228:         else:  # distance > 0 and step > 0: regular euclidean division
 2229:             q, r = divmod(distance, step)
 2230:             self._len = int(q) + int(r != self._zero)
 2231: 
 2232:     def __reduce__(self):
 2233:         return numeric_range, (self._start, self._stop, self._step)
 2234: 
 2235:     def __repr__(self):
 2236:         if self._step == 1:
 2237:             return "numeric_range({}, {})".format(
 2238:                 repr(self._start), repr(self._stop)
 2239:             )
 2240:         else:
 2241:             return "numeric_range({}, {}, {})".format(
 2242:                 repr(self._start), repr(self._stop), repr(self._step)
 2243:             )
 2244: 
 2245:     def __reversed__(self):
 2246:         return iter(
 2247:             numeric_range(
 2248:                 self._get_by_index(-1), self._start - self._step, -self._step
 2249:             )
 2250:         )
 2251: 
 2252:     def count(self, value):
 2253:         return int(value in self)
 2254: 
 2255:     def index(self, value):
 2256:         if self._growing:
 2257:             if self._start <= value < self._stop:
 2258:                 q, r = divmod(value - self._start, self._step)
 2259:                 if r == self._zero:
 2260:                     return int(q)
 2261:         else:
 2262:             if self._start >= value > self._stop:
 2263:                 q, r = divmod(self._start - value, -self._step)
 2264:                 if r == self._zero:
 2265:                     return int(q)
 2266: 
 2267:         raise ValueError("{} is not in numeric range".format(value))
 2268: 
 2269:     def _get_by_index(self, i):
 2270:         if i < 0:
 2271:             i += self._len
 2272:         if i < 0 or i >= self._len:
 2273:             raise IndexError("numeric range object index out of range")
 2274:         return self._start + i * self._step
 2275: 
 2276: 
 2277: def count_cycle(iterable, n=None):
 2278:     """Cycle through the items from *iterable* up to *n* times, yielding
 2279:     the number of completed cycles along with each item. If *n* is omitted the
 2280:     process repeats indefinitely.
 2281: 
 2282:     >>> list(count_cycle('AB', 3))
 2283:     [(0, 'A'), (0, 'B'), (1, 'A'), (1, 'B'), (2, 'A'), (2, 'B')]
 2284: 
 2285:     """
 2286:     iterable = tuple(iterable)
 2287:     if not iterable:
 2288:         return iter(())
 2289:     counter = count() if n is None else range(n)
 2290:     return ((i, item) for i in counter for item in iterable)
 2291: 
 2292: 
 2293: def mark_ends(iterable):
 2294:     """Yield 3-tuples of the form ``(is_first, is_last, item)``.
 2295: 
 2296:     >>> list(mark_ends('ABC'))
 2297:     [(True, False, 'A'), (False, False, 'B'), (False, True, 'C')]
 2298: 
 2299:     Use this when looping over an iterable to take special action on its first
 2300:     and/or last items:
 2301: 
 2302:     >>> iterable = ['Header', 100, 200, 'Footer']
 2303:     >>> total = 0
 2304:     >>> for is_first, is_last, item in mark_ends(iterable):
 2305:     ...     if is_first:
 2306:     ...         continue  # Skip the header
 2307:     ...     if is_last:
 2308:     ...         continue  # Skip the footer
 2309:     ...     total += item
 2310:     >>> print(total)
 2311:     300
 2312:     """
 2313:     it = iter(iterable)
 2314: 
 2315:     try:
 2316:         b = next(it)
 2317:     except StopIteration:
 2318:         return
 2319: 
 2320:     try:
 2321:         for i in count():
 2322:             a = b
 2323:             b = next(it)
 2324:             yield i == 0, False, a
 2325: 
 2326:     except StopIteration:
 2327:         yield i == 0, True, a
 2328: 
 2329: 
 2330: def locate(iterable, pred=bool, window_size=None):
 2331:     """Yield the index of each item in *iterable* for which *pred* returns
 2332:     ``True``.
 2333: 
 2334:     *pred* defaults to :func:`bool`, which will select truthy items:
 2335: 
 2336:         >>> list(locate([0, 1, 1, 0, 1, 0, 0]))
 2337:         [1, 2, 4]
 2338: 
 2339:     Set *pred* to a custom function to, e.g., find the indexes for a particular
 2340:     item.
 2341: 
 2342:         >>> list(locate(['a', 'b', 'c', 'b'], lambda x: x == 'b'))
 2343:         [1, 3]
 2344: 
 2345:     If *window_size* is given, then the *pred* function will be called with
 2346:     that many items. This enables searching for sub-sequences:
 2347: 
 2348:         >>> iterable = [0, 1, 2, 3, 0, 1, 2, 3, 0, 1, 2, 3]
 2349:         >>> pred = lambda *args: args == (1, 2, 3)
 2350:         >>> list(locate(iterable, pred=pred, window_size=3))
 2351:         [1, 5, 9]
 2352: 
 2353:     Use with :func:`seekable` to find indexes and then retrieve the associated
 2354:     items:
 2355: 
 2356:         >>> from itertools import count
 2357:         >>> from more_itertools import seekable
 2358:         >>> source = (3 * n + 1 if (n % 2) else n // 2 for n in count())
 2359:         >>> it = seekable(source)
 2360:         >>> pred = lambda x: x > 100
 2361:         >>> indexes = locate(it, pred=pred)
 2362:         >>> i = next(indexes)
 2363:         >>> it.seek(i)
 2364:         >>> next(it)
 2365:         106
 2366: 
 2367:     """
 2368:     if window_size is None:
 2369:         return compress(count(), map(pred, iterable))
 2370: 
 2371:     if window_size < 1:
 2372:         raise ValueError('window size must be at least 1')
 2373: 
 2374:     it = windowed(iterable, window_size, fillvalue=_marker)
 2375:     return compress(count(), starmap(pred, it))
 2376: 
 2377: 
 2378: def lstrip(iterable, pred):
 2379:     """Yield the items from *iterable*, but strip any from the beginning
 2380:     for which *pred* returns ``True``.
 2381: 
 2382:     For example, to remove a set of items from the start of an iterable:
 2383: 
 2384:         >>> iterable = (None, False, None, 1, 2, None, 3, False, None)
 2385:         >>> pred = lambda x: x in {None, False, ''}
 2386:         >>> list(lstrip(iterable, pred))
 2387:         [1, 2, None, 3, False, None]
 2388: 
 2389:     This function is analogous to to :func:`str.lstrip`, and is essentially
 2390:     an wrapper for :func:`itertools.dropwhile`.
 2391: 
 2392:     """
 2393:     return dropwhile(pred, iterable)
 2394: 
 2395: 
 2396: def rstrip(iterable, pred):
 2397:     """Yield the items from *iterable*, but strip any from the end
 2398:     for which *pred* returns ``True``.
 2399: 
 2400:     For example, to remove a set of items from the end of an iterable:
 2401: 
 2402:         >>> iterable = (None, False, None, 1, 2, None, 3, False, None)
 2403:         >>> pred = lambda x: x in {None, False, ''}
 2404:         >>> list(rstrip(iterable, pred))
 2405:         [None, False, None, 1, 2, None, 3]
 2406: 
 2407:     This function is analogous to :func:`str.rstrip`.
 2408: 
 2409:     """
 2410:     cache = []
 2411:     cache_append = cache.append
 2412:     cache_clear = cache.clear
 2413:     for x in iterable:
 2414:         if pred(x):
 2415:             cache_append(x)
 2416:         else:
 2417:             yield from cache
 2418:             cache_clear()
 2419:             yield x
 2420: 
 2421: 
 2422: def strip(iterable, pred):
 2423:     """Yield the items from *iterable*, but strip any from the
 2424:     beginning and end for which *pred* returns ``True``.
 2425: 
 2426:     For example, to remove a set of items from both ends of an iterable:
 2427: 
 2428:         >>> iterable = (None, False, None, 1, 2, None, 3, False, None)
 2429:         >>> pred = lambda x: x in {None, False, ''}
 2430:         >>> list(strip(iterable, pred))
 2431:         [1, 2, None, 3]
 2432: 
 2433:     This function is analogous to :func:`str.strip`.
 2434: 
 2435:     """
 2436:     return rstrip(lstrip(iterable, pred), pred)
 2437: 
 2438: 
 2439: class islice_extended:
 2440:     """An extension of :func:`itertools.islice` that supports negative values
 2441:     for *stop*, *start*, and *step*.
 2442: 
 2443:         >>> iterable = iter('abcdefgh')
 2444:         >>> list(islice_extended(iterable, -4, -1))
 2445:         ['e', 'f', 'g']
 2446: 
 2447:     Slices with negative values require some caching of *iterable*, but this
 2448:     function takes care to minimize the amount of memory required.
 2449: 
 2450:     For example, you can use a negative step with an infinite iterator:
 2451: 
 2452:         >>> from itertools import count
 2453:         >>> list(islice_extended(count(), 110, 99, -2))
 2454:         [110, 108, 106, 104, 102, 100]
 2455: 
 2456:     You can also use slice notation directly:
 2457: 
 2458:         >>> iterable = map(str, count())
 2459:         >>> it = islice_extended(iterable)[10:20:2]
 2460:         >>> list(it)
 2461:         ['10', '12', '14', '16', '18']
 2462: 
 2463:     """
 2464: 
 2465:     def __init__(self, iterable, *args):
 2466:         it = iter(iterable)
 2467:         if args:
 2468:             self._iterable = _islice_helper(it, slice(*args))
 2469:         else:
 2470:             self._iterable = it
 2471: 
 2472:     def __iter__(self):
 2473:         return self
 2474: 
 2475:     def __next__(self):
 2476:         return next(self._iterable)
 2477: 
 2478:     def __getitem__(self, key):
 2479:         if isinstance(key, slice):
 2480:             return islice_extended(_islice_helper(self._iterable, key))
 2481: 
 2482:         raise TypeError('islice_extended.__getitem__ argument must be a slice')
 2483: 
 2484: 
 2485: def _islice_helper(it, s):
 2486:     start = s.start
 2487:     stop = s.stop
 2488:     if s.step == 0:
 2489:         raise ValueError('step argument must be a non-zero integer or None.')
 2490:     step = s.step or 1
 2491: 
 2492:     if step > 0:
 2493:         start = 0 if (start is None) else start
 2494: 
 2495:         if start < 0:
 2496:             # Consume all but the last -start items
 2497:             cache = deque(enumerate(it, 1), maxlen=-start)
 2498:             len_iter = cache[-1][0] if cache else 0
 2499: 
 2500:             # Adjust start to be positive
 2501:             i = max(len_iter + start, 0)
 2502: 
 2503:             # Adjust stop to be positive
 2504:             if stop is None:
 2505:                 j = len_iter
 2506:             elif stop >= 0:
 2507:                 j = min(stop, len_iter)
 2508:             else:
 2509:                 j = max(len_iter + stop, 0)
 2510: 
 2511:             # Slice the cache
 2512:             n = j - i
 2513:             if n <= 0:
 2514:                 return
 2515: 
 2516:             for index, item in islice(cache, 0, n, step):
 2517:                 yield item
 2518:         elif (stop is not None) and (stop < 0):
 2519:             # Advance to the start position
 2520:             next(islice(it, start, start), None)
 2521: 
 2522:             # When stop is negative, we have to carry -stop items while
 2523:             # iterating
 2524:             cache = deque(islice(it, -stop), maxlen=-stop)
 2525: 
 2526:             for index, item in enumerate(it):
 2527:                 cached_item = cache.popleft()
 2528:                 if index % step == 0:
 2529:                     yield cached_item
 2530:                 cache.append(item)
 2531:         else:
 2532:             # When both start and stop are positive we have the normal case
 2533:             yield from islice(it, start, stop, step)
 2534:     else:
 2535:         start = -1 if (start is None) else start
 2536: 
 2537:         if (stop is not None) and (stop < 0):
 2538:             # Consume all but the last items
 2539:             n = -stop - 1
 2540:             cache = deque(enumerate(it, 1), maxlen=n)
 2541:             len_iter = cache[-1][0] if cache else 0
 2542: 
 2543:             # If start and stop are both negative they are comparable and
 2544:             # we can just slice. Otherwise we can adjust start to be negative
 2545:             # and then slice.
 2546:             if start < 0:
 2547:                 i, j = start, stop
 2548:             else:
 2549:                 i, j = min(start - len_iter, -1), None
 2550: 
 2551:             for index, item in list(cache)[i:j:step]:
 2552:                 yield item
 2553:         else:
 2554:             # Advance to the stop position
 2555:             if stop is not None:
 2556:                 m = stop + 1
 2557:                 next(islice(it, m, m), None)
 2558: 
 2559:             # stop is positive, so if start is negative they are not comparable
 2560:             # and we need the rest of the items.
 2561:             if start < 0:
 2562:                 i = start
 2563:                 n = None
 2564:             # stop is None and start is positive, so we just need items up to
 2565:             # the start index.
 2566:             elif stop is None:
 2567:                 i = None
 2568:                 n = start + 1
 2569:             # Both stop and start are positive, so they are comparable.
 2570:             else:
 2571:                 i = None
 2572:                 n = start - stop
 2573:                 if n <= 0:
 2574:                     return
 2575: 
 2576:             cache = list(islice(it, n))
 2577: 
 2578:             yield from cache[i::step]
 2579: 
 2580: 
 2581: def always_reversible(iterable):
 2582:     """An extension of :func:`reversed` that supports all iterables, not
 2583:     just those which implement the ``Reversible`` or ``Sequence`` protocols.
 2584: 
 2585:         >>> print(*always_reversible(x for x in range(3)))
 2586:         2 1 0
 2587: 
 2588:     If the iterable is already reversible, this function returns the
 2589:     result of :func:`reversed()`. If the iterable is not reversible,
 2590:     this function will cache the remaining items in the iterable and
 2591:     yield them in reverse order, which may require significant storage.
 2592:     """
 2593:     try:
 2594:         return reversed(iterable)
 2595:     except TypeError:
 2596:         return reversed(list(iterable))
 2597: 
 2598: 
 2599: def consecutive_groups(iterable, ordering=lambda x: x):
 2600:     """Yield groups of consecutive items using :func:`itertools.groupby`.
 2601:     The *ordering* function determines whether two items are adjacent by
 2602:     returning their position.
 2603: 
 2604:     By default, the ordering function is the identity function. This is
 2605:     suitable for finding runs of numbers:
 2606: 
 2607:         >>> iterable = [1, 10, 11, 12, 20, 30, 31, 32, 33, 40]
 2608:         >>> for group in consecutive_groups(iterable):
 2609:         ...     print(list(group))
 2610:         [1]
 2611:         [10, 11, 12]
 2612:         [20]
 2613:         [30, 31, 32, 33]
 2614:         [40]
 2615: 
 2616:     For finding runs of adjacent letters, try using the :meth:`index` method
 2617:     of a string of letters:
 2618: 
 2619:         >>> from string import ascii_lowercase
 2620:         >>> iterable = 'abcdfgilmnop'
 2621:         >>> ordering = ascii_lowercase.index
 2622:         >>> for group in consecutive_groups(iterable, ordering):
 2623:         ...     print(list(group))
 2624:         ['a', 'b', 'c', 'd']
 2625:         ['f', 'g']
 2626:         ['i']
 2627:         ['l', 'm', 'n', 'o', 'p']
 2628: 
 2629:     Each group of consecutive items is an iterator that shares it source with
 2630:     *iterable*. When an an output group is advanced, the previous group is
 2631:     no longer available unless its elements are copied (e.g., into a ``list``).
 2632: 
 2633:         >>> iterable = [1, 2, 11, 12, 21, 22]
 2634:         >>> saved_groups = []
 2635:         >>> for group in consecutive_groups(iterable):
 2636:         ...     saved_groups.append(list(group))  # Copy group elements
 2637:         >>> saved_groups
 2638:         [[1, 2], [11, 12], [21, 22]]
 2639: 
 2640:     """
 2641:     for k, g in groupby(
 2642:         enumerate(iterable), key=lambda x: x[0] - ordering(x[1])
 2643:     ):
 2644:         yield map(itemgetter(1), g)
 2645: 
 2646: 
 2647: def difference(iterable, func=sub, *, initial=None):
 2648:     """This function is the inverse of :func:`itertools.accumulate`. By default
 2649:     it will compute the first difference of *iterable* using
 2650:     :func:`operator.sub`:
 2651: 
 2652:         >>> from itertools import accumulate
 2653:         >>> iterable = accumulate([0, 1, 2, 3, 4])  # produces 0, 1, 3, 6, 10
 2654:         >>> list(difference(iterable))
 2655:         [0, 1, 2, 3, 4]
 2656: 
 2657:     *func* defaults to :func:`operator.sub`, but other functions can be
 2658:     specified. They will be applied as follows::
 2659: 
 2660:         A, B, C, D, ... --> A, func(B, A), func(C, B), func(D, C), ...
 2661: 
 2662:     For example, to do progressive division:
 2663: 
 2664:         >>> iterable = [1, 2, 6, 24, 120]
 2665:         >>> func = lambda x, y: x // y
 2666:         >>> list(difference(iterable, func))
 2667:         [1, 2, 3, 4, 5]
 2668: 
 2669:     If the *initial* keyword is set, the first element will be skipped when
 2670:     computing successive differences.
 2671: 
 2672:         >>> it = [10, 11, 13, 16]  # from accumulate([1, 2, 3], initial=10)
 2673:         >>> list(difference(it, initial=10))
 2674:         [1, 2, 3]
 2675: 
 2676:     """
 2677:     a, b = tee(iterable)
 2678:     try:
 2679:         first = [next(b)]
 2680:     except StopIteration:
 2681:         return iter([])
 2682: 
 2683:     if initial is not None:
 2684:         first = []
 2685: 
 2686:     return chain(first, starmap(func, zip(b, a)))
 2687: 
 2688: 
 2689: class SequenceView(Sequence):
 2690:     """Return a read-only view of the sequence object *target*.
 2691: 
 2692:     :class:`SequenceView` objects are analogous to Python's built-in
 2693:     "dictionary view" types. They provide a dynamic view of a sequence's items,
 2694:     meaning that when the sequence updates, so does the view.
 2695: 
 2696:         >>> seq = ['0', '1', '2']
 2697:         >>> view = SequenceView(seq)
 2698:         >>> view
 2699:         SequenceView(['0', '1', '2'])
 2700:         >>> seq.append('3')
 2701:         >>> view
 2702:         SequenceView(['0', '1', '2', '3'])
 2703: 
 2704:     Sequence views support indexing, slicing, and length queries. They act
 2705:     like the underlying sequence, except they don't allow assignment:
 2706: 
 2707:         >>> view[1]
 2708:         '1'
 2709:         >>> view[1:-1]
 2710:         ['1', '2']
 2711:         >>> len(view)
 2712:         4
 2713: 
 2714:     Sequence views are useful as an alternative to copying, as they don't
 2715:     require (much) extra storage.
 2716: 
 2717:     """
 2718: 
 2719:     def __init__(self, target):
 2720:         if not isinstance(target, Sequence):
 2721:             raise TypeError
 2722:         self._target = target
 2723: 
 2724:     def __getitem__(self, index):
 2725:         return self._target[index]
 2726: 
 2727:     def __len__(self):
 2728:         return len(self._target)
 2729: 
 2730:     def __repr__(self):
 2731:         return '{}({})'.format(self.__class__.__name__, repr(self._target))
 2732: 
 2733: 
 2734: class seekable:
 2735:     """Wrap an iterator to allow for seeking backward and forward. This
 2736:     progressively caches the items in the source iterable so they can be
 2737:     re-visited.
 2738: 
 2739:     Call :meth:`seek` with an index to seek to that position in the source
 2740:     iterable.
 2741: 
 2742:     To "reset" an iterator, seek to ``0``:
 2743: 
 2744:         >>> from itertools import count
 2745:         >>> it = seekable((str(n) for n in count()))
 2746:         >>> next(it), next(it), next(it)
 2747:         ('0', '1', '2')
 2748:         >>> it.seek(0)
 2749:         >>> next(it), next(it), next(it)
 2750:         ('0', '1', '2')
 2751:         >>> next(it)
 2752:         '3'
 2753: 
 2754:     You can also seek forward:
 2755: 
 2756:         >>> it = seekable((str(n) for n in range(20)))
 2757:         >>> it.seek(10)
 2758:         >>> next(it)
 2759:         '10'
 2760:         >>> it.seek(20)  # Seeking past the end of the source isn't a problem
 2761:         >>> list(it)
 2762:         []
 2763:         >>> it.seek(0)  # Resetting works even after hitting the end
 2764:         >>> next(it), next(it), next(it)
 2765:         ('0', '1', '2')
 2766: 
 2767:     Call :meth:`peek` to look ahead one item without advancing the iterator:
 2768: 
 2769:         >>> it = seekable('1234')
 2770:         >>> it.peek()
 2771:         '1'
 2772:         >>> list(it)
 2773:         ['1', '2', '3', '4']
 2774:         >>> it.peek(default='empty')
 2775:         'empty'
 2776: 
 2777:     Before the iterator is at its end, calling :func:`bool` on it will return
 2778:     ``True``. After it will return ``False``:
 2779: 
 2780:         >>> it = seekable('5678')
 2781:         >>> bool(it)
 2782:         True
 2783:         >>> list(it)
 2784:         ['5', '6', '7', '8']
 2785:         >>> bool(it)
 2786:         False
 2787: 
 2788:     You may view the contents of the cache with the :meth:`elements` method.
 2789:     That returns a :class:`SequenceView`, a view that updates automatically:
 2790: 
 2791:         >>> it = seekable((str(n) for n in range(10)))
 2792:         >>> next(it), next(it), next(it)
 2793:         ('0', '1', '2')
 2794:         >>> elements = it.elements()
 2795:         >>> elements
 2796:         SequenceView(['0', '1', '2'])
 2797:         >>> next(it)
 2798:         '3'
 2799:         >>> elements
 2800:         SequenceView(['0', '1', '2', '3'])
 2801: 
 2802:     By default, the cache grows as the source iterable progresses, so beware of
 2803:     wrapping very large or infinite iterables. Supply *maxlen* to limit the
 2804:     size of the cache (this of course limits how far back you can seek).
 2805: 
 2806:         >>> from itertools import count
 2807:         >>> it = seekable((str(n) for n in count()), maxlen=2)
 2808:         >>> next(it), next(it), next(it), next(it)
 2809:         ('0', '1', '2', '3')
 2810:         >>> list(it.elements())
 2811:         ['2', '3']
 2812:         >>> it.seek(0)
 2813:         >>> next(it), next(it), next(it), next(it)
 2814:         ('2', '3', '4', '5')
 2815:         >>> next(it)
 2816:         '6'
 2817: 
 2818:     """
 2819: 
 2820:     def __init__(self, iterable, maxlen=None):
 2821:         self._source = iter(iterable)
 2822:         if maxlen is None:
 2823:             self._cache = []
 2824:         else:
 2825:             self._cache = deque([], maxlen)
 2826:         self._index = None
 2827: 
 2828:     def __iter__(self):
 2829:         return self
 2830: 
 2831:     def __next__(self):
 2832:         if self._index is not None:
 2833:             try:
 2834:                 item = self._cache[self._index]
 2835:             except IndexError:
 2836:                 self._index = None
 2837:             else:
 2838:                 self._index += 1
 2839:                 return item
 2840: 
 2841:         item = next(self._source)
 2842:         self._cache.append(item)
 2843:         return item
 2844: 
 2845:     def __bool__(self):
 2846:         try:
 2847:             self.peek()
 2848:         except StopIteration:
 2849:             return False
 2850:         return True
 2851: 
 2852:     def peek(self, default=_marker):
 2853:         try:
 2854:             peeked = next(self)
 2855:         except StopIteration:
 2856:             if default is _marker:
 2857:                 raise
 2858:             return default
 2859:         if self._index is None:
 2860:             self._index = len(self._cache)
 2861:         self._index -= 1
 2862:         return peeked
 2863: 
 2864:     def elements(self):
 2865:         return SequenceView(self._cache)
 2866: 
 2867:     def seek(self, index):
 2868:         self._index = index
 2869:         remainder = index - len(self._cache)
 2870:         if remainder > 0:
 2871:             consume(self, remainder)
 2872: 
 2873: 
 2874: class run_length:
 2875:     """
 2876:     :func:`run_length.encode` compresses an iterable with run-length encoding.
 2877:     It yields groups of repeated items with the count of how many times they
 2878:     were repeated:
 2879: 
 2880:         >>> uncompressed = 'abbcccdddd'
 2881:         >>> list(run_length.encode(uncompressed))
 2882:         [('a', 1), ('b', 2), ('c', 3), ('d', 4)]
 2883: 
 2884:     :func:`run_length.decode` decompresses an iterable that was previously
 2885:     compressed with run-length encoding. It yields the items of the
 2886:     decompressed iterable:
 2887: 
 2888:         >>> compressed = [('a', 1), ('b', 2), ('c', 3), ('d', 4)]
 2889:         >>> list(run_length.decode(compressed))
 2890:         ['a', 'b', 'b', 'c', 'c', 'c', 'd', 'd', 'd', 'd']
 2891: 
 2892:     """
 2893: 
 2894:     @staticmethod
 2895:     def encode(iterable):
 2896:         return ((k, ilen(g)) for k, g in groupby(iterable))
 2897: 
 2898:     @staticmethod
 2899:     def decode(iterable):
 2900:         return chain.from_iterable(repeat(k, n) for k, n in iterable)
 2901: 
 2902: 
 2903: def exactly_n(iterable, n, predicate=bool):
 2904:     """Return ``True`` if exactly ``n`` items in the iterable are ``True``
 2905:     according to the *predicate* function.
 2906: 
 2907:         >>> exactly_n([True, True, False], 2)
 2908:         True
 2909:         >>> exactly_n([True, True, False], 1)
 2910:         False
 2911:         >>> exactly_n([0, 1, 2, 3, 4, 5], 3, lambda x: x < 3)
 2912:         True
 2913: 
 2914:     The iterable will be advanced until ``n + 1`` truthy items are encountered,
 2915:     so avoid calling it on infinite iterables.
 2916: 
 2917:     """
 2918:     return len(take(n + 1, filter(predicate, iterable))) == n
 2919: 
 2920: 
 2921: def circular_shifts(iterable):
 2922:     """Return a list of circular shifts of *iterable*.
 2923: 
 2924:     >>> circular_shifts(range(4))
 2925:     [(0, 1, 2, 3), (1, 2, 3, 0), (2, 3, 0, 1), (3, 0, 1, 2)]
 2926:     """
 2927:     lst = list(iterable)
 2928:     return take(len(lst), windowed(cycle(lst), len(lst)))
 2929: 
 2930: 
 2931: def make_decorator(wrapping_func, result_index=0):
 2932:     """Return a decorator version of *wrapping_func*, which is a function that
 2933:     modifies an iterable. *result_index* is the position in that function's
 2934:     signature where the iterable goes.
 2935: 
 2936:     This lets you use itertools on the "production end," i.e. at function
 2937:     definition. This can augment what the function returns without changing the
 2938:     function's code.
 2939: 
 2940:     For example, to produce a decorator version of :func:`chunked`:
 2941: 
 2942:         >>> from more_itertools import chunked
 2943:         >>> chunker = make_decorator(chunked, result_index=0)
 2944:         >>> @chunker(3)
 2945:         ... def iter_range(n):
 2946:         ...     return iter(range(n))
 2947:         ...
 2948:         >>> list(iter_range(9))
 2949:         [[0, 1, 2], [3, 4, 5], [6, 7, 8]]
 2950: 
 2951:     To only allow truthy items to be returned:
 2952: 
 2953:         >>> truth_serum = make_decorator(filter, result_index=1)
 2954:         >>> @truth_serum(bool)
 2955:         ... def boolean_test():
 2956:         ...     return [0, 1, '', ' ', False, True]
 2957:         ...
 2958:         >>> list(boolean_test())
 2959:         [1, ' ', True]
 2960: 
 2961:     The :func:`peekable` and :func:`seekable` wrappers make for practical
 2962:     decorators:
 2963: 
 2964:         >>> from more_itertools import peekable
 2965:         >>> peekable_function = make_decorator(peekable)
 2966:         >>> @peekable_function()
 2967:         ... def str_range(*args):
 2968:         ...     return (str(x) for x in range(*args))
 2969:         ...
 2970:         >>> it = str_range(1, 20, 2)
 2971:         >>> next(it), next(it), next(it)
 2972:         ('1', '3', '5')
 2973:         >>> it.peek()
 2974:         '7'
 2975:         >>> next(it)
 2976:         '7'
 2977: 
 2978:     """
 2979:     # See https://sites.google.com/site/bbayles/index/decorator_factory for
 2980:     # notes on how this works.
 2981:     def decorator(*wrapping_args, **wrapping_kwargs):
 2982:         def outer_wrapper(f):
 2983:             def inner_wrapper(*args, **kwargs):
 2984:                 result = f(*args, **kwargs)
 2985:                 wrapping_args_ = list(wrapping_args)
 2986:                 wrapping_args_.insert(result_index, result)
 2987:                 return wrapping_func(*wrapping_args_, **wrapping_kwargs)
 2988: 
 2989:             return inner_wrapper
 2990: 
 2991:         return outer_wrapper
 2992: 
 2993:     return decorator
 2994: 
 2995: 
 2996: def map_reduce(iterable, keyfunc, valuefunc=None, reducefunc=None):
 2997:     """Return a dictionary that maps the items in *iterable* to categories
 2998:     defined by *keyfunc*, transforms them with *valuefunc*, and
 2999:     then summarizes them by category with *reducefunc*.
 3000: 
 3001:     *valuefunc* defaults to the identity function if it is unspecified.
 3002:     If *reducefunc* is unspecified, no summarization takes place:
 3003: 
 3004:         >>> keyfunc = lambda x: x.upper()
 3005:         >>> result = map_reduce('abbccc', keyfunc)
 3006:         >>> sorted(result.items())
 3007:         [('A', ['a']), ('B', ['b', 'b']), ('C', ['c', 'c', 'c'])]
 3008: 
 3009:     Specifying *valuefunc* transforms the categorized items:
 3010: 
 3011:         >>> keyfunc = lambda x: x.upper()
 3012:         >>> valuefunc = lambda x: 1
 3013:         >>> result = map_reduce('abbccc', keyfunc, valuefunc)
 3014:         >>> sorted(result.items())
 3015:         [('A', [1]), ('B', [1, 1]), ('C', [1, 1, 1])]
 3016: 
 3017:     Specifying *reducefunc* summarizes the categorized items:
 3018: 
 3019:         >>> keyfunc = lambda x: x.upper()
 3020:         >>> valuefunc = lambda x: 1
 3021:         >>> reducefunc = sum
 3022:         >>> result = map_reduce('abbccc', keyfunc, valuefunc, reducefunc)
 3023:         >>> sorted(result.items())
 3024:         [('A', 1), ('B', 2), ('C', 3)]
 3025: 
 3026:     You may want to filter the input iterable before applying the map/reduce
 3027:     procedure:
 3028: 
 3029:         >>> all_items = range(30)
 3030:         >>> items = [x for x in all_items if 10 <= x <= 20]  # Filter
 3031:         >>> keyfunc = lambda x: x % 2  # Evens map to 0; odds to 1
 3032:         >>> categories = map_reduce(items, keyfunc=keyfunc)
 3033:         >>> sorted(categories.items())
 3034:         [(0, [10, 12, 14, 16, 18, 20]), (1, [11, 13, 15, 17, 19])]
 3035:         >>> summaries = map_reduce(items, keyfunc=keyfunc, reducefunc=sum)
 3036:         >>> sorted(summaries.items())
 3037:         [(0, 90), (1, 75)]
 3038: 
 3039:     Note that all items in the iterable are gathered into a list before the
 3040:     summarization step, which may require significant storage.
 3041: 
 3042:     The returned object is a :obj:`collections.defaultdict` with the
 3043:     ``default_factory`` set to ``None``, such that it behaves like a normal
 3044:     dictionary.
 3045: 
 3046:     """
 3047:     valuefunc = (lambda x: x) if (valuefunc is None) else valuefunc
 3048: 
 3049:     ret = defaultdict(list)
 3050:     for item in iterable:
 3051:         key = keyfunc(item)
 3052:         value = valuefunc(item)
 3053:         ret[key].append(value)
 3054: 
 3055:     if reducefunc is not None:
 3056:         for key, value_list in ret.items():
 3057:             ret[key] = reducefunc(value_list)
 3058: 
 3059:     ret.default_factory = None
 3060:     return ret
 3061: 
 3062: 
 3063: def rlocate(iterable, pred=bool, window_size=None):
 3064:     """Yield the index of each item in *iterable* for which *pred* returns
 3065:     ``True``, starting from the right and moving left.
 3066: 
 3067:     *pred* defaults to :func:`bool`, which will select truthy items:
 3068: 
 3069:         >>> list(rlocate([0, 1, 1, 0, 1, 0, 0]))  # Truthy at 1, 2, and 4
 3070:         [4, 2, 1]
 3071: 
 3072:     Set *pred* to a custom function to, e.g., find the indexes for a particular
 3073:     item:
 3074: 
 3075:         >>> iterable = iter('abcb')
 3076:         >>> pred = lambda x: x == 'b'
 3077:         >>> list(rlocate(iterable, pred))
 3078:         [3, 1]
 3079: 
 3080:     If *window_size* is given, then the *pred* function will be called with
 3081:     that many items. This enables searching for sub-sequences:
 3082: 
 3083:         >>> iterable = [0, 1, 2, 3, 0, 1, 2, 3, 0, 1, 2, 3]
 3084:         >>> pred = lambda *args: args == (1, 2, 3)
 3085:         >>> list(rlocate(iterable, pred=pred, window_size=3))
 3086:         [9, 5, 1]
 3087: 
 3088:     Beware, this function won't return anything for infinite iterables.
 3089:     If *iterable* is reversible, ``rlocate`` will reverse it and search from
 3090:     the right. Otherwise, it will search from the left and return the results
 3091:     in reverse order.
 3092: 
 3093:     See :func:`locate` to for other example applications.
 3094: 
 3095:     """
 3096:     if window_size is None:
 3097:         try:
 3098:             len_iter = len(iterable)
 3099:             return (len_iter - i - 1 for i in locate(reversed(iterable), pred))
 3100:         except TypeError:
 3101:             pass
 3102: 
 3103:     return reversed(list(locate(iterable, pred, window_size)))
 3104: 
 3105: 
 3106: def replace(iterable, pred, substitutes, count=None, window_size=1):
 3107:     """Yield the items from *iterable*, replacing the items for which *pred*
 3108:     returns ``True`` with the items from the iterable *substitutes*.
 3109: 
 3110:         >>> iterable = [1, 1, 0, 1, 1, 0, 1, 1]
 3111:         >>> pred = lambda x: x == 0
 3112:         >>> substitutes = (2, 3)
 3113:         >>> list(replace(iterable, pred, substitutes))
 3114:         [1, 1, 2, 3, 1, 1, 2, 3, 1, 1]
 3115: 
 3116:     If *count* is given, the number of replacements will be limited:
 3117: 
 3118:         >>> iterable = [1, 1, 0, 1, 1, 0, 1, 1, 0]
 3119:         >>> pred = lambda x: x == 0
 3120:         >>> substitutes = [None]
 3121:         >>> list(replace(iterable, pred, substitutes, count=2))
 3122:         [1, 1, None, 1, 1, None, 1, 1, 0]
 3123: 
 3124:     Use *window_size* to control the number of items passed as arguments to
 3125:     *pred*. This allows for locating and replacing subsequences.
 3126: 
 3127:         >>> iterable = [0, 1, 2, 5, 0, 1, 2, 5]
 3128:         >>> window_size = 3
 3129:         >>> pred = lambda *args: args == (0, 1, 2)  # 3 items passed to pred
 3130:         >>> substitutes = [3, 4] # Splice in these items
 3131:         >>> list(replace(iterable, pred, substitutes, window_size=window_size))
 3132:         [3, 4, 5, 3, 4, 5]
 3133: 
 3134:     """
 3135:     if window_size < 1:
 3136:         raise ValueError('window_size must be at least 1')
 3137: 
 3138:     # Save the substitutes iterable, since it's used more than once
 3139:     substitutes = tuple(substitutes)
 3140: 
 3141:     # Add padding such that the number of windows matches the length of the
 3142:     # iterable
 3143:     it = chain(iterable, [_marker] * (window_size - 1))
 3144:     windows = windowed(it, window_size)
 3145: 
 3146:     n = 0
 3147:     for w in windows:
 3148:         # If the current window matches our predicate (and we haven't hit
 3149:         # our maximum number of replacements), splice in the substitutes
 3150:         # and then consume the following windows that overlap with this one.
 3151:         # For example, if the iterable is (0, 1, 2, 3, 4...)
 3152:         # and the window size is 2, we have (0, 1), (1, 2), (2, 3)...
 3153:         # If the predicate matches on (0, 1), we need to zap (0, 1) and (1, 2)
 3154:         if pred(*w):
 3155:             if (count is None) or (n < count):
 3156:                 n += 1
 3157:                 yield from substitutes
 3158:                 consume(windows, window_size - 1)
 3159:                 continue
 3160: 
 3161:         # If there was no match (or we've reached the replacement limit),
 3162:         # yield the first item from the window.
 3163:         if w and (w[0] is not _marker):
 3164:             yield w[0]
 3165: 
 3166: 
 3167: def partitions(iterable):
 3168:     """Yield all possible order-preserving partitions of *iterable*.
 3169: 
 3170:     >>> iterable = 'abc'
 3171:     >>> for part in partitions(iterable):
 3172:     ...     print([''.join(p) for p in part])
 3173:     ['abc']
 3174:     ['a', 'bc']
 3175:     ['ab', 'c']
 3176:     ['a', 'b', 'c']
 3177: 
 3178:     This is unrelated to :func:`partition`.
 3179: 
 3180:     """
 3181:     sequence = list(iterable)
 3182:     n = len(sequence)
 3183:     for i in powerset(range(1, n)):
 3184:         yield [sequence[i:j] for i, j in zip((0,) + i, i + (n,))]
 3185: 
 3186: 
 3187: def set_partitions(iterable, k=None):
 3188:     """
 3189:     Yield the set partitions of *iterable* into *k* parts. Set partitions are
 3190:     not order-preserving.
 3191: 
 3192:     >>> iterable = 'abc'
 3193:     >>> for part in set_partitions(iterable, 2):
 3194:     ...     print([''.join(p) for p in part])
 3195:     ['a', 'bc']
 3196:     ['ab', 'c']
 3197:     ['b', 'ac']
 3198: 
 3199: 
 3200:     If *k* is not given, every set partition is generated.
 3201: 
 3202:     >>> iterable = 'abc'
 3203:     >>> for part in set_partitions(iterable):
 3204:     ...     print([''.join(p) for p in part])
 3205:     ['abc']
 3206:     ['a', 'bc']
 3207:     ['ab', 'c']
 3208:     ['b', 'ac']
 3209:     ['a', 'b', 'c']
 3210: 
 3211:     """
 3212:     L = list(iterable)
 3213:     n = len(L)
 3214:     if k is not None:
 3215:         if k < 1:
 3216:             raise ValueError(
 3217:                 "Can't partition in a negative or zero number of groups"
 3218:             )
 3219:         elif k > n:
 3220:             return
 3221: 
 3222:     def set_partitions_helper(L, k):
 3223:         n = len(L)
 3224:         if k == 1:
 3225:             yield [L]
 3226:         elif n == k:
 3227:             yield [[s] for s in L]
 3228:         else:
 3229:             e, *M = L
 3230:             for p in set_partitions_helper(M, k - 1):
 3231:                 yield [[e], *p]
 3232:             for p in set_partitions_helper(M, k):
 3233:                 for i in range(len(p)):
 3234:                     yield p[:i] + [[e] + p[i]] + p[i + 1 :]
 3235: 
 3236:     if k is None:
 3237:         for k in range(1, n + 1):
 3238:             yield from set_partitions_helper(L, k)
 3239:     else:
 3240:         yield from set_partitions_helper(L, k)
 3241: 
 3242: 
 3243: class time_limited:
 3244:     """
 3245:     Yield items from *iterable* until *limit_seconds* have passed.
 3246:     If the time limit expires before all items have been yielded, the
 3247:     ``timed_out`` parameter will be set to ``True``.
 3248: 
 3249:     >>> from time import sleep
 3250:     >>> def generator():
 3251:     ...     yield 1
 3252:     ...     yield 2
 3253:     ...     sleep(0.2)
 3254:     ...     yield 3
 3255:     >>> iterable = time_limited(0.1, generator())
 3256:     >>> list(iterable)
 3257:     [1, 2]
 3258:     >>> iterable.timed_out
 3259:     True
 3260: 
 3261:     Note that the time is checked before each item is yielded, and iteration
 3262:     stops if  the time elapsed is greater than *limit_seconds*. If your time
 3263:     limit is 1 second, but it takes 2 seconds to generate the first item from
 3264:     the iterable, the function will run for 2 seconds and not yield anything.
 3265: 
 3266:     """
 3267: 
 3268:     def __init__(self, limit_seconds, iterable):
 3269:         if limit_seconds < 0:
 3270:             raise ValueError('limit_seconds must be positive')
 3271:         self.limit_seconds = limit_seconds
 3272:         self._iterable = iter(iterable)
 3273:         self._start_time = monotonic()
 3274:         self.timed_out = False
 3275: 
 3276:     def __iter__(self):
 3277:         return self
 3278: 
 3279:     def __next__(self):
 3280:         item = next(self._iterable)
 3281:         if monotonic() - self._start_time > self.limit_seconds:
 3282:             self.timed_out = True
 3283:             raise StopIteration
 3284: 
 3285:         return item
 3286: 
 3287: 
 3288: def only(iterable, default=None, too_long=None):
 3289:     """If *iterable* has only one item, return it.
 3290:     If it has zero items, return *default*.
 3291:     If it has more than one item, raise the exception given by *too_long*,
 3292:     which is ``ValueError`` by default.
 3293: 
 3294:     >>> only([], default='missing')
 3295:     'missing'
 3296:     >>> only([1])
 3297:     1
 3298:     >>> only([1, 2])  # doctest: +IGNORE_EXCEPTION_DETAIL
 3299:     Traceback (most recent call last):
 3300:     ...
 3301:     ValueError: Expected exactly one item in iterable, but got 1, 2,
 3302:      and perhaps more.'
 3303:     >>> only([1, 2], too_long=TypeError)  # doctest: +IGNORE_EXCEPTION_DETAIL
 3304:     Traceback (most recent call last):
 3305:     ...
 3306:     TypeError
 3307: 
 3308:     Note that :func:`only` attempts to advance *iterable* twice to ensure there
 3309:     is only one item.  See :func:`spy` or :func:`peekable` to check
 3310:     iterable contents less destructively.
 3311:     """
 3312:     it = iter(iterable)
 3313:     first_value = next(it, default)
 3314: 
 3315:     try:
 3316:         second_value = next(it)
 3317:     except StopIteration:
 3318:         pass
 3319:     else:
 3320:         msg = (
 3321:             'Expected exactly one item in iterable, but got {!r}, {!r}, '
 3322:             'and perhaps more.'.format(first_value, second_value)
 3323:         )
 3324:         raise too_long or ValueError(msg)
 3325: 
 3326:     return first_value
 3327: 
 3328: 
 3329: def ichunked(iterable, n):
 3330:     """Break *iterable* into sub-iterables with *n* elements each.
 3331:     :func:`ichunked` is like :func:`chunked`, but it yields iterables
 3332:     instead of lists.
 3333: 
 3334:     If the sub-iterables are read in order, the elements of *iterable*
 3335:     won't be stored in memory.
 3336:     If they are read out of order, :func:`itertools.tee` is used to cache
 3337:     elements as necessary.
 3338: 
 3339:     >>> from itertools import count
 3340:     >>> all_chunks = ichunked(count(), 4)
 3341:     >>> c_1, c_2, c_3 = next(all_chunks), next(all_chunks), next(all_chunks)
 3342:     >>> list(c_2)  # c_1's elements have been cached; c_3's haven't been
 3343:     [4, 5, 6, 7]
 3344:     >>> list(c_1)
 3345:     [0, 1, 2, 3]
 3346:     >>> list(c_3)
 3347:     [8, 9, 10, 11]
 3348: 
 3349:     """
 3350:     source = iter(iterable)
 3351: 
 3352:     while True:
 3353:         # Check to see whether we're at the end of the source iterable
 3354:         item = next(source, _marker)
 3355:         if item is _marker:
 3356:             return
 3357: 
 3358:         # Clone the source and yield an n-length slice
 3359:         source, it = tee(chain([item], source))
 3360:         yield islice(it, n)
 3361: 
 3362:         # Advance the source iterable
 3363:         consume(source, n)
 3364: 
 3365: 
 3366: def distinct_combinations(iterable, r):
 3367:     """Yield the distinct combinations of *r* items taken from *iterable*.
 3368: 
 3369:         >>> list(distinct_combinations([0, 0, 1], 2))
 3370:         [(0, 0), (0, 1)]
 3371: 
 3372:     Equivalent to ``set(combinations(iterable))``, except duplicates are not
 3373:     generated and thrown away. For larger input sequences this is much more
 3374:     efficient.
 3375: 
 3376:     """
 3377:     if r < 0:
 3378:         raise ValueError('r must be non-negative')
 3379:     elif r == 0:
 3380:         yield ()
 3381:         return
 3382:     pool = tuple(iterable)
 3383:     generators = [unique_everseen(enumerate(pool), key=itemgetter(1))]
 3384:     current_combo = [None] * r
 3385:     level = 0
 3386:     while generators:
 3387:         try:
 3388:             cur_idx, p = next(generators[-1])
 3389:         except StopIteration:
 3390:             generators.pop()
 3391:             level -= 1
 3392:             continue
 3393:         current_combo[level] = p
 3394:         if level + 1 == r:
 3395:             yield tuple(current_combo)
 3396:         else:
 3397:             generators.append(
 3398:                 unique_everseen(
 3399:                     enumerate(pool[cur_idx + 1 :], cur_idx + 1),
 3400:                     key=itemgetter(1),
 3401:                 )
 3402:             )
 3403:             level += 1
 3404: 
 3405: 
 3406: def filter_except(validator, iterable, *exceptions):
 3407:     """Yield the items from *iterable* for which the *validator* function does
 3408:     not raise one of the specified *exceptions*.
 3409: 
 3410:     *validator* is called for each item in *iterable*.
 3411:     It should be a function that accepts one argument and raises an exception
 3412:     if that item is not valid.
 3413: 
 3414:     >>> iterable = ['1', '2', 'three', '4', None]
 3415:     >>> list(filter_except(int, iterable, ValueError, TypeError))
 3416:     ['1', '2', '4']
 3417: 
 3418:     If an exception other than one given by *exceptions* is raised by
 3419:     *validator*, it is raised like normal.
 3420:     """
 3421:     for item in iterable:
 3422:         try:
 3423:             validator(item)
 3424:         except exceptions:
 3425:             pass
 3426:         else:
 3427:             yield item
 3428: 
 3429: 
 3430: def map_except(function, iterable, *exceptions):
 3431:     """Transform each item from *iterable* with *function* and yield the
 3432:     result, unless *function* raises one of the specified *exceptions*.
 3433: 
 3434:     *function* is called to transform each item in *iterable*.
 3435:     It should accept one argument.
 3436: 
 3437:     >>> iterable = ['1', '2', 'three', '4', None]
 3438:     >>> list(map_except(int, iterable, ValueError, TypeError))
 3439:     [1, 2, 4]
 3440: 
 3441:     If an exception other than one given by *exceptions* is raised by
 3442:     *function*, it is raised like normal.
 3443:     """
 3444:     for item in iterable:
 3445:         try:
 3446:             yield function(item)
 3447:         except exceptions:
 3448:             pass
 3449: 
 3450: 
 3451: def map_if(iterable, pred, func, func_else=lambda x: x):
 3452:     """Evaluate each item from *iterable* using *pred*. If the result is
 3453:     equivalent to ``True``, transform the item with *func* and yield it.
 3454:     Otherwise, transform the item with *func_else* and yield it.
 3455: 
 3456:     *pred*, *func*, and *func_else* should each be functions that accept
 3457:     one argument. By default, *func_else* is the identity function.
 3458: 
 3459:     >>> from math import sqrt
 3460:     >>> iterable = list(range(-5, 5))
 3461:     >>> iterable
 3462:     [-5, -4, -3, -2, -1, 0, 1, 2, 3, 4]
 3463:     >>> list(map_if(iterable, lambda x: x > 3, lambda x: 'toobig'))
 3464:     [-5, -4, -3, -2, -1, 0, 1, 2, 3, 'toobig']
 3465:     >>> list(map_if(iterable, lambda x: x >= 0,
 3466:     ... lambda x: f'{sqrt(x):.2f}', lambda x: None))
 3467:     [None, None, None, None, None, '0.00', '1.00', '1.41', '1.73', '2.00']
 3468:     """
 3469:     for item in iterable:
 3470:         yield func(item) if pred(item) else func_else(item)
 3471: 
 3472: 
 3473: def _sample_unweighted(iterable, k):
 3474:     # Implementation of "Algorithm L" from the 1994 paper by Kim-Hung Li:
 3475:     # "Reservoir-Sampling Algorithms of Time Complexity O(n(1+log(N/n)))".
 3476: 
 3477:     # Fill up the reservoir (collection of samples) with the first `k` samples
 3478:     reservoir = take(k, iterable)
 3479: 
 3480:     # Generate random number that's the largest in a sample of k U(0,1) numbers
 3481:     # Largest order statistic: https://en.wikipedia.org/wiki/Order_statistic
 3482:     W = exp(log(random()) / k)
 3483: 
 3484:     # The number of elements to skip before changing the reservoir is a random
 3485:     # number with a geometric distribution. Sample it using random() and logs.
 3486:     next_index = k + floor(log(random()) / log(1 - W))
 3487: 
 3488:     for index, element in enumerate(iterable, k):
 3489: 
 3490:         if index == next_index:
 3491:             reservoir[randrange(k)] = element
 3492:             # The new W is the largest in a sample of k U(0, `old_W`) numbers
 3493:             W *= exp(log(random()) / k)
 3494:             next_index += floor(log(random()) / log(1 - W)) + 1
 3495: 
 3496:     return reservoir
 3497: 
 3498: 
 3499: def _sample_weighted(iterable, k, weights):
 3500:     # Implementation of "A-ExpJ" from the 2006 paper by Efraimidis et al. :
 3501:     # "Weighted random sampling with a reservoir".
 3502: 
 3503:     # Log-transform for numerical stability for weights that are small/large
 3504:     weight_keys = (log(random()) / weight for weight in weights)
 3505: 
 3506:     # Fill up the reservoir (collection of samples) with the first `k`
 3507:     # weight-keys and elements, then heapify the list.
 3508:     reservoir = take(k, zip(weight_keys, iterable))
 3509:     heapify(reservoir)
 3510: 
 3511:     # The number of jumps before changing the reservoir is a random variable
 3512:     # with an exponential distribution. Sample it using random() and logs.
 3513:     smallest_weight_key, _ = reservoir[0]
 3514:     weights_to_skip = log(random()) / smallest_weight_key
 3515: 
 3516:     for weight, element in zip(weights, iterable):
 3517:         if weight >= weights_to_skip:
 3518:             # The notation here is consistent with the paper, but we store
 3519:             # the weight-keys in log-space for better numerical stability.
 3520:             smallest_weight_key, _ = reservoir[0]
 3521:             t_w = exp(weight * smallest_weight_key)
 3522:             r_2 = uniform(t_w, 1)  # generate U(t_w, 1)
 3523:             weight_key = log(r_2) / weight
 3524:             heapreplace(reservoir, (weight_key, element))
 3525:             smallest_weight_key, _ = reservoir[0]
 3526:             weights_to_skip = log(random()) / smallest_weight_key
 3527:         else:
 3528:             weights_to_skip -= weight
 3529: 
 3530:     # Equivalent to [element for weight_key, element in sorted(reservoir)]
 3531:     return [heappop(reservoir)[1] for _ in range(k)]
 3532: 
 3533: 
 3534: def sample(iterable, k, weights=None):
 3535:     """Return a *k*-length list of elements chosen (without replacement)
 3536:     from the *iterable*. Like :func:`random.sample`, but works on iterables
 3537:     of unknown length.
 3538: 
 3539:     >>> iterable = range(100)
 3540:     >>> sample(iterable, 5)  # doctest: +SKIP
 3541:     [81, 60, 96, 16, 4]
 3542: 
 3543:     An iterable with *weights* may also be given:
 3544: 
 3545:     >>> iterable = range(100)
 3546:     >>> weights = (i * i + 1 for i in range(100))
 3547:     >>> sampled = sample(iterable, 5, weights=weights)  # doctest: +SKIP
 3548:     [79, 67, 74, 66, 78]
 3549: 
 3550:     The algorithm can also be used to generate weighted random permutations.
 3551:     The relative weight of each item determines the probability that it
 3552:     appears late in the permutation.
 3553: 
 3554:     >>> data = "abcdefgh"
 3555:     >>> weights = range(1, len(data) + 1)
 3556:     >>> sample(data, k=len(data), weights=weights)  # doctest: +SKIP
 3557:     ['c', 'a', 'b', 'e', 'g', 'd', 'h', 'f']
 3558:     """
 3559:     if k == 0:
 3560:         return []
 3561: 
 3562:     iterable = iter(iterable)
 3563:     if weights is None:
 3564:         return _sample_unweighted(iterable, k)
 3565:     else:
 3566:         weights = iter(weights)
 3567:         return _sample_weighted(iterable, k, weights)
 3568: 
 3569: 
 3570: def is_sorted(iterable, key=None, reverse=False, strict=False):
 3571:     """Returns ``True`` if the items of iterable are in sorted order, and
 3572:     ``False`` otherwise. *key* and *reverse* have the same meaning that they do
 3573:     in the built-in :func:`sorted` function.
 3574: 
 3575:     >>> is_sorted(['1', '2', '3', '4', '5'], key=int)
 3576:     True
 3577:     >>> is_sorted([5, 4, 3, 1, 2], reverse=True)
 3578:     False
 3579: 
 3580:     If *strict*, tests for strict sorting, that is, returns ``False`` if equal
 3581:     elements are found:
 3582: 
 3583:     >>> is_sorted([1, 2, 2])
 3584:     True
 3585:     >>> is_sorted([1, 2, 2], strict=True)
 3586:     False
 3587: 
 3588:     The function returns ``False`` after encountering the first out-of-order
 3589:     item. If there are no out-of-order items, the iterable is exhausted.
 3590:     """
 3591: 
 3592:     compare = (le if reverse else ge) if strict else (lt if reverse else gt)
 3593:     it = iterable if key is None else map(key, iterable)
 3594:     return not any(starmap(compare, pairwise(it)))
 3595: 
 3596: 
 3597: class AbortThread(BaseException):
 3598:     pass
 3599: 
 3600: 
 3601: class callback_iter:
 3602:     """Convert a function that uses callbacks to an iterator.
 3603: 
 3604:     Let *func* be a function that takes a `callback` keyword argument.
 3605:     For example:
 3606: 
 3607:     >>> def func(callback=None):
 3608:     ...     for i, c in [(1, 'a'), (2, 'b'), (3, 'c')]:
 3609:     ...         if callback:
 3610:     ...             callback(i, c)
 3611:     ...     return 4
 3612: 
 3613: 
 3614:     Use ``with callback_iter(func)`` to get an iterator over the parameters
 3615:     that are delivered to the callback.
 3616: 
 3617:     >>> with callback_iter(func) as it:
 3618:     ...     for args, kwargs in it:
 3619:     ...         print(args)
 3620:     (1, 'a')
 3621:     (2, 'b')
 3622:     (3, 'c')
 3623: 
 3624:     The function will be called in a background thread. The ``done`` property
 3625:     indicates whether it has completed execution.
 3626: 
 3627:     >>> it.done
 3628:     True
 3629: 
 3630:     If it completes successfully, its return value will be available
 3631:     in the ``result`` property.
 3632: 
 3633:     >>> it.result
 3634:     4
 3635: 
 3636:     Notes:
 3637: 
 3638:     * If the function uses some keyword argument besides ``callback``, supply
 3639:       *callback_kwd*.
 3640:     * If it finished executing, but raised an exception, accessing the
 3641:       ``result`` property will raise the same exception.
 3642:     * If it hasn't finished executing, accessing the ``result``
 3643:       property from within the ``with`` block will raise ``RuntimeError``.
 3644:     * If it hasn't finished executing, accessing the ``result`` property from
 3645:       outside the ``with`` block will raise a
 3646:       ``more_itertools.AbortThread`` exception.
 3647:     * Provide *wait_seconds* to adjust how frequently the it is polled for
 3648:       output.
 3649: 
 3650:     """
 3651: 
 3652:     def __init__(self, func, callback_kwd='callback', wait_seconds=0.1):
 3653:         self._func = func
 3654:         self._callback_kwd = callback_kwd
 3655:         self._aborted = False
 3656:         self._future = None
 3657:         self._wait_seconds = wait_seconds
 3658:         self._executor = __import__("concurrent.futures").futures.ThreadPoolExecutor(max_workers=1)
 3659:         self._iterator = self._reader()
 3660: 
 3661:     def __enter__(self):
 3662:         return self
 3663: 
 3664:     def __exit__(self, exc_type, exc_value, traceback):
 3665:         self._aborted = True
 3666:         self._executor.shutdown()
 3667: 
 3668:     def __iter__(self):
 3669:         return self
 3670: 
 3671:     def __next__(self):
 3672:         return next(self._iterator)
 3673: 
 3674:     @property
 3675:     def done(self):
 3676:         if self._future is None:
 3677:             return False
 3678:         return self._future.done()
 3679: 
 3680:     @property
 3681:     def result(self):
 3682:         if not self.done:
 3683:             raise RuntimeError('Function has not yet completed')
 3684: 
 3685:         return self._future.result()
 3686: 
 3687:     def _reader(self):
 3688:         q = Queue()
 3689: 
 3690:         def callback(*args, **kwargs):
 3691:             if self._aborted:
 3692:                 raise AbortThread('canceled by user')
 3693: 
 3694:             q.put((args, kwargs))
 3695: 
 3696:         self._future = self._executor.submit(
 3697:             self._func, **{self._callback_kwd: callback}
 3698:         )
 3699: 
 3700:         while True:
 3701:             try:
 3702:                 item = q.get(timeout=self._wait_seconds)
 3703:             except Empty:
 3704:                 pass
 3705:             else:
 3706:                 q.task_done()
 3707:                 yield item
 3708: 
 3709:             if self._future.done():
 3710:                 break
 3711: 
 3712:         remaining = []
 3713:         while True:
 3714:             try:
 3715:                 item = q.get_nowait()
 3716:             except Empty:
 3717:                 break
 3718:             else:
 3719:                 q.task_done()
 3720:                 remaining.append(item)
 3721:         q.join()
 3722:         yield from remaining
 3723: 
 3724: 
 3725: def windowed_complete(iterable, n):
 3726:     """
 3727:     Yield ``(beginning, middle, end)`` tuples, where:
 3728: 
 3729:     * Each ``middle`` has *n* items from *iterable*
 3730:     * Each ``beginning`` has the items before the ones in ``middle``
 3731:     * Each ``end`` has the items after the ones in ``middle``
 3732: 
 3733:     >>> iterable = range(7)
 3734:     >>> n = 3
 3735:     >>> for beginning, middle, end in windowed_complete(iterable, n):
 3736:     ...     print(beginning, middle, end)
 3737:     () (0, 1, 2) (3, 4, 5, 6)
 3738:     (0,) (1, 2, 3) (4, 5, 6)
 3739:     (0, 1) (2, 3, 4) (5, 6)
 3740:     (0, 1, 2) (3, 4, 5) (6,)
 3741:     (0, 1, 2, 3) (4, 5, 6) ()
 3742: 
 3743:     Note that *n* must be at least 0 and most equal to the length of
 3744:     *iterable*.
 3745: 
 3746:     This function will exhaust the iterable and may require significant
 3747:     storage.
 3748:     """
 3749:     if n < 0:
 3750:         raise ValueError('n must be >= 0')
 3751: 
 3752:     seq = tuple(iterable)
 3753:     size = len(seq)
 3754: 
 3755:     if n > size:
 3756:         raise ValueError('n must be <= len(seq)')
 3757: 
 3758:     for i in range(size - n + 1):
 3759:         beginning = seq[:i]
 3760:         middle = seq[i : i + n]
 3761:         end = seq[i + n :]
 3762:         yield beginning, middle, end
 3763: 
 3764: 
 3765: def all_unique(iterable, key=None):
 3766:     """
 3767:     Returns ``True`` if all the elements of *iterable* are unique (no two
 3768:     elements are equal).
 3769: 
 3770:         >>> all_unique('ABCB')
 3771:         False
 3772: 
 3773:     If a *key* function is specified, it will be used to make comparisons.
 3774: 
 3775:         >>> all_unique('ABCb')
 3776:         True
 3777:         >>> all_unique('ABCb', str.lower)
 3778:         False
 3779: 
 3780:     The function returns as soon as the first non-unique element is
 3781:     encountered. Iterables with a mix of hashable and unhashable items can
 3782:     be used, but the function will be slower for unhashable items.
 3783:     """
 3784:     seenset = set()
 3785:     seenset_add = seenset.add
 3786:     seenlist = []
 3787:     seenlist_add = seenlist.append
 3788:     for element in map(key, iterable) if key else iterable:
 3789:         try:
 3790:             if element in seenset:
 3791:                 return False
 3792:             seenset_add(element)
 3793:         except TypeError:
 3794:             if element in seenlist:
 3795:                 return False
 3796:             seenlist_add(element)
 3797:     return True
 3798: 
 3799: 
 3800: def nth_product(index, *args):
 3801:     """Equivalent to ``list(product(*args))[index]``.
 3802: 
 3803:     The products of *args* can be ordered lexicographically.
 3804:     :func:`nth_product` computes the product at sort position *index* without
 3805:     computing the previous products.
 3806: 
 3807:         >>> nth_product(8, range(2), range(2), range(2), range(2))
 3808:         (1, 0, 0, 0)
 3809: 
 3810:     ``IndexError`` will be raised if the given *index* is invalid.
 3811:     """
 3812:     pools = list(map(tuple, reversed(args)))
 3813:     ns = list(map(len, pools))
 3814: 
 3815:     c = reduce(mul, ns)
 3816: 
 3817:     if index < 0:
 3818:         index += c
 3819: 
 3820:     if not 0 <= index < c:
 3821:         raise IndexError
 3822: 
 3823:     result = []
 3824:     for pool, n in zip(pools, ns):
 3825:         result.append(pool[index % n])
 3826:         index //= n
 3827: 
 3828:     return tuple(reversed(result))
 3829: 
 3830: 
 3831: def nth_permutation(iterable, r, index):
 3832:     """Equivalent to ``list(permutations(iterable, r))[index]```
 3833: 
 3834:     The subsequences of *iterable* that are of length *r* where order is
 3835:     important can be ordered lexicographically. :func:`nth_permutation`
 3836:     computes the subsequence at sort position *index* directly, without
 3837:     computing the previous subsequences.
 3838: 
 3839:         >>> nth_permutation('ghijk', 2, 5)
 3840:         ('h', 'i')
 3841: 
 3842:     ``ValueError`` will be raised If *r* is negative or greater than the length
 3843:     of *iterable*.
 3844:     ``IndexError`` will be raised if the given *index* is invalid.
 3845:     """
 3846:     pool = list(iterable)
 3847:     n = len(pool)
 3848: 
 3849:     if r is None or r == n:
 3850:         r, c = n, factorial(n)
 3851:     elif not 0 <= r < n:
 3852:         raise ValueError
 3853:     else:
 3854:         c = factorial(n) // factorial(n - r)
 3855: 
 3856:     if index < 0:
 3857:         index += c
 3858: 
 3859:     if not 0 <= index < c:
 3860:         raise IndexError
 3861: 
 3862:     if c == 0:
 3863:         return tuple()
 3864: 
 3865:     result = [0] * r
 3866:     q = index * factorial(n) // c if r < n else index
 3867:     for d in range(1, n + 1):
 3868:         q, i = divmod(q, d)
 3869:         if 0 <= n - d < r:
 3870:             result[n - d] = i
 3871:         if q == 0:
 3872:             break
 3873: 
 3874:     return tuple(map(pool.pop, result))
 3875: 
 3876: 
 3877: def value_chain(*args):
 3878:     """Yield all arguments passed to the function in the same order in which
 3879:     they were passed. If an argument itself is iterable then iterate over its
 3880:     values.
 3881: 
 3882:         >>> list(value_chain(1, 2, 3, [4, 5, 6]))
 3883:         [1, 2, 3, 4, 5, 6]
 3884: 
 3885:     Binary and text strings are not considered iterable and are emitted
 3886:     as-is:
 3887: 
 3888:         >>> list(value_chain('12', '34', ['56', '78']))
 3889:         ['12', '34', '56', '78']
 3890: 
 3891: 
 3892:     Multiple levels of nesting are not flattened.
 3893: 
 3894:     """
 3895:     for value in args:
 3896:         if isinstance(value, (str, bytes)):
 3897:             yield value
 3898:             continue
 3899:         try:
 3900:             yield from value
 3901:         except TypeError:
 3902:             yield value
 3903: 
 3904: 
 3905: def product_index(element, *args):
 3906:     """Equivalent to ``list(product(*args)).index(element)``
 3907: 
 3908:     The products of *args* can be ordered lexicographically.
 3909:     :func:`product_index` computes the first index of *element* without
 3910:     computing the previous products.
 3911: 
 3912:         >>> product_index([8, 2], range(10), range(5))
 3913:         42
 3914: 
 3915:     ``ValueError`` will be raised if the given *element* isn't in the product
 3916:     of *args*.
 3917:     """
 3918:     index = 0
 3919: 
 3920:     for x, pool in zip_longest(element, args, fillvalue=_marker):
 3921:         if x is _marker or pool is _marker:
 3922:             raise ValueError('element is not a product of args')
 3923: 
 3924:         pool = tuple(pool)
 3925:         index = index * len(pool) + pool.index(x)
 3926: 
 3927:     return index
 3928: 
 3929: 
 3930: def combination_index(element, iterable):
 3931:     """Equivalent to ``list(combinations(iterable, r)).index(element)``
 3932: 
 3933:     The subsequences of *iterable* that are of length *r* can be ordered
 3934:     lexicographically. :func:`combination_index` computes the index of the
 3935:     first *element*, without computing the previous combinations.
 3936: 
 3937:         >>> combination_index('adf', 'abcdefg')
 3938:         10
 3939: 
 3940:     ``ValueError`` will be raised if the given *element* isn't one of the
 3941:     combinations of *iterable*.
 3942:     """
 3943:     element = enumerate(element)
 3944:     k, y = next(element, (None, None))
 3945:     if k is None:
 3946:         return 0
 3947: 
 3948:     indexes = []
 3949:     pool = enumerate(iterable)
 3950:     for n, x in pool:
 3951:         if x == y:
 3952:             indexes.append(n)
 3953:             tmp, y = next(element, (None, None))
 3954:             if tmp is None:
 3955:                 break
 3956:             else:
 3957:                 k = tmp
 3958:     else:
 3959:         raise ValueError('element is not a combination of iterable')
 3960: 
 3961:     n, _ = last(pool, default=(n, None))
 3962: 
 3963:     # Python versiosn below 3.8 don't have math.comb
 3964:     index = 1
 3965:     for i, j in enumerate(reversed(indexes), start=1):
 3966:         j = n - j
 3967:         if i <= j:
 3968:             index += factorial(j) // (factorial(i) * factorial(j - i))
 3969: 
 3970:     return factorial(n + 1) // (factorial(k + 1) * factorial(n - k)) - index
 3971: 
 3972: 
 3973: def permutation_index(element, iterable):
 3974:     """Equivalent to ``list(permutations(iterable, r)).index(element)```
 3975: 
 3976:     The subsequences of *iterable* that are of length *r* where order is
 3977:     important can be ordered lexicographically. :func:`permutation_index`
 3978:     computes the index of the first *element* directly, without computing
 3979:     the previous permutations.
 3980: 
 3981:         >>> permutation_index([1, 3, 2], range(5))
 3982:         19
 3983: 
 3984:     ``ValueError`` will be raised if the given *element* isn't one of the
 3985:     permutations of *iterable*.
 3986:     """
 3987:     index = 0
 3988:     pool = list(iterable)
 3989:     for i, x in zip(range(len(pool), -1, -1), element):
 3990:         r = pool.index(x)
 3991:         index = index * i + r
 3992:         del pool[r]
 3993: 
 3994:     return index
 3995: 
 3996: 
 3997: class countable:
 3998:     """Wrap *iterable* and keep a count of how many items have been consumed.
 3999: 
 4000:     The ``items_seen`` attribute starts at ``0`` and increments as the iterable
 4001:     is consumed:
 4002: 
 4003:         >>> iterable = map(str, range(10))
 4004:         >>> it = countable(iterable)
 4005:         >>> it.items_seen
 4006:         0
 4007:         >>> next(it), next(it)
 4008:         ('0', '1')
 4009:         >>> list(it)
 4010:         ['2', '3', '4', '5', '6', '7', '8', '9']
 4011:         >>> it.items_seen
 4012:         10
 4013:     """
 4014: 
 4015:     def __init__(self, iterable):
 4016:         self._it = iter(iterable)
 4017:         self.items_seen = 0
 4018: 
 4019:     def __iter__(self):
 4020:         return self
 4021: 
 4022:     def __next__(self):
 4023:         item = next(self._it)
 4024:         self.items_seen += 1
 4025: 
 4026:         return item
 4027: 
 4028: 
 4029: def chunked_even(iterable, n):
 4030:     """Break *iterable* into lists of approximately length *n*.
 4031:     Items are distributed such the lengths of the lists differ by at most
 4032:     1 item.
 4033: 
 4034:     >>> iterable = [1, 2, 3, 4, 5, 6, 7]
 4035:     >>> n = 3
 4036:     >>> list(chunked_even(iterable, n))  # List lengths: 3, 2, 2
 4037:     [[1, 2, 3], [4, 5], [6, 7]]
 4038:     >>> list(chunked(iterable, n))  # List lengths: 3, 3, 1
 4039:     [[1, 2, 3], [4, 5, 6], [7]]
 4040: 
 4041:     """
 4042: 
 4043:     len_method = getattr(iterable, '__len__', None)
 4044: 
 4045:     if len_method is None:
 4046:         return _chunked_even_online(iterable, n)
 4047:     else:
 4048:         return _chunked_even_finite(iterable, len_method(), n)
 4049: 
 4050: 
 4051: def _chunked_even_online(iterable, n):
 4052:     buffer = []
 4053:     maxbuf = n + (n - 2) * (n - 1)
 4054:     for x in iterable:
 4055:         buffer.append(x)
 4056:         if len(buffer) == maxbuf:
 4057:             yield buffer[:n]
 4058:             buffer = buffer[n:]
 4059:     yield from _chunked_even_finite(buffer, len(buffer), n)
 4060: 
 4061: 
 4062: def _chunked_even_finite(iterable, N, n):
 4063:     if N < 1:
 4064:         return
 4065: 
 4066:     # Lists are either size `full_size <= n` or `partial_size = full_size - 1`
 4067:     q, r = divmod(N, n)
 4068:     num_lists = q + (1 if r > 0 else 0)
 4069:     q, r = divmod(N, num_lists)
 4070:     full_size = q + (1 if r > 0 else 0)
 4071:     partial_size = full_size - 1
 4072:     num_full = N - partial_size * num_lists
 4073:     num_partial = num_lists - num_full
 4074: 
 4075:     buffer = []
 4076:     iterator = iter(iterable)
 4077: 
 4078:     # Yield num_full lists of full_size
 4079:     for x in iterator:
 4080:         buffer.append(x)
 4081:         if len(buffer) == full_size:
 4082:             yield buffer
 4083:             buffer = []
 4084:             num_full -= 1
 4085:             if num_full <= 0:
 4086:                 break
 4087: 
 4088:     # Yield num_partial lists of partial_size
 4089:     for x in iterator:
 4090:         buffer.append(x)
 4091:         if len(buffer) == partial_size:
 4092:             yield buffer
 4093:             buffer = []
 4094:             num_partial -= 1
 4095: 
 4096: 
 4097: def zip_broadcast(*objects, scalar_types=(str, bytes), strict=False):
 4098:     """A version of :func:`zip` that "broadcasts" any scalar
 4099:     (i.e., non-iterable) items into output tuples.
 4100: 
 4101:     >>> iterable_1 = [1, 2, 3]
 4102:     >>> iterable_2 = ['a', 'b', 'c']
 4103:     >>> scalar = '_'
 4104:     >>> list(zip_broadcast(iterable_1, iterable_2, scalar))
 4105:     [(1, 'a', '_'), (2, 'b', '_'), (3, 'c', '_')]
 4106: 
 4107:     The *scalar_types* keyword argument determines what types are considered
 4108:     scalar. It is set to ``(str, bytes)`` by default. Set it to ``None`` to
 4109:     treat strings and byte strings as iterable:
 4110: 
 4111:     >>> list(zip_broadcast('abc', 0, 'xyz', scalar_types=None))
 4112:     [('a', 0, 'x'), ('b', 0, 'y'), ('c', 0, 'z')]
 4113: 
 4114:     If the *strict* keyword argument is ``True``, then
 4115:     ``UnequalIterablesError`` will be raised if any of the iterables have
 4116:     different lengthss.
 4117:     """
 4118: 
 4119:     def is_scalar(obj):
 4120:         if scalar_types and isinstance(obj, scalar_types):
 4121:             return True
 4122:         try:
 4123:             iter(obj)
 4124:         except TypeError:
 4125:             return True
 4126:         else:
 4127:             return False
 4128: 
 4129:     size = len(objects)
 4130:     if not size:
 4131:         return
 4132: 
 4133:     iterables, iterable_positions = [], []
 4134:     scalars, scalar_positions = [], []
 4135:     for i, obj in enumerate(objects):
 4136:         if is_scalar(obj):
 4137:             scalars.append(obj)
 4138:             scalar_positions.append(i)
 4139:         else:
 4140:             iterables.append(iter(obj))
 4141:             iterable_positions.append(i)
 4142: 
 4143:     if len(scalars) == size:
 4144:         yield tuple(objects)
 4145:         return
 4146: 
 4147:     zipper = _zip_equal if strict else zip
 4148:     for item in zipper(*iterables):
 4149:         new_item = [None] * size
 4150: 
 4151:         for i, elem in zip(iterable_positions, item):
 4152:             new_item[i] = elem
 4153: 
 4154:         for i, elem in zip(scalar_positions, scalars):
 4155:             new_item[i] = elem
 4156: 
 4157:         yield tuple(new_item)
 4158: 
 4159: 
 4160: def unique_in_window(iterable, n, key=None):
 4161:     """Yield the items from *iterable* that haven't been seen recently.
 4162:     *n* is the size of the lookback window.
 4163: 
 4164:         >>> iterable = [0, 1, 0, 2, 3, 0]
 4165:         >>> n = 3
 4166:         >>> list(unique_in_window(iterable, n))
 4167:         [0, 1, 2, 3, 0]
 4168: 
 4169:     The *key* function, if provided, will be used to determine uniqueness:
 4170: 
 4171:         >>> list(unique_in_window('abAcda', 3, key=lambda x: x.lower()))
 4172:         ['a', 'b', 'c', 'd', 'a']
 4173: 
 4174:     The items in *iterable* must be hashable.
 4175: 
 4176:     """
 4177:     if n <= 0:
 4178:         raise ValueError('n must be greater than 0')
 4179: 
 4180:     window = deque(maxlen=n)
 4181:     uniques = set()
 4182:     use_key = key is not None
 4183: 
 4184:     for item in iterable:
 4185:         k = key(item) if use_key else item
 4186:         if k in uniques:
 4187:             continue
 4188: 
 4189:         if len(uniques) == n:
 4190:             uniques.discard(window[0])
 4191: 
 4192:         uniques.add(k)
 4193:         window.append(k)
 4194: 
 4195:         yield item
 4196: 
 4197: 
 4198: def duplicates_everseen(iterable, key=None):
 4199:     """Yield duplicate elements after their first appearance.
 4200: 
 4201:     >>> list(duplicates_everseen('mississippi'))
 4202:     ['s', 'i', 's', 's', 'i', 'p', 'i']
 4203:     >>> list(duplicates_everseen('AaaBbbCccAaa', str.lower))
 4204:     ['a', 'a', 'b', 'b', 'c', 'c', 'A', 'a', 'a']
 4205: 
 4206:     This function is analagous to :func:`unique_everseen` and is subject to
 4207:     the same performance considerations.
 4208: 
 4209:     """
 4210:     seen_set = set()
 4211:     seen_list = []
 4212:     use_key = key is not None
 4213: 
 4214:     for element in iterable:
 4215:         k = key(element) if use_key else element
 4216:         try:
 4217:             if k not in seen_set:
 4218:                 seen_set.add(k)
 4219:             else:
 4220:                 yield element
 4221:         except TypeError:
 4222:             if k not in seen_list:
 4223:                 seen_list.append(k)
 4224:             else:
 4225:                 yield element
 4226: 
 4227: 
 4228: def duplicates_justseen(iterable, key=None):
 4229:     """Yields serially-duplicate elements after their first appearance.
 4230: 
 4231:     >>> list(duplicates_justseen('mississippi'))
 4232:     ['s', 's', 'p']
 4233:     >>> list(duplicates_justseen('AaaBbbCccAaa', str.lower))
 4234:     ['a', 'a', 'b', 'b', 'c', 'c', 'a', 'a']
 4235: 
 4236:     This function is analagous to :func:`unique_justseen`.
 4237: 
 4238:     """
 4239:     return flatten(
 4240:         map(
 4241:             lambda group_tuple: islice_extended(group_tuple[1])[1:],
 4242:             groupby(iterable, key),
 4243:         )
 4244:     )
 4245: 
 4246: 
 4247: def minmax(iterable_or_value, *others, key=None, default=_marker):
 4248:     """Returns both the smallest and largest items in an iterable
 4249:     or the largest of two or more arguments.
 4250: 
 4251:         >>> minmax([3, 1, 5])
 4252:         (1, 5)
 4253: 
 4254:         >>> minmax(4, 2, 6)
 4255:         (2, 6)
 4256: 
 4257:     If a *key* function is provided, it will be used to transform the input
 4258:     items for comparison.
 4259: 
 4260:         >>> minmax([5, 30], key=str)  # '30' sorts before '5'
 4261:         (30, 5)
 4262: 
 4263:     If a *default* value is provided, it will be returned if there are no
 4264:     input items.
 4265: 
 4266:         >>> minmax([], default=(0, 0))
 4267:         (0, 0)
 4268: 
 4269:     Otherwise ``ValueError`` is raised.
 4270: 
 4271:     This function is based on the
 4272:     `recipe <http://code.activestate.com/recipes/577916/>`__ by
 4273:     Raymond Hettinger and takes care to minimize the number of comparisons
 4274:     performed.
 4275:     """
 4276:     iterable = (iterable_or_value, *others) if others else iterable_or_value
 4277: 
 4278:     it = iter(iterable)
 4279: 
 4280:     try:
 4281:         lo = hi = next(it)
 4282:     except StopIteration as e:
 4283:         if default is _marker:
 4284:             raise ValueError(
 4285:                 '`minmax()` argument is an empty iterable. '
 4286:                 'Provide a `default` value to suppress this error.'
 4287:             ) from e
 4288:         return default
 4289: 
 4290:     # Different branches depending on the presence of key. This saves a lot
 4291:     # of unimportant copies which would slow the "key=None" branch
 4292:     # significantly down.
 4293:     if key is None:
 4294:         for x, y in zip_longest(it, it, fillvalue=lo):
 4295:             if y < x:
 4296:                 x, y = y, x
 4297:             if x < lo:
 4298:                 lo = x
 4299:             if hi < y:
 4300:                 hi = y
 4301: 
 4302:     else:
 4303:         lo_key = hi_key = key(lo)
 4304: 
 4305:         for x, y in zip_longest(it, it, fillvalue=lo):
 4306: 
 4307:             x_key, y_key = key(x), key(y)
 4308: 
 4309:             if y_key < x_key:
 4310:                 x, y, x_key, y_key = y, x, y_key, x_key
 4311:             if x_key < lo_key:
 4312:                 lo, lo_key = x, x_key
 4313:             if hi_key < y_key:
 4314:                 hi, hi_key = y, y_key
 4315: 
 4316:     return lo, hi
