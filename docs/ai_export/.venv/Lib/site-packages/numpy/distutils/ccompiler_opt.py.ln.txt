    1: """Provides the `CCompilerOpt` class, used for handling the CPU/hardware
    2: optimization, starting from parsing the command arguments, to managing the
    3: relation between the CPU baseline and dispatch-able features,
    4: also generating the required C headers and ending with compiling
    5: the sources with proper compiler's flags.
    6: 
    7: `CCompilerOpt` doesn't provide runtime detection for the CPU features,
    8: instead only focuses on the compiler side, but it creates abstract C headers
    9: that can be used later for the final runtime dispatching process."""
   10: 
   11: import atexit
   12: import inspect
   13: import os
   14: import pprint
   15: import re
   16: import subprocess
   17: import textwrap
   18: 
   19: class _Config:
   20:     """An abstract class holds all configurable attributes of `CCompilerOpt`,
   21:     these class attributes can be used to change the default behavior
   22:     of `CCompilerOpt` in order to fit other requirements.
   23: 
   24:     Attributes
   25:     ----------
   26:     conf_nocache : bool
   27:         Set True to disable memory and file cache.
   28:         Default is False.
   29: 
   30:     conf_noopt : bool
   31:         Set True to forces the optimization to be disabled,
   32:         in this case `CCompilerOpt` tends to generate all
   33:         expected headers in order to 'not' break the build.
   34:         Default is False.
   35: 
   36:     conf_cache_factors : list
   37:         Add extra factors to the primary caching factors. The caching factors
   38:         are utilized to determine if there are changes had happened that
   39:         requires to discard the cache and re-updating it. The primary factors
   40:         are the arguments of `CCompilerOpt` and `CCompiler`'s properties(type, flags, etc).
   41:         Default is list of two items, containing the time of last modification
   42:         of `ccompiler_opt` and value of attribute "conf_noopt"
   43: 
   44:     conf_tmp_path : str,
   45:         The path of temporary directory. Default is auto-created
   46:         temporary directory via ``tempfile.mkdtemp()``.
   47: 
   48:     conf_check_path : str
   49:         The path of testing files. Each added CPU feature must have a
   50:         **C** source file contains at least one intrinsic or instruction that
   51:         related to this feature, so it can be tested against the compiler.
   52:         Default is ``./distutils/checks``.
   53: 
   54:     conf_target_groups : dict
   55:         Extra tokens that can be reached from dispatch-able sources through
   56:         the special mark ``@targets``. Default is an empty dictionary.
   57: 
   58:         **Notes**:
   59:             - case-insensitive for tokens and group names
   60:             - sign '#' must stick in the begin of group name and only within ``@targets``
   61: 
   62:         **Example**:
   63:             .. code-block:: console
   64: 
   65:                 $ "@targets #avx_group other_tokens" > group_inside.c
   66: 
   67:             >>> CCompilerOpt.conf_target_groups["avx_group"] = \\
   68:             "$werror $maxopt avx2 avx512f avx512_skx"
   69:             >>> cco = CCompilerOpt(cc_instance)
   70:             >>> cco.try_dispatch(["group_inside.c"])
   71: 
   72:     conf_c_prefix : str
   73:         The prefix of public C definitions. Default is ``"NPY_"``.
   74: 
   75:     conf_c_prefix_ : str
   76:         The prefix of internal C definitions. Default is ``"NPY__"``.
   77: 
   78:     conf_cc_flags : dict
   79:         Nested dictionaries defining several compiler flags
   80:         that linked to some major functions, the main key
   81:         represent the compiler name and sub-keys represent
   82:         flags names. Default is already covers all supported
   83:         **C** compilers.
   84: 
   85:         Sub-keys explained as follows:
   86: 
   87:         "native": str or None
   88:             used by argument option `native`, to detect the current
   89:             machine support via the compiler.
   90:         "werror": str or None
   91:             utilized to treat warning as errors during testing CPU features
   92:             against the compiler and also for target's policy `$werror`
   93:             via dispatch-able sources.
   94:         "maxopt": str or None
   95:             utilized for target's policy '$maxopt' and the value should
   96:             contains the maximum acceptable optimization by the compiler.
   97:             e.g. in gcc ``'-O3'``
   98: 
   99:         **Notes**:
  100:             * case-sensitive for compiler names and flags
  101:             * use space to separate multiple flags
  102:             * any flag will tested against the compiler and it will skipped
  103:               if it's not applicable.
  104: 
  105:     conf_min_features : dict
  106:         A dictionary defines the used CPU features for
  107:         argument option ``'min'``, the key represent the CPU architecture
  108:         name e.g. ``'x86'``. Default values provide the best effort
  109:         on wide range of users platforms.
  110: 
  111:         **Note**: case-sensitive for architecture names.
  112: 
  113:     conf_features : dict
  114:         Nested dictionaries used for identifying the CPU features.
  115:         the primary key is represented as a feature name or group name
  116:         that gathers several features. Default values covers all
  117:         supported features but without the major options like "flags",
  118:         these undefined options handle it by method `conf_features_partial()`.
  119:         Default value is covers almost all CPU features for *X86*, *IBM/Power64*
  120:         and *ARM 7/8*.
  121: 
  122:         Sub-keys explained as follows:
  123: 
  124:         "implies" : str or list, optional,
  125:             List of CPU feature names to be implied by it,
  126:             the feature name must be defined within `conf_features`.
  127:             Default is None.
  128: 
  129:         "flags": str or list, optional
  130:             List of compiler flags. Default is None.
  131: 
  132:         "detect": str or list, optional
  133:             List of CPU feature names that required to be detected
  134:             in runtime. By default, its the feature name or features
  135:             in "group" if its specified.
  136: 
  137:         "implies_detect": bool, optional
  138:             If True, all "detect" of implied features will be combined.
  139:             Default is True. see `feature_detect()`.
  140: 
  141:         "group": str or list, optional
  142:             Same as "implies" but doesn't require the feature name to be
  143:             defined within `conf_features`.
  144: 
  145:         "interest": int, required
  146:             a key for sorting CPU features
  147: 
  148:         "headers": str or list, optional
  149:             intrinsics C header file
  150: 
  151:         "disable": str, optional
  152:             force disable feature, the string value should contains the
  153:             reason of disabling.
  154: 
  155:         "autovec": bool or None, optional
  156:             True or False to declare that CPU feature can be auto-vectorized
  157:             by the compiler.
  158:             By default(None), treated as True if the feature contains at
  159:             least one applicable flag. see `feature_can_autovec()`
  160: 
  161:         "extra_checks": str or list, optional
  162:             Extra test case names for the CPU feature that need to be tested
  163:             against the compiler.
  164: 
  165:             Each test case must have a C file named ``extra_xxxx.c``, where
  166:             ``xxxx`` is the case name in lower case, under 'conf_check_path'.
  167:             It should contain at least one intrinsic or function related to the test case.
  168: 
  169:             If the compiler able to successfully compile the C file then `CCompilerOpt`
  170:             will add a C ``#define`` for it into the main dispatch header, e.g.
  171:             ``#define {conf_c_prefix}_XXXX`` where ``XXXX`` is the case name in upper case.
  172: 
  173:         **NOTES**:
  174:             * space can be used as separator with options that supports "str or list"
  175:             * case-sensitive for all values and feature name must be in upper-case.
  176:             * if flags aren't applicable, its will skipped rather than disable the
  177:               CPU feature
  178:             * the CPU feature will disabled if the compiler fail to compile
  179:               the test file
  180:     """
  181:     conf_nocache = False
  182:     conf_noopt = False
  183:     conf_cache_factors = None
  184:     conf_tmp_path = None
  185:     conf_check_path = os.path.join(
  186:         os.path.dirname(os.path.realpath(__file__)), "checks"
  187:     )
  188:     conf_target_groups = {}
  189:     conf_c_prefix = 'NPY_'
  190:     conf_c_prefix_ = 'NPY__'
  191:     conf_cc_flags = dict(
  192:         gcc = dict(
  193:             # native should always fail on arm and ppc64,
  194:             # native usually works only with x86
  195:             native = '-march=native',
  196:             opt = '-O3',
  197:             werror = '-Werror',
  198:         ),
  199:         clang = dict(
  200:             native = '-march=native',
  201:             opt = "-O3",
  202:             # One of the following flags needs to be applicable for Clang to
  203:             # guarantee the sanity of the testing process, however in certain
  204:             # cases `-Werror` gets skipped during the availability test due to
  205:             # "unused arguments" warnings.
  206:             # see https://github.com/numpy/numpy/issues/19624
  207:             werror = '-Werror=switch -Werror',
  208:         ),
  209:         icc = dict(
  210:             native = '-xHost',
  211:             opt = '-O3',
  212:             werror = '-Werror',
  213:         ),
  214:         iccw = dict(
  215:             native = '/QxHost',
  216:             opt = '/O3',
  217:             werror = '/Werror',
  218:         ),
  219:         msvc = dict(
  220:             native = None,
  221:             opt = '/O2',
  222:             werror = '/WX',
  223:         ),
  224:         fcc = dict(
  225:             native = '-mcpu=a64fx',
  226:             opt = None,
  227:             werror = None,
  228:         )
  229:     )
  230:     conf_min_features = dict(
  231:         x86 = "SSE SSE2",
  232:         x64 = "SSE SSE2 SSE3",
  233:         ppc64 = '', # play it safe
  234:         ppc64le = "VSX VSX2",
  235:         s390x = '',
  236:         armhf = '', # play it safe
  237:         aarch64 = "NEON NEON_FP16 NEON_VFPV4 ASIMD"
  238:     )
  239:     conf_features = dict(
  240:         # X86
  241:         SSE = dict(
  242:             interest=1, headers="xmmintrin.h",
  243:             # enabling SSE without SSE2 is useless also
  244:             # it's non-optional for x86_64
  245:             implies="SSE2"
  246:         ),
  247:         SSE2   = dict(interest=2, implies="SSE", headers="emmintrin.h"),
  248:         SSE3   = dict(interest=3, implies="SSE2", headers="pmmintrin.h"),
  249:         SSSE3  = dict(interest=4, implies="SSE3", headers="tmmintrin.h"),
  250:         SSE41  = dict(interest=5, implies="SSSE3", headers="smmintrin.h"),
  251:         POPCNT = dict(interest=6, implies="SSE41", headers="popcntintrin.h"),
  252:         SSE42  = dict(interest=7, implies="POPCNT"),
  253:         AVX    = dict(
  254:             interest=8, implies="SSE42", headers="immintrin.h",
  255:             implies_detect=False
  256:         ),
  257:         XOP    = dict(interest=9, implies="AVX", headers="x86intrin.h"),
  258:         FMA4   = dict(interest=10, implies="AVX", headers="x86intrin.h"),
  259:         F16C   = dict(interest=11, implies="AVX"),
  260:         FMA3   = dict(interest=12, implies="F16C"),
  261:         AVX2   = dict(interest=13, implies="F16C"),
  262:         AVX512F = dict(
  263:             interest=20, implies="FMA3 AVX2", implies_detect=False,
  264:             extra_checks="AVX512F_REDUCE"
  265:         ),
  266:         AVX512CD = dict(interest=21, implies="AVX512F"),
  267:         AVX512_KNL = dict(
  268:             interest=40, implies="AVX512CD", group="AVX512ER AVX512PF",
  269:             detect="AVX512_KNL", implies_detect=False
  270:         ),
  271:         AVX512_KNM = dict(
  272:             interest=41, implies="AVX512_KNL",
  273:             group="AVX5124FMAPS AVX5124VNNIW AVX512VPOPCNTDQ",
  274:             detect="AVX512_KNM", implies_detect=False
  275:         ),
  276:         AVX512_SKX = dict(
  277:             interest=42, implies="AVX512CD", group="AVX512VL AVX512BW AVX512DQ",
  278:             detect="AVX512_SKX", implies_detect=False,
  279:             extra_checks="AVX512BW_MASK AVX512DQ_MASK"
  280:         ),
  281:         AVX512_CLX = dict(
  282:             interest=43, implies="AVX512_SKX", group="AVX512VNNI",
  283:             detect="AVX512_CLX"
  284:         ),
  285:         AVX512_CNL = dict(
  286:             interest=44, implies="AVX512_SKX", group="AVX512IFMA AVX512VBMI",
  287:             detect="AVX512_CNL", implies_detect=False
  288:         ),
  289:         AVX512_ICL = dict(
  290:             interest=45, implies="AVX512_CLX AVX512_CNL",
  291:             group="AVX512VBMI2 AVX512BITALG AVX512VPOPCNTDQ",
  292:             detect="AVX512_ICL", implies_detect=False
  293:         ),
  294:         AVX512_SPR = dict(
  295:             interest=46, implies="AVX512_ICL", group="AVX512FP16",
  296:             detect="AVX512_SPR", implies_detect=False
  297:         ),
  298:         # IBM/Power
  299:         ## Power7/ISA 2.06
  300:         VSX = dict(interest=1, headers="altivec.h", extra_checks="VSX_ASM"),
  301:         ## Power8/ISA 2.07
  302:         VSX2 = dict(interest=2, implies="VSX", implies_detect=False),
  303:         ## Power9/ISA 3.00
  304:         VSX3 = dict(interest=3, implies="VSX2", implies_detect=False,
  305:                     extra_checks="VSX3_HALF_DOUBLE"),
  306:         ## Power10/ISA 3.1
  307:         VSX4 = dict(interest=4, implies="VSX3", implies_detect=False,
  308:                     extra_checks="VSX4_MMA"),
  309:         # IBM/Z
  310:         ## VX(z13) support
  311:         VX = dict(interest=1, headers="vecintrin.h"),
  312:         ## Vector-Enhancements Facility
  313:         VXE = dict(interest=2, implies="VX", implies_detect=False),
  314:         ## Vector-Enhancements Facility 2
  315:         VXE2 = dict(interest=3, implies="VXE", implies_detect=False),
  316:         # ARM
  317:         NEON  = dict(interest=1, headers="arm_neon.h"),
  318:         NEON_FP16 = dict(interest=2, implies="NEON"),
  319:         ## FMA
  320:         NEON_VFPV4 = dict(interest=3, implies="NEON_FP16"),
  321:         ## Advanced SIMD
  322:         ASIMD = dict(interest=4, implies="NEON_FP16 NEON_VFPV4", implies_detect=False),
  323:         ## ARMv8.2 half-precision & vector arithm
  324:         ASIMDHP = dict(interest=5, implies="ASIMD"),
  325:         ## ARMv8.2 dot product
  326:         ASIMDDP = dict(interest=6, implies="ASIMD"),
  327:         ## ARMv8.2 Single & half-precision Multiply
  328:         ASIMDFHM = dict(interest=7, implies="ASIMDHP")
  329:     )
  330:     def conf_features_partial(self):
  331:         """Return a dictionary of supported CPU features by the platform,
  332:         and accumulate the rest of undefined options in `conf_features`,
  333:         the returned dict has same rules and notes in
  334:         class attribute `conf_features`, also its override
  335:         any options that been set in 'conf_features'.
  336:         """
  337:         if self.cc_noopt:
  338:             # optimization is disabled
  339:             return {}
  340: 
  341:         on_x86 = self.cc_on_x86 or self.cc_on_x64
  342:         is_unix = self.cc_is_gcc or self.cc_is_clang or self.cc_is_fcc
  343: 
  344:         if on_x86 and is_unix: return dict(
  345:             SSE    = dict(flags="-msse"),
  346:             SSE2   = dict(flags="-msse2"),
  347:             SSE3   = dict(flags="-msse3"),
  348:             SSSE3  = dict(flags="-mssse3"),
  349:             SSE41  = dict(flags="-msse4.1"),
  350:             POPCNT = dict(flags="-mpopcnt"),
  351:             SSE42  = dict(flags="-msse4.2"),
  352:             AVX    = dict(flags="-mavx"),
  353:             F16C   = dict(flags="-mf16c"),
  354:             XOP    = dict(flags="-mxop"),
  355:             FMA4   = dict(flags="-mfma4"),
  356:             FMA3   = dict(flags="-mfma"),
  357:             AVX2   = dict(flags="-mavx2"),
  358:             AVX512F = dict(flags="-mavx512f -mno-mmx"),
  359:             AVX512CD = dict(flags="-mavx512cd"),
  360:             AVX512_KNL = dict(flags="-mavx512er -mavx512pf"),
  361:             AVX512_KNM = dict(
  362:                 flags="-mavx5124fmaps -mavx5124vnniw -mavx512vpopcntdq"
  363:             ),
  364:             AVX512_SKX = dict(flags="-mavx512vl -mavx512bw -mavx512dq"),
  365:             AVX512_CLX = dict(flags="-mavx512vnni"),
  366:             AVX512_CNL = dict(flags="-mavx512ifma -mavx512vbmi"),
  367:             AVX512_ICL = dict(
  368:                 flags="-mavx512vbmi2 -mavx512bitalg -mavx512vpopcntdq"
  369:             ),
  370:             AVX512_SPR = dict(flags="-mavx512fp16"),
  371:         )
  372:         if on_x86 and self.cc_is_icc: return dict(
  373:             SSE    = dict(flags="-msse"),
  374:             SSE2   = dict(flags="-msse2"),
  375:             SSE3   = dict(flags="-msse3"),
  376:             SSSE3  = dict(flags="-mssse3"),
  377:             SSE41  = dict(flags="-msse4.1"),
  378:             POPCNT = {},
  379:             SSE42  = dict(flags="-msse4.2"),
  380:             AVX    = dict(flags="-mavx"),
  381:             F16C   = {},
  382:             XOP    = dict(disable="Intel Compiler doesn't support it"),
  383:             FMA4   = dict(disable="Intel Compiler doesn't support it"),
  384:             # Intel Compiler doesn't support AVX2 or FMA3 independently
  385:             FMA3 = dict(
  386:                 implies="F16C AVX2", flags="-march=core-avx2"
  387:             ),
  388:             AVX2 = dict(implies="FMA3", flags="-march=core-avx2"),
  389:             # Intel Compiler doesn't support AVX512F or AVX512CD independently
  390:             AVX512F = dict(
  391:                 implies="AVX2 AVX512CD", flags="-march=common-avx512"
  392:             ),
  393:             AVX512CD = dict(
  394:                 implies="AVX2 AVX512F", flags="-march=common-avx512"
  395:             ),
  396:             AVX512_KNL = dict(flags="-xKNL"),
  397:             AVX512_KNM = dict(flags="-xKNM"),
  398:             AVX512_SKX = dict(flags="-xSKYLAKE-AVX512"),
  399:             AVX512_CLX = dict(flags="-xCASCADELAKE"),
  400:             AVX512_CNL = dict(flags="-xCANNONLAKE"),
  401:             AVX512_ICL = dict(flags="-xICELAKE-CLIENT"),
  402:             AVX512_SPR = dict(disable="Not supported yet")
  403:         )
  404:         if on_x86 and self.cc_is_iccw: return dict(
  405:             SSE    = dict(flags="/arch:SSE"),
  406:             SSE2   = dict(flags="/arch:SSE2"),
  407:             SSE3   = dict(flags="/arch:SSE3"),
  408:             SSSE3  = dict(flags="/arch:SSSE3"),
  409:             SSE41  = dict(flags="/arch:SSE4.1"),
  410:             POPCNT = {},
  411:             SSE42  = dict(flags="/arch:SSE4.2"),
  412:             AVX    = dict(flags="/arch:AVX"),
  413:             F16C   = {},
  414:             XOP    = dict(disable="Intel Compiler doesn't support it"),
  415:             FMA4   = dict(disable="Intel Compiler doesn't support it"),
  416:             # Intel Compiler doesn't support FMA3 or AVX2 independently
  417:             FMA3 = dict(
  418:                 implies="F16C AVX2", flags="/arch:CORE-AVX2"
  419:             ),
  420:             AVX2 = dict(
  421:                 implies="FMA3", flags="/arch:CORE-AVX2"
  422:             ),
  423:             # Intel Compiler doesn't support AVX512F or AVX512CD independently
  424:             AVX512F = dict(
  425:                 implies="AVX2 AVX512CD", flags="/Qx:COMMON-AVX512"
  426:             ),
  427:             AVX512CD = dict(
  428:                 implies="AVX2 AVX512F", flags="/Qx:COMMON-AVX512"
  429:             ),
  430:             AVX512_KNL = dict(flags="/Qx:KNL"),
  431:             AVX512_KNM = dict(flags="/Qx:KNM"),
  432:             AVX512_SKX = dict(flags="/Qx:SKYLAKE-AVX512"),
  433:             AVX512_CLX = dict(flags="/Qx:CASCADELAKE"),
  434:             AVX512_CNL = dict(flags="/Qx:CANNONLAKE"),
  435:             AVX512_ICL = dict(flags="/Qx:ICELAKE-CLIENT"),
  436:             AVX512_SPR = dict(disable="Not supported yet")
  437:         )
  438:         if on_x86 and self.cc_is_msvc: return dict(
  439:             SSE = dict(flags="/arch:SSE") if self.cc_on_x86 else {},
  440:             SSE2 = dict(flags="/arch:SSE2") if self.cc_on_x86 else {},
  441:             SSE3   = {},
  442:             SSSE3  = {},
  443:             SSE41  = {},
  444:             POPCNT = dict(headers="nmmintrin.h"),
  445:             SSE42  = {},
  446:             AVX    = dict(flags="/arch:AVX"),
  447:             F16C   = {},
  448:             XOP    = dict(headers="ammintrin.h"),
  449:             FMA4   = dict(headers="ammintrin.h"),
  450:             # MSVC doesn't support FMA3 or AVX2 independently
  451:             FMA3 = dict(
  452:                 implies="F16C AVX2", flags="/arch:AVX2"
  453:             ),
  454:             AVX2 = dict(
  455:                 implies="F16C FMA3", flags="/arch:AVX2"
  456:             ),
  457:             # MSVC doesn't support AVX512F or AVX512CD independently,
  458:             # always generate instructions belong to (VL/VW/DQ)
  459:             AVX512F = dict(
  460:                 implies="AVX2 AVX512CD AVX512_SKX", flags="/arch:AVX512"
  461:             ),
  462:             AVX512CD = dict(
  463:                 implies="AVX512F AVX512_SKX", flags="/arch:AVX512"
  464:             ),
  465:             AVX512_KNL = dict(
  466:                 disable="MSVC compiler doesn't support it"
  467:             ),
  468:             AVX512_KNM = dict(
  469:                 disable="MSVC compiler doesn't support it"
  470:             ),
  471:             AVX512_SKX = dict(flags="/arch:AVX512"),
  472:             AVX512_CLX = {},
  473:             AVX512_CNL = {},
  474:             AVX512_ICL = {},
  475:             AVX512_SPR= dict(
  476:                 disable="MSVC compiler doesn't support it"
  477:             )
  478:         )
  479: 
  480:         on_power = self.cc_on_ppc64le or self.cc_on_ppc64
  481:         if on_power:
  482:             partial = dict(
  483:                 VSX = dict(
  484:                     implies=("VSX2" if self.cc_on_ppc64le else ""),
  485:                     flags="-mvsx"
  486:                 ),
  487:                 VSX2 = dict(
  488:                     flags="-mcpu=power8", implies_detect=False
  489:                 ),
  490:                 VSX3 = dict(
  491:                     flags="-mcpu=power9 -mtune=power9", implies_detect=False
  492:                 ),
  493:                 VSX4 = dict(
  494:                     flags="-mcpu=power10 -mtune=power10", implies_detect=False
  495:                 )
  496:             )
  497:             if self.cc_is_clang:
  498:                 partial["VSX"]["flags"]  = "-maltivec -mvsx"
  499:                 partial["VSX2"]["flags"] = "-mcpu=power8"
  500:                 partial["VSX3"]["flags"] = "-mcpu=power9"
  501:                 partial["VSX4"]["flags"] = "-mcpu=power10"
  502: 
  503:             return partial
  504: 
  505:         on_zarch = self.cc_on_s390x
  506:         if on_zarch:
  507:             partial = dict(
  508:                 VX = dict(
  509:                     flags="-march=arch11 -mzvector"
  510:                 ),
  511:                 VXE = dict(
  512:                     flags="-march=arch12", implies_detect=False
  513:                 ),
  514:                 VXE2 = dict(
  515:                     flags="-march=arch13", implies_detect=False
  516:                 )
  517:             )
  518: 
  519:             return partial
  520: 
  521: 
  522:         if self.cc_on_aarch64 and is_unix: return dict(
  523:             NEON = dict(
  524:                 implies="NEON_FP16 NEON_VFPV4 ASIMD", autovec=True
  525:             ),
  526:             NEON_FP16 = dict(
  527:                 implies="NEON NEON_VFPV4 ASIMD", autovec=True
  528:             ),
  529:             NEON_VFPV4 = dict(
  530:                 implies="NEON NEON_FP16 ASIMD", autovec=True
  531:             ),
  532:             ASIMD = dict(
  533:                 implies="NEON NEON_FP16 NEON_VFPV4", autovec=True
  534:             ),
  535:             ASIMDHP = dict(
  536:                 flags="-march=armv8.2-a+fp16"
  537:             ),
  538:             ASIMDDP = dict(
  539:                 flags="-march=armv8.2-a+dotprod"
  540:             ),
  541:             ASIMDFHM = dict(
  542:                 flags="-march=armv8.2-a+fp16fml"
  543:             ),
  544:         )
  545:         if self.cc_on_armhf and is_unix: return dict(
  546:             NEON = dict(
  547:                 flags="-mfpu=neon"
  548:             ),
  549:             NEON_FP16 = dict(
  550:                 flags="-mfpu=neon-fp16 -mfp16-format=ieee"
  551:             ),
  552:             NEON_VFPV4 = dict(
  553:                 flags="-mfpu=neon-vfpv4",
  554:             ),
  555:             ASIMD = dict(
  556:                 flags="-mfpu=neon-fp-armv8 -march=armv8-a+simd",
  557:             ),
  558:             ASIMDHP = dict(
  559:                 flags="-march=armv8.2-a+fp16"
  560:             ),
  561:             ASIMDDP = dict(
  562:                 flags="-march=armv8.2-a+dotprod",
  563:             ),
  564:             ASIMDFHM = dict(
  565:                 flags="-march=armv8.2-a+fp16fml"
  566:             )
  567:         )
  568:         # TODO: ARM MSVC
  569:         return {}
  570: 
  571:     def __init__(self):
  572:         if self.conf_tmp_path is None:
  573:             import shutil
  574:             import tempfile
  575:             tmp = tempfile.mkdtemp()
  576:             def rm_temp():
  577:                 try:
  578:                     shutil.rmtree(tmp)
  579:                 except OSError:
  580:                     pass
  581:             atexit.register(rm_temp)
  582:             self.conf_tmp_path = tmp
  583: 
  584:         if self.conf_cache_factors is None:
  585:             self.conf_cache_factors = [
  586:                 os.path.getmtime(__file__),
  587:                 self.conf_nocache
  588:             ]
  589: 
  590: class _Distutils:
  591:     """A helper class that provides a collection of fundamental methods
  592:     implemented in a top of Python and NumPy Distutils.
  593: 
  594:     The idea behind this class is to gather all methods that it may
  595:     need to override in case of reuse 'CCompilerOpt' in environment
  596:     different than of what NumPy has.
  597: 
  598:     Parameters
  599:     ----------
  600:     ccompiler : `CCompiler`
  601:         The generate instance that returned from `distutils.ccompiler.new_compiler()`.
  602:     """
  603:     def __init__(self, ccompiler):
  604:         self._ccompiler = ccompiler
  605: 
  606:     def dist_compile(self, sources, flags, ccompiler=None, **kwargs):
  607:         """Wrap CCompiler.compile()"""
  608:         assert(isinstance(sources, list))
  609:         assert(isinstance(flags, list))
  610:         flags = kwargs.pop("extra_postargs", []) + flags
  611:         if not ccompiler:
  612:             ccompiler = self._ccompiler
  613: 
  614:         return ccompiler.compile(sources, extra_postargs=flags, **kwargs)
  615: 
  616:     def dist_test(self, source, flags, macros=[]):
  617:         """Return True if 'CCompiler.compile()' able to compile
  618:         a source file with certain flags.
  619:         """
  620:         assert(isinstance(source, str))
  621:         from distutils.errors import CompileError
  622:         cc = self._ccompiler;
  623:         bk_spawn = getattr(cc, 'spawn', None)
  624:         if bk_spawn:
  625:             cc_type = getattr(self._ccompiler, "compiler_type", "")
  626:             if cc_type in ("msvc",):
  627:                 setattr(cc, 'spawn', self._dist_test_spawn_paths)
  628:             else:
  629:                 setattr(cc, 'spawn', self._dist_test_spawn)
  630:         test = False
  631:         try:
  632:             self.dist_compile(
  633:                 [source], flags, macros=macros, output_dir=self.conf_tmp_path
  634:             )
  635:             test = True
  636:         except CompileError as e:
  637:             self.dist_log(str(e), stderr=True)
  638:         if bk_spawn:
  639:             setattr(cc, 'spawn', bk_spawn)
  640:         return test
  641: 
  642:     def dist_info(self):
  643:         """
  644:         Return a tuple containing info about (platform, compiler, extra_args),
  645:         required by the abstract class '_CCompiler' for discovering the
  646:         platform environment. This is also used as a cache factor in order
  647:         to detect any changes happening from outside.
  648:         """
  649:         if hasattr(self, "_dist_info"):
  650:             return self._dist_info
  651: 
  652:         cc_type = getattr(self._ccompiler, "compiler_type", '')
  653:         if cc_type in ("intelem", "intelemw"):
  654:             platform = "x86_64"
  655:         elif cc_type in ("intel", "intelw", "intele"):
  656:             platform = "x86"
  657:         else:
  658:             from distutils.util import get_platform
  659:             platform = get_platform()
  660: 
  661:         cc_info = getattr(self._ccompiler, "compiler", getattr(self._ccompiler, "compiler_so", ''))
  662:         if not cc_type or cc_type == "unix":
  663:             if hasattr(cc_info, "__iter__"):
  664:                 compiler = cc_info[0]
  665:             else:
  666:                 compiler = str(cc_info)
  667:         else:
  668:             compiler = cc_type
  669: 
  670:         if hasattr(cc_info, "__iter__") and len(cc_info) > 1:
  671:             extra_args = ' '.join(cc_info[1:])
  672:         else:
  673:             extra_args  = os.environ.get("CFLAGS", "")
  674:             extra_args += os.environ.get("CPPFLAGS", "")
  675: 
  676:         self._dist_info = (platform, compiler, extra_args)
  677:         return self._dist_info
  678: 
  679:     @staticmethod
  680:     def dist_error(*args):
  681:         """Raise a compiler error"""
  682:         from distutils.errors import CompileError
  683:         raise CompileError(_Distutils._dist_str(*args))
  684: 
  685:     @staticmethod
  686:     def dist_fatal(*args):
  687:         """Raise a distutils error"""
  688:         from distutils.errors import DistutilsError
  689:         raise DistutilsError(_Distutils._dist_str(*args))
  690: 
  691:     @staticmethod
  692:     def dist_log(*args, stderr=False):
  693:         """Print a console message"""
  694:         from numpy.distutils import log
  695:         out = _Distutils._dist_str(*args)
  696:         if stderr:
  697:             log.warn(out)
  698:         else:
  699:             log.info(out)
  700: 
  701:     @staticmethod
  702:     def dist_load_module(name, path):
  703:         """Load a module from file, required by the abstract class '_Cache'."""
  704:         from .misc_util import exec_mod_from_location
  705:         try:
  706:             return exec_mod_from_location(name, path)
  707:         except Exception as e:
  708:             _Distutils.dist_log(e, stderr=True)
  709:         return None
  710: 
  711:     @staticmethod
  712:     def _dist_str(*args):
  713:         """Return a string to print by log and errors."""
  714:         def to_str(arg):
  715:             if not isinstance(arg, str) and hasattr(arg, '__iter__'):
  716:                 ret = []
  717:                 for a in arg:
  718:                     ret.append(to_str(a))
  719:                 return '('+ ' '.join(ret) + ')'
  720:             return str(arg)
  721: 
  722:         stack = inspect.stack()[2]
  723:         start = "CCompilerOpt.%s[%d] : " % (stack.function, stack.lineno)
  724:         out = ' '.join([
  725:             to_str(a)
  726:             for a in (*args,)
  727:         ])
  728:         return start + out
  729: 
  730:     def _dist_test_spawn_paths(self, cmd, display=None):
  731:         """
  732:         Fix msvc SDK ENV path same as distutils do
  733:         without it we get c1: fatal error C1356: unable to find mspdbcore.dll
  734:         """
  735:         if not hasattr(self._ccompiler, "_paths"):
  736:             self._dist_test_spawn(cmd)
  737:             return
  738:         old_path = os.getenv("path")
  739:         try:
  740:             os.environ["path"] = self._ccompiler._paths
  741:             self._dist_test_spawn(cmd)
  742:         finally:
  743:             os.environ["path"] = old_path
  744: 
  745:     _dist_warn_regex = re.compile(
  746:         # intel and msvc compilers don't raise
  747:         # fatal errors when flags are wrong or unsupported
  748:         ".*("
  749:         "warning D9002|"  # msvc, it should be work with any language.
  750:         "invalid argument for option" # intel
  751:         ").*"
  752:     )
  753:     @staticmethod
  754:     def _dist_test_spawn(cmd, display=None):
  755:         try:
  756:             o = subprocess.check_output(cmd, stderr=subprocess.STDOUT,
  757:                                         text=True)
  758:             if o and re.match(_Distutils._dist_warn_regex, o):
  759:                 _Distutils.dist_error(
  760:                     "Flags in command", cmd ,"aren't supported by the compiler"
  761:                     ", output -> \n%s" % o
  762:                 )
  763:         except subprocess.CalledProcessError as exc:
  764:             o = exc.output
  765:             s = exc.returncode
  766:         except OSError as e:
  767:             o = e
  768:             s = 127
  769:         else:
  770:             return None
  771:         _Distutils.dist_error(
  772:             "Command", cmd, "failed with exit status %d output -> \n%s" % (
  773:             s, o
  774:         ))
  775: 
  776: _share_cache = {}
  777: class _Cache:
  778:     """An abstract class handles caching functionality, provides two
  779:     levels of caching, in-memory by share instances attributes among
  780:     each other and by store attributes into files.
  781: 
  782:     **Note**:
  783:         any attributes that start with ``_`` or ``conf_`` will be ignored.
  784: 
  785:     Parameters
  786:     ----------
  787:     cache_path : str or None
  788:         The path of cache file, if None then cache in file will disabled.
  789: 
  790:     *factors :
  791:         The caching factors that need to utilize next to `conf_cache_factors`.
  792: 
  793:     Attributes
  794:     ----------
  795:     cache_private : set
  796:         Hold the attributes that need be skipped from "in-memory cache".
  797: 
  798:     cache_infile : bool
  799:         Utilized during initializing this class, to determine if the cache was able
  800:         to loaded from the specified cache path in 'cache_path'.
  801:     """
  802: 
  803:     # skip attributes from cache
  804:     _cache_ignore = re.compile("^(_|conf_)")
  805: 
  806:     def __init__(self, cache_path=None, *factors):
  807:         self.cache_me = {}
  808:         self.cache_private = set()
  809:         self.cache_infile = False
  810:         self._cache_path = None
  811: 
  812:         if self.conf_nocache:
  813:             self.dist_log("cache is disabled by `Config`")
  814:             return
  815: 
  816:         self._cache_hash = self.cache_hash(*factors, *self.conf_cache_factors)
  817:         self._cache_path = cache_path
  818:         if cache_path:
  819:             if os.path.exists(cache_path):
  820:                 self.dist_log("load cache from file ->", cache_path)
  821:                 cache_mod = self.dist_load_module("cache", cache_path)
  822:                 if not cache_mod:
  823:                     self.dist_log(
  824:                         "unable to load the cache file as a module",
  825:                         stderr=True
  826:                     )
  827:                 elif not hasattr(cache_mod, "hash") or \
  828:                      not hasattr(cache_mod, "data"):
  829:                     self.dist_log("invalid cache file", stderr=True)
  830:                 elif self._cache_hash == cache_mod.hash:
  831:                     self.dist_log("hit the file cache")
  832:                     for attr, val in cache_mod.data.items():
  833:                         setattr(self, attr, val)
  834:                     self.cache_infile = True
  835:                 else:
  836:                     self.dist_log("miss the file cache")
  837: 
  838:         if not self.cache_infile:
  839:             other_cache = _share_cache.get(self._cache_hash)
  840:             if other_cache:
  841:                 self.dist_log("hit the memory cache")
  842:                 for attr, val in other_cache.__dict__.items():
  843:                     if attr in other_cache.cache_private or \
  844:                                re.match(self._cache_ignore, attr):
  845:                         continue
  846:                     setattr(self, attr, val)
  847: 
  848:         _share_cache[self._cache_hash] = self
  849:         atexit.register(self.cache_flush)
  850: 
  851:     def __del__(self):
  852:         for h, o in _share_cache.items():
  853:             if o == self:
  854:                 _share_cache.pop(h)
  855:                 break
  856: 
  857:     def cache_flush(self):
  858:         """
  859:         Force update the cache.
  860:         """
  861:         if not self._cache_path:
  862:             return
  863:         # TODO: don't write if the cache doesn't change
  864:         self.dist_log("write cache to path ->", self._cache_path)
  865:         cdict = self.__dict__.copy()
  866:         for attr in self.__dict__.keys():
  867:             if re.match(self._cache_ignore, attr):
  868:                 cdict.pop(attr)
  869: 
  870:         d = os.path.dirname(self._cache_path)
  871:         if not os.path.exists(d):
  872:             os.makedirs(d)
  873: 
  874:         repr_dict = pprint.pformat(cdict, compact=True)
  875:         with open(self._cache_path, "w") as f:
  876:             f.write(textwrap.dedent("""\
  877:             # AUTOGENERATED DON'T EDIT
  878:             # Please make changes to the code generator \
  879:             (distutils/ccompiler_opt.py)
  880:             hash = {}
  881:             data = \\
  882:             """).format(self._cache_hash))
  883:             f.write(repr_dict)
  884: 
  885:     def cache_hash(self, *factors):
  886:         # is there a built-in non-crypto hash?
  887:         # sdbm
  888:         chash = 0
  889:         for f in factors:
  890:             for char in str(f):
  891:                 chash  = ord(char) + (chash << 6) + (chash << 16) - chash
  892:                 chash &= 0xFFFFFFFF
  893:         return chash
  894: 
  895:     @staticmethod
  896:     def me(cb):
  897:         """
  898:         A static method that can be treated as a decorator to
  899:         dynamically cache certain methods.
  900:         """
  901:         def cache_wrap_me(self, *args, **kwargs):
  902:             # good for normal args
  903:             cache_key = str((
  904:                 cb.__name__, *args, *kwargs.keys(), *kwargs.values()
  905:             ))
  906:             if cache_key in self.cache_me:
  907:                 return self.cache_me[cache_key]
  908:             ccb = cb(self, *args, **kwargs)
  909:             self.cache_me[cache_key] = ccb
  910:             return ccb
  911:         return cache_wrap_me
  912: 
  913: class _CCompiler:
  914:     """A helper class for `CCompilerOpt` containing all utilities that
  915:     related to the fundamental compiler's functions.
  916: 
  917:     Attributes
  918:     ----------
  919:     cc_on_x86 : bool
  920:         True when the target architecture is 32-bit x86
  921:     cc_on_x64 : bool
  922:         True when the target architecture is 64-bit x86
  923:     cc_on_ppc64 : bool
  924:         True when the target architecture is 64-bit big-endian powerpc
  925:     cc_on_ppc64le : bool
  926:         True when the target architecture is 64-bit litle-endian powerpc
  927:     cc_on_s390x : bool
  928:         True when the target architecture is IBM/ZARCH on linux
  929:     cc_on_armhf : bool
  930:         True when the target architecture is 32-bit ARMv7+
  931:     cc_on_aarch64 : bool
  932:         True when the target architecture is 64-bit Armv8-a+
  933:     cc_on_noarch : bool
  934:         True when the target architecture is unknown or not supported
  935:     cc_is_gcc : bool
  936:         True if the compiler is GNU or
  937:         if the compiler is unknown
  938:     cc_is_clang : bool
  939:         True if the compiler is Clang
  940:     cc_is_icc : bool
  941:         True if the compiler is Intel compiler (unix like)
  942:     cc_is_iccw : bool
  943:         True if the compiler is Intel compiler (msvc like)
  944:     cc_is_nocc : bool
  945:         True if the compiler isn't supported directly,
  946:         Note: that cause a fail-back to gcc
  947:     cc_has_debug : bool
  948:         True if the compiler has debug flags
  949:     cc_has_native : bool
  950:         True if the compiler has native flags
  951:     cc_noopt : bool
  952:         True if the compiler has definition 'DISABLE_OPT*',
  953:         or 'cc_on_noarch' is True
  954:     cc_march : str
  955:         The target architecture name, or "unknown" if
  956:         the architecture isn't supported
  957:     cc_name : str
  958:         The compiler name, or "unknown" if the compiler isn't supported
  959:     cc_flags : dict
  960:         Dictionary containing the initialized flags of `_Config.conf_cc_flags`
  961:     """
  962:     def __init__(self):
  963:         if hasattr(self, "cc_is_cached"):
  964:             return
  965:         #      attr            regex        compiler-expression
  966:         detect_arch = (
  967:             ("cc_on_x64",      ".*(x|x86_|amd)64.*", ""),
  968:             ("cc_on_x86",      ".*(win32|x86|i386|i686).*", ""),
  969:             ("cc_on_ppc64le",  ".*(powerpc|ppc)64(el|le).*|.*powerpc.*",
  970:                                           "defined(__powerpc64__) && "
  971:                                           "defined(__LITTLE_ENDIAN__)"),
  972:             ("cc_on_ppc64",    ".*(powerpc|ppc).*|.*powerpc.*",
  973:                                           "defined(__powerpc64__) && "
  974:                                           "defined(__BIG_ENDIAN__)"),
  975:             ("cc_on_aarch64",  ".*(aarch64|arm64).*", ""),
  976:             ("cc_on_armhf",    ".*arm.*", "defined(__ARM_ARCH_7__) || "
  977:                                           "defined(__ARM_ARCH_7A__)"),
  978:             ("cc_on_s390x",    ".*s390x.*", ""),
  979:             # undefined platform
  980:             ("cc_on_noarch",   "", ""),
  981:         )
  982:         detect_compiler = (
  983:             ("cc_is_gcc",     r".*(gcc|gnu\-g).*", ""),
  984:             ("cc_is_clang",    ".*clang.*", ""),
  985:             # intel msvc like
  986:             ("cc_is_iccw",     ".*(intelw|intelemw|iccw).*", ""),
  987:             ("cc_is_icc",      ".*(intel|icc).*", ""),  # intel unix like
  988:             ("cc_is_msvc",     ".*msvc.*", ""),
  989:             ("cc_is_fcc",     ".*fcc.*", ""),
  990:             # undefined compiler will be treat it as gcc
  991:             ("cc_is_nocc",     "", ""),
  992:         )
  993:         detect_args = (
  994:            ("cc_has_debug",  ".*(O0|Od|ggdb|coverage|debug:full).*", ""),
  995:            ("cc_has_native",
  996:                 ".*(-march=native|-xHost|/QxHost|-mcpu=a64fx).*", ""),
  997:            # in case if the class run with -DNPY_DISABLE_OPTIMIZATION
  998:            ("cc_noopt", ".*DISABLE_OPT.*", ""),
  999:         )
 1000: 
 1001:         dist_info = self.dist_info()
 1002:         platform, compiler_info, extra_args = dist_info
 1003:         # set False to all attrs
 1004:         for section in (detect_arch, detect_compiler, detect_args):
 1005:             for attr, rgex, cexpr in section:
 1006:                 setattr(self, attr, False)
 1007: 
 1008:         for detect, searchin in ((detect_arch, platform), (detect_compiler, compiler_info)):
 1009:             for attr, rgex, cexpr in detect:
 1010:                 if rgex and not re.match(rgex, searchin, re.IGNORECASE):
 1011:                     continue
 1012:                 if cexpr and not self.cc_test_cexpr(cexpr):
 1013:                     continue
 1014:                 setattr(self, attr, True)
 1015:                 break
 1016: 
 1017:         for attr, rgex, cexpr in detect_args:
 1018:             if rgex and not re.match(rgex, extra_args, re.IGNORECASE):
 1019:                 continue
 1020:             if cexpr and not self.cc_test_cexpr(cexpr):
 1021:                 continue
 1022:             setattr(self, attr, True)
 1023: 
 1024:         if self.cc_on_noarch:
 1025:             self.dist_log(
 1026:                 "unable to detect CPU architecture which lead to disable the optimization. "
 1027:                 f"check dist_info:<<\n{dist_info}\n>>",
 1028:                 stderr=True
 1029:             )
 1030:             self.cc_noopt = True
 1031: 
 1032:         if self.conf_noopt:
 1033:             self.dist_log("Optimization is disabled by the Config", stderr=True)
 1034:             self.cc_noopt = True
 1035: 
 1036:         if self.cc_is_nocc:
 1037:             """
 1038:             mingw can be treated as a gcc, and also xlc even if it based on clang,
 1039:             but still has the same gcc optimization flags.
 1040:             """
 1041:             self.dist_log(
 1042:                 "unable to detect compiler type which leads to treating it as GCC. "
 1043:                 "this is a normal behavior if you're using gcc-like compiler such as MinGW or IBM/XLC."
 1044:                 f"check dist_info:<<\n{dist_info}\n>>",
 1045:                 stderr=True
 1046:             )
 1047:             self.cc_is_gcc = True
 1048: 
 1049:         self.cc_march = "unknown"
 1050:         for arch in ("x86", "x64", "ppc64", "ppc64le",
 1051:                      "armhf", "aarch64", "s390x"):
 1052:             if getattr(self, "cc_on_" + arch):
 1053:                 self.cc_march = arch
 1054:                 break
 1055: 
 1056:         self.cc_name = "unknown"
 1057:         for name in ("gcc", "clang", "iccw", "icc", "msvc", "fcc"):
 1058:             if getattr(self, "cc_is_" + name):
 1059:                 self.cc_name = name
 1060:                 break
 1061: 
 1062:         self.cc_flags = {}
 1063:         compiler_flags = self.conf_cc_flags.get(self.cc_name)
 1064:         if compiler_flags is None:
 1065:             self.dist_fatal(
 1066:                 "undefined flag for compiler '%s', "
 1067:                 "leave an empty dict instead" % self.cc_name
 1068:             )
 1069:         for name, flags in compiler_flags.items():
 1070:             self.cc_flags[name] = nflags = []
 1071:             if flags:
 1072:                 assert(isinstance(flags, str))
 1073:                 flags = flags.split()
 1074:                 for f in flags:
 1075:                     if self.cc_test_flags([f]):
 1076:                         nflags.append(f)
 1077: 
 1078:         self.cc_is_cached = True
 1079: 
 1080:     @_Cache.me
 1081:     def cc_test_flags(self, flags):
 1082:         """
 1083:         Returns True if the compiler supports 'flags'.
 1084:         """
 1085:         assert(isinstance(flags, list))
 1086:         self.dist_log("testing flags", flags)
 1087:         test_path = os.path.join(self.conf_check_path, "test_flags.c")
 1088:         test = self.dist_test(test_path, flags)
 1089:         if not test:
 1090:             self.dist_log("testing failed", stderr=True)
 1091:         return test
 1092: 
 1093:     @_Cache.me
 1094:     def cc_test_cexpr(self, cexpr, flags=[]):
 1095:         """
 1096:         Same as the above but supports compile-time expressions.
 1097:         """
 1098:         self.dist_log("testing compiler expression", cexpr)
 1099:         test_path = os.path.join(self.conf_tmp_path, "npy_dist_test_cexpr.c")
 1100:         with open(test_path, "w") as fd:
 1101:             fd.write(textwrap.dedent(f"""\
 1102:                #if !({cexpr})
 1103:                    #error "unsupported expression"
 1104:                #endif
 1105:                int dummy;
 1106:             """))
 1107:         test = self.dist_test(test_path, flags)
 1108:         if not test:
 1109:             self.dist_log("testing failed", stderr=True)
 1110:         return test
 1111: 
 1112:     def cc_normalize_flags(self, flags):
 1113:         """
 1114:         Remove the conflicts that caused due gathering implied features flags.
 1115: 
 1116:         Parameters
 1117:         ----------
 1118:         'flags' list, compiler flags
 1119:             flags should be sorted from the lowest to the highest interest.
 1120: 
 1121:         Returns
 1122:         -------
 1123:         list, filtered from any conflicts.
 1124: 
 1125:         Examples
 1126:         --------
 1127:         >>> self.cc_normalize_flags(['-march=armv8.2-a+fp16', '-march=armv8.2-a+dotprod'])
 1128:         ['armv8.2-a+fp16+dotprod']
 1129: 
 1130:         >>> self.cc_normalize_flags(
 1131:             ['-msse', '-msse2', '-msse3', '-mssse3', '-msse4.1', '-msse4.2', '-mavx', '-march=core-avx2']
 1132:         )
 1133:         ['-march=core-avx2']
 1134:         """
 1135:         assert(isinstance(flags, list))
 1136:         if self.cc_is_gcc or self.cc_is_clang or self.cc_is_icc:
 1137:             return self._cc_normalize_unix(flags)
 1138: 
 1139:         if self.cc_is_msvc or self.cc_is_iccw:
 1140:             return self._cc_normalize_win(flags)
 1141:         return flags
 1142: 
 1143:     _cc_normalize_unix_mrgx = re.compile(
 1144:         # 1- to check the highest of
 1145:         r"^(-mcpu=|-march=|-x[A-Z0-9\-])"
 1146:     )
 1147:     _cc_normalize_unix_frgx = re.compile(
 1148:         # 2- to remove any flags starts with
 1149:         # -march, -mcpu, -x(INTEL) and '-m' without '='
 1150:         r"^(?!(-mcpu=|-march=|-x[A-Z0-9\-]|-m[a-z0-9\-\.]*.$))|"
 1151:         # exclude:
 1152:         r"(?:-mzvector)"
 1153:     )
 1154:     _cc_normalize_unix_krgx = re.compile(
 1155:         # 3- keep only the highest of
 1156:         r"^(-mfpu|-mtune)"
 1157:     )
 1158:     _cc_normalize_arch_ver = re.compile(
 1159:         r"[0-9.]"
 1160:     )
 1161:     def _cc_normalize_unix(self, flags):
 1162:         def ver_flags(f):
 1163:             #        arch ver  subflag
 1164:             # -march=armv8.2-a+fp16fml
 1165:             tokens = f.split('+')
 1166:             ver = float('0' + ''.join(
 1167:                 re.findall(self._cc_normalize_arch_ver, tokens[0])
 1168:             ))
 1169:             return ver, tokens[0], tokens[1:]
 1170: 
 1171:         if len(flags) <= 1:
 1172:             return flags
 1173:         # get the highest matched flag
 1174:         for i, cur_flag in enumerate(reversed(flags)):
 1175:             if not re.match(self._cc_normalize_unix_mrgx, cur_flag):
 1176:                 continue
 1177:             lower_flags = flags[:-(i+1)]
 1178:             upper_flags = flags[-i:]
 1179:             filtered = list(filter(
 1180:                 self._cc_normalize_unix_frgx.search, lower_flags
 1181:             ))
 1182:             # gather subflags
 1183:             ver, arch, subflags = ver_flags(cur_flag)
 1184:             if ver > 0 and len(subflags) > 0:
 1185:                 for xflag in lower_flags:
 1186:                     xver, _, xsubflags = ver_flags(xflag)
 1187:                     if ver == xver:
 1188:                         subflags = xsubflags + subflags
 1189:                 cur_flag = arch + '+' + '+'.join(subflags)
 1190: 
 1191:             flags = filtered + [cur_flag]
 1192:             if i > 0:
 1193:                 flags += upper_flags
 1194:             break
 1195: 
 1196:         # to remove overridable flags
 1197:         final_flags = []
 1198:         matched = set()
 1199:         for f in reversed(flags):
 1200:             match = re.match(self._cc_normalize_unix_krgx, f)
 1201:             if not match:
 1202:                 pass
 1203:             elif match[0] in matched:
 1204:                 continue
 1205:             else:
 1206:                 matched.add(match[0])
 1207:             final_flags.insert(0, f)
 1208:         return final_flags
 1209: 
 1210:     _cc_normalize_win_frgx = re.compile(
 1211:         r"^(?!(/arch\:|/Qx\:))"
 1212:     )
 1213:     _cc_normalize_win_mrgx = re.compile(
 1214:         r"^(/arch|/Qx:)"
 1215:     )
 1216:     def _cc_normalize_win(self, flags):
 1217:         for i, f in enumerate(reversed(flags)):
 1218:             if not re.match(self._cc_normalize_win_mrgx, f):
 1219:                 continue
 1220:             i += 1
 1221:             return list(filter(
 1222:                 self._cc_normalize_win_frgx.search, flags[:-i]
 1223:             )) + flags[-i:]
 1224:         return flags
 1225: 
 1226: class _Feature:
 1227:     """A helper class for `CCompilerOpt` that managing CPU features.
 1228: 
 1229:     Attributes
 1230:     ----------
 1231:     feature_supported : dict
 1232:         Dictionary containing all CPU features that supported
 1233:         by the platform, according to the specified values in attribute
 1234:         `_Config.conf_features` and `_Config.conf_features_partial()`
 1235: 
 1236:     feature_min : set
 1237:         The minimum support of CPU features, according to
 1238:         the specified values in attribute `_Config.conf_min_features`.
 1239:     """
 1240:     def __init__(self):
 1241:         if hasattr(self, "feature_is_cached"):
 1242:             return
 1243:         self.feature_supported = pfeatures = self.conf_features_partial()
 1244:         for feature_name in list(pfeatures.keys()):
 1245:             feature  = pfeatures[feature_name]
 1246:             cfeature = self.conf_features[feature_name]
 1247:             feature.update({
 1248:                 k:v for k,v in cfeature.items() if k not in feature
 1249:             })
 1250:             disabled = feature.get("disable")
 1251:             if disabled is not None:
 1252:                 pfeatures.pop(feature_name)
 1253:                 self.dist_log(
 1254:                     "feature '%s' is disabled," % feature_name,
 1255:                     disabled, stderr=True
 1256:                 )
 1257:                 continue
 1258:             # list is used internally for these options
 1259:             for option in (
 1260:                 "implies", "group", "detect", "headers", "flags", "extra_checks"
 1261:             ) :
 1262:                 oval = feature.get(option)
 1263:                 if isinstance(oval, str):
 1264:                     feature[option] = oval.split()
 1265: 
 1266:         self.feature_min = set()
 1267:         min_f = self.conf_min_features.get(self.cc_march, "")
 1268:         for F in min_f.upper().split():
 1269:             if F in self.feature_supported:
 1270:                 self.feature_min.add(F)
 1271: 
 1272:         self.feature_is_cached = True
 1273: 
 1274:     def feature_names(self, names=None, force_flags=None, macros=[]):
 1275:         """
 1276:         Returns a set of CPU feature names that supported by platform and the **C** compiler.
 1277: 
 1278:         Parameters
 1279:         ----------
 1280:         names : sequence or None, optional
 1281:             Specify certain CPU features to test it against the **C** compiler.
 1282:             if None(default), it will test all current supported features.
 1283:             **Note**: feature names must be in upper-case.
 1284: 
 1285:         force_flags : list or None, optional
 1286:             If None(default), default compiler flags for every CPU feature will
 1287:             be used during the test.
 1288: 
 1289:         macros : list of tuples, optional
 1290:             A list of C macro definitions.
 1291:         """
 1292:         assert(
 1293:             names is None or (
 1294:                 not isinstance(names, str) and
 1295:                 hasattr(names, "__iter__")
 1296:             )
 1297:         )
 1298:         assert(force_flags is None or isinstance(force_flags, list))
 1299:         if names is None:
 1300:             names = self.feature_supported.keys()
 1301:         supported_names = set()
 1302:         for f in names:
 1303:             if self.feature_is_supported(
 1304:                 f, force_flags=force_flags, macros=macros
 1305:             ):
 1306:                 supported_names.add(f)
 1307:         return supported_names
 1308: 
 1309:     def feature_is_exist(self, name):
 1310:         """
 1311:         Returns True if a certain feature is exist and covered within
 1312:         ``_Config.conf_features``.
 1313: 
 1314:         Parameters
 1315:         ----------
 1316:         'name': str
 1317:             feature name in uppercase.
 1318:         """
 1319:         assert(name.isupper())
 1320:         return name in self.conf_features
 1321: 
 1322:     def feature_sorted(self, names, reverse=False):
 1323:         """
 1324:         Sort a list of CPU features ordered by the lowest interest.
 1325: 
 1326:         Parameters
 1327:         ----------
 1328:         'names': sequence
 1329:             sequence of supported feature names in uppercase.
 1330:         'reverse': bool, optional
 1331:             If true, the sorted features is reversed. (highest interest)
 1332: 
 1333:         Returns
 1334:         -------
 1335:         list, sorted CPU features
 1336:         """
 1337:         def sort_cb(k):
 1338:             if isinstance(k, str):
 1339:                 return self.feature_supported[k]["interest"]
 1340:             # multiple features
 1341:             rank = max([self.feature_supported[f]["interest"] for f in k])
 1342:             # FIXME: that's not a safe way to increase the rank for
 1343:             # multi targets
 1344:             rank += len(k) -1
 1345:             return rank
 1346:         return sorted(names, reverse=reverse, key=sort_cb)
 1347: 
 1348:     def feature_implies(self, names, keep_origins=False):
 1349:         """
 1350:         Return a set of CPU features that implied by 'names'
 1351: 
 1352:         Parameters
 1353:         ----------
 1354:         names : str or sequence of str
 1355:             CPU feature name(s) in uppercase.
 1356: 
 1357:         keep_origins : bool
 1358:             if False(default) then the returned set will not contain any
 1359:             features from 'names'. This case happens only when two features
 1360:             imply each other.
 1361: 
 1362:         Examples
 1363:         --------
 1364:         >>> self.feature_implies("SSE3")
 1365:         {'SSE', 'SSE2'}
 1366:         >>> self.feature_implies("SSE2")
 1367:         {'SSE'}
 1368:         >>> self.feature_implies("SSE2", keep_origins=True)
 1369:         # 'SSE2' found here since 'SSE' and 'SSE2' imply each other
 1370:         {'SSE', 'SSE2'}
 1371:         """
 1372:         def get_implies(name, _caller=set()):
 1373:             implies = set()
 1374:             d = self.feature_supported[name]
 1375:             for i in d.get("implies", []):
 1376:                 implies.add(i)
 1377:                 if i in _caller:
 1378:                     # infinity recursive guard since
 1379:                     # features can imply each other
 1380:                     continue
 1381:                 _caller.add(name)
 1382:                 implies = implies.union(get_implies(i, _caller))
 1383:             return implies
 1384: 
 1385:         if isinstance(names, str):
 1386:             implies = get_implies(names)
 1387:             names = [names]
 1388:         else:
 1389:             assert(hasattr(names, "__iter__"))
 1390:             implies = set()
 1391:             for n in names:
 1392:                 implies = implies.union(get_implies(n))
 1393:         if not keep_origins:
 1394:             implies.difference_update(names)
 1395:         return implies
 1396: 
 1397:     def feature_implies_c(self, names):
 1398:         """same as feature_implies() but combining 'names'"""
 1399:         if isinstance(names, str):
 1400:             names = set((names,))
 1401:         else:
 1402:             names = set(names)
 1403:         return names.union(self.feature_implies(names))
 1404: 
 1405:     def feature_ahead(self, names):
 1406:         """
 1407:         Return list of features in 'names' after remove any
 1408:         implied features and keep the origins.
 1409: 
 1410:         Parameters
 1411:         ----------
 1412:         'names': sequence
 1413:             sequence of CPU feature names in uppercase.
 1414: 
 1415:         Returns
 1416:         -------
 1417:         list of CPU features sorted as-is 'names'
 1418: 
 1419:         Examples
 1420:         --------
 1421:         >>> self.feature_ahead(["SSE2", "SSE3", "SSE41"])
 1422:         ["SSE41"]
 1423:         # assume AVX2 and FMA3 implies each other and AVX2
 1424:         # is the highest interest
 1425:         >>> self.feature_ahead(["SSE2", "SSE3", "SSE41", "AVX2", "FMA3"])
 1426:         ["AVX2"]
 1427:         # assume AVX2 and FMA3 don't implies each other
 1428:         >>> self.feature_ahead(["SSE2", "SSE3", "SSE41", "AVX2", "FMA3"])
 1429:         ["AVX2", "FMA3"]
 1430:         """
 1431:         assert(
 1432:             not isinstance(names, str)
 1433:             and hasattr(names, '__iter__')
 1434:         )
 1435:         implies = self.feature_implies(names, keep_origins=True)
 1436:         ahead = [n for n in names if n not in implies]
 1437:         if len(ahead) == 0:
 1438:             # return the highest interested feature
 1439:             # if all features imply each other
 1440:             ahead = self.feature_sorted(names, reverse=True)[:1]
 1441:         return ahead
 1442: 
 1443:     def feature_untied(self, names):
 1444:         """
 1445:         same as 'feature_ahead()' but if both features implied each other
 1446:         and keep the highest interest.
 1447: 
 1448:         Parameters
 1449:         ----------
 1450:         'names': sequence
 1451:             sequence of CPU feature names in uppercase.
 1452: 
 1453:         Returns
 1454:         -------
 1455:         list of CPU features sorted as-is 'names'
 1456: 
 1457:         Examples
 1458:         --------
 1459:         >>> self.feature_untied(["SSE2", "SSE3", "SSE41"])
 1460:         ["SSE2", "SSE3", "SSE41"]
 1461:         # assume AVX2 and FMA3 implies each other
 1462:         >>> self.feature_untied(["SSE2", "SSE3", "SSE41", "FMA3", "AVX2"])
 1463:         ["SSE2", "SSE3", "SSE41", "AVX2"]
 1464:         """
 1465:         assert(
 1466:             not isinstance(names, str)
 1467:             and hasattr(names, '__iter__')
 1468:         )
 1469:         final = []
 1470:         for n in names:
 1471:             implies = self.feature_implies(n)
 1472:             tied = [
 1473:                 nn for nn in final
 1474:                 if nn in implies and n in self.feature_implies(nn)
 1475:             ]
 1476:             if tied:
 1477:                 tied = self.feature_sorted(tied + [n])
 1478:                 if n not in tied[1:]:
 1479:                     continue
 1480:                 final.remove(tied[:1][0])
 1481:             final.append(n)
 1482:         return final
 1483: 
 1484:     def feature_get_til(self, names, keyisfalse):
 1485:         """
 1486:         same as `feature_implies_c()` but stop collecting implied
 1487:         features when feature's option that provided through
 1488:         parameter 'keyisfalse' is False, also sorting the returned
 1489:         features.
 1490:         """
 1491:         def til(tnames):
 1492:             # sort from highest to lowest interest then cut if "key" is False
 1493:             tnames = self.feature_implies_c(tnames)
 1494:             tnames = self.feature_sorted(tnames, reverse=True)
 1495:             for i, n in enumerate(tnames):
 1496:                 if not self.feature_supported[n].get(keyisfalse, True):
 1497:                     tnames = tnames[:i+1]
 1498:                     break
 1499:             return tnames
 1500: 
 1501:         if isinstance(names, str) or len(names) <= 1:
 1502:             names = til(names)
 1503:             # normalize the sort
 1504:             names.reverse()
 1505:             return names
 1506: 
 1507:         names = self.feature_ahead(names)
 1508:         names = {t for n in names for t in til(n)}
 1509:         return self.feature_sorted(names)
 1510: 
 1511:     def feature_detect(self, names):
 1512:         """
 1513:         Return a list of CPU features that required to be detected
 1514:         sorted from the lowest to highest interest.
 1515:         """
 1516:         names = self.feature_get_til(names, "implies_detect")
 1517:         detect = []
 1518:         for n in names:
 1519:             d = self.feature_supported[n]
 1520:             detect += d.get("detect", d.get("group", [n]))
 1521:         return detect
 1522: 
 1523:     @_Cache.me
 1524:     def feature_flags(self, names):
 1525:         """
 1526:         Return a list of CPU features flags sorted from the lowest
 1527:         to highest interest.
 1528:         """
 1529:         names = self.feature_sorted(self.feature_implies_c(names))
 1530:         flags = []
 1531:         for n in names:
 1532:             d = self.feature_supported[n]
 1533:             f = d.get("flags", [])
 1534:             if not f or not self.cc_test_flags(f):
 1535:                 continue
 1536:             flags += f
 1537:         return self.cc_normalize_flags(flags)
 1538: 
 1539:     @_Cache.me
 1540:     def feature_test(self, name, force_flags=None, macros=[]):
 1541:         """
 1542:         Test a certain CPU feature against the compiler through its own
 1543:         check file.
 1544: 
 1545:         Parameters
 1546:         ----------
 1547:         name : str
 1548:             Supported CPU feature name.
 1549: 
 1550:         force_flags : list or None, optional
 1551:             If None(default), the returned flags from `feature_flags()`
 1552:             will be used.
 1553: 
 1554:         macros : list of tuples, optional
 1555:             A list of C macro definitions.
 1556:         """
 1557:         if force_flags is None:
 1558:             force_flags = self.feature_flags(name)
 1559: 
 1560:         self.dist_log(
 1561:             "testing feature '%s' with flags (%s)" % (
 1562:             name, ' '.join(force_flags)
 1563:         ))
 1564:         # Each CPU feature must have C source code contains at
 1565:         # least one intrinsic or instruction related to this feature.
 1566:         test_path = os.path.join(
 1567:             self.conf_check_path, "cpu_%s.c" % name.lower()
 1568:         )
 1569:         if not os.path.exists(test_path):
 1570:             self.dist_fatal("feature test file is not exist", test_path)
 1571: 
 1572:         test = self.dist_test(
 1573:             test_path, force_flags + self.cc_flags["werror"], macros=macros
 1574:         )
 1575:         if not test:
 1576:             self.dist_log("testing failed", stderr=True)
 1577:         return test
 1578: 
 1579:     @_Cache.me
 1580:     def feature_is_supported(self, name, force_flags=None, macros=[]):
 1581:         """
 1582:         Check if a certain CPU feature is supported by the platform and compiler.
 1583: 
 1584:         Parameters
 1585:         ----------
 1586:         name : str
 1587:             CPU feature name in uppercase.
 1588: 
 1589:         force_flags : list or None, optional
 1590:             If None(default), default compiler flags for every CPU feature will
 1591:             be used during test.
 1592: 
 1593:         macros : list of tuples, optional
 1594:             A list of C macro definitions.
 1595:         """
 1596:         assert(name.isupper())
 1597:         assert(force_flags is None or isinstance(force_flags, list))
 1598: 
 1599:         supported = name in self.feature_supported
 1600:         if supported:
 1601:             for impl in self.feature_implies(name):
 1602:                 if not self.feature_test(impl, force_flags, macros=macros):
 1603:                     return False
 1604:             if not self.feature_test(name, force_flags, macros=macros):
 1605:                 return False
 1606:         return supported
 1607: 
 1608:     @_Cache.me
 1609:     def feature_can_autovec(self, name):
 1610:         """
 1611:         check if the feature can be auto-vectorized by the compiler
 1612:         """
 1613:         assert(isinstance(name, str))
 1614:         d = self.feature_supported[name]
 1615:         can = d.get("autovec", None)
 1616:         if can is None:
 1617:             valid_flags = [
 1618:                 self.cc_test_flags([f]) for f in d.get("flags", [])
 1619:             ]
 1620:             can = valid_flags and any(valid_flags)
 1621:         return can
 1622: 
 1623:     @_Cache.me
 1624:     def feature_extra_checks(self, name):
 1625:         """
 1626:         Return a list of supported extra checks after testing them against
 1627:         the compiler.
 1628: 
 1629:         Parameters
 1630:         ----------
 1631:         names : str
 1632:             CPU feature name in uppercase.
 1633:         """
 1634:         assert isinstance(name, str)
 1635:         d = self.feature_supported[name]
 1636:         extra_checks = d.get("extra_checks", [])
 1637:         if not extra_checks:
 1638:             return []
 1639: 
 1640:         self.dist_log("Testing extra checks for feature '%s'" % name, extra_checks)
 1641:         flags = self.feature_flags(name)
 1642:         available = []
 1643:         not_available = []
 1644:         for chk in extra_checks:
 1645:             test_path = os.path.join(
 1646:                 self.conf_check_path, "extra_%s.c" % chk.lower()
 1647:             )
 1648:             if not os.path.exists(test_path):
 1649:                 self.dist_fatal("extra check file does not exist", test_path)
 1650: 
 1651:             is_supported = self.dist_test(test_path, flags + self.cc_flags["werror"])
 1652:             if is_supported:
 1653:                 available.append(chk)
 1654:             else:
 1655:                 not_available.append(chk)
 1656: 
 1657:         if not_available:
 1658:             self.dist_log("testing failed for checks", not_available, stderr=True)
 1659:         return available
 1660: 
 1661: 
 1662:     def feature_c_preprocessor(self, feature_name, tabs=0):
 1663:         """
 1664:         Generate C preprocessor definitions and include headers of a CPU feature.
 1665: 
 1666:         Parameters
 1667:         ----------
 1668:         'feature_name': str
 1669:             CPU feature name in uppercase.
 1670:         'tabs': int
 1671:             if > 0, align the generated strings to the right depend on number of tabs.
 1672: 
 1673:         Returns
 1674:         -------
 1675:         str, generated C preprocessor
 1676: 
 1677:         Examples
 1678:         --------
 1679:         >>> self.feature_c_preprocessor("SSE3")
 1680:         /** SSE3 **/
 1681:         #define NPY_HAVE_SSE3 1
 1682:         #include <pmmintrin.h>
 1683:         """
 1684:         assert(feature_name.isupper())
 1685:         feature = self.feature_supported.get(feature_name)
 1686:         assert(feature is not None)
 1687: 
 1688:         prepr = [
 1689:             "/** %s **/" % feature_name,
 1690:             "#define %sHAVE_%s 1" % (self.conf_c_prefix, feature_name)
 1691:         ]
 1692:         prepr += [
 1693:             "#include <%s>" % h for h in feature.get("headers", [])
 1694:         ]
 1695: 
 1696:         extra_defs = feature.get("group", [])
 1697:         extra_defs += self.feature_extra_checks(feature_name)
 1698:         for edef in extra_defs:
 1699:             # Guard extra definitions in case of duplicate with
 1700:             # another feature
 1701:             prepr += [
 1702:                 "#ifndef %sHAVE_%s" % (self.conf_c_prefix, edef),
 1703:                 "\t#define %sHAVE_%s 1" % (self.conf_c_prefix, edef),
 1704:                 "#endif",
 1705:             ]
 1706: 
 1707:         if tabs > 0:
 1708:             prepr = [('\t'*tabs) + l for l in prepr]
 1709:         return '\n'.join(prepr)
 1710: 
 1711: class _Parse:
 1712:     """A helper class that parsing main arguments of `CCompilerOpt`,
 1713:     also parsing configuration statements in dispatch-able sources.
 1714: 
 1715:     Parameters
 1716:     ----------
 1717:     cpu_baseline : str or None
 1718:         minimal set of required CPU features or special options.
 1719: 
 1720:     cpu_dispatch : str or None
 1721:         dispatched set of additional CPU features or special options.
 1722: 
 1723:     Special options can be:
 1724:         - **MIN**: Enables the minimum CPU features that utilized via `_Config.conf_min_features`
 1725:         - **MAX**: Enables all supported CPU features by the Compiler and platform.
 1726:         - **NATIVE**: Enables all CPU features that supported by the current machine.
 1727:         - **NONE**: Enables nothing
 1728:         - **Operand +/-**: remove or add features, useful with options **MAX**, **MIN** and **NATIVE**.
 1729:             NOTE: operand + is only added for nominal reason.
 1730: 
 1731:     NOTES:
 1732:         - Case-insensitive among all CPU features and special options.
 1733:         - Comma or space can be used as a separator.
 1734:         - If the CPU feature is not supported by the user platform or compiler,
 1735:           it will be skipped rather than raising a fatal error.
 1736:         - Any specified CPU features to 'cpu_dispatch' will be skipped if its part of CPU baseline features
 1737:         - 'cpu_baseline' force enables implied features.
 1738: 
 1739:     Attributes
 1740:     ----------
 1741:     parse_baseline_names : list
 1742:         Final CPU baseline's feature names(sorted from low to high)
 1743:     parse_baseline_flags : list
 1744:         Compiler flags of baseline features
 1745:     parse_dispatch_names : list
 1746:         Final CPU dispatch-able feature names(sorted from low to high)
 1747:     parse_target_groups : dict
 1748:         Dictionary containing initialized target groups that configured
 1749:         through class attribute `conf_target_groups`.
 1750: 
 1751:         The key is represent the group name and value is a tuple
 1752:         contains three items :
 1753:             - bool, True if group has the 'baseline' option.
 1754:             - list, list of CPU features.
 1755:             - list, list of extra compiler flags.
 1756: 
 1757:     """
 1758:     def __init__(self, cpu_baseline, cpu_dispatch):
 1759:         self._parse_policies = dict(
 1760:             # POLICY NAME, (HAVE, NOT HAVE, [DEB])
 1761:             KEEP_BASELINE = (
 1762:                 None, self._parse_policy_not_keepbase,
 1763:                 []
 1764:             ),
 1765:             KEEP_SORT = (
 1766:                 self._parse_policy_keepsort,
 1767:                 self._parse_policy_not_keepsort,
 1768:                 []
 1769:             ),
 1770:             MAXOPT = (
 1771:                 self._parse_policy_maxopt, None,
 1772:                 []
 1773:             ),
 1774:             WERROR = (
 1775:                 self._parse_policy_werror, None,
 1776:                 []
 1777:             ),
 1778:             AUTOVEC = (
 1779:                 self._parse_policy_autovec, None,
 1780:                 ["MAXOPT"]
 1781:             )
 1782:         )
 1783:         if hasattr(self, "parse_is_cached"):
 1784:             return
 1785: 
 1786:         self.parse_baseline_names = []
 1787:         self.parse_baseline_flags = []
 1788:         self.parse_dispatch_names = []
 1789:         self.parse_target_groups = {}
 1790: 
 1791:         if self.cc_noopt:
 1792:             # skip parsing baseline and dispatch args and keep parsing target groups
 1793:             cpu_baseline = cpu_dispatch = None
 1794: 
 1795:         self.dist_log("check requested baseline")
 1796:         if cpu_baseline is not None:
 1797:             cpu_baseline = self._parse_arg_features("cpu_baseline", cpu_baseline)
 1798:             baseline_names = self.feature_names(cpu_baseline)
 1799:             self.parse_baseline_flags = self.feature_flags(baseline_names)
 1800:             self.parse_baseline_names = self.feature_sorted(
 1801:                 self.feature_implies_c(baseline_names)
 1802:             )
 1803: 
 1804:         self.dist_log("check requested dispatch-able features")
 1805:         if cpu_dispatch is not None:
 1806:             cpu_dispatch_ = self._parse_arg_features("cpu_dispatch", cpu_dispatch)
 1807:             cpu_dispatch = {
 1808:                 f for f in cpu_dispatch_
 1809:                 if f not in self.parse_baseline_names
 1810:             }
 1811:             conflict_baseline = cpu_dispatch_.difference(cpu_dispatch)
 1812:             self.parse_dispatch_names = self.feature_sorted(
 1813:                 self.feature_names(cpu_dispatch)
 1814:             )
 1815:             if len(conflict_baseline) > 0:
 1816:                 self.dist_log(
 1817:                     "skip features", conflict_baseline, "since its part of baseline"
 1818:                 )
 1819: 
 1820:         self.dist_log("initialize targets groups")
 1821:         for group_name, tokens in self.conf_target_groups.items():
 1822:             self.dist_log("parse target group", group_name)
 1823:             GROUP_NAME = group_name.upper()
 1824:             if not tokens or not tokens.strip():
 1825:                 # allow empty groups, useful in case if there's a need
 1826:                 # to disable certain group since '_parse_target_tokens()'
 1827:                 # requires at least one valid target
 1828:                 self.parse_target_groups[GROUP_NAME] = (
 1829:                     False, [], []
 1830:                 )
 1831:                 continue
 1832:             has_baseline, features, extra_flags = \
 1833:                 self._parse_target_tokens(tokens)
 1834:             self.parse_target_groups[GROUP_NAME] = (
 1835:                 has_baseline, features, extra_flags
 1836:             )
 1837: 
 1838:         self.parse_is_cached = True
 1839: 
 1840:     def parse_targets(self, source):
 1841:         """
 1842:         Fetch and parse configuration statements that required for
 1843:         defining the targeted CPU features, statements should be declared
 1844:         in the top of source in between **C** comment and start
 1845:         with a special mark **@targets**.
 1846: 
 1847:         Configuration statements are sort of keywords representing
 1848:         CPU features names, group of statements and policies, combined
 1849:         together to determine the required optimization.
 1850: 
 1851:         Parameters
 1852:         ----------
 1853:         source : str
 1854:             the path of **C** source file.
 1855: 
 1856:         Returns
 1857:         -------
 1858:         - bool, True if group has the 'baseline' option
 1859:         - list, list of CPU features
 1860:         - list, list of extra compiler flags
 1861:         """
 1862:         self.dist_log("looking for '@targets' inside -> ", source)
 1863:         # get lines between /*@targets and */
 1864:         with open(source) as fd:
 1865:             tokens = ""
 1866:             max_to_reach = 1000 # good enough, isn't?
 1867:             start_with = "@targets"
 1868:             start_pos = -1
 1869:             end_with = "*/"
 1870:             end_pos = -1
 1871:             for current_line, line in enumerate(fd):
 1872:                 if current_line == max_to_reach:
 1873:                     self.dist_fatal("reached the max of lines")
 1874:                     break
 1875:                 if start_pos == -1:
 1876:                     start_pos = line.find(start_with)
 1877:                     if start_pos == -1:
 1878:                         continue
 1879:                     start_pos += len(start_with)
 1880:                 tokens += line
 1881:                 end_pos = line.find(end_with)
 1882:                 if end_pos != -1:
 1883:                     end_pos += len(tokens) - len(line)
 1884:                     break
 1885: 
 1886:         if start_pos == -1:
 1887:             self.dist_fatal("expected to find '%s' within a C comment" % start_with)
 1888:         if end_pos == -1:
 1889:             self.dist_fatal("expected to end with '%s'" % end_with)
 1890: 
 1891:         tokens = tokens[start_pos:end_pos]
 1892:         return self._parse_target_tokens(tokens)
 1893: 
 1894:     _parse_regex_arg = re.compile(r'\s|,|([+-])')
 1895:     def _parse_arg_features(self, arg_name, req_features):
 1896:         if not isinstance(req_features, str):
 1897:             self.dist_fatal("expected a string in '%s'" % arg_name)
 1898: 
 1899:         final_features = set()
 1900:         # space and comma can be used as a separator
 1901:         tokens = list(filter(None, re.split(self._parse_regex_arg, req_features)))
 1902:         append = True # append is the default
 1903:         for tok in tokens:
 1904:             if tok[0] in ("#", "$"):
 1905:                 self.dist_fatal(
 1906:                     arg_name, "target groups and policies "
 1907:                     "aren't allowed from arguments, "
 1908:                     "only from dispatch-able sources"
 1909:                 )
 1910:             if tok == '+':
 1911:                 append = True
 1912:                 continue
 1913:             if tok == '-':
 1914:                 append = False
 1915:                 continue
 1916: 
 1917:             TOK = tok.upper() # we use upper-case internally
 1918:             features_to = set()
 1919:             if TOK == "NONE":
 1920:                 pass
 1921:             elif TOK == "NATIVE":
 1922:                 native = self.cc_flags["native"]
 1923:                 if not native:
 1924:                     self.dist_fatal(arg_name,
 1925:                         "native option isn't supported by the compiler"
 1926:                     )
 1927:                 features_to = self.feature_names(
 1928:                     force_flags=native, macros=[("DETECT_FEATURES", 1)]
 1929:                 )
 1930:             elif TOK == "MAX":
 1931:                 features_to = self.feature_supported.keys()
 1932:             elif TOK == "MIN":
 1933:                 features_to = self.feature_min
 1934:             else:
 1935:                 if TOK in self.feature_supported:
 1936:                     features_to.add(TOK)
 1937:                 else:
 1938:                     if not self.feature_is_exist(TOK):
 1939:                         self.dist_fatal(arg_name,
 1940:                             ", '%s' isn't a known feature or option" % tok
 1941:                         )
 1942:             if append:
 1943:                 final_features = final_features.union(features_to)
 1944:             else:
 1945:                 final_features = final_features.difference(features_to)
 1946: 
 1947:             append = True # back to default
 1948: 
 1949:         return final_features
 1950: 
 1951:     _parse_regex_target = re.compile(r'\s|[*,/]|([()])')
 1952:     def _parse_target_tokens(self, tokens):
 1953:         assert(isinstance(tokens, str))
 1954:         final_targets = [] # to keep it sorted as specified
 1955:         extra_flags = []
 1956:         has_baseline = False
 1957: 
 1958:         skipped  = set()
 1959:         policies = set()
 1960:         multi_target = None
 1961: 
 1962:         tokens = list(filter(None, re.split(self._parse_regex_target, tokens)))
 1963:         if not tokens:
 1964:             self.dist_fatal("expected one token at least")
 1965: 
 1966:         for tok in tokens:
 1967:             TOK = tok.upper()
 1968:             ch = tok[0]
 1969:             if ch in ('+', '-'):
 1970:                 self.dist_fatal(
 1971:                     "+/- are 'not' allowed from target's groups or @targets, "
 1972:                     "only from cpu_baseline and cpu_dispatch parms"
 1973:                 )
 1974:             elif ch == '$':
 1975:                 if multi_target is not None:
 1976:                     self.dist_fatal(
 1977:                         "policies aren't allowed inside multi-target '()'"
 1978:                         ", only CPU features"
 1979:                     )
 1980:                 policies.add(self._parse_token_policy(TOK))
 1981:             elif ch == '#':
 1982:                 if multi_target is not None:
 1983:                     self.dist_fatal(
 1984:                         "target groups aren't allowed inside multi-target '()'"
 1985:                         ", only CPU features"
 1986:                     )
 1987:                 has_baseline, final_targets, extra_flags = \
 1988:                 self._parse_token_group(TOK, has_baseline, final_targets, extra_flags)
 1989:             elif ch == '(':
 1990:                 if multi_target is not None:
 1991:                     self.dist_fatal("unclosed multi-target, missing ')'")
 1992:                 multi_target = set()
 1993:             elif ch == ')':
 1994:                 if multi_target is None:
 1995:                     self.dist_fatal("multi-target opener '(' wasn't found")
 1996:                 targets = self._parse_multi_target(multi_target)
 1997:                 if targets is None:
 1998:                     skipped.add(tuple(multi_target))
 1999:                 else:
 2000:                     if len(targets) == 1:
 2001:                         targets = targets[0]
 2002:                     if targets and targets not in final_targets:
 2003:                         final_targets.append(targets)
 2004:                 multi_target = None # back to default
 2005:             else:
 2006:                 if TOK == "BASELINE":
 2007:                     if multi_target is not None:
 2008:                         self.dist_fatal("baseline isn't allowed inside multi-target '()'")
 2009:                     has_baseline = True
 2010:                     continue
 2011: 
 2012:                 if multi_target is not None:
 2013:                     multi_target.add(TOK)
 2014:                     continue
 2015: 
 2016:                 if not self.feature_is_exist(TOK):
 2017:                     self.dist_fatal("invalid target name '%s'" % TOK)
 2018: 
 2019:                 is_enabled = (
 2020:                     TOK in self.parse_baseline_names or
 2021:                     TOK in self.parse_dispatch_names
 2022:                 )
 2023:                 if  is_enabled:
 2024:                     if TOK not in final_targets:
 2025:                         final_targets.append(TOK)
 2026:                     continue
 2027: 
 2028:                 skipped.add(TOK)
 2029: 
 2030:         if multi_target is not None:
 2031:             self.dist_fatal("unclosed multi-target, missing ')'")
 2032:         if skipped:
 2033:             self.dist_log(
 2034:                 "skip targets", skipped,
 2035:                 "not part of baseline or dispatch-able features"
 2036:             )
 2037: 
 2038:         final_targets = self.feature_untied(final_targets)
 2039: 
 2040:         # add polices dependencies
 2041:         for p in list(policies):
 2042:             _, _, deps = self._parse_policies[p]
 2043:             for d in deps:
 2044:                 if d in policies:
 2045:                     continue
 2046:                 self.dist_log(
 2047:                     "policy '%s' force enables '%s'" % (
 2048:                     p, d
 2049:                 ))
 2050:                 policies.add(d)
 2051: 
 2052:         # release policies filtrations
 2053:         for p, (have, nhave, _) in self._parse_policies.items():
 2054:             func = None
 2055:             if p in policies:
 2056:                 func = have
 2057:                 self.dist_log("policy '%s' is ON" % p)
 2058:             else:
 2059:                 func = nhave
 2060:             if not func:
 2061:                 continue
 2062:             has_baseline, final_targets, extra_flags = func(
 2063:                 has_baseline, final_targets, extra_flags
 2064:             )
 2065: 
 2066:         return has_baseline, final_targets, extra_flags
 2067: 
 2068:     def _parse_token_policy(self, token):
 2069:         """validate policy token"""
 2070:         if len(token) <= 1 or token[-1:] == token[0]:
 2071:             self.dist_fatal("'$' must stuck in the begin of policy name")
 2072:         token = token[1:]
 2073:         if token not in self._parse_policies:
 2074:             self.dist_fatal(
 2075:                 "'%s' is an invalid policy name, available policies are" % token,
 2076:                 self._parse_policies.keys()
 2077:             )
 2078:         return token
 2079: 
 2080:     def _parse_token_group(self, token, has_baseline, final_targets, extra_flags):
 2081:         """validate group token"""
 2082:         if len(token) <= 1 or token[-1:] == token[0]:
 2083:             self.dist_fatal("'#' must stuck in the begin of group name")
 2084: 
 2085:         token = token[1:]
 2086:         ghas_baseline, gtargets, gextra_flags = self.parse_target_groups.get(
 2087:             token, (False, None, [])
 2088:         )
 2089:         if gtargets is None:
 2090:             self.dist_fatal(
 2091:                 "'%s' is an invalid target group name, " % token + \
 2092:                 "available target groups are",
 2093:                 self.parse_target_groups.keys()
 2094:             )
 2095:         if ghas_baseline:
 2096:             has_baseline = True
 2097:         # always keep sorting as specified
 2098:         final_targets += [f for f in gtargets if f not in final_targets]
 2099:         extra_flags += [f for f in gextra_flags if f not in extra_flags]
 2100:         return has_baseline, final_targets, extra_flags
 2101: 
 2102:     def _parse_multi_target(self, targets):
 2103:         """validate multi targets that defined between parentheses()"""
 2104:         # remove any implied features and keep the origins
 2105:         if not targets:
 2106:             self.dist_fatal("empty multi-target '()'")
 2107:         if not all([
 2108:             self.feature_is_exist(tar) for tar in targets
 2109:         ]) :
 2110:             self.dist_fatal("invalid target name in multi-target", targets)
 2111:         if not all([
 2112:             (
 2113:                 tar in self.parse_baseline_names or
 2114:                 tar in self.parse_dispatch_names
 2115:             )
 2116:             for tar in targets
 2117:         ]) :
 2118:             return None
 2119:         targets = self.feature_ahead(targets)
 2120:         if not targets:
 2121:             return None
 2122:         # force sort multi targets, so it can be comparable
 2123:         targets = self.feature_sorted(targets)
 2124:         targets = tuple(targets) # hashable
 2125:         return targets
 2126: 
 2127:     def _parse_policy_not_keepbase(self, has_baseline, final_targets, extra_flags):
 2128:         """skip all baseline features"""
 2129:         skipped = []
 2130:         for tar in final_targets[:]:
 2131:             is_base = False
 2132:             if isinstance(tar, str):
 2133:                 is_base = tar in self.parse_baseline_names
 2134:             else:
 2135:                 # multi targets
 2136:                 is_base = all([
 2137:                     f in self.parse_baseline_names
 2138:                     for f in tar
 2139:                 ])
 2140:             if is_base:
 2141:                 skipped.append(tar)
 2142:                 final_targets.remove(tar)
 2143: 
 2144:         if skipped:
 2145:             self.dist_log("skip baseline features", skipped)
 2146: 
 2147:         return has_baseline, final_targets, extra_flags
 2148: 
 2149:     def _parse_policy_keepsort(self, has_baseline, final_targets, extra_flags):
 2150:         """leave a notice that $keep_sort is on"""
 2151:         self.dist_log(
 2152:             "policy 'keep_sort' is on, dispatch-able targets", final_targets, "\n"
 2153:             "are 'not' sorted depend on the highest interest but"
 2154:             "as specified in the dispatch-able source or the extra group"
 2155:         )
 2156:         return has_baseline, final_targets, extra_flags
 2157: 
 2158:     def _parse_policy_not_keepsort(self, has_baseline, final_targets, extra_flags):
 2159:         """sorted depend on the highest interest"""
 2160:         final_targets = self.feature_sorted(final_targets, reverse=True)
 2161:         return has_baseline, final_targets, extra_flags
 2162: 
 2163:     def _parse_policy_maxopt(self, has_baseline, final_targets, extra_flags):
 2164:         """append the compiler optimization flags"""
 2165:         if self.cc_has_debug:
 2166:             self.dist_log("debug mode is detected, policy 'maxopt' is skipped.")
 2167:         elif self.cc_noopt:
 2168:             self.dist_log("optimization is disabled, policy 'maxopt' is skipped.")
 2169:         else:
 2170:             flags = self.cc_flags["opt"]
 2171:             if not flags:
 2172:                 self.dist_log(
 2173:                     "current compiler doesn't support optimization flags, "
 2174:                     "policy 'maxopt' is skipped", stderr=True
 2175:                 )
 2176:             else:
 2177:                 extra_flags += flags
 2178:         return has_baseline, final_targets, extra_flags
 2179: 
 2180:     def _parse_policy_werror(self, has_baseline, final_targets, extra_flags):
 2181:         """force warnings to treated as errors"""
 2182:         flags = self.cc_flags["werror"]
 2183:         if not flags:
 2184:             self.dist_log(
 2185:                 "current compiler doesn't support werror flags, "
 2186:                 "warnings will 'not' treated as errors", stderr=True
 2187:             )
 2188:         else:
 2189:             self.dist_log("compiler warnings are treated as errors")
 2190:             extra_flags += flags
 2191:         return has_baseline, final_targets, extra_flags
 2192: 
 2193:     def _parse_policy_autovec(self, has_baseline, final_targets, extra_flags):
 2194:         """skip features that has no auto-vectorized support by compiler"""
 2195:         skipped = []
 2196:         for tar in final_targets[:]:
 2197:             if isinstance(tar, str):
 2198:                 can = self.feature_can_autovec(tar)
 2199:             else: # multiple target
 2200:                 can = all([
 2201:                     self.feature_can_autovec(t)
 2202:                     for t in tar
 2203:                 ])
 2204:             if not can:
 2205:                 final_targets.remove(tar)
 2206:                 skipped.append(tar)
 2207: 
 2208:         if skipped:
 2209:             self.dist_log("skip non auto-vectorized features", skipped)
 2210: 
 2211:         return has_baseline, final_targets, extra_flags
 2212: 
 2213: class CCompilerOpt(_Config, _Distutils, _Cache, _CCompiler, _Feature, _Parse):
 2214:     """
 2215:     A helper class for `CCompiler` aims to provide extra build options
 2216:     to effectively control of compiler optimizations that are directly
 2217:     related to CPU features.
 2218:     """
 2219:     def __init__(self, ccompiler, cpu_baseline="min", cpu_dispatch="max", cache_path=None):
 2220:         _Config.__init__(self)
 2221:         _Distutils.__init__(self, ccompiler)
 2222:         _Cache.__init__(self, cache_path, self.dist_info(), cpu_baseline, cpu_dispatch)
 2223:         _CCompiler.__init__(self)
 2224:         _Feature.__init__(self)
 2225:         if not self.cc_noopt and self.cc_has_native:
 2226:             self.dist_log(
 2227:                 "native flag is specified through environment variables. "
 2228:                 "force cpu-baseline='native'"
 2229:             )
 2230:             cpu_baseline = "native"
 2231:         _Parse.__init__(self, cpu_baseline, cpu_dispatch)
 2232:         # keep the requested features untouched, need it later for report
 2233:         # and trace purposes
 2234:         self._requested_baseline = cpu_baseline
 2235:         self._requested_dispatch = cpu_dispatch
 2236:         # key is the dispatch-able source and value is a tuple
 2237:         # contains two items (has_baseline[boolean], dispatched-features[list])
 2238:         self.sources_status = getattr(self, "sources_status", {})
 2239:         # every instance should has a separate one
 2240:         self.cache_private.add("sources_status")
 2241:         # set it at the end to make sure the cache writing was done after init
 2242:         # this class
 2243:         self.hit_cache = hasattr(self, "hit_cache")
 2244: 
 2245:     def is_cached(self):
 2246:         """
 2247:         Returns True if the class loaded from the cache file
 2248:         """
 2249:         return self.cache_infile and self.hit_cache
 2250: 
 2251:     def cpu_baseline_flags(self):
 2252:         """
 2253:         Returns a list of final CPU baseline compiler flags
 2254:         """
 2255:         return self.parse_baseline_flags
 2256: 
 2257:     def cpu_baseline_names(self):
 2258:         """
 2259:         return a list of final CPU baseline feature names
 2260:         """
 2261:         return self.parse_baseline_names
 2262: 
 2263:     def cpu_dispatch_names(self):
 2264:         """
 2265:         return a list of final CPU dispatch feature names
 2266:         """
 2267:         return self.parse_dispatch_names
 2268: 
 2269:     def try_dispatch(self, sources, src_dir=None, ccompiler=None, **kwargs):
 2270:         """
 2271:         Compile one or more dispatch-able sources and generates object files,
 2272:         also generates abstract C config headers and macros that
 2273:         used later for the final runtime dispatching process.
 2274: 
 2275:         The mechanism behind it is to takes each source file that specified
 2276:         in 'sources' and branching it into several files depend on
 2277:         special configuration statements that must be declared in the
 2278:         top of each source which contains targeted CPU features,
 2279:         then it compiles every branched source with the proper compiler flags.
 2280: 
 2281:         Parameters
 2282:         ----------
 2283:         sources : list
 2284:             Must be a list of dispatch-able sources file paths,
 2285:             and configuration statements must be declared inside
 2286:             each file.
 2287: 
 2288:         src_dir : str
 2289:             Path of parent directory for the generated headers and wrapped sources.
 2290:             If None(default) the files will generated in-place.
 2291: 
 2292:         ccompiler : CCompiler
 2293:             Distutils `CCompiler` instance to be used for compilation.
 2294:             If None (default), the provided instance during the initialization
 2295:             will be used instead.
 2296: 
 2297:         **kwargs : any
 2298:             Arguments to pass on to the `CCompiler.compile()`
 2299: 
 2300:         Returns
 2301:         -------
 2302:         list : generated object files
 2303: 
 2304:         Raises
 2305:         ------
 2306:         CompileError
 2307:             Raises by `CCompiler.compile()` on compiling failure.
 2308:         DistutilsError
 2309:             Some errors during checking the sanity of configuration statements.
 2310: 
 2311:         See Also
 2312:         --------
 2313:         parse_targets :
 2314:             Parsing the configuration statements of dispatch-able sources.
 2315:         """
 2316:         to_compile = {}
 2317:         baseline_flags = self.cpu_baseline_flags()
 2318:         include_dirs = kwargs.setdefault("include_dirs", [])
 2319: 
 2320:         for src in sources:
 2321:             output_dir = os.path.dirname(src)
 2322:             if src_dir:
 2323:                 if not output_dir.startswith(src_dir):
 2324:                     output_dir = os.path.join(src_dir, output_dir)
 2325:                 if output_dir not in include_dirs:
 2326:                     # To allow including the generated config header(*.dispatch.h)
 2327:                     # by the dispatch-able sources
 2328:                     include_dirs.append(output_dir)
 2329: 
 2330:             has_baseline, targets, extra_flags = self.parse_targets(src)
 2331:             nochange = self._generate_config(output_dir, src, targets, has_baseline)
 2332:             for tar in targets:
 2333:                 tar_src = self._wrap_target(output_dir, src, tar, nochange=nochange)
 2334:                 flags = tuple(extra_flags + self.feature_flags(tar))
 2335:                 to_compile.setdefault(flags, []).append(tar_src)
 2336: 
 2337:             if has_baseline:
 2338:                 flags = tuple(extra_flags + baseline_flags)
 2339:                 to_compile.setdefault(flags, []).append(src)
 2340: 
 2341:             self.sources_status[src] = (has_baseline, targets)
 2342: 
 2343:         # For these reasons, the sources are compiled in a separate loop:
 2344:         # - Gathering all sources with the same flags to benefit from
 2345:         #   the parallel compiling as much as possible.
 2346:         # - To generate all config headers of the dispatchable sources,
 2347:         #   before the compilation in case if there are dependency relationships
 2348:         #   among them.
 2349:         objects = []
 2350:         for flags, srcs in to_compile.items():
 2351:             objects += self.dist_compile(
 2352:                 srcs, list(flags), ccompiler=ccompiler, **kwargs
 2353:             )
 2354:         return objects
 2355: 
 2356:     def generate_dispatch_header(self, header_path):
 2357:         """
 2358:         Generate the dispatch header which contains the #definitions and headers
 2359:         for platform-specific instruction-sets for the enabled CPU baseline and
 2360:         dispatch-able features.
 2361: 
 2362:         Its highly recommended to take a look at the generated header
 2363:         also the generated source files via `try_dispatch()`
 2364:         in order to get the full picture.
 2365:         """
 2366:         self.dist_log("generate CPU dispatch header: (%s)" % header_path)
 2367: 
 2368:         baseline_names = self.cpu_baseline_names()
 2369:         dispatch_names = self.cpu_dispatch_names()
 2370:         baseline_len = len(baseline_names)
 2371:         dispatch_len = len(dispatch_names)
 2372: 
 2373:         header_dir = os.path.dirname(header_path)
 2374:         if not os.path.exists(header_dir):
 2375:             self.dist_log(
 2376:                 f"dispatch header dir {header_dir} does not exist, creating it",
 2377:                 stderr=True
 2378:             )
 2379:             os.makedirs(header_dir)
 2380: 
 2381:         with open(header_path, 'w') as f:
 2382:             baseline_calls = ' \\\n'.join([
 2383:                 (
 2384:                     "\t%sWITH_CPU_EXPAND_(MACRO_TO_CALL(%s, __VA_ARGS__))"
 2385:                 ) % (self.conf_c_prefix, f)
 2386:                 for f in baseline_names
 2387:             ])
 2388:             dispatch_calls = ' \\\n'.join([
 2389:                 (
 2390:                     "\t%sWITH_CPU_EXPAND_(MACRO_TO_CALL(%s, __VA_ARGS__))"
 2391:                 ) % (self.conf_c_prefix, f)
 2392:                 for f in dispatch_names
 2393:             ])
 2394:             f.write(textwrap.dedent("""\
 2395:                 /*
 2396:                  * AUTOGENERATED DON'T EDIT
 2397:                  * Please make changes to the code generator (distutils/ccompiler_opt.py)
 2398:                 */
 2399:                 #define {pfx}WITH_CPU_BASELINE  "{baseline_str}"
 2400:                 #define {pfx}WITH_CPU_DISPATCH  "{dispatch_str}"
 2401:                 #define {pfx}WITH_CPU_BASELINE_N {baseline_len}
 2402:                 #define {pfx}WITH_CPU_DISPATCH_N {dispatch_len}
 2403:                 #define {pfx}WITH_CPU_EXPAND_(X) X
 2404:                 #define {pfx}WITH_CPU_BASELINE_CALL(MACRO_TO_CALL, ...) \\
 2405:                 {baseline_calls}
 2406:                 #define {pfx}WITH_CPU_DISPATCH_CALL(MACRO_TO_CALL, ...) \\
 2407:                 {dispatch_calls}
 2408:             """).format(
 2409:                 pfx=self.conf_c_prefix, baseline_str=" ".join(baseline_names),
 2410:                 dispatch_str=" ".join(dispatch_names), baseline_len=baseline_len,
 2411:                 dispatch_len=dispatch_len, baseline_calls=baseline_calls,
 2412:                 dispatch_calls=dispatch_calls
 2413:             ))
 2414:             baseline_pre = ''
 2415:             for name in baseline_names:
 2416:                 baseline_pre += self.feature_c_preprocessor(name, tabs=1) + '\n'
 2417: 
 2418:             dispatch_pre = ''
 2419:             for name in dispatch_names:
 2420:                 dispatch_pre += textwrap.dedent("""\
 2421:                 #ifdef {pfx}CPU_TARGET_{name}
 2422:                 {pre}
 2423:                 #endif /*{pfx}CPU_TARGET_{name}*/
 2424:                 """).format(
 2425:                     pfx=self.conf_c_prefix_, name=name, pre=self.feature_c_preprocessor(
 2426:                     name, tabs=1
 2427:                 ))
 2428: 
 2429:             f.write(textwrap.dedent("""\
 2430:             /******* baseline features *******/
 2431:             {baseline_pre}
 2432:             /******* dispatch features *******/
 2433:             {dispatch_pre}
 2434:             """).format(
 2435:                 pfx=self.conf_c_prefix_, baseline_pre=baseline_pre,
 2436:                 dispatch_pre=dispatch_pre
 2437:             ))
 2438: 
 2439:     def report(self, full=False):
 2440:         report = []
 2441:         platform_rows = []
 2442:         baseline_rows = []
 2443:         dispatch_rows = []
 2444:         report.append(("Platform", platform_rows))
 2445:         report.append(("", ""))
 2446:         report.append(("CPU baseline", baseline_rows))
 2447:         report.append(("", ""))
 2448:         report.append(("CPU dispatch", dispatch_rows))
 2449: 
 2450:         ########## platform ##########
 2451:         platform_rows.append(("Architecture", (
 2452:             "unsupported" if self.cc_on_noarch else self.cc_march)
 2453:         ))
 2454:         platform_rows.append(("Compiler", (
 2455:             "unix-like"   if self.cc_is_nocc   else self.cc_name)
 2456:         ))
 2457:         ########## baseline ##########
 2458:         if self.cc_noopt:
 2459:             baseline_rows.append(("Requested", "optimization disabled"))
 2460:         else:
 2461:             baseline_rows.append(("Requested", repr(self._requested_baseline)))
 2462: 
 2463:         baseline_names = self.cpu_baseline_names()
 2464:         baseline_rows.append((
 2465:             "Enabled", (' '.join(baseline_names) if baseline_names else "none")
 2466:         ))
 2467:         baseline_flags = self.cpu_baseline_flags()
 2468:         baseline_rows.append((
 2469:             "Flags", (' '.join(baseline_flags) if baseline_flags else "none")
 2470:         ))
 2471:         extra_checks = []
 2472:         for name in baseline_names:
 2473:             extra_checks += self.feature_extra_checks(name)
 2474:         baseline_rows.append((
 2475:             "Extra checks", (' '.join(extra_checks) if extra_checks else "none")
 2476:         ))
 2477: 
 2478:         ########## dispatch ##########
 2479:         if self.cc_noopt:
 2480:             baseline_rows.append(("Requested", "optimization disabled"))
 2481:         else:
 2482:             dispatch_rows.append(("Requested", repr(self._requested_dispatch)))
 2483: 
 2484:         dispatch_names = self.cpu_dispatch_names()
 2485:         dispatch_rows.append((
 2486:             "Enabled", (' '.join(dispatch_names) if dispatch_names else "none")
 2487:         ))
 2488:         ########## Generated ##########
 2489:         # TODO:
 2490:         # - collect object names from 'try_dispatch()'
 2491:         #   then get size of each object and printed
 2492:         # - give more details about the features that not
 2493:         #   generated due compiler support
 2494:         # - find a better output's design.
 2495:         #
 2496:         target_sources = {}
 2497:         for source, (_, targets) in self.sources_status.items():
 2498:             for tar in targets:
 2499:                 target_sources.setdefault(tar, []).append(source)
 2500: 
 2501:         if not full or not target_sources:
 2502:             generated = ""
 2503:             for tar in self.feature_sorted(target_sources):
 2504:                 sources = target_sources[tar]
 2505:                 name = tar if isinstance(tar, str) else '(%s)' % ' '.join(tar)
 2506:                 generated += name + "[%d] " % len(sources)
 2507:             dispatch_rows.append(("Generated", generated[:-1] if generated else "none"))
 2508:         else:
 2509:             dispatch_rows.append(("Generated", ''))
 2510:             for tar in self.feature_sorted(target_sources):
 2511:                 sources = target_sources[tar]
 2512:                 pretty_name = tar if isinstance(tar, str) else '(%s)' % ' '.join(tar)
 2513:                 flags = ' '.join(self.feature_flags(tar))
 2514:                 implies = ' '.join(self.feature_sorted(self.feature_implies(tar)))
 2515:                 detect = ' '.join(self.feature_detect(tar))
 2516:                 extra_checks = []
 2517:                 for name in ((tar,) if isinstance(tar, str) else tar):
 2518:                     extra_checks += self.feature_extra_checks(name)
 2519:                 extra_checks = (' '.join(extra_checks) if extra_checks else "none")
 2520: 
 2521:                 dispatch_rows.append(('', ''))
 2522:                 dispatch_rows.append((pretty_name, implies))
 2523:                 dispatch_rows.append(("Flags", flags))
 2524:                 dispatch_rows.append(("Extra checks", extra_checks))
 2525:                 dispatch_rows.append(("Detect", detect))
 2526:                 for src in sources:
 2527:                     dispatch_rows.append(("", src))
 2528: 
 2529:         ###############################
 2530:         # TODO: add support for 'markdown' format
 2531:         text = []
 2532:         secs_len = [len(secs) for secs, _ in report]
 2533:         cols_len = [len(col) for _, rows in report for col, _ in rows]
 2534:         tab = ' ' * 2
 2535:         pad =  max(max(secs_len), max(cols_len))
 2536:         for sec, rows in report:
 2537:             if not sec:
 2538:                 text.append("") # empty line
 2539:                 continue
 2540:             sec += ' ' * (pad - len(sec))
 2541:             text.append(sec + tab + ': ')
 2542:             for col, val in rows:
 2543:                 col += ' ' * (pad - len(col))
 2544:                 text.append(tab + col + ': ' + val)
 2545: 
 2546:         return '\n'.join(text)
 2547: 
 2548:     def _wrap_target(self, output_dir, dispatch_src, target, nochange=False):
 2549:         assert(isinstance(target, (str, tuple)))
 2550:         if isinstance(target, str):
 2551:             ext_name = target_name = target
 2552:         else:
 2553:             # multi-target
 2554:             ext_name = '.'.join(target)
 2555:             target_name = '__'.join(target)
 2556: 
 2557:         wrap_path = os.path.join(output_dir, os.path.basename(dispatch_src))
 2558:         wrap_path = "{0}.{2}{1}".format(*os.path.splitext(wrap_path), ext_name.lower())
 2559:         if nochange and os.path.exists(wrap_path):
 2560:             return wrap_path
 2561: 
 2562:         self.dist_log("wrap dispatch-able target -> ", wrap_path)
 2563:         # sorting for readability
 2564:         features = self.feature_sorted(self.feature_implies_c(target))
 2565:         target_join = "#define %sCPU_TARGET_" % self.conf_c_prefix_
 2566:         target_defs = [target_join + f for f in features]
 2567:         target_defs = '\n'.join(target_defs)
 2568: 
 2569:         with open(wrap_path, "w") as fd:
 2570:             fd.write(textwrap.dedent("""\
 2571:             /**
 2572:              * AUTOGENERATED DON'T EDIT
 2573:              * Please make changes to the code generator \
 2574:              (distutils/ccompiler_opt.py)
 2575:              */
 2576:             #define {pfx}CPU_TARGET_MODE
 2577:             #define {pfx}CPU_TARGET_CURRENT {target_name}
 2578:             {target_defs}
 2579:             #include "{path}"
 2580:             """).format(
 2581:                 pfx=self.conf_c_prefix_, target_name=target_name,
 2582:                 path=os.path.abspath(dispatch_src), target_defs=target_defs
 2583:             ))
 2584:         return wrap_path
 2585: 
 2586:     def _generate_config(self, output_dir, dispatch_src, targets, has_baseline=False):
 2587:         config_path = os.path.basename(dispatch_src)
 2588:         config_path = os.path.splitext(config_path)[0] + '.h'
 2589:         config_path = os.path.join(output_dir, config_path)
 2590:         # check if targets didn't change to avoid recompiling
 2591:         cache_hash = self.cache_hash(targets, has_baseline)
 2592:         try:
 2593:             with open(config_path) as f:
 2594:                 last_hash = f.readline().split("cache_hash:")
 2595:                 if len(last_hash) == 2 and int(last_hash[1]) == cache_hash:
 2596:                     return True
 2597:         except OSError:
 2598:             pass
 2599: 
 2600:         os.makedirs(os.path.dirname(config_path), exist_ok=True)
 2601: 
 2602:         self.dist_log("generate dispatched config -> ", config_path)
 2603:         dispatch_calls = []
 2604:         for tar in targets:
 2605:             if isinstance(tar, str):
 2606:                 target_name = tar
 2607:             else: # multi target
 2608:                 target_name = '__'.join([t for t in tar])
 2609:             req_detect = self.feature_detect(tar)
 2610:             req_detect = '&&'.join([
 2611:                 "CHK(%s)" % f for f in req_detect
 2612:             ])
 2613:             dispatch_calls.append(
 2614:                 "\t%sCPU_DISPATCH_EXPAND_(CB((%s), %s, __VA_ARGS__))" % (
 2615:                 self.conf_c_prefix_, req_detect, target_name
 2616:             ))
 2617:         dispatch_calls = ' \\\n'.join(dispatch_calls)
 2618: 
 2619:         if has_baseline:
 2620:             baseline_calls = (
 2621:                 "\t%sCPU_DISPATCH_EXPAND_(CB(__VA_ARGS__))"
 2622:             ) % self.conf_c_prefix_
 2623:         else:
 2624:             baseline_calls = ''
 2625: 
 2626:         with open(config_path, "w") as fd:
 2627:             fd.write(textwrap.dedent("""\
 2628:             // cache_hash:{cache_hash}
 2629:             /**
 2630:              * AUTOGENERATED DON'T EDIT
 2631:              * Please make changes to the code generator (distutils/ccompiler_opt.py)
 2632:              */
 2633:             #ifndef {pfx}CPU_DISPATCH_EXPAND_
 2634:                 #define {pfx}CPU_DISPATCH_EXPAND_(X) X
 2635:             #endif
 2636:             #undef {pfx}CPU_DISPATCH_BASELINE_CALL
 2637:             #undef {pfx}CPU_DISPATCH_CALL
 2638:             #define {pfx}CPU_DISPATCH_BASELINE_CALL(CB, ...) \\
 2639:             {baseline_calls}
 2640:             #define {pfx}CPU_DISPATCH_CALL(CHK, CB, ...) \\
 2641:             {dispatch_calls}
 2642:             """).format(
 2643:                 pfx=self.conf_c_prefix_, baseline_calls=baseline_calls,
 2644:                 dispatch_calls=dispatch_calls, cache_hash=cache_hash
 2645:             ))
 2646:         return False
 2647: 
 2648: def new_ccompiler_opt(compiler, dispatch_hpath, **kwargs):
 2649:     """
 2650:     Create a new instance of 'CCompilerOpt' and generate the dispatch header
 2651:     which contains the #definitions and headers of platform-specific instruction-sets for
 2652:     the enabled CPU baseline and dispatch-able features.
 2653: 
 2654:     Parameters
 2655:     ----------
 2656:     compiler : CCompiler instance
 2657:     dispatch_hpath : str
 2658:         path of the dispatch header
 2659: 
 2660:     **kwargs: passed as-is to `CCompilerOpt(...)`
 2661:     Returns
 2662:     -------
 2663:     new instance of CCompilerOpt
 2664:     """
 2665:     opt = CCompilerOpt(compiler, **kwargs)
 2666:     if not os.path.exists(dispatch_hpath) or not opt.is_cached():
 2667:         opt.generate_dispatch_header(dispatch_hpath)
 2668:     return opt
