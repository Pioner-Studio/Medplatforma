    1: """
    2: Functions that ignore NaN.
    3: 
    4: Functions
    5: ---------
    6: 
    7: - `nanmin` -- minimum non-NaN value
    8: - `nanmax` -- maximum non-NaN value
    9: - `nanargmin` -- index of minimum non-NaN value
   10: - `nanargmax` -- index of maximum non-NaN value
   11: - `nansum` -- sum of non-NaN values
   12: - `nanprod` -- product of non-NaN values
   13: - `nancumsum` -- cumulative sum of non-NaN values
   14: - `nancumprod` -- cumulative product of non-NaN values
   15: - `nanmean` -- mean of non-NaN values
   16: - `nanvar` -- variance of non-NaN values
   17: - `nanstd` -- standard deviation of non-NaN values
   18: - `nanmedian` -- median of non-NaN values
   19: - `nanquantile` -- qth quantile of non-NaN values
   20: - `nanpercentile` -- qth percentile of non-NaN values
   21: 
   22: """
   23: import functools
   24: import warnings
   25: 
   26: import numpy as np
   27: import numpy._core.numeric as _nx
   28: from numpy._core import overrides
   29: from numpy.lib import _function_base_impl as fnb
   30: from numpy.lib._function_base_impl import _weights_are_valid
   31: 
   32: array_function_dispatch = functools.partial(
   33:     overrides.array_function_dispatch, module='numpy')
   34: 
   35: 
   36: __all__ = [
   37:     'nansum', 'nanmax', 'nanmin', 'nanargmax', 'nanargmin', 'nanmean',
   38:     'nanmedian', 'nanpercentile', 'nanvar', 'nanstd', 'nanprod',
   39:     'nancumsum', 'nancumprod', 'nanquantile'
   40:     ]
   41: 
   42: 
   43: def _nan_mask(a, out=None):
   44:     """
   45:     Parameters
   46:     ----------
   47:     a : array-like
   48:         Input array with at least 1 dimension.
   49:     out : ndarray, optional
   50:         Alternate output array in which to place the result.  The default
   51:         is ``None``; if provided, it must have the same shape as the
   52:         expected output and will prevent the allocation of a new array.
   53: 
   54:     Returns
   55:     -------
   56:     y : bool ndarray or True
   57:         A bool array where ``np.nan`` positions are marked with ``False``
   58:         and other positions are marked with ``True``. If the type of ``a``
   59:         is such that it can't possibly contain ``np.nan``, returns ``True``.
   60:     """
   61:     # we assume that a is an array for this private function
   62: 
   63:     if a.dtype.kind not in 'fc':
   64:         return True
   65: 
   66:     y = np.isnan(a, out=out)
   67:     y = np.invert(y, out=y)
   68:     return y
   69: 
   70: def _replace_nan(a, val):
   71:     """
   72:     If `a` is of inexact type, make a copy of `a`, replace NaNs with
   73:     the `val` value, and return the copy together with a boolean mask
   74:     marking the locations where NaNs were present. If `a` is not of
   75:     inexact type, do nothing and return `a` together with a mask of None.
   76: 
   77:     Note that scalars will end up as array scalars, which is important
   78:     for using the result as the value of the out argument in some
   79:     operations.
   80: 
   81:     Parameters
   82:     ----------
   83:     a : array-like
   84:         Input array.
   85:     val : float
   86:         NaN values are set to val before doing the operation.
   87: 
   88:     Returns
   89:     -------
   90:     y : ndarray
   91:         If `a` is of inexact type, return a copy of `a` with the NaNs
   92:         replaced by the fill value, otherwise return `a`.
   93:     mask: {bool, None}
   94:         If `a` is of inexact type, return a boolean mask marking locations of
   95:         NaNs, otherwise return None.
   96: 
   97:     """
   98:     a = np.asanyarray(a)
   99: 
  100:     if a.dtype == np.object_:
  101:         # object arrays do not support `isnan` (gh-9009), so make a guess
  102:         mask = np.not_equal(a, a, dtype=bool)
  103:     elif issubclass(a.dtype.type, np.inexact):
  104:         mask = np.isnan(a)
  105:     else:
  106:         mask = None
  107: 
  108:     if mask is not None:
  109:         a = np.array(a, subok=True, copy=True)
  110:         np.copyto(a, val, where=mask)
  111: 
  112:     return a, mask
  113: 
  114: 
  115: def _copyto(a, val, mask):
  116:     """
  117:     Replace values in `a` with NaN where `mask` is True.  This differs from
  118:     copyto in that it will deal with the case where `a` is a numpy scalar.
  119: 
  120:     Parameters
  121:     ----------
  122:     a : ndarray or numpy scalar
  123:         Array or numpy scalar some of whose values are to be replaced
  124:         by val.
  125:     val : numpy scalar
  126:         Value used a replacement.
  127:     mask : ndarray, scalar
  128:         Boolean array. Where True the corresponding element of `a` is
  129:         replaced by `val`. Broadcasts.
  130: 
  131:     Returns
  132:     -------
  133:     res : ndarray, scalar
  134:         Array with elements replaced or scalar `val`.
  135: 
  136:     """
  137:     if isinstance(a, np.ndarray):
  138:         np.copyto(a, val, where=mask, casting='unsafe')
  139:     else:
  140:         a = a.dtype.type(val)
  141:     return a
  142: 
  143: 
  144: def _remove_nan_1d(arr1d, second_arr1d=None, overwrite_input=False):
  145:     """
  146:     Equivalent to arr1d[~arr1d.isnan()], but in a different order
  147: 
  148:     Presumably faster as it incurs fewer copies
  149: 
  150:     Parameters
  151:     ----------
  152:     arr1d : ndarray
  153:         Array to remove nans from
  154:     second_arr1d : ndarray or None
  155:         A second array which will have the same positions removed as arr1d.
  156:     overwrite_input : bool
  157:         True if `arr1d` can be modified in place
  158: 
  159:     Returns
  160:     -------
  161:     res : ndarray
  162:         Array with nan elements removed
  163:     second_res : ndarray or None
  164:         Second array with nan element positions of first array removed.
  165:     overwrite_input : bool
  166:         True if `res` can be modified in place, given the constraint on the
  167:         input
  168:     """
  169:     if arr1d.dtype == object:
  170:         # object arrays do not support `isnan` (gh-9009), so make a guess
  171:         c = np.not_equal(arr1d, arr1d, dtype=bool)
  172:     else:
  173:         c = np.isnan(arr1d)
  174: 
  175:     s = np.nonzero(c)[0]
  176:     if s.size == arr1d.size:
  177:         warnings.warn("All-NaN slice encountered", RuntimeWarning,
  178:                       stacklevel=6)
  179:         if second_arr1d is None:
  180:             return arr1d[:0], None, True
  181:         else:
  182:             return arr1d[:0], second_arr1d[:0], True
  183:     elif s.size == 0:
  184:         return arr1d, second_arr1d, overwrite_input
  185:     else:
  186:         if not overwrite_input:
  187:             arr1d = arr1d.copy()
  188:         # select non-nans at end of array
  189:         enonan = arr1d[-s.size:][~c[-s.size:]]
  190:         # fill nans in beginning of array with non-nans of end
  191:         arr1d[s[:enonan.size]] = enonan
  192: 
  193:         if second_arr1d is None:
  194:             return arr1d[:-s.size], None, True
  195:         else:
  196:             if not overwrite_input:
  197:                 second_arr1d = second_arr1d.copy()
  198:             enonan = second_arr1d[-s.size:][~c[-s.size:]]
  199:             second_arr1d[s[:enonan.size]] = enonan
  200: 
  201:             return arr1d[:-s.size], second_arr1d[:-s.size], True
  202: 
  203: 
  204: def _divide_by_count(a, b, out=None):
  205:     """
  206:     Compute a/b ignoring invalid results. If `a` is an array the division
  207:     is done in place. If `a` is a scalar, then its type is preserved in the
  208:     output. If out is None, then a is used instead so that the division
  209:     is in place. Note that this is only called with `a` an inexact type.
  210: 
  211:     Parameters
  212:     ----------
  213:     a : {ndarray, numpy scalar}
  214:         Numerator. Expected to be of inexact type but not checked.
  215:     b : {ndarray, numpy scalar}
  216:         Denominator.
  217:     out : ndarray, optional
  218:         Alternate output array in which to place the result.  The default
  219:         is ``None``; if provided, it must have the same shape as the
  220:         expected output, but the type will be cast if necessary.
  221: 
  222:     Returns
  223:     -------
  224:     ret : {ndarray, numpy scalar}
  225:         The return value is a/b. If `a` was an ndarray the division is done
  226:         in place. If `a` is a numpy scalar, the division preserves its type.
  227: 
  228:     """
  229:     with np.errstate(invalid='ignore', divide='ignore'):
  230:         if isinstance(a, np.ndarray):
  231:             if out is None:
  232:                 return np.divide(a, b, out=a, casting='unsafe')
  233:             else:
  234:                 return np.divide(a, b, out=out, casting='unsafe')
  235:         elif out is None:
  236:             # Precaution against reduced object arrays
  237:             try:
  238:                 return a.dtype.type(a / b)
  239:             except AttributeError:
  240:                 return a / b
  241:         else:
  242:             # This is questionable, but currently a numpy scalar can
  243:             # be output to a zero dimensional array.
  244:             return np.divide(a, b, out=out, casting='unsafe')
  245: 
  246: 
  247: def _nanmin_dispatcher(a, axis=None, out=None, keepdims=None,
  248:                        initial=None, where=None):
  249:     return (a, out)
  250: 
  251: 
  252: @array_function_dispatch(_nanmin_dispatcher)
  253: def nanmin(a, axis=None, out=None, keepdims=np._NoValue, initial=np._NoValue,
  254:            where=np._NoValue):
  255:     """
  256:     Return minimum of an array or minimum along an axis, ignoring any NaNs.
  257:     When all-NaN slices are encountered a ``RuntimeWarning`` is raised and
  258:     Nan is returned for that slice.
  259: 
  260:     Parameters
  261:     ----------
  262:     a : array_like
  263:         Array containing numbers whose minimum is desired. If `a` is not an
  264:         array, a conversion is attempted.
  265:     axis : {int, tuple of int, None}, optional
  266:         Axis or axes along which the minimum is computed. The default is to compute
  267:         the minimum of the flattened array.
  268:     out : ndarray, optional
  269:         Alternate output array in which to place the result.  The default
  270:         is ``None``; if provided, it must have the same shape as the
  271:         expected output, but the type will be cast if necessary. See
  272:         :ref:`ufuncs-output-type` for more details.
  273:     keepdims : bool, optional
  274:         If this is set to True, the axes which are reduced are left
  275:         in the result as dimensions with size one. With this option,
  276:         the result will broadcast correctly against the original `a`.
  277: 
  278:         If the value is anything but the default, then
  279:         `keepdims` will be passed through to the `min` method
  280:         of sub-classes of `ndarray`.  If the sub-classes methods
  281:         does not implement `keepdims` any exceptions will be raised.
  282:     initial : scalar, optional
  283:         The maximum value of an output element. Must be present to allow
  284:         computation on empty slice. See `~numpy.ufunc.reduce` for details.
  285: 
  286:         .. versionadded:: 1.22.0
  287:     where : array_like of bool, optional
  288:         Elements to compare for the minimum. See `~numpy.ufunc.reduce`
  289:         for details.
  290: 
  291:         .. versionadded:: 1.22.0
  292: 
  293:     Returns
  294:     -------
  295:     nanmin : ndarray
  296:         An array with the same shape as `a`, with the specified axis
  297:         removed.  If `a` is a 0-d array, or if axis is None, an ndarray
  298:         scalar is returned.  The same dtype as `a` is returned.
  299: 
  300:     See Also
  301:     --------
  302:     nanmax :
  303:         The maximum value of an array along a given axis, ignoring any NaNs.
  304:     amin :
  305:         The minimum value of an array along a given axis, propagating any NaNs.
  306:     fmin :
  307:         Element-wise minimum of two arrays, ignoring any NaNs.
  308:     minimum :
  309:         Element-wise minimum of two arrays, propagating any NaNs.
  310:     isnan :
  311:         Shows which elements are Not a Number (NaN).
  312:     isfinite:
  313:         Shows which elements are neither NaN nor infinity.
  314: 
  315:     amax, fmax, maximum
  316: 
  317:     Notes
  318:     -----
  319:     NumPy uses the IEEE Standard for Binary Floating-Point for Arithmetic
  320:     (IEEE 754). This means that Not a Number is not equivalent to infinity.
  321:     Positive infinity is treated as a very large number and negative
  322:     infinity is treated as a very small (i.e. negative) number.
  323: 
  324:     If the input has a integer type the function is equivalent to np.min.
  325: 
  326:     Examples
  327:     --------
  328:     >>> import numpy as np
  329:     >>> a = np.array([[1, 2], [3, np.nan]])
  330:     >>> np.nanmin(a)
  331:     1.0
  332:     >>> np.nanmin(a, axis=0)
  333:     array([1.,  2.])
  334:     >>> np.nanmin(a, axis=1)
  335:     array([1.,  3.])
  336: 
  337:     When positive infinity and negative infinity are present:
  338: 
  339:     >>> np.nanmin([1, 2, np.nan, np.inf])
  340:     1.0
  341:     >>> np.nanmin([1, 2, np.nan, -np.inf])
  342:     -inf
  343: 
  344:     """
  345:     kwargs = {}
  346:     if keepdims is not np._NoValue:
  347:         kwargs['keepdims'] = keepdims
  348:     if initial is not np._NoValue:
  349:         kwargs['initial'] = initial
  350:     if where is not np._NoValue:
  351:         kwargs['where'] = where
  352: 
  353:     if (type(a) is np.ndarray or type(a) is np.memmap) and a.dtype != np.object_:
  354:         # Fast, but not safe for subclasses of ndarray, or object arrays,
  355:         # which do not implement isnan (gh-9009), or fmin correctly (gh-8975)
  356:         res = np.fmin.reduce(a, axis=axis, out=out, **kwargs)
  357:         if np.isnan(res).any():
  358:             warnings.warn("All-NaN slice encountered", RuntimeWarning,
  359:                           stacklevel=2)
  360:     else:
  361:         # Slow, but safe for subclasses of ndarray
  362:         a, mask = _replace_nan(a, +np.inf)
  363:         res = np.amin(a, axis=axis, out=out, **kwargs)
  364:         if mask is None:
  365:             return res
  366: 
  367:         # Check for all-NaN axis
  368:         kwargs.pop("initial", None)
  369:         mask = np.all(mask, axis=axis, **kwargs)
  370:         if np.any(mask):
  371:             res = _copyto(res, np.nan, mask)
  372:             warnings.warn("All-NaN axis encountered", RuntimeWarning,
  373:                           stacklevel=2)
  374:     return res
  375: 
  376: 
  377: def _nanmax_dispatcher(a, axis=None, out=None, keepdims=None,
  378:                        initial=None, where=None):
  379:     return (a, out)
  380: 
  381: 
  382: @array_function_dispatch(_nanmax_dispatcher)
  383: def nanmax(a, axis=None, out=None, keepdims=np._NoValue, initial=np._NoValue,
  384:            where=np._NoValue):
  385:     """
  386:     Return the maximum of an array or maximum along an axis, ignoring any
  387:     NaNs.  When all-NaN slices are encountered a ``RuntimeWarning`` is
  388:     raised and NaN is returned for that slice.
  389: 
  390:     Parameters
  391:     ----------
  392:     a : array_like
  393:         Array containing numbers whose maximum is desired. If `a` is not an
  394:         array, a conversion is attempted.
  395:     axis : {int, tuple of int, None}, optional
  396:         Axis or axes along which the maximum is computed. The default is to compute
  397:         the maximum of the flattened array.
  398:     out : ndarray, optional
  399:         Alternate output array in which to place the result.  The default
  400:         is ``None``; if provided, it must have the same shape as the
  401:         expected output, but the type will be cast if necessary. See
  402:         :ref:`ufuncs-output-type` for more details.
  403:     keepdims : bool, optional
  404:         If this is set to True, the axes which are reduced are left
  405:         in the result as dimensions with size one. With this option,
  406:         the result will broadcast correctly against the original `a`.
  407:         If the value is anything but the default, then
  408:         `keepdims` will be passed through to the `max` method
  409:         of sub-classes of `ndarray`.  If the sub-classes methods
  410:         does not implement `keepdims` any exceptions will be raised.
  411:     initial : scalar, optional
  412:         The minimum value of an output element. Must be present to allow
  413:         computation on empty slice. See `~numpy.ufunc.reduce` for details.
  414: 
  415:         .. versionadded:: 1.22.0
  416:     where : array_like of bool, optional
  417:         Elements to compare for the maximum. See `~numpy.ufunc.reduce`
  418:         for details.
  419: 
  420:         .. versionadded:: 1.22.0
  421: 
  422:     Returns
  423:     -------
  424:     nanmax : ndarray
  425:         An array with the same shape as `a`, with the specified axis removed.
  426:         If `a` is a 0-d array, or if axis is None, an ndarray scalar is
  427:         returned.  The same dtype as `a` is returned.
  428: 
  429:     See Also
  430:     --------
  431:     nanmin :
  432:         The minimum value of an array along a given axis, ignoring any NaNs.
  433:     amax :
  434:         The maximum value of an array along a given axis, propagating any NaNs.
  435:     fmax :
  436:         Element-wise maximum of two arrays, ignoring any NaNs.
  437:     maximum :
  438:         Element-wise maximum of two arrays, propagating any NaNs.
  439:     isnan :
  440:         Shows which elements are Not a Number (NaN).
  441:     isfinite:
  442:         Shows which elements are neither NaN nor infinity.
  443: 
  444:     amin, fmin, minimum
  445: 
  446:     Notes
  447:     -----
  448:     NumPy uses the IEEE Standard for Binary Floating-Point for Arithmetic
  449:     (IEEE 754). This means that Not a Number is not equivalent to infinity.
  450:     Positive infinity is treated as a very large number and negative
  451:     infinity is treated as a very small (i.e. negative) number.
  452: 
  453:     If the input has a integer type the function is equivalent to np.max.
  454: 
  455:     Examples
  456:     --------
  457:     >>> import numpy as np
  458:     >>> a = np.array([[1, 2], [3, np.nan]])
  459:     >>> np.nanmax(a)
  460:     3.0
  461:     >>> np.nanmax(a, axis=0)
  462:     array([3.,  2.])
  463:     >>> np.nanmax(a, axis=1)
  464:     array([2.,  3.])
  465: 
  466:     When positive infinity and negative infinity are present:
  467: 
  468:     >>> np.nanmax([1, 2, np.nan, -np.inf])
  469:     2.0
  470:     >>> np.nanmax([1, 2, np.nan, np.inf])
  471:     inf
  472: 
  473:     """
  474:     kwargs = {}
  475:     if keepdims is not np._NoValue:
  476:         kwargs['keepdims'] = keepdims
  477:     if initial is not np._NoValue:
  478:         kwargs['initial'] = initial
  479:     if where is not np._NoValue:
  480:         kwargs['where'] = where
  481: 
  482:     if (type(a) is np.ndarray or type(a) is np.memmap) and a.dtype != np.object_:
  483:         # Fast, but not safe for subclasses of ndarray, or object arrays,
  484:         # which do not implement isnan (gh-9009), or fmax correctly (gh-8975)
  485:         res = np.fmax.reduce(a, axis=axis, out=out, **kwargs)
  486:         if np.isnan(res).any():
  487:             warnings.warn("All-NaN slice encountered", RuntimeWarning,
  488:                           stacklevel=2)
  489:     else:
  490:         # Slow, but safe for subclasses of ndarray
  491:         a, mask = _replace_nan(a, -np.inf)
  492:         res = np.amax(a, axis=axis, out=out, **kwargs)
  493:         if mask is None:
  494:             return res
  495: 
  496:         # Check for all-NaN axis
  497:         kwargs.pop("initial", None)
  498:         mask = np.all(mask, axis=axis, **kwargs)
  499:         if np.any(mask):
  500:             res = _copyto(res, np.nan, mask)
  501:             warnings.warn("All-NaN axis encountered", RuntimeWarning,
  502:                           stacklevel=2)
  503:     return res
  504: 
  505: 
  506: def _nanargmin_dispatcher(a, axis=None, out=None, *, keepdims=None):
  507:     return (a,)
  508: 
  509: 
  510: @array_function_dispatch(_nanargmin_dispatcher)
  511: def nanargmin(a, axis=None, out=None, *, keepdims=np._NoValue):
  512:     """
  513:     Return the indices of the minimum values in the specified axis ignoring
  514:     NaNs. For all-NaN slices ``ValueError`` is raised. Warning: the results
  515:     cannot be trusted if a slice contains only NaNs and Infs.
  516: 
  517:     Parameters
  518:     ----------
  519:     a : array_like
  520:         Input data.
  521:     axis : int, optional
  522:         Axis along which to operate.  By default flattened input is used.
  523:     out : array, optional
  524:         If provided, the result will be inserted into this array. It should
  525:         be of the appropriate shape and dtype.
  526: 
  527:         .. versionadded:: 1.22.0
  528:     keepdims : bool, optional
  529:         If this is set to True, the axes which are reduced are left
  530:         in the result as dimensions with size one. With this option,
  531:         the result will broadcast correctly against the array.
  532: 
  533:         .. versionadded:: 1.22.0
  534: 
  535:     Returns
  536:     -------
  537:     index_array : ndarray
  538:         An array of indices or a single index value.
  539: 
  540:     See Also
  541:     --------
  542:     argmin, nanargmax
  543: 
  544:     Examples
  545:     --------
  546:     >>> import numpy as np
  547:     >>> a = np.array([[np.nan, 4], [2, 3]])
  548:     >>> np.argmin(a)
  549:     0
  550:     >>> np.nanargmin(a)
  551:     2
  552:     >>> np.nanargmin(a, axis=0)
  553:     array([1, 1])
  554:     >>> np.nanargmin(a, axis=1)
  555:     array([1, 0])
  556: 
  557:     """
  558:     a, mask = _replace_nan(a, np.inf)
  559:     if mask is not None and mask.size:
  560:         mask = np.all(mask, axis=axis)
  561:         if np.any(mask):
  562:             raise ValueError("All-NaN slice encountered")
  563:     res = np.argmin(a, axis=axis, out=out, keepdims=keepdims)
  564:     return res
  565: 
  566: 
  567: def _nanargmax_dispatcher(a, axis=None, out=None, *, keepdims=None):
  568:     return (a,)
  569: 
  570: 
  571: @array_function_dispatch(_nanargmax_dispatcher)
  572: def nanargmax(a, axis=None, out=None, *, keepdims=np._NoValue):
  573:     """
  574:     Return the indices of the maximum values in the specified axis ignoring
  575:     NaNs. For all-NaN slices ``ValueError`` is raised. Warning: the
  576:     results cannot be trusted if a slice contains only NaNs and -Infs.
  577: 
  578: 
  579:     Parameters
  580:     ----------
  581:     a : array_like
  582:         Input data.
  583:     axis : int, optional
  584:         Axis along which to operate.  By default flattened input is used.
  585:     out : array, optional
  586:         If provided, the result will be inserted into this array. It should
  587:         be of the appropriate shape and dtype.
  588: 
  589:         .. versionadded:: 1.22.0
  590:     keepdims : bool, optional
  591:         If this is set to True, the axes which are reduced are left
  592:         in the result as dimensions with size one. With this option,
  593:         the result will broadcast correctly against the array.
  594: 
  595:         .. versionadded:: 1.22.0
  596: 
  597:     Returns
  598:     -------
  599:     index_array : ndarray
  600:         An array of indices or a single index value.
  601: 
  602:     See Also
  603:     --------
  604:     argmax, nanargmin
  605: 
  606:     Examples
  607:     --------
  608:     >>> import numpy as np
  609:     >>> a = np.array([[np.nan, 4], [2, 3]])
  610:     >>> np.argmax(a)
  611:     0
  612:     >>> np.nanargmax(a)
  613:     1
  614:     >>> np.nanargmax(a, axis=0)
  615:     array([1, 0])
  616:     >>> np.nanargmax(a, axis=1)
  617:     array([1, 1])
  618: 
  619:     """
  620:     a, mask = _replace_nan(a, -np.inf)
  621:     if mask is not None and mask.size:
  622:         mask = np.all(mask, axis=axis)
  623:         if np.any(mask):
  624:             raise ValueError("All-NaN slice encountered")
  625:     res = np.argmax(a, axis=axis, out=out, keepdims=keepdims)
  626:     return res
  627: 
  628: 
  629: def _nansum_dispatcher(a, axis=None, dtype=None, out=None, keepdims=None,
  630:                        initial=None, where=None):
  631:     return (a, out)
  632: 
  633: 
  634: @array_function_dispatch(_nansum_dispatcher)
  635: def nansum(a, axis=None, dtype=None, out=None, keepdims=np._NoValue,
  636:            initial=np._NoValue, where=np._NoValue):
  637:     """
  638:     Return the sum of array elements over a given axis treating Not a
  639:     Numbers (NaNs) as zero.
  640: 
  641:     In NumPy versions <= 1.9.0 Nan is returned for slices that are all-NaN or
  642:     empty. In later versions zero is returned.
  643: 
  644:     Parameters
  645:     ----------
  646:     a : array_like
  647:         Array containing numbers whose sum is desired. If `a` is not an
  648:         array, a conversion is attempted.
  649:     axis : {int, tuple of int, None}, optional
  650:         Axis or axes along which the sum is computed. The default is to compute the
  651:         sum of the flattened array.
  652:     dtype : data-type, optional
  653:         The type of the returned array and of the accumulator in which the
  654:         elements are summed.  By default, the dtype of `a` is used.  An
  655:         exception is when `a` has an integer type with less precision than
  656:         the platform (u)intp. In that case, the default will be either
  657:         (u)int32 or (u)int64 depending on whether the platform is 32 or 64
  658:         bits. For inexact inputs, dtype must be inexact.
  659:     out : ndarray, optional
  660:         Alternate output array in which to place the result.  The default
  661:         is ``None``. If provided, it must have the same shape as the
  662:         expected output, but the type will be cast if necessary.  See
  663:         :ref:`ufuncs-output-type` for more details. The casting of NaN to integer
  664:         can yield unexpected results.
  665:     keepdims : bool, optional
  666:         If this is set to True, the axes which are reduced are left
  667:         in the result as dimensions with size one. With this option,
  668:         the result will broadcast correctly against the original `a`.
  669: 
  670:         If the value is anything but the default, then
  671:         `keepdims` will be passed through to the `mean` or `sum` methods
  672:         of sub-classes of `ndarray`.  If the sub-classes methods
  673:         does not implement `keepdims` any exceptions will be raised.
  674:     initial : scalar, optional
  675:         Starting value for the sum. See `~numpy.ufunc.reduce` for details.
  676: 
  677:         .. versionadded:: 1.22.0
  678:     where : array_like of bool, optional
  679:         Elements to include in the sum. See `~numpy.ufunc.reduce` for details.
  680: 
  681:         .. versionadded:: 1.22.0
  682: 
  683:     Returns
  684:     -------
  685:     nansum : ndarray.
  686:         A new array holding the result is returned unless `out` is
  687:         specified, in which it is returned. The result has the same
  688:         size as `a`, and the same shape as `a` if `axis` is not None
  689:         or `a` is a 1-d array.
  690: 
  691:     See Also
  692:     --------
  693:     numpy.sum : Sum across array propagating NaNs.
  694:     isnan : Show which elements are NaN.
  695:     isfinite : Show which elements are not NaN or +/-inf.
  696: 
  697:     Notes
  698:     -----
  699:     If both positive and negative infinity are present, the sum will be Not
  700:     A Number (NaN).
  701: 
  702:     Examples
  703:     --------
  704:     >>> import numpy as np
  705:     >>> np.nansum(1)
  706:     1
  707:     >>> np.nansum([1])
  708:     1
  709:     >>> np.nansum([1, np.nan])
  710:     1.0
  711:     >>> a = np.array([[1, 1], [1, np.nan]])
  712:     >>> np.nansum(a)
  713:     3.0
  714:     >>> np.nansum(a, axis=0)
  715:     array([2.,  1.])
  716:     >>> np.nansum([1, np.nan, np.inf])
  717:     inf
  718:     >>> np.nansum([1, np.nan, -np.inf])
  719:     -inf
  720:     >>> from numpy.testing import suppress_warnings
  721:     >>> with np.errstate(invalid="ignore"):
  722:     ...     np.nansum([1, np.nan, np.inf, -np.inf]) # both +/- infinity present
  723:     np.float64(nan)
  724: 
  725:     """
  726:     a, mask = _replace_nan(a, 0)
  727:     return np.sum(a, axis=axis, dtype=dtype, out=out, keepdims=keepdims,
  728:                   initial=initial, where=where)
  729: 
  730: 
  731: def _nanprod_dispatcher(a, axis=None, dtype=None, out=None, keepdims=None,
  732:                         initial=None, where=None):
  733:     return (a, out)
  734: 
  735: 
  736: @array_function_dispatch(_nanprod_dispatcher)
  737: def nanprod(a, axis=None, dtype=None, out=None, keepdims=np._NoValue,
  738:             initial=np._NoValue, where=np._NoValue):
  739:     """
  740:     Return the product of array elements over a given axis treating Not a
  741:     Numbers (NaNs) as ones.
  742: 
  743:     One is returned for slices that are all-NaN or empty.
  744: 
  745:     Parameters
  746:     ----------
  747:     a : array_like
  748:         Array containing numbers whose product is desired. If `a` is not an
  749:         array, a conversion is attempted.
  750:     axis : {int, tuple of int, None}, optional
  751:         Axis or axes along which the product is computed. The default is to compute
  752:         the product of the flattened array.
  753:     dtype : data-type, optional
  754:         The type of the returned array and of the accumulator in which the
  755:         elements are summed.  By default, the dtype of `a` is used.  An
  756:         exception is when `a` has an integer type with less precision than
  757:         the platform (u)intp. In that case, the default will be either
  758:         (u)int32 or (u)int64 depending on whether the platform is 32 or 64
  759:         bits. For inexact inputs, dtype must be inexact.
  760:     out : ndarray, optional
  761:         Alternate output array in which to place the result.  The default
  762:         is ``None``. If provided, it must have the same shape as the
  763:         expected output, but the type will be cast if necessary. See
  764:         :ref:`ufuncs-output-type` for more details. The casting of NaN to integer
  765:         can yield unexpected results.
  766:     keepdims : bool, optional
  767:         If True, the axes which are reduced are left in the result as
  768:         dimensions with size one. With this option, the result will
  769:         broadcast correctly against the original `arr`.
  770:     initial : scalar, optional
  771:         The starting value for this product. See `~numpy.ufunc.reduce`
  772:         for details.
  773: 
  774:         .. versionadded:: 1.22.0
  775:     where : array_like of bool, optional
  776:         Elements to include in the product. See `~numpy.ufunc.reduce`
  777:         for details.
  778: 
  779:         .. versionadded:: 1.22.0
  780: 
  781:     Returns
  782:     -------
  783:     nanprod : ndarray
  784:         A new array holding the result is returned unless `out` is
  785:         specified, in which case it is returned.
  786: 
  787:     See Also
  788:     --------
  789:     numpy.prod : Product across array propagating NaNs.
  790:     isnan : Show which elements are NaN.
  791: 
  792:     Examples
  793:     --------
  794:     >>> import numpy as np
  795:     >>> np.nanprod(1)
  796:     1
  797:     >>> np.nanprod([1])
  798:     1
  799:     >>> np.nanprod([1, np.nan])
  800:     1.0
  801:     >>> a = np.array([[1, 2], [3, np.nan]])
  802:     >>> np.nanprod(a)
  803:     6.0
  804:     >>> np.nanprod(a, axis=0)
  805:     array([3., 2.])
  806: 
  807:     """
  808:     a, mask = _replace_nan(a, 1)
  809:     return np.prod(a, axis=axis, dtype=dtype, out=out, keepdims=keepdims,
  810:                    initial=initial, where=where)
  811: 
  812: 
  813: def _nancumsum_dispatcher(a, axis=None, dtype=None, out=None):
  814:     return (a, out)
  815: 
  816: 
  817: @array_function_dispatch(_nancumsum_dispatcher)
  818: def nancumsum(a, axis=None, dtype=None, out=None):
  819:     """
  820:     Return the cumulative sum of array elements over a given axis treating Not a
  821:     Numbers (NaNs) as zero.  The cumulative sum does not change when NaNs are
  822:     encountered and leading NaNs are replaced by zeros.
  823: 
  824:     Zeros are returned for slices that are all-NaN or empty.
  825: 
  826:     Parameters
  827:     ----------
  828:     a : array_like
  829:         Input array.
  830:     axis : int, optional
  831:         Axis along which the cumulative sum is computed. The default
  832:         (None) is to compute the cumsum over the flattened array.
  833:     dtype : dtype, optional
  834:         Type of the returned array and of the accumulator in which the
  835:         elements are summed.  If `dtype` is not specified, it defaults
  836:         to the dtype of `a`, unless `a` has an integer dtype with a
  837:         precision less than that of the default platform integer.  In
  838:         that case, the default platform integer is used.
  839:     out : ndarray, optional
  840:         Alternative output array in which to place the result. It must
  841:         have the same shape and buffer length as the expected output
  842:         but the type will be cast if necessary. See :ref:`ufuncs-output-type` for
  843:         more details.
  844: 
  845:     Returns
  846:     -------
  847:     nancumsum : ndarray.
  848:         A new array holding the result is returned unless `out` is
  849:         specified, in which it is returned. The result has the same
  850:         size as `a`, and the same shape as `a` if `axis` is not None
  851:         or `a` is a 1-d array.
  852: 
  853:     See Also
  854:     --------
  855:     numpy.cumsum : Cumulative sum across array propagating NaNs.
  856:     isnan : Show which elements are NaN.
  857: 
  858:     Examples
  859:     --------
  860:     >>> import numpy as np
  861:     >>> np.nancumsum(1)
  862:     array([1])
  863:     >>> np.nancumsum([1])
  864:     array([1])
  865:     >>> np.nancumsum([1, np.nan])
  866:     array([1.,  1.])
  867:     >>> a = np.array([[1, 2], [3, np.nan]])
  868:     >>> np.nancumsum(a)
  869:     array([1.,  3.,  6.,  6.])
  870:     >>> np.nancumsum(a, axis=0)
  871:     array([[1.,  2.],
  872:            [4.,  2.]])
  873:     >>> np.nancumsum(a, axis=1)
  874:     array([[1.,  3.],
  875:            [3.,  3.]])
  876: 
  877:     """
  878:     a, mask = _replace_nan(a, 0)
  879:     return np.cumsum(a, axis=axis, dtype=dtype, out=out)
  880: 
  881: 
  882: def _nancumprod_dispatcher(a, axis=None, dtype=None, out=None):
  883:     return (a, out)
  884: 
  885: 
  886: @array_function_dispatch(_nancumprod_dispatcher)
  887: def nancumprod(a, axis=None, dtype=None, out=None):
  888:     """
  889:     Return the cumulative product of array elements over a given axis treating Not a
  890:     Numbers (NaNs) as one.  The cumulative product does not change when NaNs are
  891:     encountered and leading NaNs are replaced by ones.
  892: 
  893:     Ones are returned for slices that are all-NaN or empty.
  894: 
  895:     Parameters
  896:     ----------
  897:     a : array_like
  898:         Input array.
  899:     axis : int, optional
  900:         Axis along which the cumulative product is computed.  By default
  901:         the input is flattened.
  902:     dtype : dtype, optional
  903:         Type of the returned array, as well as of the accumulator in which
  904:         the elements are multiplied.  If *dtype* is not specified, it
  905:         defaults to the dtype of `a`, unless `a` has an integer dtype with
  906:         a precision less than that of the default platform integer.  In
  907:         that case, the default platform integer is used instead.
  908:     out : ndarray, optional
  909:         Alternative output array in which to place the result. It must
  910:         have the same shape and buffer length as the expected output
  911:         but the type of the resulting values will be cast if necessary.
  912: 
  913:     Returns
  914:     -------
  915:     nancumprod : ndarray
  916:         A new array holding the result is returned unless `out` is
  917:         specified, in which case it is returned.
  918: 
  919:     See Also
  920:     --------
  921:     numpy.cumprod : Cumulative product across array propagating NaNs.
  922:     isnan : Show which elements are NaN.
  923: 
  924:     Examples
  925:     --------
  926:     >>> import numpy as np
  927:     >>> np.nancumprod(1)
  928:     array([1])
  929:     >>> np.nancumprod([1])
  930:     array([1])
  931:     >>> np.nancumprod([1, np.nan])
  932:     array([1.,  1.])
  933:     >>> a = np.array([[1, 2], [3, np.nan]])
  934:     >>> np.nancumprod(a)
  935:     array([1.,  2.,  6.,  6.])
  936:     >>> np.nancumprod(a, axis=0)
  937:     array([[1.,  2.],
  938:            [3.,  2.]])
  939:     >>> np.nancumprod(a, axis=1)
  940:     array([[1.,  2.],
  941:            [3.,  3.]])
  942: 
  943:     """
  944:     a, mask = _replace_nan(a, 1)
  945:     return np.cumprod(a, axis=axis, dtype=dtype, out=out)
  946: 
  947: 
  948: def _nanmean_dispatcher(a, axis=None, dtype=None, out=None, keepdims=None,
  949:                         *, where=None):
  950:     return (a, out)
  951: 
  952: 
  953: @array_function_dispatch(_nanmean_dispatcher)
  954: def nanmean(a, axis=None, dtype=None, out=None, keepdims=np._NoValue,
  955:             *, where=np._NoValue):
  956:     """
  957:     Compute the arithmetic mean along the specified axis, ignoring NaNs.
  958: 
  959:     Returns the average of the array elements.  The average is taken over
  960:     the flattened array by default, otherwise over the specified axis.
  961:     `float64` intermediate and return values are used for integer inputs.
  962: 
  963:     For all-NaN slices, NaN is returned and a `RuntimeWarning` is raised.
  964: 
  965:     Parameters
  966:     ----------
  967:     a : array_like
  968:         Array containing numbers whose mean is desired. If `a` is not an
  969:         array, a conversion is attempted.
  970:     axis : {int, tuple of int, None}, optional
  971:         Axis or axes along which the means are computed. The default is to compute
  972:         the mean of the flattened array.
  973:     dtype : data-type, optional
  974:         Type to use in computing the mean.  For integer inputs, the default
  975:         is `float64`; for inexact inputs, it is the same as the input
  976:         dtype.
  977:     out : ndarray, optional
  978:         Alternate output array in which to place the result.  The default
  979:         is ``None``; if provided, it must have the same shape as the
  980:         expected output, but the type will be cast if necessary.
  981:         See :ref:`ufuncs-output-type` for more details.
  982:     keepdims : bool, optional
  983:         If this is set to True, the axes which are reduced are left
  984:         in the result as dimensions with size one. With this option,
  985:         the result will broadcast correctly against the original `a`.
  986: 
  987:         If the value is anything but the default, then
  988:         `keepdims` will be passed through to the `mean` or `sum` methods
  989:         of sub-classes of `ndarray`.  If the sub-classes methods
  990:         does not implement `keepdims` any exceptions will be raised.
  991:     where : array_like of bool, optional
  992:         Elements to include in the mean. See `~numpy.ufunc.reduce` for details.
  993: 
  994:         .. versionadded:: 1.22.0
  995: 
  996:     Returns
  997:     -------
  998:     m : ndarray, see dtype parameter above
  999:         If `out=None`, returns a new array containing the mean values,
 1000:         otherwise a reference to the output array is returned. Nan is
 1001:         returned for slices that contain only NaNs.
 1002: 
 1003:     See Also
 1004:     --------
 1005:     average : Weighted average
 1006:     mean : Arithmetic mean taken while not ignoring NaNs
 1007:     var, nanvar
 1008: 
 1009:     Notes
 1010:     -----
 1011:     The arithmetic mean is the sum of the non-NaN elements along the axis
 1012:     divided by the number of non-NaN elements.
 1013: 
 1014:     Note that for floating-point input, the mean is computed using the same
 1015:     precision the input has.  Depending on the input data, this can cause
 1016:     the results to be inaccurate, especially for `float32`.  Specifying a
 1017:     higher-precision accumulator using the `dtype` keyword can alleviate
 1018:     this issue.
 1019: 
 1020:     Examples
 1021:     --------
 1022:     >>> import numpy as np
 1023:     >>> a = np.array([[1, np.nan], [3, 4]])
 1024:     >>> np.nanmean(a)
 1025:     2.6666666666666665
 1026:     >>> np.nanmean(a, axis=0)
 1027:     array([2.,  4.])
 1028:     >>> np.nanmean(a, axis=1)
 1029:     array([1.,  3.5]) # may vary
 1030: 
 1031:     """
 1032:     arr, mask = _replace_nan(a, 0)
 1033:     if mask is None:
 1034:         return np.mean(arr, axis=axis, dtype=dtype, out=out, keepdims=keepdims,
 1035:                        where=where)
 1036: 
 1037:     if dtype is not None:
 1038:         dtype = np.dtype(dtype)
 1039:     if dtype is not None and not issubclass(dtype.type, np.inexact):
 1040:         raise TypeError("If a is inexact, then dtype must be inexact")
 1041:     if out is not None and not issubclass(out.dtype.type, np.inexact):
 1042:         raise TypeError("If a is inexact, then out must be inexact")
 1043: 
 1044:     cnt = np.sum(~mask, axis=axis, dtype=np.intp, keepdims=keepdims,
 1045:                  where=where)
 1046:     tot = np.sum(arr, axis=axis, dtype=dtype, out=out, keepdims=keepdims,
 1047:                  where=where)
 1048:     avg = _divide_by_count(tot, cnt, out=out)
 1049: 
 1050:     isbad = (cnt == 0)
 1051:     if isbad.any():
 1052:         warnings.warn("Mean of empty slice", RuntimeWarning, stacklevel=2)
 1053:         # NaN is the only possible bad value, so no further
 1054:         # action is needed to handle bad results.
 1055:     return avg
 1056: 
 1057: 
 1058: def _nanmedian1d(arr1d, overwrite_input=False):
 1059:     """
 1060:     Private function for rank 1 arrays. Compute the median ignoring NaNs.
 1061:     See nanmedian for parameter usage
 1062:     """
 1063:     arr1d_parsed, _, overwrite_input = _remove_nan_1d(
 1064:         arr1d, overwrite_input=overwrite_input,
 1065:     )
 1066: 
 1067:     if arr1d_parsed.size == 0:
 1068:         # Ensure that a nan-esque scalar of the appropriate type (and unit)
 1069:         # is returned for `timedelta64` and `complexfloating`
 1070:         return arr1d[-1]
 1071: 
 1072:     return np.median(arr1d_parsed, overwrite_input=overwrite_input)
 1073: 
 1074: 
 1075: def _nanmedian(a, axis=None, out=None, overwrite_input=False):
 1076:     """
 1077:     Private function that doesn't support extended axis or keepdims.
 1078:     These methods are extended to this function using _ureduce
 1079:     See nanmedian for parameter usage
 1080: 
 1081:     """
 1082:     if axis is None or a.ndim == 1:
 1083:         part = a.ravel()
 1084:         if out is None:
 1085:             return _nanmedian1d(part, overwrite_input)
 1086:         else:
 1087:             out[...] = _nanmedian1d(part, overwrite_input)
 1088:             return out
 1089:     else:
 1090:         # for small medians use sort + indexing which is still faster than
 1091:         # apply_along_axis
 1092:         # benchmarked with shuffled (50, 50, x) containing a few NaN
 1093:         if a.shape[axis] < 600:
 1094:             return _nanmedian_small(a, axis, out, overwrite_input)
 1095:         result = np.apply_along_axis(_nanmedian1d, axis, a, overwrite_input)
 1096:         if out is not None:
 1097:             out[...] = result
 1098:         return result
 1099: 
 1100: 
 1101: def _nanmedian_small(a, axis=None, out=None, overwrite_input=False):
 1102:     """
 1103:     sort + indexing median, faster for small medians along multiple
 1104:     dimensions due to the high overhead of apply_along_axis
 1105: 
 1106:     see nanmedian for parameter usage
 1107:     """
 1108:     a = np.ma.masked_array(a, np.isnan(a))
 1109:     m = np.ma.median(a, axis=axis, overwrite_input=overwrite_input)
 1110:     for i in range(np.count_nonzero(m.mask.ravel())):
 1111:         warnings.warn("All-NaN slice encountered", RuntimeWarning,
 1112:                       stacklevel=5)
 1113: 
 1114:     fill_value = np.timedelta64("NaT") if m.dtype.kind == "m" else np.nan
 1115:     if out is not None:
 1116:         out[...] = m.filled(fill_value)
 1117:         return out
 1118:     return m.filled(fill_value)
 1119: 
 1120: 
 1121: def _nanmedian_dispatcher(
 1122:         a, axis=None, out=None, overwrite_input=None, keepdims=None):
 1123:     return (a, out)
 1124: 
 1125: 
 1126: @array_function_dispatch(_nanmedian_dispatcher)
 1127: def nanmedian(a, axis=None, out=None, overwrite_input=False, keepdims=np._NoValue):
 1128:     """
 1129:     Compute the median along the specified axis, while ignoring NaNs.
 1130: 
 1131:     Returns the median of the array elements.
 1132: 
 1133:     Parameters
 1134:     ----------
 1135:     a : array_like
 1136:         Input array or object that can be converted to an array.
 1137:     axis : {int, sequence of int, None}, optional
 1138:         Axis or axes along which the medians are computed. The default
 1139:         is to compute the median along a flattened version of the array.
 1140:         A sequence of axes is supported since version 1.9.0.
 1141:     out : ndarray, optional
 1142:         Alternative output array in which to place the result. It must
 1143:         have the same shape and buffer length as the expected output,
 1144:         but the type (of the output) will be cast if necessary.
 1145:     overwrite_input : bool, optional
 1146:        If True, then allow use of memory of input array `a` for
 1147:        calculations. The input array will be modified by the call to
 1148:        `median`. This will save memory when you do not need to preserve
 1149:        the contents of the input array. Treat the input as undefined,
 1150:        but it will probably be fully or partially sorted. Default is
 1151:        False. If `overwrite_input` is ``True`` and `a` is not already an
 1152:        `ndarray`, an error will be raised.
 1153:     keepdims : bool, optional
 1154:         If this is set to True, the axes which are reduced are left
 1155:         in the result as dimensions with size one. With this option,
 1156:         the result will broadcast correctly against the original `a`.
 1157: 
 1158:         If this is anything but the default value it will be passed
 1159:         through (in the special case of an empty array) to the
 1160:         `mean` function of the underlying array.  If the array is
 1161:         a sub-class and `mean` does not have the kwarg `keepdims` this
 1162:         will raise a RuntimeError.
 1163: 
 1164:     Returns
 1165:     -------
 1166:     median : ndarray
 1167:         A new array holding the result. If the input contains integers
 1168:         or floats smaller than ``float64``, then the output data-type is
 1169:         ``np.float64``.  Otherwise, the data-type of the output is the
 1170:         same as that of the input. If `out` is specified, that array is
 1171:         returned instead.
 1172: 
 1173:     See Also
 1174:     --------
 1175:     mean, median, percentile
 1176: 
 1177:     Notes
 1178:     -----
 1179:     Given a vector ``V`` of length ``N``, the median of ``V`` is the
 1180:     middle value of a sorted copy of ``V``, ``V_sorted`` - i.e.,
 1181:     ``V_sorted[(N-1)/2]``, when ``N`` is odd and the average of the two
 1182:     middle values of ``V_sorted`` when ``N`` is even.
 1183: 
 1184:     Examples
 1185:     --------
 1186:     >>> import numpy as np
 1187:     >>> a = np.array([[10.0, 7, 4], [3, 2, 1]])
 1188:     >>> a[0, 1] = np.nan
 1189:     >>> a
 1190:     array([[10., nan,  4.],
 1191:            [ 3.,  2.,  1.]])
 1192:     >>> np.median(a)
 1193:     np.float64(nan)
 1194:     >>> np.nanmedian(a)
 1195:     3.0
 1196:     >>> np.nanmedian(a, axis=0)
 1197:     array([6.5, 2. , 2.5])
 1198:     >>> np.median(a, axis=1)
 1199:     array([nan,  2.])
 1200:     >>> b = a.copy()
 1201:     >>> np.nanmedian(b, axis=1, overwrite_input=True)
 1202:     array([7.,  2.])
 1203:     >>> assert not np.all(a==b)
 1204:     >>> b = a.copy()
 1205:     >>> np.nanmedian(b, axis=None, overwrite_input=True)
 1206:     3.0
 1207:     >>> assert not np.all(a==b)
 1208: 
 1209:     """
 1210:     a = np.asanyarray(a)
 1211:     # apply_along_axis in _nanmedian doesn't handle empty arrays well,
 1212:     # so deal them upfront
 1213:     if a.size == 0:
 1214:         return np.nanmean(a, axis, out=out, keepdims=keepdims)
 1215: 
 1216:     return fnb._ureduce(a, func=_nanmedian, keepdims=keepdims,
 1217:                         axis=axis, out=out,
 1218:                         overwrite_input=overwrite_input)
 1219: 
 1220: 
 1221: def _nanpercentile_dispatcher(
 1222:         a, q, axis=None, out=None, overwrite_input=None,
 1223:         method=None, keepdims=None, *, weights=None, interpolation=None):
 1224:     return (a, q, out, weights)
 1225: 
 1226: 
 1227: @array_function_dispatch(_nanpercentile_dispatcher)
 1228: def nanpercentile(
 1229:         a,
 1230:         q,
 1231:         axis=None,
 1232:         out=None,
 1233:         overwrite_input=False,
 1234:         method="linear",
 1235:         keepdims=np._NoValue,
 1236:         *,
 1237:         weights=None,
 1238:         interpolation=None,
 1239: ):
 1240:     """
 1241:     Compute the qth percentile of the data along the specified axis,
 1242:     while ignoring nan values.
 1243: 
 1244:     Returns the qth percentile(s) of the array elements.
 1245: 
 1246:     Parameters
 1247:     ----------
 1248:     a : array_like
 1249:         Input array or object that can be converted to an array, containing
 1250:         nan values to be ignored.
 1251:     q : array_like of float
 1252:         Percentile or sequence of percentiles to compute, which must be
 1253:         between 0 and 100 inclusive.
 1254:     axis : {int, tuple of int, None}, optional
 1255:         Axis or axes along which the percentiles are computed. The default
 1256:         is to compute the percentile(s) along a flattened version of the
 1257:         array.
 1258:     out : ndarray, optional
 1259:         Alternative output array in which to place the result. It must have
 1260:         the same shape and buffer length as the expected output, but the
 1261:         type (of the output) will be cast if necessary.
 1262:     overwrite_input : bool, optional
 1263:         If True, then allow the input array `a` to be modified by
 1264:         intermediate calculations, to save memory. In this case, the
 1265:         contents of the input `a` after this function completes is
 1266:         undefined.
 1267:     method : str, optional
 1268:         This parameter specifies the method to use for estimating the
 1269:         percentile.  There are many different methods, some unique to NumPy.
 1270:         See the notes for explanation.  The options sorted by their R type
 1271:         as summarized in the H&F paper [1]_ are:
 1272: 
 1273:         1. 'inverted_cdf'
 1274:         2. 'averaged_inverted_cdf'
 1275:         3. 'closest_observation'
 1276:         4. 'interpolated_inverted_cdf'
 1277:         5. 'hazen'
 1278:         6. 'weibull'
 1279:         7. 'linear'  (default)
 1280:         8. 'median_unbiased'
 1281:         9. 'normal_unbiased'
 1282: 
 1283:         The first three methods are discontinuous.  NumPy further defines the
 1284:         following discontinuous variations of the default 'linear' (7.) option:
 1285: 
 1286:         * 'lower'
 1287:         * 'higher',
 1288:         * 'midpoint'
 1289:         * 'nearest'
 1290: 
 1291:         .. versionchanged:: 1.22.0
 1292:             This argument was previously called "interpolation" and only
 1293:             offered the "linear" default and last four options.
 1294: 
 1295:     keepdims : bool, optional
 1296:         If this is set to True, the axes which are reduced are left in
 1297:         the result as dimensions with size one. With this option, the
 1298:         result will broadcast correctly against the original array `a`.
 1299: 
 1300:         If this is anything but the default value it will be passed
 1301:         through (in the special case of an empty array) to the
 1302:         `mean` function of the underlying array.  If the array is
 1303:         a sub-class and `mean` does not have the kwarg `keepdims` this
 1304:         will raise a RuntimeError.
 1305: 
 1306:     weights : array_like, optional
 1307:         An array of weights associated with the values in `a`. Each value in
 1308:         `a` contributes to the percentile according to its associated weight.
 1309:         The weights array can either be 1-D (in which case its length must be
 1310:         the size of `a` along the given axis) or of the same shape as `a`.
 1311:         If `weights=None`, then all data in `a` are assumed to have a
 1312:         weight equal to one.
 1313:         Only `method="inverted_cdf"` supports weights.
 1314: 
 1315:         .. versionadded:: 2.0.0
 1316: 
 1317:     interpolation : str, optional
 1318:         Deprecated name for the method keyword argument.
 1319: 
 1320:         .. deprecated:: 1.22.0
 1321: 
 1322:     Returns
 1323:     -------
 1324:     percentile : scalar or ndarray
 1325:         If `q` is a single percentile and `axis=None`, then the result
 1326:         is a scalar. If multiple percentiles are given, first axis of
 1327:         the result corresponds to the percentiles. The other axes are
 1328:         the axes that remain after the reduction of `a`. If the input
 1329:         contains integers or floats smaller than ``float64``, the output
 1330:         data-type is ``float64``. Otherwise, the output data-type is the
 1331:         same as that of the input. If `out` is specified, that array is
 1332:         returned instead.
 1333: 
 1334:     See Also
 1335:     --------
 1336:     nanmean
 1337:     nanmedian : equivalent to ``nanpercentile(..., 50)``
 1338:     percentile, median, mean
 1339:     nanquantile : equivalent to nanpercentile, except q in range [0, 1].
 1340: 
 1341:     Notes
 1342:     -----
 1343:     The behavior of `numpy.nanpercentile` with percentage `q` is that of
 1344:     `numpy.quantile` with argument ``q/100`` (ignoring nan values).
 1345:     For more information, please see `numpy.quantile`.
 1346: 
 1347:     Examples
 1348:     --------
 1349:     >>> import numpy as np
 1350:     >>> a = np.array([[10., 7., 4.], [3., 2., 1.]])
 1351:     >>> a[0][1] = np.nan
 1352:     >>> a
 1353:     array([[10.,  nan,   4.],
 1354:           [ 3.,   2.,   1.]])
 1355:     >>> np.percentile(a, 50)
 1356:     np.float64(nan)
 1357:     >>> np.nanpercentile(a, 50)
 1358:     3.0
 1359:     >>> np.nanpercentile(a, 50, axis=0)
 1360:     array([6.5, 2. , 2.5])
 1361:     >>> np.nanpercentile(a, 50, axis=1, keepdims=True)
 1362:     array([[7.],
 1363:            [2.]])
 1364:     >>> m = np.nanpercentile(a, 50, axis=0)
 1365:     >>> out = np.zeros_like(m)
 1366:     >>> np.nanpercentile(a, 50, axis=0, out=out)
 1367:     array([6.5, 2. , 2.5])
 1368:     >>> m
 1369:     array([6.5,  2. ,  2.5])
 1370: 
 1371:     >>> b = a.copy()
 1372:     >>> np.nanpercentile(b, 50, axis=1, overwrite_input=True)
 1373:     array([7., 2.])
 1374:     >>> assert not np.all(a==b)
 1375: 
 1376:     References
 1377:     ----------
 1378:     .. [1] R. J. Hyndman and Y. Fan,
 1379:        "Sample quantiles in statistical packages,"
 1380:        The American Statistician, 50(4), pp. 361-365, 1996
 1381: 
 1382:     """
 1383:     if interpolation is not None:
 1384:         method = fnb._check_interpolation_as_method(
 1385:             method, interpolation, "nanpercentile")
 1386: 
 1387:     a = np.asanyarray(a)
 1388:     if a.dtype.kind == "c":
 1389:         raise TypeError("a must be an array of real numbers")
 1390: 
 1391:     q = np.true_divide(q, a.dtype.type(100) if a.dtype.kind == "f" else 100, out=...)
 1392:     if not fnb._quantile_is_valid(q):
 1393:         raise ValueError("Percentiles must be in the range [0, 100]")
 1394: 
 1395:     if weights is not None:
 1396:         if method != "inverted_cdf":
 1397:             msg = ("Only method 'inverted_cdf' supports weights. "
 1398:                    f"Got: {method}.")
 1399:             raise ValueError(msg)
 1400:         if axis is not None:
 1401:             axis = _nx.normalize_axis_tuple(axis, a.ndim, argname="axis")
 1402:         weights = _weights_are_valid(weights=weights, a=a, axis=axis)
 1403:         if np.any(weights < 0):
 1404:             raise ValueError("Weights must be non-negative.")
 1405: 
 1406:     return _nanquantile_unchecked(
 1407:         a, q, axis, out, overwrite_input, method, keepdims, weights)
 1408: 
 1409: 
 1410: def _nanquantile_dispatcher(a, q, axis=None, out=None, overwrite_input=None,
 1411:                             method=None, keepdims=None, *, weights=None,
 1412:                             interpolation=None):
 1413:     return (a, q, out, weights)
 1414: 
 1415: 
 1416: @array_function_dispatch(_nanquantile_dispatcher)
 1417: def nanquantile(
 1418:         a,
 1419:         q,
 1420:         axis=None,
 1421:         out=None,
 1422:         overwrite_input=False,
 1423:         method="linear",
 1424:         keepdims=np._NoValue,
 1425:         *,
 1426:         weights=None,
 1427:         interpolation=None,
 1428: ):
 1429:     """
 1430:     Compute the qth quantile of the data along the specified axis,
 1431:     while ignoring nan values.
 1432:     Returns the qth quantile(s) of the array elements.
 1433: 
 1434:     Parameters
 1435:     ----------
 1436:     a : array_like
 1437:         Input array or object that can be converted to an array, containing
 1438:         nan values to be ignored
 1439:     q : array_like of float
 1440:         Probability or sequence of probabilities for the quantiles to compute.
 1441:         Values must be between 0 and 1 inclusive.
 1442:     axis : {int, tuple of int, None}, optional
 1443:         Axis or axes along which the quantiles are computed. The
 1444:         default is to compute the quantile(s) along a flattened
 1445:         version of the array.
 1446:     out : ndarray, optional
 1447:         Alternative output array in which to place the result. It must
 1448:         have the same shape and buffer length as the expected output,
 1449:         but the type (of the output) will be cast if necessary.
 1450:     overwrite_input : bool, optional
 1451:         If True, then allow the input array `a` to be modified by intermediate
 1452:         calculations, to save memory. In this case, the contents of the input
 1453:         `a` after this function completes is undefined.
 1454:     method : str, optional
 1455:         This parameter specifies the method to use for estimating the
 1456:         quantile.  There are many different methods, some unique to NumPy.
 1457:         See the notes for explanation.  The options sorted by their R type
 1458:         as summarized in the H&F paper [1]_ are:
 1459: 
 1460:         1. 'inverted_cdf'
 1461:         2. 'averaged_inverted_cdf'
 1462:         3. 'closest_observation'
 1463:         4. 'interpolated_inverted_cdf'
 1464:         5. 'hazen'
 1465:         6. 'weibull'
 1466:         7. 'linear'  (default)
 1467:         8. 'median_unbiased'
 1468:         9. 'normal_unbiased'
 1469: 
 1470:         The first three methods are discontinuous.  NumPy further defines the
 1471:         following discontinuous variations of the default 'linear' (7.) option:
 1472: 
 1473:         * 'lower'
 1474:         * 'higher',
 1475:         * 'midpoint'
 1476:         * 'nearest'
 1477: 
 1478:         .. versionchanged:: 1.22.0
 1479:             This argument was previously called "interpolation" and only
 1480:             offered the "linear" default and last four options.
 1481: 
 1482:     keepdims : bool, optional
 1483:         If this is set to True, the axes which are reduced are left in
 1484:         the result as dimensions with size one. With this option, the
 1485:         result will broadcast correctly against the original array `a`.
 1486: 
 1487:         If this is anything but the default value it will be passed
 1488:         through (in the special case of an empty array) to the
 1489:         `mean` function of the underlying array.  If the array is
 1490:         a sub-class and `mean` does not have the kwarg `keepdims` this
 1491:         will raise a RuntimeError.
 1492: 
 1493:     weights : array_like, optional
 1494:         An array of weights associated with the values in `a`. Each value in
 1495:         `a` contributes to the quantile according to its associated weight.
 1496:         The weights array can either be 1-D (in which case its length must be
 1497:         the size of `a` along the given axis) or of the same shape as `a`.
 1498:         If `weights=None`, then all data in `a` are assumed to have a
 1499:         weight equal to one.
 1500:         Only `method="inverted_cdf"` supports weights.
 1501: 
 1502:         .. versionadded:: 2.0.0
 1503: 
 1504:     interpolation : str, optional
 1505:         Deprecated name for the method keyword argument.
 1506: 
 1507:         .. deprecated:: 1.22.0
 1508: 
 1509:     Returns
 1510:     -------
 1511:     quantile : scalar or ndarray
 1512:         If `q` is a single probability and `axis=None`, then the result
 1513:         is a scalar. If multiple probability levels are given, first axis of
 1514:         the result corresponds to the quantiles. The other axes are
 1515:         the axes that remain after the reduction of `a`. If the input
 1516:         contains integers or floats smaller than ``float64``, the output
 1517:         data-type is ``float64``. Otherwise, the output data-type is the
 1518:         same as that of the input. If `out` is specified, that array is
 1519:         returned instead.
 1520: 
 1521:     See Also
 1522:     --------
 1523:     quantile
 1524:     nanmean, nanmedian
 1525:     nanmedian : equivalent to ``nanquantile(..., 0.5)``
 1526:     nanpercentile : same as nanquantile, but with q in the range [0, 100].
 1527: 
 1528:     Notes
 1529:     -----
 1530:     The behavior of `numpy.nanquantile` is the same as that of
 1531:     `numpy.quantile` (ignoring nan values).
 1532:     For more information, please see `numpy.quantile`.
 1533: 
 1534:     Examples
 1535:     --------
 1536:     >>> import numpy as np
 1537:     >>> a = np.array([[10., 7., 4.], [3., 2., 1.]])
 1538:     >>> a[0][1] = np.nan
 1539:     >>> a
 1540:     array([[10.,  nan,   4.],
 1541:           [ 3.,   2.,   1.]])
 1542:     >>> np.quantile(a, 0.5)
 1543:     np.float64(nan)
 1544:     >>> np.nanquantile(a, 0.5)
 1545:     3.0
 1546:     >>> np.nanquantile(a, 0.5, axis=0)
 1547:     array([6.5, 2. , 2.5])
 1548:     >>> np.nanquantile(a, 0.5, axis=1, keepdims=True)
 1549:     array([[7.],
 1550:            [2.]])
 1551:     >>> m = np.nanquantile(a, 0.5, axis=0)
 1552:     >>> out = np.zeros_like(m)
 1553:     >>> np.nanquantile(a, 0.5, axis=0, out=out)
 1554:     array([6.5, 2. , 2.5])
 1555:     >>> m
 1556:     array([6.5,  2. ,  2.5])
 1557:     >>> b = a.copy()
 1558:     >>> np.nanquantile(b, 0.5, axis=1, overwrite_input=True)
 1559:     array([7., 2.])
 1560:     >>> assert not np.all(a==b)
 1561: 
 1562:     References
 1563:     ----------
 1564:     .. [1] R. J. Hyndman and Y. Fan,
 1565:        "Sample quantiles in statistical packages,"
 1566:        The American Statistician, 50(4), pp. 361-365, 1996
 1567: 
 1568:     """
 1569: 
 1570:     if interpolation is not None:
 1571:         method = fnb._check_interpolation_as_method(
 1572:             method, interpolation, "nanquantile")
 1573: 
 1574:     a = np.asanyarray(a)
 1575:     if a.dtype.kind == "c":
 1576:         raise TypeError("a must be an array of real numbers")
 1577: 
 1578:     # Use dtype of array if possible (e.g., if q is a python int or float).
 1579:     if isinstance(q, (int, float)) and a.dtype.kind == "f":
 1580:         q = np.asanyarray(q, dtype=a.dtype)
 1581:     else:
 1582:         q = np.asanyarray(q)
 1583: 
 1584:     if not fnb._quantile_is_valid(q):
 1585:         raise ValueError("Quantiles must be in the range [0, 1]")
 1586: 
 1587:     if weights is not None:
 1588:         if method != "inverted_cdf":
 1589:             msg = ("Only method 'inverted_cdf' supports weights. "
 1590:                    f"Got: {method}.")
 1591:             raise ValueError(msg)
 1592:         if axis is not None:
 1593:             axis = _nx.normalize_axis_tuple(axis, a.ndim, argname="axis")
 1594:         weights = _weights_are_valid(weights=weights, a=a, axis=axis)
 1595:         if np.any(weights < 0):
 1596:             raise ValueError("Weights must be non-negative.")
 1597: 
 1598:     return _nanquantile_unchecked(
 1599:         a, q, axis, out, overwrite_input, method, keepdims, weights)
 1600: 
 1601: 
 1602: def _nanquantile_unchecked(
 1603:         a,
 1604:         q,
 1605:         axis=None,
 1606:         out=None,
 1607:         overwrite_input=False,
 1608:         method="linear",
 1609:         keepdims=np._NoValue,
 1610:         weights=None,
 1611: ):
 1612:     """Assumes that q is in [0, 1], and is an ndarray"""
 1613:     # apply_along_axis in _nanpercentile doesn't handle empty arrays well,
 1614:     # so deal them upfront
 1615:     if a.size == 0:
 1616:         return np.nanmean(a, axis, out=out, keepdims=keepdims)
 1617:     return fnb._ureduce(a,
 1618:                         func=_nanquantile_ureduce_func,
 1619:                         q=q,
 1620:                         weights=weights,
 1621:                         keepdims=keepdims,
 1622:                         axis=axis,
 1623:                         out=out,
 1624:                         overwrite_input=overwrite_input,
 1625:                         method=method)
 1626: 
 1627: 
 1628: def _nanquantile_ureduce_func(
 1629:         a: np.array,
 1630:         q: np.array,
 1631:         weights: np.array,
 1632:         axis: int | None = None,
 1633:         out=None,
 1634:         overwrite_input: bool = False,
 1635:         method="linear",
 1636: ):
 1637:     """
 1638:     Private function that doesn't support extended axis or keepdims.
 1639:     These methods are extended to this function using _ureduce
 1640:     See nanpercentile for parameter usage
 1641:     """
 1642:     if axis is None or a.ndim == 1:
 1643:         part = a.ravel()
 1644:         wgt = None if weights is None else weights.ravel()
 1645:         result = _nanquantile_1d(part, q, overwrite_input, method, weights=wgt)
 1646:     # Note that this code could try to fill in `out` right away
 1647:     elif weights is None:
 1648:         result = np.apply_along_axis(_nanquantile_1d, axis, a, q,
 1649:                                      overwrite_input, method, weights)
 1650:         # apply_along_axis fills in collapsed axis with results.
 1651:         # Move those axes to the beginning to match percentile's
 1652:         # convention.
 1653:         if q.ndim != 0:
 1654:             from_ax = [axis + i for i in range(q.ndim)]
 1655:             result = np.moveaxis(result, from_ax, list(range(q.ndim)))
 1656:     else:
 1657:         # We need to apply along axis over 2 arrays, a and weights.
 1658:         # move operation axes to end for simplicity:
 1659:         a = np.moveaxis(a, axis, -1)
 1660:         if weights is not None:
 1661:             weights = np.moveaxis(weights, axis, -1)
 1662:         if out is not None:
 1663:             result = out
 1664:         else:
 1665:             # weights are limited to `inverted_cdf` so the result dtype
 1666:             # is known to be identical to that of `a` here:
 1667:             result = np.empty_like(a, shape=q.shape + a.shape[:-1])
 1668: 
 1669:         for ii in np.ndindex(a.shape[:-1]):
 1670:             result[(...,) + ii] = _nanquantile_1d(
 1671:                     a[ii], q, weights=weights[ii],
 1672:                     overwrite_input=overwrite_input, method=method,
 1673:             )
 1674:         # This path dealt with `out` already...
 1675:         return result
 1676: 
 1677:     if out is not None:
 1678:         out[...] = result
 1679:     return result
 1680: 
 1681: 
 1682: def _nanquantile_1d(
 1683:     arr1d, q, overwrite_input=False, method="linear", weights=None,
 1684: ):
 1685:     """
 1686:     Private function for rank 1 arrays. Compute quantile ignoring NaNs.
 1687:     See nanpercentile for parameter usage
 1688:     """
 1689:     # TODO: What to do when arr1d = [1, np.nan] and weights = [0, 1]?
 1690:     arr1d, weights, overwrite_input = _remove_nan_1d(arr1d,
 1691:         second_arr1d=weights, overwrite_input=overwrite_input)
 1692:     if arr1d.size == 0:
 1693:         # convert to scalar
 1694:         return np.full(q.shape, np.nan, dtype=arr1d.dtype)[()]
 1695: 
 1696:     return fnb._quantile_unchecked(
 1697:         arr1d,
 1698:         q,
 1699:         overwrite_input=overwrite_input,
 1700:         method=method,
 1701:         weights=weights,
 1702:     )
 1703: 
 1704: 
 1705: def _nanvar_dispatcher(a, axis=None, dtype=None, out=None, ddof=None,
 1706:                        keepdims=None, *, where=None, mean=None,
 1707:                        correction=None):
 1708:     return (a, out)
 1709: 
 1710: 
 1711: @array_function_dispatch(_nanvar_dispatcher)
 1712: def nanvar(a, axis=None, dtype=None, out=None, ddof=0, keepdims=np._NoValue,
 1713:            *, where=np._NoValue, mean=np._NoValue, correction=np._NoValue):
 1714:     """
 1715:     Compute the variance along the specified axis, while ignoring NaNs.
 1716: 
 1717:     Returns the variance of the array elements, a measure of the spread of
 1718:     a distribution.  The variance is computed for the flattened array by
 1719:     default, otherwise over the specified axis.
 1720: 
 1721:     For all-NaN slices or slices with zero degrees of freedom, NaN is
 1722:     returned and a `RuntimeWarning` is raised.
 1723: 
 1724:     Parameters
 1725:     ----------
 1726:     a : array_like
 1727:         Array containing numbers whose variance is desired.  If `a` is not an
 1728:         array, a conversion is attempted.
 1729:     axis : {int, tuple of int, None}, optional
 1730:         Axis or axes along which the variance is computed.  The default is to compute
 1731:         the variance of the flattened array.
 1732:     dtype : data-type, optional
 1733:         Type to use in computing the variance.  For arrays of integer type
 1734:         the default is `float64`; for arrays of float types it is the same as
 1735:         the array type.
 1736:     out : ndarray, optional
 1737:         Alternate output array in which to place the result.  It must have
 1738:         the same shape as the expected output, but the type is cast if
 1739:         necessary.
 1740:     ddof : {int, float}, optional
 1741:         "Delta Degrees of Freedom": the divisor used in the calculation is
 1742:         ``N - ddof``, where ``N`` represents the number of non-NaN
 1743:         elements. By default `ddof` is zero.
 1744:     keepdims : bool, optional
 1745:         If this is set to True, the axes which are reduced are left
 1746:         in the result as dimensions with size one. With this option,
 1747:         the result will broadcast correctly against the original `a`.
 1748:     where : array_like of bool, optional
 1749:         Elements to include in the variance. See `~numpy.ufunc.reduce` for
 1750:         details.
 1751: 
 1752:         .. versionadded:: 1.22.0
 1753: 
 1754:     mean : array_like, optional
 1755:         Provide the mean to prevent its recalculation. The mean should have
 1756:         a shape as if it was calculated with ``keepdims=True``.
 1757:         The axis for the calculation of the mean should be the same as used in
 1758:         the call to this var function.
 1759: 
 1760:         .. versionadded:: 2.0.0
 1761: 
 1762:     correction : {int, float}, optional
 1763:         Array API compatible name for the ``ddof`` parameter. Only one of them
 1764:         can be provided at the same time.
 1765: 
 1766:         .. versionadded:: 2.0.0
 1767: 
 1768:     Returns
 1769:     -------
 1770:     variance : ndarray, see dtype parameter above
 1771:         If `out` is None, return a new array containing the variance,
 1772:         otherwise return a reference to the output array. If ddof is >= the
 1773:         number of non-NaN elements in a slice or the slice contains only
 1774:         NaNs, then the result for that slice is NaN.
 1775: 
 1776:     See Also
 1777:     --------
 1778:     std : Standard deviation
 1779:     mean : Average
 1780:     var : Variance while not ignoring NaNs
 1781:     nanstd, nanmean
 1782:     :ref:`ufuncs-output-type`
 1783: 
 1784:     Notes
 1785:     -----
 1786:     The variance is the average of the squared deviations from the mean,
 1787:     i.e.,  ``var = mean(abs(x - x.mean())**2)``.
 1788: 
 1789:     The mean is normally calculated as ``x.sum() / N``, where ``N = len(x)``.
 1790:     If, however, `ddof` is specified, the divisor ``N - ddof`` is used
 1791:     instead.  In standard statistical practice, ``ddof=1`` provides an
 1792:     unbiased estimator of the variance of a hypothetical infinite
 1793:     population.  ``ddof=0`` provides a maximum likelihood estimate of the
 1794:     variance for normally distributed variables.
 1795: 
 1796:     Note that for complex numbers, the absolute value is taken before
 1797:     squaring, so that the result is always real and nonnegative.
 1798: 
 1799:     For floating-point input, the variance is computed using the same
 1800:     precision the input has.  Depending on the input data, this can cause
 1801:     the results to be inaccurate, especially for `float32` (see example
 1802:     below).  Specifying a higher-accuracy accumulator using the ``dtype``
 1803:     keyword can alleviate this issue.
 1804: 
 1805:     For this function to work on sub-classes of ndarray, they must define
 1806:     `sum` with the kwarg `keepdims`
 1807: 
 1808:     Examples
 1809:     --------
 1810:     >>> import numpy as np
 1811:     >>> a = np.array([[1, np.nan], [3, 4]])
 1812:     >>> np.nanvar(a)
 1813:     1.5555555555555554
 1814:     >>> np.nanvar(a, axis=0)
 1815:     array([1.,  0.])
 1816:     >>> np.nanvar(a, axis=1)
 1817:     array([0.,  0.25])  # may vary
 1818: 
 1819:     """
 1820:     arr, mask = _replace_nan(a, 0)
 1821:     if mask is None:
 1822:         return np.var(arr, axis=axis, dtype=dtype, out=out, ddof=ddof,
 1823:                       keepdims=keepdims, where=where, mean=mean,
 1824:                       correction=correction)
 1825: 
 1826:     if dtype is not None:
 1827:         dtype = np.dtype(dtype)
 1828:     if dtype is not None and not issubclass(dtype.type, np.inexact):
 1829:         raise TypeError("If a is inexact, then dtype must be inexact")
 1830:     if out is not None and not issubclass(out.dtype.type, np.inexact):
 1831:         raise TypeError("If a is inexact, then out must be inexact")
 1832: 
 1833:     if correction != np._NoValue:
 1834:         if ddof != 0:
 1835:             raise ValueError(
 1836:                 "ddof and correction can't be provided simultaneously."
 1837:             )
 1838:         else:
 1839:             ddof = correction
 1840: 
 1841:     # Compute mean
 1842:     if type(arr) is np.matrix:
 1843:         _keepdims = np._NoValue
 1844:     else:
 1845:         _keepdims = True
 1846: 
 1847:     cnt = np.sum(~mask, axis=axis, dtype=np.intp, keepdims=_keepdims,
 1848:                      where=where)
 1849: 
 1850:     if mean is not np._NoValue:
 1851:         avg = mean
 1852:     else:
 1853:         # we need to special case matrix for reverse compatibility
 1854:         # in order for this to work, these sums need to be called with
 1855:         # keepdims=True, however matrix now raises an error in this case, but
 1856:         # the reason that it drops the keepdims kwarg is to force keepdims=True
 1857:         # so this used to work by serendipity.
 1858:         avg = np.sum(arr, axis=axis, dtype=dtype,
 1859:                      keepdims=_keepdims, where=where)
 1860:         avg = _divide_by_count(avg, cnt)
 1861: 
 1862:     # Compute squared deviation from mean.
 1863:     np.subtract(arr, avg, out=arr, casting='unsafe', where=where)
 1864:     arr = _copyto(arr, 0, mask)
 1865:     if issubclass(arr.dtype.type, np.complexfloating):
 1866:         sqr = np.multiply(arr, arr.conj(), out=arr, where=where).real
 1867:     else:
 1868:         sqr = np.multiply(arr, arr, out=arr, where=where)
 1869: 
 1870:     # Compute variance.
 1871:     var = np.sum(sqr, axis=axis, dtype=dtype, out=out, keepdims=keepdims,
 1872:                  where=where)
 1873: 
 1874:     # Precaution against reduced object arrays
 1875:     try:
 1876:         var_ndim = var.ndim
 1877:     except AttributeError:
 1878:         var_ndim = np.ndim(var)
 1879:     if var_ndim < cnt.ndim:
 1880:         # Subclasses of ndarray may ignore keepdims, so check here.
 1881:         cnt = cnt.squeeze(axis)
 1882:     dof = cnt - ddof
 1883:     var = _divide_by_count(var, dof)
 1884: 
 1885:     isbad = (dof <= 0)
 1886:     if np.any(isbad):
 1887:         warnings.warn("Degrees of freedom <= 0 for slice.", RuntimeWarning,
 1888:                       stacklevel=2)
 1889:         # NaN, inf, or negative numbers are all possible bad
 1890:         # values, so explicitly replace them with NaN.
 1891:         var = _copyto(var, np.nan, isbad)
 1892:     return var
 1893: 
 1894: 
 1895: def _nanstd_dispatcher(a, axis=None, dtype=None, out=None, ddof=None,
 1896:                        keepdims=None, *, where=None, mean=None,
 1897:                        correction=None):
 1898:     return (a, out)
 1899: 
 1900: 
 1901: @array_function_dispatch(_nanstd_dispatcher)
 1902: def nanstd(a, axis=None, dtype=None, out=None, ddof=0, keepdims=np._NoValue,
 1903:            *, where=np._NoValue, mean=np._NoValue, correction=np._NoValue):
 1904:     """
 1905:     Compute the standard deviation along the specified axis, while
 1906:     ignoring NaNs.
 1907: 
 1908:     Returns the standard deviation, a measure of the spread of a
 1909:     distribution, of the non-NaN array elements. The standard deviation is
 1910:     computed for the flattened array by default, otherwise over the
 1911:     specified axis.
 1912: 
 1913:     For all-NaN slices or slices with zero degrees of freedom, NaN is
 1914:     returned and a `RuntimeWarning` is raised.
 1915: 
 1916:     Parameters
 1917:     ----------
 1918:     a : array_like
 1919:         Calculate the standard deviation of the non-NaN values.
 1920:     axis : {int, tuple of int, None}, optional
 1921:         Axis or axes along which the standard deviation is computed. The default is
 1922:         to compute the standard deviation of the flattened array.
 1923:     dtype : dtype, optional
 1924:         Type to use in computing the standard deviation. For arrays of
 1925:         integer type the default is float64, for arrays of float types it
 1926:         is the same as the array type.
 1927:     out : ndarray, optional
 1928:         Alternative output array in which to place the result. It must have
 1929:         the same shape as the expected output but the type (of the
 1930:         calculated values) will be cast if necessary.
 1931:     ddof : {int, float}, optional
 1932:         Means Delta Degrees of Freedom.  The divisor used in calculations
 1933:         is ``N - ddof``, where ``N`` represents the number of non-NaN
 1934:         elements.  By default `ddof` is zero.
 1935: 
 1936:     keepdims : bool, optional
 1937:         If this is set to True, the axes which are reduced are left
 1938:         in the result as dimensions with size one. With this option,
 1939:         the result will broadcast correctly against the original `a`.
 1940: 
 1941:         If this value is anything but the default it is passed through
 1942:         as-is to the relevant functions of the sub-classes.  If these
 1943:         functions do not have a `keepdims` kwarg, a RuntimeError will
 1944:         be raised.
 1945:     where : array_like of bool, optional
 1946:         Elements to include in the standard deviation.
 1947:         See `~numpy.ufunc.reduce` for details.
 1948: 
 1949:         .. versionadded:: 1.22.0
 1950: 
 1951:     mean : array_like, optional
 1952:         Provide the mean to prevent its recalculation. The mean should have
 1953:         a shape as if it was calculated with ``keepdims=True``.
 1954:         The axis for the calculation of the mean should be the same as used in
 1955:         the call to this std function.
 1956: 
 1957:         .. versionadded:: 2.0.0
 1958: 
 1959:     correction : {int, float}, optional
 1960:         Array API compatible name for the ``ddof`` parameter. Only one of them
 1961:         can be provided at the same time.
 1962: 
 1963:         .. versionadded:: 2.0.0
 1964: 
 1965:     Returns
 1966:     -------
 1967:     standard_deviation : ndarray, see dtype parameter above.
 1968:         If `out` is None, return a new array containing the standard
 1969:         deviation, otherwise return a reference to the output array. If
 1970:         ddof is >= the number of non-NaN elements in a slice or the slice
 1971:         contains only NaNs, then the result for that slice is NaN.
 1972: 
 1973:     See Also
 1974:     --------
 1975:     var, mean, std
 1976:     nanvar, nanmean
 1977:     :ref:`ufuncs-output-type`
 1978: 
 1979:     Notes
 1980:     -----
 1981:     The standard deviation is the square root of the average of the squared
 1982:     deviations from the mean: ``std = sqrt(mean(abs(x - x.mean())**2))``.
 1983: 
 1984:     The average squared deviation is normally calculated as
 1985:     ``x.sum() / N``, where ``N = len(x)``.  If, however, `ddof` is
 1986:     specified, the divisor ``N - ddof`` is used instead. In standard
 1987:     statistical practice, ``ddof=1`` provides an unbiased estimator of the
 1988:     variance of the infinite population. ``ddof=0`` provides a maximum
 1989:     likelihood estimate of the variance for normally distributed variables.
 1990:     The standard deviation computed in this function is the square root of
 1991:     the estimated variance, so even with ``ddof=1``, it will not be an
 1992:     unbiased estimate of the standard deviation per se.
 1993: 
 1994:     Note that, for complex numbers, `std` takes the absolute value before
 1995:     squaring, so that the result is always real and nonnegative.
 1996: 
 1997:     For floating-point input, the *std* is computed using the same
 1998:     precision the input has. Depending on the input data, this can cause
 1999:     the results to be inaccurate, especially for float32 (see example
 2000:     below).  Specifying a higher-accuracy accumulator using the `dtype`
 2001:     keyword can alleviate this issue.
 2002: 
 2003:     Examples
 2004:     --------
 2005:     >>> import numpy as np
 2006:     >>> a = np.array([[1, np.nan], [3, 4]])
 2007:     >>> np.nanstd(a)
 2008:     1.247219128924647
 2009:     >>> np.nanstd(a, axis=0)
 2010:     array([1., 0.])
 2011:     >>> np.nanstd(a, axis=1)
 2012:     array([0.,  0.5]) # may vary
 2013: 
 2014:     """
 2015:     var = nanvar(a, axis=axis, dtype=dtype, out=out, ddof=ddof,
 2016:                  keepdims=keepdims, where=where, mean=mean,
 2017:                  correction=correction)
 2018:     if isinstance(var, np.ndarray):
 2019:         std = np.sqrt(var, out=var)
 2020:     elif hasattr(var, 'dtype'):
 2021:         std = var.dtype.type(np.sqrt(var))
 2022:     else:
 2023:         std = np.sqrt(var)
 2024:     return std
