    1: """
    2: Set operations for arrays based on sorting.
    3: 
    4: Notes
    5: -----
    6: 
    7: For floating point arrays, inaccurate results may appear due to usual round-off
    8: and floating point comparison issues.
    9: 
   10: Speed could be gained in some operations by an implementation of
   11: `numpy.sort`, that can provide directly the permutation vectors, thus avoiding
   12: calls to `numpy.argsort`.
   13: 
   14: Original author: Robert Cimrman
   15: 
   16: """
   17: import functools
   18: import warnings
   19: from typing import NamedTuple
   20: 
   21: import numpy as np
   22: from numpy._core import overrides
   23: from numpy._core._multiarray_umath import _array_converter, _unique_hash
   24: 
   25: array_function_dispatch = functools.partial(
   26:     overrides.array_function_dispatch, module='numpy')
   27: 
   28: 
   29: __all__ = [
   30:     "ediff1d", "in1d", "intersect1d", "isin", "setdiff1d", "setxor1d",
   31:     "union1d", "unique", "unique_all", "unique_counts", "unique_inverse",
   32:     "unique_values"
   33: ]
   34: 
   35: 
   36: def _ediff1d_dispatcher(ary, to_end=None, to_begin=None):
   37:     return (ary, to_end, to_begin)
   38: 
   39: 
   40: @array_function_dispatch(_ediff1d_dispatcher)
   41: def ediff1d(ary, to_end=None, to_begin=None):
   42:     """
   43:     The differences between consecutive elements of an array.
   44: 
   45:     Parameters
   46:     ----------
   47:     ary : array_like
   48:         If necessary, will be flattened before the differences are taken.
   49:     to_end : array_like, optional
   50:         Number(s) to append at the end of the returned differences.
   51:     to_begin : array_like, optional
   52:         Number(s) to prepend at the beginning of the returned differences.
   53: 
   54:     Returns
   55:     -------
   56:     ediff1d : ndarray
   57:         The differences. Loosely, this is ``ary.flat[1:] - ary.flat[:-1]``.
   58: 
   59:     See Also
   60:     --------
   61:     diff, gradient
   62: 
   63:     Notes
   64:     -----
   65:     When applied to masked arrays, this function drops the mask information
   66:     if the `to_begin` and/or `to_end` parameters are used.
   67: 
   68:     Examples
   69:     --------
   70:     >>> import numpy as np
   71:     >>> x = np.array([1, 2, 4, 7, 0])
   72:     >>> np.ediff1d(x)
   73:     array([ 1,  2,  3, -7])
   74: 
   75:     >>> np.ediff1d(x, to_begin=-99, to_end=np.array([88, 99]))
   76:     array([-99,   1,   2, ...,  -7,  88,  99])
   77: 
   78:     The returned array is always 1D.
   79: 
   80:     >>> y = [[1, 2, 4], [1, 6, 24]]
   81:     >>> np.ediff1d(y)
   82:     array([ 1,  2, -3,  5, 18])
   83: 
   84:     """
   85:     conv = _array_converter(ary)
   86:     # Convert to (any) array and ravel:
   87:     ary = conv[0].ravel()
   88: 
   89:     # enforce that the dtype of `ary` is used for the output
   90:     dtype_req = ary.dtype
   91: 
   92:     # fast track default case
   93:     if to_begin is None and to_end is None:
   94:         return ary[1:] - ary[:-1]
   95: 
   96:     if to_begin is None:
   97:         l_begin = 0
   98:     else:
   99:         to_begin = np.asanyarray(to_begin)
  100:         if not np.can_cast(to_begin, dtype_req, casting="same_kind"):
  101:             raise TypeError("dtype of `to_begin` must be compatible "
  102:                             "with input `ary` under the `same_kind` rule.")
  103: 
  104:         to_begin = to_begin.ravel()
  105:         l_begin = len(to_begin)
  106: 
  107:     if to_end is None:
  108:         l_end = 0
  109:     else:
  110:         to_end = np.asanyarray(to_end)
  111:         if not np.can_cast(to_end, dtype_req, casting="same_kind"):
  112:             raise TypeError("dtype of `to_end` must be compatible "
  113:                             "with input `ary` under the `same_kind` rule.")
  114: 
  115:         to_end = to_end.ravel()
  116:         l_end = len(to_end)
  117: 
  118:     # do the calculation in place and copy to_begin and to_end
  119:     l_diff = max(len(ary) - 1, 0)
  120:     result = np.empty_like(ary, shape=l_diff + l_begin + l_end)
  121: 
  122:     if l_begin > 0:
  123:         result[:l_begin] = to_begin
  124:     if l_end > 0:
  125:         result[l_begin + l_diff:] = to_end
  126:     np.subtract(ary[1:], ary[:-1], result[l_begin:l_begin + l_diff])
  127: 
  128:     return conv.wrap(result)
  129: 
  130: 
  131: def _unpack_tuple(x):
  132:     """ Unpacks one-element tuples for use as return values """
  133:     if len(x) == 1:
  134:         return x[0]
  135:     else:
  136:         return x
  137: 
  138: 
  139: def _unique_dispatcher(ar, return_index=None, return_inverse=None,
  140:                        return_counts=None, axis=None, *, equal_nan=None,
  141:                        sorted=True):
  142:     return (ar,)
  143: 
  144: 
  145: @array_function_dispatch(_unique_dispatcher)
  146: def unique(ar, return_index=False, return_inverse=False,
  147:            return_counts=False, axis=None, *, equal_nan=True,
  148:            sorted=True):
  149:     """
  150:     Find the unique elements of an array.
  151: 
  152:     Returns the sorted unique elements of an array. There are three optional
  153:     outputs in addition to the unique elements:
  154: 
  155:     * the indices of the input array that give the unique values
  156:     * the indices of the unique array that reconstruct the input array
  157:     * the number of times each unique value comes up in the input array
  158: 
  159:     Parameters
  160:     ----------
  161:     ar : array_like
  162:         Input array. Unless `axis` is specified, this will be flattened if it
  163:         is not already 1-D.
  164:     return_index : bool, optional
  165:         If True, also return the indices of `ar` (along the specified axis,
  166:         if provided, or in the flattened array) that result in the unique array.
  167:     return_inverse : bool, optional
  168:         If True, also return the indices of the unique array (for the specified
  169:         axis, if provided) that can be used to reconstruct `ar`.
  170:     return_counts : bool, optional
  171:         If True, also return the number of times each unique item appears
  172:         in `ar`.
  173:     axis : int or None, optional
  174:         The axis to operate on. If None, `ar` will be flattened. If an integer,
  175:         the subarrays indexed by the given axis will be flattened and treated
  176:         as the elements of a 1-D array with the dimension of the given axis,
  177:         see the notes for more details.  Object arrays or structured arrays
  178:         that contain objects are not supported if the `axis` kwarg is used. The
  179:         default is None.
  180: 
  181:     equal_nan : bool, optional
  182:         If True, collapses multiple NaN values in the return array into one.
  183: 
  184:         .. versionadded:: 1.24
  185: 
  186:     sorted : bool, optional
  187:         If True, the unique elements are sorted. Elements may be sorted in
  188:         practice even if ``sorted=False``, but this could change without
  189:         notice.
  190: 
  191:         .. versionadded:: 2.3
  192: 
  193:     Returns
  194:     -------
  195:     unique : ndarray
  196:         The sorted unique values.
  197:     unique_indices : ndarray, optional
  198:         The indices of the first occurrences of the unique values in the
  199:         original array. Only provided if `return_index` is True.
  200:     unique_inverse : ndarray, optional
  201:         The indices to reconstruct the original array from the
  202:         unique array. Only provided if `return_inverse` is True.
  203:     unique_counts : ndarray, optional
  204:         The number of times each of the unique values comes up in the
  205:         original array. Only provided if `return_counts` is True.
  206: 
  207:     See Also
  208:     --------
  209:     repeat : Repeat elements of an array.
  210:     sort : Return a sorted copy of an array.
  211: 
  212:     Notes
  213:     -----
  214:     When an axis is specified the subarrays indexed by the axis are sorted.
  215:     This is done by making the specified axis the first dimension of the array
  216:     (move the axis to the first dimension to keep the order of the other axes)
  217:     and then flattening the subarrays in C order. The flattened subarrays are
  218:     then viewed as a structured type with each element given a label, with the
  219:     effect that we end up with a 1-D array of structured types that can be
  220:     treated in the same way as any other 1-D array. The result is that the
  221:     flattened subarrays are sorted in lexicographic order starting with the
  222:     first element.
  223: 
  224:     .. versionchanged:: 1.21
  225:         Like np.sort, NaN will sort to the end of the values.
  226:         For complex arrays all NaN values are considered equivalent
  227:         (no matter whether the NaN is in the real or imaginary part).
  228:         As the representant for the returned array the smallest one in the
  229:         lexicographical order is chosen - see np.sort for how the lexicographical
  230:         order is defined for complex arrays.
  231: 
  232:     .. versionchanged:: 2.0
  233:         For multi-dimensional inputs, ``unique_inverse`` is reshaped
  234:         such that the input can be reconstructed using
  235:         ``np.take(unique, unique_inverse, axis=axis)``. The result is
  236:         now not 1-dimensional when ``axis=None``.
  237: 
  238:         Note that in NumPy 2.0.0 a higher dimensional array was returned also
  239:         when ``axis`` was not ``None``.  This was reverted, but
  240:         ``inverse.reshape(-1)`` can be used to ensure compatibility with both
  241:         versions.
  242: 
  243:     Examples
  244:     --------
  245:     >>> import numpy as np
  246:     >>> np.unique([1, 1, 2, 2, 3, 3])
  247:     array([1, 2, 3])
  248:     >>> a = np.array([[1, 1], [2, 3]])
  249:     >>> np.unique(a)
  250:     array([1, 2, 3])
  251: 
  252:     Return the unique rows of a 2D array
  253: 
  254:     >>> a = np.array([[1, 0, 0], [1, 0, 0], [2, 3, 4]])
  255:     >>> np.unique(a, axis=0)
  256:     array([[1, 0, 0], [2, 3, 4]])
  257: 
  258:     Return the indices of the original array that give the unique values:
  259: 
  260:     >>> a = np.array(['a', 'b', 'b', 'c', 'a'])
  261:     >>> u, indices = np.unique(a, return_index=True)
  262:     >>> u
  263:     array(['a', 'b', 'c'], dtype='<U1')
  264:     >>> indices
  265:     array([0, 1, 3])
  266:     >>> a[indices]
  267:     array(['a', 'b', 'c'], dtype='<U1')
  268: 
  269:     Reconstruct the input array from the unique values and inverse:
  270: 
  271:     >>> a = np.array([1, 2, 6, 4, 2, 3, 2])
  272:     >>> u, indices = np.unique(a, return_inverse=True)
  273:     >>> u
  274:     array([1, 2, 3, 4, 6])
  275:     >>> indices
  276:     array([0, 1, 4, 3, 1, 2, 1])
  277:     >>> u[indices]
  278:     array([1, 2, 6, 4, 2, 3, 2])
  279: 
  280:     Reconstruct the input values from the unique values and counts:
  281: 
  282:     >>> a = np.array([1, 2, 6, 4, 2, 3, 2])
  283:     >>> values, counts = np.unique(a, return_counts=True)
  284:     >>> values
  285:     array([1, 2, 3, 4, 6])
  286:     >>> counts
  287:     array([1, 3, 1, 1, 1])
  288:     >>> np.repeat(values, counts)
  289:     array([1, 2, 2, 2, 3, 4, 6])    # original order not preserved
  290: 
  291:     """
  292:     ar = np.asanyarray(ar)
  293:     if axis is None:
  294:         ret = _unique1d(ar, return_index, return_inverse, return_counts,
  295:                         equal_nan=equal_nan, inverse_shape=ar.shape, axis=None,
  296:                         sorted=sorted)
  297:         return _unpack_tuple(ret)
  298: 
  299:     # axis was specified and not None
  300:     try:
  301:         ar = np.moveaxis(ar, axis, 0)
  302:     except np.exceptions.AxisError:
  303:         # this removes the "axis1" or "axis2" prefix from the error message
  304:         raise np.exceptions.AxisError(axis, ar.ndim) from None
  305:     inverse_shape = [1] * ar.ndim
  306:     inverse_shape[axis] = ar.shape[0]
  307: 
  308:     # Must reshape to a contiguous 2D array for this to work...
  309:     orig_shape, orig_dtype = ar.shape, ar.dtype
  310:     ar = ar.reshape(orig_shape[0], np.prod(orig_shape[1:], dtype=np.intp))
  311:     ar = np.ascontiguousarray(ar)
  312:     dtype = [(f'f{i}', ar.dtype) for i in range(ar.shape[1])]
  313: 
  314:     # At this point, `ar` has shape `(n, m)`, and `dtype` is a structured
  315:     # data type with `m` fields where each field has the data type of `ar`.
  316:     # In the following, we create the array `consolidated`, which has
  317:     # shape `(n,)` with data type `dtype`.
  318:     try:
  319:         if ar.shape[1] > 0:
  320:             consolidated = ar.view(dtype)
  321:         else:
  322:             # If ar.shape[1] == 0, then dtype will be `np.dtype([])`, which is
  323:             # a data type with itemsize 0, and the call `ar.view(dtype)` will
  324:             # fail.  Instead, we'll use `np.empty` to explicitly create the
  325:             # array with shape `(len(ar),)`.  Because `dtype` in this case has
  326:             # itemsize 0, the total size of the result is still 0 bytes.
  327:             consolidated = np.empty(len(ar), dtype=dtype)
  328:     except TypeError as e:
  329:         # There's no good way to do this for object arrays, etc...
  330:         msg = 'The axis argument to unique is not supported for dtype {dt}'
  331:         raise TypeError(msg.format(dt=ar.dtype)) from e
  332: 
  333:     def reshape_uniq(uniq):
  334:         n = len(uniq)
  335:         uniq = uniq.view(orig_dtype)
  336:         uniq = uniq.reshape(n, *orig_shape[1:])
  337:         uniq = np.moveaxis(uniq, 0, axis)
  338:         return uniq
  339: 
  340:     output = _unique1d(consolidated, return_index,
  341:                        return_inverse, return_counts,
  342:                        equal_nan=equal_nan, inverse_shape=inverse_shape,
  343:                        axis=axis, sorted=sorted)
  344:     output = (reshape_uniq(output[0]),) + output[1:]
  345:     return _unpack_tuple(output)
  346: 
  347: 
  348: def _unique1d(ar, return_index=False, return_inverse=False,
  349:               return_counts=False, *, equal_nan=True, inverse_shape=None,
  350:               axis=None, sorted=True):
  351:     """
  352:     Find the unique elements of an array, ignoring shape.
  353: 
  354:     Uses a hash table to find the unique elements if possible.
  355:     """
  356:     ar = np.asanyarray(ar).flatten()
  357:     if len(ar.shape) != 1:
  358:         # np.matrix, and maybe some other array subclasses, insist on keeping
  359:         # two dimensions for all operations. Coerce to an ndarray in such cases.
  360:         ar = np.asarray(ar).flatten()
  361: 
  362:     optional_indices = return_index or return_inverse
  363: 
  364:     # masked arrays are not supported yet.
  365:     if not optional_indices and not return_counts and not np.ma.is_masked(ar):
  366:         # First we convert the array to a numpy array, later we wrap it back
  367:         # in case it was a subclass of numpy.ndarray.
  368:         conv = _array_converter(ar)
  369:         ar_, = conv
  370: 
  371:         if (hash_unique := _unique_hash(ar_)) is not NotImplemented:
  372:             if sorted:
  373:                 hash_unique.sort()
  374:             # We wrap the result back in case it was a subclass of numpy.ndarray.
  375:             return (conv.wrap(hash_unique),)
  376: 
  377:     # If we don't use the hash map, we use the slower sorting method.
  378:     if optional_indices:
  379:         perm = ar.argsort(kind='mergesort' if return_index else 'quicksort')
  380:         aux = ar[perm]
  381:     else:
  382:         ar.sort()
  383:         aux = ar
  384:     mask = np.empty(aux.shape, dtype=np.bool)
  385:     mask[:1] = True
  386:     if (equal_nan and aux.shape[0] > 0 and aux.dtype.kind in "cfmM" and
  387:             np.isnan(aux[-1])):
  388:         if aux.dtype.kind == "c":  # for complex all NaNs are considered equivalent
  389:             aux_firstnan = np.searchsorted(np.isnan(aux), True, side='left')
  390:         else:
  391:             aux_firstnan = np.searchsorted(aux, aux[-1], side='left')
  392:         if aux_firstnan > 0:
  393:             mask[1:aux_firstnan] = (
  394:                 aux[1:aux_firstnan] != aux[:aux_firstnan - 1])
  395:         mask[aux_firstnan] = True
  396:         mask[aux_firstnan + 1:] = False
  397:     else:
  398:         mask[1:] = aux[1:] != aux[:-1]
  399: 
  400:     ret = (aux[mask],)
  401:     if return_index:
  402:         ret += (perm[mask],)
  403:     if return_inverse:
  404:         imask = np.cumsum(mask) - 1
  405:         inv_idx = np.empty(mask.shape, dtype=np.intp)
  406:         inv_idx[perm] = imask
  407:         ret += (inv_idx.reshape(inverse_shape) if axis is None else inv_idx,)
  408:     if return_counts:
  409:         idx = np.concatenate(np.nonzero(mask) + ([mask.size],))
  410:         ret += (np.diff(idx),)
  411:     return ret
  412: 
  413: 
  414: # Array API set functions
  415: 
  416: class UniqueAllResult(NamedTuple):
  417:     values: np.ndarray
  418:     indices: np.ndarray
  419:     inverse_indices: np.ndarray
  420:     counts: np.ndarray
  421: 
  422: 
  423: class UniqueCountsResult(NamedTuple):
  424:     values: np.ndarray
  425:     counts: np.ndarray
  426: 
  427: 
  428: class UniqueInverseResult(NamedTuple):
  429:     values: np.ndarray
  430:     inverse_indices: np.ndarray
  431: 
  432: 
  433: def _unique_all_dispatcher(x, /):
  434:     return (x,)
  435: 
  436: 
  437: @array_function_dispatch(_unique_all_dispatcher)
  438: def unique_all(x):
  439:     """
  440:     Find the unique elements of an array, and counts, inverse, and indices.
  441: 
  442:     This function is an Array API compatible alternative to::
  443: 
  444:         np.unique(x, return_index=True, return_inverse=True,
  445:                   return_counts=True, equal_nan=False, sorted=False)
  446: 
  447:     but returns a namedtuple for easier access to each output.
  448: 
  449:     .. note::
  450:         This function currently always returns a sorted result, however,
  451:         this could change in any NumPy minor release.
  452: 
  453:     Parameters
  454:     ----------
  455:     x : array_like
  456:         Input array. It will be flattened if it is not already 1-D.
  457: 
  458:     Returns
  459:     -------
  460:     out : namedtuple
  461:         The result containing:
  462: 
  463:         * values - The unique elements of an input array.
  464:         * indices - The first occurring indices for each unique element.
  465:         * inverse_indices - The indices from the set of unique elements
  466:           that reconstruct `x`.
  467:         * counts - The corresponding counts for each unique element.
  468: 
  469:     See Also
  470:     --------
  471:     unique : Find the unique elements of an array.
  472: 
  473:     Examples
  474:     --------
  475:     >>> import numpy as np
  476:     >>> x = [1, 1, 2]
  477:     >>> uniq = np.unique_all(x)
  478:     >>> uniq.values
  479:     array([1, 2])
  480:     >>> uniq.indices
  481:     array([0, 2])
  482:     >>> uniq.inverse_indices
  483:     array([0, 0, 1])
  484:     >>> uniq.counts
  485:     array([2, 1])
  486:     """
  487:     result = unique(
  488:         x,
  489:         return_index=True,
  490:         return_inverse=True,
  491:         return_counts=True,
  492:         equal_nan=False,
  493:     )
  494:     return UniqueAllResult(*result)
  495: 
  496: 
  497: def _unique_counts_dispatcher(x, /):
  498:     return (x,)
  499: 
  500: 
  501: @array_function_dispatch(_unique_counts_dispatcher)
  502: def unique_counts(x):
  503:     """
  504:     Find the unique elements and counts of an input array `x`.
  505: 
  506:     This function is an Array API compatible alternative to::
  507: 
  508:         np.unique(x, return_counts=True, equal_nan=False, sorted=False)
  509: 
  510:     but returns a namedtuple for easier access to each output.
  511: 
  512:     .. note::
  513:         This function currently always returns a sorted result, however,
  514:         this could change in any NumPy minor release.
  515: 
  516:     Parameters
  517:     ----------
  518:     x : array_like
  519:         Input array. It will be flattened if it is not already 1-D.
  520: 
  521:     Returns
  522:     -------
  523:     out : namedtuple
  524:         The result containing:
  525: 
  526:         * values - The unique elements of an input array.
  527:         * counts - The corresponding counts for each unique element.
  528: 
  529:     See Also
  530:     --------
  531:     unique : Find the unique elements of an array.
  532: 
  533:     Examples
  534:     --------
  535:     >>> import numpy as np
  536:     >>> x = [1, 1, 2]
  537:     >>> uniq = np.unique_counts(x)
  538:     >>> uniq.values
  539:     array([1, 2])
  540:     >>> uniq.counts
  541:     array([2, 1])
  542:     """
  543:     result = unique(
  544:         x,
  545:         return_index=False,
  546:         return_inverse=False,
  547:         return_counts=True,
  548:         equal_nan=False,
  549:     )
  550:     return UniqueCountsResult(*result)
  551: 
  552: 
  553: def _unique_inverse_dispatcher(x, /):
  554:     return (x,)
  555: 
  556: 
  557: @array_function_dispatch(_unique_inverse_dispatcher)
  558: def unique_inverse(x):
  559:     """
  560:     Find the unique elements of `x` and indices to reconstruct `x`.
  561: 
  562:     This function is an Array API compatible alternative to::
  563: 
  564:         np.unique(x, return_inverse=True, equal_nan=False, sorted=False)
  565: 
  566:     but returns a namedtuple for easier access to each output.
  567: 
  568:     .. note::
  569:         This function currently always returns a sorted result, however,
  570:         this could change in any NumPy minor release.
  571: 
  572:     Parameters
  573:     ----------
  574:     x : array_like
  575:         Input array. It will be flattened if it is not already 1-D.
  576: 
  577:     Returns
  578:     -------
  579:     out : namedtuple
  580:         The result containing:
  581: 
  582:         * values - The unique elements of an input array.
  583:         * inverse_indices - The indices from the set of unique elements
  584:           that reconstruct `x`.
  585: 
  586:     See Also
  587:     --------
  588:     unique : Find the unique elements of an array.
  589: 
  590:     Examples
  591:     --------
  592:     >>> import numpy as np
  593:     >>> x = [1, 1, 2]
  594:     >>> uniq = np.unique_inverse(x)
  595:     >>> uniq.values
  596:     array([1, 2])
  597:     >>> uniq.inverse_indices
  598:     array([0, 0, 1])
  599:     """
  600:     result = unique(
  601:         x,
  602:         return_index=False,
  603:         return_inverse=True,
  604:         return_counts=False,
  605:         equal_nan=False,
  606:     )
  607:     return UniqueInverseResult(*result)
  608: 
  609: 
  610: def _unique_values_dispatcher(x, /):
  611:     return (x,)
  612: 
  613: 
  614: @array_function_dispatch(_unique_values_dispatcher)
  615: def unique_values(x):
  616:     """
  617:     Returns the unique elements of an input array `x`.
  618: 
  619:     This function is an Array API compatible alternative to::
  620: 
  621:         np.unique(x, equal_nan=False, sorted=False)
  622: 
  623:     .. versionchanged:: 2.3
  624:        The algorithm was changed to a faster one that does not rely on
  625:        sorting, and hence the results are no longer implicitly sorted.
  626: 
  627:     Parameters
  628:     ----------
  629:     x : array_like
  630:         Input array. It will be flattened if it is not already 1-D.
  631: 
  632:     Returns
  633:     -------
  634:     out : ndarray
  635:         The unique elements of an input array.
  636: 
  637:     See Also
  638:     --------
  639:     unique : Find the unique elements of an array.
  640: 
  641:     Examples
  642:     --------
  643:     >>> import numpy as np
  644:     >>> np.unique_values([1, 1, 2])
  645:     array([1, 2])  # may vary
  646: 
  647:     """
  648:     return unique(
  649:         x,
  650:         return_index=False,
  651:         return_inverse=False,
  652:         return_counts=False,
  653:         equal_nan=False,
  654:         sorted=False,
  655:     )
  656: 
  657: 
  658: def _intersect1d_dispatcher(
  659:         ar1, ar2, assume_unique=None, return_indices=None):
  660:     return (ar1, ar2)
  661: 
  662: 
  663: @array_function_dispatch(_intersect1d_dispatcher)
  664: def intersect1d(ar1, ar2, assume_unique=False, return_indices=False):
  665:     """
  666:     Find the intersection of two arrays.
  667: 
  668:     Return the sorted, unique values that are in both of the input arrays.
  669: 
  670:     Parameters
  671:     ----------
  672:     ar1, ar2 : array_like
  673:         Input arrays. Will be flattened if not already 1D.
  674:     assume_unique : bool
  675:         If True, the input arrays are both assumed to be unique, which
  676:         can speed up the calculation.  If True but ``ar1`` or ``ar2`` are not
  677:         unique, incorrect results and out-of-bounds indices could result.
  678:         Default is False.
  679:     return_indices : bool
  680:         If True, the indices which correspond to the intersection of the two
  681:         arrays are returned. The first instance of a value is used if there are
  682:         multiple. Default is False.
  683: 
  684:     Returns
  685:     -------
  686:     intersect1d : ndarray
  687:         Sorted 1D array of common and unique elements.
  688:     comm1 : ndarray
  689:         The indices of the first occurrences of the common values in `ar1`.
  690:         Only provided if `return_indices` is True.
  691:     comm2 : ndarray
  692:         The indices of the first occurrences of the common values in `ar2`.
  693:         Only provided if `return_indices` is True.
  694: 
  695:     Examples
  696:     --------
  697:     >>> import numpy as np
  698:     >>> np.intersect1d([1, 3, 4, 3], [3, 1, 2, 1])
  699:     array([1, 3])
  700: 
  701:     To intersect more than two arrays, use functools.reduce:
  702: 
  703:     >>> from functools import reduce
  704:     >>> reduce(np.intersect1d, ([1, 3, 4, 3], [3, 1, 2, 1], [6, 3, 4, 2]))
  705:     array([3])
  706: 
  707:     To return the indices of the values common to the input arrays
  708:     along with the intersected values:
  709: 
  710:     >>> x = np.array([1, 1, 2, 3, 4])
  711:     >>> y = np.array([2, 1, 4, 6])
  712:     >>> xy, x_ind, y_ind = np.intersect1d(x, y, return_indices=True)
  713:     >>> x_ind, y_ind
  714:     (array([0, 2, 4]), array([1, 0, 2]))
  715:     >>> xy, x[x_ind], y[y_ind]
  716:     (array([1, 2, 4]), array([1, 2, 4]), array([1, 2, 4]))
  717: 
  718:     """
  719:     ar1 = np.asanyarray(ar1)
  720:     ar2 = np.asanyarray(ar2)
  721: 
  722:     if not assume_unique:
  723:         if return_indices:
  724:             ar1, ind1 = unique(ar1, return_index=True)
  725:             ar2, ind2 = unique(ar2, return_index=True)
  726:         else:
  727:             ar1 = unique(ar1)
  728:             ar2 = unique(ar2)
  729:     else:
  730:         ar1 = ar1.ravel()
  731:         ar2 = ar2.ravel()
  732: 
  733:     aux = np.concatenate((ar1, ar2))
  734:     if return_indices:
  735:         aux_sort_indices = np.argsort(aux, kind='mergesort')
  736:         aux = aux[aux_sort_indices]
  737:     else:
  738:         aux.sort()
  739: 
  740:     mask = aux[1:] == aux[:-1]
  741:     int1d = aux[:-1][mask]
  742: 
  743:     if return_indices:
  744:         ar1_indices = aux_sort_indices[:-1][mask]
  745:         ar2_indices = aux_sort_indices[1:][mask] - ar1.size
  746:         if not assume_unique:
  747:             ar1_indices = ind1[ar1_indices]
  748:             ar2_indices = ind2[ar2_indices]
  749: 
  750:         return int1d, ar1_indices, ar2_indices
  751:     else:
  752:         return int1d
  753: 
  754: 
  755: def _setxor1d_dispatcher(ar1, ar2, assume_unique=None):
  756:     return (ar1, ar2)
  757: 
  758: 
  759: @array_function_dispatch(_setxor1d_dispatcher)
  760: def setxor1d(ar1, ar2, assume_unique=False):
  761:     """
  762:     Find the set exclusive-or of two arrays.
  763: 
  764:     Return the sorted, unique values that are in only one (not both) of the
  765:     input arrays.
  766: 
  767:     Parameters
  768:     ----------
  769:     ar1, ar2 : array_like
  770:         Input arrays.
  771:     assume_unique : bool
  772:         If True, the input arrays are both assumed to be unique, which
  773:         can speed up the calculation. Default is False.
  774: 
  775:     Returns
  776:     -------
  777:     setxor1d : ndarray
  778:         Sorted 1D array of unique values that are in only one of the input
  779:         arrays.
  780: 
  781:     Examples
  782:     --------
  783:     >>> import numpy as np
  784:     >>> a = np.array([1, 2, 3, 2, 4])
  785:     >>> b = np.array([2, 3, 5, 7, 5])
  786:     >>> np.setxor1d(a,b)
  787:     array([1, 4, 5, 7])
  788: 
  789:     """
  790:     if not assume_unique:
  791:         ar1 = unique(ar1)
  792:         ar2 = unique(ar2)
  793: 
  794:     aux = np.concatenate((ar1, ar2), axis=None)
  795:     if aux.size == 0:
  796:         return aux
  797: 
  798:     aux.sort()
  799:     flag = np.concatenate(([True], aux[1:] != aux[:-1], [True]))
  800:     return aux[flag[1:] & flag[:-1]]
  801: 
  802: 
  803: def _in1d_dispatcher(ar1, ar2, assume_unique=None, invert=None, *,
  804:                      kind=None):
  805:     return (ar1, ar2)
  806: 
  807: 
  808: @array_function_dispatch(_in1d_dispatcher)
  809: def in1d(ar1, ar2, assume_unique=False, invert=False, *, kind=None):
  810:     """
  811:     Test whether each element of a 1-D array is also present in a second array.
  812: 
  813:     .. deprecated:: 2.0
  814:         Use :func:`isin` instead of `in1d` for new code.
  815: 
  816:     Returns a boolean array the same length as `ar1` that is True
  817:     where an element of `ar1` is in `ar2` and False otherwise.
  818: 
  819:     Parameters
  820:     ----------
  821:     ar1 : (M,) array_like
  822:         Input array.
  823:     ar2 : array_like
  824:         The values against which to test each value of `ar1`.
  825:     assume_unique : bool, optional
  826:         If True, the input arrays are both assumed to be unique, which
  827:         can speed up the calculation.  Default is False.
  828:     invert : bool, optional
  829:         If True, the values in the returned array are inverted (that is,
  830:         False where an element of `ar1` is in `ar2` and True otherwise).
  831:         Default is False. ``np.in1d(a, b, invert=True)`` is equivalent
  832:         to (but is faster than) ``np.invert(in1d(a, b))``.
  833:     kind : {None, 'sort', 'table'}, optional
  834:         The algorithm to use. This will not affect the final result,
  835:         but will affect the speed and memory use. The default, None,
  836:         will select automatically based on memory considerations.
  837: 
  838:         * If 'sort', will use a mergesort-based approach. This will have
  839:           a memory usage of roughly 6 times the sum of the sizes of
  840:           `ar1` and `ar2`, not accounting for size of dtypes.
  841:         * If 'table', will use a lookup table approach similar
  842:           to a counting sort. This is only available for boolean and
  843:           integer arrays. This will have a memory usage of the
  844:           size of `ar1` plus the max-min value of `ar2`. `assume_unique`
  845:           has no effect when the 'table' option is used.
  846:         * If None, will automatically choose 'table' if
  847:           the required memory allocation is less than or equal to
  848:           6 times the sum of the sizes of `ar1` and `ar2`,
  849:           otherwise will use 'sort'. This is done to not use
  850:           a large amount of memory by default, even though
  851:           'table' may be faster in most cases. If 'table' is chosen,
  852:           `assume_unique` will have no effect.
  853: 
  854:     Returns
  855:     -------
  856:     in1d : (M,) ndarray, bool
  857:         The values `ar1[in1d]` are in `ar2`.
  858: 
  859:     See Also
  860:     --------
  861:     isin                  : Version of this function that preserves the
  862:                             shape of ar1.
  863: 
  864:     Notes
  865:     -----
  866:     `in1d` can be considered as an element-wise function version of the
  867:     python keyword `in`, for 1-D sequences. ``in1d(a, b)`` is roughly
  868:     equivalent to ``np.array([item in b for item in a])``.
  869:     However, this idea fails if `ar2` is a set, or similar (non-sequence)
  870:     container:  As ``ar2`` is converted to an array, in those cases
  871:     ``asarray(ar2)`` is an object array rather than the expected array of
  872:     contained values.
  873: 
  874:     Using ``kind='table'`` tends to be faster than `kind='sort'` if the
  875:     following relationship is true:
  876:     ``log10(len(ar2)) > (log10(max(ar2)-min(ar2)) - 2.27) / 0.927``,
  877:     but may use greater memory. The default value for `kind` will
  878:     be automatically selected based only on memory usage, so one may
  879:     manually set ``kind='table'`` if memory constraints can be relaxed.
  880: 
  881:     Examples
  882:     --------
  883:     >>> import numpy as np
  884:     >>> test = np.array([0, 1, 2, 5, 0])
  885:     >>> states = [0, 2]
  886:     >>> mask = np.in1d(test, states)
  887:     >>> mask
  888:     array([ True, False,  True, False,  True])
  889:     >>> test[mask]
  890:     array([0, 2, 0])
  891:     >>> mask = np.in1d(test, states, invert=True)
  892:     >>> mask
  893:     array([False,  True, False,  True, False])
  894:     >>> test[mask]
  895:     array([1, 5])
  896:     """
  897: 
  898:     # Deprecated in NumPy 2.0, 2023-08-18
  899:     warnings.warn(
  900:         "`in1d` is deprecated. Use `np.isin` instead.",
  901:         DeprecationWarning,
  902:         stacklevel=2
  903:     )
  904: 
  905:     return _in1d(ar1, ar2, assume_unique, invert, kind=kind)
  906: 
  907: 
  908: def _in1d(ar1, ar2, assume_unique=False, invert=False, *, kind=None):
  909:     # Ravel both arrays, behavior for the first array could be different
  910:     ar1 = np.asarray(ar1).ravel()
  911:     ar2 = np.asarray(ar2).ravel()
  912: 
  913:     # Ensure that iteration through object arrays yields size-1 arrays
  914:     if ar2.dtype == object:
  915:         ar2 = ar2.reshape(-1, 1)
  916: 
  917:     if kind not in {None, 'sort', 'table'}:
  918:         raise ValueError(
  919:             f"Invalid kind: '{kind}'. Please use None, 'sort' or 'table'.")
  920: 
  921:     # Can use the table method if all arrays are integers or boolean:
  922:     is_int_arrays = all(ar.dtype.kind in ("u", "i", "b") for ar in (ar1, ar2))
  923:     use_table_method = is_int_arrays and kind in {None, 'table'}
  924: 
  925:     if use_table_method:
  926:         if ar2.size == 0:
  927:             if invert:
  928:                 return np.ones_like(ar1, dtype=bool)
  929:             else:
  930:                 return np.zeros_like(ar1, dtype=bool)
  931: 
  932:         # Convert booleans to uint8 so we can use the fast integer algorithm
  933:         if ar1.dtype == bool:
  934:             ar1 = ar1.astype(np.uint8)
  935:         if ar2.dtype == bool:
  936:             ar2 = ar2.astype(np.uint8)
  937: 
  938:         ar2_min = int(np.min(ar2))
  939:         ar2_max = int(np.max(ar2))
  940: 
  941:         ar2_range = ar2_max - ar2_min
  942: 
  943:         # Constraints on whether we can actually use the table method:
  944:         #  1. Assert memory usage is not too large
  945:         below_memory_constraint = ar2_range <= 6 * (ar1.size + ar2.size)
  946:         #  2. Check overflows for (ar2 - ar2_min); dtype=ar2.dtype
  947:         range_safe_from_overflow = ar2_range <= np.iinfo(ar2.dtype).max
  948: 
  949:         # Optimal performance is for approximately
  950:         # log10(size) > (log10(range) - 2.27) / 0.927.
  951:         # However, here we set the requirement that by default
  952:         # the intermediate array can only be 6x
  953:         # the combined memory allocation of the original
  954:         # arrays. See discussion on
  955:         # https://github.com/numpy/numpy/pull/12065.
  956: 
  957:         if (
  958:             range_safe_from_overflow and
  959:             (below_memory_constraint or kind == 'table')
  960:         ):
  961: 
  962:             if invert:
  963:                 outgoing_array = np.ones_like(ar1, dtype=bool)
  964:             else:
  965:                 outgoing_array = np.zeros_like(ar1, dtype=bool)
  966: 
  967:             # Make elements 1 where the integer exists in ar2
  968:             if invert:
  969:                 isin_helper_ar = np.ones(ar2_range + 1, dtype=bool)
  970:                 isin_helper_ar[ar2 - ar2_min] = 0
  971:             else:
  972:                 isin_helper_ar = np.zeros(ar2_range + 1, dtype=bool)
  973:                 isin_helper_ar[ar2 - ar2_min] = 1
  974: 
  975:             # Mask out elements we know won't work
  976:             basic_mask = (ar1 <= ar2_max) & (ar1 >= ar2_min)
  977:             in_range_ar1 = ar1[basic_mask]
  978:             if in_range_ar1.size == 0:
  979:                 # Nothing more to do, since all values are out of range.
  980:                 return outgoing_array
  981: 
  982:             # Unfortunately, ar2_min can be out of range for `intp` even
  983:             # if the calculation result must fit in range (and be positive).
  984:             # In that case, use ar2.dtype which must work for all unmasked
  985:             # values.
  986:             try:
  987:                 ar2_min = np.array(ar2_min, dtype=np.intp)
  988:                 dtype = np.intp
  989:             except OverflowError:
  990:                 dtype = ar2.dtype
  991: 
  992:             out = np.empty_like(in_range_ar1, dtype=np.intp)
  993:             outgoing_array[basic_mask] = isin_helper_ar[
  994:                     np.subtract(in_range_ar1, ar2_min, dtype=dtype,
  995:                                 out=out, casting="unsafe")]
  996: 
  997:             return outgoing_array
  998:         elif kind == 'table':  # not range_safe_from_overflow
  999:             raise RuntimeError(
 1000:                 "You have specified kind='table', "
 1001:                 "but the range of values in `ar2` or `ar1` exceed the "
 1002:                 "maximum integer of the datatype. "
 1003:                 "Please set `kind` to None or 'sort'."
 1004:             )
 1005:     elif kind == 'table':
 1006:         raise ValueError(
 1007:             "The 'table' method is only "
 1008:             "supported for boolean or integer arrays. "
 1009:             "Please select 'sort' or None for kind."
 1010:         )
 1011: 
 1012:     # Check if one of the arrays may contain arbitrary objects
 1013:     contains_object = ar1.dtype.hasobject or ar2.dtype.hasobject
 1014: 
 1015:     # This code is run when
 1016:     # a) the first condition is true, making the code significantly faster
 1017:     # b) the second condition is true (i.e. `ar1` or `ar2` may contain
 1018:     #    arbitrary objects), since then sorting is not guaranteed to work
 1019:     if len(ar2) < 10 * len(ar1) ** 0.145 or contains_object:
 1020:         if invert:
 1021:             mask = np.ones(len(ar1), dtype=bool)
 1022:             for a in ar2:
 1023:                 mask &= (ar1 != a)
 1024:         else:
 1025:             mask = np.zeros(len(ar1), dtype=bool)
 1026:             for a in ar2:
 1027:                 mask |= (ar1 == a)
 1028:         return mask
 1029: 
 1030:     # Otherwise use sorting
 1031:     if not assume_unique:
 1032:         ar1, rev_idx = np.unique(ar1, return_inverse=True)
 1033:         ar2 = np.unique(ar2)
 1034: 
 1035:     ar = np.concatenate((ar1, ar2))
 1036:     # We need this to be a stable sort, so always use 'mergesort'
 1037:     # here. The values from the first array should always come before
 1038:     # the values from the second array.
 1039:     order = ar.argsort(kind='mergesort')
 1040:     sar = ar[order]
 1041:     if invert:
 1042:         bool_ar = (sar[1:] != sar[:-1])
 1043:     else:
 1044:         bool_ar = (sar[1:] == sar[:-1])
 1045:     flag = np.concatenate((bool_ar, [invert]))
 1046:     ret = np.empty(ar.shape, dtype=bool)
 1047:     ret[order] = flag
 1048: 
 1049:     if assume_unique:
 1050:         return ret[:len(ar1)]
 1051:     else:
 1052:         return ret[rev_idx]
 1053: 
 1054: 
 1055: def _isin_dispatcher(element, test_elements, assume_unique=None, invert=None,
 1056:                      *, kind=None):
 1057:     return (element, test_elements)
 1058: 
 1059: 
 1060: @array_function_dispatch(_isin_dispatcher)
 1061: def isin(element, test_elements, assume_unique=False, invert=False, *,
 1062:          kind=None):
 1063:     """
 1064:     Calculates ``element in test_elements``, broadcasting over `element` only.
 1065:     Returns a boolean array of the same shape as `element` that is True
 1066:     where an element of `element` is in `test_elements` and False otherwise.
 1067: 
 1068:     Parameters
 1069:     ----------
 1070:     element : array_like
 1071:         Input array.
 1072:     test_elements : array_like
 1073:         The values against which to test each value of `element`.
 1074:         This argument is flattened if it is an array or array_like.
 1075:         See notes for behavior with non-array-like parameters.
 1076:     assume_unique : bool, optional
 1077:         If True, the input arrays are both assumed to be unique, which
 1078:         can speed up the calculation.  Default is False.
 1079:     invert : bool, optional
 1080:         If True, the values in the returned array are inverted, as if
 1081:         calculating `element not in test_elements`. Default is False.
 1082:         ``np.isin(a, b, invert=True)`` is equivalent to (but faster
 1083:         than) ``np.invert(np.isin(a, b))``.
 1084:     kind : {None, 'sort', 'table'}, optional
 1085:         The algorithm to use. This will not affect the final result,
 1086:         but will affect the speed and memory use. The default, None,
 1087:         will select automatically based on memory considerations.
 1088: 
 1089:         * If 'sort', will use a mergesort-based approach. This will have
 1090:           a memory usage of roughly 6 times the sum of the sizes of
 1091:           `element` and `test_elements`, not accounting for size of dtypes.
 1092:         * If 'table', will use a lookup table approach similar
 1093:           to a counting sort. This is only available for boolean and
 1094:           integer arrays. This will have a memory usage of the
 1095:           size of `element` plus the max-min value of `test_elements`.
 1096:           `assume_unique` has no effect when the 'table' option is used.
 1097:         * If None, will automatically choose 'table' if
 1098:           the required memory allocation is less than or equal to
 1099:           6 times the sum of the sizes of `element` and `test_elements`,
 1100:           otherwise will use 'sort'. This is done to not use
 1101:           a large amount of memory by default, even though
 1102:           'table' may be faster in most cases. If 'table' is chosen,
 1103:           `assume_unique` will have no effect.
 1104: 
 1105: 
 1106:     Returns
 1107:     -------
 1108:     isin : ndarray, bool
 1109:         Has the same shape as `element`. The values `element[isin]`
 1110:         are in `test_elements`.
 1111: 
 1112:     Notes
 1113:     -----
 1114:     `isin` is an element-wise function version of the python keyword `in`.
 1115:     ``isin(a, b)`` is roughly equivalent to
 1116:     ``np.array([item in b for item in a])`` if `a` and `b` are 1-D sequences.
 1117: 
 1118:     `element` and `test_elements` are converted to arrays if they are not
 1119:     already. If `test_elements` is a set (or other non-sequence collection)
 1120:     it will be converted to an object array with one element, rather than an
 1121:     array of the values contained in `test_elements`. This is a consequence
 1122:     of the `array` constructor's way of handling non-sequence collections.
 1123:     Converting the set to a list usually gives the desired behavior.
 1124: 
 1125:     Using ``kind='table'`` tends to be faster than `kind='sort'` if the
 1126:     following relationship is true:
 1127:     ``log10(len(test_elements)) >
 1128:     (log10(max(test_elements)-min(test_elements)) - 2.27) / 0.927``,
 1129:     but may use greater memory. The default value for `kind` will
 1130:     be automatically selected based only on memory usage, so one may
 1131:     manually set ``kind='table'`` if memory constraints can be relaxed.
 1132: 
 1133:     Examples
 1134:     --------
 1135:     >>> import numpy as np
 1136:     >>> element = 2*np.arange(4).reshape((2, 2))
 1137:     >>> element
 1138:     array([[0, 2],
 1139:            [4, 6]])
 1140:     >>> test_elements = [1, 2, 4, 8]
 1141:     >>> mask = np.isin(element, test_elements)
 1142:     >>> mask
 1143:     array([[False,  True],
 1144:            [ True, False]])
 1145:     >>> element[mask]
 1146:     array([2, 4])
 1147: 
 1148:     The indices of the matched values can be obtained with `nonzero`:
 1149: 
 1150:     >>> np.nonzero(mask)
 1151:     (array([0, 1]), array([1, 0]))
 1152: 
 1153:     The test can also be inverted:
 1154: 
 1155:     >>> mask = np.isin(element, test_elements, invert=True)
 1156:     >>> mask
 1157:     array([[ True, False],
 1158:            [False,  True]])
 1159:     >>> element[mask]
 1160:     array([0, 6])
 1161: 
 1162:     Because of how `array` handles sets, the following does not
 1163:     work as expected:
 1164: 
 1165:     >>> test_set = {1, 2, 4, 8}
 1166:     >>> np.isin(element, test_set)
 1167:     array([[False, False],
 1168:            [False, False]])
 1169: 
 1170:     Casting the set to a list gives the expected result:
 1171: 
 1172:     >>> np.isin(element, list(test_set))
 1173:     array([[False,  True],
 1174:            [ True, False]])
 1175:     """
 1176:     element = np.asarray(element)
 1177:     return _in1d(element, test_elements, assume_unique=assume_unique,
 1178:                  invert=invert, kind=kind).reshape(element.shape)
 1179: 
 1180: 
 1181: def _union1d_dispatcher(ar1, ar2):
 1182:     return (ar1, ar2)
 1183: 
 1184: 
 1185: @array_function_dispatch(_union1d_dispatcher)
 1186: def union1d(ar1, ar2):
 1187:     """
 1188:     Find the union of two arrays.
 1189: 
 1190:     Return the unique, sorted array of values that are in either of the two
 1191:     input arrays.
 1192: 
 1193:     Parameters
 1194:     ----------
 1195:     ar1, ar2 : array_like
 1196:         Input arrays. They are flattened if they are not already 1D.
 1197: 
 1198:     Returns
 1199:     -------
 1200:     union1d : ndarray
 1201:         Unique, sorted union of the input arrays.
 1202: 
 1203:     Examples
 1204:     --------
 1205:     >>> import numpy as np
 1206:     >>> np.union1d([-1, 0, 1], [-2, 0, 2])
 1207:     array([-2, -1,  0,  1,  2])
 1208: 
 1209:     To find the union of more than two arrays, use functools.reduce:
 1210: 
 1211:     >>> from functools import reduce
 1212:     >>> reduce(np.union1d, ([1, 3, 4, 3], [3, 1, 2, 1], [6, 3, 4, 2]))
 1213:     array([1, 2, 3, 4, 6])
 1214:     """
 1215:     return unique(np.concatenate((ar1, ar2), axis=None))
 1216: 
 1217: 
 1218: def _setdiff1d_dispatcher(ar1, ar2, assume_unique=None):
 1219:     return (ar1, ar2)
 1220: 
 1221: 
 1222: @array_function_dispatch(_setdiff1d_dispatcher)
 1223: def setdiff1d(ar1, ar2, assume_unique=False):
 1224:     """
 1225:     Find the set difference of two arrays.
 1226: 
 1227:     Return the unique values in `ar1` that are not in `ar2`.
 1228: 
 1229:     Parameters
 1230:     ----------
 1231:     ar1 : array_like
 1232:         Input array.
 1233:     ar2 : array_like
 1234:         Input comparison array.
 1235:     assume_unique : bool
 1236:         If True, the input arrays are both assumed to be unique, which
 1237:         can speed up the calculation.  Default is False.
 1238: 
 1239:     Returns
 1240:     -------
 1241:     setdiff1d : ndarray
 1242:         1D array of values in `ar1` that are not in `ar2`. The result
 1243:         is sorted when `assume_unique=False`, but otherwise only sorted
 1244:         if the input is sorted.
 1245: 
 1246:     Examples
 1247:     --------
 1248:     >>> import numpy as np
 1249:     >>> a = np.array([1, 2, 3, 2, 4, 1])
 1250:     >>> b = np.array([3, 4, 5, 6])
 1251:     >>> np.setdiff1d(a, b)
 1252:     array([1, 2])
 1253: 
 1254:     """
 1255:     if assume_unique:
 1256:         ar1 = np.asarray(ar1).ravel()
 1257:     else:
 1258:         ar1 = unique(ar1)
 1259:         ar2 = unique(ar2)
 1260:     return ar1[_in1d(ar1, ar2, assume_unique=True, invert=True)]
