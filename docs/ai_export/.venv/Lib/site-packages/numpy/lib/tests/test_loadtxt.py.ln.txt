    1: """
    2: Tests specific to `np.loadtxt` added during the move of loadtxt to be backed
    3: by C code.
    4: These tests complement those found in `test_io.py`.
    5: """
    6: 
    7: import os
    8: import sys
    9: from io import StringIO
   10: from tempfile import NamedTemporaryFile, mkstemp
   11: 
   12: import pytest
   13: 
   14: import numpy as np
   15: from numpy.ma.testutils import assert_equal
   16: from numpy.testing import HAS_REFCOUNT, IS_PYPY, assert_array_equal
   17: 
   18: 
   19: def test_scientific_notation():
   20:     """Test that both 'e' and 'E' are parsed correctly."""
   21:     data = StringIO(
   22: 
   23:             "1.0e-1,2.0E1,3.0\n"
   24:             "4.0e-2,5.0E-1,6.0\n"
   25:             "7.0e-3,8.0E1,9.0\n"
   26:             "0.0e-4,1.0E-1,2.0"
   27: 
   28:     )
   29:     expected = np.array(
   30:         [[0.1, 20., 3.0], [0.04, 0.5, 6], [0.007, 80., 9], [0, 0.1, 2]]
   31:     )
   32:     assert_array_equal(np.loadtxt(data, delimiter=","), expected)
   33: 
   34: 
   35: @pytest.mark.parametrize("comment", ["..", "//", "@-", "this is a comment:"])
   36: def test_comment_multiple_chars(comment):
   37:     content = "# IGNORE\n1.5, 2.5# ABC\n3.0,4.0# XXX\n5.5,6.0\n"
   38:     txt = StringIO(content.replace("#", comment))
   39:     a = np.loadtxt(txt, delimiter=",", comments=comment)
   40:     assert_equal(a, [[1.5, 2.5], [3.0, 4.0], [5.5, 6.0]])
   41: 
   42: 
   43: @pytest.fixture
   44: def mixed_types_structured():
   45:     """
   46:     Fixture providing heterogeneous input data with a structured dtype, along
   47:     with the associated structured array.
   48:     """
   49:     data = StringIO(
   50: 
   51:             "1000;2.4;alpha;-34\n"
   52:             "2000;3.1;beta;29\n"
   53:             "3500;9.9;gamma;120\n"
   54:             "4090;8.1;delta;0\n"
   55:             "5001;4.4;epsilon;-99\n"
   56:             "6543;7.8;omega;-1\n"
   57: 
   58:     )
   59:     dtype = np.dtype(
   60:         [('f0', np.uint16), ('f1', np.float64), ('f2', 'S7'), ('f3', np.int8)]
   61:     )
   62:     expected = np.array(
   63:         [
   64:             (1000, 2.4, "alpha", -34),
   65:             (2000, 3.1, "beta", 29),
   66:             (3500, 9.9, "gamma", 120),
   67:             (4090, 8.1, "delta", 0),
   68:             (5001, 4.4, "epsilon", -99),
   69:             (6543, 7.8, "omega", -1)
   70:         ],
   71:         dtype=dtype
   72:     )
   73:     return data, dtype, expected
   74: 
   75: 
   76: @pytest.mark.parametrize('skiprows', [0, 1, 2, 3])
   77: def test_structured_dtype_and_skiprows_no_empty_lines(
   78:         skiprows, mixed_types_structured):
   79:     data, dtype, expected = mixed_types_structured
   80:     a = np.loadtxt(data, dtype=dtype, delimiter=";", skiprows=skiprows)
   81:     assert_array_equal(a, expected[skiprows:])
   82: 
   83: 
   84: def test_unpack_structured(mixed_types_structured):
   85:     data, dtype, expected = mixed_types_structured
   86: 
   87:     a, b, c, d = np.loadtxt(data, dtype=dtype, delimiter=";", unpack=True)
   88:     assert_array_equal(a, expected["f0"])
   89:     assert_array_equal(b, expected["f1"])
   90:     assert_array_equal(c, expected["f2"])
   91:     assert_array_equal(d, expected["f3"])
   92: 
   93: 
   94: def test_structured_dtype_with_shape():
   95:     dtype = np.dtype([("a", "u1", 2), ("b", "u1", 2)])
   96:     data = StringIO("0,1,2,3\n6,7,8,9\n")
   97:     expected = np.array([((0, 1), (2, 3)), ((6, 7), (8, 9))], dtype=dtype)
   98:     assert_array_equal(np.loadtxt(data, delimiter=",", dtype=dtype), expected)
   99: 
  100: 
  101: def test_structured_dtype_with_multi_shape():
  102:     dtype = np.dtype([("a", "u1", (2, 2))])
  103:     data = StringIO("0 1 2 3\n")
  104:     expected = np.array([(((0, 1), (2, 3)),)], dtype=dtype)
  105:     assert_array_equal(np.loadtxt(data, dtype=dtype), expected)
  106: 
  107: 
  108: def test_nested_structured_subarray():
  109:     # Test from gh-16678
  110:     point = np.dtype([('x', float), ('y', float)])
  111:     dt = np.dtype([('code', int), ('points', point, (2,))])
  112:     data = StringIO("100,1,2,3,4\n200,5,6,7,8\n")
  113:     expected = np.array(
  114:         [
  115:             (100, [(1., 2.), (3., 4.)]),
  116:             (200, [(5., 6.), (7., 8.)]),
  117:         ],
  118:         dtype=dt
  119:     )
  120:     assert_array_equal(np.loadtxt(data, dtype=dt, delimiter=","), expected)
  121: 
  122: 
  123: def test_structured_dtype_offsets():
  124:     # An aligned structured dtype will have additional padding
  125:     dt = np.dtype("i1, i4, i1, i4, i1, i4", align=True)
  126:     data = StringIO("1,2,3,4,5,6\n7,8,9,10,11,12\n")
  127:     expected = np.array([(1, 2, 3, 4, 5, 6), (7, 8, 9, 10, 11, 12)], dtype=dt)
  128:     assert_array_equal(np.loadtxt(data, delimiter=",", dtype=dt), expected)
  129: 
  130: 
  131: @pytest.mark.parametrize("param", ("skiprows", "max_rows"))
  132: def test_exception_negative_row_limits(param):
  133:     """skiprows and max_rows should raise for negative parameters."""
  134:     with pytest.raises(ValueError, match="argument must be nonnegative"):
  135:         np.loadtxt("foo.bar", **{param: -3})
  136: 
  137: 
  138: @pytest.mark.parametrize("param", ("skiprows", "max_rows"))
  139: def test_exception_noninteger_row_limits(param):
  140:     with pytest.raises(TypeError, match="argument must be an integer"):
  141:         np.loadtxt("foo.bar", **{param: 1.0})
  142: 
  143: 
  144: @pytest.mark.parametrize(
  145:     "data, shape",
  146:     [
  147:         ("1 2 3 4 5\n", (1, 5)),  # Single row
  148:         ("1\n2\n3\n4\n5\n", (5, 1)),  # Single column
  149:     ]
  150: )
  151: def test_ndmin_single_row_or_col(data, shape):
  152:     arr = np.array([1, 2, 3, 4, 5])
  153:     arr2d = arr.reshape(shape)
  154: 
  155:     assert_array_equal(np.loadtxt(StringIO(data), dtype=int), arr)
  156:     assert_array_equal(np.loadtxt(StringIO(data), dtype=int, ndmin=0), arr)
  157:     assert_array_equal(np.loadtxt(StringIO(data), dtype=int, ndmin=1), arr)
  158:     assert_array_equal(np.loadtxt(StringIO(data), dtype=int, ndmin=2), arr2d)
  159: 
  160: 
  161: @pytest.mark.parametrize("badval", [-1, 3, None, "plate of shrimp"])
  162: def test_bad_ndmin(badval):
  163:     with pytest.raises(ValueError, match="Illegal value of ndmin keyword"):
  164:         np.loadtxt("foo.bar", ndmin=badval)
  165: 
  166: 
  167: @pytest.mark.parametrize(
  168:     "ws",
  169:     (
  170:             " ",  # space
  171:             "\t",  # tab
  172:             "\u2003",  # em
  173:             "\u00A0",  # non-break
  174:             "\u3000",  # ideographic space
  175:     )
  176: )
  177: def test_blank_lines_spaces_delimit(ws):
  178:     txt = StringIO(
  179:         f"1 2{ws}30\n\n{ws}\n"
  180:         f"4 5 60{ws}\n  {ws}  \n"
  181:         f"7 8 {ws} 90\n  # comment\n"
  182:         f"3 2 1"
  183:     )
  184:     # NOTE: It is unclear that the `  # comment` should succeed. Except
  185:     #       for delimiter=None, which should use any whitespace (and maybe
  186:     #       should just be implemented closer to Python
  187:     expected = np.array([[1, 2, 30], [4, 5, 60], [7, 8, 90], [3, 2, 1]])
  188:     assert_equal(
  189:         np.loadtxt(txt, dtype=int, delimiter=None, comments="#"), expected
  190:     )
  191: 
  192: 
  193: def test_blank_lines_normal_delimiter():
  194:     txt = StringIO('1,2,30\n\n4,5,60\n\n7,8,90\n# comment\n3,2,1')
  195:     expected = np.array([[1, 2, 30], [4, 5, 60], [7, 8, 90], [3, 2, 1]])
  196:     assert_equal(
  197:         np.loadtxt(txt, dtype=int, delimiter=',', comments="#"), expected
  198:     )
  199: 
  200: 
  201: @pytest.mark.parametrize("dtype", (float, object))
  202: def test_maxrows_no_blank_lines(dtype):
  203:     txt = StringIO("1.5,2.5\n3.0,4.0\n5.5,6.0")
  204:     res = np.loadtxt(txt, dtype=dtype, delimiter=",", max_rows=2)
  205:     assert_equal(res.dtype, dtype)
  206:     assert_equal(res, np.array([["1.5", "2.5"], ["3.0", "4.0"]], dtype=dtype))
  207: 
  208: 
  209: @pytest.mark.skipif(IS_PYPY and sys.implementation.version <= (7, 3, 8),
  210:                     reason="PyPy bug in error formatting")
  211: @pytest.mark.parametrize("dtype", (np.dtype("f8"), np.dtype("i2")))
  212: def test_exception_message_bad_values(dtype):
  213:     txt = StringIO("1,2\n3,XXX\n5,6")
  214:     msg = f"could not convert string 'XXX' to {dtype} at row 1, column 2"
  215:     with pytest.raises(ValueError, match=msg):
  216:         np.loadtxt(txt, dtype=dtype, delimiter=",")
  217: 
  218: 
  219: def test_converters_negative_indices():
  220:     txt = StringIO('1.5,2.5\n3.0,XXX\n5.5,6.0')
  221:     conv = {-1: lambda s: np.nan if s == 'XXX' else float(s)}
  222:     expected = np.array([[1.5, 2.5], [3.0, np.nan], [5.5, 6.0]])
  223:     res = np.loadtxt(txt, dtype=np.float64, delimiter=",", converters=conv)
  224:     assert_equal(res, expected)
  225: 
  226: 
  227: def test_converters_negative_indices_with_usecols():
  228:     txt = StringIO('1.5,2.5,3.5\n3.0,4.0,XXX\n5.5,6.0,7.5\n')
  229:     conv = {-1: lambda s: np.nan if s == 'XXX' else float(s)}
  230:     expected = np.array([[1.5, 3.5], [3.0, np.nan], [5.5, 7.5]])
  231:     res = np.loadtxt(
  232:         txt,
  233:         dtype=np.float64,
  234:         delimiter=",",
  235:         converters=conv,
  236:         usecols=[0, -1],
  237:     )
  238:     assert_equal(res, expected)
  239: 
  240:     # Second test with variable number of rows:
  241:     res = np.loadtxt(StringIO('''0,1,2\n0,1,2,3,4'''), delimiter=",",
  242:                      usecols=[0, -1], converters={-1: (lambda x: -1)})
  243:     assert_array_equal(res, [[0, -1], [0, -1]])
  244: 
  245: 
  246: def test_ragged_error():
  247:     rows = ["1,2,3", "1,2,3", "4,3,2,1"]
  248:     with pytest.raises(ValueError,
  249:             match="the number of columns changed from 3 to 4 at row 3"):
  250:         np.loadtxt(rows, delimiter=",")
  251: 
  252: 
  253: def test_ragged_usecols():
  254:     # usecols, and negative ones, work even with varying number of columns.
  255:     txt = StringIO("0,0,XXX\n0,XXX,0,XXX\n0,XXX,XXX,0,XXX\n")
  256:     expected = np.array([[0, 0], [0, 0], [0, 0]])
  257:     res = np.loadtxt(txt, dtype=float, delimiter=",", usecols=[0, -2])
  258:     assert_equal(res, expected)
  259: 
  260:     txt = StringIO("0,0,XXX\n0\n0,XXX,XXX,0,XXX\n")
  261:     with pytest.raises(ValueError,
  262:                 match="invalid column index -2 at row 2 with 1 columns"):
  263:         # There is no -2 column in the second row:
  264:         np.loadtxt(txt, dtype=float, delimiter=",", usecols=[0, -2])
  265: 
  266: 
  267: def test_empty_usecols():
  268:     txt = StringIO("0,0,XXX\n0,XXX,0,XXX\n0,XXX,XXX,0,XXX\n")
  269:     res = np.loadtxt(txt, dtype=np.dtype([]), delimiter=",", usecols=[])
  270:     assert res.shape == (3,)
  271:     assert res.dtype == np.dtype([])
  272: 
  273: 
  274: @pytest.mark.parametrize("c1", ["a", "гЃ®", "рџ«•"])
  275: @pytest.mark.parametrize("c2", ["a", "гЃ®", "рџ«•"])
  276: def test_large_unicode_characters(c1, c2):
  277:     # c1 and c2 span ascii, 16bit and 32bit range.
  278:     txt = StringIO(f"a,{c1},c,1.0\ne,{c2},2.0,g")
  279:     res = np.loadtxt(txt, dtype=np.dtype('U12'), delimiter=",")
  280:     expected = np.array(
  281:         [f"a,{c1},c,1.0".split(","), f"e,{c2},2.0,g".split(",")],
  282:         dtype=np.dtype('U12')
  283:     )
  284:     assert_equal(res, expected)
  285: 
  286: 
  287: def test_unicode_with_converter():
  288:     txt = StringIO("cat,dog\nО±ОІОі,ОґОµО¶\nabc,def\n")
  289:     conv = {0: lambda s: s.upper()}
  290:     res = np.loadtxt(
  291:         txt,
  292:         dtype=np.dtype("U12"),
  293:         converters=conv,
  294:         delimiter=",",
  295:         encoding=None
  296:     )
  297:     expected = np.array([['CAT', 'dog'], ['О‘О’О“', 'ОґОµО¶'], ['ABC', 'def']])
  298:     assert_equal(res, expected)
  299: 
  300: 
  301: def test_converter_with_structured_dtype():
  302:     txt = StringIO('1.5,2.5,Abc\n3.0,4.0,dEf\n5.5,6.0,ghI\n')
  303:     dt = np.dtype([('m', np.int32), ('r', np.float32), ('code', 'U8')])
  304:     conv = {0: lambda s: int(10 * float(s)), -1: lambda s: s.upper()}
  305:     res = np.loadtxt(txt, dtype=dt, delimiter=",", converters=conv)
  306:     expected = np.array(
  307:         [(15, 2.5, 'ABC'), (30, 4.0, 'DEF'), (55, 6.0, 'GHI')], dtype=dt
  308:     )
  309:     assert_equal(res, expected)
  310: 
  311: 
  312: def test_converter_with_unicode_dtype():
  313:     """
  314:     With the 'bytes' encoding, tokens are encoded prior to being
  315:     passed to the converter. This means that the output of the converter may
  316:     be bytes instead of unicode as expected by `read_rows`.
  317: 
  318:     This test checks that outputs from the above scenario are properly decoded
  319:     prior to parsing by `read_rows`.
  320:     """
  321:     txt = StringIO('abc,def\nrst,xyz')
  322:     conv = bytes.upper
  323:     res = np.loadtxt(
  324:             txt, dtype=np.dtype("U3"), converters=conv, delimiter=",",
  325:             encoding="bytes")
  326:     expected = np.array([['ABC', 'DEF'], ['RST', 'XYZ']])
  327:     assert_equal(res, expected)
  328: 
  329: 
  330: def test_read_huge_row():
  331:     row = "1.5, 2.5," * 50000
  332:     row = row[:-1] + "\n"
  333:     txt = StringIO(row * 2)
  334:     res = np.loadtxt(txt, delimiter=",", dtype=float)
  335:     assert_equal(res, np.tile([1.5, 2.5], (2, 50000)))
  336: 
  337: 
  338: @pytest.mark.parametrize("dtype", "edfgFDG")
  339: def test_huge_float(dtype):
  340:     # Covers a non-optimized path that is rarely taken:
  341:     field = "0" * 1000 + ".123456789"
  342:     dtype = np.dtype(dtype)
  343:     value = np.loadtxt([field], dtype=dtype)[()]
  344:     assert value == dtype.type("0.123456789")
  345: 
  346: 
  347: @pytest.mark.parametrize(
  348:     ("given_dtype", "expected_dtype"),
  349:     [
  350:         ("S", np.dtype("S5")),
  351:         ("U", np.dtype("U5")),
  352:     ],
  353: )
  354: def test_string_no_length_given(given_dtype, expected_dtype):
  355:     """
  356:     The given dtype is just 'S' or 'U' with no length. In these cases, the
  357:     length of the resulting dtype is determined by the longest string found
  358:     in the file.
  359:     """
  360:     txt = StringIO("AAA,5-1\nBBBBB,0-3\nC,4-9\n")
  361:     res = np.loadtxt(txt, dtype=given_dtype, delimiter=",")
  362:     expected = np.array(
  363:         [['AAA', '5-1'], ['BBBBB', '0-3'], ['C', '4-9']], dtype=expected_dtype
  364:     )
  365:     assert_equal(res, expected)
  366:     assert_equal(res.dtype, expected_dtype)
  367: 
  368: 
  369: def test_float_conversion():
  370:     """
  371:     Some tests that the conversion to float64 works as accurately as the
  372:     Python built-in `float` function. In a naive version of the float parser,
  373:     these strings resulted in values that were off by an ULP or two.
  374:     """
  375:     strings = [
  376:         '0.9999999999999999',
  377:         '9876543210.123456',
  378:         '5.43215432154321e+300',
  379:         '0.901',
  380:         '0.333',
  381:     ]
  382:     txt = StringIO('\n'.join(strings))
  383:     res = np.loadtxt(txt)
  384:     expected = np.array([float(s) for s in strings])
  385:     assert_equal(res, expected)
  386: 
  387: 
  388: def test_bool():
  389:     # Simple test for bool via integer
  390:     txt = StringIO("1, 0\n10, -1")
  391:     res = np.loadtxt(txt, dtype=bool, delimiter=",")
  392:     assert res.dtype == bool
  393:     assert_array_equal(res, [[True, False], [True, True]])
  394:     # Make sure we use only 1 and 0 on the byte level:
  395:     assert_array_equal(res.view(np.uint8), [[1, 0], [1, 1]])
  396: 
  397: 
  398: @pytest.mark.skipif(IS_PYPY and sys.implementation.version <= (7, 3, 8),
  399:                     reason="PyPy bug in error formatting")
  400: @pytest.mark.parametrize("dtype", np.typecodes["AllInteger"])
  401: @pytest.mark.filterwarnings("error:.*integer via a float.*:DeprecationWarning")
  402: def test_integer_signs(dtype):
  403:     dtype = np.dtype(dtype)
  404:     assert np.loadtxt(["+2"], dtype=dtype) == 2
  405:     if dtype.kind == "u":
  406:         with pytest.raises(ValueError):
  407:             np.loadtxt(["-1\n"], dtype=dtype)
  408:     else:
  409:         assert np.loadtxt(["-2\n"], dtype=dtype) == -2
  410: 
  411:     for sign in ["++", "+-", "--", "-+"]:
  412:         with pytest.raises(ValueError):
  413:             np.loadtxt([f"{sign}2\n"], dtype=dtype)
  414: 
  415: 
  416: @pytest.mark.skipif(IS_PYPY and sys.implementation.version <= (7, 3, 8),
  417:                     reason="PyPy bug in error formatting")
  418: @pytest.mark.parametrize("dtype", np.typecodes["AllInteger"])
  419: @pytest.mark.filterwarnings("error:.*integer via a float.*:DeprecationWarning")
  420: def test_implicit_cast_float_to_int_fails(dtype):
  421:     txt = StringIO("1.0, 2.1, 3.7\n4, 5, 6")
  422:     with pytest.raises(ValueError):
  423:         np.loadtxt(txt, dtype=dtype, delimiter=",")
  424: 
  425: @pytest.mark.parametrize("dtype", (np.complex64, np.complex128))
  426: @pytest.mark.parametrize("with_parens", (False, True))
  427: def test_complex_parsing(dtype, with_parens):
  428:     s = "(1.0-2.5j),3.75,(7+-5.0j)\n(4),(-19e2j),(0)"
  429:     if not with_parens:
  430:         s = s.replace("(", "").replace(")", "")
  431: 
  432:     res = np.loadtxt(StringIO(s), dtype=dtype, delimiter=",")
  433:     expected = np.array(
  434:         [[1.0 - 2.5j, 3.75, 7 - 5j], [4.0, -1900j, 0]], dtype=dtype
  435:     )
  436:     assert_equal(res, expected)
  437: 
  438: 
  439: def test_read_from_generator():
  440:     def gen():
  441:         for i in range(4):
  442:             yield f"{i},{2 * i},{i**2}"
  443: 
  444:     res = np.loadtxt(gen(), dtype=int, delimiter=",")
  445:     expected = np.array([[0, 0, 0], [1, 2, 1], [2, 4, 4], [3, 6, 9]])
  446:     assert_equal(res, expected)
  447: 
  448: 
  449: def test_read_from_generator_multitype():
  450:     def gen():
  451:         for i in range(3):
  452:             yield f"{i} {i / 4}"
  453: 
  454:     res = np.loadtxt(gen(), dtype="i, d", delimiter=" ")
  455:     expected = np.array([(0, 0.0), (1, 0.25), (2, 0.5)], dtype="i, d")
  456:     assert_equal(res, expected)
  457: 
  458: 
  459: def test_read_from_bad_generator():
  460:     def gen():
  461:         yield from ["1,2", b"3, 5", 12738]
  462: 
  463:     with pytest.raises(
  464:             TypeError, match=r"non-string returned while reading data"):
  465:         np.loadtxt(gen(), dtype="i, i", delimiter=",")
  466: 
  467: 
  468: @pytest.mark.skipif(not HAS_REFCOUNT, reason="Python lacks refcounts")
  469: def test_object_cleanup_on_read_error():
  470:     sentinel = object()
  471:     already_read = 0
  472: 
  473:     def conv(x):
  474:         nonlocal already_read
  475:         if already_read > 4999:
  476:             raise ValueError("failed half-way through!")
  477:         already_read += 1
  478:         return sentinel
  479: 
  480:     txt = StringIO("x\n" * 10000)
  481: 
  482:     with pytest.raises(ValueError, match="at row 5000, column 1"):
  483:         np.loadtxt(txt, dtype=object, converters={0: conv})
  484: 
  485:     assert sys.getrefcount(sentinel) == 2
  486: 
  487: 
  488: @pytest.mark.skipif(IS_PYPY and sys.implementation.version <= (7, 3, 8),
  489:                     reason="PyPy bug in error formatting")
  490: def test_character_not_bytes_compatible():
  491:     """Test exception when a character cannot be encoded as 'S'."""
  492:     data = StringIO("вЂ“")  # == \u2013
  493:     with pytest.raises(ValueError):
  494:         np.loadtxt(data, dtype="S5")
  495: 
  496: 
  497: @pytest.mark.parametrize("conv", (0, [float], ""))
  498: def test_invalid_converter(conv):
  499:     msg = (
  500:         "converters must be a dictionary mapping columns to converter "
  501:         "functions or a single callable."
  502:     )
  503:     with pytest.raises(TypeError, match=msg):
  504:         np.loadtxt(StringIO("1 2\n3 4"), converters=conv)
  505: 
  506: 
  507: @pytest.mark.skipif(IS_PYPY and sys.implementation.version <= (7, 3, 8),
  508:                     reason="PyPy bug in error formatting")
  509: def test_converters_dict_raises_non_integer_key():
  510:     with pytest.raises(TypeError, match="keys of the converters dict"):
  511:         np.loadtxt(StringIO("1 2\n3 4"), converters={"a": int})
  512:     with pytest.raises(TypeError, match="keys of the converters dict"):
  513:         np.loadtxt(StringIO("1 2\n3 4"), converters={"a": int}, usecols=0)
  514: 
  515: 
  516: @pytest.mark.parametrize("bad_col_ind", (3, -3))
  517: def test_converters_dict_raises_non_col_key(bad_col_ind):
  518:     data = StringIO("1 2\n3 4")
  519:     with pytest.raises(ValueError, match="converter specified for column"):
  520:         np.loadtxt(data, converters={bad_col_ind: int})
  521: 
  522: 
  523: def test_converters_dict_raises_val_not_callable():
  524:     with pytest.raises(TypeError,
  525:                 match="values of the converters dictionary must be callable"):
  526:         np.loadtxt(StringIO("1 2\n3 4"), converters={0: 1})
  527: 
  528: 
  529: @pytest.mark.parametrize("q", ('"', "'", "`"))
  530: def test_quoted_field(q):
  531:     txt = StringIO(
  532:         f"{q}alpha, x{q}, 2.5\n{q}beta, y{q}, 4.5\n{q}gamma, z{q}, 5.0\n"
  533:     )
  534:     dtype = np.dtype([('f0', 'U8'), ('f1', np.float64)])
  535:     expected = np.array(
  536:         [("alpha, x", 2.5), ("beta, y", 4.5), ("gamma, z", 5.0)], dtype=dtype
  537:     )
  538: 
  539:     res = np.loadtxt(txt, dtype=dtype, delimiter=",", quotechar=q)
  540:     assert_array_equal(res, expected)
  541: 
  542: 
  543: @pytest.mark.parametrize("q", ('"', "'", "`"))
  544: def test_quoted_field_with_whitepace_delimiter(q):
  545:     txt = StringIO(
  546:         f"{q}alpha, x{q}     2.5\n{q}beta, y{q} 4.5\n{q}gamma, z{q}   5.0\n"
  547:     )
  548:     dtype = np.dtype([('f0', 'U8'), ('f1', np.float64)])
  549:     expected = np.array(
  550:         [("alpha, x", 2.5), ("beta, y", 4.5), ("gamma, z", 5.0)], dtype=dtype
  551:     )
  552: 
  553:     res = np.loadtxt(txt, dtype=dtype, delimiter=None, quotechar=q)
  554:     assert_array_equal(res, expected)
  555: 
  556: 
  557: def test_quote_support_default():
  558:     """Support for quoted fields is disabled by default."""
  559:     txt = StringIO('"lat,long", 45, 30\n')
  560:     dtype = np.dtype([('f0', 'U24'), ('f1', np.float64), ('f2', np.float64)])
  561: 
  562:     with pytest.raises(ValueError,
  563:             match="the dtype passed requires 3 columns but 4 were"):
  564:         np.loadtxt(txt, dtype=dtype, delimiter=",")
  565: 
  566:     # Enable quoting support with non-None value for quotechar param
  567:     txt.seek(0)
  568:     expected = np.array([("lat,long", 45., 30.)], dtype=dtype)
  569: 
  570:     res = np.loadtxt(txt, dtype=dtype, delimiter=",", quotechar='"')
  571:     assert_array_equal(res, expected)
  572: 
  573: 
  574: @pytest.mark.skipif(IS_PYPY and sys.implementation.version <= (7, 3, 8),
  575:                     reason="PyPy bug in error formatting")
  576: def test_quotechar_multichar_error():
  577:     txt = StringIO("1,2\n3,4")
  578:     msg = r".*must be a single unicode character or None"
  579:     with pytest.raises(TypeError, match=msg):
  580:         np.loadtxt(txt, delimiter=",", quotechar="''")
  581: 
  582: 
  583: def test_comment_multichar_error_with_quote():
  584:     txt = StringIO("1,2\n3,4")
  585:     msg = (
  586:         "when multiple comments or a multi-character comment is given, "
  587:         "quotes are not supported."
  588:     )
  589:     with pytest.raises(ValueError, match=msg):
  590:         np.loadtxt(txt, delimiter=",", comments="123", quotechar='"')
  591:     with pytest.raises(ValueError, match=msg):
  592:         np.loadtxt(txt, delimiter=",", comments=["#", "%"], quotechar='"')
  593: 
  594:     # A single character string in a tuple is unpacked though:
  595:     res = np.loadtxt(txt, delimiter=",", comments=("#",), quotechar="'")
  596:     assert_equal(res, [[1, 2], [3, 4]])
  597: 
  598: 
  599: def test_structured_dtype_with_quotes():
  600:     data = StringIO(
  601: 
  602:             "1000;2.4;'alpha';-34\n"
  603:             "2000;3.1;'beta';29\n"
  604:             "3500;9.9;'gamma';120\n"
  605:             "4090;8.1;'delta';0\n"
  606:             "5001;4.4;'epsilon';-99\n"
  607:             "6543;7.8;'omega';-1\n"
  608: 
  609:     )
  610:     dtype = np.dtype(
  611:         [('f0', np.uint16), ('f1', np.float64), ('f2', 'S7'), ('f3', np.int8)]
  612:     )
  613:     expected = np.array(
  614:         [
  615:             (1000, 2.4, "alpha", -34),
  616:             (2000, 3.1, "beta", 29),
  617:             (3500, 9.9, "gamma", 120),
  618:             (4090, 8.1, "delta", 0),
  619:             (5001, 4.4, "epsilon", -99),
  620:             (6543, 7.8, "omega", -1)
  621:         ],
  622:         dtype=dtype
  623:     )
  624:     res = np.loadtxt(data, dtype=dtype, delimiter=";", quotechar="'")
  625:     assert_array_equal(res, expected)
  626: 
  627: 
  628: def test_quoted_field_is_not_empty():
  629:     txt = StringIO('1\n\n"4"\n""')
  630:     expected = np.array(["1", "4", ""], dtype="U1")
  631:     res = np.loadtxt(txt, delimiter=",", dtype="U1", quotechar='"')
  632:     assert_equal(res, expected)
  633: 
  634: def test_quoted_field_is_not_empty_nonstrict():
  635:     # Same as test_quoted_field_is_not_empty but check that we are not strict
  636:     # about missing closing quote (this is the `csv.reader` default also)
  637:     txt = StringIO('1\n\n"4"\n"')
  638:     expected = np.array(["1", "4", ""], dtype="U1")
  639:     res = np.loadtxt(txt, delimiter=",", dtype="U1", quotechar='"')
  640:     assert_equal(res, expected)
  641: 
  642: def test_consecutive_quotechar_escaped():
  643:     txt = StringIO('"Hello, my name is ""Monty""!"')
  644:     expected = np.array('Hello, my name is "Monty"!', dtype="U40")
  645:     res = np.loadtxt(txt, dtype="U40", delimiter=",", quotechar='"')
  646:     assert_equal(res, expected)
  647: 
  648: 
  649: @pytest.mark.parametrize("data", ("", "\n\n\n", "# 1 2 3\n# 4 5 6\n"))
  650: @pytest.mark.parametrize("ndmin", (0, 1, 2))
  651: @pytest.mark.parametrize("usecols", [None, (1, 2, 3)])
  652: def test_warn_on_no_data(data, ndmin, usecols):
  653:     """Check that a UserWarning is emitted when no data is read from input."""
  654:     if usecols is not None:
  655:         expected_shape = (0, 3)
  656:     elif ndmin == 2:
  657:         expected_shape = (0, 1)  # guess a single column?!
  658:     else:
  659:         expected_shape = (0,)
  660: 
  661:     txt = StringIO(data)
  662:     with pytest.warns(UserWarning, match="input contained no data"):
  663:         res = np.loadtxt(txt, ndmin=ndmin, usecols=usecols)
  664:     assert res.shape == expected_shape
  665: 
  666:     with NamedTemporaryFile(mode="w") as fh:
  667:         fh.write(data)
  668:         fh.seek(0)
  669:         with pytest.warns(UserWarning, match="input contained no data"):
  670:             res = np.loadtxt(txt, ndmin=ndmin, usecols=usecols)
  671:         assert res.shape == expected_shape
  672: 
  673: @pytest.mark.parametrize("skiprows", (2, 3))
  674: def test_warn_on_skipped_data(skiprows):
  675:     data = "1 2 3\n4 5 6"
  676:     txt = StringIO(data)
  677:     with pytest.warns(UserWarning, match="input contained no data"):
  678:         np.loadtxt(txt, skiprows=skiprows)
  679: 
  680: 
  681: @pytest.mark.parametrize(["dtype", "value"], [
  682:         ("i2", 0x0001), ("u2", 0x0001),
  683:         ("i4", 0x00010203), ("u4", 0x00010203),
  684:         ("i8", 0x0001020304050607), ("u8", 0x0001020304050607),
  685:         # The following values are constructed to lead to unique bytes:
  686:         ("float16", 3.07e-05),
  687:         ("float32", 9.2557e-41), ("complex64", 9.2557e-41 + 2.8622554e-29j),
  688:         ("float64", -1.758571353180402e-24),
  689:         # Here and below, the repr side-steps a small loss of precision in
  690:         # complex `str` in PyPy (which is probably fine, as repr works):
  691:         ("complex128", repr(5.406409232372729e-29 - 1.758571353180402e-24j)),
  692:         # Use integer values that fit into double.  Everything else leads to
  693:         # problems due to longdoubles going via double and decimal strings
  694:         # causing rounding errors.
  695:         ("longdouble", 0x01020304050607),
  696:         ("clongdouble", repr(0x01020304050607 + (0x00121314151617 * 1j))),
  697:         ("U2", "\U00010203\U000a0b0c")])
  698: @pytest.mark.parametrize("swap", [True, False])
  699: def test_byteswapping_and_unaligned(dtype, value, swap):
  700:     # Try to create "interesting" values within the valid unicode range:
  701:     dtype = np.dtype(dtype)
  702:     data = [f"x,{value}\n"]  # repr as PyPy `str` truncates some
  703:     if swap:
  704:         dtype = dtype.newbyteorder()
  705:     full_dt = np.dtype([("a", "S1"), ("b", dtype)], align=False)
  706:     # The above ensures that the interesting "b" field is unaligned:
  707:     assert full_dt.fields["b"][1] == 1
  708:     res = np.loadtxt(data, dtype=full_dt, delimiter=",",
  709:                      max_rows=1)  # max-rows prevents over-allocation
  710:     assert res["b"] == dtype.type(value)
  711: 
  712: 
  713: @pytest.mark.parametrize("dtype",
  714:         np.typecodes["AllInteger"] + "efdFD" + "?")
  715: def test_unicode_whitespace_stripping(dtype):
  716:     # Test that all numeric types (and bool) strip whitespace correctly
  717:     # \u202F is a narrow no-break space, `\n` is just a whitespace if quoted.
  718:     # Currently, skip float128 as it did not always support this and has no
  719:     # "custom" parsing:
  720:     txt = StringIO(' 3 ,"\u202F2\n"')
  721:     res = np.loadtxt(txt, dtype=dtype, delimiter=",", quotechar='"')
  722:     assert_array_equal(res, np.array([3, 2]).astype(dtype))
  723: 
  724: 
  725: @pytest.mark.parametrize("dtype", "FD")
  726: def test_unicode_whitespace_stripping_complex(dtype):
  727:     # Complex has a few extra cases since it has two components and
  728:     # parentheses
  729:     line = " 1 , 2+3j , ( 4+5j ), ( 6+-7j )  , 8j , ( 9j ) \n"
  730:     data = [line, line.replace(" ", "\u202F")]
  731:     res = np.loadtxt(data, dtype=dtype, delimiter=',')
  732:     assert_array_equal(res, np.array([[1, 2 + 3j, 4 + 5j, 6 - 7j, 8j, 9j]] * 2))
  733: 
  734: 
  735: @pytest.mark.skipif(IS_PYPY and sys.implementation.version <= (7, 3, 8),
  736:                     reason="PyPy bug in error formatting")
  737: @pytest.mark.parametrize("dtype", "FD")
  738: @pytest.mark.parametrize("field",
  739:         ["1 +2j", "1+ 2j", "1+2 j", "1+-+3", "(1j", "(1", "(1+2j", "1+2j)"])
  740: def test_bad_complex(dtype, field):
  741:     with pytest.raises(ValueError):
  742:         np.loadtxt([field + "\n"], dtype=dtype, delimiter=",")
  743: 
  744: 
  745: @pytest.mark.skipif(IS_PYPY and sys.implementation.version <= (7, 3, 8),
  746:                     reason="PyPy bug in error formatting")
  747: @pytest.mark.parametrize("dtype",
  748:             np.typecodes["AllInteger"] + "efgdFDG" + "?")
  749: def test_nul_character_error(dtype):
  750:     # Test that a \0 character is correctly recognized as an error even if
  751:     # what comes before is valid (not everything gets parsed internally).
  752:     if dtype.lower() == "g":
  753:         pytest.xfail("longdouble/clongdouble assignment may misbehave.")
  754:     with pytest.raises(ValueError):
  755:         np.loadtxt(["1\000"], dtype=dtype, delimiter=",", quotechar='"')
  756: 
  757: 
  758: @pytest.mark.skipif(IS_PYPY and sys.implementation.version <= (7, 3, 8),
  759:                     reason="PyPy bug in error formatting")
  760: @pytest.mark.parametrize("dtype",
  761:         np.typecodes["AllInteger"] + "efgdFDG" + "?")
  762: def test_no_thousands_support(dtype):
  763:     # Mainly to document behaviour, Python supports thousands like 1_1.
  764:     # (e and G may end up using different conversion and support it, this is
  765:     # a bug but happens...)
  766:     if dtype == "e":
  767:         pytest.skip("half assignment currently uses Python float converter")
  768:     if dtype in "eG":
  769:         pytest.xfail("clongdouble assignment is buggy (uses `complex`?).")
  770: 
  771:     assert int("1_1") == float("1_1") == complex("1_1") == 11
  772:     with pytest.raises(ValueError):
  773:         np.loadtxt(["1_1\n"], dtype=dtype)
  774: 
  775: 
  776: @pytest.mark.parametrize("data", [
  777:     ["1,2\n", "2\n,3\n"],
  778:     ["1,2\n", "2\r,3\n"]])
  779: def test_bad_newline_in_iterator(data):
  780:     # In NumPy <=1.22 this was accepted, because newlines were completely
  781:     # ignored when the input was an iterable.  This could be changed, but right
  782:     # now, we raise an error.
  783:     msg = "Found an unquoted embedded newline within a single line"
  784:     with pytest.raises(ValueError, match=msg):
  785:         np.loadtxt(data, delimiter=",")
  786: 
  787: 
  788: @pytest.mark.parametrize("data", [
  789:     ["1,2\n", "2,3\r\n"],  # a universal newline
  790:     ["1,2\n", "'2\n',3\n"],  # a quoted newline
  791:     ["1,2\n", "'2\r',3\n"],
  792:     ["1,2\n", "'2\r\n',3\n"],
  793: ])
  794: def test_good_newline_in_iterator(data):
  795:     # The quoted newlines will be untransformed here, but are just whitespace.
  796:     res = np.loadtxt(data, delimiter=",", quotechar="'")
  797:     assert_array_equal(res, [[1., 2.], [2., 3.]])
  798: 
  799: 
  800: @pytest.mark.parametrize("newline", ["\n", "\r", "\r\n"])
  801: def test_universal_newlines_quoted(newline):
  802:     # Check that universal newline support within the tokenizer is not applied
  803:     # to quoted fields.  (note that lines must end in newline or quoted
  804:     # fields will not include a newline at all)
  805:     data = ['1,"2\n"\n', '3,"4\n', '1"\n']
  806:     data = [row.replace("\n", newline) for row in data]
  807:     res = np.loadtxt(data, dtype=object, delimiter=",", quotechar='"')
  808:     assert_array_equal(res, [['1', f'2{newline}'], ['3', f'4{newline}1']])
  809: 
  810: 
  811: def test_null_character():
  812:     # Basic tests to check that the NUL character is not special:
  813:     res = np.loadtxt(["1\0002\0003\n", "4\0005\0006"], delimiter="\000")
  814:     assert_array_equal(res, [[1, 2, 3], [4, 5, 6]])
  815: 
  816:     # Also not as part of a field (avoid unicode/arrays as unicode strips \0)
  817:     res = np.loadtxt(["1\000,2\000,3\n", "4\000,5\000,6"],
  818:                      delimiter=",", dtype=object)
  819:     assert res.tolist() == [["1\000", "2\000", "3"], ["4\000", "5\000", "6"]]
  820: 
  821: 
  822: def test_iterator_fails_getting_next_line():
  823:     class BadSequence:
  824:         def __len__(self):
  825:             return 100
  826: 
  827:         def __getitem__(self, item):
  828:             if item == 50:
  829:                 raise RuntimeError("Bad things happened!")
  830:             return f"{item}, {item + 1}"
  831: 
  832:     with pytest.raises(RuntimeError, match="Bad things happened!"):
  833:         np.loadtxt(BadSequence(), dtype=int, delimiter=",")
  834: 
  835: 
  836: class TestCReaderUnitTests:
  837:     # These are internal tests for path that should not be possible to hit
  838:     # unless things go very very wrong somewhere.
  839:     def test_not_an_filelike(self):
  840:         with pytest.raises(AttributeError, match=".*read"):
  841:             np._core._multiarray_umath._load_from_filelike(
  842:                 object(), dtype=np.dtype("i"), filelike=True)
  843: 
  844:     def test_filelike_read_fails(self):
  845:         # Can only be reached if loadtxt opens the file, so it is hard to do
  846:         # via the public interface (although maybe not impossible considering
  847:         # the current "DataClass" backing).
  848:         class BadFileLike:
  849:             counter = 0
  850: 
  851:             def read(self, size):
  852:                 self.counter += 1
  853:                 if self.counter > 20:
  854:                     raise RuntimeError("Bad bad bad!")
  855:                 return "1,2,3\n"
  856: 
  857:         with pytest.raises(RuntimeError, match="Bad bad bad!"):
  858:             np._core._multiarray_umath._load_from_filelike(
  859:                 BadFileLike(), dtype=np.dtype("i"), filelike=True)
  860: 
  861:     def test_filelike_bad_read(self):
  862:         # Can only be reached if loadtxt opens the file, so it is hard to do
  863:         # via the public interface (although maybe not impossible considering
  864:         # the current "DataClass" backing).
  865: 
  866:         class BadFileLike:
  867:             counter = 0
  868: 
  869:             def read(self, size):
  870:                 return 1234  # not a string!
  871: 
  872:         with pytest.raises(TypeError,
  873:                     match="non-string returned while reading data"):
  874:             np._core._multiarray_umath._load_from_filelike(
  875:                 BadFileLike(), dtype=np.dtype("i"), filelike=True)
  876: 
  877:     def test_not_an_iter(self):
  878:         with pytest.raises(TypeError,
  879:                     match="error reading from object, expected an iterable"):
  880:             np._core._multiarray_umath._load_from_filelike(
  881:                 object(), dtype=np.dtype("i"), filelike=False)
  882: 
  883:     def test_bad_type(self):
  884:         with pytest.raises(TypeError, match="internal error: dtype must"):
  885:             np._core._multiarray_umath._load_from_filelike(
  886:                 object(), dtype="i", filelike=False)
  887: 
  888:     def test_bad_encoding(self):
  889:         with pytest.raises(TypeError, match="encoding must be a unicode"):
  890:             np._core._multiarray_umath._load_from_filelike(
  891:                 object(), dtype=np.dtype("i"), filelike=False, encoding=123)
  892: 
  893:     @pytest.mark.parametrize("newline", ["\r", "\n", "\r\n"])
  894:     def test_manual_universal_newlines(self, newline):
  895:         # This is currently not available to users, because we should always
  896:         # open files with universal newlines enabled `newlines=None`.
  897:         # (And reading from an iterator uses slightly different code paths.)
  898:         # We have no real support for `newline="\r"` or `newline="\n" as the
  899:         # user cannot specify those options.
  900:         data = StringIO('0\n1\n"2\n"\n3\n4 #\n'.replace("\n", newline),
  901:                         newline="")
  902: 
  903:         res = np._core._multiarray_umath._load_from_filelike(
  904:             data, dtype=np.dtype("U10"), filelike=True,
  905:             quote='"', comment="#", skiplines=1)
  906:         assert_array_equal(res[:, 0], ["1", f"2{newline}", "3", "4 "])
  907: 
  908: 
  909: def test_delimiter_comment_collision_raises():
  910:     with pytest.raises(TypeError, match=".*control characters.*incompatible"):
  911:         np.loadtxt(StringIO("1, 2, 3"), delimiter=",", comments=",")
  912: 
  913: 
  914: def test_delimiter_quotechar_collision_raises():
  915:     with pytest.raises(TypeError, match=".*control characters.*incompatible"):
  916:         np.loadtxt(StringIO("1, 2, 3"), delimiter=",", quotechar=",")
  917: 
  918: 
  919: def test_comment_quotechar_collision_raises():
  920:     with pytest.raises(TypeError, match=".*control characters.*incompatible"):
  921:         np.loadtxt(StringIO("1 2 3"), comments="#", quotechar="#")
  922: 
  923: 
  924: def test_delimiter_and_multiple_comments_collision_raises():
  925:     with pytest.raises(
  926:         TypeError, match="Comment characters.*cannot include the delimiter"
  927:     ):
  928:         np.loadtxt(StringIO("1, 2, 3"), delimiter=",", comments=["#", ","])
  929: 
  930: 
  931: @pytest.mark.parametrize(
  932:     "ws",
  933:     (
  934:         " ",  # space
  935:         "\t",  # tab
  936:         "\u2003",  # em
  937:         "\u00A0",  # non-break
  938:         "\u3000",  # ideographic space
  939:     )
  940: )
  941: def test_collision_with_default_delimiter_raises(ws):
  942:     with pytest.raises(TypeError, match=".*control characters.*incompatible"):
  943:         np.loadtxt(StringIO(f"1{ws}2{ws}3\n4{ws}5{ws}6\n"), comments=ws)
  944:     with pytest.raises(TypeError, match=".*control characters.*incompatible"):
  945:         np.loadtxt(StringIO(f"1{ws}2{ws}3\n4{ws}5{ws}6\n"), quotechar=ws)
  946: 
  947: 
  948: @pytest.mark.parametrize("nl", ("\n", "\r"))
  949: def test_control_character_newline_raises(nl):
  950:     txt = StringIO(f"1{nl}2{nl}3{nl}{nl}4{nl}5{nl}6{nl}{nl}")
  951:     msg = "control character.*cannot be a newline"
  952:     with pytest.raises(TypeError, match=msg):
  953:         np.loadtxt(txt, delimiter=nl)
  954:     with pytest.raises(TypeError, match=msg):
  955:         np.loadtxt(txt, comments=nl)
  956:     with pytest.raises(TypeError, match=msg):
  957:         np.loadtxt(txt, quotechar=nl)
  958: 
  959: 
  960: @pytest.mark.parametrize(
  961:     ("generic_data", "long_datum", "unitless_dtype", "expected_dtype"),
  962:     [
  963:         ("2012-03", "2013-01-15", "M8", "M8[D]"),  # Datetimes
  964:         ("spam-a-lot", "tis_but_a_scratch", "U", "U17"),  # str
  965:     ],
  966: )
  967: @pytest.mark.parametrize("nrows", (10, 50000, 60000))  # lt, eq, gt chunksize
  968: def test_parametric_unit_discovery(
  969:     generic_data, long_datum, unitless_dtype, expected_dtype, nrows
  970: ):
  971:     """Check that the correct unit (e.g. month, day, second) is discovered from
  972:     the data when a user specifies a unitless datetime."""
  973:     # Unit should be "D" (days) due to last entry
  974:     data = [generic_data] * nrows + [long_datum]
  975:     expected = np.array(data, dtype=expected_dtype)
  976:     assert len(data) == nrows + 1
  977:     assert len(data) == len(expected)
  978: 
  979:     # file-like path
  980:     txt = StringIO("\n".join(data))
  981:     a = np.loadtxt(txt, dtype=unitless_dtype)
  982:     assert len(a) == len(expected)
  983:     assert a.dtype == expected.dtype
  984:     assert_equal(a, expected)
  985: 
  986:     # file-obj path
  987:     fd, fname = mkstemp()
  988:     os.close(fd)
  989:     with open(fname, "w") as fh:
  990:         fh.write("\n".join(data) + "\n")
  991:     # loading the full file...
  992:     a = np.loadtxt(fname, dtype=unitless_dtype)
  993:     assert len(a) == len(expected)
  994:     assert a.dtype == expected.dtype
  995:     assert_equal(a, expected)
  996:     # loading half of the file...
  997:     a = np.loadtxt(fname, dtype=unitless_dtype, max_rows=int(nrows / 2))
  998:     os.remove(fname)
  999:     assert len(a) == int(nrows / 2)
 1000:     assert_equal(a, expected[:int(nrows / 2)])
 1001: 
 1002: 
 1003: def test_str_dtype_unit_discovery_with_converter():
 1004:     data = ["spam-a-lot"] * 60000 + ["XXXtis_but_a_scratch"]
 1005:     expected = np.array(
 1006:         ["spam-a-lot"] * 60000 + ["tis_but_a_scratch"], dtype="U17"
 1007:     )
 1008:     conv = lambda s: s.removeprefix("XXX")
 1009: 
 1010:     # file-like path
 1011:     txt = StringIO("\n".join(data))
 1012:     a = np.loadtxt(txt, dtype="U", converters=conv)
 1013:     assert a.dtype == expected.dtype
 1014:     assert_equal(a, expected)
 1015: 
 1016:     # file-obj path
 1017:     fd, fname = mkstemp()
 1018:     os.close(fd)
 1019:     with open(fname, "w") as fh:
 1020:         fh.write("\n".join(data))
 1021:     a = np.loadtxt(fname, dtype="U", converters=conv)
 1022:     os.remove(fname)
 1023:     assert a.dtype == expected.dtype
 1024:     assert_equal(a, expected)
 1025: 
 1026: 
 1027: @pytest.mark.skipif(IS_PYPY and sys.implementation.version <= (7, 3, 8),
 1028:                     reason="PyPy bug in error formatting")
 1029: def test_control_character_empty():
 1030:     with pytest.raises(TypeError, match="Text reading control character must"):
 1031:         np.loadtxt(StringIO("1 2 3"), delimiter="")
 1032:     with pytest.raises(TypeError, match="Text reading control character must"):
 1033:         np.loadtxt(StringIO("1 2 3"), quotechar="")
 1034:     with pytest.raises(ValueError, match="comments cannot be an empty string"):
 1035:         np.loadtxt(StringIO("1 2 3"), comments="")
 1036:     with pytest.raises(ValueError, match="comments cannot be an empty string"):
 1037:         np.loadtxt(StringIO("1 2 3"), comments=["#", ""])
 1038: 
 1039: 
 1040: def test_control_characters_as_bytes():
 1041:     """Byte control characters (comments, delimiter) are supported."""
 1042:     a = np.loadtxt(StringIO("#header\n1,2,3"), comments=b"#", delimiter=b",")
 1043:     assert_equal(a, [1, 2, 3])
 1044: 
 1045: 
 1046: @pytest.mark.filterwarnings('ignore::UserWarning')
 1047: def test_field_growing_cases():
 1048:     # Test empty field appending/growing (each field still takes 1 character)
 1049:     # to see if the final field appending does not create issues.
 1050:     res = np.loadtxt([""], delimiter=",", dtype=bytes)
 1051:     assert len(res) == 0
 1052: 
 1053:     for i in range(1, 1024):
 1054:         res = np.loadtxt(["," * i], delimiter=",", dtype=bytes, max_rows=10)
 1055:         assert len(res) == i + 1
 1056: 
 1057: @pytest.mark.parametrize("nmax", (10000, 50000, 55000, 60000))
 1058: def test_maxrows_exceeding_chunksize(nmax):
 1059:     # tries to read all of the file,
 1060:     # or less, equal, greater than _loadtxt_chunksize
 1061:     file_length = 60000
 1062: 
 1063:     # file-like path
 1064:     data = ["a 0.5 1"] * file_length
 1065:     txt = StringIO("\n".join(data))
 1066:     res = np.loadtxt(txt, dtype=str, delimiter=" ", max_rows=nmax)
 1067:     assert len(res) == nmax
 1068: 
 1069:     # file-obj path
 1070:     fd, fname = mkstemp()
 1071:     os.close(fd)
 1072:     with open(fname, "w") as fh:
 1073:         fh.write("\n".join(data))
 1074:     res = np.loadtxt(fname, dtype=str, delimiter=" ", max_rows=nmax)
 1075:     os.remove(fname)
 1076:     assert len(res) == nmax
 1077: 
 1078: @pytest.mark.parametrize("nskip", (0, 10000, 12345, 50000, 67891, 100000))
 1079: def test_skiprow_exceeding_maxrows_exceeding_chunksize(tmpdir, nskip):
 1080:     # tries to read a file in chunks by skipping a variable amount of lines,
 1081:     # less, equal, greater than max_rows
 1082:     file_length = 110000
 1083:     data = "\n".join(f"{i} a 0.5 1" for i in range(1, file_length + 1))
 1084:     expected_length = min(60000, file_length - nskip)
 1085:     expected = np.arange(nskip + 1, nskip + 1 + expected_length).astype(str)
 1086: 
 1087:     # file-like path
 1088:     txt = StringIO(data)
 1089:     res = np.loadtxt(txt, dtype='str', delimiter=" ", skiprows=nskip, max_rows=60000)
 1090:     assert len(res) == expected_length
 1091:     # are the right lines read in res?
 1092:     assert_array_equal(expected, res[:, 0])
 1093: 
 1094:     # file-obj path
 1095:     tmp_file = tmpdir / "test_data.txt"
 1096:     tmp_file.write(data)
 1097:     fname = str(tmp_file)
 1098:     res = np.loadtxt(fname, dtype='str', delimiter=" ", skiprows=nskip, max_rows=60000)
 1099:     assert len(res) == expected_length
 1100:     # are the right lines read in res?
 1101:     assert_array_equal(expected, res[:, 0])
