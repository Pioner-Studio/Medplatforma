    1: import inspect
    2: import warnings
    3: from functools import partial
    4: 
    5: import pytest
    6: 
    7: import numpy as np
    8: from numpy._core.numeric import normalize_axis_tuple
    9: from numpy.exceptions import AxisError, ComplexWarning
   10: from numpy.lib._nanfunctions_impl import _nan_mask, _replace_nan
   11: from numpy.testing import (
   12:     assert_,
   13:     assert_almost_equal,
   14:     assert_array_equal,
   15:     assert_equal,
   16:     assert_raises,
   17:     assert_raises_regex,
   18:     suppress_warnings,
   19: )
   20: 
   21: # Test data
   22: _ndat = np.array([[0.6244, np.nan, 0.2692, 0.0116, np.nan, 0.1170],
   23:                   [0.5351, -0.9403, np.nan, 0.2100, 0.4759, 0.2833],
   24:                   [np.nan, np.nan, np.nan, 0.1042, np.nan, -0.5954],
   25:                   [0.1610, np.nan, np.nan, 0.1859, 0.3146, np.nan]])
   26: 
   27: 
   28: # Rows of _ndat with nans removed
   29: _rdat = [np.array([0.6244, 0.2692, 0.0116, 0.1170]),
   30:          np.array([0.5351, -0.9403, 0.2100, 0.4759, 0.2833]),
   31:          np.array([0.1042, -0.5954]),
   32:          np.array([0.1610, 0.1859, 0.3146])]
   33: 
   34: # Rows of _ndat with nans converted to ones
   35: _ndat_ones = np.array([[0.6244, 1.0, 0.2692, 0.0116, 1.0, 0.1170],
   36:                        [0.5351, -0.9403, 1.0, 0.2100, 0.4759, 0.2833],
   37:                        [1.0, 1.0, 1.0, 0.1042, 1.0, -0.5954],
   38:                        [0.1610, 1.0, 1.0, 0.1859, 0.3146, 1.0]])
   39: 
   40: # Rows of _ndat with nans converted to zeros
   41: _ndat_zeros = np.array([[0.6244, 0.0, 0.2692, 0.0116, 0.0, 0.1170],
   42:                         [0.5351, -0.9403, 0.0, 0.2100, 0.4759, 0.2833],
   43:                         [0.0, 0.0, 0.0, 0.1042, 0.0, -0.5954],
   44:                         [0.1610, 0.0, 0.0, 0.1859, 0.3146, 0.0]])
   45: 
   46: 
   47: class TestSignatureMatch:
   48:     NANFUNCS = {
   49:         np.nanmin: np.amin,
   50:         np.nanmax: np.amax,
   51:         np.nanargmin: np.argmin,
   52:         np.nanargmax: np.argmax,
   53:         np.nansum: np.sum,
   54:         np.nanprod: np.prod,
   55:         np.nancumsum: np.cumsum,
   56:         np.nancumprod: np.cumprod,
   57:         np.nanmean: np.mean,
   58:         np.nanmedian: np.median,
   59:         np.nanpercentile: np.percentile,
   60:         np.nanquantile: np.quantile,
   61:         np.nanvar: np.var,
   62:         np.nanstd: np.std,
   63:     }
   64:     IDS = [k.__name__ for k in NANFUNCS]
   65: 
   66:     @staticmethod
   67:     def get_signature(func, default="..."):
   68:         """Construct a signature and replace all default parameter-values."""
   69:         prm_list = []
   70:         signature = inspect.signature(func)
   71:         for prm in signature.parameters.values():
   72:             if prm.default is inspect.Parameter.empty:
   73:                 prm_list.append(prm)
   74:             else:
   75:                 prm_list.append(prm.replace(default=default))
   76:         return inspect.Signature(prm_list)
   77: 
   78:     @pytest.mark.parametrize("nan_func,func", NANFUNCS.items(), ids=IDS)
   79:     def test_signature_match(self, nan_func, func):
   80:         # Ignore the default parameter-values as they can sometimes differ
   81:         # between the two functions (*e.g.* one has `False` while the other
   82:         # has `np._NoValue`)
   83:         signature = self.get_signature(func)
   84:         nan_signature = self.get_signature(nan_func)
   85:         np.testing.assert_equal(signature, nan_signature)
   86: 
   87:     def test_exhaustiveness(self):
   88:         """Validate that all nan functions are actually tested."""
   89:         np.testing.assert_equal(
   90:             set(self.IDS), set(np.lib._nanfunctions_impl.__all__)
   91:         )
   92: 
   93: 
   94: class TestNanFunctions_MinMax:
   95: 
   96:     nanfuncs = [np.nanmin, np.nanmax]
   97:     stdfuncs = [np.min, np.max]
   98: 
   99:     def test_mutation(self):
  100:         # Check that passed array is not modified.
  101:         ndat = _ndat.copy()
  102:         for f in self.nanfuncs:
  103:             f(ndat)
  104:             assert_equal(ndat, _ndat)
  105: 
  106:     def test_keepdims(self):
  107:         mat = np.eye(3)
  108:         for nf, rf in zip(self.nanfuncs, self.stdfuncs):
  109:             for axis in [None, 0, 1]:
  110:                 tgt = rf(mat, axis=axis, keepdims=True)
  111:                 res = nf(mat, axis=axis, keepdims=True)
  112:                 assert_(res.ndim == tgt.ndim)
  113: 
  114:     def test_out(self):
  115:         mat = np.eye(3)
  116:         for nf, rf in zip(self.nanfuncs, self.stdfuncs):
  117:             resout = np.zeros(3)
  118:             tgt = rf(mat, axis=1)
  119:             res = nf(mat, axis=1, out=resout)
  120:             assert_almost_equal(res, resout)
  121:             assert_almost_equal(res, tgt)
  122: 
  123:     def test_dtype_from_input(self):
  124:         codes = 'efdgFDG'
  125:         for nf, rf in zip(self.nanfuncs, self.stdfuncs):
  126:             for c in codes:
  127:                 mat = np.eye(3, dtype=c)
  128:                 tgt = rf(mat, axis=1).dtype.type
  129:                 res = nf(mat, axis=1).dtype.type
  130:                 assert_(res is tgt)
  131:                 # scalar case
  132:                 tgt = rf(mat, axis=None).dtype.type
  133:                 res = nf(mat, axis=None).dtype.type
  134:                 assert_(res is tgt)
  135: 
  136:     def test_result_values(self):
  137:         for nf, rf in zip(self.nanfuncs, self.stdfuncs):
  138:             tgt = [rf(d) for d in _rdat]
  139:             res = nf(_ndat, axis=1)
  140:             assert_almost_equal(res, tgt)
  141: 
  142:     @pytest.mark.parametrize("axis", [None, 0, 1])
  143:     @pytest.mark.parametrize("dtype", np.typecodes["AllFloat"])
  144:     @pytest.mark.parametrize("array", [
  145:         np.array(np.nan),
  146:         np.full((3, 3), np.nan),
  147:     ], ids=["0d", "2d"])
  148:     def test_allnans(self, axis, dtype, array):
  149:         if axis is not None and array.ndim == 0:
  150:             pytest.skip("`axis != None` not supported for 0d arrays")
  151: 
  152:         array = array.astype(dtype)
  153:         match = "All-NaN slice encountered"
  154:         for func in self.nanfuncs:
  155:             with pytest.warns(RuntimeWarning, match=match):
  156:                 out = func(array, axis=axis)
  157:             assert np.isnan(out).all()
  158:             assert out.dtype == array.dtype
  159: 
  160:     def test_masked(self):
  161:         mat = np.ma.fix_invalid(_ndat)
  162:         msk = mat._mask.copy()
  163:         for f in [np.nanmin]:
  164:             res = f(mat, axis=1)
  165:             tgt = f(_ndat, axis=1)
  166:             assert_equal(res, tgt)
  167:             assert_equal(mat._mask, msk)
  168:             assert_(not np.isinf(mat).any())
  169: 
  170:     def test_scalar(self):
  171:         for f in self.nanfuncs:
  172:             assert_(f(0.) == 0.)
  173: 
  174:     def test_subclass(self):
  175:         class MyNDArray(np.ndarray):
  176:             pass
  177: 
  178:         # Check that it works and that type and
  179:         # shape are preserved
  180:         mine = np.eye(3).view(MyNDArray)
  181:         for f in self.nanfuncs:
  182:             res = f(mine, axis=0)
  183:             assert_(isinstance(res, MyNDArray))
  184:             assert_(res.shape == (3,))
  185:             res = f(mine, axis=1)
  186:             assert_(isinstance(res, MyNDArray))
  187:             assert_(res.shape == (3,))
  188:             res = f(mine)
  189:             assert_(res.shape == ())
  190: 
  191:         # check that rows of nan are dealt with for subclasses (#4628)
  192:         mine[1] = np.nan
  193:         for f in self.nanfuncs:
  194:             with warnings.catch_warnings(record=True) as w:
  195:                 warnings.simplefilter('always')
  196:                 res = f(mine, axis=0)
  197:                 assert_(isinstance(res, MyNDArray))
  198:                 assert_(not np.any(np.isnan(res)))
  199:                 assert_(len(w) == 0)
  200: 
  201:             with warnings.catch_warnings(record=True) as w:
  202:                 warnings.simplefilter('always')
  203:                 res = f(mine, axis=1)
  204:                 assert_(isinstance(res, MyNDArray))
  205:                 assert_(np.isnan(res[1]) and not np.isnan(res[0])
  206:                         and not np.isnan(res[2]))
  207:                 assert_(len(w) == 1, 'no warning raised')
  208:                 assert_(issubclass(w[0].category, RuntimeWarning))
  209: 
  210:             with warnings.catch_warnings(record=True) as w:
  211:                 warnings.simplefilter('always')
  212:                 res = f(mine)
  213:                 assert_(res.shape == ())
  214:                 assert_(res != np.nan)
  215:                 assert_(len(w) == 0)
  216: 
  217:     def test_object_array(self):
  218:         arr = np.array([[1.0, 2.0], [np.nan, 4.0], [np.nan, np.nan]], dtype=object)
  219:         assert_equal(np.nanmin(arr), 1.0)
  220:         assert_equal(np.nanmin(arr, axis=0), [1.0, 2.0])
  221: 
  222:         with warnings.catch_warnings(record=True) as w:
  223:             warnings.simplefilter('always')
  224:             # assert_equal does not work on object arrays of nan
  225:             assert_equal(list(np.nanmin(arr, axis=1)), [1.0, 4.0, np.nan])
  226:             assert_(len(w) == 1, 'no warning raised')
  227:             assert_(issubclass(w[0].category, RuntimeWarning))
  228: 
  229:     @pytest.mark.parametrize("dtype", np.typecodes["AllFloat"])
  230:     def test_initial(self, dtype):
  231:         class MyNDArray(np.ndarray):
  232:             pass
  233: 
  234:         ar = np.arange(9).astype(dtype)
  235:         ar[:5] = np.nan
  236: 
  237:         for f in self.nanfuncs:
  238:             initial = 100 if f is np.nanmax else 0
  239: 
  240:             ret1 = f(ar, initial=initial)
  241:             assert ret1.dtype == dtype
  242:             assert ret1 == initial
  243: 
  244:             ret2 = f(ar.view(MyNDArray), initial=initial)
  245:             assert ret2.dtype == dtype
  246:             assert ret2 == initial
  247: 
  248:     @pytest.mark.parametrize("dtype", np.typecodes["AllFloat"])
  249:     def test_where(self, dtype):
  250:         class MyNDArray(np.ndarray):
  251:             pass
  252: 
  253:         ar = np.arange(9).reshape(3, 3).astype(dtype)
  254:         ar[0, :] = np.nan
  255:         where = np.ones_like(ar, dtype=np.bool)
  256:         where[:, 0] = False
  257: 
  258:         for f in self.nanfuncs:
  259:             reference = 4 if f is np.nanmin else 8
  260: 
  261:             ret1 = f(ar, where=where, initial=5)
  262:             assert ret1.dtype == dtype
  263:             assert ret1 == reference
  264: 
  265:             ret2 = f(ar.view(MyNDArray), where=where, initial=5)
  266:             assert ret2.dtype == dtype
  267:             assert ret2 == reference
  268: 
  269: 
  270: class TestNanFunctions_ArgminArgmax:
  271: 
  272:     nanfuncs = [np.nanargmin, np.nanargmax]
  273: 
  274:     def test_mutation(self):
  275:         # Check that passed array is not modified.
  276:         ndat = _ndat.copy()
  277:         for f in self.nanfuncs:
  278:             f(ndat)
  279:             assert_equal(ndat, _ndat)
  280: 
  281:     def test_result_values(self):
  282:         for f, fcmp in zip(self.nanfuncs, [np.greater, np.less]):
  283:             for row in _ndat:
  284:                 with suppress_warnings() as sup:
  285:                     sup.filter(RuntimeWarning, "invalid value encountered in")
  286:                     ind = f(row)
  287:                     val = row[ind]
  288:                     # comparing with NaN is tricky as the result
  289:                     # is always false except for NaN != NaN
  290:                     assert_(not np.isnan(val))
  291:                     assert_(not fcmp(val, row).any())
  292:                     assert_(not np.equal(val, row[:ind]).any())
  293: 
  294:     @pytest.mark.parametrize("axis", [None, 0, 1])
  295:     @pytest.mark.parametrize("dtype", np.typecodes["AllFloat"])
  296:     @pytest.mark.parametrize("array", [
  297:         np.array(np.nan),
  298:         np.full((3, 3), np.nan),
  299:     ], ids=["0d", "2d"])
  300:     def test_allnans(self, axis, dtype, array):
  301:         if axis is not None and array.ndim == 0:
  302:             pytest.skip("`axis != None` not supported for 0d arrays")
  303: 
  304:         array = array.astype(dtype)
  305:         for func in self.nanfuncs:
  306:             with pytest.raises(ValueError, match="All-NaN slice encountered"):
  307:                 func(array, axis=axis)
  308: 
  309:     def test_empty(self):
  310:         mat = np.zeros((0, 3))
  311:         for f in self.nanfuncs:
  312:             for axis in [0, None]:
  313:                 assert_raises_regex(
  314:                         ValueError,
  315:                         "attempt to get argm.. of an empty sequence",
  316:                         f, mat, axis=axis)
  317:             for axis in [1]:
  318:                 res = f(mat, axis=axis)
  319:                 assert_equal(res, np.zeros(0))
  320: 
  321:     def test_scalar(self):
  322:         for f in self.nanfuncs:
  323:             assert_(f(0.) == 0.)
  324: 
  325:     def test_subclass(self):
  326:         class MyNDArray(np.ndarray):
  327:             pass
  328: 
  329:         # Check that it works and that type and
  330:         # shape are preserved
  331:         mine = np.eye(3).view(MyNDArray)
  332:         for f in self.nanfuncs:
  333:             res = f(mine, axis=0)
  334:             assert_(isinstance(res, MyNDArray))
  335:             assert_(res.shape == (3,))
  336:             res = f(mine, axis=1)
  337:             assert_(isinstance(res, MyNDArray))
  338:             assert_(res.shape == (3,))
  339:             res = f(mine)
  340:             assert_(res.shape == ())
  341: 
  342:     @pytest.mark.parametrize("dtype", np.typecodes["AllFloat"])
  343:     def test_keepdims(self, dtype):
  344:         ar = np.arange(9).astype(dtype)
  345:         ar[:5] = np.nan
  346: 
  347:         for f in self.nanfuncs:
  348:             reference = 5 if f is np.nanargmin else 8
  349:             ret = f(ar, keepdims=True)
  350:             assert ret.ndim == ar.ndim
  351:             assert ret == reference
  352: 
  353:     @pytest.mark.parametrize("dtype", np.typecodes["AllFloat"])
  354:     def test_out(self, dtype):
  355:         ar = np.arange(9).astype(dtype)
  356:         ar[:5] = np.nan
  357: 
  358:         for f in self.nanfuncs:
  359:             out = np.zeros((), dtype=np.intp)
  360:             reference = 5 if f is np.nanargmin else 8
  361:             ret = f(ar, out=out)
  362:             assert ret is out
  363:             assert ret == reference
  364: 
  365: 
  366: _TEST_ARRAYS = {
  367:     "0d": np.array(5),
  368:     "1d": np.array([127, 39, 93, 87, 46])
  369: }
  370: for _v in _TEST_ARRAYS.values():
  371:     _v.setflags(write=False)
  372: 
  373: 
  374: @pytest.mark.parametrize(
  375:     "dtype",
  376:     np.typecodes["AllInteger"] + np.typecodes["AllFloat"] + "O",
  377: )
  378: @pytest.mark.parametrize("mat", _TEST_ARRAYS.values(), ids=_TEST_ARRAYS.keys())
  379: class TestNanFunctions_NumberTypes:
  380:     nanfuncs = {
  381:         np.nanmin: np.min,
  382:         np.nanmax: np.max,
  383:         np.nanargmin: np.argmin,
  384:         np.nanargmax: np.argmax,
  385:         np.nansum: np.sum,
  386:         np.nanprod: np.prod,
  387:         np.nancumsum: np.cumsum,
  388:         np.nancumprod: np.cumprod,
  389:         np.nanmean: np.mean,
  390:         np.nanmedian: np.median,
  391:         np.nanvar: np.var,
  392:         np.nanstd: np.std,
  393:     }
  394:     nanfunc_ids = [i.__name__ for i in nanfuncs]
  395: 
  396:     @pytest.mark.parametrize("nanfunc,func", nanfuncs.items(), ids=nanfunc_ids)
  397:     @np.errstate(over="ignore")
  398:     def test_nanfunc(self, mat, dtype, nanfunc, func):
  399:         mat = mat.astype(dtype)
  400:         tgt = func(mat)
  401:         out = nanfunc(mat)
  402: 
  403:         assert_almost_equal(out, tgt)
  404:         if dtype == "O":
  405:             assert type(out) is type(tgt)
  406:         else:
  407:             assert out.dtype == tgt.dtype
  408: 
  409:     @pytest.mark.parametrize(
  410:         "nanfunc,func",
  411:         [(np.nanquantile, np.quantile), (np.nanpercentile, np.percentile)],
  412:         ids=["nanquantile", "nanpercentile"],
  413:     )
  414:     def test_nanfunc_q(self, mat, dtype, nanfunc, func):
  415:         mat = mat.astype(dtype)
  416:         if mat.dtype.kind == "c":
  417:             assert_raises(TypeError, func, mat, q=1)
  418:             assert_raises(TypeError, nanfunc, mat, q=1)
  419: 
  420:         else:
  421:             tgt = func(mat, q=1)
  422:             out = nanfunc(mat, q=1)
  423: 
  424:             assert_almost_equal(out, tgt)
  425: 
  426:             if dtype == "O":
  427:                 assert type(out) is type(tgt)
  428:             else:
  429:                 assert out.dtype == tgt.dtype
  430: 
  431:     @pytest.mark.parametrize(
  432:         "nanfunc,func",
  433:         [(np.nanvar, np.var), (np.nanstd, np.std)],
  434:         ids=["nanvar", "nanstd"],
  435:     )
  436:     def test_nanfunc_ddof(self, mat, dtype, nanfunc, func):
  437:         mat = mat.astype(dtype)
  438:         tgt = func(mat, ddof=0.5)
  439:         out = nanfunc(mat, ddof=0.5)
  440: 
  441:         assert_almost_equal(out, tgt)
  442:         if dtype == "O":
  443:             assert type(out) is type(tgt)
  444:         else:
  445:             assert out.dtype == tgt.dtype
  446: 
  447:     @pytest.mark.parametrize(
  448:         "nanfunc", [np.nanvar, np.nanstd]
  449:     )
  450:     def test_nanfunc_correction(self, mat, dtype, nanfunc):
  451:         mat = mat.astype(dtype)
  452:         assert_almost_equal(
  453:             nanfunc(mat, correction=0.5), nanfunc(mat, ddof=0.5)
  454:         )
  455: 
  456:         err_msg = "ddof and correction can't be provided simultaneously."
  457:         with assert_raises_regex(ValueError, err_msg):
  458:             nanfunc(mat, ddof=0.5, correction=0.5)
  459: 
  460:         with assert_raises_regex(ValueError, err_msg):
  461:             nanfunc(mat, ddof=1, correction=0)
  462: 
  463: 
  464: class SharedNanFunctionsTestsMixin:
  465:     def test_mutation(self):
  466:         # Check that passed array is not modified.
  467:         ndat = _ndat.copy()
  468:         for f in self.nanfuncs:
  469:             f(ndat)
  470:             assert_equal(ndat, _ndat)
  471: 
  472:     def test_keepdims(self):
  473:         mat = np.eye(3)
  474:         for nf, rf in zip(self.nanfuncs, self.stdfuncs):
  475:             for axis in [None, 0, 1]:
  476:                 tgt = rf(mat, axis=axis, keepdims=True)
  477:                 res = nf(mat, axis=axis, keepdims=True)
  478:                 assert_(res.ndim == tgt.ndim)
  479: 
  480:     def test_out(self):
  481:         mat = np.eye(3)
  482:         for nf, rf in zip(self.nanfuncs, self.stdfuncs):
  483:             resout = np.zeros(3)
  484:             tgt = rf(mat, axis=1)
  485:             res = nf(mat, axis=1, out=resout)
  486:             assert_almost_equal(res, resout)
  487:             assert_almost_equal(res, tgt)
  488: 
  489:     def test_dtype_from_dtype(self):
  490:         mat = np.eye(3)
  491:         codes = 'efdgFDG'
  492:         for nf, rf in zip(self.nanfuncs, self.stdfuncs):
  493:             for c in codes:
  494:                 with suppress_warnings() as sup:
  495:                     if nf in {np.nanstd, np.nanvar} and c in 'FDG':
  496:                         # Giving the warning is a small bug, see gh-8000
  497:                         sup.filter(ComplexWarning)
  498:                     tgt = rf(mat, dtype=np.dtype(c), axis=1).dtype.type
  499:                     res = nf(mat, dtype=np.dtype(c), axis=1).dtype.type
  500:                     assert_(res is tgt)
  501:                     # scalar case
  502:                     tgt = rf(mat, dtype=np.dtype(c), axis=None).dtype.type
  503:                     res = nf(mat, dtype=np.dtype(c), axis=None).dtype.type
  504:                     assert_(res is tgt)
  505: 
  506:     def test_dtype_from_char(self):
  507:         mat = np.eye(3)
  508:         codes = 'efdgFDG'
  509:         for nf, rf in zip(self.nanfuncs, self.stdfuncs):
  510:             for c in codes:
  511:                 with suppress_warnings() as sup:
  512:                     if nf in {np.nanstd, np.nanvar} and c in 'FDG':
  513:                         # Giving the warning is a small bug, see gh-8000
  514:                         sup.filter(ComplexWarning)
  515:                     tgt = rf(mat, dtype=c, axis=1).dtype.type
  516:                     res = nf(mat, dtype=c, axis=1).dtype.type
  517:                     assert_(res is tgt)
  518:                     # scalar case
  519:                     tgt = rf(mat, dtype=c, axis=None).dtype.type
  520:                     res = nf(mat, dtype=c, axis=None).dtype.type
  521:                     assert_(res is tgt)
  522: 
  523:     def test_dtype_from_input(self):
  524:         codes = 'efdgFDG'
  525:         for nf, rf in zip(self.nanfuncs, self.stdfuncs):
  526:             for c in codes:
  527:                 mat = np.eye(3, dtype=c)
  528:                 tgt = rf(mat, axis=1).dtype.type
  529:                 res = nf(mat, axis=1).dtype.type
  530:                 assert_(res is tgt, f"res {res}, tgt {tgt}")
  531:                 # scalar case
  532:                 tgt = rf(mat, axis=None).dtype.type
  533:                 res = nf(mat, axis=None).dtype.type
  534:                 assert_(res is tgt)
  535: 
  536:     def test_result_values(self):
  537:         for nf, rf in zip(self.nanfuncs, self.stdfuncs):
  538:             tgt = [rf(d) for d in _rdat]
  539:             res = nf(_ndat, axis=1)
  540:             assert_almost_equal(res, tgt)
  541: 
  542:     def test_scalar(self):
  543:         for f in self.nanfuncs:
  544:             assert_(f(0.) == 0.)
  545: 
  546:     def test_subclass(self):
  547:         class MyNDArray(np.ndarray):
  548:             pass
  549: 
  550:         # Check that it works and that type and
  551:         # shape are preserved
  552:         array = np.eye(3)
  553:         mine = array.view(MyNDArray)
  554:         for f in self.nanfuncs:
  555:             expected_shape = f(array, axis=0).shape
  556:             res = f(mine, axis=0)
  557:             assert_(isinstance(res, MyNDArray))
  558:             assert_(res.shape == expected_shape)
  559:             expected_shape = f(array, axis=1).shape
  560:             res = f(mine, axis=1)
  561:             assert_(isinstance(res, MyNDArray))
  562:             assert_(res.shape == expected_shape)
  563:             expected_shape = f(array).shape
  564:             res = f(mine)
  565:             assert_(isinstance(res, MyNDArray))
  566:             assert_(res.shape == expected_shape)
  567: 
  568: 
  569: class TestNanFunctions_SumProd(SharedNanFunctionsTestsMixin):
  570: 
  571:     nanfuncs = [np.nansum, np.nanprod]
  572:     stdfuncs = [np.sum, np.prod]
  573: 
  574:     @pytest.mark.parametrize("axis", [None, 0, 1])
  575:     @pytest.mark.parametrize("dtype", np.typecodes["AllFloat"])
  576:     @pytest.mark.parametrize("array", [
  577:         np.array(np.nan),
  578:         np.full((3, 3), np.nan),
  579:     ], ids=["0d", "2d"])
  580:     def test_allnans(self, axis, dtype, array):
  581:         if axis is not None and array.ndim == 0:
  582:             pytest.skip("`axis != None` not supported for 0d arrays")
  583: 
  584:         array = array.astype(dtype)
  585:         for func, identity in zip(self.nanfuncs, [0, 1]):
  586:             out = func(array, axis=axis)
  587:             assert np.all(out == identity)
  588:             assert out.dtype == array.dtype
  589: 
  590:     def test_empty(self):
  591:         for f, tgt_value in zip([np.nansum, np.nanprod], [0, 1]):
  592:             mat = np.zeros((0, 3))
  593:             tgt = [tgt_value] * 3
  594:             res = f(mat, axis=0)
  595:             assert_equal(res, tgt)
  596:             tgt = []
  597:             res = f(mat, axis=1)
  598:             assert_equal(res, tgt)
  599:             tgt = tgt_value
  600:             res = f(mat, axis=None)
  601:             assert_equal(res, tgt)
  602: 
  603:     @pytest.mark.parametrize("dtype", np.typecodes["AllFloat"])
  604:     def test_initial(self, dtype):
  605:         ar = np.arange(9).astype(dtype)
  606:         ar[:5] = np.nan
  607: 
  608:         for f in self.nanfuncs:
  609:             reference = 28 if f is np.nansum else 3360
  610:             ret = f(ar, initial=2)
  611:             assert ret.dtype == dtype
  612:             assert ret == reference
  613: 
  614:     @pytest.mark.parametrize("dtype", np.typecodes["AllFloat"])
  615:     def test_where(self, dtype):
  616:         ar = np.arange(9).reshape(3, 3).astype(dtype)
  617:         ar[0, :] = np.nan
  618:         where = np.ones_like(ar, dtype=np.bool)
  619:         where[:, 0] = False
  620: 
  621:         for f in self.nanfuncs:
  622:             reference = 26 if f is np.nansum else 2240
  623:             ret = f(ar, where=where, initial=2)
  624:             assert ret.dtype == dtype
  625:             assert ret == reference
  626: 
  627: 
  628: class TestNanFunctions_CumSumProd(SharedNanFunctionsTestsMixin):
  629: 
  630:     nanfuncs = [np.nancumsum, np.nancumprod]
  631:     stdfuncs = [np.cumsum, np.cumprod]
  632: 
  633:     @pytest.mark.parametrize("axis", [None, 0, 1])
  634:     @pytest.mark.parametrize("dtype", np.typecodes["AllFloat"])
  635:     @pytest.mark.parametrize("array", [
  636:         np.array(np.nan),
  637:         np.full((3, 3), np.nan)
  638:     ], ids=["0d", "2d"])
  639:     def test_allnans(self, axis, dtype, array):
  640:         if axis is not None and array.ndim == 0:
  641:             pytest.skip("`axis != None` not supported for 0d arrays")
  642: 
  643:         array = array.astype(dtype)
  644:         for func, identity in zip(self.nanfuncs, [0, 1]):
  645:             out = func(array)
  646:             assert np.all(out == identity)
  647:             assert out.dtype == array.dtype
  648: 
  649:     def test_empty(self):
  650:         for f, tgt_value in zip(self.nanfuncs, [0, 1]):
  651:             mat = np.zeros((0, 3))
  652:             tgt = tgt_value * np.ones((0, 3))
  653:             res = f(mat, axis=0)
  654:             assert_equal(res, tgt)
  655:             tgt = mat
  656:             res = f(mat, axis=1)
  657:             assert_equal(res, tgt)
  658:             tgt = np.zeros(0)
  659:             res = f(mat, axis=None)
  660:             assert_equal(res, tgt)
  661: 
  662:     def test_keepdims(self):
  663:         for f, g in zip(self.nanfuncs, self.stdfuncs):
  664:             mat = np.eye(3)
  665:             for axis in [None, 0, 1]:
  666:                 tgt = f(mat, axis=axis, out=None)
  667:                 res = g(mat, axis=axis, out=None)
  668:                 assert_(res.ndim == tgt.ndim)
  669: 
  670:         for f in self.nanfuncs:
  671:             d = np.ones((3, 5, 7, 11))
  672:             # Randomly set some elements to NaN:
  673:             rs = np.random.RandomState(0)
  674:             d[rs.rand(*d.shape) < 0.5] = np.nan
  675:             res = f(d, axis=None)
  676:             assert_equal(res.shape, (1155,))
  677:             for axis in np.arange(4):
  678:                 res = f(d, axis=axis)
  679:                 assert_equal(res.shape, (3, 5, 7, 11))
  680: 
  681:     def test_result_values(self):
  682:         for axis in (-2, -1, 0, 1, None):
  683:             tgt = np.cumprod(_ndat_ones, axis=axis)
  684:             res = np.nancumprod(_ndat, axis=axis)
  685:             assert_almost_equal(res, tgt)
  686:             tgt = np.cumsum(_ndat_zeros, axis=axis)
  687:             res = np.nancumsum(_ndat, axis=axis)
  688:             assert_almost_equal(res, tgt)
  689: 
  690:     def test_out(self):
  691:         mat = np.eye(3)
  692:         for nf, rf in zip(self.nanfuncs, self.stdfuncs):
  693:             resout = np.eye(3)
  694:             for axis in (-2, -1, 0, 1):
  695:                 tgt = rf(mat, axis=axis)
  696:                 res = nf(mat, axis=axis, out=resout)
  697:                 assert_almost_equal(res, resout)
  698:                 assert_almost_equal(res, tgt)
  699: 
  700: 
  701: class TestNanFunctions_MeanVarStd(SharedNanFunctionsTestsMixin):
  702: 
  703:     nanfuncs = [np.nanmean, np.nanvar, np.nanstd]
  704:     stdfuncs = [np.mean, np.var, np.std]
  705: 
  706:     def test_dtype_error(self):
  707:         for f in self.nanfuncs:
  708:             for dtype in [np.bool, np.int_, np.object_]:
  709:                 assert_raises(TypeError, f, _ndat, axis=1, dtype=dtype)
  710: 
  711:     def test_out_dtype_error(self):
  712:         for f in self.nanfuncs:
  713:             for dtype in [np.bool, np.int_, np.object_]:
  714:                 out = np.empty(_ndat.shape[0], dtype=dtype)
  715:                 assert_raises(TypeError, f, _ndat, axis=1, out=out)
  716: 
  717:     def test_ddof(self):
  718:         nanfuncs = [np.nanvar, np.nanstd]
  719:         stdfuncs = [np.var, np.std]
  720:         for nf, rf in zip(nanfuncs, stdfuncs):
  721:             for ddof in [0, 1]:
  722:                 tgt = [rf(d, ddof=ddof) for d in _rdat]
  723:                 res = nf(_ndat, axis=1, ddof=ddof)
  724:                 assert_almost_equal(res, tgt)
  725: 
  726:     def test_ddof_too_big(self):
  727:         nanfuncs = [np.nanvar, np.nanstd]
  728:         stdfuncs = [np.var, np.std]
  729:         dsize = [len(d) for d in _rdat]
  730:         for nf, rf in zip(nanfuncs, stdfuncs):
  731:             for ddof in range(5):
  732:                 with suppress_warnings() as sup:
  733:                     sup.record(RuntimeWarning)
  734:                     sup.filter(ComplexWarning)
  735:                     tgt = [ddof >= d for d in dsize]
  736:                     res = nf(_ndat, axis=1, ddof=ddof)
  737:                     assert_equal(np.isnan(res), tgt)
  738:                     if any(tgt):
  739:                         assert_(len(sup.log) == 1)
  740:                     else:
  741:                         assert_(len(sup.log) == 0)
  742: 
  743:     @pytest.mark.parametrize("axis", [None, 0, 1])
  744:     @pytest.mark.parametrize("dtype", np.typecodes["AllFloat"])
  745:     @pytest.mark.parametrize("array", [
  746:         np.array(np.nan),
  747:         np.full((3, 3), np.nan),
  748:     ], ids=["0d", "2d"])
  749:     def test_allnans(self, axis, dtype, array):
  750:         if axis is not None and array.ndim == 0:
  751:             pytest.skip("`axis != None` not supported for 0d arrays")
  752: 
  753:         array = array.astype(dtype)
  754:         match = "(Degrees of freedom <= 0 for slice.)|(Mean of empty slice)"
  755:         for func in self.nanfuncs:
  756:             with pytest.warns(RuntimeWarning, match=match):
  757:                 out = func(array, axis=axis)
  758:             assert np.isnan(out).all()
  759: 
  760:             # `nanvar` and `nanstd` convert complex inputs to their
  761:             # corresponding floating dtype
  762:             if func is np.nanmean:
  763:                 assert out.dtype == array.dtype
  764:             else:
  765:                 assert out.dtype == np.abs(array).dtype
  766: 
  767:     def test_empty(self):
  768:         mat = np.zeros((0, 3))
  769:         for f in self.nanfuncs:
  770:             for axis in [0, None]:
  771:                 with warnings.catch_warnings(record=True) as w:
  772:                     warnings.simplefilter('always')
  773:                     assert_(np.isnan(f(mat, axis=axis)).all())
  774:                     assert_(len(w) == 1)
  775:                     assert_(issubclass(w[0].category, RuntimeWarning))
  776:             for axis in [1]:
  777:                 with warnings.catch_warnings(record=True) as w:
  778:                     warnings.simplefilter('always')
  779:                     assert_equal(f(mat, axis=axis), np.zeros([]))
  780:                     assert_(len(w) == 0)
  781: 
  782:     @pytest.mark.parametrize("dtype", np.typecodes["AllFloat"])
  783:     def test_where(self, dtype):
  784:         ar = np.arange(9).reshape(3, 3).astype(dtype)
  785:         ar[0, :] = np.nan
  786:         where = np.ones_like(ar, dtype=np.bool)
  787:         where[:, 0] = False
  788: 
  789:         for f, f_std in zip(self.nanfuncs, self.stdfuncs):
  790:             reference = f_std(ar[where][2:])
  791:             dtype_reference = dtype if f is np.nanmean else ar.real.dtype
  792: 
  793:             ret = f(ar, where=where)
  794:             assert ret.dtype == dtype_reference
  795:             np.testing.assert_allclose(ret, reference)
  796: 
  797:     def test_nanstd_with_mean_keyword(self):
  798:         # Setting the seed to make the test reproducible
  799:         rng = np.random.RandomState(1234)
  800:         A = rng.randn(10, 20, 5) + 0.5
  801:         A[:, 5, :] = np.nan
  802: 
  803:         mean_out = np.zeros((10, 1, 5))
  804:         std_out = np.zeros((10, 1, 5))
  805: 
  806:         mean = np.nanmean(A,
  807:                        out=mean_out,
  808:                        axis=1,
  809:                        keepdims=True)
  810: 
  811:         # The returned  object should be the object specified during calling
  812:         assert mean_out is mean
  813: 
  814:         std = np.nanstd(A,
  815:                      out=std_out,
  816:                      axis=1,
  817:                      keepdims=True,
  818:                      mean=mean)
  819: 
  820:         # The returned  object should be the object specified during calling
  821:         assert std_out is std
  822: 
  823:         # Shape of returned mean and std should be same
  824:         assert std.shape == mean.shape
  825:         assert std.shape == (10, 1, 5)
  826: 
  827:         # Output should be the same as from the individual algorithms
  828:         std_old = np.nanstd(A, axis=1, keepdims=True)
  829: 
  830:         assert std_old.shape == mean.shape
  831:         assert_almost_equal(std, std_old)
  832: 
  833: 
  834: _TIME_UNITS = (
  835:     "Y", "M", "W", "D", "h", "m", "s", "ms", "us", "ns", "ps", "fs", "as"
  836: )
  837: 
  838: # All `inexact` + `timdelta64` type codes
  839: _TYPE_CODES = list(np.typecodes["AllFloat"])
  840: _TYPE_CODES += [f"m8[{unit}]" for unit in _TIME_UNITS]
  841: 
  842: 
  843: class TestNanFunctions_Median:
  844: 
  845:     def test_mutation(self):
  846:         # Check that passed array is not modified.
  847:         ndat = _ndat.copy()
  848:         np.nanmedian(ndat)
  849:         assert_equal(ndat, _ndat)
  850: 
  851:     def test_keepdims(self):
  852:         mat = np.eye(3)
  853:         for axis in [None, 0, 1]:
  854:             tgt = np.median(mat, axis=axis, out=None, overwrite_input=False)
  855:             res = np.nanmedian(mat, axis=axis, out=None, overwrite_input=False)
  856:             assert_(res.ndim == tgt.ndim)
  857: 
  858:         d = np.ones((3, 5, 7, 11))
  859:         # Randomly set some elements to NaN:
  860:         w = np.random.random((4, 200)) * np.array(d.shape)[:, None]
  861:         w = w.astype(np.intp)
  862:         d[tuple(w)] = np.nan
  863:         with suppress_warnings() as sup:
  864:             sup.filter(RuntimeWarning)
  865:             res = np.nanmedian(d, axis=None, keepdims=True)
  866:             assert_equal(res.shape, (1, 1, 1, 1))
  867:             res = np.nanmedian(d, axis=(0, 1), keepdims=True)
  868:             assert_equal(res.shape, (1, 1, 7, 11))
  869:             res = np.nanmedian(d, axis=(0, 3), keepdims=True)
  870:             assert_equal(res.shape, (1, 5, 7, 1))
  871:             res = np.nanmedian(d, axis=(1,), keepdims=True)
  872:             assert_equal(res.shape, (3, 1, 7, 11))
  873:             res = np.nanmedian(d, axis=(0, 1, 2, 3), keepdims=True)
  874:             assert_equal(res.shape, (1, 1, 1, 1))
  875:             res = np.nanmedian(d, axis=(0, 1, 3), keepdims=True)
  876:             assert_equal(res.shape, (1, 1, 7, 1))
  877: 
  878:     @pytest.mark.parametrize(
  879:         argnames='axis',
  880:         argvalues=[
  881:             None,
  882:             1,
  883:             (1, ),
  884:             (0, 1),
  885:             (-3, -1),
  886:         ]
  887:     )
  888:     @pytest.mark.filterwarnings("ignore:All-NaN slice:RuntimeWarning")
  889:     def test_keepdims_out(self, axis):
  890:         d = np.ones((3, 5, 7, 11))
  891:         # Randomly set some elements to NaN:
  892:         w = np.random.random((4, 200)) * np.array(d.shape)[:, None]
  893:         w = w.astype(np.intp)
  894:         d[tuple(w)] = np.nan
  895:         if axis is None:
  896:             shape_out = (1,) * d.ndim
  897:         else:
  898:             axis_norm = normalize_axis_tuple(axis, d.ndim)
  899:             shape_out = tuple(
  900:                 1 if i in axis_norm else d.shape[i] for i in range(d.ndim))
  901:         out = np.empty(shape_out)
  902:         result = np.nanmedian(d, axis=axis, keepdims=True, out=out)
  903:         assert result is out
  904:         assert_equal(result.shape, shape_out)
  905: 
  906:     def test_out(self):
  907:         mat = np.random.rand(3, 3)
  908:         nan_mat = np.insert(mat, [0, 2], np.nan, axis=1)
  909:         resout = np.zeros(3)
  910:         tgt = np.median(mat, axis=1)
  911:         res = np.nanmedian(nan_mat, axis=1, out=resout)
  912:         assert_almost_equal(res, resout)
  913:         assert_almost_equal(res, tgt)
  914:         # 0-d output:
  915:         resout = np.zeros(())
  916:         tgt = np.median(mat, axis=None)
  917:         res = np.nanmedian(nan_mat, axis=None, out=resout)
  918:         assert_almost_equal(res, resout)
  919:         assert_almost_equal(res, tgt)
  920:         res = np.nanmedian(nan_mat, axis=(0, 1), out=resout)
  921:         assert_almost_equal(res, resout)
  922:         assert_almost_equal(res, tgt)
  923: 
  924:     def test_small_large(self):
  925:         # test the small and large code paths, current cutoff 400 elements
  926:         for s in [5, 20, 51, 200, 1000]:
  927:             d = np.random.randn(4, s)
  928:             # Randomly set some elements to NaN:
  929:             w = np.random.randint(0, d.size, size=d.size // 5)
  930:             d.ravel()[w] = np.nan
  931:             d[:, 0] = 1.  # ensure at least one good value
  932:             # use normal median without nans to compare
  933:             tgt = []
  934:             for x in d:
  935:                 nonan = np.compress(~np.isnan(x), x)
  936:                 tgt.append(np.median(nonan, overwrite_input=True))
  937: 
  938:             assert_array_equal(np.nanmedian(d, axis=-1), tgt)
  939: 
  940:     def test_result_values(self):
  941:         tgt = [np.median(d) for d in _rdat]
  942:         res = np.nanmedian(_ndat, axis=1)
  943:         assert_almost_equal(res, tgt)
  944: 
  945:     @pytest.mark.parametrize("axis", [None, 0, 1])
  946:     @pytest.mark.parametrize("dtype", _TYPE_CODES)
  947:     def test_allnans(self, dtype, axis):
  948:         mat = np.full((3, 3), np.nan).astype(dtype)
  949:         with suppress_warnings() as sup:
  950:             sup.record(RuntimeWarning)
  951: 
  952:             output = np.nanmedian(mat, axis=axis)
  953:             assert output.dtype == mat.dtype
  954:             assert np.isnan(output).all()
  955: 
  956:             if axis is None:
  957:                 assert_(len(sup.log) == 1)
  958:             else:
  959:                 assert_(len(sup.log) == 3)
  960: 
  961:             # Check scalar
  962:             scalar = np.array(np.nan).astype(dtype)[()]
  963:             output_scalar = np.nanmedian(scalar)
  964:             assert output_scalar.dtype == scalar.dtype
  965:             assert np.isnan(output_scalar)
  966: 
  967:             if axis is None:
  968:                 assert_(len(sup.log) == 2)
  969:             else:
  970:                 assert_(len(sup.log) == 4)
  971: 
  972:     def test_empty(self):
  973:         mat = np.zeros((0, 3))
  974:         for axis in [0, None]:
  975:             with warnings.catch_warnings(record=True) as w:
  976:                 warnings.simplefilter('always')
  977:                 assert_(np.isnan(np.nanmedian(mat, axis=axis)).all())
  978:                 assert_(len(w) == 1)
  979:                 assert_(issubclass(w[0].category, RuntimeWarning))
  980:         for axis in [1]:
  981:             with warnings.catch_warnings(record=True) as w:
  982:                 warnings.simplefilter('always')
  983:                 assert_equal(np.nanmedian(mat, axis=axis), np.zeros([]))
  984:                 assert_(len(w) == 0)
  985: 
  986:     def test_scalar(self):
  987:         assert_(np.nanmedian(0.) == 0.)
  988: 
  989:     def test_extended_axis_invalid(self):
  990:         d = np.ones((3, 5, 7, 11))
  991:         assert_raises(AxisError, np.nanmedian, d, axis=-5)
  992:         assert_raises(AxisError, np.nanmedian, d, axis=(0, -5))
  993:         assert_raises(AxisError, np.nanmedian, d, axis=4)
  994:         assert_raises(AxisError, np.nanmedian, d, axis=(0, 4))
  995:         assert_raises(ValueError, np.nanmedian, d, axis=(1, 1))
  996: 
  997:     def test_float_special(self):
  998:         with suppress_warnings() as sup:
  999:             sup.filter(RuntimeWarning)
 1000:             for inf in [np.inf, -np.inf]:
 1001:                 a = np.array([[inf,  np.nan], [np.nan, np.nan]])
 1002:                 assert_equal(np.nanmedian(a, axis=0), [inf,  np.nan])
 1003:                 assert_equal(np.nanmedian(a, axis=1), [inf,  np.nan])
 1004:                 assert_equal(np.nanmedian(a), inf)
 1005: 
 1006:                 # minimum fill value check
 1007:                 a = np.array([[np.nan, np.nan, inf],
 1008:                              [np.nan, np.nan, inf]])
 1009:                 assert_equal(np.nanmedian(a), inf)
 1010:                 assert_equal(np.nanmedian(a, axis=0), [np.nan, np.nan, inf])
 1011:                 assert_equal(np.nanmedian(a, axis=1), inf)
 1012: 
 1013:                 # no mask path
 1014:                 a = np.array([[inf, inf], [inf, inf]])
 1015:                 assert_equal(np.nanmedian(a, axis=1), inf)
 1016: 
 1017:                 a = np.array([[inf, 7, -inf, -9],
 1018:                               [-10, np.nan, np.nan, 5],
 1019:                               [4, np.nan, np.nan, inf]],
 1020:                               dtype=np.float32)
 1021:                 if inf > 0:
 1022:                     assert_equal(np.nanmedian(a, axis=0), [4., 7., -inf, 5.])
 1023:                     assert_equal(np.nanmedian(a), 4.5)
 1024:                 else:
 1025:                     assert_equal(np.nanmedian(a, axis=0), [-10., 7., -inf, -9.])
 1026:                     assert_equal(np.nanmedian(a), -2.5)
 1027:                 assert_equal(np.nanmedian(a, axis=-1), [-1., -2.5, inf])
 1028: 
 1029:                 for i in range(10):
 1030:                     for j in range(1, 10):
 1031:                         a = np.array([([np.nan] * i) + ([inf] * j)] * 2)
 1032:                         assert_equal(np.nanmedian(a), inf)
 1033:                         assert_equal(np.nanmedian(a, axis=1), inf)
 1034:                         assert_equal(np.nanmedian(a, axis=0),
 1035:                                      ([np.nan] * i) + [inf] * j)
 1036: 
 1037:                         a = np.array([([np.nan] * i) + ([-inf] * j)] * 2)
 1038:                         assert_equal(np.nanmedian(a), -inf)
 1039:                         assert_equal(np.nanmedian(a, axis=1), -inf)
 1040:                         assert_equal(np.nanmedian(a, axis=0),
 1041:                                      ([np.nan] * i) + [-inf] * j)
 1042: 
 1043: 
 1044: class TestNanFunctions_Percentile:
 1045: 
 1046:     def test_mutation(self):
 1047:         # Check that passed array is not modified.
 1048:         ndat = _ndat.copy()
 1049:         np.nanpercentile(ndat, 30)
 1050:         assert_equal(ndat, _ndat)
 1051: 
 1052:     def test_keepdims(self):
 1053:         mat = np.eye(3)
 1054:         for axis in [None, 0, 1]:
 1055:             tgt = np.percentile(mat, 70, axis=axis, out=None,
 1056:                                 overwrite_input=False)
 1057:             res = np.nanpercentile(mat, 70, axis=axis, out=None,
 1058:                                    overwrite_input=False)
 1059:             assert_(res.ndim == tgt.ndim)
 1060: 
 1061:         d = np.ones((3, 5, 7, 11))
 1062:         # Randomly set some elements to NaN:
 1063:         w = np.random.random((4, 200)) * np.array(d.shape)[:, None]
 1064:         w = w.astype(np.intp)
 1065:         d[tuple(w)] = np.nan
 1066:         with suppress_warnings() as sup:
 1067:             sup.filter(RuntimeWarning)
 1068:             res = np.nanpercentile(d, 90, axis=None, keepdims=True)
 1069:             assert_equal(res.shape, (1, 1, 1, 1))
 1070:             res = np.nanpercentile(d, 90, axis=(0, 1), keepdims=True)
 1071:             assert_equal(res.shape, (1, 1, 7, 11))
 1072:             res = np.nanpercentile(d, 90, axis=(0, 3), keepdims=True)
 1073:             assert_equal(res.shape, (1, 5, 7, 1))
 1074:             res = np.nanpercentile(d, 90, axis=(1,), keepdims=True)
 1075:             assert_equal(res.shape, (3, 1, 7, 11))
 1076:             res = np.nanpercentile(d, 90, axis=(0, 1, 2, 3), keepdims=True)
 1077:             assert_equal(res.shape, (1, 1, 1, 1))
 1078:             res = np.nanpercentile(d, 90, axis=(0, 1, 3), keepdims=True)
 1079:             assert_equal(res.shape, (1, 1, 7, 1))
 1080: 
 1081:     @pytest.mark.parametrize('q', [7, [1, 7]])
 1082:     @pytest.mark.parametrize(
 1083:         argnames='axis',
 1084:         argvalues=[
 1085:             None,
 1086:             1,
 1087:             (1,),
 1088:             (0, 1),
 1089:             (-3, -1),
 1090:         ]
 1091:     )
 1092:     @pytest.mark.filterwarnings("ignore:All-NaN slice:RuntimeWarning")
 1093:     def test_keepdims_out(self, q, axis):
 1094:         d = np.ones((3, 5, 7, 11))
 1095:         # Randomly set some elements to NaN:
 1096:         w = np.random.random((4, 200)) * np.array(d.shape)[:, None]
 1097:         w = w.astype(np.intp)
 1098:         d[tuple(w)] = np.nan
 1099:         if axis is None:
 1100:             shape_out = (1,) * d.ndim
 1101:         else:
 1102:             axis_norm = normalize_axis_tuple(axis, d.ndim)
 1103:             shape_out = tuple(
 1104:                 1 if i in axis_norm else d.shape[i] for i in range(d.ndim))
 1105:         shape_out = np.shape(q) + shape_out
 1106: 
 1107:         out = np.empty(shape_out)
 1108:         result = np.nanpercentile(d, q, axis=axis, keepdims=True, out=out)
 1109:         assert result is out
 1110:         assert_equal(result.shape, shape_out)
 1111: 
 1112:     @pytest.mark.parametrize("weighted", [False, True])
 1113:     def test_out(self, weighted):
 1114:         mat = np.random.rand(3, 3)
 1115:         nan_mat = np.insert(mat, [0, 2], np.nan, axis=1)
 1116:         resout = np.zeros(3)
 1117:         if weighted:
 1118:             w_args = {"weights": np.ones_like(mat), "method": "inverted_cdf"}
 1119:             nan_w_args = {
 1120:                 "weights": np.ones_like(nan_mat), "method": "inverted_cdf"
 1121:             }
 1122:         else:
 1123:             w_args = {}
 1124:             nan_w_args = {}
 1125:         tgt = np.percentile(mat, 42, axis=1, **w_args)
 1126:         res = np.nanpercentile(nan_mat, 42, axis=1, out=resout, **nan_w_args)
 1127:         assert_almost_equal(res, resout)
 1128:         assert_almost_equal(res, tgt)
 1129:         # 0-d output:
 1130:         resout = np.zeros(())
 1131:         tgt = np.percentile(mat, 42, axis=None, **w_args)
 1132:         res = np.nanpercentile(
 1133:             nan_mat, 42, axis=None, out=resout, **nan_w_args
 1134:         )
 1135:         assert_almost_equal(res, resout)
 1136:         assert_almost_equal(res, tgt)
 1137:         res = np.nanpercentile(
 1138:             nan_mat, 42, axis=(0, 1), out=resout, **nan_w_args
 1139:         )
 1140:         assert_almost_equal(res, resout)
 1141:         assert_almost_equal(res, tgt)
 1142: 
 1143:     def test_complex(self):
 1144:         arr_c = np.array([0.5 + 3.0j, 2.1 + 0.5j, 1.6 + 2.3j], dtype='G')
 1145:         assert_raises(TypeError, np.nanpercentile, arr_c, 0.5)
 1146:         arr_c = np.array([0.5 + 3.0j, 2.1 + 0.5j, 1.6 + 2.3j], dtype='D')
 1147:         assert_raises(TypeError, np.nanpercentile, arr_c, 0.5)
 1148:         arr_c = np.array([0.5 + 3.0j, 2.1 + 0.5j, 1.6 + 2.3j], dtype='F')
 1149:         assert_raises(TypeError, np.nanpercentile, arr_c, 0.5)
 1150: 
 1151:     @pytest.mark.parametrize("weighted", [False, True])
 1152:     @pytest.mark.parametrize("use_out", [False, True])
 1153:     def test_result_values(self, weighted, use_out):
 1154:         if weighted:
 1155:             percentile = partial(np.percentile, method="inverted_cdf")
 1156:             nanpercentile = partial(np.nanpercentile, method="inverted_cdf")
 1157: 
 1158:             def gen_weights(d):
 1159:                 return np.ones_like(d)
 1160: 
 1161:         else:
 1162:             percentile = np.percentile
 1163:             nanpercentile = np.nanpercentile
 1164: 
 1165:             def gen_weights(d):
 1166:                 return None
 1167: 
 1168:         tgt = [percentile(d, 28, weights=gen_weights(d)) for d in _rdat]
 1169:         out = np.empty_like(tgt) if use_out else None
 1170:         res = nanpercentile(_ndat, 28, axis=1,
 1171:                             weights=gen_weights(_ndat), out=out)
 1172:         assert_almost_equal(res, tgt)
 1173:         # Transpose the array to fit the output convention of numpy.percentile
 1174:         tgt = np.transpose([percentile(d, (28, 98), weights=gen_weights(d))
 1175:                             for d in _rdat])
 1176:         out = np.empty_like(tgt) if use_out else None
 1177:         res = nanpercentile(_ndat, (28, 98), axis=1,
 1178:                             weights=gen_weights(_ndat), out=out)
 1179:         assert_almost_equal(res, tgt)
 1180: 
 1181:     @pytest.mark.parametrize("axis", [None, 0, 1])
 1182:     @pytest.mark.parametrize("dtype", np.typecodes["Float"])
 1183:     @pytest.mark.parametrize("array", [
 1184:         np.array(np.nan),
 1185:         np.full((3, 3), np.nan),
 1186:     ], ids=["0d", "2d"])
 1187:     def test_allnans(self, axis, dtype, array):
 1188:         if axis is not None and array.ndim == 0:
 1189:             pytest.skip("`axis != None` not supported for 0d arrays")
 1190: 
 1191:         array = array.astype(dtype)
 1192:         with pytest.warns(RuntimeWarning, match="All-NaN slice encountered"):
 1193:             out = np.nanpercentile(array, 60, axis=axis)
 1194:         assert np.isnan(out).all()
 1195:         assert out.dtype == array.dtype
 1196: 
 1197:     def test_empty(self):
 1198:         mat = np.zeros((0, 3))
 1199:         for axis in [0, None]:
 1200:             with warnings.catch_warnings(record=True) as w:
 1201:                 warnings.simplefilter('always')
 1202:                 assert_(np.isnan(np.nanpercentile(mat, 40, axis=axis)).all())
 1203:                 assert_(len(w) == 1)
 1204:                 assert_(issubclass(w[0].category, RuntimeWarning))
 1205:         for axis in [1]:
 1206:             with warnings.catch_warnings(record=True) as w:
 1207:                 warnings.simplefilter('always')
 1208:                 assert_equal(np.nanpercentile(mat, 40, axis=axis), np.zeros([]))
 1209:                 assert_(len(w) == 0)
 1210: 
 1211:     def test_scalar(self):
 1212:         assert_equal(np.nanpercentile(0., 100), 0.)
 1213:         a = np.arange(6)
 1214:         r = np.nanpercentile(a, 50, axis=0)
 1215:         assert_equal(r, 2.5)
 1216:         assert_(np.isscalar(r))
 1217: 
 1218:     def test_extended_axis_invalid(self):
 1219:         d = np.ones((3, 5, 7, 11))
 1220:         assert_raises(AxisError, np.nanpercentile, d, q=5, axis=-5)
 1221:         assert_raises(AxisError, np.nanpercentile, d, q=5, axis=(0, -5))
 1222:         assert_raises(AxisError, np.nanpercentile, d, q=5, axis=4)
 1223:         assert_raises(AxisError, np.nanpercentile, d, q=5, axis=(0, 4))
 1224:         assert_raises(ValueError, np.nanpercentile, d, q=5, axis=(1, 1))
 1225: 
 1226:     def test_multiple_percentiles(self):
 1227:         perc = [50, 100]
 1228:         mat = np.ones((4, 3))
 1229:         nan_mat = np.nan * mat
 1230:         # For checking consistency in higher dimensional case
 1231:         large_mat = np.ones((3, 4, 5))
 1232:         large_mat[:, 0:2:4, :] = 0
 1233:         large_mat[:, :, 3:] *= 2
 1234:         for axis in [None, 0, 1]:
 1235:             for keepdim in [False, True]:
 1236:                 with suppress_warnings() as sup:
 1237:                     sup.filter(RuntimeWarning, "All-NaN slice encountered")
 1238:                     val = np.percentile(mat, perc, axis=axis, keepdims=keepdim)
 1239:                     nan_val = np.nanpercentile(nan_mat, perc, axis=axis,
 1240:                                                keepdims=keepdim)
 1241:                     assert_equal(nan_val.shape, val.shape)
 1242: 
 1243:                     val = np.percentile(large_mat, perc, axis=axis,
 1244:                                         keepdims=keepdim)
 1245:                     nan_val = np.nanpercentile(large_mat, perc, axis=axis,
 1246:                                                keepdims=keepdim)
 1247:                     assert_equal(nan_val, val)
 1248: 
 1249:         megamat = np.ones((3, 4, 5, 6))
 1250:         assert_equal(
 1251:             np.nanpercentile(megamat, perc, axis=(1, 2)).shape, (2, 3, 6)
 1252:         )
 1253: 
 1254:     @pytest.mark.parametrize("nan_weight", [0, 1, 2, 3, 1e200])
 1255:     def test_nan_value_with_weight(self, nan_weight):
 1256:         x = [1, np.nan, 2, 3]
 1257:         result = np.float64(2.0)
 1258:         q_unweighted = np.nanpercentile(x, 50, method="inverted_cdf")
 1259:         assert_equal(q_unweighted, result)
 1260: 
 1261:         # The weight value at the nan position should not matter.
 1262:         w = [1.0, nan_weight, 1.0, 1.0]
 1263:         q_weighted = np.nanpercentile(x, 50, weights=w, method="inverted_cdf")
 1264:         assert_equal(q_weighted, result)
 1265: 
 1266:     @pytest.mark.parametrize("axis", [0, 1, 2])
 1267:     def test_nan_value_with_weight_ndim(self, axis):
 1268:         # Create a multi-dimensional array to test
 1269:         np.random.seed(1)
 1270:         x_no_nan = np.random.random(size=(100, 99, 2))
 1271:         # Set some places to NaN (not particularly smart) so there is always
 1272:         # some non-Nan.
 1273:         x = x_no_nan.copy()
 1274:         x[np.arange(99), np.arange(99), 0] = np.nan
 1275: 
 1276:         p = np.array([[20., 50., 30], [70, 33, 80]])
 1277: 
 1278:         # We just use ones as weights, but replace it with 0 or 1e200 at the
 1279:         # NaN positions below.
 1280:         weights = np.ones_like(x)
 1281: 
 1282:         # For comparison use weighted normal percentile with nan weights at
 1283:         # 0 (and no NaNs); not sure this is strictly identical but should be
 1284:         # sufficiently so (if a percentile lies exactly on a 0 value).
 1285:         weights[np.isnan(x)] = 0
 1286:         p_expected = np.percentile(
 1287:             x_no_nan, p, axis=axis, weights=weights, method="inverted_cdf")
 1288: 
 1289:         p_unweighted = np.nanpercentile(
 1290:             x, p, axis=axis, method="inverted_cdf")
 1291:         # The normal and unweighted versions should be identical:
 1292:         assert_equal(p_unweighted, p_expected)
 1293: 
 1294:         weights[np.isnan(x)] = 1e200  # huge value, shouldn't matter
 1295:         p_weighted = np.nanpercentile(
 1296:             x, p, axis=axis, weights=weights, method="inverted_cdf")
 1297:         assert_equal(p_weighted, p_expected)
 1298:         # Also check with out passed:
 1299:         out = np.empty_like(p_weighted)
 1300:         res = np.nanpercentile(
 1301:             x, p, axis=axis, weights=weights, out=out, method="inverted_cdf")
 1302: 
 1303:         assert res is out
 1304:         assert_equal(out, p_expected)
 1305: 
 1306: 
 1307: class TestNanFunctions_Quantile:
 1308:     # most of this is already tested by TestPercentile
 1309: 
 1310:     @pytest.mark.parametrize("weighted", [False, True])
 1311:     def test_regression(self, weighted):
 1312:         ar = np.arange(24).reshape(2, 3, 4).astype(float)
 1313:         ar[0][1] = np.nan
 1314:         if weighted:
 1315:             w_args = {"weights": np.ones_like(ar), "method": "inverted_cdf"}
 1316:         else:
 1317:             w_args = {}
 1318: 
 1319:         assert_equal(np.nanquantile(ar, q=0.5, **w_args),
 1320:                      np.nanpercentile(ar, q=50, **w_args))
 1321:         assert_equal(np.nanquantile(ar, q=0.5, axis=0, **w_args),
 1322:                      np.nanpercentile(ar, q=50, axis=0, **w_args))
 1323:         assert_equal(np.nanquantile(ar, q=0.5, axis=1, **w_args),
 1324:                      np.nanpercentile(ar, q=50, axis=1, **w_args))
 1325:         assert_equal(np.nanquantile(ar, q=[0.5], axis=1, **w_args),
 1326:                      np.nanpercentile(ar, q=[50], axis=1, **w_args))
 1327:         assert_equal(np.nanquantile(ar, q=[0.25, 0.5, 0.75], axis=1, **w_args),
 1328:                      np.nanpercentile(ar, q=[25, 50, 75], axis=1, **w_args))
 1329: 
 1330:     def test_basic(self):
 1331:         x = np.arange(8) * 0.5
 1332:         assert_equal(np.nanquantile(x, 0), 0.)
 1333:         assert_equal(np.nanquantile(x, 1), 3.5)
 1334:         assert_equal(np.nanquantile(x, 0.5), 1.75)
 1335: 
 1336:     def test_complex(self):
 1337:         arr_c = np.array([0.5 + 3.0j, 2.1 + 0.5j, 1.6 + 2.3j], dtype='G')
 1338:         assert_raises(TypeError, np.nanquantile, arr_c, 0.5)
 1339:         arr_c = np.array([0.5 + 3.0j, 2.1 + 0.5j, 1.6 + 2.3j], dtype='D')
 1340:         assert_raises(TypeError, np.nanquantile, arr_c, 0.5)
 1341:         arr_c = np.array([0.5 + 3.0j, 2.1 + 0.5j, 1.6 + 2.3j], dtype='F')
 1342:         assert_raises(TypeError, np.nanquantile, arr_c, 0.5)
 1343: 
 1344:     def test_no_p_overwrite(self):
 1345:         # this is worth retesting, because quantile does not make a copy
 1346:         p0 = np.array([0, 0.75, 0.25, 0.5, 1.0])
 1347:         p = p0.copy()
 1348:         np.nanquantile(np.arange(100.), p, method="midpoint")
 1349:         assert_array_equal(p, p0)
 1350: 
 1351:         p0 = p0.tolist()
 1352:         p = p.tolist()
 1353:         np.nanquantile(np.arange(100.), p, method="midpoint")
 1354:         assert_array_equal(p, p0)
 1355: 
 1356:     @pytest.mark.parametrize("axis", [None, 0, 1])
 1357:     @pytest.mark.parametrize("dtype", np.typecodes["Float"])
 1358:     @pytest.mark.parametrize("array", [
 1359:         np.array(np.nan),
 1360:         np.full((3, 3), np.nan),
 1361:     ], ids=["0d", "2d"])
 1362:     def test_allnans(self, axis, dtype, array):
 1363:         if axis is not None and array.ndim == 0:
 1364:             pytest.skip("`axis != None` not supported for 0d arrays")
 1365: 
 1366:         array = array.astype(dtype)
 1367:         with pytest.warns(RuntimeWarning, match="All-NaN slice encountered"):
 1368:             out = np.nanquantile(array, 1, axis=axis)
 1369:         assert np.isnan(out).all()
 1370:         assert out.dtype == array.dtype
 1371: 
 1372: @pytest.mark.parametrize("arr, expected", [
 1373:     # array of floats with some nans
 1374:     (np.array([np.nan, 5.0, np.nan, np.inf]),
 1375:      np.array([False, True, False, True])),
 1376:     # int64 array that can't possibly have nans
 1377:     (np.array([1, 5, 7, 9], dtype=np.int64),
 1378:      True),
 1379:     # bool array that can't possibly have nans
 1380:     (np.array([False, True, False, True]),
 1381:      True),
 1382:     # 2-D complex array with nans
 1383:     (np.array([[np.nan, 5.0],
 1384:                [np.nan, np.inf]], dtype=np.complex64),
 1385:      np.array([[False, True],
 1386:                [False, True]])),
 1387:     ])
 1388: def test__nan_mask(arr, expected):
 1389:     for out in [None, np.empty(arr.shape, dtype=np.bool)]:
 1390:         actual = _nan_mask(arr, out=out)
 1391:         assert_equal(actual, expected)
 1392:         # the above won't distinguish between True proper
 1393:         # and an array of True values; we want True proper
 1394:         # for types that can't possibly contain NaN
 1395:         if type(expected) is not np.ndarray:
 1396:             assert actual is True
 1397: 
 1398: 
 1399: def test__replace_nan():
 1400:     """ Test that _replace_nan returns the original array if there are no
 1401:     NaNs, not a copy.
 1402:     """
 1403:     for dtype in [np.bool, np.int32, np.int64]:
 1404:         arr = np.array([0, 1], dtype=dtype)
 1405:         result, mask = _replace_nan(arr, 0)
 1406:         assert mask is None
 1407:         # do not make a copy if there are no nans
 1408:         assert result is arr
 1409: 
 1410:     for dtype in [np.float32, np.float64]:
 1411:         arr = np.array([0, 1], dtype=dtype)
 1412:         result, mask = _replace_nan(arr, 2)
 1413:         assert (mask == False).all()
 1414:         # mask is not None, so we make a copy
 1415:         assert result is not arr
 1416:         assert_equal(result, arr)
 1417: 
 1418:         arr_nan = np.array([0, 1, np.nan], dtype=dtype)
 1419:         result_nan, mask_nan = _replace_nan(arr_nan, 2)
 1420:         assert_equal(mask_nan, np.array([False, False, True]))
 1421:         assert result_nan is not arr_nan
 1422:         assert_equal(result_nan, np.array([0, 1, 2]))
 1423:         assert np.isnan(arr_nan[-1])
 1424: 
 1425: 
 1426: def test_memmap_takes_fast_route(tmpdir):
 1427:     # We want memory mapped arrays to take the fast route through nanmax,
 1428:     # which avoids creating a mask by using fmax.reduce (see gh-28721). So we
 1429:     # check that on bad input, the error is from fmax (rather than maximum).
 1430:     a = np.arange(10., dtype=float)
 1431:     with open(tmpdir.join("data.bin"), "w+b") as fh:
 1432:         fh.write(a.tobytes())
 1433:         mm = np.memmap(fh, dtype=a.dtype, shape=a.shape)
 1434:         with pytest.raises(ValueError, match="reduction operation fmax"):
 1435:             np.nanmax(mm, out=np.zeros(2))
 1436:         # For completeness, same for nanmin.
 1437:         with pytest.raises(ValueError, match="reduction operation fmin"):
 1438:             np.nanmin(mm, out=np.zeros(2))
