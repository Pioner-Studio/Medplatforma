    1: import contextlib
    2: import itertools
    3: import operator
    4: import platform
    5: import sys
    6: import warnings
    7: 
    8: import pytest
    9: from hypothesis import given, settings
   10: from hypothesis.extra import numpy as hynp
   11: from hypothesis.strategies import sampled_from
   12: from numpy._core._rational_tests import rational
   13: 
   14: import numpy as np
   15: from numpy._utils import _pep440
   16: from numpy.exceptions import ComplexWarning
   17: from numpy.testing import (
   18:     IS_PYPY,
   19:     _gen_alignment_data,
   20:     assert_,
   21:     assert_almost_equal,
   22:     assert_array_equal,
   23:     assert_equal,
   24:     assert_raises,
   25:     check_support_sve,
   26:     suppress_warnings,
   27: )
   28: 
   29: types = [np.bool, np.byte, np.ubyte, np.short, np.ushort, np.intc, np.uintc,
   30:          np.int_, np.uint, np.longlong, np.ulonglong,
   31:          np.single, np.double, np.longdouble, np.csingle,
   32:          np.cdouble, np.clongdouble]
   33: 
   34: floating_types = np.floating.__subclasses__()
   35: complex_floating_types = np.complexfloating.__subclasses__()
   36: 
   37: objecty_things = [object(), None, np.array(None, dtype=object)]
   38: 
   39: binary_operators_for_scalars = [
   40:     operator.lt, operator.le, operator.eq, operator.ne, operator.ge,
   41:     operator.gt, operator.add, operator.floordiv, operator.mod,
   42:     operator.mul, operator.pow, operator.sub, operator.truediv
   43: ]
   44: binary_operators_for_scalar_ints = binary_operators_for_scalars + [
   45:     operator.xor, operator.or_, operator.and_
   46: ]
   47: 
   48: 
   49: # This compares scalarmath against ufuncs.
   50: 
   51: class TestTypes:
   52:     def test_types(self):
   53:         for atype in types:
   54:             a = atype(1)
   55:             assert_(a == 1, f"error with {atype!r}: got {a!r}")
   56: 
   57:     def test_type_add(self):
   58:         # list of types
   59:         for k, atype in enumerate(types):
   60:             a_scalar = atype(3)
   61:             a_array = np.array([3], dtype=atype)
   62:             for l, btype in enumerate(types):
   63:                 b_scalar = btype(1)
   64:                 b_array = np.array([1], dtype=btype)
   65:                 c_scalar = a_scalar + b_scalar
   66:                 c_array = a_array + b_array
   67:                 # It was comparing the type numbers, but the new ufunc
   68:                 # function-finding mechanism finds the lowest function
   69:                 # to which both inputs can be cast - which produces 'l'
   70:                 # when you do 'q' + 'b'.  The old function finding mechanism
   71:                 # skipped ahead based on the first argument, but that
   72:                 # does not produce properly symmetric results...
   73:                 assert_equal(c_scalar.dtype, c_array.dtype,
   74:                            "error with types (%d/'%c' + %d/'%c')" %
   75:                             (k, np.dtype(atype).char, l, np.dtype(btype).char))
   76: 
   77:     def test_type_create(self):
   78:         for atype in types:
   79:             a = np.array([1, 2, 3], atype)
   80:             b = atype([1, 2, 3])
   81:             assert_equal(a, b)
   82: 
   83:     def test_leak(self):
   84:         # test leak of scalar objects
   85:         # a leak would show up in valgrind as still-reachable of ~2.6MB
   86:         for i in range(200000):
   87:             np.add(1, 1)
   88: 
   89: 
   90: def check_ufunc_scalar_equivalence(op, arr1, arr2):
   91:     scalar1 = arr1[()]
   92:     scalar2 = arr2[()]
   93:     assert isinstance(scalar1, np.generic)
   94:     assert isinstance(scalar2, np.generic)
   95: 
   96:     if arr1.dtype.kind == "c" or arr2.dtype.kind == "c":
   97:         comp_ops = {operator.ge, operator.gt, operator.le, operator.lt}
   98:         if op in comp_ops and (np.isnan(scalar1) or np.isnan(scalar2)):
   99:             pytest.xfail("complex comp ufuncs use sort-order, scalars do not.")
  100:     if op == operator.pow and arr2.item() in [-1, 0, 0.5, 1, 2]:
  101:         # array**scalar special case can have different result dtype
  102:         # (Other powers may have issues also, but are not hit here.)
  103:         # TODO: It would be nice to resolve this issue.
  104:         pytest.skip("array**2 can have incorrect/weird result dtype")
  105: 
  106:     # ignore fpe's since they may just mismatch for integers anyway.
  107:     with warnings.catch_warnings(), np.errstate(all="ignore"):
  108:         # Comparisons DeprecationWarnings replacing errors (2022-03):
  109:         warnings.simplefilter("error", DeprecationWarning)
  110:         try:
  111:             res = op(arr1, arr2)
  112:         except Exception as e:
  113:             with pytest.raises(type(e)):
  114:                 op(scalar1, scalar2)
  115:         else:
  116:             scalar_res = op(scalar1, scalar2)
  117:             assert_array_equal(scalar_res, res, strict=True)
  118: 
  119: 
  120: @pytest.mark.slow
  121: @settings(max_examples=10000, deadline=2000)
  122: @given(sampled_from(binary_operators_for_scalars),
  123:        hynp.arrays(dtype=hynp.scalar_dtypes(), shape=()),
  124:        hynp.arrays(dtype=hynp.scalar_dtypes(), shape=()))
  125: def test_array_scalar_ufunc_equivalence(op, arr1, arr2):
  126:     """
  127:     This is a thorough test attempting to cover important promotion paths
  128:     and ensuring that arrays and scalars stay as aligned as possible.
  129:     However, if it creates troubles, it should maybe just be removed.
  130:     """
  131:     check_ufunc_scalar_equivalence(op, arr1, arr2)
  132: 
  133: 
  134: @pytest.mark.slow
  135: @given(sampled_from(binary_operators_for_scalars),
  136:        hynp.scalar_dtypes(), hynp.scalar_dtypes())
  137: def test_array_scalar_ufunc_dtypes(op, dt1, dt2):
  138:     # Same as above, but don't worry about sampling weird values so that we
  139:     # do not have to sample as much
  140:     arr1 = np.array(2, dtype=dt1)
  141:     arr2 = np.array(3, dtype=dt2)  # some power do weird things.
  142: 
  143:     check_ufunc_scalar_equivalence(op, arr1, arr2)
  144: 
  145: 
  146: @pytest.mark.parametrize("fscalar", [np.float16, np.float32])
  147: def test_int_float_promotion_truediv(fscalar):
  148:     # Promotion for mixed int and float32/float16 must not go to float64
  149:     i = np.int8(1)
  150:     f = fscalar(1)
  151:     expected = np.result_type(i, f)
  152:     assert (i / f).dtype == expected
  153:     assert (f / i).dtype == expected
  154:     # But normal int / int true division goes to float64:
  155:     assert (i / i).dtype == np.dtype("float64")
  156:     # For int16, result has to be ast least float32 (takes ufunc path):
  157:     assert (np.int16(1) / f).dtype == np.dtype("float32")
  158: 
  159: 
  160: class TestBaseMath:
  161:     @pytest.mark.xfail(check_support_sve(), reason="gh-22982")
  162:     def test_blocked(self):
  163:         # test alignments offsets for simd instructions
  164:         # alignments for vz + 2 * (vs - 1) + 1
  165:         for dt, sz in [(np.float32, 11), (np.float64, 7), (np.int32, 11)]:
  166:             for out, inp1, inp2, msg in _gen_alignment_data(dtype=dt,
  167:                                                             type='binary',
  168:                                                             max_size=sz):
  169:                 exp1 = np.ones_like(inp1)
  170:                 inp1[...] = np.ones_like(inp1)
  171:                 inp2[...] = np.zeros_like(inp2)
  172:                 assert_almost_equal(np.add(inp1, inp2), exp1, err_msg=msg)
  173:                 assert_almost_equal(np.add(inp1, 2), exp1 + 2, err_msg=msg)
  174:                 assert_almost_equal(np.add(1, inp2), exp1, err_msg=msg)
  175: 
  176:                 np.add(inp1, inp2, out=out)
  177:                 assert_almost_equal(out, exp1, err_msg=msg)
  178: 
  179:                 inp2[...] += np.arange(inp2.size, dtype=dt) + 1
  180:                 assert_almost_equal(np.square(inp2),
  181:                                     np.multiply(inp2, inp2), err_msg=msg)
  182:                 # skip true divide for ints
  183:                 if dt != np.int32:
  184:                     assert_almost_equal(np.reciprocal(inp2),
  185:                                         np.divide(1, inp2), err_msg=msg)
  186: 
  187:                 inp1[...] = np.ones_like(inp1)
  188:                 np.add(inp1, 2, out=out)
  189:                 assert_almost_equal(out, exp1 + 2, err_msg=msg)
  190:                 inp2[...] = np.ones_like(inp2)
  191:                 np.add(2, inp2, out=out)
  192:                 assert_almost_equal(out, exp1 + 2, err_msg=msg)
  193: 
  194:     def test_lower_align(self):
  195:         # check data that is not aligned to element size
  196:         # i.e doubles are aligned to 4 bytes on i386
  197:         d = np.zeros(23 * 8, dtype=np.int8)[4:-4].view(np.float64)
  198:         o = np.zeros(23 * 8, dtype=np.int8)[4:-4].view(np.float64)
  199:         assert_almost_equal(d + d, d * 2)
  200:         np.add(d, d, out=o)
  201:         np.add(np.ones_like(d), d, out=o)
  202:         np.add(d, np.ones_like(d), out=o)
  203:         np.add(np.ones_like(d), d)
  204:         np.add(d, np.ones_like(d))
  205: 
  206: 
  207: class TestPower:
  208:     def test_small_types(self):
  209:         for t in [np.int8, np.int16, np.float16]:
  210:             a = t(3)
  211:             b = a ** 4
  212:             assert_(b == 81, f"error with {t!r}: got {b!r}")
  213: 
  214:     def test_large_types(self):
  215:         for t in [np.int32, np.int64, np.float32, np.float64, np.longdouble]:
  216:             a = t(51)
  217:             b = a ** 4
  218:             msg = f"error with {t!r}: got {b!r}"
  219:             if np.issubdtype(t, np.integer):
  220:                 assert_(b == 6765201, msg)
  221:             else:
  222:                 assert_almost_equal(b, 6765201, err_msg=msg)
  223: 
  224:     def test_integers_to_negative_integer_power(self):
  225:         # Note that the combination of uint64 with a signed integer
  226:         # has common type np.float64. The other combinations should all
  227:         # raise a ValueError for integer ** negative integer.
  228:         exp = [np.array(-1, dt)[()] for dt in 'bhilq']
  229: 
  230:         # 1 ** -1 possible special case
  231:         base = [np.array(1, dt)[()] for dt in 'bhilqBHILQ']
  232:         for i1, i2 in itertools.product(base, exp):
  233:             if i1.dtype != np.uint64:
  234:                 assert_raises(ValueError, operator.pow, i1, i2)
  235:             else:
  236:                 res = operator.pow(i1, i2)
  237:                 assert_(res.dtype.type is np.float64)
  238:                 assert_almost_equal(res, 1.)
  239: 
  240:         # -1 ** -1 possible special case
  241:         base = [np.array(-1, dt)[()] for dt in 'bhilq']
  242:         for i1, i2 in itertools.product(base, exp):
  243:             if i1.dtype != np.uint64:
  244:                 assert_raises(ValueError, operator.pow, i1, i2)
  245:             else:
  246:                 res = operator.pow(i1, i2)
  247:                 assert_(res.dtype.type is np.float64)
  248:                 assert_almost_equal(res, -1.)
  249: 
  250:         # 2 ** -1 perhaps generic
  251:         base = [np.array(2, dt)[()] for dt in 'bhilqBHILQ']
  252:         for i1, i2 in itertools.product(base, exp):
  253:             if i1.dtype != np.uint64:
  254:                 assert_raises(ValueError, operator.pow, i1, i2)
  255:             else:
  256:                 res = operator.pow(i1, i2)
  257:                 assert_(res.dtype.type is np.float64)
  258:                 assert_almost_equal(res, .5)
  259: 
  260:     def test_mixed_types(self):
  261:         typelist = [np.int8, np.int16, np.float16,
  262:                     np.float32, np.float64, np.int8,
  263:                     np.int16, np.int32, np.int64]
  264:         for t1 in typelist:
  265:             for t2 in typelist:
  266:                 a = t1(3)
  267:                 b = t2(2)
  268:                 result = a**b
  269:                 msg = f"error with {t1!r} and {t2!r}:got {result!r}, expected {9!r}"
  270:                 if np.issubdtype(np.dtype(result), np.integer):
  271:                     assert_(result == 9, msg)
  272:                 else:
  273:                     assert_almost_equal(result, 9, err_msg=msg)
  274: 
  275:     def test_modular_power(self):
  276:         # modular power is not implemented, so ensure it errors
  277:         a = 5
  278:         b = 4
  279:         c = 10
  280:         expected = pow(a, b, c)  # noqa: F841
  281:         for t in (np.int32, np.float32, np.complex64):
  282:             # note that 3-operand power only dispatches on the first argument
  283:             assert_raises(TypeError, operator.pow, t(a), b, c)
  284:             assert_raises(TypeError, operator.pow, np.array(t(a)), b, c)
  285: 
  286: 
  287: def floordiv_and_mod(x, y):
  288:     return (x // y, x % y)
  289: 
  290: 
  291: def _signs(dt):
  292:     if dt in np.typecodes['UnsignedInteger']:
  293:         return (+1,)
  294:     else:
  295:         return (+1, -1)
  296: 
  297: 
  298: class TestModulus:
  299: 
  300:     def test_modulus_basic(self):
  301:         dt = np.typecodes['AllInteger'] + np.typecodes['Float']
  302:         for op in [floordiv_and_mod, divmod]:
  303:             for dt1, dt2 in itertools.product(dt, dt):
  304:                 for sg1, sg2 in itertools.product(_signs(dt1), _signs(dt2)):
  305:                     fmt = 'op: %s, dt1: %s, dt2: %s, sg1: %s, sg2: %s'
  306:                     msg = fmt % (op.__name__, dt1, dt2, sg1, sg2)
  307:                     a = np.array(sg1 * 71, dtype=dt1)[()]
  308:                     b = np.array(sg2 * 19, dtype=dt2)[()]
  309:                     div, rem = op(a, b)
  310:                     assert_equal(div * b + rem, a, err_msg=msg)
  311:                     if sg2 == -1:
  312:                         assert_(b < rem <= 0, msg)
  313:                     else:
  314:                         assert_(b > rem >= 0, msg)
  315: 
  316:     def test_float_modulus_exact(self):
  317:         # test that float results are exact for small integers. This also
  318:         # holds for the same integers scaled by powers of two.
  319:         nlst = list(range(-127, 0))
  320:         plst = list(range(1, 128))
  321:         dividend = nlst + [0] + plst
  322:         divisor = nlst + plst
  323:         arg = list(itertools.product(dividend, divisor))
  324:         tgt = [divmod(*t) for t in arg]
  325: 
  326:         a, b = np.array(arg, dtype=int).T
  327:         # convert exact integer results from Python to float so that
  328:         # signed zero can be used, it is checked.
  329:         tgtdiv, tgtrem = np.array(tgt, dtype=float).T
  330:         tgtdiv = np.where((tgtdiv == 0.0) & ((b < 0) ^ (a < 0)), -0.0, tgtdiv)
  331:         tgtrem = np.where((tgtrem == 0.0) & (b < 0), -0.0, tgtrem)
  332: 
  333:         for op in [floordiv_and_mod, divmod]:
  334:             for dt in np.typecodes['Float']:
  335:                 msg = f'op: {op.__name__}, dtype: {dt}'
  336:                 fa = a.astype(dt)
  337:                 fb = b.astype(dt)
  338:                 # use list comprehension so a_ and b_ are scalars
  339:                 div, rem = zip(*[op(a_, b_) for a_, b_ in zip(fa, fb)])
  340:                 assert_equal(div, tgtdiv, err_msg=msg)
  341:                 assert_equal(rem, tgtrem, err_msg=msg)
  342: 
  343:     def test_float_modulus_roundoff(self):
  344:         # gh-6127
  345:         dt = np.typecodes['Float']
  346:         for op in [floordiv_and_mod, divmod]:
  347:             for dt1, dt2 in itertools.product(dt, dt):
  348:                 for sg1, sg2 in itertools.product((+1, -1), (+1, -1)):
  349:                     fmt = 'op: %s, dt1: %s, dt2: %s, sg1: %s, sg2: %s'
  350:                     msg = fmt % (op.__name__, dt1, dt2, sg1, sg2)
  351:                     a = np.array(sg1 * 78 * 6e-8, dtype=dt1)[()]
  352:                     b = np.array(sg2 * 6e-8, dtype=dt2)[()]
  353:                     div, rem = op(a, b)
  354:                     # Equal assertion should hold when fmod is used
  355:                     assert_equal(div * b + rem, a, err_msg=msg)
  356:                     if sg2 == -1:
  357:                         assert_(b < rem <= 0, msg)
  358:                     else:
  359:                         assert_(b > rem >= 0, msg)
  360: 
  361:     def test_float_modulus_corner_cases(self):
  362:         # Check remainder magnitude.
  363:         for dt in np.typecodes['Float']:
  364:             b = np.array(1.0, dtype=dt)
  365:             a = np.nextafter(np.array(0.0, dtype=dt), -b)
  366:             rem = operator.mod(a, b)
  367:             assert_(rem <= b, f'dt: {dt}')
  368:             rem = operator.mod(-a, -b)
  369:             assert_(rem >= -b, f'dt: {dt}')
  370: 
  371:         # Check nans, inf
  372:         with suppress_warnings() as sup:
  373:             sup.filter(RuntimeWarning, "invalid value encountered in remainder")
  374:             sup.filter(RuntimeWarning, "divide by zero encountered in remainder")
  375:             sup.filter(RuntimeWarning, "divide by zero encountered in floor_divide")
  376:             sup.filter(RuntimeWarning, "divide by zero encountered in divmod")
  377:             sup.filter(RuntimeWarning, "invalid value encountered in divmod")
  378:             for dt in np.typecodes['Float']:
  379:                 fone = np.array(1.0, dtype=dt)
  380:                 fzer = np.array(0.0, dtype=dt)
  381:                 finf = np.array(np.inf, dtype=dt)
  382:                 fnan = np.array(np.nan, dtype=dt)
  383:                 rem = operator.mod(fone, fzer)
  384:                 assert_(np.isnan(rem), f'dt: {dt}')
  385:                 # MSVC 2008 returns NaN here, so disable the check.
  386:                 #rem = operator.mod(fone, finf)
  387:                 #assert_(rem == fone, 'dt: %s' % dt)
  388:                 rem = operator.mod(fone, fnan)
  389:                 assert_(np.isnan(rem), f'dt: {dt}')
  390:                 rem = operator.mod(finf, fone)
  391:                 assert_(np.isnan(rem), f'dt: {dt}')
  392:                 for op in [floordiv_and_mod, divmod]:
  393:                     div, mod = op(fone, fzer)
  394:                     assert_(np.isinf(div)) and assert_(np.isnan(mod))
  395: 
  396:     def test_inplace_floordiv_handling(self):
  397:         # issue gh-12927
  398:         # this only applies to in-place floordiv //=, because the output type
  399:         # promotes to float which does not fit
  400:         a = np.array([1, 2], np.int64)
  401:         b = np.array([1, 2], np.uint64)
  402:         with pytest.raises(TypeError,
  403:                 match=r"Cannot cast ufunc 'floor_divide' output from"):
  404:             a //= b
  405: 
  406: class TestComparison:
  407:     def test_comparision_different_types(self):
  408:         x = np.array(1)
  409:         y = np.array('s')
  410:         eq = x == y
  411:         neq = x != y
  412:         assert eq is np.bool_(False)
  413:         assert neq is np.bool_(True)
  414: 
  415: 
  416: class TestComplexDivision:
  417:     def test_zero_division(self):
  418:         with np.errstate(all="ignore"):
  419:             for t in [np.complex64, np.complex128]:
  420:                 a = t(0.0)
  421:                 b = t(1.0)
  422:                 assert_(np.isinf(b / a))
  423:                 b = t(complex(np.inf, np.inf))
  424:                 assert_(np.isinf(b / a))
  425:                 b = t(complex(np.inf, np.nan))
  426:                 assert_(np.isinf(b / a))
  427:                 b = t(complex(np.nan, np.inf))
  428:                 assert_(np.isinf(b / a))
  429:                 b = t(complex(np.nan, np.nan))
  430:                 assert_(np.isnan(b / a))
  431:                 b = t(0.)
  432:                 assert_(np.isnan(b / a))
  433: 
  434:     def test_signed_zeros(self):
  435:         with np.errstate(all="ignore"):
  436:             for t in [np.complex64, np.complex128]:
  437:                 # tupled (numerator, denominator, expected)
  438:                 # for testing as expected == numerator/denominator
  439:                 data = (
  440:                     (( 0.0, -1.0), ( 0.0, 1.0), (-1.0, -0.0)),
  441:                     (( 0.0, -1.0), ( 0.0, -1.0), ( 1.0, -0.0)),
  442:                     (( 0.0, -1.0), (-0.0, -1.0), ( 1.0, 0.0)),
  443:                     (( 0.0, -1.0), (-0.0, 1.0), (-1.0, 0.0)),
  444:                     (( 0.0, 1.0), ( 0.0, -1.0), (-1.0, 0.0)),
  445:                     (( 0.0, -1.0), ( 0.0, -1.0), ( 1.0, -0.0)),
  446:                     ((-0.0, -1.0), ( 0.0, -1.0), ( 1.0, -0.0)),
  447:                     ((-0.0, 1.0), ( 0.0, -1.0), (-1.0, -0.0))
  448:                 )
  449:                 for cases in data:
  450:                     n = cases[0]
  451:                     d = cases[1]
  452:                     ex = cases[2]
  453:                     result = t(complex(n[0], n[1])) / t(complex(d[0], d[1]))
  454:                     # check real and imag parts separately to avoid comparison
  455:                     # in array context, which does not account for signed zeros
  456:                     assert_equal(result.real, ex[0])
  457:                     assert_equal(result.imag, ex[1])
  458: 
  459:     def test_branches(self):
  460:         with np.errstate(all="ignore"):
  461:             for t in [np.complex64, np.complex128]:
  462:                 # tupled (numerator, denominator, expected)
  463:                 # for testing as expected == numerator/denominator
  464:                 data = []
  465: 
  466:                 # trigger branch: real(fabs(denom)) > imag(fabs(denom))
  467:                 # followed by else condition as neither are == 0
  468:                 data.append((( 2.0, 1.0), ( 2.0, 1.0), (1.0, 0.0)))
  469: 
  470:                 # trigger branch: real(fabs(denom)) > imag(fabs(denom))
  471:                 # followed by if condition as both are == 0
  472:                 # is performed in test_zero_division(), so this is skipped
  473: 
  474:                 # trigger else if branch: real(fabs(denom)) < imag(fabs(denom))
  475:                 data.append(((1.0, 2.0), (1.0, 2.0), (1.0, 0.0)))
  476: 
  477:                 for cases in data:
  478:                     n = cases[0]
  479:                     d = cases[1]
  480:                     ex = cases[2]
  481:                     result = t(complex(n[0], n[1])) / t(complex(d[0], d[1]))
  482:                     # check real and imag parts separately to avoid comparison
  483:                     # in array context, which does not account for signed zeros
  484:                     assert_equal(result.real, ex[0])
  485:                     assert_equal(result.imag, ex[1])
  486: 
  487: 
  488: class TestConversion:
  489:     def test_int_from_long(self):
  490:         l = [1e6, 1e12, 1e18, -1e6, -1e12, -1e18]
  491:         li = [10**6, 10**12, 10**18, -10**6, -10**12, -10**18]
  492:         for T in [None, np.float64, np.int64]:
  493:             a = np.array(l, dtype=T)
  494:             assert_equal([int(_m) for _m in a], li)
  495: 
  496:         a = np.array(l[:3], dtype=np.uint64)
  497:         assert_equal([int(_m) for _m in a], li[:3])
  498: 
  499:     def test_iinfo_long_values(self):
  500:         for code in 'bBhH':
  501:             with pytest.raises(OverflowError):
  502:                 np.array(np.iinfo(code).max + 1, dtype=code)
  503: 
  504:         for code in np.typecodes['AllInteger']:
  505:             res = np.array(np.iinfo(code).max, dtype=code)
  506:             tgt = np.iinfo(code).max
  507:             assert_(res == tgt)
  508: 
  509:         for code in np.typecodes['AllInteger']:
  510:             res = np.dtype(code).type(np.iinfo(code).max)
  511:             tgt = np.iinfo(code).max
  512:             assert_(res == tgt)
  513: 
  514:     def test_int_raise_behaviour(self):
  515:         def overflow_error_func(dtype):
  516:             dtype(np.iinfo(dtype).max + 1)
  517: 
  518:         for code in [np.int_, np.uint, np.longlong, np.ulonglong]:
  519:             assert_raises(OverflowError, overflow_error_func, code)
  520: 
  521:     def test_int_from_infinite_longdouble(self):
  522:         # gh-627
  523:         x = np.longdouble(np.inf)
  524:         assert_raises(OverflowError, int, x)
  525:         with suppress_warnings() as sup:
  526:             sup.record(ComplexWarning)
  527:             x = np.clongdouble(np.inf)
  528:             assert_raises(OverflowError, int, x)
  529:             assert_equal(len(sup.log), 1)
  530: 
  531:     @pytest.mark.skipif(not IS_PYPY, reason="Test is PyPy only (gh-9972)")
  532:     def test_int_from_infinite_longdouble___int__(self):
  533:         x = np.longdouble(np.inf)
  534:         assert_raises(OverflowError, x.__int__)
  535:         with suppress_warnings() as sup:
  536:             sup.record(ComplexWarning)
  537:             x = np.clongdouble(np.inf)
  538:             assert_raises(OverflowError, x.__int__)
  539:             assert_equal(len(sup.log), 1)
  540: 
  541:     @pytest.mark.skipif(np.finfo(np.double) == np.finfo(np.longdouble),
  542:                         reason="long double is same as double")
  543:     @pytest.mark.skipif(platform.machine().startswith("ppc"),
  544:                         reason="IBM double double")
  545:     def test_int_from_huge_longdouble(self):
  546:         # Produce a longdouble that would overflow a double,
  547:         # use exponent that avoids bug in Darwin pow function.
  548:         exp = np.finfo(np.double).maxexp - 1
  549:         huge_ld = 2 * 1234 * np.longdouble(2) ** exp
  550:         huge_i = 2 * 1234 * 2 ** exp
  551:         assert_(huge_ld != np.inf)
  552:         assert_equal(int(huge_ld), huge_i)
  553: 
  554:     def test_int_from_longdouble(self):
  555:         x = np.longdouble(1.5)
  556:         assert_equal(int(x), 1)
  557:         x = np.longdouble(-10.5)
  558:         assert_equal(int(x), -10)
  559: 
  560:     def test_numpy_scalar_relational_operators(self):
  561:         # All integer
  562:         for dt1 in np.typecodes['AllInteger']:
  563:             assert_(1 > np.array(0, dtype=dt1)[()], f"type {dt1} failed")
  564:             assert_(not 1 < np.array(0, dtype=dt1)[()], f"type {dt1} failed")
  565: 
  566:             for dt2 in np.typecodes['AllInteger']:
  567:                 assert_(np.array(1, dtype=dt1)[()] > np.array(0, dtype=dt2)[()],
  568:                         f"type {dt1} and {dt2} failed")
  569:                 assert_(not np.array(1, dtype=dt1)[()] < np.array(0, dtype=dt2)[()],
  570:                         f"type {dt1} and {dt2} failed")
  571: 
  572:         # Unsigned integers
  573:         for dt1 in 'BHILQP':
  574:             assert_(-1 < np.array(1, dtype=dt1)[()], f"type {dt1} failed")
  575:             assert_(not -1 > np.array(1, dtype=dt1)[()], f"type {dt1} failed")
  576:             assert_(-1 != np.array(1, dtype=dt1)[()], f"type {dt1} failed")
  577: 
  578:             # unsigned vs signed
  579:             for dt2 in 'bhilqp':
  580:                 assert_(np.array(1, dtype=dt1)[()] > np.array(-1, dtype=dt2)[()],
  581:                         f"type {dt1} and {dt2} failed")
  582:                 assert_(not np.array(1, dtype=dt1)[()] < np.array(-1, dtype=dt2)[()],
  583:                         f"type {dt1} and {dt2} failed")
  584:                 assert_(np.array(1, dtype=dt1)[()] != np.array(-1, dtype=dt2)[()],
  585:                         f"type {dt1} and {dt2} failed")
  586: 
  587:         # Signed integers and floats
  588:         for dt1 in 'bhlqp' + np.typecodes['Float']:
  589:             assert_(1 > np.array(-1, dtype=dt1)[()], f"type {dt1} failed")
  590:             assert_(not 1 < np.array(-1, dtype=dt1)[()], f"type {dt1} failed")
  591:             assert_(-1 == np.array(-1, dtype=dt1)[()], f"type {dt1} failed")
  592: 
  593:             for dt2 in 'bhlqp' + np.typecodes['Float']:
  594:                 assert_(np.array(1, dtype=dt1)[()] > np.array(-1, dtype=dt2)[()],
  595:                         f"type {dt1} and {dt2} failed")
  596:                 assert_(not np.array(1, dtype=dt1)[()] < np.array(-1, dtype=dt2)[()],
  597:                         f"type {dt1} and {dt2} failed")
  598:                 assert_(np.array(-1, dtype=dt1)[()] == np.array(-1, dtype=dt2)[()],
  599:                         f"type {dt1} and {dt2} failed")
  600: 
  601:     def test_scalar_comparison_to_none(self):
  602:         # Scalars should just return False and not give a warnings.
  603:         # The comparisons are flagged by pep8, ignore that.
  604:         with warnings.catch_warnings(record=True) as w:
  605:             warnings.filterwarnings('always', '', FutureWarning)
  606:             assert_(not np.float32(1) == None)  # noqa: E711
  607:             assert_(not np.str_('test') == None)  # noqa: E711
  608:             # This is dubious (see below):
  609:             assert_(not np.datetime64('NaT') == None)  # noqa: E711
  610: 
  611:             assert_(np.float32(1) != None)  # noqa: E711
  612:             assert_(np.str_('test') != None)  # noqa: E711
  613:             # This is dubious (see below):
  614:             assert_(np.datetime64('NaT') != None)  # noqa: E711
  615:         assert_(len(w) == 0)
  616: 
  617:         # For documentation purposes, this is why the datetime is dubious.
  618:         # At the time of deprecation this was no behaviour change, but
  619:         # it has to be considered when the deprecations are done.
  620:         assert_(np.equal(np.datetime64('NaT'), None))
  621: 
  622: 
  623: #class TestRepr:
  624: #    def test_repr(self):
  625: #        for t in types:
  626: #            val = t(1197346475.0137341)
  627: #            val_repr = repr(val)
  628: #            val2 = eval(val_repr)
  629: #            assert_equal( val, val2 )
  630: 
  631: 
  632: class TestRepr:
  633:     def _test_type_repr(self, t):
  634:         finfo = np.finfo(t)
  635:         last_fraction_bit_idx = finfo.nexp + finfo.nmant
  636:         last_exponent_bit_idx = finfo.nexp
  637:         storage_bytes = np.dtype(t).itemsize * 8
  638:         # could add some more types to the list below
  639:         for which in ['small denorm', 'small norm']:
  640:             # Values from https://en.wikipedia.org/wiki/IEEE_754
  641:             constr = np.array([0x00] * storage_bytes, dtype=np.uint8)
  642:             if which == 'small denorm':
  643:                 byte = last_fraction_bit_idx // 8
  644:                 bytebit = 7 - (last_fraction_bit_idx % 8)
  645:                 constr[byte] = 1 << bytebit
  646:             elif which == 'small norm':
  647:                 byte = last_exponent_bit_idx // 8
  648:                 bytebit = 7 - (last_exponent_bit_idx % 8)
  649:                 constr[byte] = 1 << bytebit
  650:             else:
  651:                 raise ValueError('hmm')
  652:             val = constr.view(t)[0]
  653:             val_repr = repr(val)
  654:             val2 = t(eval(val_repr))
  655:             if not (val2 == 0 and val < 1e-100):
  656:                 assert_equal(val, val2)
  657: 
  658:     def test_float_repr(self):
  659:         # long double test cannot work, because eval goes through a python
  660:         # float
  661:         for t in [np.float32, np.float64]:
  662:             self._test_type_repr(t)
  663: 
  664: 
  665: if not IS_PYPY:
  666:     # sys.getsizeof() is not valid on PyPy
  667:     class TestSizeOf:
  668: 
  669:         def test_equal_nbytes(self):
  670:             for type in types:
  671:                 x = type(0)
  672:                 assert_(sys.getsizeof(x) > x.nbytes)
  673: 
  674:         def test_error(self):
  675:             d = np.float32()
  676:             assert_raises(TypeError, d.__sizeof__, "a")
  677: 
  678: 
  679: class TestMultiply:
  680:     def test_seq_repeat(self):
  681:         # Test that basic sequences get repeated when multiplied with
  682:         # numpy integers. And errors are raised when multiplied with others.
  683:         # Some of this behaviour may be controversial and could be open for
  684:         # change.
  685:         accepted_types = set(np.typecodes["AllInteger"])
  686:         deprecated_types = {'?'}
  687:         forbidden_types = (
  688:             set(np.typecodes["All"]) - accepted_types - deprecated_types)
  689:         forbidden_types -= {'V'}  # can't default-construct void scalars
  690: 
  691:         for seq_type in (list, tuple):
  692:             seq = seq_type([1, 2, 3])
  693:             for numpy_type in accepted_types:
  694:                 i = np.dtype(numpy_type).type(2)
  695:                 assert_equal(seq * i, seq * int(i))
  696:                 assert_equal(i * seq, int(i) * seq)
  697: 
  698:             for numpy_type in deprecated_types:
  699:                 i = np.dtype(numpy_type).type()
  700:                 with assert_raises(TypeError):
  701:                     operator.mul(seq, i)
  702: 
  703:             for numpy_type in forbidden_types:
  704:                 i = np.dtype(numpy_type).type()
  705:                 assert_raises(TypeError, operator.mul, seq, i)
  706:                 assert_raises(TypeError, operator.mul, i, seq)
  707: 
  708:     def test_no_seq_repeat_basic_array_like(self):
  709:         # Test that an array-like which does not know how to be multiplied
  710:         # does not attempt sequence repeat (raise TypeError).
  711:         # See also gh-7428.
  712:         class ArrayLike:
  713:             def __init__(self, arr):
  714:                 self.arr = arr
  715: 
  716:             def __array__(self, dtype=None, copy=None):
  717:                 return self.arr
  718: 
  719:         # Test for simple ArrayLike above and memoryviews (original report)
  720:         for arr_like in (ArrayLike(np.ones(3)), memoryview(np.ones(3))):
  721:             assert_array_equal(arr_like * np.float32(3.), np.full(3, 3.))
  722:             assert_array_equal(np.float32(3.) * arr_like, np.full(3, 3.))
  723:             assert_array_equal(arr_like * np.int_(3), np.full(3, 3))
  724:             assert_array_equal(np.int_(3) * arr_like, np.full(3, 3))
  725: 
  726: 
  727: class TestNegative:
  728:     def test_exceptions(self):
  729:         a = np.ones((), dtype=np.bool)[()]
  730:         assert_raises(TypeError, operator.neg, a)
  731: 
  732:     def test_result(self):
  733:         types = np.typecodes['AllInteger'] + np.typecodes['AllFloat']
  734:         with suppress_warnings() as sup:
  735:             sup.filter(RuntimeWarning)
  736:             for dt in types:
  737:                 a = np.ones((), dtype=dt)[()]
  738:                 if dt in np.typecodes['UnsignedInteger']:
  739:                     st = np.dtype(dt).type
  740:                     max = st(np.iinfo(dt).max)
  741:                     assert_equal(operator.neg(a), max)
  742:                 else:
  743:                     assert_equal(operator.neg(a) + a, 0)
  744: 
  745: class TestSubtract:
  746:     def test_exceptions(self):
  747:         a = np.ones((), dtype=np.bool)[()]
  748:         assert_raises(TypeError, operator.sub, a, a)
  749: 
  750:     def test_result(self):
  751:         types = np.typecodes['AllInteger'] + np.typecodes['AllFloat']
  752:         with suppress_warnings() as sup:
  753:             sup.filter(RuntimeWarning)
  754:             for dt in types:
  755:                 a = np.ones((), dtype=dt)[()]
  756:                 assert_equal(operator.sub(a, a), 0)
  757: 
  758: 
  759: class TestAbs:
  760:     def _test_abs_func(self, absfunc, test_dtype):
  761:         x = test_dtype(-1.5)
  762:         assert_equal(absfunc(x), 1.5)
  763:         x = test_dtype(0.0)
  764:         res = absfunc(x)
  765:         # assert_equal() checks zero signedness
  766:         assert_equal(res, 0.0)
  767:         x = test_dtype(-0.0)
  768:         res = absfunc(x)
  769:         assert_equal(res, 0.0)
  770: 
  771:         x = test_dtype(np.finfo(test_dtype).max)
  772:         assert_equal(absfunc(x), x.real)
  773: 
  774:         with suppress_warnings() as sup:
  775:             sup.filter(UserWarning)
  776:             x = test_dtype(np.finfo(test_dtype).tiny)
  777:             assert_equal(absfunc(x), x.real)
  778: 
  779:         x = test_dtype(np.finfo(test_dtype).min)
  780:         assert_equal(absfunc(x), -x.real)
  781: 
  782:     @pytest.mark.parametrize("dtype", floating_types + complex_floating_types)
  783:     def test_builtin_abs(self, dtype):
  784:         if (
  785:                 sys.platform == "cygwin" and dtype == np.clongdouble and
  786:                 (
  787:                     _pep440.parse(platform.release().split("-")[0])
  788:                     < _pep440.Version("3.3.0")
  789:                 )
  790:         ):
  791:             pytest.xfail(
  792:                 reason="absl is computed in double precision on cygwin < 3.3"
  793:             )
  794:         self._test_abs_func(abs, dtype)
  795: 
  796:     @pytest.mark.parametrize("dtype", floating_types + complex_floating_types)
  797:     def test_numpy_abs(self, dtype):
  798:         if (
  799:                 sys.platform == "cygwin" and dtype == np.clongdouble and
  800:                 (
  801:                     _pep440.parse(platform.release().split("-")[0])
  802:                     < _pep440.Version("3.3.0")
  803:                 )
  804:         ):
  805:             pytest.xfail(
  806:                 reason="absl is computed in double precision on cygwin < 3.3"
  807:             )
  808:         self._test_abs_func(np.abs, dtype)
  809: 
  810: class TestBitShifts:
  811: 
  812:     @pytest.mark.parametrize('type_code', np.typecodes['AllInteger'])
  813:     @pytest.mark.parametrize('op',
  814:         [operator.rshift, operator.lshift], ids=['>>', '<<'])
  815:     def test_shift_all_bits(self, type_code, op):
  816:         """Shifts where the shift amount is the width of the type or wider """
  817:         # gh-2449
  818:         dt = np.dtype(type_code)
  819:         nbits = dt.itemsize * 8
  820:         for val in [5, -5]:
  821:             for shift in [nbits, nbits + 4]:
  822:                 val_scl = np.array(val).astype(dt)[()]
  823:                 shift_scl = dt.type(shift)
  824:                 res_scl = op(val_scl, shift_scl)
  825:                 if val_scl < 0 and op is operator.rshift:
  826:                     # sign bit is preserved
  827:                     assert_equal(res_scl, -1)
  828:                 else:
  829:                     assert_equal(res_scl, 0)
  830: 
  831:                 # Result on scalars should be the same as on arrays
  832:                 val_arr = np.array([val_scl] * 32, dtype=dt)
  833:                 shift_arr = np.array([shift] * 32, dtype=dt)
  834:                 res_arr = op(val_arr, shift_arr)
  835:                 assert_equal(res_arr, res_scl)
  836: 
  837: 
  838: class TestHash:
  839:     @pytest.mark.parametrize("type_code", np.typecodes['AllInteger'])
  840:     def test_integer_hashes(self, type_code):
  841:         scalar = np.dtype(type_code).type
  842:         for i in range(128):
  843:             assert hash(i) == hash(scalar(i))
  844: 
  845:     @pytest.mark.parametrize("type_code", np.typecodes['AllFloat'])
  846:     def test_float_and_complex_hashes(self, type_code):
  847:         scalar = np.dtype(type_code).type
  848:         for val in [np.pi, np.inf, 3, 6.]:
  849:             numpy_val = scalar(val)
  850:             # Cast back to Python, in case the NumPy scalar has less precision
  851:             if numpy_val.dtype.kind == 'c':
  852:                 val = complex(numpy_val)
  853:             else:
  854:                 val = float(numpy_val)
  855:             assert val == numpy_val
  856:             assert hash(val) == hash(numpy_val)
  857: 
  858:         if hash(float(np.nan)) != hash(float(np.nan)):
  859:             # If Python distinguishes different NaNs we do so too (gh-18833)
  860:             assert hash(scalar(np.nan)) != hash(scalar(np.nan))
  861: 
  862:     @pytest.mark.parametrize("type_code", np.typecodes['Complex'])
  863:     def test_complex_hashes(self, type_code):
  864:         # Test some complex valued hashes specifically:
  865:         scalar = np.dtype(type_code).type
  866:         for val in [np.pi + 1j, np.inf - 3j, 3j, 6. + 1j]:
  867:             numpy_val = scalar(val)
  868:             assert hash(complex(numpy_val)) == hash(numpy_val)
  869: 
  870: 
  871: @contextlib.contextmanager
  872: def recursionlimit(n):
  873:     o = sys.getrecursionlimit()
  874:     try:
  875:         sys.setrecursionlimit(n)
  876:         yield
  877:     finally:
  878:         sys.setrecursionlimit(o)
  879: 
  880: 
  881: @given(sampled_from(objecty_things),
  882:        sampled_from(binary_operators_for_scalar_ints),
  883:        sampled_from(types + [rational]))
  884: def test_operator_object_left(o, op, type_):
  885:     try:
  886:         with recursionlimit(200):
  887:             op(o, type_(1))
  888:     except TypeError:
  889:         pass
  890: 
  891: 
  892: @given(sampled_from(objecty_things),
  893:        sampled_from(binary_operators_for_scalar_ints),
  894:        sampled_from(types + [rational]))
  895: def test_operator_object_right(o, op, type_):
  896:     try:
  897:         with recursionlimit(200):
  898:             op(type_(1), o)
  899:     except TypeError:
  900:         pass
  901: 
  902: 
  903: @given(sampled_from(binary_operators_for_scalars),
  904:        sampled_from(types),
  905:        sampled_from(types))
  906: def test_operator_scalars(op, type1, type2):
  907:     try:
  908:         op(type1(1), type2(1))
  909:     except TypeError:
  910:         pass
  911: 
  912: 
  913: @pytest.mark.parametrize("op", binary_operators_for_scalars)
  914: @pytest.mark.parametrize("sctype", [np.longdouble, np.clongdouble])
  915: def test_longdouble_operators_with_obj(sctype, op):
  916:     # This is/used to be tricky, because NumPy generally falls back to
  917:     # using the ufunc via `np.asarray()`, this effectively might do:
  918:     # longdouble + None
  919:     #   -> asarray(longdouble) + np.array(None, dtype=object)
  920:     #   -> asarray(longdouble).astype(object) + np.array(None, dtype=object)
  921:     # And after getting the scalars in the inner loop:
  922:     #   -> longdouble + None
  923:     #
  924:     # That would recurse infinitely.  Other scalars return the python object
  925:     # on cast, so this type of things works OK.
  926:     #
  927:     # As of NumPy 2.1, this has been consolidated into the np.generic binops
  928:     # and now checks `.item()`.  That also allows the below path to work now.
  929:     try:
  930:         op(sctype(3), None)
  931:     except TypeError:
  932:         pass
  933:     try:
  934:         op(None, sctype(3))
  935:     except TypeError:
  936:         pass
  937: 
  938: 
  939: @pytest.mark.parametrize("op", [operator.add, operator.pow, operator.sub])
  940: @pytest.mark.parametrize("sctype", [np.longdouble, np.clongdouble])
  941: def test_longdouble_with_arrlike(sctype, op):
  942:     # As of NumPy 2.1, longdouble behaves like other types and can coerce
  943:     # e.g. lists.  (Not necessarily better, but consistent.)
  944:     assert_array_equal(op(sctype(3), [1, 2]), op(3, np.array([1, 2])))
  945:     assert_array_equal(op([1, 2], sctype(3)), op(np.array([1, 2]), 3))
  946: 
  947: 
  948: @pytest.mark.parametrize("op", binary_operators_for_scalars)
  949: @pytest.mark.parametrize("sctype", [np.longdouble, np.clongdouble])
  950: @np.errstate(all="ignore")
  951: def test_longdouble_operators_with_large_int(sctype, op):
  952:     # (See `test_longdouble_operators_with_obj` for why longdouble is special)
  953:     # NEP 50 means that the result is clearly a (c)longdouble here:
  954:     if sctype == np.clongdouble and op in [operator.mod, operator.floordiv]:
  955:         # The above operators are not support for complex though...
  956:         with pytest.raises(TypeError):
  957:             op(sctype(3), 2**64)
  958:         with pytest.raises(TypeError):
  959:             op(sctype(3), 2**64)
  960:     else:
  961:         assert op(sctype(3), -2**64) == op(sctype(3), sctype(-2**64))
  962:         assert op(2**64, sctype(3)) == op(sctype(2**64), sctype(3))
  963: 
  964: 
  965: @pytest.mark.parametrize("dtype", np.typecodes["AllInteger"])
  966: @pytest.mark.parametrize("operation", [
  967:         lambda min, max: max + max,
  968:         lambda min, max: min - max,
  969:         lambda min, max: max * max], ids=["+", "-", "*"])
  970: def test_scalar_integer_operation_overflow(dtype, operation):
  971:     st = np.dtype(dtype).type
  972:     min = st(np.iinfo(dtype).min)
  973:     max = st(np.iinfo(dtype).max)
  974: 
  975:     with pytest.warns(RuntimeWarning, match="overflow encountered"):
  976:         operation(min, max)
  977: 
  978: 
  979: @pytest.mark.parametrize("dtype", np.typecodes["Integer"])
  980: @pytest.mark.parametrize("operation", [
  981:         lambda min, neg_1: -min,
  982:         lambda min, neg_1: abs(min),
  983:         lambda min, neg_1: min * neg_1,
  984:         pytest.param(lambda min, neg_1: min // neg_1,
  985:             marks=pytest.mark.skip(reason="broken on some platforms"))],
  986:         ids=["neg", "abs", "*", "//"])
  987: def test_scalar_signed_integer_overflow(dtype, operation):
  988:     # The minimum signed integer can "overflow" for some additional operations
  989:     st = np.dtype(dtype).type
  990:     min = st(np.iinfo(dtype).min)
  991:     neg_1 = st(-1)
  992: 
  993:     with pytest.warns(RuntimeWarning, match="overflow encountered"):
  994:         operation(min, neg_1)
  995: 
  996: 
  997: @pytest.mark.parametrize("dtype", np.typecodes["UnsignedInteger"])
  998: def test_scalar_unsigned_integer_overflow(dtype):
  999:     val = np.dtype(dtype).type(8)
 1000:     with pytest.warns(RuntimeWarning, match="overflow encountered"):
 1001:         -val
 1002: 
 1003:     zero = np.dtype(dtype).type(0)
 1004:     -zero  # does not warn
 1005: 
 1006: @pytest.mark.parametrize("dtype", np.typecodes["AllInteger"])
 1007: @pytest.mark.parametrize("operation", [
 1008:         lambda val, zero: val // zero,
 1009:         lambda val, zero: val % zero, ], ids=["//", "%"])
 1010: def test_scalar_integer_operation_divbyzero(dtype, operation):
 1011:     st = np.dtype(dtype).type
 1012:     val = st(100)
 1013:     zero = st(0)
 1014: 
 1015:     with pytest.warns(RuntimeWarning, match="divide by zero"):
 1016:         operation(val, zero)
 1017: 
 1018: 
 1019: ops_with_names = [
 1020:     ("__lt__", "__gt__", operator.lt, True),
 1021:     ("__le__", "__ge__", operator.le, True),
 1022:     ("__eq__", "__eq__", operator.eq, True),
 1023:     # Note __op__ and __rop__ may be identical here:
 1024:     ("__ne__", "__ne__", operator.ne, True),
 1025:     ("__gt__", "__lt__", operator.gt, True),
 1026:     ("__ge__", "__le__", operator.ge, True),
 1027:     ("__floordiv__", "__rfloordiv__", operator.floordiv, False),
 1028:     ("__truediv__", "__rtruediv__", operator.truediv, False),
 1029:     ("__add__", "__radd__", operator.add, False),
 1030:     ("__mod__", "__rmod__", operator.mod, False),
 1031:     ("__mul__", "__rmul__", operator.mul, False),
 1032:     ("__pow__", "__rpow__", operator.pow, False),
 1033:     ("__sub__", "__rsub__", operator.sub, False),
 1034: ]
 1035: 
 1036: 
 1037: @pytest.mark.parametrize(["__op__", "__rop__", "op", "cmp"], ops_with_names)
 1038: @pytest.mark.parametrize("sctype", [np.float32, np.float64, np.longdouble])
 1039: def test_subclass_deferral(sctype, __op__, __rop__, op, cmp):
 1040:     """
 1041:     This test covers scalar subclass deferral.  Note that this is exceedingly
 1042:     complicated, especially since it tends to fall back to the array paths and
 1043:     these additionally add the "array priority" mechanism.
 1044: 
 1045:     The behaviour was modified subtly in 1.22 (to make it closer to how Python
 1046:     scalars work).  Due to its complexity and the fact that subclassing NumPy
 1047:     scalars is probably a bad idea to begin with.  There is probably room
 1048:     for adjustments here.
 1049:     """
 1050:     class myf_simple1(sctype):
 1051:         pass
 1052: 
 1053:     class myf_simple2(sctype):
 1054:         pass
 1055: 
 1056:     def op_func(self, other):
 1057:         return __op__
 1058: 
 1059:     def rop_func(self, other):
 1060:         return __rop__
 1061: 
 1062:     myf_op = type("myf_op", (sctype,), {__op__: op_func, __rop__: rop_func})
 1063: 
 1064:     # inheritance has to override, or this is correctly lost:
 1065:     res = op(myf_simple1(1), myf_simple2(2))
 1066:     assert type(res) == sctype or type(res) == np.bool
 1067:     assert op(myf_simple1(1), myf_simple2(2)) == op(1, 2)  # inherited
 1068: 
 1069:     # Two independent subclasses do not really define an order.  This could
 1070:     # be attempted, but we do not since Python's `int` does neither:
 1071:     assert op(myf_op(1), myf_simple1(2)) == __op__
 1072:     assert op(myf_simple1(1), myf_op(2)) == op(1, 2)  # inherited
 1073: 
 1074: 
 1075: def test_longdouble_complex():
 1076:     # Simple test to check longdouble and complex combinations, since these
 1077:     # need to go through promotion, which longdouble needs to be careful about.
 1078:     x = np.longdouble(1)
 1079:     assert x + 1j == 1 + 1j
 1080:     assert 1j + x == 1 + 1j
 1081: 
 1082: 
 1083: @pytest.mark.parametrize(["__op__", "__rop__", "op", "cmp"], ops_with_names)
 1084: @pytest.mark.parametrize("subtype", [float, int, complex, np.float16])
 1085: def test_pyscalar_subclasses(subtype, __op__, __rop__, op, cmp):
 1086:     # This tests that python scalar subclasses behave like a float64 (if they
 1087:     # don't override it).
 1088:     # In an earlier version of NEP 50, they behaved like the Python buildins.
 1089:     def op_func(self, other):
 1090:         return __op__
 1091: 
 1092:     def rop_func(self, other):
 1093:         return __rop__
 1094: 
 1095:     # Check that deferring is indicated using `__array_ufunc__`:
 1096:     myt = type("myt", (subtype,),
 1097:                {__op__: op_func, __rop__: rop_func, "__array_ufunc__": None})
 1098: 
 1099:     # Just like normally, we should never presume we can modify the float.
 1100:     assert op(myt(1), np.float64(2)) == __op__
 1101:     assert op(np.float64(1), myt(2)) == __rop__
 1102: 
 1103:     if op in {operator.mod, operator.floordiv} and subtype == complex:
 1104:         return  # module is not support for complex.  Do not test.
 1105: 
 1106:     if __rop__ == __op__:
 1107:         return
 1108: 
 1109:     # When no deferring is indicated, subclasses are handled normally.
 1110:     myt = type("myt", (subtype,), {__rop__: rop_func})
 1111:     behaves_like = lambda x: np.array(subtype(x))[()]
 1112: 
 1113:     # Check for float32, as a float subclass float64 may behave differently
 1114:     res = op(myt(1), np.float16(2))
 1115:     expected = op(behaves_like(1), np.float16(2))
 1116:     assert res == expected
 1117:     assert type(res) == type(expected)
 1118:     res = op(np.float32(2), myt(1))
 1119:     expected = op(np.float32(2), behaves_like(1))
 1120:     assert res == expected
 1121:     assert type(res) == type(expected)
 1122: 
 1123:     # Same check for longdouble (compare via dtype to accept float64 when
 1124:     # longdouble has the identical size), which is currently not perfectly
 1125:     # consistent.
 1126:     res = op(myt(1), np.longdouble(2))
 1127:     expected = op(behaves_like(1), np.longdouble(2))
 1128:     assert res == expected
 1129:     assert np.dtype(type(res)) == np.dtype(type(expected))
 1130:     res = op(np.float32(2), myt(1))
 1131:     expected = op(np.float32(2), behaves_like(1))
 1132:     assert res == expected
 1133:     assert np.dtype(type(res)) == np.dtype(type(expected))
 1134: 
 1135: 
 1136: def test_truediv_int():
 1137:     # This should work, as the result is float:
 1138:     assert np.uint8(3) / 123454 == np.float64(3) / 123454
 1139: 
 1140: 
 1141: @pytest.mark.slow
 1142: @pytest.mark.parametrize("op",
 1143:     # TODO: Power is a bit special, but here mostly bools seem to behave oddly
 1144:     [op for op in binary_operators_for_scalars if op is not operator.pow])
 1145: @pytest.mark.parametrize("sctype", types)
 1146: @pytest.mark.parametrize("other_type", [float, int, complex])
 1147: @pytest.mark.parametrize("rop", [True, False])
 1148: def test_scalar_matches_array_op_with_pyscalar(op, sctype, other_type, rop):
 1149:     # Check that the ufunc path matches by coercing to an array explicitly
 1150:     val1 = sctype(2)
 1151:     val2 = other_type(2)
 1152: 
 1153:     if rop:
 1154:         _op = op
 1155:         op = lambda x, y: _op(y, x)
 1156: 
 1157:     try:
 1158:         res = op(val1, val2)
 1159:     except TypeError:
 1160:         try:
 1161:             expected = op(np.asarray(val1), val2)
 1162:             raise AssertionError("ufunc didn't raise.")
 1163:         except TypeError:
 1164:             return
 1165:     else:
 1166:         expected = op(np.asarray(val1), val2)
 1167: 
 1168:     # Note that we only check dtype equivalency, as ufuncs may pick the lower
 1169:     # dtype if they are equivalent.
 1170:     assert res == expected
 1171:     if isinstance(val1, float) and other_type is complex and rop:
 1172:         # Python complex accepts float subclasses, so we don't get a chance
 1173:         # and the result may be a Python complex (thus, the `np.array()``)
 1174:         assert np.array(res).dtype == expected.dtype
 1175:     else:
 1176:         assert res.dtype == expected.dtype
