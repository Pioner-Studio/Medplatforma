    1: import itertools
    2: 
    3: import pytest
    4: from numpy._core._multiarray_tests import internal_overlap, solve_diophantine
    5: 
    6: import numpy as np
    7: from numpy._core import _umath_tests
    8: from numpy.lib.stride_tricks import as_strided
    9: from numpy.testing import assert_, assert_array_equal, assert_equal, assert_raises
   10: 
   11: ndims = 2
   12: size = 10
   13: shape = tuple([size] * ndims)
   14: 
   15: MAY_SHARE_BOUNDS = 0
   16: MAY_SHARE_EXACT = -1
   17: 
   18: 
   19: def _indices_for_nelems(nelems):
   20:     """Returns slices of length nelems, from start onwards, in direction sign."""
   21: 
   22:     if nelems == 0:
   23:         return [size // 2]  # int index
   24: 
   25:     res = []
   26:     for step in (1, 2):
   27:         for sign in (-1, 1):
   28:             start = size // 2 - nelems * step * sign // 2
   29:             stop = start + nelems * step * sign
   30:             res.append(slice(start, stop, step * sign))
   31: 
   32:     return res
   33: 
   34: 
   35: def _indices_for_axis():
   36:     """Returns (src, dst) pairs of indices."""
   37: 
   38:     res = []
   39:     for nelems in (0, 2, 3):
   40:         ind = _indices_for_nelems(nelems)
   41:         res.extend(itertools.product(ind, ind))  # all assignments of size "nelems"
   42: 
   43:     return res
   44: 
   45: 
   46: def _indices(ndims):
   47:     """Returns ((axis0_src, axis0_dst), (axis1_src, axis1_dst), ... ) index pairs."""
   48: 
   49:     ind = _indices_for_axis()
   50:     return itertools.product(ind, repeat=ndims)
   51: 
   52: 
   53: def _check_assignment(srcidx, dstidx):
   54:     """Check assignment arr[dstidx] = arr[srcidx] works."""
   55: 
   56:     arr = np.arange(np.prod(shape)).reshape(shape)
   57: 
   58:     cpy = arr.copy()
   59: 
   60:     cpy[dstidx] = arr[srcidx]
   61:     arr[dstidx] = arr[srcidx]
   62: 
   63:     assert_(np.all(arr == cpy),
   64:             f'assigning arr[{dstidx}] = arr[{srcidx}]')
   65: 
   66: 
   67: def test_overlapping_assignments():
   68:     # Test automatically generated assignments which overlap in memory.
   69: 
   70:     inds = _indices(ndims)
   71: 
   72:     for ind in inds:
   73:         srcidx = tuple(a[0] for a in ind)
   74:         dstidx = tuple(a[1] for a in ind)
   75: 
   76:         _check_assignment(srcidx, dstidx)
   77: 
   78: 
   79: @pytest.mark.slow
   80: def test_diophantine_fuzz():
   81:     # Fuzz test the diophantine solver
   82:     rng = np.random.RandomState(1234)
   83: 
   84:     max_int = np.iinfo(np.intp).max
   85: 
   86:     for ndim in range(10):
   87:         feasible_count = 0
   88:         infeasible_count = 0
   89: 
   90:         min_count = 500 // (ndim + 1)
   91: 
   92:         while min(feasible_count, infeasible_count) < min_count:
   93:             # Ensure big and small integer problems
   94:             A_max = 1 + rng.randint(0, 11, dtype=np.intp)**6
   95:             U_max = rng.randint(0, 11, dtype=np.intp)**6
   96: 
   97:             A_max = min(max_int, A_max)
   98:             U_max = min(max_int - 1, U_max)
   99: 
  100:             A = tuple(int(rng.randint(1, A_max + 1, dtype=np.intp))
  101:                       for j in range(ndim))
  102:             U = tuple(int(rng.randint(0, U_max + 2, dtype=np.intp))
  103:                       for j in range(ndim))
  104: 
  105:             b_ub = min(max_int - 2, sum(a * ub for a, ub in zip(A, U)))
  106:             b = int(rng.randint(-1, b_ub + 2, dtype=np.intp))
  107: 
  108:             if ndim == 0 and feasible_count < min_count:
  109:                 b = 0
  110: 
  111:             X = solve_diophantine(A, U, b)
  112: 
  113:             if X is None:
  114:                 # Check the simplified decision problem agrees
  115:                 X_simplified = solve_diophantine(A, U, b, simplify=1)
  116:                 assert_(X_simplified is None, (A, U, b, X_simplified))
  117: 
  118:                 # Check no solution exists (provided the problem is
  119:                 # small enough so that brute force checking doesn't
  120:                 # take too long)
  121:                 ranges = tuple(range(0, a * ub + 1, a) for a, ub in zip(A, U))
  122: 
  123:                 size = 1
  124:                 for r in ranges:
  125:                     size *= len(r)
  126:                 if size < 100000:
  127:                     assert_(not any(sum(w) == b for w in itertools.product(*ranges)))
  128:                     infeasible_count += 1
  129:             else:
  130:                 # Check the simplified decision problem agrees
  131:                 X_simplified = solve_diophantine(A, U, b, simplify=1)
  132:                 assert_(X_simplified is not None, (A, U, b, X_simplified))
  133: 
  134:                 # Check validity
  135:                 assert_(sum(a * x for a, x in zip(A, X)) == b)
  136:                 assert_(all(0 <= x <= ub for x, ub in zip(X, U)))
  137:                 feasible_count += 1
  138: 
  139: 
  140: def test_diophantine_overflow():
  141:     # Smoke test integer overflow detection
  142:     max_intp = np.iinfo(np.intp).max
  143:     max_int64 = np.iinfo(np.int64).max
  144: 
  145:     if max_int64 <= max_intp:
  146:         # Check that the algorithm works internally in 128-bit;
  147:         # solving this problem requires large intermediate numbers
  148:         A = (max_int64 // 2, max_int64 // 2 - 10)
  149:         U = (max_int64 // 2, max_int64 // 2 - 10)
  150:         b = 2 * (max_int64 // 2) - 10
  151: 
  152:         assert_equal(solve_diophantine(A, U, b), (1, 1))
  153: 
  154: 
  155: def check_may_share_memory_exact(a, b):
  156:     got = np.may_share_memory(a, b, max_work=MAY_SHARE_EXACT)
  157: 
  158:     assert_equal(np.may_share_memory(a, b),
  159:                  np.may_share_memory(a, b, max_work=MAY_SHARE_BOUNDS))
  160: 
  161:     a.fill(0)
  162:     b.fill(0)
  163:     a.fill(1)
  164:     exact = b.any()
  165: 
  166:     err_msg = ""
  167:     if got != exact:
  168:         err_msg = "    " + "\n    ".join([
  169:             f"base_a - base_b = {a.__array_interface__['data'][0] - b.__array_interface__['data'][0]!r}",
  170:             f"shape_a = {a.shape!r}",
  171:             f"shape_b = {b.shape!r}",
  172:             f"strides_a = {a.strides!r}",
  173:             f"strides_b = {b.strides!r}",
  174:             f"size_a = {a.size!r}",
  175:             f"size_b = {b.size!r}"
  176:         ])
  177: 
  178:     assert_equal(got, exact, err_msg=err_msg)
  179: 
  180: 
  181: def test_may_share_memory_manual():
  182:     # Manual test cases for may_share_memory
  183: 
  184:     # Base arrays
  185:     xs0 = [
  186:         np.zeros([13, 21, 23, 22], dtype=np.int8),
  187:         np.zeros([13, 21, 23 * 2, 22], dtype=np.int8)[:, :, ::2, :]
  188:     ]
  189: 
  190:     # Generate all negative stride combinations
  191:     xs = []
  192:     for x in xs0:
  193:         for ss in itertools.product(*(([slice(None), slice(None, None, -1)],) * 4)):
  194:             xp = x[ss]
  195:             xs.append(xp)
  196: 
  197:     for x in xs:
  198:         # The default is a simple extent check
  199:         assert_(np.may_share_memory(x[:, 0, :], x[:, 1, :]))
  200:         assert_(np.may_share_memory(x[:, 0, :], x[:, 1, :], max_work=None))
  201: 
  202:         # Exact checks
  203:         check_may_share_memory_exact(x[:, 0, :], x[:, 1, :])
  204:         check_may_share_memory_exact(x[:, ::7], x[:, 3::3])
  205: 
  206:         try:
  207:             xp = x.ravel()
  208:             if xp.flags.owndata:
  209:                 continue
  210:             xp = xp.view(np.int16)
  211:         except ValueError:
  212:             continue
  213: 
  214:         # 0-size arrays cannot overlap
  215:         check_may_share_memory_exact(x.ravel()[6:6],
  216:                                      xp.reshape(13, 21, 23, 11)[:, ::7])
  217: 
  218:         # Test itemsize is dealt with
  219:         check_may_share_memory_exact(x[:, ::7],
  220:                                      xp.reshape(13, 21, 23, 11))
  221:         check_may_share_memory_exact(x[:, ::7],
  222:                                      xp.reshape(13, 21, 23, 11)[:, 3::3])
  223:         check_may_share_memory_exact(x.ravel()[6:7],
  224:                                      xp.reshape(13, 21, 23, 11)[:, ::7])
  225: 
  226:     # Check unit size
  227:     x = np.zeros([1], dtype=np.int8)
  228:     check_may_share_memory_exact(x, x)
  229:     check_may_share_memory_exact(x, x.copy())
  230: 
  231: 
  232: def iter_random_view_pairs(x, same_steps=True, equal_size=False):
  233:     rng = np.random.RandomState(1234)
  234: 
  235:     if equal_size and same_steps:
  236:         raise ValueError
  237: 
  238:     def random_slice(n, step):
  239:         start = rng.randint(0, n + 1, dtype=np.intp)
  240:         stop = rng.randint(start, n + 1, dtype=np.intp)
  241:         if rng.randint(0, 2, dtype=np.intp) == 0:
  242:             stop, start = start, stop
  243:             step *= -1
  244:         return slice(start, stop, step)
  245: 
  246:     def random_slice_fixed_size(n, step, size):
  247:         start = rng.randint(0, n + 1 - size * step)
  248:         stop = start + (size - 1) * step + 1
  249:         if rng.randint(0, 2) == 0:
  250:             stop, start = start - 1, stop - 1
  251:             if stop < 0:
  252:                 stop = None
  253:             step *= -1
  254:         return slice(start, stop, step)
  255: 
  256:     # First a few regular views
  257:     yield x, x
  258:     for j in range(1, 7, 3):
  259:         yield x[j:], x[:-j]
  260:         yield x[..., j:], x[..., :-j]
  261: 
  262:     # An array with zero stride internal overlap
  263:     strides = list(x.strides)
  264:     strides[0] = 0
  265:     xp = as_strided(x, shape=x.shape, strides=strides)
  266:     yield x, xp
  267:     yield xp, xp
  268: 
  269:     # An array with non-zero stride internal overlap
  270:     strides = list(x.strides)
  271:     if strides[0] > 1:
  272:         strides[0] = 1
  273:     xp = as_strided(x, shape=x.shape, strides=strides)
  274:     yield x, xp
  275:     yield xp, xp
  276: 
  277:     # Then discontiguous views
  278:     while True:
  279:         steps = tuple(rng.randint(1, 11, dtype=np.intp)
  280:                       if rng.randint(0, 5, dtype=np.intp) == 0 else 1
  281:                       for j in range(x.ndim))
  282:         s1 = tuple(random_slice(p, s) for p, s in zip(x.shape, steps))
  283: 
  284:         t1 = np.arange(x.ndim)
  285:         rng.shuffle(t1)
  286: 
  287:         if equal_size:
  288:             t2 = t1
  289:         else:
  290:             t2 = np.arange(x.ndim)
  291:             rng.shuffle(t2)
  292: 
  293:         a = x[s1]
  294: 
  295:         if equal_size:
  296:             if a.size == 0:
  297:                 continue
  298: 
  299:             steps2 = tuple(rng.randint(1, max(2, p // (1 + pa)))
  300:                            if rng.randint(0, 5) == 0 else 1
  301:                            for p, s, pa in zip(x.shape, s1, a.shape))
  302:             s2 = tuple(random_slice_fixed_size(p, s, pa)
  303:                        for p, s, pa in zip(x.shape, steps2, a.shape))
  304:         elif same_steps:
  305:             steps2 = steps
  306:         else:
  307:             steps2 = tuple(rng.randint(1, 11, dtype=np.intp)
  308:                            if rng.randint(0, 5, dtype=np.intp) == 0 else 1
  309:                            for j in range(x.ndim))
  310: 
  311:         if not equal_size:
  312:             s2 = tuple(random_slice(p, s) for p, s in zip(x.shape, steps2))
  313: 
  314:         a = a.transpose(t1)
  315:         b = x[s2].transpose(t2)
  316: 
  317:         yield a, b
  318: 
  319: 
  320: def check_may_share_memory_easy_fuzz(get_max_work, same_steps, min_count):
  321:     # Check that overlap problems with common strides are solved with
  322:     # little work.
  323:     x = np.zeros([17, 34, 71, 97], dtype=np.int16)
  324: 
  325:     feasible = 0
  326:     infeasible = 0
  327: 
  328:     pair_iter = iter_random_view_pairs(x, same_steps)
  329: 
  330:     while min(feasible, infeasible) < min_count:
  331:         a, b = next(pair_iter)
  332: 
  333:         bounds_overlap = np.may_share_memory(a, b)
  334:         may_share_answer = np.may_share_memory(a, b)
  335:         easy_answer = np.may_share_memory(a, b, max_work=get_max_work(a, b))
  336:         exact_answer = np.may_share_memory(a, b, max_work=MAY_SHARE_EXACT)
  337: 
  338:         if easy_answer != exact_answer:
  339:             # assert_equal is slow...
  340:             assert_equal(easy_answer, exact_answer)
  341: 
  342:         if may_share_answer != bounds_overlap:
  343:             assert_equal(may_share_answer, bounds_overlap)
  344: 
  345:         if bounds_overlap:
  346:             if exact_answer:
  347:                 feasible += 1
  348:             else:
  349:                 infeasible += 1
  350: 
  351: 
  352: @pytest.mark.slow
  353: def test_may_share_memory_easy_fuzz():
  354:     # Check that overlap problems with common strides are always
  355:     # solved with little work.
  356: 
  357:     check_may_share_memory_easy_fuzz(get_max_work=lambda a, b: 1,
  358:                                      same_steps=True,
  359:                                      min_count=2000)
  360: 
  361: 
  362: @pytest.mark.slow
  363: def test_may_share_memory_harder_fuzz():
  364:     # Overlap problems with not necessarily common strides take more
  365:     # work.
  366:     #
  367:     # The work bound below can't be reduced much. Harder problems can
  368:     # also exist but not be detected here, as the set of problems
  369:     # comes from RNG.
  370: 
  371:     check_may_share_memory_easy_fuzz(get_max_work=lambda a, b: max(a.size, b.size) // 2,
  372:                                      same_steps=False,
  373:                                      min_count=2000)
  374: 
  375: 
  376: def test_shares_memory_api():
  377:     x = np.zeros([4, 5, 6], dtype=np.int8)
  378: 
  379:     assert_equal(np.shares_memory(x, x), True)
  380:     assert_equal(np.shares_memory(x, x.copy()), False)
  381: 
  382:     a = x[:, ::2, ::3]
  383:     b = x[:, ::3, ::2]
  384:     assert_equal(np.shares_memory(a, b), True)
  385:     assert_equal(np.shares_memory(a, b, max_work=None), True)
  386:     assert_raises(
  387:         np.exceptions.TooHardError, np.shares_memory, a, b, max_work=1
  388:     )
  389: 
  390: 
  391: def test_may_share_memory_bad_max_work():
  392:     x = np.zeros([1])
  393:     assert_raises(OverflowError, np.may_share_memory, x, x, max_work=10**100)
  394:     assert_raises(OverflowError, np.shares_memory, x, x, max_work=10**100)
  395: 
  396: 
  397: def test_internal_overlap_diophantine():
  398:     def check(A, U, exists=None):
  399:         X = solve_diophantine(A, U, 0, require_ub_nontrivial=1)
  400: 
  401:         if exists is None:
  402:             exists = (X is not None)
  403: 
  404:         if X is not None:
  405:             assert_(sum(a * x for a, x in zip(A, X)) == sum(a * u // 2 for a, u in zip(A, U)))
  406:             assert_(all(0 <= x <= u for x, u in zip(X, U)))
  407:             assert_(any(x != u // 2 for x, u in zip(X, U)))
  408: 
  409:         if exists:
  410:             assert_(X is not None, repr(X))
  411:         else:
  412:             assert_(X is None, repr(X))
  413: 
  414:     # Smoke tests
  415:     check((3, 2), (2 * 2, 3 * 2), exists=True)
  416:     check((3 * 2, 2), (15 * 2, (3 - 1) * 2), exists=False)
  417: 
  418: 
  419: def test_internal_overlap_slices():
  420:     # Slicing an array never generates internal overlap
  421: 
  422:     x = np.zeros([17, 34, 71, 97], dtype=np.int16)
  423: 
  424:     rng = np.random.RandomState(1234)
  425: 
  426:     def random_slice(n, step):
  427:         start = rng.randint(0, n + 1, dtype=np.intp)
  428:         stop = rng.randint(start, n + 1, dtype=np.intp)
  429:         if rng.randint(0, 2, dtype=np.intp) == 0:
  430:             stop, start = start, stop
  431:             step *= -1
  432:         return slice(start, stop, step)
  433: 
  434:     cases = 0
  435:     min_count = 5000
  436: 
  437:     while cases < min_count:
  438:         steps = tuple(rng.randint(1, 11, dtype=np.intp)
  439:                       if rng.randint(0, 5, dtype=np.intp) == 0 else 1
  440:                       for j in range(x.ndim))
  441:         t1 = np.arange(x.ndim)
  442:         rng.shuffle(t1)
  443:         s1 = tuple(random_slice(p, s) for p, s in zip(x.shape, steps))
  444:         a = x[s1].transpose(t1)
  445: 
  446:         assert_(not internal_overlap(a))
  447:         cases += 1
  448: 
  449: 
  450: def check_internal_overlap(a, manual_expected=None):
  451:     got = internal_overlap(a)
  452: 
  453:     # Brute-force check
  454:     m = set()
  455:     ranges = tuple(range(n) for n in a.shape)
  456:     for v in itertools.product(*ranges):
  457:         offset = sum(s * w for s, w in zip(a.strides, v))
  458:         if offset in m:
  459:             expected = True
  460:             break
  461:         else:
  462:             m.add(offset)
  463:     else:
  464:         expected = False
  465: 
  466:     # Compare
  467:     if got != expected:
  468:         assert_equal(got, expected, err_msg=repr((a.strides, a.shape)))
  469:     if manual_expected is not None and expected != manual_expected:
  470:         assert_equal(expected, manual_expected)
  471:     return got
  472: 
  473: 
  474: def test_internal_overlap_manual():
  475:     # Stride tricks can construct arrays with internal overlap
  476: 
  477:     # We don't care about memory bounds, the array is not
  478:     # read/write accessed
  479:     x = np.arange(1).astype(np.int8)
  480: 
  481:     # Check low-dimensional special cases
  482: 
  483:     check_internal_overlap(x, False)  # 1-dim
  484:     check_internal_overlap(x.reshape([]), False)  # 0-dim
  485: 
  486:     a = as_strided(x, strides=(3, 4), shape=(4, 4))
  487:     check_internal_overlap(a, False)
  488: 
  489:     a = as_strided(x, strides=(3, 4), shape=(5, 4))
  490:     check_internal_overlap(a, True)
  491: 
  492:     a = as_strided(x, strides=(0,), shape=(0,))
  493:     check_internal_overlap(a, False)
  494: 
  495:     a = as_strided(x, strides=(0,), shape=(1,))
  496:     check_internal_overlap(a, False)
  497: 
  498:     a = as_strided(x, strides=(0,), shape=(2,))
  499:     check_internal_overlap(a, True)
  500: 
  501:     a = as_strided(x, strides=(0, -9993), shape=(87, 22))
  502:     check_internal_overlap(a, True)
  503: 
  504:     a = as_strided(x, strides=(0, -9993), shape=(1, 22))
  505:     check_internal_overlap(a, False)
  506: 
  507:     a = as_strided(x, strides=(0, -9993), shape=(0, 22))
  508:     check_internal_overlap(a, False)
  509: 
  510: 
  511: def test_internal_overlap_fuzz():
  512:     # Fuzz check; the brute-force check is fairly slow
  513: 
  514:     x = np.arange(1).astype(np.int8)
  515: 
  516:     overlap = 0
  517:     no_overlap = 0
  518:     min_count = 100
  519: 
  520:     rng = np.random.RandomState(1234)
  521: 
  522:     while min(overlap, no_overlap) < min_count:
  523:         ndim = rng.randint(1, 4, dtype=np.intp)
  524: 
  525:         strides = tuple(rng.randint(-1000, 1000, dtype=np.intp)
  526:                         for j in range(ndim))
  527:         shape = tuple(rng.randint(1, 30, dtype=np.intp)
  528:                       for j in range(ndim))
  529: 
  530:         a = as_strided(x, strides=strides, shape=shape)
  531:         result = check_internal_overlap(a)
  532: 
  533:         if result:
  534:             overlap += 1
  535:         else:
  536:             no_overlap += 1
  537: 
  538: 
  539: def test_non_ndarray_inputs():
  540:     # Regression check for gh-5604
  541: 
  542:     class MyArray:
  543:         def __init__(self, data):
  544:             self.data = data
  545: 
  546:         @property
  547:         def __array_interface__(self):
  548:             return self.data.__array_interface__
  549: 
  550:     class MyArray2:
  551:         def __init__(self, data):
  552:             self.data = data
  553: 
  554:         def __array__(self, dtype=None, copy=None):
  555:             return self.data
  556: 
  557:     for cls in [MyArray, MyArray2]:
  558:         x = np.arange(5)
  559: 
  560:         assert_(np.may_share_memory(cls(x[::2]), x[1::2]))
  561:         assert_(not np.shares_memory(cls(x[::2]), x[1::2]))
  562: 
  563:         assert_(np.shares_memory(cls(x[1::3]), x[::2]))
  564:         assert_(np.may_share_memory(cls(x[1::3]), x[::2]))
  565: 
  566: 
  567: def view_element_first_byte(x):
  568:     """Construct an array viewing the first byte of each element of `x`"""
  569:     from numpy.lib._stride_tricks_impl import DummyArray
  570:     interface = dict(x.__array_interface__)
  571:     interface['typestr'] = '|b1'
  572:     interface['descr'] = [('', '|b1')]
  573:     return np.asarray(DummyArray(interface, x))
  574: 
  575: 
  576: def assert_copy_equivalent(operation, args, out, **kwargs):
  577:     """
  578:     Check that operation(*args, out=out) produces results
  579:     equivalent to out[...] = operation(*args, out=out.copy())
  580:     """
  581: 
  582:     kwargs['out'] = out
  583:     kwargs2 = dict(kwargs)
  584:     kwargs2['out'] = out.copy()
  585: 
  586:     out_orig = out.copy()
  587:     out[...] = operation(*args, **kwargs2)
  588:     expected = out.copy()
  589:     out[...] = out_orig
  590: 
  591:     got = operation(*args, **kwargs).copy()
  592: 
  593:     if (got != expected).any():
  594:         assert_equal(got, expected)
  595: 
  596: 
  597: class TestUFunc:
  598:     """
  599:     Test ufunc call memory overlap handling
  600:     """
  601: 
  602:     def check_unary_fuzz(self, operation, get_out_axis_size, dtype=np.int16,
  603:                              count=5000):
  604:         shapes = [7, 13, 8, 21, 29, 32]
  605: 
  606:         rng = np.random.RandomState(1234)
  607: 
  608:         for ndim in range(1, 6):
  609:             x = rng.randint(0, 2**16, size=shapes[:ndim]).astype(dtype)
  610: 
  611:             it = iter_random_view_pairs(x, same_steps=False, equal_size=True)
  612: 
  613:             min_count = count // (ndim + 1)**2
  614: 
  615:             overlapping = 0
  616:             while overlapping < min_count:
  617:                 a, b = next(it)
  618: 
  619:                 a_orig = a.copy()
  620:                 b_orig = b.copy()
  621: 
  622:                 if get_out_axis_size is None:
  623:                     assert_copy_equivalent(operation, [a], out=b)
  624: 
  625:                     if np.shares_memory(a, b):
  626:                         overlapping += 1
  627:                 else:
  628:                     for axis in itertools.chain(range(ndim), [None]):
  629:                         a[...] = a_orig
  630:                         b[...] = b_orig
  631: 
  632:                         # Determine size for reduction axis (None if scalar)
  633:                         outsize, scalarize = get_out_axis_size(a, b, axis)
  634:                         if outsize == 'skip':
  635:                             continue
  636: 
  637:                         # Slice b to get an output array of the correct size
  638:                         sl = [slice(None)] * ndim
  639:                         if axis is None:
  640:                             if outsize is None:
  641:                                 sl = [slice(0, 1)] + [0] * (ndim - 1)
  642:                             else:
  643:                                 sl = [slice(0, outsize)] + [0] * (ndim - 1)
  644:                         elif outsize is None:
  645:                             k = b.shape[axis] // 2
  646:                             if ndim == 1:
  647:                                 sl[axis] = slice(k, k + 1)
  648:                             else:
  649:                                 sl[axis] = k
  650:                         else:
  651:                             assert b.shape[axis] >= outsize
  652:                             sl[axis] = slice(0, outsize)
  653:                         b_out = b[tuple(sl)]
  654: 
  655:                         if scalarize:
  656:                             b_out = b_out.reshape([])
  657: 
  658:                         if np.shares_memory(a, b_out):
  659:                             overlapping += 1
  660: 
  661:                         # Check result
  662:                         assert_copy_equivalent(operation, [a], out=b_out, axis=axis)
  663: 
  664:     @pytest.mark.slow
  665:     def test_unary_ufunc_call_fuzz(self):
  666:         self.check_unary_fuzz(np.invert, None, np.int16)
  667: 
  668:     @pytest.mark.slow
  669:     def test_unary_ufunc_call_complex_fuzz(self):
  670:         # Complex typically has a smaller alignment than itemsize
  671:         self.check_unary_fuzz(np.negative, None, np.complex128, count=500)
  672: 
  673:     def test_binary_ufunc_accumulate_fuzz(self):
  674:         def get_out_axis_size(a, b, axis):
  675:             if axis is None:
  676:                 if a.ndim == 1:
  677:                     return a.size, False
  678:                 else:
  679:                     return 'skip', False  # accumulate doesn't support this
  680:             else:
  681:                 return a.shape[axis], False
  682: 
  683:         self.check_unary_fuzz(np.add.accumulate, get_out_axis_size,
  684:                               dtype=np.int16, count=500)
  685: 
  686:     def test_binary_ufunc_reduce_fuzz(self):
  687:         def get_out_axis_size(a, b, axis):
  688:             return None, (axis is None or a.ndim == 1)
  689: 
  690:         self.check_unary_fuzz(np.add.reduce, get_out_axis_size,
  691:                               dtype=np.int16, count=500)
  692: 
  693:     def test_binary_ufunc_reduceat_fuzz(self):
  694:         def get_out_axis_size(a, b, axis):
  695:             if axis is None:
  696:                 if a.ndim == 1:
  697:                     return a.size, False
  698:                 else:
  699:                     return 'skip', False  # reduceat doesn't support this
  700:             else:
  701:                 return a.shape[axis], False
  702: 
  703:         def do_reduceat(a, out, axis):
  704:             if axis is None:
  705:                 size = len(a)
  706:                 step = size // len(out)
  707:             else:
  708:                 size = a.shape[axis]
  709:                 step = a.shape[axis] // out.shape[axis]
  710:             idx = np.arange(0, size, step)
  711:             return np.add.reduceat(a, idx, out=out, axis=axis)
  712: 
  713:         self.check_unary_fuzz(do_reduceat, get_out_axis_size,
  714:                               dtype=np.int16, count=500)
  715: 
  716:     def test_binary_ufunc_reduceat_manual(self):
  717:         def check(ufunc, a, ind, out):
  718:             c1 = ufunc.reduceat(a.copy(), ind.copy(), out=out.copy())
  719:             c2 = ufunc.reduceat(a, ind, out=out)
  720:             assert_array_equal(c1, c2)
  721: 
  722:         # Exactly same input/output arrays
  723:         a = np.arange(10000, dtype=np.int16)
  724:         check(np.add, a, a[::-1].copy(), a)
  725: 
  726:         # Overlap with index
  727:         a = np.arange(10000, dtype=np.int16)
  728:         check(np.add, a, a[::-1], a)
  729: 
  730:     @pytest.mark.slow
  731:     def test_unary_gufunc_fuzz(self):
  732:         shapes = [7, 13, 8, 21, 29, 32]
  733:         gufunc = _umath_tests.euclidean_pdist
  734: 
  735:         rng = np.random.RandomState(1234)
  736: 
  737:         for ndim in range(2, 6):
  738:             x = rng.rand(*shapes[:ndim])
  739: 
  740:             it = iter_random_view_pairs(x, same_steps=False, equal_size=True)
  741: 
  742:             min_count = 500 // (ndim + 1)**2
  743: 
  744:             overlapping = 0
  745:             while overlapping < min_count:
  746:                 a, b = next(it)
  747: 
  748:                 if min(a.shape[-2:]) < 2 or min(b.shape[-2:]) < 2 or a.shape[-1] < 2:
  749:                     continue
  750: 
  751:                 # Ensure the shapes are so that euclidean_pdist is happy
  752:                 if b.shape[-1] > b.shape[-2]:
  753:                     b = b[..., 0, :]
  754:                 else:
  755:                     b = b[..., :, 0]
  756: 
  757:                 n = a.shape[-2]
  758:                 p = n * (n - 1) // 2
  759:                 if p <= b.shape[-1] and p > 0:
  760:                     b = b[..., :p]
  761:                 else:
  762:                     n = max(2, int(np.sqrt(b.shape[-1])) // 2)
  763:                     p = n * (n - 1) // 2
  764:                     a = a[..., :n, :]
  765:                     b = b[..., :p]
  766: 
  767:                 # Call
  768:                 if np.shares_memory(a, b):
  769:                     overlapping += 1
  770: 
  771:                 with np.errstate(over='ignore', invalid='ignore'):
  772:                     assert_copy_equivalent(gufunc, [a], out=b)
  773: 
  774:     def test_ufunc_at_manual(self):
  775:         def check(ufunc, a, ind, b=None):
  776:             a0 = a.copy()
  777:             if b is None:
  778:                 ufunc.at(a0, ind.copy())
  779:                 c1 = a0.copy()
  780:                 ufunc.at(a, ind)
  781:                 c2 = a.copy()
  782:             else:
  783:                 ufunc.at(a0, ind.copy(), b.copy())
  784:                 c1 = a0.copy()
  785:                 ufunc.at(a, ind, b)
  786:                 c2 = a.copy()
  787:             assert_array_equal(c1, c2)
  788: 
  789:         # Overlap with index
  790:         a = np.arange(10000, dtype=np.int16)
  791:         check(np.invert, a[::-1], a)
  792: 
  793:         # Overlap with second data array
  794:         a = np.arange(100, dtype=np.int16)
  795:         ind = np.arange(0, 100, 2, dtype=np.int16)
  796:         check(np.add, a, ind, a[25:75])
  797: 
  798:     def test_unary_ufunc_1d_manual(self):
  799:         # Exercise ufunc fast-paths (that avoid creation of an `np.nditer`)
  800: 
  801:         def check(a, b):
  802:             a_orig = a.copy()
  803:             b_orig = b.copy()
  804: 
  805:             b0 = b.copy()
  806:             c1 = ufunc(a, out=b0)
  807:             c2 = ufunc(a, out=b)
  808:             assert_array_equal(c1, c2)
  809: 
  810:             # Trigger "fancy ufunc loop" code path
  811:             mask = view_element_first_byte(b).view(np.bool)
  812: 
  813:             a[...] = a_orig
  814:             b[...] = b_orig
  815:             c1 = ufunc(a, out=b.copy(), where=mask.copy()).copy()
  816: 
  817:             a[...] = a_orig
  818:             b[...] = b_orig
  819:             c2 = ufunc(a, out=b, where=mask.copy()).copy()
  820: 
  821:             # Also, mask overlapping with output
  822:             a[...] = a_orig
  823:             b[...] = b_orig
  824:             c3 = ufunc(a, out=b, where=mask).copy()
  825: 
  826:             assert_array_equal(c1, c2)
  827:             assert_array_equal(c1, c3)
  828: 
  829:         dtypes = [np.int8, np.int16, np.int32, np.int64, np.float32,
  830:                   np.float64, np.complex64, np.complex128]
  831:         dtypes = [np.dtype(x) for x in dtypes]
  832: 
  833:         for dtype in dtypes:
  834:             if np.issubdtype(dtype, np.integer):
  835:                 ufunc = np.invert
  836:             else:
  837:                 ufunc = np.reciprocal
  838: 
  839:             n = 1000
  840:             k = 10
  841:             indices = [
  842:                 np.index_exp[:n],
  843:                 np.index_exp[k:k + n],
  844:                 np.index_exp[n - 1::-1],
  845:                 np.index_exp[k + n - 1:k - 1:-1],
  846:                 np.index_exp[:2 * n:2],
  847:                 np.index_exp[k:k + 2 * n:2],
  848:                 np.index_exp[2 * n - 1::-2],
  849:                 np.index_exp[k + 2 * n - 1:k - 1:-2],
  850:             ]
  851: 
  852:             for xi, yi in itertools.product(indices, indices):
  853:                 v = np.arange(1, 1 + n * 2 + k, dtype=dtype)
  854:                 x = v[xi]
  855:                 y = v[yi]
  856: 
  857:                 with np.errstate(all='ignore'):
  858:                     check(x, y)
  859: 
  860:                     # Scalar cases
  861:                     check(x[:1], y)
  862:                     check(x[-1:], y)
  863:                     check(x[:1].reshape([]), y)
  864:                     check(x[-1:].reshape([]), y)
  865: 
  866:     def test_unary_ufunc_where_same(self):
  867:         # Check behavior at wheremask overlap
  868:         ufunc = np.invert
  869: 
  870:         def check(a, out, mask):
  871:             c1 = ufunc(a, out=out.copy(), where=mask.copy())
  872:             c2 = ufunc(a, out=out, where=mask)
  873:             assert_array_equal(c1, c2)
  874: 
  875:         # Check behavior with same input and output arrays
  876:         x = np.arange(100).astype(np.bool)
  877:         check(x, x, x)
  878:         check(x, x.copy(), x)
  879:         check(x, x, x.copy())
  880: 
  881:     @pytest.mark.slow
  882:     def test_binary_ufunc_1d_manual(self):
  883:         ufunc = np.add
  884: 
  885:         def check(a, b, c):
  886:             c0 = c.copy()
  887:             c1 = ufunc(a, b, out=c0)
  888:             c2 = ufunc(a, b, out=c)
  889:             assert_array_equal(c1, c2)
  890: 
  891:         for dtype in [np.int8, np.int16, np.int32, np.int64,
  892:                       np.float32, np.float64, np.complex64, np.complex128]:
  893:             # Check different data dependency orders
  894: 
  895:             n = 1000
  896:             k = 10
  897: 
  898:             indices = []
  899:             for p in [1, 2]:
  900:                 indices.extend([
  901:                     np.index_exp[:p * n:p],
  902:                     np.index_exp[k:k + p * n:p],
  903:                     np.index_exp[p * n - 1::-p],
  904:                     np.index_exp[k + p * n - 1:k - 1:-p],
  905:                 ])
  906: 
  907:             for x, y, z in itertools.product(indices, indices, indices):
  908:                 v = np.arange(6 * n).astype(dtype)
  909:                 x = v[x]
  910:                 y = v[y]
  911:                 z = v[z]
  912: 
  913:                 check(x, y, z)
  914: 
  915:                 # Scalar cases
  916:                 check(x[:1], y, z)
  917:                 check(x[-1:], y, z)
  918:                 check(x[:1].reshape([]), y, z)
  919:                 check(x[-1:].reshape([]), y, z)
  920:                 check(x, y[:1], z)
  921:                 check(x, y[-1:], z)
  922:                 check(x, y[:1].reshape([]), z)
  923:                 check(x, y[-1:].reshape([]), z)
  924: 
  925:     def test_inplace_op_simple_manual(self):
  926:         rng = np.random.RandomState(1234)
  927:         x = rng.rand(200, 200)  # bigger than bufsize
  928: 
  929:         x += x.T
  930:         assert_array_equal(x - x.T, 0)
