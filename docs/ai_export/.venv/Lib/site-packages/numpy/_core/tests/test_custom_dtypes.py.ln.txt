    1: from tempfile import NamedTemporaryFile
    2: 
    3: import pytest
    4: from numpy._core._multiarray_umath import (
    5:     _discover_array_parameters as discover_array_params,
    6: )
    7: from numpy._core._multiarray_umath import _get_sfloat_dtype
    8: 
    9: import numpy as np
   10: from numpy.testing import assert_array_equal
   11: 
   12: SF = _get_sfloat_dtype()
   13: 
   14: 
   15: class TestSFloat:
   16:     def _get_array(self, scaling, aligned=True):
   17:         if not aligned:
   18:             a = np.empty(3 * 8 + 1, dtype=np.uint8)[1:]
   19:             a = a.view(np.float64)
   20:             a[:] = [1., 2., 3.]
   21:         else:
   22:             a = np.array([1., 2., 3.])
   23: 
   24:         a *= 1. / scaling  # the casting code also uses the reciprocal.
   25:         return a.view(SF(scaling))
   26: 
   27:     def test_sfloat_rescaled(self):
   28:         sf = SF(1.)
   29:         sf2 = sf.scaled_by(2.)
   30:         assert sf2.get_scaling() == 2.
   31:         sf6 = sf2.scaled_by(3.)
   32:         assert sf6.get_scaling() == 6.
   33: 
   34:     def test_class_discovery(self):
   35:         # This does not test much, since we always discover the scaling as 1.
   36:         # But most of NumPy (when writing) does not understand DType classes
   37:         dt, _ = discover_array_params([1., 2., 3.], dtype=SF)
   38:         assert dt == SF(1.)
   39: 
   40:     @pytest.mark.parametrize("scaling", [1., -1., 2.])
   41:     def test_scaled_float_from_floats(self, scaling):
   42:         a = np.array([1., 2., 3.], dtype=SF(scaling))
   43: 
   44:         assert a.dtype.get_scaling() == scaling
   45:         assert_array_equal(scaling * a.view(np.float64), [1., 2., 3.])
   46: 
   47:     def test_repr(self):
   48:         # Check the repr, mainly to cover the code paths:
   49:         assert repr(SF(scaling=1.)) == "_ScaledFloatTestDType(scaling=1.0)"
   50: 
   51:     def test_dtype_str(self):
   52:         assert SF(1.).str == "_ScaledFloatTestDType(scaling=1.0)"
   53: 
   54:     def test_dtype_name(self):
   55:         assert SF(1.).name == "_ScaledFloatTestDType64"
   56: 
   57:     def test_sfloat_structured_dtype_printing(self):
   58:         dt = np.dtype([("id", int), ("value", SF(0.5))])
   59:         # repr of structured dtypes need special handling because the
   60:         # implementation bypasses the object repr
   61:         assert "('value', '_ScaledFloatTestDType64')" in repr(dt)
   62: 
   63:     @pytest.mark.parametrize("scaling", [1., -1., 2.])
   64:     def test_sfloat_from_float(self, scaling):
   65:         a = np.array([1., 2., 3.]).astype(dtype=SF(scaling))
   66: 
   67:         assert a.dtype.get_scaling() == scaling
   68:         assert_array_equal(scaling * a.view(np.float64), [1., 2., 3.])
   69: 
   70:     @pytest.mark.parametrize("aligned", [True, False])
   71:     @pytest.mark.parametrize("scaling", [1., -1., 2.])
   72:     def test_sfloat_getitem(self, aligned, scaling):
   73:         a = self._get_array(1., aligned)
   74:         assert a.tolist() == [1., 2., 3.]
   75: 
   76:     @pytest.mark.parametrize("aligned", [True, False])
   77:     def test_sfloat_casts(self, aligned):
   78:         a = self._get_array(1., aligned)
   79: 
   80:         assert np.can_cast(a, SF(-1.), casting="equiv")
   81:         assert not np.can_cast(a, SF(-1.), casting="no")
   82:         na = a.astype(SF(-1.))
   83:         assert_array_equal(-1 * na.view(np.float64), a.view(np.float64))
   84: 
   85:         assert np.can_cast(a, SF(2.), casting="same_kind")
   86:         assert not np.can_cast(a, SF(2.), casting="safe")
   87:         a2 = a.astype(SF(2.))
   88:         assert_array_equal(2 * a2.view(np.float64), a.view(np.float64))
   89: 
   90:     @pytest.mark.parametrize("aligned", [True, False])
   91:     def test_sfloat_cast_internal_errors(self, aligned):
   92:         a = self._get_array(2e300, aligned)
   93: 
   94:         with pytest.raises(TypeError,
   95:                 match="error raised inside the core-loop: non-finite factor!"):
   96:             a.astype(SF(2e-300))
   97: 
   98:     def test_sfloat_promotion(self):
   99:         assert np.result_type(SF(2.), SF(3.)) == SF(3.)
  100:         assert np.result_type(SF(3.), SF(2.)) == SF(3.)
  101:         # Float64 -> SF(1.) and then promotes normally, so both of this work:
  102:         assert np.result_type(SF(3.), np.float64) == SF(3.)
  103:         assert np.result_type(np.float64, SF(0.5)) == SF(1.)
  104: 
  105:         # Test an undefined promotion:
  106:         with pytest.raises(TypeError):
  107:             np.result_type(SF(1.), np.int64)
  108: 
  109:     def test_basic_multiply(self):
  110:         a = self._get_array(2.)
  111:         b = self._get_array(4.)
  112: 
  113:         res = a * b
  114:         # multiplies dtype scaling and content separately:
  115:         assert res.dtype.get_scaling() == 8.
  116:         expected_view = a.view(np.float64) * b.view(np.float64)
  117:         assert_array_equal(res.view(np.float64), expected_view)
  118: 
  119:     def test_possible_and_impossible_reduce(self):
  120:         # For reductions to work, the first and last operand must have the
  121:         # same dtype.  For this parametric DType that is not necessarily true.
  122:         a = self._get_array(2.)
  123:         # Addition reduction works (as of writing requires to pass initial
  124:         # because setting a scaled-float from the default `0` fails).
  125:         res = np.add.reduce(a, initial=0.)
  126:         assert res == a.astype(np.float64).sum()
  127: 
  128:         # But each multiplication changes the factor, so a reduction is not
  129:         # possible (the relaxed version of the old refusal to handle any
  130:         # flexible dtype).
  131:         with pytest.raises(TypeError,
  132:                 match="the resolved dtypes are not compatible"):
  133:             np.multiply.reduce(a)
  134: 
  135:     def test_basic_ufunc_at(self):
  136:         float_a = np.array([1., 2., 3.])
  137:         b = self._get_array(2.)
  138: 
  139:         float_b = b.view(np.float64).copy()
  140:         np.multiply.at(float_b, [1, 1, 1], float_a)
  141:         np.multiply.at(b, [1, 1, 1], float_a)
  142: 
  143:         assert_array_equal(b.view(np.float64), float_b)
  144: 
  145:     def test_basic_multiply_promotion(self):
  146:         float_a = np.array([1., 2., 3.])
  147:         b = self._get_array(2.)
  148: 
  149:         res1 = float_a * b
  150:         res2 = b * float_a
  151: 
  152:         # one factor is one, so we get the factor of b:
  153:         assert res1.dtype == res2.dtype == b.dtype
  154:         expected_view = float_a * b.view(np.float64)
  155:         assert_array_equal(res1.view(np.float64), expected_view)
  156:         assert_array_equal(res2.view(np.float64), expected_view)
  157: 
  158:         # Check that promotion works when `out` is used:
  159:         np.multiply(b, float_a, out=res2)
  160:         with pytest.raises(TypeError):
  161:             # The promoter accepts this (maybe it should not), but the SFloat
  162:             # result cannot be cast to integer:
  163:             np.multiply(b, float_a, out=np.arange(3))
  164: 
  165:     def test_basic_addition(self):
  166:         a = self._get_array(2.)
  167:         b = self._get_array(4.)
  168: 
  169:         res = a + b
  170:         # addition uses the type promotion rules for the result:
  171:         assert res.dtype == np.result_type(a.dtype, b.dtype)
  172:         expected_view = (a.astype(res.dtype).view(np.float64) +
  173:                          b.astype(res.dtype).view(np.float64))
  174:         assert_array_equal(res.view(np.float64), expected_view)
  175: 
  176:     def test_addition_cast_safety(self):
  177:         """The addition method is special for the scaled float, because it
  178:         includes the "cast" between different factors, thus cast-safety
  179:         is influenced by the implementation.
  180:         """
  181:         a = self._get_array(2.)
  182:         b = self._get_array(-2.)
  183:         c = self._get_array(3.)
  184: 
  185:         # sign change is "equiv":
  186:         np.add(a, b, casting="equiv")
  187:         with pytest.raises(TypeError):
  188:             np.add(a, b, casting="no")
  189: 
  190:         # Different factor is "same_kind" (default) so check that "safe" fails
  191:         with pytest.raises(TypeError):
  192:             np.add(a, c, casting="safe")
  193: 
  194:         # Check that casting the output fails also (done by the ufunc here)
  195:         with pytest.raises(TypeError):
  196:             np.add(a, a, out=c, casting="safe")
  197: 
  198:     @pytest.mark.parametrize("ufunc",
  199:             [np.logical_and, np.logical_or, np.logical_xor])
  200:     def test_logical_ufuncs_casts_to_bool(self, ufunc):
  201:         a = self._get_array(2.)
  202:         a[0] = 0.  # make sure first element is considered False.
  203: 
  204:         float_equiv = a.astype(float)
  205:         expected = ufunc(float_equiv, float_equiv)
  206:         res = ufunc(a, a)
  207:         assert_array_equal(res, expected)
  208: 
  209:         # also check that the same works for reductions:
  210:         expected = ufunc.reduce(float_equiv)
  211:         res = ufunc.reduce(a)
  212:         assert_array_equal(res, expected)
  213: 
  214:         # The output casting does not match the bool, bool -> bool loop:
  215:         with pytest.raises(TypeError):
  216:             ufunc(a, a, out=np.empty(a.shape, dtype=int), casting="equiv")
  217: 
  218:     def test_wrapped_and_wrapped_reductions(self):
  219:         a = self._get_array(2.)
  220:         float_equiv = a.astype(float)
  221: 
  222:         expected = np.hypot(float_equiv, float_equiv)
  223:         res = np.hypot(a, a)
  224:         assert res.dtype == a.dtype
  225:         res_float = res.view(np.float64) * 2
  226:         assert_array_equal(res_float, expected)
  227: 
  228:         # Also check reduction (keepdims, due to incorrect getitem)
  229:         res = np.hypot.reduce(a, keepdims=True)
  230:         assert res.dtype == a.dtype
  231:         expected = np.hypot.reduce(float_equiv, keepdims=True)
  232:         assert res.view(np.float64) * 2 == expected
  233: 
  234:     def test_astype_class(self):
  235:         # Very simple test that we accept `.astype()` also on the class.
  236:         # ScaledFloat always returns the default descriptor, but it does
  237:         # check the relevant code paths.
  238:         arr = np.array([1., 2., 3.], dtype=object)
  239: 
  240:         res = arr.astype(SF)  # passing the class class
  241:         expected = arr.astype(SF(1.))  # above will have discovered 1. scaling
  242:         assert_array_equal(res.view(np.float64), expected.view(np.float64))
  243: 
  244:     def test_creation_class(self):
  245:         # passing in a dtype class should return
  246:         # the default descriptor
  247:         arr1 = np.array([1., 2., 3.], dtype=SF)
  248:         assert arr1.dtype == SF(1.)
  249:         arr2 = np.array([1., 2., 3.], dtype=SF(1.))
  250:         assert_array_equal(arr1.view(np.float64), arr2.view(np.float64))
  251:         assert arr1.dtype == arr2.dtype
  252: 
  253:         assert np.empty(3, dtype=SF).dtype == SF(1.)
  254:         assert np.empty_like(arr1, dtype=SF).dtype == SF(1.)
  255:         assert np.zeros(3, dtype=SF).dtype == SF(1.)
  256:         assert np.zeros_like(arr1, dtype=SF).dtype == SF(1.)
  257: 
  258:     def test_np_save_load(self):
  259:         # this monkeypatch is needed because pickle
  260:         # uses the repr of a type to reconstruct it
  261:         np._ScaledFloatTestDType = SF
  262: 
  263:         arr = np.array([1.0, 2.0, 3.0], dtype=SF(1.0))
  264: 
  265:         # adapted from RoundtripTest.roundtrip in np.save tests
  266:         with NamedTemporaryFile("wb", delete=False, suffix=".npz") as f:
  267:             with pytest.warns(UserWarning) as record:
  268:                 np.savez(f.name, arr)
  269: 
  270:         assert len(record) == 1
  271: 
  272:         with np.load(f.name, allow_pickle=True) as data:
  273:             larr = data["arr_0"]
  274:         assert_array_equal(arr.view(np.float64), larr.view(np.float64))
  275:         assert larr.dtype == arr.dtype == SF(1.0)
  276: 
  277:         del np._ScaledFloatTestDType
  278: 
  279:     def test_flatiter(self):
  280:         arr = np.array([1.0, 2.0, 3.0], dtype=SF(1.0))
  281: 
  282:         for i, val in enumerate(arr.flat):
  283:             assert arr[i] == val
  284: 
  285:     @pytest.mark.parametrize(
  286:         "index", [
  287:             [1, 2], ..., slice(None, 2, None),
  288:             np.array([True, True, False]), np.array([0, 1])
  289:         ], ids=["int_list", "ellipsis", "slice", "bool_array", "int_array"])
  290:     def test_flatiter_index(self, index):
  291:         arr = np.array([1.0, 2.0, 3.0], dtype=SF(1.0))
  292:         np.testing.assert_array_equal(
  293:             arr[index].view(np.float64), arr.flat[index].view(np.float64))
  294: 
  295:         arr2 = arr.copy()
  296:         arr[index] = 5.0
  297:         arr2.flat[index] = 5.0
  298:         np.testing.assert_array_equal(
  299:             arr.view(np.float64), arr2.view(np.float64))
  300: 
  301: def test_type_pickle():
  302:     # can't actually unpickle, but we can pickle (if in namespace)
  303:     import pickle
  304: 
  305:     np._ScaledFloatTestDType = SF
  306: 
  307:     s = pickle.dumps(SF)
  308:     res = pickle.loads(s)
  309:     assert res is SF
  310: 
  311:     del np._ScaledFloatTestDType
  312: 
  313: 
  314: def test_is_numeric():
  315:     assert SF._is_numeric
