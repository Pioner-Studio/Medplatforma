    1: # Copyright 2011-present MongoDB, Inc.
    2: #
    3: # Licensed under the Apache License, Version 2.0 (the "License"); you
    4: # may not use this file except in compliance with the License.  You
    5: # may obtain a copy of the License at
    6: #
    7: # http://www.apache.org/licenses/LICENSE-2.0
    8: #
    9: # Unless required by applicable law or agreed to in writing, software
   10: # distributed under the License is distributed on an "AS IS" BASIS,
   11: # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or
   12: # implied.  See the License for the specific language governing
   13: # permissions and limitations under the License.
   14: 
   15: from __future__ import annotations
   16: 
   17: import collections
   18: import contextlib
   19: import copy
   20: import logging
   21: import os
   22: import platform
   23: import socket
   24: import ssl
   25: import sys
   26: import threading
   27: import time
   28: import weakref
   29: from pathlib import Path
   30: from typing import (
   31:     TYPE_CHECKING,
   32:     Any,
   33:     Iterator,
   34:     Mapping,
   35:     MutableMapping,
   36:     NoReturn,
   37:     Optional,
   38:     Sequence,
   39:     Union,
   40: )
   41: 
   42: import bson
   43: from bson import DEFAULT_CODEC_OPTIONS
   44: from pymongo import __version__, _csot, helpers
   45: from pymongo.client_session import _validate_session_write_concern
   46: from pymongo.common import (
   47:     MAX_BSON_SIZE,
   48:     MAX_CONNECTING,
   49:     MAX_IDLE_TIME_SEC,
   50:     MAX_MESSAGE_SIZE,
   51:     MAX_POOL_SIZE,
   52:     MAX_WIRE_VERSION,
   53:     MAX_WRITE_BATCH_SIZE,
   54:     MIN_POOL_SIZE,
   55:     ORDERED_TYPES,
   56:     WAIT_QUEUE_TIMEOUT,
   57: )
   58: from pymongo.errors import (  # type:ignore[attr-defined]
   59:     AutoReconnect,
   60:     ConfigurationError,
   61:     ConnectionFailure,
   62:     DocumentTooLarge,
   63:     ExecutionTimeout,
   64:     InvalidOperation,
   65:     NetworkTimeout,
   66:     NotPrimaryError,
   67:     OperationFailure,
   68:     PyMongoError,
   69:     WaitQueueTimeoutError,
   70:     _CertificateError,
   71: )
   72: from pymongo.hello import Hello, HelloCompat
   73: from pymongo.helpers import _handle_reauth
   74: from pymongo.lock import _create_lock
   75: from pymongo.logger import (
   76:     _CONNECTION_LOGGER,
   77:     _ConnectionStatusMessage,
   78:     _debug_log,
   79:     _verbose_connection_error_reason,
   80: )
   81: from pymongo.monitoring import (
   82:     ConnectionCheckOutFailedReason,
   83:     ConnectionClosedReason,
   84:     _EventListeners,
   85: )
   86: from pymongo.network import command, receive_message
   87: from pymongo.read_preferences import ReadPreference
   88: from pymongo.server_api import _add_to_command
   89: from pymongo.server_type import SERVER_TYPE
   90: from pymongo.socket_checker import SocketChecker
   91: from pymongo.ssl_support import HAS_SNI, SSLError
   92: 
   93: if TYPE_CHECKING:
   94:     from bson import CodecOptions
   95:     from bson.objectid import ObjectId
   96:     from pymongo.auth import MongoCredential, _AuthContext
   97:     from pymongo.client_session import ClientSession
   98:     from pymongo.compression_support import (
   99:         CompressionSettings,
  100:         SnappyContext,
  101:         ZlibContext,
  102:         ZstdContext,
  103:     )
  104:     from pymongo.driver_info import DriverInfo
  105:     from pymongo.message import _OpMsg, _OpReply
  106:     from pymongo.mongo_client import MongoClient, _MongoClientErrorHandler
  107:     from pymongo.pyopenssl_context import SSLContext, _sslConn
  108:     from pymongo.read_concern import ReadConcern
  109:     from pymongo.read_preferences import _ServerMode
  110:     from pymongo.server_api import ServerApi
  111:     from pymongo.typings import ClusterTime, _Address, _CollationIn
  112:     from pymongo.write_concern import WriteConcern
  113: 
  114: try:
  115:     from fcntl import F_GETFD, F_SETFD, FD_CLOEXEC, fcntl
  116: 
  117:     def _set_non_inheritable_non_atomic(fd: int) -> None:
  118:         """Set the close-on-exec flag on the given file descriptor."""
  119:         flags = fcntl(fd, F_GETFD)
  120:         fcntl(fd, F_SETFD, flags | FD_CLOEXEC)
  121: 
  122: except ImportError:
  123:     # Windows, various platforms we don't claim to support
  124:     # (Jython, IronPython, ..), systems that don't provide
  125:     # everything we need from fcntl, etc.
  126:     def _set_non_inheritable_non_atomic(fd: int) -> None:  # noqa: ARG001
  127:         """Dummy function for platforms that don't provide fcntl."""
  128: 
  129: 
  130: _MAX_TCP_KEEPIDLE = 120
  131: _MAX_TCP_KEEPINTVL = 10
  132: _MAX_TCP_KEEPCNT = 9
  133: 
  134: if sys.platform == "win32":
  135:     try:
  136:         import _winreg as winreg
  137:     except ImportError:
  138:         import winreg
  139: 
  140:     def _query(key, name, default):
  141:         try:
  142:             value, _ = winreg.QueryValueEx(key, name)
  143:             # Ensure the value is a number or raise ValueError.
  144:             return int(value)
  145:         except (OSError, ValueError):
  146:             # QueryValueEx raises OSError when the key does not exist (i.e.
  147:             # the system is using the Windows default value).
  148:             return default
  149: 
  150:     try:
  151:         with winreg.OpenKey(
  152:             winreg.HKEY_LOCAL_MACHINE, r"SYSTEM\CurrentControlSet\Services\Tcpip\Parameters"
  153:         ) as key:
  154:             _WINDOWS_TCP_IDLE_MS = _query(key, "KeepAliveTime", 7200000)
  155:             _WINDOWS_TCP_INTERVAL_MS = _query(key, "KeepAliveInterval", 1000)
  156:     except OSError:
  157:         # We could not check the default values because winreg.OpenKey failed.
  158:         # Assume the system is using the default values.
  159:         _WINDOWS_TCP_IDLE_MS = 7200000
  160:         _WINDOWS_TCP_INTERVAL_MS = 1000
  161: 
  162:     def _set_keepalive_times(sock):
  163:         idle_ms = min(_WINDOWS_TCP_IDLE_MS, _MAX_TCP_KEEPIDLE * 1000)
  164:         interval_ms = min(_WINDOWS_TCP_INTERVAL_MS, _MAX_TCP_KEEPINTVL * 1000)
  165:         if idle_ms < _WINDOWS_TCP_IDLE_MS or interval_ms < _WINDOWS_TCP_INTERVAL_MS:
  166:             sock.ioctl(socket.SIO_KEEPALIVE_VALS, (1, idle_ms, interval_ms))
  167: 
  168: else:
  169: 
  170:     def _set_tcp_option(sock: socket.socket, tcp_option: str, max_value: int) -> None:
  171:         if hasattr(socket, tcp_option):
  172:             sockopt = getattr(socket, tcp_option)
  173:             try:
  174:                 # PYTHON-1350 - NetBSD doesn't implement getsockopt for
  175:                 # TCP_KEEPIDLE and friends. Don't attempt to set the
  176:                 # values there.
  177:                 default = sock.getsockopt(socket.IPPROTO_TCP, sockopt)
  178:                 if default > max_value:
  179:                     sock.setsockopt(socket.IPPROTO_TCP, sockopt, max_value)
  180:             except OSError:
  181:                 pass
  182: 
  183:     def _set_keepalive_times(sock: socket.socket) -> None:
  184:         _set_tcp_option(sock, "TCP_KEEPIDLE", _MAX_TCP_KEEPIDLE)
  185:         _set_tcp_option(sock, "TCP_KEEPINTVL", _MAX_TCP_KEEPINTVL)
  186:         _set_tcp_option(sock, "TCP_KEEPCNT", _MAX_TCP_KEEPCNT)
  187: 
  188: 
  189: _METADATA: dict[str, Any] = {"driver": {"name": "PyMongo", "version": __version__}}
  190: 
  191: if sys.platform.startswith("linux"):
  192:     # platform.linux_distribution was deprecated in Python 3.5
  193:     # and removed in Python 3.8. Starting in Python 3.5 it
  194:     # raises DeprecationWarning
  195:     # DeprecationWarning: dist() and linux_distribution() functions are deprecated in Python 3.5
  196:     _name = platform.system()
  197:     _METADATA["os"] = {
  198:         "type": _name,
  199:         "name": _name,
  200:         "architecture": platform.machine(),
  201:         # Kernel version (e.g. 4.4.0-17-generic).
  202:         "version": platform.release(),
  203:     }
  204: elif sys.platform == "darwin":
  205:     _METADATA["os"] = {
  206:         "type": platform.system(),
  207:         "name": platform.system(),
  208:         "architecture": platform.machine(),
  209:         # (mac|i|tv)OS(X) version (e.g. 10.11.6) instead of darwin
  210:         # kernel version.
  211:         "version": platform.mac_ver()[0],
  212:     }
  213: elif sys.platform == "win32":
  214:     _ver = sys.getwindowsversion()
  215:     _METADATA["os"] = {
  216:         "type": "Windows",
  217:         "name": "Windows",
  218:         # Avoid using platform calls, see PYTHON-4455.
  219:         "architecture": os.environ.get("PROCESSOR_ARCHITECTURE") or platform.machine(),
  220:         # Windows patch level (e.g. 10.0.17763-SP0).
  221:         "version": ".".join(map(str, _ver[:3])) + f"-SP{_ver[-1] or '0'}",
  222:     }
  223: elif sys.platform.startswith("java"):
  224:     _name, _ver, _arch = platform.java_ver()[-1]
  225:     _METADATA["os"] = {
  226:         # Linux, Windows 7, Mac OS X, etc.
  227:         "type": _name,
  228:         "name": _name,
  229:         # x86, x86_64, AMD64, etc.
  230:         "architecture": _arch,
  231:         # Linux kernel version, OSX version, etc.
  232:         "version": _ver,
  233:     }
  234: else:
  235:     # Get potential alias (e.g. SunOS 5.11 becomes Solaris 2.11)
  236:     _aliased = platform.system_alias(platform.system(), platform.release(), platform.version())
  237:     _METADATA["os"] = {
  238:         "type": platform.system(),
  239:         "name": " ".join([part for part in _aliased[:2] if part]),
  240:         "architecture": platform.machine(),
  241:         "version": _aliased[2],
  242:     }
  243: 
  244: if platform.python_implementation().startswith("PyPy"):
  245:     _METADATA["platform"] = " ".join(
  246:         (
  247:             platform.python_implementation(),
  248:             ".".join(map(str, sys.pypy_version_info)),  # type: ignore
  249:             "(Python %s)" % ".".join(map(str, sys.version_info)),
  250:         )
  251:     )
  252: elif sys.platform.startswith("java"):
  253:     _METADATA["platform"] = " ".join(
  254:         (
  255:             platform.python_implementation(),
  256:             ".".join(map(str, sys.version_info)),
  257:             "(%s)" % " ".join((platform.system(), platform.release())),
  258:         )
  259:     )
  260: else:
  261:     _METADATA["platform"] = " ".join(
  262:         (platform.python_implementation(), ".".join(map(str, sys.version_info)))
  263:     )
  264: 
  265: DOCKER_ENV_PATH = "/.dockerenv"
  266: ENV_VAR_K8S = "KUBERNETES_SERVICE_HOST"
  267: 
  268: RUNTIME_NAME_DOCKER = "docker"
  269: ORCHESTRATOR_NAME_K8S = "kubernetes"
  270: 
  271: 
  272: def get_container_env_info() -> dict[str, str]:
  273:     """Returns the runtime and orchestrator of a container.
  274:     If neither value is present, the metadata client.env.container field will be omitted."""
  275:     container = {}
  276: 
  277:     if Path(DOCKER_ENV_PATH).exists():
  278:         container["runtime"] = RUNTIME_NAME_DOCKER
  279:     if os.getenv(ENV_VAR_K8S):
  280:         container["orchestrator"] = ORCHESTRATOR_NAME_K8S
  281: 
  282:     return container
  283: 
  284: 
  285: def _is_lambda() -> bool:
  286:     if os.getenv("AWS_LAMBDA_RUNTIME_API"):
  287:         return True
  288:     env = os.getenv("AWS_EXECUTION_ENV")
  289:     if env:
  290:         return env.startswith("AWS_Lambda_")
  291:     return False
  292: 
  293: 
  294: def _is_azure_func() -> bool:
  295:     return bool(os.getenv("FUNCTIONS_WORKER_RUNTIME"))
  296: 
  297: 
  298: def _is_gcp_func() -> bool:
  299:     return bool(os.getenv("K_SERVICE") or os.getenv("FUNCTION_NAME"))
  300: 
  301: 
  302: def _is_vercel() -> bool:
  303:     return bool(os.getenv("VERCEL"))
  304: 
  305: 
  306: def _is_faas() -> bool:
  307:     return _is_lambda() or _is_azure_func() or _is_gcp_func() or _is_vercel()
  308: 
  309: 
  310: def _getenv_int(key: str) -> Optional[int]:
  311:     """Like os.getenv but returns an int, or None if the value is missing/malformed."""
  312:     val = os.getenv(key)
  313:     if not val:
  314:         return None
  315:     try:
  316:         return int(val)
  317:     except ValueError:
  318:         return None
  319: 
  320: 
  321: def _metadata_env() -> dict[str, Any]:
  322:     env: dict[str, Any] = {}
  323:     container = get_container_env_info()
  324:     if container:
  325:         env["container"] = container
  326:     # Skip if multiple (or no) envs are matched.
  327:     if (_is_lambda(), _is_azure_func(), _is_gcp_func(), _is_vercel()).count(True) != 1:
  328:         return env
  329:     if _is_lambda():
  330:         env["name"] = "aws.lambda"
  331:         region = os.getenv("AWS_REGION")
  332:         if region:
  333:             env["region"] = region
  334:         memory_mb = _getenv_int("AWS_LAMBDA_FUNCTION_MEMORY_SIZE")
  335:         if memory_mb is not None:
  336:             env["memory_mb"] = memory_mb
  337:     elif _is_azure_func():
  338:         env["name"] = "azure.func"
  339:     elif _is_gcp_func():
  340:         env["name"] = "gcp.func"
  341:         region = os.getenv("FUNCTION_REGION")
  342:         if region:
  343:             env["region"] = region
  344:         memory_mb = _getenv_int("FUNCTION_MEMORY_MB")
  345:         if memory_mb is not None:
  346:             env["memory_mb"] = memory_mb
  347:         timeout_sec = _getenv_int("FUNCTION_TIMEOUT_SEC")
  348:         if timeout_sec is not None:
  349:             env["timeout_sec"] = timeout_sec
  350:     elif _is_vercel():
  351:         env["name"] = "vercel"
  352:         region = os.getenv("VERCEL_REGION")
  353:         if region:
  354:             env["region"] = region
  355:     return env
  356: 
  357: 
  358: _MAX_METADATA_SIZE = 512
  359: 
  360: 
  361: # See: https://github.com/mongodb/specifications/blob/5112bcc/source/mongodb-handshake/handshake.rst#limitations
  362: def _truncate_metadata(metadata: MutableMapping[str, Any]) -> None:
  363:     """Perform metadata truncation."""
  364:     if len(bson.encode(metadata)) <= _MAX_METADATA_SIZE:
  365:         return
  366:     # 1. Omit fields from env except env.name.
  367:     env_name = metadata.get("env", {}).get("name")
  368:     if env_name:
  369:         metadata["env"] = {"name": env_name}
  370:     if len(bson.encode(metadata)) <= _MAX_METADATA_SIZE:
  371:         return
  372:     # 2. Omit fields from os except os.type.
  373:     os_type = metadata.get("os", {}).get("type")
  374:     if os_type:
  375:         metadata["os"] = {"type": os_type}
  376:     if len(bson.encode(metadata)) <= _MAX_METADATA_SIZE:
  377:         return
  378:     # 3. Omit the env document entirely.
  379:     metadata.pop("env", None)
  380:     encoded_size = len(bson.encode(metadata))
  381:     if encoded_size <= _MAX_METADATA_SIZE:
  382:         return
  383:     # 4. Truncate platform.
  384:     overflow = encoded_size - _MAX_METADATA_SIZE
  385:     plat = metadata.get("platform", "")
  386:     if plat:
  387:         plat = plat[:-overflow]
  388:     if plat:
  389:         metadata["platform"] = plat
  390:     else:
  391:         metadata.pop("platform", None)
  392: 
  393: 
  394: # If the first getaddrinfo call of this interpreter's life is on a thread,
  395: # while the main thread holds the import lock, getaddrinfo deadlocks trying
  396: # to import the IDNA codec. Import it here, where presumably we're on the
  397: # main thread, to avoid the deadlock. See PYTHON-607.
  398: "foo".encode("idna")
  399: 
  400: 
  401: def _raise_connection_failure(
  402:     address: Any,
  403:     error: Exception,
  404:     msg_prefix: Optional[str] = None,
  405:     timeout_details: Optional[dict[str, float]] = None,
  406: ) -> NoReturn:
  407:     """Convert a socket.error to ConnectionFailure and raise it."""
  408:     host, port = address
  409:     # If connecting to a Unix socket, port will be None.
  410:     if port is not None:
  411:         msg = "%s:%d: %s" % (host, port, error)
  412:     else:
  413:         msg = f"{host}: {error}"
  414:     if msg_prefix:
  415:         msg = msg_prefix + msg
  416:     if "configured timeouts" not in msg:
  417:         msg += format_timeout_details(timeout_details)
  418:     if isinstance(error, socket.timeout):
  419:         raise NetworkTimeout(msg) from error
  420:     elif isinstance(error, SSLError) and "timed out" in str(error):
  421:         # Eventlet does not distinguish TLS network timeouts from other
  422:         # SSLErrors (https://github.com/eventlet/eventlet/issues/692).
  423:         # Luckily, we can work around this limitation because the phrase
  424:         # 'timed out' appears in all the timeout related SSLErrors raised.
  425:         raise NetworkTimeout(msg) from error
  426:     else:
  427:         raise AutoReconnect(msg) from error
  428: 
  429: 
  430: def _cond_wait(condition: threading.Condition, deadline: Optional[float]) -> bool:
  431:     timeout = deadline - time.monotonic() if deadline else None
  432:     return condition.wait(timeout)
  433: 
  434: 
  435: def _get_timeout_details(options: PoolOptions) -> dict[str, float]:
  436:     details = {}
  437:     timeout = _csot.get_timeout()
  438:     socket_timeout = options.socket_timeout
  439:     connect_timeout = options.connect_timeout
  440:     if timeout:
  441:         details["timeoutMS"] = timeout * 1000
  442:     if socket_timeout and not timeout:
  443:         details["socketTimeoutMS"] = socket_timeout * 1000
  444:     if connect_timeout:
  445:         details["connectTimeoutMS"] = connect_timeout * 1000
  446:     return details
  447: 
  448: 
  449: def format_timeout_details(details: Optional[dict[str, float]]) -> str:
  450:     result = ""
  451:     if details:
  452:         result += " (configured timeouts:"
  453:         for timeout in ["socketTimeoutMS", "timeoutMS", "connectTimeoutMS"]:
  454:             if timeout in details:
  455:                 result += f" {timeout}: {details[timeout]}ms,"
  456:         result = result[:-1]
  457:         result += ")"
  458:     return result
  459: 
  460: 
  461: class PoolOptions:
  462:     """Read only connection pool options for a MongoClient.
  463: 
  464:     Should not be instantiated directly by application developers. Access
  465:     a client's pool options via
  466:     :attr:`~pymongo.client_options.ClientOptions.pool_options` instead::
  467: 
  468:       pool_opts = client.options.pool_options
  469:       pool_opts.max_pool_size
  470:       pool_opts.min_pool_size
  471: 
  472:     """
  473: 
  474:     __slots__ = (
  475:         "__max_pool_size",
  476:         "__min_pool_size",
  477:         "__max_idle_time_seconds",
  478:         "__connect_timeout",
  479:         "__socket_timeout",
  480:         "__wait_queue_timeout",
  481:         "__ssl_context",
  482:         "__tls_allow_invalid_hostnames",
  483:         "__event_listeners",
  484:         "__appname",
  485:         "__driver",
  486:         "__metadata",
  487:         "__compression_settings",
  488:         "__max_connecting",
  489:         "__pause_enabled",
  490:         "__server_api",
  491:         "__load_balanced",
  492:         "__credentials",
  493:     )
  494: 
  495:     def __init__(
  496:         self,
  497:         max_pool_size: int = MAX_POOL_SIZE,
  498:         min_pool_size: int = MIN_POOL_SIZE,
  499:         max_idle_time_seconds: Optional[int] = MAX_IDLE_TIME_SEC,
  500:         connect_timeout: Optional[float] = None,
  501:         socket_timeout: Optional[float] = None,
  502:         wait_queue_timeout: Optional[int] = WAIT_QUEUE_TIMEOUT,
  503:         ssl_context: Optional[SSLContext] = None,
  504:         tls_allow_invalid_hostnames: bool = False,
  505:         event_listeners: Optional[_EventListeners] = None,
  506:         appname: Optional[str] = None,
  507:         driver: Optional[DriverInfo] = None,
  508:         compression_settings: Optional[CompressionSettings] = None,
  509:         max_connecting: int = MAX_CONNECTING,
  510:         pause_enabled: bool = True,
  511:         server_api: Optional[ServerApi] = None,
  512:         load_balanced: Optional[bool] = None,
  513:         credentials: Optional[MongoCredential] = None,
  514:     ):
  515:         self.__max_pool_size = max_pool_size
  516:         self.__min_pool_size = min_pool_size
  517:         self.__max_idle_time_seconds = max_idle_time_seconds
  518:         self.__connect_timeout = connect_timeout
  519:         self.__socket_timeout = socket_timeout
  520:         self.__wait_queue_timeout = wait_queue_timeout
  521:         self.__ssl_context = ssl_context
  522:         self.__tls_allow_invalid_hostnames = tls_allow_invalid_hostnames
  523:         self.__event_listeners = event_listeners
  524:         self.__appname = appname
  525:         self.__driver = driver
  526:         self.__compression_settings = compression_settings
  527:         self.__max_connecting = max_connecting
  528:         self.__pause_enabled = pause_enabled
  529:         self.__server_api = server_api
  530:         self.__load_balanced = load_balanced
  531:         self.__credentials = credentials
  532:         self.__metadata = copy.deepcopy(_METADATA)
  533:         if appname:
  534:             self.__metadata["application"] = {"name": appname}
  535: 
  536:         # Combine the "driver" MongoClient option with PyMongo's info, like:
  537:         # {
  538:         #    'driver': {
  539:         #        'name': 'PyMongo|MyDriver',
  540:         #        'version': '4.2.0|1.2.3',
  541:         #    },
  542:         #    'platform': 'CPython 3.8.0|MyPlatform'
  543:         # }
  544:         if driver:
  545:             if driver.name:
  546:                 self.__metadata["driver"]["name"] = "{}|{}".format(
  547:                     _METADATA["driver"]["name"],
  548:                     driver.name,
  549:                 )
  550:             if driver.version:
  551:                 self.__metadata["driver"]["version"] = "{}|{}".format(
  552:                     _METADATA["driver"]["version"],
  553:                     driver.version,
  554:                 )
  555:             if driver.platform:
  556:                 self.__metadata["platform"] = "{}|{}".format(_METADATA["platform"], driver.platform)
  557: 
  558:         env = _metadata_env()
  559:         if env:
  560:             self.__metadata["env"] = env
  561: 
  562:         _truncate_metadata(self.__metadata)
  563: 
  564:     @property
  565:     def _credentials(self) -> Optional[MongoCredential]:
  566:         """A :class:`~pymongo.auth.MongoCredentials` instance or None."""
  567:         return self.__credentials
  568: 
  569:     @property
  570:     def non_default_options(self) -> dict[str, Any]:
  571:         """The non-default options this pool was created with.
  572: 
  573:         Added for CMAP's :class:`PoolCreatedEvent`.
  574:         """
  575:         opts = {}
  576:         if self.__max_pool_size != MAX_POOL_SIZE:
  577:             opts["maxPoolSize"] = self.__max_pool_size
  578:         if self.__min_pool_size != MIN_POOL_SIZE:
  579:             opts["minPoolSize"] = self.__min_pool_size
  580:         if self.__max_idle_time_seconds != MAX_IDLE_TIME_SEC:
  581:             assert self.__max_idle_time_seconds is not None
  582:             opts["maxIdleTimeMS"] = self.__max_idle_time_seconds * 1000
  583:         if self.__wait_queue_timeout != WAIT_QUEUE_TIMEOUT:
  584:             assert self.__wait_queue_timeout is not None
  585:             opts["waitQueueTimeoutMS"] = self.__wait_queue_timeout * 1000
  586:         if self.__max_connecting != MAX_CONNECTING:
  587:             opts["maxConnecting"] = self.__max_connecting
  588:         return opts
  589: 
  590:     @property
  591:     def max_pool_size(self) -> float:
  592:         """The maximum allowable number of concurrent connections to each
  593:         connected server. Requests to a server will block if there are
  594:         `maxPoolSize` outstanding connections to the requested server.
  595:         Defaults to 100. Cannot be 0.
  596: 
  597:         When a server's pool has reached `max_pool_size`, operations for that
  598:         server block waiting for a socket to be returned to the pool. If
  599:         ``waitQueueTimeoutMS`` is set, a blocked operation will raise
  600:         :exc:`~pymongo.errors.ConnectionFailure` after a timeout.
  601:         By default ``waitQueueTimeoutMS`` is not set.
  602:         """
  603:         return self.__max_pool_size
  604: 
  605:     @property
  606:     def min_pool_size(self) -> int:
  607:         """The minimum required number of concurrent connections that the pool
  608:         will maintain to each connected server. Default is 0.
  609:         """
  610:         return self.__min_pool_size
  611: 
  612:     @property
  613:     def max_connecting(self) -> int:
  614:         """The maximum number of concurrent connection creation attempts per
  615:         pool. Defaults to 2.
  616:         """
  617:         return self.__max_connecting
  618: 
  619:     @property
  620:     def pause_enabled(self) -> bool:
  621:         return self.__pause_enabled
  622: 
  623:     @property
  624:     def max_idle_time_seconds(self) -> Optional[int]:
  625:         """The maximum number of seconds that a connection can remain
  626:         idle in the pool before being removed and replaced. Defaults to
  627:         `None` (no limit).
  628:         """
  629:         return self.__max_idle_time_seconds
  630: 
  631:     @property
  632:     def connect_timeout(self) -> Optional[float]:
  633:         """How long a connection can take to be opened before timing out."""
  634:         return self.__connect_timeout
  635: 
  636:     @property
  637:     def socket_timeout(self) -> Optional[float]:
  638:         """How long a send or receive on a socket can take before timing out."""
  639:         return self.__socket_timeout
  640: 
  641:     @property
  642:     def wait_queue_timeout(self) -> Optional[int]:
  643:         """How long a thread will wait for a socket from the pool if the pool
  644:         has no free sockets.
  645:         """
  646:         return self.__wait_queue_timeout
  647: 
  648:     @property
  649:     def _ssl_context(self) -> Optional[SSLContext]:
  650:         """An SSLContext instance or None."""
  651:         return self.__ssl_context
  652: 
  653:     @property
  654:     def tls_allow_invalid_hostnames(self) -> bool:
  655:         """If True skip ssl.match_hostname."""
  656:         return self.__tls_allow_invalid_hostnames
  657: 
  658:     @property
  659:     def _event_listeners(self) -> Optional[_EventListeners]:
  660:         """An instance of pymongo.monitoring._EventListeners."""
  661:         return self.__event_listeners
  662: 
  663:     @property
  664:     def appname(self) -> Optional[str]:
  665:         """The application name, for sending with hello in server handshake."""
  666:         return self.__appname
  667: 
  668:     @property
  669:     def driver(self) -> Optional[DriverInfo]:
  670:         """Driver name and version, for sending with hello in handshake."""
  671:         return self.__driver
  672: 
  673:     @property
  674:     def _compression_settings(self) -> Optional[CompressionSettings]:
  675:         return self.__compression_settings
  676: 
  677:     @property
  678:     def metadata(self) -> dict[str, Any]:
  679:         """A dict of metadata about the application, driver, os, and platform."""
  680:         return self.__metadata.copy()
  681: 
  682:     @property
  683:     def server_api(self) -> Optional[ServerApi]:
  684:         """A pymongo.server_api.ServerApi or None."""
  685:         return self.__server_api
  686: 
  687:     @property
  688:     def load_balanced(self) -> Optional[bool]:
  689:         """True if this Pool is configured in load balanced mode."""
  690:         return self.__load_balanced
  691: 
  692: 
  693: class _CancellationContext:
  694:     def __init__(self) -> None:
  695:         self._cancelled = False
  696: 
  697:     def cancel(self) -> None:
  698:         """Cancel this context."""
  699:         self._cancelled = True
  700: 
  701:     @property
  702:     def cancelled(self) -> bool:
  703:         """Was cancel called?"""
  704:         return self._cancelled
  705: 
  706: 
  707: class Connection:
  708:     """Store a connection with some metadata.
  709: 
  710:     :param conn: a raw connection object
  711:     :param pool: a Pool instance
  712:     :param address: the server's (host, port)
  713:     :param id: the id of this socket in it's pool
  714:     """
  715: 
  716:     def __init__(
  717:         self, conn: Union[socket.socket, _sslConn], pool: Pool, address: tuple[str, int], id: int
  718:     ):
  719:         self.pool_ref = weakref.ref(pool)
  720:         self.conn = conn
  721:         self.address = address
  722:         self.id = id
  723:         self.closed = False
  724:         self.last_checkin_time = time.monotonic()
  725:         self.performed_handshake = False
  726:         self.is_writable: bool = False
  727:         self.max_wire_version = MAX_WIRE_VERSION
  728:         self.max_bson_size = MAX_BSON_SIZE
  729:         self.max_message_size = MAX_MESSAGE_SIZE
  730:         self.max_write_batch_size = MAX_WRITE_BATCH_SIZE
  731:         self.supports_sessions = False
  732:         self.hello_ok: bool = False
  733:         self.is_mongos = False
  734:         self.op_msg_enabled = False
  735:         self.listeners = pool.opts._event_listeners
  736:         self.enabled_for_cmap = pool.enabled_for_cmap
  737:         self.enabled_for_logging = pool.enabled_for_logging
  738:         self.compression_settings = pool.opts._compression_settings
  739:         self.compression_context: Union[SnappyContext, ZlibContext, ZstdContext, None] = None
  740:         self.socket_checker: SocketChecker = SocketChecker()
  741:         self.oidc_token_gen_id: Optional[int] = None
  742:         # Support for mechanism negotiation on the initial handshake.
  743:         self.negotiated_mechs: Optional[list[str]] = None
  744:         self.auth_ctx: Optional[_AuthContext] = None
  745: 
  746:         # The pool's generation changes with each reset() so we can close
  747:         # sockets created before the last reset.
  748:         self.pool_gen = pool.gen
  749:         self.generation = self.pool_gen.get_overall()
  750:         self.ready = False
  751:         self.cancel_context: _CancellationContext = _CancellationContext()
  752:         self.opts = pool.opts
  753:         self.more_to_come: bool = False
  754:         # For load balancer support.
  755:         self.service_id: Optional[ObjectId] = None
  756:         self.server_connection_id: Optional[int] = None
  757:         # When executing a transaction in load balancing mode, this flag is
  758:         # set to true to indicate that the session now owns the connection.
  759:         self.pinned_txn = False
  760:         self.pinned_cursor = False
  761:         self.active = False
  762:         self.last_timeout = self.opts.socket_timeout
  763:         self.connect_rtt = 0.0
  764:         self._client_id = pool._client_id
  765:         self.creation_time = time.monotonic()
  766: 
  767:     def set_conn_timeout(self, timeout: Optional[float]) -> None:
  768:         """Cache last timeout to avoid duplicate calls to conn.settimeout."""
  769:         if timeout == self.last_timeout:
  770:             return
  771:         self.last_timeout = timeout
  772:         self.conn.settimeout(timeout)
  773: 
  774:     def apply_timeout(
  775:         self, client: MongoClient, cmd: Optional[MutableMapping[str, Any]]
  776:     ) -> Optional[float]:
  777:         # CSOT: use remaining timeout when set.
  778:         timeout = _csot.remaining()
  779:         if timeout is None:
  780:             # Reset the socket timeout unless we're performing a streaming monitor check.
  781:             if not self.more_to_come:
  782:                 self.set_conn_timeout(self.opts.socket_timeout)
  783:             return None
  784:         # RTT validation.
  785:         rtt = _csot.get_rtt()
  786:         if rtt is None:
  787:             rtt = self.connect_rtt
  788:         max_time_ms = timeout - rtt
  789:         if max_time_ms < 0:
  790:             timeout_details = _get_timeout_details(self.opts)
  791:             formatted = format_timeout_details(timeout_details)
  792:             # CSOT: raise an error without running the command since we know it will time out.
  793:             errmsg = f"operation would exceed time limit, remaining timeout:{timeout:.5f} <= network round trip time:{rtt:.5f} {formatted}"
  794:             raise ExecutionTimeout(
  795:                 errmsg,
  796:                 50,
  797:                 {"ok": 0, "errmsg": errmsg, "code": 50},
  798:                 self.max_wire_version,
  799:             )
  800:         if cmd is not None:
  801:             cmd["maxTimeMS"] = int(max_time_ms * 1000)
  802:         self.set_conn_timeout(timeout)
  803:         return timeout
  804: 
  805:     def pin_txn(self) -> None:
  806:         self.pinned_txn = True
  807:         assert not self.pinned_cursor
  808: 
  809:     def pin_cursor(self) -> None:
  810:         self.pinned_cursor = True
  811:         assert not self.pinned_txn
  812: 
  813:     def unpin(self) -> None:
  814:         pool = self.pool_ref()
  815:         if pool:
  816:             pool.checkin(self)
  817:         else:
  818:             self.close_conn(ConnectionClosedReason.STALE)
  819: 
  820:     def hello_cmd(self) -> dict[str, Any]:
  821:         # Handshake spec requires us to use OP_MSG+hello command for the
  822:         # initial handshake in load balanced or stable API mode.
  823:         if self.opts.server_api or self.hello_ok or self.opts.load_balanced:
  824:             self.op_msg_enabled = True
  825:             return {HelloCompat.CMD: 1}
  826:         else:
  827:             return {HelloCompat.LEGACY_CMD: 1, "helloOk": True}
  828: 
  829:     def hello(self) -> Hello[dict[str, Any]]:
  830:         return self._hello(None, None, None)
  831: 
  832:     def _hello(
  833:         self,
  834:         cluster_time: Optional[ClusterTime],
  835:         topology_version: Optional[Any],
  836:         heartbeat_frequency: Optional[int],
  837:     ) -> Hello[dict[str, Any]]:
  838:         cmd = self.hello_cmd()
  839:         performing_handshake = not self.performed_handshake
  840:         awaitable = False
  841:         if performing_handshake:
  842:             self.performed_handshake = True
  843:             cmd["client"] = self.opts.metadata
  844:             if self.compression_settings:
  845:                 cmd["compression"] = self.compression_settings.compressors
  846:             if self.opts.load_balanced:
  847:                 cmd["loadBalanced"] = True
  848:         elif topology_version is not None:
  849:             cmd["topologyVersion"] = topology_version
  850:             assert heartbeat_frequency is not None
  851:             cmd["maxAwaitTimeMS"] = int(heartbeat_frequency * 1000)
  852:             awaitable = True
  853:             # If connect_timeout is None there is no timeout.
  854:             if self.opts.connect_timeout:
  855:                 self.set_conn_timeout(self.opts.connect_timeout + heartbeat_frequency)
  856: 
  857:         if not performing_handshake and cluster_time is not None:
  858:             cmd["$clusterTime"] = cluster_time
  859: 
  860:         creds = self.opts._credentials
  861:         if creds:
  862:             if creds.mechanism == "DEFAULT" and creds.username:
  863:                 cmd["saslSupportedMechs"] = creds.source + "." + creds.username
  864:             from pymongo import auth
  865: 
  866:             auth_ctx = auth._AuthContext.from_credentials(creds, self.address)
  867:             if auth_ctx:
  868:                 speculative_authenticate = auth_ctx.speculate_command()
  869:                 if speculative_authenticate is not None:
  870:                     cmd["speculativeAuthenticate"] = speculative_authenticate
  871:         else:
  872:             auth_ctx = None
  873: 
  874:         if performing_handshake:
  875:             start = time.monotonic()
  876:         doc = self.command("admin", cmd, publish_events=False, exhaust_allowed=awaitable)
  877:         if performing_handshake:
  878:             self.connect_rtt = time.monotonic() - start
  879:         hello = Hello(doc, awaitable=awaitable)
  880:         self.is_writable = hello.is_writable
  881:         self.max_wire_version = hello.max_wire_version
  882:         self.max_bson_size = hello.max_bson_size
  883:         self.max_message_size = hello.max_message_size
  884:         self.max_write_batch_size = hello.max_write_batch_size
  885:         self.supports_sessions = (
  886:             hello.logical_session_timeout_minutes is not None and hello.is_readable
  887:         )
  888:         self.logical_session_timeout_minutes: Optional[int] = hello.logical_session_timeout_minutes
  889:         self.hello_ok = hello.hello_ok
  890:         self.is_repl = hello.server_type in (
  891:             SERVER_TYPE.RSPrimary,
  892:             SERVER_TYPE.RSSecondary,
  893:             SERVER_TYPE.RSArbiter,
  894:             SERVER_TYPE.RSOther,
  895:             SERVER_TYPE.RSGhost,
  896:         )
  897:         self.is_standalone = hello.server_type == SERVER_TYPE.Standalone
  898:         self.is_mongos = hello.server_type == SERVER_TYPE.Mongos
  899:         if performing_handshake and self.compression_settings:
  900:             ctx = self.compression_settings.get_compression_context(hello.compressors)
  901:             self.compression_context = ctx
  902: 
  903:         self.op_msg_enabled = True
  904:         self.server_connection_id = hello.connection_id
  905:         if creds:
  906:             self.negotiated_mechs = hello.sasl_supported_mechs
  907:         if auth_ctx:
  908:             auth_ctx.parse_response(hello)  # type:ignore[arg-type]
  909:             if auth_ctx.speculate_succeeded():
  910:                 self.auth_ctx = auth_ctx
  911:         if self.opts.load_balanced:
  912:             if not hello.service_id:
  913:                 raise ConfigurationError(
  914:                     "Driver attempted to initialize in load balancing mode,"
  915:                     " but the server does not support this mode"
  916:                 )
  917:             self.service_id = hello.service_id
  918:             self.generation = self.pool_gen.get(self.service_id)
  919:         return hello
  920: 
  921:     def _next_reply(self) -> dict[str, Any]:
  922:         reply = self.receive_message(None)
  923:         self.more_to_come = reply.more_to_come
  924:         unpacked_docs = reply.unpack_response()
  925:         response_doc = unpacked_docs[0]
  926:         helpers._check_command_response(response_doc, self.max_wire_version)
  927:         return response_doc
  928: 
  929:     @_handle_reauth
  930:     def command(
  931:         self,
  932:         dbname: str,
  933:         spec: MutableMapping[str, Any],
  934:         read_preference: _ServerMode = ReadPreference.PRIMARY,
  935:         codec_options: CodecOptions = DEFAULT_CODEC_OPTIONS,
  936:         check: bool = True,
  937:         allowable_errors: Optional[Sequence[Union[str, int]]] = None,
  938:         read_concern: Optional[ReadConcern] = None,
  939:         write_concern: Optional[WriteConcern] = None,
  940:         parse_write_concern_error: bool = False,
  941:         collation: Optional[_CollationIn] = None,
  942:         session: Optional[ClientSession] = None,
  943:         client: Optional[MongoClient] = None,
  944:         retryable_write: bool = False,
  945:         publish_events: bool = True,
  946:         user_fields: Optional[Mapping[str, Any]] = None,
  947:         exhaust_allowed: bool = False,
  948:     ) -> dict[str, Any]:
  949:         """Execute a command or raise an error.
  950: 
  951:         :param dbname: name of the database on which to run the command
  952:         :param spec: a command document as a dict, SON, or mapping object
  953:         :param read_preference: a read preference
  954:         :param codec_options: a CodecOptions instance
  955:         :param check: raise OperationFailure if there are errors
  956:         :param allowable_errors: errors to ignore if `check` is True
  957:         :param read_concern: The read concern for this command.
  958:         :param write_concern: The write concern for this command.
  959:         :param parse_write_concern_error: Whether to parse the
  960:             ``writeConcernError`` field in the command response.
  961:         :param collation: The collation for this command.
  962:         :param session: optional ClientSession instance.
  963:         :param client: optional MongoClient for gossipping $clusterTime.
  964:         :param retryable_write: True if this command is a retryable write.
  965:         :param publish_events: Should we publish events for this command?
  966:         :param user_fields: Response fields that should be decoded
  967:             using the TypeDecoders from codec_options, passed to
  968:             bson._decode_all_selective.
  969:         """
  970:         self.validate_session(client, session)
  971:         session = _validate_session_write_concern(session, write_concern)
  972: 
  973:         # Ensure command name remains in first place.
  974:         if not isinstance(spec, ORDERED_TYPES):  # type:ignore[arg-type]
  975:             spec = dict(spec)
  976: 
  977:         if not (write_concern is None or write_concern.acknowledged or collation is None):
  978:             raise ConfigurationError("Collation is unsupported for unacknowledged writes.")
  979: 
  980:         self.add_server_api(spec)
  981:         if session:
  982:             session._apply_to(spec, retryable_write, read_preference, self)
  983:         self.send_cluster_time(spec, session, client)
  984:         listeners = self.listeners if publish_events else None
  985:         unacknowledged = bool(write_concern and not write_concern.acknowledged)
  986:         if self.op_msg_enabled:
  987:             self._raise_if_not_writable(unacknowledged)
  988:         try:
  989:             return command(
  990:                 self,
  991:                 dbname,
  992:                 spec,
  993:                 self.is_mongos,
  994:                 read_preference,
  995:                 codec_options,
  996:                 session,
  997:                 client,
  998:                 check,
  999:                 allowable_errors,
 1000:                 self.address,
 1001:                 listeners,
 1002:                 self.max_bson_size,
 1003:                 read_concern,
 1004:                 parse_write_concern_error=parse_write_concern_error,
 1005:                 collation=collation,
 1006:                 compression_ctx=self.compression_context,
 1007:                 use_op_msg=self.op_msg_enabled,
 1008:                 unacknowledged=unacknowledged,
 1009:                 user_fields=user_fields,
 1010:                 exhaust_allowed=exhaust_allowed,
 1011:                 write_concern=write_concern,
 1012:             )
 1013:         except (OperationFailure, NotPrimaryError):
 1014:             raise
 1015:         # Catch socket.error, KeyboardInterrupt, etc. and close ourselves.
 1016:         except BaseException as error:
 1017:             self._raise_connection_failure(error)
 1018: 
 1019:     def send_message(self, message: bytes, max_doc_size: int) -> None:
 1020:         """Send a raw BSON message or raise ConnectionFailure.
 1021: 
 1022:         If a network exception is raised, the socket is closed.
 1023:         """
 1024:         if self.max_bson_size is not None and max_doc_size > self.max_bson_size:
 1025:             raise DocumentTooLarge(
 1026:                 "BSON document too large (%d bytes) - the connected server "
 1027:                 "supports BSON document sizes up to %d bytes." % (max_doc_size, self.max_bson_size)
 1028:             )
 1029: 
 1030:         try:
 1031:             self.conn.sendall(message)
 1032:         except BaseException as error:
 1033:             self._raise_connection_failure(error)
 1034: 
 1035:     def receive_message(self, request_id: Optional[int]) -> Union[_OpReply, _OpMsg]:
 1036:         """Receive a raw BSON message or raise ConnectionFailure.
 1037: 
 1038:         If any exception is raised, the socket is closed.
 1039:         """
 1040:         try:
 1041:             return receive_message(self, request_id, self.max_message_size)
 1042:         except BaseException as error:
 1043:             self._raise_connection_failure(error)
 1044: 
 1045:     def _raise_if_not_writable(self, unacknowledged: bool) -> None:
 1046:         """Raise NotPrimaryError on unacknowledged write if this socket is not
 1047:         writable.
 1048:         """
 1049:         if unacknowledged and not self.is_writable:
 1050:             # Write won't succeed, bail as if we'd received a not primary error.
 1051:             raise NotPrimaryError("not primary", {"ok": 0, "errmsg": "not primary", "code": 10107})
 1052: 
 1053:     def unack_write(self, msg: bytes, max_doc_size: int) -> None:
 1054:         """Send unack OP_MSG.
 1055: 
 1056:         Can raise ConnectionFailure or InvalidDocument.
 1057: 
 1058:         :param msg: bytes, an OP_MSG message.
 1059:         :param max_doc_size: size in bytes of the largest document in `msg`.
 1060:         """
 1061:         self._raise_if_not_writable(True)
 1062:         self.send_message(msg, max_doc_size)
 1063: 
 1064:     def write_command(
 1065:         self, request_id: int, msg: bytes, codec_options: CodecOptions
 1066:     ) -> dict[str, Any]:
 1067:         """Send "insert" etc. command, returning response as a dict.
 1068: 
 1069:         Can raise ConnectionFailure or OperationFailure.
 1070: 
 1071:         :param request_id: an int.
 1072:         :param msg: bytes, the command message.
 1073:         """
 1074:         self.send_message(msg, 0)
 1075:         reply = self.receive_message(request_id)
 1076:         result = reply.command_response(codec_options)
 1077: 
 1078:         # Raises NotPrimaryError or OperationFailure.
 1079:         helpers._check_command_response(result, self.max_wire_version)
 1080:         return result
 1081: 
 1082:     def authenticate(self, reauthenticate: bool = False) -> None:
 1083:         """Authenticate to the server if needed.
 1084: 
 1085:         Can raise ConnectionFailure or OperationFailure.
 1086:         """
 1087:         # CMAP spec says to publish the ready event only after authenticating
 1088:         # the connection.
 1089:         if reauthenticate:
 1090:             if self.performed_handshake:
 1091:                 # Existing auth_ctx is stale, remove it.
 1092:                 self.auth_ctx = None
 1093:             self.ready = False
 1094:         if not self.ready:
 1095:             creds = self.opts._credentials
 1096:             if creds:
 1097:                 from pymongo import auth
 1098: 
 1099:                 auth.authenticate(creds, self, reauthenticate=reauthenticate)
 1100:             self.ready = True
 1101:             duration = time.monotonic() - self.creation_time
 1102:             if self.enabled_for_cmap:
 1103:                 assert self.listeners is not None
 1104:                 self.listeners.publish_connection_ready(self.address, self.id, duration)
 1105:             if self.enabled_for_logging and _CONNECTION_LOGGER.isEnabledFor(logging.DEBUG):
 1106:                 _debug_log(
 1107:                     _CONNECTION_LOGGER,
 1108:                     clientId=self._client_id,
 1109:                     message=_ConnectionStatusMessage.CONN_READY,
 1110:                     serverHost=self.address[0],
 1111:                     serverPort=self.address[1],
 1112:                     driverConnectionId=self.id,
 1113:                     durationMS=duration,
 1114:                 )
 1115: 
 1116:     def validate_session(
 1117:         self, client: Optional[MongoClient], session: Optional[ClientSession]
 1118:     ) -> None:
 1119:         """Validate this session before use with client.
 1120: 
 1121:         Raises error if the client is not the one that created the session.
 1122:         """
 1123:         if session:
 1124:             if session._client is not client:
 1125:                 raise InvalidOperation("Can only use session with the MongoClient that started it")
 1126: 
 1127:     def close_conn(self, reason: Optional[str]) -> None:
 1128:         """Close this connection with a reason."""
 1129:         if self.closed:
 1130:             return
 1131:         self._close_conn()
 1132:         if reason:
 1133:             if self.enabled_for_cmap:
 1134:                 assert self.listeners is not None
 1135:                 self.listeners.publish_connection_closed(self.address, self.id, reason)
 1136:             if self.enabled_for_logging and _CONNECTION_LOGGER.isEnabledFor(logging.DEBUG):
 1137:                 _debug_log(
 1138:                     _CONNECTION_LOGGER,
 1139:                     clientId=self._client_id,
 1140:                     message=_ConnectionStatusMessage.CONN_CLOSED,
 1141:                     serverHost=self.address[0],
 1142:                     serverPort=self.address[1],
 1143:                     driverConnectionId=self.id,
 1144:                     reason=_verbose_connection_error_reason(reason),
 1145:                     error=reason,
 1146:                 )
 1147: 
 1148:     def _close_conn(self) -> None:
 1149:         """Close this connection."""
 1150:         if self.closed:
 1151:             return
 1152:         self.closed = True
 1153:         self.cancel_context.cancel()
 1154:         # Note: We catch exceptions to avoid spurious errors on interpreter
 1155:         # shutdown.
 1156:         try:
 1157:             self.conn.close()
 1158:         except Exception:  # noqa: S110
 1159:             pass
 1160: 
 1161:     def conn_closed(self) -> bool:
 1162:         """Return True if we know socket has been closed, False otherwise."""
 1163:         return self.socket_checker.socket_closed(self.conn)
 1164: 
 1165:     def send_cluster_time(
 1166:         self,
 1167:         command: MutableMapping[str, Any],
 1168:         session: Optional[ClientSession],
 1169:         client: Optional[MongoClient],
 1170:     ) -> None:
 1171:         """Add $clusterTime."""
 1172:         if client:
 1173:             client._send_cluster_time(command, session)
 1174: 
 1175:     def add_server_api(self, command: MutableMapping[str, Any]) -> None:
 1176:         """Add server_api parameters."""
 1177:         if self.opts.server_api:
 1178:             _add_to_command(command, self.opts.server_api)
 1179: 
 1180:     def update_last_checkin_time(self) -> None:
 1181:         self.last_checkin_time = time.monotonic()
 1182: 
 1183:     def update_is_writable(self, is_writable: bool) -> None:
 1184:         self.is_writable = is_writable
 1185: 
 1186:     def idle_time_seconds(self) -> float:
 1187:         """Seconds since this socket was last checked into its pool."""
 1188:         return time.monotonic() - self.last_checkin_time
 1189: 
 1190:     def _raise_connection_failure(self, error: BaseException) -> NoReturn:
 1191:         # Catch *all* exceptions from socket methods and close the socket. In
 1192:         # regular Python, socket operations only raise socket.error, even if
 1193:         # the underlying cause was a Ctrl-C: a signal raised during socket.recv
 1194:         # is expressed as an EINTR error from poll. See internal_select_ex() in
 1195:         # socketmodule.c. All error codes from poll become socket.error at
 1196:         # first. Eventually in PyEval_EvalFrameEx the interpreter checks for
 1197:         # signals and throws KeyboardInterrupt into the current frame on the
 1198:         # main thread.
 1199:         #
 1200:         # But in Gevent and Eventlet, the polling mechanism (epoll, kqueue,
 1201:         # ..) is called in Python code, which experiences the signal as a
 1202:         # KeyboardInterrupt from the start, rather than as an initial
 1203:         # socket.error, so we catch that, close the socket, and reraise it.
 1204:         #
 1205:         # The connection closed event will be emitted later in checkin.
 1206:         if self.ready:
 1207:             reason = None
 1208:         else:
 1209:             reason = ConnectionClosedReason.ERROR
 1210:         self.close_conn(reason)
 1211:         # SSLError from PyOpenSSL inherits directly from Exception.
 1212:         if isinstance(error, (IOError, OSError, SSLError)):
 1213:             details = _get_timeout_details(self.opts)
 1214:             _raise_connection_failure(self.address, error, timeout_details=details)
 1215:         else:
 1216:             raise
 1217: 
 1218:     def __eq__(self, other: Any) -> bool:
 1219:         return self.conn == other.conn
 1220: 
 1221:     def __ne__(self, other: Any) -> bool:
 1222:         return not self == other
 1223: 
 1224:     def __hash__(self) -> int:
 1225:         return hash(self.conn)
 1226: 
 1227:     def __repr__(self) -> str:
 1228:         return "Connection({}){} at {}".format(
 1229:             repr(self.conn),
 1230:             self.closed and " CLOSED" or "",
 1231:             id(self),
 1232:         )
 1233: 
 1234: 
 1235: def _create_connection(address: _Address, options: PoolOptions) -> socket.socket:
 1236:     """Given (host, port) and PoolOptions, connect and return a socket object.
 1237: 
 1238:     Can raise socket.error.
 1239: 
 1240:     This is a modified version of create_connection from CPython >= 2.7.
 1241:     """
 1242:     host, port = address
 1243: 
 1244:     # Check if dealing with a unix domain socket
 1245:     if host.endswith(".sock"):
 1246:         if not hasattr(socket, "AF_UNIX"):
 1247:             raise ConnectionFailure("UNIX-sockets are not supported on this system")
 1248:         sock = socket.socket(socket.AF_UNIX)
 1249:         # SOCK_CLOEXEC not supported for Unix sockets.
 1250:         _set_non_inheritable_non_atomic(sock.fileno())
 1251:         try:
 1252:             sock.connect(host)
 1253:             return sock
 1254:         except OSError:
 1255:             sock.close()
 1256:             raise
 1257: 
 1258:     # Don't try IPv6 if we don't support it. Also skip it if host
 1259:     # is 'localhost' (::1 is fine). Avoids slow connect issues
 1260:     # like PYTHON-356.
 1261:     family = socket.AF_INET
 1262:     if socket.has_ipv6 and host != "localhost":
 1263:         family = socket.AF_UNSPEC
 1264: 
 1265:     err = None
 1266:     for res in socket.getaddrinfo(host, port, family, socket.SOCK_STREAM):
 1267:         af, socktype, proto, dummy, sa = res
 1268:         # SOCK_CLOEXEC was new in CPython 3.2, and only available on a limited
 1269:         # number of platforms (newer Linux and *BSD). Starting with CPython 3.4
 1270:         # all file descriptors are created non-inheritable. See PEP 446.
 1271:         try:
 1272:             sock = socket.socket(af, socktype | getattr(socket, "SOCK_CLOEXEC", 0), proto)
 1273:         except OSError:
 1274:             # Can SOCK_CLOEXEC be defined even if the kernel doesn't support
 1275:             # it?
 1276:             sock = socket.socket(af, socktype, proto)
 1277:         # Fallback when SOCK_CLOEXEC isn't available.
 1278:         _set_non_inheritable_non_atomic(sock.fileno())
 1279:         try:
 1280:             sock.setsockopt(socket.IPPROTO_TCP, socket.TCP_NODELAY, 1)
 1281:             # CSOT: apply timeout to socket connect.
 1282:             timeout = _csot.remaining()
 1283:             if timeout is None:
 1284:                 timeout = options.connect_timeout
 1285:             elif timeout <= 0:
 1286:                 raise socket.timeout("timed out")
 1287:             sock.settimeout(timeout)
 1288:             sock.setsockopt(socket.SOL_SOCKET, socket.SO_KEEPALIVE, True)
 1289:             _set_keepalive_times(sock)
 1290:             sock.connect(sa)
 1291:             return sock
 1292:         except OSError as e:
 1293:             err = e
 1294:             sock.close()
 1295: 
 1296:     if err is not None:
 1297:         raise err
 1298:     else:
 1299:         # This likely means we tried to connect to an IPv6 only
 1300:         # host with an OS/kernel or Python interpreter that doesn't
 1301:         # support IPv6. The test case is Jython2.5.1 which doesn't
 1302:         # support IPv6 at all.
 1303:         raise OSError("getaddrinfo failed")
 1304: 
 1305: 
 1306: def _configured_socket(address: _Address, options: PoolOptions) -> Union[socket.socket, _sslConn]:
 1307:     """Given (host, port) and PoolOptions, return a configured socket.
 1308: 
 1309:     Can raise socket.error, ConnectionFailure, or _CertificateError.
 1310: 
 1311:     Sets socket's SSL and timeout options.
 1312:     """
 1313:     sock = _create_connection(address, options)
 1314:     ssl_context = options._ssl_context
 1315: 
 1316:     if ssl_context is None:
 1317:         sock.settimeout(options.socket_timeout)
 1318:         return sock
 1319: 
 1320:     host = address[0]
 1321:     try:
 1322:         # We have to pass hostname / ip address to wrap_socket
 1323:         # to use SSLContext.check_hostname.
 1324:         if HAS_SNI:
 1325:             ssl_sock = ssl_context.wrap_socket(sock, server_hostname=host)
 1326:         else:
 1327:             ssl_sock = ssl_context.wrap_socket(sock)
 1328:     except _CertificateError:
 1329:         sock.close()
 1330:         # Raise _CertificateError directly like we do after match_hostname
 1331:         # below.
 1332:         raise
 1333:     except (OSError, SSLError) as exc:
 1334:         sock.close()
 1335:         # We raise AutoReconnect for transient and permanent SSL handshake
 1336:         # failures alike. Permanent handshake failures, like protocol
 1337:         # mismatch, will be turned into ServerSelectionTimeoutErrors later.
 1338:         details = _get_timeout_details(options)
 1339:         _raise_connection_failure(address, exc, "SSL handshake failed: ", timeout_details=details)
 1340:     if (
 1341:         ssl_context.verify_mode
 1342:         and not ssl_context.check_hostname
 1343:         and not options.tls_allow_invalid_hostnames
 1344:     ):
 1345:         try:
 1346:             ssl.match_hostname(ssl_sock.getpeercert(), hostname=host)
 1347:         except _CertificateError:
 1348:             ssl_sock.close()
 1349:             raise
 1350: 
 1351:     ssl_sock.settimeout(options.socket_timeout)
 1352:     return ssl_sock
 1353: 
 1354: 
 1355: class _PoolClosedError(PyMongoError):
 1356:     """Internal error raised when a thread tries to get a connection from a
 1357:     closed pool.
 1358:     """
 1359: 
 1360: 
 1361: class _PoolGeneration:
 1362:     def __init__(self) -> None:
 1363:         # Maps service_id to generation.
 1364:         self._generations: dict[ObjectId, int] = collections.defaultdict(int)
 1365:         # Overall pool generation.
 1366:         self._generation = 0
 1367: 
 1368:     def get(self, service_id: Optional[ObjectId]) -> int:
 1369:         """Get the generation for the given service_id."""
 1370:         if service_id is None:
 1371:             return self._generation
 1372:         return self._generations[service_id]
 1373: 
 1374:     def get_overall(self) -> int:
 1375:         """Get the Pool's overall generation."""
 1376:         return self._generation
 1377: 
 1378:     def inc(self, service_id: Optional[ObjectId]) -> None:
 1379:         """Increment the generation for the given service_id."""
 1380:         self._generation += 1
 1381:         if service_id is None:
 1382:             for service_id in self._generations:
 1383:                 self._generations[service_id] += 1
 1384:         else:
 1385:             self._generations[service_id] += 1
 1386: 
 1387:     def stale(self, gen: int, service_id: Optional[ObjectId]) -> bool:
 1388:         """Return if the given generation for a given service_id is stale."""
 1389:         return gen != self.get(service_id)
 1390: 
 1391: 
 1392: class PoolState:
 1393:     PAUSED = 1
 1394:     READY = 2
 1395:     CLOSED = 3
 1396: 
 1397: 
 1398: # Do *not* explicitly inherit from object or Jython won't call __del__
 1399: # http://bugs.jython.org/issue1057
 1400: class Pool:
 1401:     def __init__(
 1402:         self,
 1403:         address: _Address,
 1404:         options: PoolOptions,
 1405:         handshake: bool = True,
 1406:         client_id: Optional[ObjectId] = None,
 1407:     ):
 1408:         """
 1409:         :param address: a (hostname, port) tuple
 1410:         :param options: a PoolOptions instance
 1411:         :param handshake: whether to call hello for each new Connection
 1412:         """
 1413:         if options.pause_enabled:
 1414:             self.state = PoolState.PAUSED
 1415:         else:
 1416:             self.state = PoolState.READY
 1417:         # Check a socket's health with socket_closed() every once in a while.
 1418:         # Can override for testing: 0 to always check, None to never check.
 1419:         self._check_interval_seconds = 1
 1420:         # LIFO pool. Sockets are ordered on idle time. Sockets claimed
 1421:         # and returned to pool from the left side. Stale sockets removed
 1422:         # from the right side.
 1423:         self.conns: collections.deque = collections.deque()
 1424:         self.active_contexts: set[_CancellationContext] = set()
 1425:         self.lock = _create_lock()
 1426:         self.active_sockets = 0
 1427:         # Monotonically increasing connection ID required for CMAP Events.
 1428:         self.next_connection_id = 1
 1429:         # Track whether the sockets in this pool are writeable or not.
 1430:         self.is_writable: Optional[bool] = None
 1431: 
 1432:         # Keep track of resets, so we notice sockets created before the most
 1433:         # recent reset and close them.
 1434:         # self.generation = 0
 1435:         self.gen = _PoolGeneration()
 1436:         self.pid = os.getpid()
 1437:         self.address = address
 1438:         self.opts = options
 1439:         self.handshake = handshake
 1440:         # Don't publish events in Monitor pools.
 1441:         self.enabled_for_cmap = (
 1442:             self.handshake
 1443:             and self.opts._event_listeners is not None
 1444:             and self.opts._event_listeners.enabled_for_cmap
 1445:         )
 1446:         self.enabled_for_logging = self.handshake
 1447: 
 1448:         # The first portion of the wait queue.
 1449:         # Enforces: maxPoolSize
 1450:         # Also used for: clearing the wait queue
 1451:         self.size_cond = threading.Condition(self.lock)
 1452:         self.requests = 0
 1453:         self.max_pool_size = self.opts.max_pool_size
 1454:         if not self.max_pool_size:
 1455:             self.max_pool_size = float("inf")
 1456:         # The second portion of the wait queue.
 1457:         # Enforces: maxConnecting
 1458:         # Also used for: clearing the wait queue
 1459:         self._max_connecting_cond = threading.Condition(self.lock)
 1460:         self._max_connecting = self.opts.max_connecting
 1461:         self._pending = 0
 1462:         self._client_id = client_id
 1463:         if self.enabled_for_cmap:
 1464:             assert self.opts._event_listeners is not None
 1465:             self.opts._event_listeners.publish_pool_created(
 1466:                 self.address, self.opts.non_default_options
 1467:             )
 1468:         if self.enabled_for_logging and _CONNECTION_LOGGER.isEnabledFor(logging.DEBUG):
 1469:             _debug_log(
 1470:                 _CONNECTION_LOGGER,
 1471:                 clientId=self._client_id,
 1472:                 message=_ConnectionStatusMessage.POOL_CREATED,
 1473:                 serverHost=self.address[0],
 1474:                 serverPort=self.address[1],
 1475:                 **self.opts.non_default_options,
 1476:             )
 1477:         # Similar to active_sockets but includes threads in the wait queue.
 1478:         self.operation_count: int = 0
 1479:         # Retain references to pinned connections to prevent the CPython GC
 1480:         # from thinking that a cursor's pinned connection can be GC'd when the
 1481:         # cursor is GC'd (see PYTHON-2751).
 1482:         self.__pinned_sockets: set[Connection] = set()
 1483:         self.ncursors = 0
 1484:         self.ntxns = 0
 1485: 
 1486:     def ready(self) -> None:
 1487:         # Take the lock to avoid the race condition described in PYTHON-2699.
 1488:         with self.lock:
 1489:             if self.state != PoolState.READY:
 1490:                 self.state = PoolState.READY
 1491:                 if self.enabled_for_cmap:
 1492:                     assert self.opts._event_listeners is not None
 1493:                     self.opts._event_listeners.publish_pool_ready(self.address)
 1494:                 if self.enabled_for_logging and _CONNECTION_LOGGER.isEnabledFor(logging.DEBUG):
 1495:                     _debug_log(
 1496:                         _CONNECTION_LOGGER,
 1497:                         clientId=self._client_id,
 1498:                         message=_ConnectionStatusMessage.POOL_READY,
 1499:                         serverHost=self.address[0],
 1500:                         serverPort=self.address[1],
 1501:                     )
 1502: 
 1503:     @property
 1504:     def closed(self) -> bool:
 1505:         return self.state == PoolState.CLOSED
 1506: 
 1507:     def _reset(
 1508:         self,
 1509:         close: bool,
 1510:         pause: bool = True,
 1511:         service_id: Optional[ObjectId] = None,
 1512:         interrupt_connections: bool = False,
 1513:     ) -> None:
 1514:         old_state = self.state
 1515:         with self.size_cond:
 1516:             if self.closed:
 1517:                 return
 1518:             if self.opts.pause_enabled and pause and not self.opts.load_balanced:
 1519:                 old_state, self.state = self.state, PoolState.PAUSED
 1520:             self.gen.inc(service_id)
 1521:             newpid = os.getpid()
 1522:             if self.pid != newpid:
 1523:                 self.pid = newpid
 1524:                 self.active_sockets = 0
 1525:                 self.operation_count = 0
 1526:             if service_id is None:
 1527:                 sockets, self.conns = self.conns, collections.deque()
 1528:             else:
 1529:                 discard: collections.deque = collections.deque()
 1530:                 keep: collections.deque = collections.deque()
 1531:                 for conn in self.conns:
 1532:                     if conn.service_id == service_id:
 1533:                         discard.append(conn)
 1534:                     else:
 1535:                         keep.append(conn)
 1536:                 sockets = discard
 1537:                 self.conns = keep
 1538: 
 1539:             if close:
 1540:                 self.state = PoolState.CLOSED
 1541:             # Clear the wait queue
 1542:             self._max_connecting_cond.notify_all()
 1543:             self.size_cond.notify_all()
 1544: 
 1545:             if interrupt_connections:
 1546:                 for context in self.active_contexts:
 1547:                     context.cancel()
 1548: 
 1549:         listeners = self.opts._event_listeners
 1550:         # CMAP spec says that close() MUST close sockets before publishing the
 1551:         # PoolClosedEvent but that reset() SHOULD close sockets *after*
 1552:         # publishing the PoolClearedEvent.
 1553:         if close:
 1554:             for conn in sockets:
 1555:                 conn.close_conn(ConnectionClosedReason.POOL_CLOSED)
 1556:             if self.enabled_for_cmap:
 1557:                 assert listeners is not None
 1558:                 listeners.publish_pool_closed(self.address)
 1559:             if self.enabled_for_logging and _CONNECTION_LOGGER.isEnabledFor(logging.DEBUG):
 1560:                 _debug_log(
 1561:                     _CONNECTION_LOGGER,
 1562:                     clientId=self._client_id,
 1563:                     message=_ConnectionStatusMessage.POOL_CLOSED,
 1564:                     serverHost=self.address[0],
 1565:                     serverPort=self.address[1],
 1566:                 )
 1567:         else:
 1568:             if old_state != PoolState.PAUSED:
 1569:                 if self.enabled_for_cmap:
 1570:                     assert listeners is not None
 1571:                     listeners.publish_pool_cleared(
 1572:                         self.address,
 1573:                         service_id=service_id,
 1574:                         interrupt_connections=interrupt_connections,
 1575:                     )
 1576:                 if self.enabled_for_logging and _CONNECTION_LOGGER.isEnabledFor(logging.DEBUG):
 1577:                     _debug_log(
 1578:                         _CONNECTION_LOGGER,
 1579:                         clientId=self._client_id,
 1580:                         message=_ConnectionStatusMessage.POOL_CLEARED,
 1581:                         serverHost=self.address[0],
 1582:                         serverPort=self.address[1],
 1583:                         serviceId=service_id,
 1584:                     )
 1585:             for conn in sockets:
 1586:                 conn.close_conn(ConnectionClosedReason.STALE)
 1587: 
 1588:     def update_is_writable(self, is_writable: Optional[bool]) -> None:
 1589:         """Updates the is_writable attribute on all sockets currently in the
 1590:         Pool.
 1591:         """
 1592:         self.is_writable = is_writable
 1593:         with self.lock:
 1594:             for _socket in self.conns:
 1595:                 _socket.update_is_writable(self.is_writable)
 1596: 
 1597:     def reset(
 1598:         self, service_id: Optional[ObjectId] = None, interrupt_connections: bool = False
 1599:     ) -> None:
 1600:         self._reset(close=False, service_id=service_id, interrupt_connections=interrupt_connections)
 1601: 
 1602:     def reset_without_pause(self) -> None:
 1603:         self._reset(close=False, pause=False)
 1604: 
 1605:     def close(self) -> None:
 1606:         self._reset(close=True)
 1607: 
 1608:     def stale_generation(self, gen: int, service_id: Optional[ObjectId]) -> bool:
 1609:         return self.gen.stale(gen, service_id)
 1610: 
 1611:     def remove_stale_sockets(self, reference_generation: int) -> None:
 1612:         """Removes stale sockets then adds new ones if pool is too small and
 1613:         has not been reset. The `reference_generation` argument specifies the
 1614:         `generation` at the point in time this operation was requested on the
 1615:         pool.
 1616:         """
 1617:         # Take the lock to avoid the race condition described in PYTHON-2699.
 1618:         with self.lock:
 1619:             if self.state != PoolState.READY:
 1620:                 return
 1621: 
 1622:         if self.opts.max_idle_time_seconds is not None:
 1623:             with self.lock:
 1624:                 while (
 1625:                     self.conns
 1626:                     and self.conns[-1].idle_time_seconds() > self.opts.max_idle_time_seconds
 1627:                 ):
 1628:                     conn = self.conns.pop()
 1629:                     conn.close_conn(ConnectionClosedReason.IDLE)
 1630: 
 1631:         while True:
 1632:             with self.size_cond:
 1633:                 # There are enough sockets in the pool.
 1634:                 if len(self.conns) + self.active_sockets >= self.opts.min_pool_size:
 1635:                     return
 1636:                 if self.requests >= self.opts.min_pool_size:
 1637:                     return
 1638:                 self.requests += 1
 1639:             incremented = False
 1640:             try:
 1641:                 with self._max_connecting_cond:
 1642:                     # If maxConnecting connections are already being created
 1643:                     # by this pool then try again later instead of waiting.
 1644:                     if self._pending >= self._max_connecting:
 1645:                         return
 1646:                     self._pending += 1
 1647:                     incremented = True
 1648:                 conn = self.connect()
 1649:                 with self.lock:
 1650:                     # Close connection and return if the pool was reset during
 1651:                     # socket creation or while acquiring the pool lock.
 1652:                     if self.gen.get_overall() != reference_generation:
 1653:                         conn.close_conn(ConnectionClosedReason.STALE)
 1654:                         return
 1655:                     self.conns.appendleft(conn)
 1656:                     self.active_contexts.discard(conn.cancel_context)
 1657:             finally:
 1658:                 if incremented:
 1659:                     # Notify after adding the socket to the pool.
 1660:                     with self._max_connecting_cond:
 1661:                         self._pending -= 1
 1662:                         self._max_connecting_cond.notify()
 1663: 
 1664:                 with self.size_cond:
 1665:                     self.requests -= 1
 1666:                     self.size_cond.notify()
 1667: 
 1668:     def connect(self, handler: Optional[_MongoClientErrorHandler] = None) -> Connection:
 1669:         """Connect to Mongo and return a new Connection.
 1670: 
 1671:         Can raise ConnectionFailure.
 1672: 
 1673:         Note that the pool does not keep a reference to the socket -- you
 1674:         must call checkin() when you're done with it.
 1675:         """
 1676:         with self.lock:
 1677:             conn_id = self.next_connection_id
 1678:             self.next_connection_id += 1
 1679: 
 1680:         listeners = self.opts._event_listeners
 1681:         if self.enabled_for_cmap:
 1682:             assert listeners is not None
 1683:             listeners.publish_connection_created(self.address, conn_id)
 1684:         if self.enabled_for_logging and _CONNECTION_LOGGER.isEnabledFor(logging.DEBUG):
 1685:             _debug_log(
 1686:                 _CONNECTION_LOGGER,
 1687:                 clientId=self._client_id,
 1688:                 message=_ConnectionStatusMessage.CONN_CREATED,
 1689:                 serverHost=self.address[0],
 1690:                 serverPort=self.address[1],
 1691:                 driverConnectionId=conn_id,
 1692:             )
 1693: 
 1694:         try:
 1695:             sock = _configured_socket(self.address, self.opts)
 1696:         except BaseException as error:
 1697:             if self.enabled_for_cmap:
 1698:                 assert listeners is not None
 1699:                 listeners.publish_connection_closed(
 1700:                     self.address, conn_id, ConnectionClosedReason.ERROR
 1701:                 )
 1702:             if self.enabled_for_logging and _CONNECTION_LOGGER.isEnabledFor(logging.DEBUG):
 1703:                 _debug_log(
 1704:                     _CONNECTION_LOGGER,
 1705:                     clientId=self._client_id,
 1706:                     message=_ConnectionStatusMessage.CONN_CLOSED,
 1707:                     serverHost=self.address[0],
 1708:                     serverPort=self.address[1],
 1709:                     driverConnectionId=conn_id,
 1710:                     reason=_verbose_connection_error_reason(ConnectionClosedReason.ERROR),
 1711:                     error=ConnectionClosedReason.ERROR,
 1712:                 )
 1713:             if isinstance(error, (IOError, OSError, SSLError)):
 1714:                 details = _get_timeout_details(self.opts)
 1715:                 _raise_connection_failure(self.address, error, timeout_details=details)
 1716: 
 1717:             raise
 1718: 
 1719:         conn = Connection(sock, self, self.address, conn_id)  # type: ignore[arg-type]
 1720:         with self.lock:
 1721:             self.active_contexts.add(conn.cancel_context)
 1722:         try:
 1723:             if self.handshake:
 1724:                 conn.hello()
 1725:                 self.is_writable = conn.is_writable
 1726:             if handler:
 1727:                 handler.contribute_socket(conn, completed_handshake=False)
 1728: 
 1729:             conn.authenticate()
 1730:         except BaseException:
 1731:             conn.close_conn(ConnectionClosedReason.ERROR)
 1732:             raise
 1733: 
 1734:         return conn
 1735: 
 1736:     @contextlib.contextmanager
 1737:     def checkout(self, handler: Optional[_MongoClientErrorHandler] = None) -> Iterator[Connection]:
 1738:         """Get a connection from the pool. Use with a "with" statement.
 1739: 
 1740:         Returns a :class:`Connection` object wrapping a connected
 1741:         :class:`socket.socket`.
 1742: 
 1743:         This method should always be used in a with-statement::
 1744: 
 1745:             with pool.get_conn() as connection:
 1746:                 connection.send_message(msg)
 1747:                 data = connection.receive_message(op_code, request_id)
 1748: 
 1749:         Can raise ConnectionFailure or OperationFailure.
 1750: 
 1751:         :param handler: A _MongoClientErrorHandler.
 1752:         """
 1753:         listeners = self.opts._event_listeners
 1754:         checkout_started_time = time.monotonic()
 1755:         if self.enabled_for_cmap:
 1756:             assert listeners is not None
 1757:             listeners.publish_connection_check_out_started(self.address)
 1758:         if self.enabled_for_logging and _CONNECTION_LOGGER.isEnabledFor(logging.DEBUG):
 1759:             _debug_log(
 1760:                 _CONNECTION_LOGGER,
 1761:                 clientId=self._client_id,
 1762:                 message=_ConnectionStatusMessage.CHECKOUT_STARTED,
 1763:                 serverHost=self.address[0],
 1764:                 serverPort=self.address[1],
 1765:             )
 1766: 
 1767:         conn = self._get_conn(checkout_started_time, handler=handler)
 1768: 
 1769:         duration = time.monotonic() - checkout_started_time
 1770:         if self.enabled_for_cmap:
 1771:             assert listeners is not None
 1772:             listeners.publish_connection_checked_out(self.address, conn.id, duration)
 1773:         if self.enabled_for_logging and _CONNECTION_LOGGER.isEnabledFor(logging.DEBUG):
 1774:             _debug_log(
 1775:                 _CONNECTION_LOGGER,
 1776:                 clientId=self._client_id,
 1777:                 message=_ConnectionStatusMessage.CHECKOUT_SUCCEEDED,
 1778:                 serverHost=self.address[0],
 1779:                 serverPort=self.address[1],
 1780:                 driverConnectionId=conn.id,
 1781:                 durationMS=duration,
 1782:             )
 1783:         try:
 1784:             with self.lock:
 1785:                 self.active_contexts.add(conn.cancel_context)
 1786:             yield conn
 1787:         except BaseException:
 1788:             # Exception in caller. Ensure the connection gets returned.
 1789:             # Note that when pinned is True, the session owns the
 1790:             # connection and it is responsible for checking the connection
 1791:             # back into the pool.
 1792:             pinned = conn.pinned_txn or conn.pinned_cursor
 1793:             if handler:
 1794:                 # Perform SDAM error handling rules while the connection is
 1795:                 # still checked out.
 1796:                 exc_type, exc_val, _ = sys.exc_info()
 1797:                 handler.handle(exc_type, exc_val)
 1798:             if not pinned and conn.active:
 1799:                 self.checkin(conn)
 1800:             raise
 1801:         if conn.pinned_txn:
 1802:             with self.lock:
 1803:                 self.__pinned_sockets.add(conn)
 1804:                 self.ntxns += 1
 1805:         elif conn.pinned_cursor:
 1806:             with self.lock:
 1807:                 self.__pinned_sockets.add(conn)
 1808:                 self.ncursors += 1
 1809:         elif conn.active:
 1810:             self.checkin(conn)
 1811: 
 1812:     def _raise_if_not_ready(self, checkout_started_time: float, emit_event: bool) -> None:
 1813:         if self.state != PoolState.READY:
 1814:             if emit_event:
 1815:                 duration = time.monotonic() - checkout_started_time
 1816:                 if self.enabled_for_cmap:
 1817:                     assert self.opts._event_listeners is not None
 1818:                     self.opts._event_listeners.publish_connection_check_out_failed(
 1819:                         self.address, ConnectionCheckOutFailedReason.CONN_ERROR, duration
 1820:                     )
 1821:                 if self.enabled_for_logging and _CONNECTION_LOGGER.isEnabledFor(logging.DEBUG):
 1822:                     _debug_log(
 1823:                         _CONNECTION_LOGGER,
 1824:                         clientId=self._client_id,
 1825:                         message=_ConnectionStatusMessage.CHECKOUT_FAILED,
 1826:                         serverHost=self.address[0],
 1827:                         serverPort=self.address[1],
 1828:                         reason="An error occurred while trying to establish a new connection",
 1829:                         error=ConnectionCheckOutFailedReason.CONN_ERROR,
 1830:                         durationMS=duration,
 1831:                     )
 1832: 
 1833:             details = _get_timeout_details(self.opts)
 1834:             _raise_connection_failure(
 1835:                 self.address, AutoReconnect("connection pool paused"), timeout_details=details
 1836:             )
 1837: 
 1838:     def _get_conn(
 1839:         self, checkout_started_time: float, handler: Optional[_MongoClientErrorHandler] = None
 1840:     ) -> Connection:
 1841:         """Get or create a Connection. Can raise ConnectionFailure."""
 1842:         # We use the pid here to avoid issues with fork / multiprocessing.
 1843:         # See test.test_client:TestClient.test_fork for an example of
 1844:         # what could go wrong otherwise
 1845:         if self.pid != os.getpid():
 1846:             self.reset_without_pause()
 1847: 
 1848:         if self.closed:
 1849:             duration = time.monotonic() - checkout_started_time
 1850:             if self.enabled_for_cmap:
 1851:                 assert self.opts._event_listeners is not None
 1852:                 self.opts._event_listeners.publish_connection_check_out_failed(
 1853:                     self.address, ConnectionCheckOutFailedReason.POOL_CLOSED, duration
 1854:                 )
 1855:             if self.enabled_for_logging and _CONNECTION_LOGGER.isEnabledFor(logging.DEBUG):
 1856:                 _debug_log(
 1857:                     _CONNECTION_LOGGER,
 1858:                     clientId=self._client_id,
 1859:                     message=_ConnectionStatusMessage.CHECKOUT_FAILED,
 1860:                     serverHost=self.address[0],
 1861:                     serverPort=self.address[1],
 1862:                     reason="Connection pool was closed",
 1863:                     error=ConnectionCheckOutFailedReason.POOL_CLOSED,
 1864:                     durationMS=duration,
 1865:                 )
 1866:             raise _PoolClosedError(
 1867:                 "Attempted to check out a connection from closed connection pool"
 1868:             )
 1869: 
 1870:         with self.lock:
 1871:             self.operation_count += 1
 1872: 
 1873:         # Get a free socket or create one.
 1874:         if _csot.get_timeout():
 1875:             deadline = _csot.get_deadline()
 1876:         elif self.opts.wait_queue_timeout:
 1877:             deadline = time.monotonic() + self.opts.wait_queue_timeout
 1878:         else:
 1879:             deadline = None
 1880: 
 1881:         with self.size_cond:
 1882:             self._raise_if_not_ready(checkout_started_time, emit_event=True)
 1883:             while not (self.requests < self.max_pool_size):
 1884:                 if not _cond_wait(self.size_cond, deadline):
 1885:                     # Timed out, notify the next thread to ensure a
 1886:                     # timeout doesn't consume the condition.
 1887:                     if self.requests < self.max_pool_size:
 1888:                         self.size_cond.notify()
 1889:                     self._raise_wait_queue_timeout(checkout_started_time)
 1890:                 self._raise_if_not_ready(checkout_started_time, emit_event=True)
 1891:             self.requests += 1
 1892: 
 1893:         # We've now acquired the semaphore and must release it on error.
 1894:         conn = None
 1895:         incremented = False
 1896:         emitted_event = False
 1897:         try:
 1898:             with self.lock:
 1899:                 self.active_sockets += 1
 1900:                 incremented = True
 1901:             while conn is None:
 1902:                 # CMAP: we MUST wait for either maxConnecting OR for a socket
 1903:                 # to be checked back into the pool.
 1904:                 with self._max_connecting_cond:
 1905:                     self._raise_if_not_ready(checkout_started_time, emit_event=False)
 1906:                     while not (self.conns or self._pending < self._max_connecting):
 1907:                         if not _cond_wait(self._max_connecting_cond, deadline):
 1908:                             # Timed out, notify the next thread to ensure a
 1909:                             # timeout doesn't consume the condition.
 1910:                             if self.conns or self._pending < self._max_connecting:
 1911:                                 self._max_connecting_cond.notify()
 1912:                             emitted_event = True
 1913:                             self._raise_wait_queue_timeout(checkout_started_time)
 1914:                         self._raise_if_not_ready(checkout_started_time, emit_event=False)
 1915: 
 1916:                     try:
 1917:                         conn = self.conns.popleft()
 1918:                     except IndexError:
 1919:                         self._pending += 1
 1920:                 if conn:  # We got a socket from the pool
 1921:                     if self._perished(conn):
 1922:                         conn = None
 1923:                         continue
 1924:                 else:  # We need to create a new connection
 1925:                     try:
 1926:                         conn = self.connect(handler=handler)
 1927:                     finally:
 1928:                         with self._max_connecting_cond:
 1929:                             self._pending -= 1
 1930:                             self._max_connecting_cond.notify()
 1931:         except BaseException:
 1932:             if conn:
 1933:                 # We checked out a socket but authentication failed.
 1934:                 conn.close_conn(ConnectionClosedReason.ERROR)
 1935:             with self.size_cond:
 1936:                 self.requests -= 1
 1937:                 if incremented:
 1938:                     self.active_sockets -= 1
 1939:                 self.size_cond.notify()
 1940: 
 1941:             if not emitted_event:
 1942:                 duration = time.monotonic() - checkout_started_time
 1943:                 if self.enabled_for_cmap:
 1944:                     assert self.opts._event_listeners is not None
 1945:                     self.opts._event_listeners.publish_connection_check_out_failed(
 1946:                         self.address, ConnectionCheckOutFailedReason.CONN_ERROR, duration
 1947:                     )
 1948:                 if self.enabled_for_logging and _CONNECTION_LOGGER.isEnabledFor(logging.DEBUG):
 1949:                     _debug_log(
 1950:                         _CONNECTION_LOGGER,
 1951:                         clientId=self._client_id,
 1952:                         message=_ConnectionStatusMessage.CHECKOUT_FAILED,
 1953:                         serverHost=self.address[0],
 1954:                         serverPort=self.address[1],
 1955:                         reason="An error occurred while trying to establish a new connection",
 1956:                         error=ConnectionCheckOutFailedReason.CONN_ERROR,
 1957:                         durationMS=duration,
 1958:                     )
 1959:             raise
 1960: 
 1961:         conn.active = True
 1962:         return conn
 1963: 
 1964:     def checkin(self, conn: Connection) -> None:
 1965:         """Return the connection to the pool, or if it's closed discard it.
 1966: 
 1967:         :param conn: The connection to check into the pool.
 1968:         """
 1969:         txn = conn.pinned_txn
 1970:         cursor = conn.pinned_cursor
 1971:         conn.active = False
 1972:         conn.pinned_txn = False
 1973:         conn.pinned_cursor = False
 1974:         self.__pinned_sockets.discard(conn)
 1975:         listeners = self.opts._event_listeners
 1976:         with self.lock:
 1977:             self.active_contexts.discard(conn.cancel_context)
 1978:         if self.enabled_for_cmap:
 1979:             assert listeners is not None
 1980:             listeners.publish_connection_checked_in(self.address, conn.id)
 1981:         if self.enabled_for_logging and _CONNECTION_LOGGER.isEnabledFor(logging.DEBUG):
 1982:             _debug_log(
 1983:                 _CONNECTION_LOGGER,
 1984:                 clientId=self._client_id,
 1985:                 message=_ConnectionStatusMessage.CHECKEDIN,
 1986:                 serverHost=self.address[0],
 1987:                 serverPort=self.address[1],
 1988:                 driverConnectionId=conn.id,
 1989:             )
 1990:         if self.pid != os.getpid():
 1991:             self.reset_without_pause()
 1992:         else:
 1993:             if self.closed:
 1994:                 conn.close_conn(ConnectionClosedReason.POOL_CLOSED)
 1995:             elif conn.closed:
 1996:                 # CMAP requires the closed event be emitted after the check in.
 1997:                 if self.enabled_for_cmap:
 1998:                     assert listeners is not None
 1999:                     listeners.publish_connection_closed(
 2000:                         self.address, conn.id, ConnectionClosedReason.ERROR
 2001:                     )
 2002:                 if self.enabled_for_logging and _CONNECTION_LOGGER.isEnabledFor(logging.DEBUG):
 2003:                     _debug_log(
 2004:                         _CONNECTION_LOGGER,
 2005:                         clientId=self._client_id,
 2006:                         message=_ConnectionStatusMessage.CONN_CLOSED,
 2007:                         serverHost=self.address[0],
 2008:                         serverPort=self.address[1],
 2009:                         driverConnectionId=conn.id,
 2010:                         reason=_verbose_connection_error_reason(ConnectionClosedReason.ERROR),
 2011:                         error=ConnectionClosedReason.ERROR,
 2012:                     )
 2013:             else:
 2014:                 with self.lock:
 2015:                     # Hold the lock to ensure this section does not race with
 2016:                     # Pool.reset().
 2017:                     if self.stale_generation(conn.generation, conn.service_id):
 2018:                         conn.close_conn(ConnectionClosedReason.STALE)
 2019:                     else:
 2020:                         conn.update_last_checkin_time()
 2021:                         conn.update_is_writable(bool(self.is_writable))
 2022:                         self.conns.appendleft(conn)
 2023:                         # Notify any threads waiting to create a connection.
 2024:                         self._max_connecting_cond.notify()
 2025: 
 2026:         with self.size_cond:
 2027:             if txn:
 2028:                 self.ntxns -= 1
 2029:             elif cursor:
 2030:                 self.ncursors -= 1
 2031:             self.requests -= 1
 2032:             self.active_sockets -= 1
 2033:             self.operation_count -= 1
 2034:             self.size_cond.notify()
 2035: 
 2036:     def _perished(self, conn: Connection) -> bool:
 2037:         """Return True and close the connection if it is "perished".
 2038: 
 2039:         This side-effecty function checks if this socket has been idle for
 2040:         for longer than the max idle time, or if the socket has been closed by
 2041:         some external network error, or if the socket's generation is outdated.
 2042: 
 2043:         Checking sockets lets us avoid seeing *some*
 2044:         :class:`~pymongo.errors.AutoReconnect` exceptions on server
 2045:         hiccups, etc. We only check if the socket was closed by an external
 2046:         error if it has been > 1 second since the socket was checked into the
 2047:         pool, to keep performance reasonable - we can't avoid AutoReconnects
 2048:         completely anyway.
 2049:         """
 2050:         idle_time_seconds = conn.idle_time_seconds()
 2051:         # If socket is idle, open a new one.
 2052:         if (
 2053:             self.opts.max_idle_time_seconds is not None
 2054:             and idle_time_seconds > self.opts.max_idle_time_seconds
 2055:         ):
 2056:             conn.close_conn(ConnectionClosedReason.IDLE)
 2057:             return True
 2058: 
 2059:         if self._check_interval_seconds is not None and (
 2060:             self._check_interval_seconds == 0 or idle_time_seconds > self._check_interval_seconds
 2061:         ):
 2062:             if conn.conn_closed():
 2063:                 conn.close_conn(ConnectionClosedReason.ERROR)
 2064:                 return True
 2065: 
 2066:         if self.stale_generation(conn.generation, conn.service_id):
 2067:             conn.close_conn(ConnectionClosedReason.STALE)
 2068:             return True
 2069: 
 2070:         return False
 2071: 
 2072:     def _raise_wait_queue_timeout(self, checkout_started_time: float) -> NoReturn:
 2073:         listeners = self.opts._event_listeners
 2074:         duration = time.monotonic() - checkout_started_time
 2075:         if self.enabled_for_cmap:
 2076:             assert listeners is not None
 2077:             listeners.publish_connection_check_out_failed(
 2078:                 self.address, ConnectionCheckOutFailedReason.TIMEOUT, duration
 2079:             )
 2080:         if self.enabled_for_logging and _CONNECTION_LOGGER.isEnabledFor(logging.DEBUG):
 2081:             _debug_log(
 2082:                 _CONNECTION_LOGGER,
 2083:                 clientId=self._client_id,
 2084:                 message=_ConnectionStatusMessage.CHECKOUT_FAILED,
 2085:                 serverHost=self.address[0],
 2086:                 serverPort=self.address[1],
 2087:                 reason="Wait queue timeout elapsed without a connection becoming available",
 2088:                 error=ConnectionCheckOutFailedReason.TIMEOUT,
 2089:                 durationMS=duration,
 2090:             )
 2091:         timeout = _csot.get_timeout() or self.opts.wait_queue_timeout
 2092:         if self.opts.load_balanced:
 2093:             other_ops = self.active_sockets - self.ncursors - self.ntxns
 2094:             raise WaitQueueTimeoutError(
 2095:                 "Timeout waiting for connection from the connection pool. "
 2096:                 "maxPoolSize: {}, connections in use by cursors: {}, "
 2097:                 "connections in use by transactions: {}, connections in use "
 2098:                 "by other operations: {}, timeout: {}".format(
 2099:                     self.opts.max_pool_size,
 2100:                     self.ncursors,
 2101:                     self.ntxns,
 2102:                     other_ops,
 2103:                     timeout,
 2104:                 )
 2105:             )
 2106:         raise WaitQueueTimeoutError(
 2107:             "Timed out while checking out a connection from connection pool. "
 2108:             f"maxPoolSize: {self.opts.max_pool_size}, timeout: {timeout}"
 2109:         )
 2110: 
 2111:     def __del__(self) -> None:
 2112:         # Avoid ResourceWarnings in Python 3
 2113:         # Close all sockets without calling reset() or close() because it is
 2114:         # not safe to acquire a lock in __del__.
 2115:         for conn in self.conns:
 2116:             conn.close_conn(None)
