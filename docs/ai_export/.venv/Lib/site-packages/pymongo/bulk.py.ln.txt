    1: # Copyright 2014-present MongoDB, Inc.
    2: #
    3: # Licensed under the Apache License, Version 2.0 (the "License");
    4: # you may not use this file except in compliance with the License.
    5: # You may obtain a copy of the License at
    6: #
    7: # http://www.apache.org/licenses/LICENSE-2.0
    8: #
    9: # Unless required by applicable law or agreed to in writing, software
   10: # distributed under the License is distributed on an "AS IS" BASIS,
   11: # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   12: # See the License for the specific language governing permissions and
   13: # limitations under the License.
   14: 
   15: """The bulk write operations interface.
   16: 
   17: .. versionadded:: 2.7
   18: """
   19: from __future__ import annotations
   20: 
   21: import copy
   22: from collections.abc import MutableMapping
   23: from itertools import islice
   24: from typing import (
   25:     TYPE_CHECKING,
   26:     Any,
   27:     Iterator,
   28:     Mapping,
   29:     NoReturn,
   30:     Optional,
   31:     Type,
   32:     Union,
   33: )
   34: 
   35: from bson.objectid import ObjectId
   36: from bson.raw_bson import RawBSONDocument
   37: from pymongo import _csot, common
   38: from pymongo.client_session import ClientSession, _validate_session_write_concern
   39: from pymongo.common import (
   40:     validate_is_document_type,
   41:     validate_ok_for_replace,
   42:     validate_ok_for_update,
   43: )
   44: from pymongo.errors import (
   45:     BulkWriteError,
   46:     ConfigurationError,
   47:     InvalidOperation,
   48:     OperationFailure,
   49: )
   50: from pymongo.helpers import _RETRYABLE_ERROR_CODES, _get_wce_doc
   51: from pymongo.message import (
   52:     _DELETE,
   53:     _INSERT,
   54:     _UPDATE,
   55:     _BulkWriteContext,
   56:     _EncryptedBulkWriteContext,
   57:     _randint,
   58: )
   59: from pymongo.read_preferences import ReadPreference
   60: from pymongo.write_concern import WriteConcern
   61: 
   62: if TYPE_CHECKING:
   63:     from pymongo.collection import Collection
   64:     from pymongo.pool import Connection
   65:     from pymongo.typings import _DocumentOut, _DocumentType, _Pipeline
   66: 
   67: _DELETE_ALL: int = 0
   68: _DELETE_ONE: int = 1
   69: 
   70: # For backwards compatibility. See MongoDB src/mongo/base/error_codes.err
   71: _BAD_VALUE: int = 2
   72: _UNKNOWN_ERROR: int = 8
   73: _WRITE_CONCERN_ERROR: int = 64
   74: 
   75: _COMMANDS: tuple[str, str, str] = ("insert", "update", "delete")
   76: 
   77: 
   78: class _Run:
   79:     """Represents a batch of write operations."""
   80: 
   81:     def __init__(self, op_type: int) -> None:
   82:         """Initialize a new Run object."""
   83:         self.op_type: int = op_type
   84:         self.index_map: list[int] = []
   85:         self.ops: list[Any] = []
   86:         self.idx_offset: int = 0
   87: 
   88:     def index(self, idx: int) -> int:
   89:         """Get the original index of an operation in this run.
   90: 
   91:         :param idx: The Run index that maps to the original index.
   92:         """
   93:         return self.index_map[idx]
   94: 
   95:     def add(self, original_index: int, operation: Any) -> None:
   96:         """Add an operation to this Run instance.
   97: 
   98:         :param original_index: The original index of this operation
   99:             within a larger bulk operation.
  100:         :param operation: The operation document.
  101:         """
  102:         self.index_map.append(original_index)
  103:         self.ops.append(operation)
  104: 
  105: 
  106: def _merge_command(
  107:     run: _Run,
  108:     full_result: MutableMapping[str, Any],
  109:     offset: int,
  110:     result: Mapping[str, Any],
  111: ) -> None:
  112:     """Merge a write command result into the full bulk result."""
  113:     affected = result.get("n", 0)
  114: 
  115:     if run.op_type == _INSERT:
  116:         full_result["nInserted"] += affected
  117: 
  118:     elif run.op_type == _DELETE:
  119:         full_result["nRemoved"] += affected
  120: 
  121:     elif run.op_type == _UPDATE:
  122:         upserted = result.get("upserted")
  123:         if upserted:
  124:             n_upserted = len(upserted)
  125:             for doc in upserted:
  126:                 doc["index"] = run.index(doc["index"] + offset)
  127:             full_result["upserted"].extend(upserted)
  128:             full_result["nUpserted"] += n_upserted
  129:             full_result["nMatched"] += affected - n_upserted
  130:         else:
  131:             full_result["nMatched"] += affected
  132:         full_result["nModified"] += result["nModified"]
  133: 
  134:     write_errors = result.get("writeErrors")
  135:     if write_errors:
  136:         for doc in write_errors:
  137:             # Leave the server response intact for APM.
  138:             replacement = doc.copy()
  139:             idx = doc["index"] + offset
  140:             replacement["index"] = run.index(idx)
  141:             # Add the failed operation to the error document.
  142:             replacement["op"] = run.ops[idx]
  143:             full_result["writeErrors"].append(replacement)
  144: 
  145:     wce = _get_wce_doc(result)
  146:     if wce:
  147:         full_result["writeConcernErrors"].append(wce)
  148: 
  149: 
  150: def _raise_bulk_write_error(full_result: _DocumentOut) -> NoReturn:
  151:     """Raise a BulkWriteError from the full bulk api result."""
  152:     # retryWrites on MMAPv1 should raise an actionable error.
  153:     if full_result["writeErrors"]:
  154:         full_result["writeErrors"].sort(key=lambda error: error["index"])
  155:         err = full_result["writeErrors"][0]
  156:         code = err["code"]
  157:         msg = err["errmsg"]
  158:         if code == 20 and msg.startswith("Transaction numbers"):
  159:             errmsg = (
  160:                 "This MongoDB deployment does not support "
  161:                 "retryable writes. Please add retryWrites=false "
  162:                 "to your connection string."
  163:             )
  164:             raise OperationFailure(errmsg, code, full_result)
  165:     raise BulkWriteError(full_result)
  166: 
  167: 
  168: class _Bulk:
  169:     """The private guts of the bulk write API."""
  170: 
  171:     def __init__(
  172:         self,
  173:         collection: Collection[_DocumentType],
  174:         ordered: bool,
  175:         bypass_document_validation: bool,
  176:         comment: Optional[str] = None,
  177:         let: Optional[Any] = None,
  178:     ) -> None:
  179:         """Initialize a _Bulk instance."""
  180:         self.collection = collection.with_options(
  181:             codec_options=collection.codec_options._replace(
  182:                 unicode_decode_error_handler="replace", document_class=dict
  183:             )
  184:         )
  185:         self.let = let
  186:         if self.let is not None:
  187:             common.validate_is_document_type("let", self.let)
  188:         self.comment: Optional[str] = comment
  189:         self.ordered = ordered
  190:         self.ops: list[tuple[int, Mapping[str, Any]]] = []
  191:         self.executed = False
  192:         self.bypass_doc_val = bypass_document_validation
  193:         self.uses_collation = False
  194:         self.uses_array_filters = False
  195:         self.uses_hint_update = False
  196:         self.uses_hint_delete = False
  197:         self.is_retryable = True
  198:         self.retrying = False
  199:         self.started_retryable_write = False
  200:         # Extra state so that we know where to pick up on a retry attempt.
  201:         self.current_run = None
  202:         self.next_run = None
  203: 
  204:     @property
  205:     def bulk_ctx_class(self) -> Type[_BulkWriteContext]:
  206:         encrypter = self.collection.database.client._encrypter
  207:         if encrypter and not encrypter._bypass_auto_encryption:
  208:             return _EncryptedBulkWriteContext
  209:         else:
  210:             return _BulkWriteContext
  211: 
  212:     def add_insert(self, document: _DocumentOut) -> None:
  213:         """Add an insert document to the list of ops."""
  214:         validate_is_document_type("document", document)
  215:         # Generate ObjectId client side.
  216:         if not (isinstance(document, RawBSONDocument) or "_id" in document):
  217:             document["_id"] = ObjectId()
  218:         self.ops.append((_INSERT, document))
  219: 
  220:     def add_update(
  221:         self,
  222:         selector: Mapping[str, Any],
  223:         update: Union[Mapping[str, Any], _Pipeline],
  224:         multi: bool = False,
  225:         upsert: bool = False,
  226:         collation: Optional[Mapping[str, Any]] = None,
  227:         array_filters: Optional[list[Mapping[str, Any]]] = None,
  228:         hint: Union[str, dict[str, Any], None] = None,
  229:     ) -> None:
  230:         """Create an update document and add it to the list of ops."""
  231:         validate_ok_for_update(update)
  232:         cmd: dict[str, Any] = dict(  # noqa: C406
  233:             [("q", selector), ("u", update), ("multi", multi), ("upsert", upsert)]
  234:         )
  235:         if collation is not None:
  236:             self.uses_collation = True
  237:             cmd["collation"] = collation
  238:         if array_filters is not None:
  239:             self.uses_array_filters = True
  240:             cmd["arrayFilters"] = array_filters
  241:         if hint is not None:
  242:             self.uses_hint_update = True
  243:             cmd["hint"] = hint
  244:         if multi:
  245:             # A bulk_write containing an update_many is not retryable.
  246:             self.is_retryable = False
  247:         self.ops.append((_UPDATE, cmd))
  248: 
  249:     def add_replace(
  250:         self,
  251:         selector: Mapping[str, Any],
  252:         replacement: Mapping[str, Any],
  253:         upsert: bool = False,
  254:         collation: Optional[Mapping[str, Any]] = None,
  255:         hint: Union[str, dict[str, Any], None] = None,
  256:     ) -> None:
  257:         """Create a replace document and add it to the list of ops."""
  258:         validate_ok_for_replace(replacement)
  259:         cmd = {"q": selector, "u": replacement, "multi": False, "upsert": upsert}
  260:         if collation is not None:
  261:             self.uses_collation = True
  262:             cmd["collation"] = collation
  263:         if hint is not None:
  264:             self.uses_hint_update = True
  265:             cmd["hint"] = hint
  266:         self.ops.append((_UPDATE, cmd))
  267: 
  268:     def add_delete(
  269:         self,
  270:         selector: Mapping[str, Any],
  271:         limit: int,
  272:         collation: Optional[Mapping[str, Any]] = None,
  273:         hint: Union[str, dict[str, Any], None] = None,
  274:     ) -> None:
  275:         """Create a delete document and add it to the list of ops."""
  276:         cmd = {"q": selector, "limit": limit}
  277:         if collation is not None:
  278:             self.uses_collation = True
  279:             cmd["collation"] = collation
  280:         if hint is not None:
  281:             self.uses_hint_delete = True
  282:             cmd["hint"] = hint
  283:         if limit == _DELETE_ALL:
  284:             # A bulk_write containing a delete_many is not retryable.
  285:             self.is_retryable = False
  286:         self.ops.append((_DELETE, cmd))
  287: 
  288:     def gen_ordered(self) -> Iterator[Optional[_Run]]:
  289:         """Generate batches of operations, batched by type of
  290:         operation, in the order **provided**.
  291:         """
  292:         run = None
  293:         for idx, (op_type, operation) in enumerate(self.ops):
  294:             if run is None:
  295:                 run = _Run(op_type)
  296:             elif run.op_type != op_type:
  297:                 yield run
  298:                 run = _Run(op_type)
  299:             run.add(idx, operation)
  300:         yield run
  301: 
  302:     def gen_unordered(self) -> Iterator[_Run]:
  303:         """Generate batches of operations, batched by type of
  304:         operation, in arbitrary order.
  305:         """
  306:         operations = [_Run(_INSERT), _Run(_UPDATE), _Run(_DELETE)]
  307:         for idx, (op_type, operation) in enumerate(self.ops):
  308:             operations[op_type].add(idx, operation)
  309: 
  310:         for run in operations:
  311:             if run.ops:
  312:                 yield run
  313: 
  314:     def _execute_command(
  315:         self,
  316:         generator: Iterator[Any],
  317:         write_concern: WriteConcern,
  318:         session: Optional[ClientSession],
  319:         conn: Connection,
  320:         op_id: int,
  321:         retryable: bool,
  322:         full_result: MutableMapping[str, Any],
  323:         final_write_concern: Optional[WriteConcern] = None,
  324:     ) -> None:
  325:         db_name = self.collection.database.name
  326:         client = self.collection.database.client
  327:         listeners = client._event_listeners
  328: 
  329:         if not self.current_run:
  330:             self.current_run = next(generator)
  331:             self.next_run = None
  332:         run = self.current_run
  333: 
  334:         # Connection.command validates the session, but we use
  335:         # Connection.write_command
  336:         conn.validate_session(client, session)
  337:         last_run = False
  338: 
  339:         while run:
  340:             if not self.retrying:
  341:                 self.next_run = next(generator, None)
  342:                 if self.next_run is None:
  343:                     last_run = True
  344: 
  345:             cmd_name = _COMMANDS[run.op_type]
  346:             bwc = self.bulk_ctx_class(
  347:                 db_name,
  348:                 cmd_name,
  349:                 conn,
  350:                 op_id,
  351:                 listeners,
  352:                 session,
  353:                 run.op_type,
  354:                 self.collection.codec_options,
  355:             )
  356: 
  357:             while run.idx_offset < len(run.ops):
  358:                 # If this is the last possible operation, use the
  359:                 # final write concern.
  360:                 if last_run and (len(run.ops) - run.idx_offset) == 1:
  361:                     write_concern = final_write_concern or write_concern
  362: 
  363:                 cmd = {cmd_name: self.collection.name, "ordered": self.ordered}
  364:                 if self.comment:
  365:                     cmd["comment"] = self.comment
  366:                 _csot.apply_write_concern(cmd, write_concern)
  367:                 if self.bypass_doc_val:
  368:                     cmd["bypassDocumentValidation"] = True
  369:                 if self.let is not None and run.op_type in (_DELETE, _UPDATE):
  370:                     cmd["let"] = self.let
  371:                 if session:
  372:                     # Start a new retryable write unless one was already
  373:                     # started for this command.
  374:                     if retryable and not self.started_retryable_write:
  375:                         session._start_retryable_write()
  376:                         self.started_retryable_write = True
  377:                     session._apply_to(cmd, retryable, ReadPreference.PRIMARY, conn)
  378:                 conn.send_cluster_time(cmd, session, client)
  379:                 conn.add_server_api(cmd)
  380:                 # CSOT: apply timeout before encoding the command.
  381:                 conn.apply_timeout(client, cmd)
  382:                 ops = islice(run.ops, run.idx_offset, None)
  383: 
  384:                 # Run as many ops as possible in one command.
  385:                 if write_concern.acknowledged:
  386:                     result, to_send = bwc.execute(cmd, ops, client)
  387: 
  388:                     # Retryable writeConcernErrors halt the execution of this run.
  389:                     wce = result.get("writeConcernError", {})
  390:                     if wce.get("code", 0) in _RETRYABLE_ERROR_CODES:
  391:                         # Synthesize the full bulk result without modifying the
  392:                         # current one because this write operation may be retried.
  393:                         full = copy.deepcopy(full_result)
  394:                         _merge_command(run, full, run.idx_offset, result)
  395:                         _raise_bulk_write_error(full)
  396: 
  397:                     _merge_command(run, full_result, run.idx_offset, result)
  398: 
  399:                     # We're no longer in a retry once a command succeeds.
  400:                     self.retrying = False
  401:                     self.started_retryable_write = False
  402: 
  403:                     if self.ordered and "writeErrors" in result:
  404:                         break
  405:                 else:
  406:                     to_send = bwc.execute_unack(cmd, ops, client)
  407: 
  408:                 run.idx_offset += len(to_send)
  409: 
  410:             # We're supposed to continue if errors are
  411:             # at the write concern level (e.g. wtimeout)
  412:             if self.ordered and full_result["writeErrors"]:
  413:                 break
  414:             # Reset our state
  415:             self.current_run = run = self.next_run
  416: 
  417:     def execute_command(
  418:         self,
  419:         generator: Iterator[Any],
  420:         write_concern: WriteConcern,
  421:         session: Optional[ClientSession],
  422:         operation: str,
  423:     ) -> dict[str, Any]:
  424:         """Execute using write commands."""
  425:         # nModified is only reported for write commands, not legacy ops.
  426:         full_result = {
  427:             "writeErrors": [],
  428:             "writeConcernErrors": [],
  429:             "nInserted": 0,
  430:             "nUpserted": 0,
  431:             "nMatched": 0,
  432:             "nModified": 0,
  433:             "nRemoved": 0,
  434:             "upserted": [],
  435:         }
  436:         op_id = _randint()
  437: 
  438:         def retryable_bulk(
  439:             session: Optional[ClientSession], conn: Connection, retryable: bool
  440:         ) -> None:
  441:             self._execute_command(
  442:                 generator,
  443:                 write_concern,
  444:                 session,
  445:                 conn,
  446:                 op_id,
  447:                 retryable,
  448:                 full_result,
  449:             )
  450: 
  451:         client = self.collection.database.client
  452:         client._retryable_write(
  453:             self.is_retryable,
  454:             retryable_bulk,
  455:             session,
  456:             operation,
  457:             bulk=self,
  458:             operation_id=op_id,
  459:         )
  460: 
  461:         if full_result["writeErrors"] or full_result["writeConcernErrors"]:
  462:             _raise_bulk_write_error(full_result)
  463:         return full_result
  464: 
  465:     def execute_op_msg_no_results(self, conn: Connection, generator: Iterator[Any]) -> None:
  466:         """Execute write commands with OP_MSG and w=0 writeConcern, unordered."""
  467:         db_name = self.collection.database.name
  468:         client = self.collection.database.client
  469:         listeners = client._event_listeners
  470:         op_id = _randint()
  471: 
  472:         if not self.current_run:
  473:             self.current_run = next(generator)
  474:         run = self.current_run
  475: 
  476:         while run:
  477:             cmd_name = _COMMANDS[run.op_type]
  478:             bwc = self.bulk_ctx_class(
  479:                 db_name,
  480:                 cmd_name,
  481:                 conn,
  482:                 op_id,
  483:                 listeners,
  484:                 None,
  485:                 run.op_type,
  486:                 self.collection.codec_options,
  487:             )
  488: 
  489:             while run.idx_offset < len(run.ops):
  490:                 cmd = {
  491:                     cmd_name: self.collection.name,
  492:                     "ordered": False,
  493:                     "writeConcern": {"w": 0},
  494:                 }
  495:                 conn.add_server_api(cmd)
  496:                 ops = islice(run.ops, run.idx_offset, None)
  497:                 # Run as many ops as possible.
  498:                 to_send = bwc.execute_unack(cmd, ops, client)
  499:                 run.idx_offset += len(to_send)
  500:             self.current_run = run = next(generator, None)
  501: 
  502:     def execute_command_no_results(
  503:         self,
  504:         conn: Connection,
  505:         generator: Iterator[Any],
  506:         write_concern: WriteConcern,
  507:     ) -> None:
  508:         """Execute write commands with OP_MSG and w=0 WriteConcern, ordered."""
  509:         full_result = {
  510:             "writeErrors": [],
  511:             "writeConcernErrors": [],
  512:             "nInserted": 0,
  513:             "nUpserted": 0,
  514:             "nMatched": 0,
  515:             "nModified": 0,
  516:             "nRemoved": 0,
  517:             "upserted": [],
  518:         }
  519:         # Ordered bulk writes have to be acknowledged so that we stop
  520:         # processing at the first error, even when the application
  521:         # specified unacknowledged writeConcern.
  522:         initial_write_concern = WriteConcern()
  523:         op_id = _randint()
  524:         try:
  525:             self._execute_command(
  526:                 generator,
  527:                 initial_write_concern,
  528:                 None,
  529:                 conn,
  530:                 op_id,
  531:                 False,
  532:                 full_result,
  533:                 write_concern,
  534:             )
  535:         except OperationFailure:
  536:             pass
  537: 
  538:     def execute_no_results(
  539:         self,
  540:         conn: Connection,
  541:         generator: Iterator[Any],
  542:         write_concern: WriteConcern,
  543:     ) -> None:
  544:         """Execute all operations, returning no results (w=0)."""
  545:         if self.uses_collation:
  546:             raise ConfigurationError("Collation is unsupported for unacknowledged writes.")
  547:         if self.uses_array_filters:
  548:             raise ConfigurationError("arrayFilters is unsupported for unacknowledged writes.")
  549:         # Guard against unsupported unacknowledged writes.
  550:         unack = write_concern and not write_concern.acknowledged
  551:         if unack and self.uses_hint_delete and conn.max_wire_version < 9:
  552:             raise ConfigurationError(
  553:                 "Must be connected to MongoDB 4.4+ to use hint on unacknowledged delete commands."
  554:             )
  555:         if unack and self.uses_hint_update and conn.max_wire_version < 8:
  556:             raise ConfigurationError(
  557:                 "Must be connected to MongoDB 4.2+ to use hint on unacknowledged update commands."
  558:             )
  559:         # Cannot have both unacknowledged writes and bypass document validation.
  560:         if self.bypass_doc_val:
  561:             raise OperationFailure(
  562:                 "Cannot set bypass_document_validation with unacknowledged write concern"
  563:             )
  564: 
  565:         if self.ordered:
  566:             return self.execute_command_no_results(conn, generator, write_concern)
  567:         return self.execute_op_msg_no_results(conn, generator)
  568: 
  569:     def execute(
  570:         self,
  571:         write_concern: WriteConcern,
  572:         session: Optional[ClientSession],
  573:         operation: str,
  574:     ) -> Any:
  575:         """Execute operations."""
  576:         if not self.ops:
  577:             raise InvalidOperation("No operations to execute")
  578:         if self.executed:
  579:             raise InvalidOperation("Bulk operations can only be executed once.")
  580:         self.executed = True
  581:         write_concern = write_concern or self.collection.write_concern
  582:         session = _validate_session_write_concern(session, write_concern)
  583: 
  584:         if self.ordered:
  585:             generator = self.gen_ordered()
  586:         else:
  587:             generator = self.gen_unordered()
  588: 
  589:         client = self.collection.database.client
  590:         if not write_concern.acknowledged:
  591:             with client._conn_for_writes(session, operation) as connection:
  592:                 self.execute_no_results(connection, generator, write_concern)
  593:                 return None
  594:         else:
  595:             return self.execute_command(generator, write_concern, session, operation)
