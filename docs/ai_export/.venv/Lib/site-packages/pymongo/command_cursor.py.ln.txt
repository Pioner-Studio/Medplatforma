    1: # Copyright 2014-present MongoDB, Inc.
    2: #
    3: # Licensed under the Apache License, Version 2.0 (the "License");
    4: # you may not use this file except in compliance with the License.
    5: # You may obtain a copy of the License at
    6: #
    7: # http://www.apache.org/licenses/LICENSE-2.0
    8: #
    9: # Unless required by applicable law or agreed to in writing, software
   10: # distributed under the License is distributed on an "AS IS" BASIS,
   11: # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   12: # See the License for the specific language governing permissions and
   13: # limitations under the License.
   14: 
   15: """CommandCursor class to iterate over command results."""
   16: from __future__ import annotations
   17: 
   18: from collections import deque
   19: from typing import (
   20:     TYPE_CHECKING,
   21:     Any,
   22:     Generic,
   23:     Iterator,
   24:     Mapping,
   25:     NoReturn,
   26:     Optional,
   27:     Sequence,
   28:     Union,
   29: )
   30: 
   31: from bson import CodecOptions, _convert_raw_document_lists_to_streams
   32: from pymongo.cursor import _CURSOR_CLOSED_ERRORS, _ConnectionManager
   33: from pymongo.errors import ConnectionFailure, InvalidOperation, OperationFailure
   34: from pymongo.message import _CursorAddress, _GetMore, _OpMsg, _OpReply, _RawBatchGetMore
   35: from pymongo.response import PinnedResponse
   36: from pymongo.typings import _Address, _DocumentOut, _DocumentType
   37: 
   38: if TYPE_CHECKING:
   39:     from pymongo.client_session import ClientSession
   40:     from pymongo.collection import Collection
   41:     from pymongo.pool import Connection
   42: 
   43: 
   44: class CommandCursor(Generic[_DocumentType]):
   45:     """A cursor / iterator over command cursors."""
   46: 
   47:     _getmore_class = _GetMore
   48: 
   49:     def __init__(
   50:         self,
   51:         collection: Collection[_DocumentType],
   52:         cursor_info: Mapping[str, Any],
   53:         address: Optional[_Address],
   54:         batch_size: int = 0,
   55:         max_await_time_ms: Optional[int] = None,
   56:         session: Optional[ClientSession] = None,
   57:         explicit_session: bool = False,
   58:         comment: Any = None,
   59:     ) -> None:
   60:         """Create a new command cursor."""
   61:         self.__sock_mgr: Any = None
   62:         self.__collection: Collection[_DocumentType] = collection
   63:         self.__id = cursor_info["id"]
   64:         self.__data = deque(cursor_info["firstBatch"])
   65:         self.__postbatchresumetoken: Optional[Mapping[str, Any]] = cursor_info.get(
   66:             "postBatchResumeToken"
   67:         )
   68:         self.__address = address
   69:         self.__batch_size = batch_size
   70:         self.__max_await_time_ms = max_await_time_ms
   71:         self.__session = session
   72:         self.__explicit_session = explicit_session
   73:         self.__killed = self.__id == 0
   74:         self.__comment = comment
   75:         if self.__killed:
   76:             self.__end_session()
   77: 
   78:         if "ns" in cursor_info:  # noqa: SIM401
   79:             self.__ns = cursor_info["ns"]
   80:         else:
   81:             self.__ns = collection.full_name
   82: 
   83:         self.batch_size(batch_size)
   84: 
   85:         if not isinstance(max_await_time_ms, int) and max_await_time_ms is not None:
   86:             raise TypeError("max_await_time_ms must be an integer or None")
   87: 
   88:     def __del__(self) -> None:
   89:         self.__die()
   90: 
   91:     def __die(self, synchronous: bool = False) -> None:
   92:         """Closes this cursor."""
   93:         already_killed = self.__killed
   94:         self.__killed = True
   95:         if self.__id and not already_killed:
   96:             cursor_id = self.__id
   97:             assert self.__address is not None
   98:             address = _CursorAddress(self.__address, self.__ns)
   99:         else:
  100:             # Skip killCursors.
  101:             cursor_id = 0
  102:             address = None
  103:         self.__collection.database.client._cleanup_cursor(
  104:             synchronous,
  105:             cursor_id,
  106:             address,
  107:             self.__sock_mgr,
  108:             self.__session,
  109:             self.__explicit_session,
  110:         )
  111:         if not self.__explicit_session:
  112:             self.__session = None
  113:         self.__sock_mgr = None
  114: 
  115:     def __end_session(self) -> None:
  116:         if self.__session and not self.__explicit_session:
  117:             self.__session.end_session()
  118:             self.__session = None
  119: 
  120:     def close(self) -> None:
  121:         """Explicitly close / kill this cursor."""
  122:         self.__die(True)
  123: 
  124:     def batch_size(self, batch_size: int) -> CommandCursor[_DocumentType]:
  125:         """Limits the number of documents returned in one batch. Each batch
  126:         requires a round trip to the server. It can be adjusted to optimize
  127:         performance and limit data transfer.
  128: 
  129:         .. note:: batch_size can not override MongoDB's internal limits on the
  130:            amount of data it will return to the client in a single batch (i.e
  131:            if you set batch size to 1,000,000,000, MongoDB will currently only
  132:            return 4-16MB of results per batch).
  133: 
  134:         Raises :exc:`TypeError` if `batch_size` is not an integer.
  135:         Raises :exc:`ValueError` if `batch_size` is less than ``0``.
  136: 
  137:         :param batch_size: The size of each batch of results requested.
  138:         """
  139:         if not isinstance(batch_size, int):
  140:             raise TypeError("batch_size must be an integer")
  141:         if batch_size < 0:
  142:             raise ValueError("batch_size must be >= 0")
  143: 
  144:         self.__batch_size = batch_size == 1 and 2 or batch_size
  145:         return self
  146: 
  147:     def _has_next(self) -> bool:
  148:         """Returns `True` if the cursor has documents remaining from the
  149:         previous batch.
  150:         """
  151:         return len(self.__data) > 0
  152: 
  153:     @property
  154:     def _post_batch_resume_token(self) -> Optional[Mapping[str, Any]]:
  155:         """Retrieve the postBatchResumeToken from the response to a
  156:         changeStream aggregate or getMore.
  157:         """
  158:         return self.__postbatchresumetoken
  159: 
  160:     def _maybe_pin_connection(self, conn: Connection) -> None:
  161:         client = self.__collection.database.client
  162:         if not client._should_pin_cursor(self.__session):
  163:             return
  164:         if not self.__sock_mgr:
  165:             conn.pin_cursor()
  166:             conn_mgr = _ConnectionManager(conn, False)
  167:             # Ensure the connection gets returned when the entire result is
  168:             # returned in the first batch.
  169:             if self.__id == 0:
  170:                 conn_mgr.close()
  171:             else:
  172:                 self.__sock_mgr = conn_mgr
  173: 
  174:     def __send_message(self, operation: _GetMore) -> None:
  175:         """Send a getmore message and handle the response."""
  176:         client = self.__collection.database.client
  177:         try:
  178:             response = client._run_operation(
  179:                 operation, self._unpack_response, address=self.__address
  180:             )
  181:         except OperationFailure as exc:
  182:             if exc.code in _CURSOR_CLOSED_ERRORS:
  183:                 # Don't send killCursors because the cursor is already closed.
  184:                 self.__killed = True
  185:             if exc.timeout:
  186:                 self.__die(False)
  187:             else:
  188:                 # Return the session and pinned connection, if necessary.
  189:                 self.close()
  190:             raise
  191:         except ConnectionFailure:
  192:             # Don't send killCursors because the cursor is already closed.
  193:             self.__killed = True
  194:             # Return the session and pinned connection, if necessary.
  195:             self.close()
  196:             raise
  197:         except Exception:
  198:             self.close()
  199:             raise
  200: 
  201:         if isinstance(response, PinnedResponse):
  202:             if not self.__sock_mgr:
  203:                 self.__sock_mgr = _ConnectionManager(response.conn, response.more_to_come)
  204:         if response.from_command:
  205:             cursor = response.docs[0]["cursor"]
  206:             documents = cursor["nextBatch"]
  207:             self.__postbatchresumetoken = cursor.get("postBatchResumeToken")
  208:             self.__id = cursor["id"]
  209:         else:
  210:             documents = response.docs
  211:             assert isinstance(response.data, _OpReply)
  212:             self.__id = response.data.cursor_id
  213: 
  214:         if self.__id == 0:
  215:             self.close()
  216:         self.__data = deque(documents)
  217: 
  218:     def _unpack_response(
  219:         self,
  220:         response: Union[_OpReply, _OpMsg],
  221:         cursor_id: Optional[int],
  222:         codec_options: CodecOptions[Mapping[str, Any]],
  223:         user_fields: Optional[Mapping[str, Any]] = None,
  224:         legacy_response: bool = False,
  225:     ) -> Sequence[_DocumentOut]:
  226:         return response.unpack_response(cursor_id, codec_options, user_fields, legacy_response)
  227: 
  228:     def _refresh(self) -> int:
  229:         """Refreshes the cursor with more data from the server.
  230: 
  231:         Returns the length of self.__data after refresh. Will exit early if
  232:         self.__data is already non-empty. Raises OperationFailure when the
  233:         cursor cannot be refreshed due to an error on the query.
  234:         """
  235:         if len(self.__data) or self.__killed:
  236:             return len(self.__data)
  237: 
  238:         if self.__id:  # Get More
  239:             dbname, collname = self.__ns.split(".", 1)
  240:             read_pref = self.__collection._read_preference_for(self.session)
  241:             self.__send_message(
  242:                 self._getmore_class(
  243:                     dbname,
  244:                     collname,
  245:                     self.__batch_size,
  246:                     self.__id,
  247:                     self.__collection.codec_options,
  248:                     read_pref,
  249:                     self.__session,
  250:                     self.__collection.database.client,
  251:                     self.__max_await_time_ms,
  252:                     self.__sock_mgr,
  253:                     False,
  254:                     self.__comment,
  255:                 )
  256:             )
  257:         else:  # Cursor id is zero nothing else to return
  258:             self.__die(True)
  259: 
  260:         return len(self.__data)
  261: 
  262:     @property
  263:     def alive(self) -> bool:
  264:         """Does this cursor have the potential to return more data?
  265: 
  266:         Even if :attr:`alive` is ``True``, :meth:`next` can raise
  267:         :exc:`StopIteration`. Best to use a for loop::
  268: 
  269:             for doc in collection.aggregate(pipeline):
  270:                 print(doc)
  271: 
  272:         .. note:: :attr:`alive` can be True while iterating a cursor from
  273:           a failed server. In this case :attr:`alive` will return False after
  274:           :meth:`next` fails to retrieve the next batch of results from the
  275:           server.
  276:         """
  277:         return bool(len(self.__data) or (not self.__killed))
  278: 
  279:     @property
  280:     def cursor_id(self) -> int:
  281:         """Returns the id of the cursor."""
  282:         return self.__id
  283: 
  284:     @property
  285:     def address(self) -> Optional[_Address]:
  286:         """The (host, port) of the server used, or None.
  287: 
  288:         .. versionadded:: 3.0
  289:         """
  290:         return self.__address
  291: 
  292:     @property
  293:     def session(self) -> Optional[ClientSession]:
  294:         """The cursor's :class:`~pymongo.client_session.ClientSession`, or None.
  295: 
  296:         .. versionadded:: 3.6
  297:         """
  298:         if self.__explicit_session:
  299:             return self.__session
  300:         return None
  301: 
  302:     def __iter__(self) -> Iterator[_DocumentType]:
  303:         return self
  304: 
  305:     def next(self) -> _DocumentType:
  306:         """Advance the cursor."""
  307:         # Block until a document is returnable.
  308:         while self.alive:
  309:             doc = self._try_next(True)
  310:             if doc is not None:
  311:                 return doc
  312: 
  313:         raise StopIteration
  314: 
  315:     __next__ = next
  316: 
  317:     def _try_next(self, get_more_allowed: bool) -> Optional[_DocumentType]:
  318:         """Advance the cursor blocking for at most one getMore command."""
  319:         if not len(self.__data) and not self.__killed and get_more_allowed:
  320:             self._refresh()
  321:         if len(self.__data):
  322:             return self.__data.popleft()
  323:         else:
  324:             return None
  325: 
  326:     def try_next(self) -> Optional[_DocumentType]:
  327:         """Advance the cursor without blocking indefinitely.
  328: 
  329:         This method returns the next document without waiting
  330:         indefinitely for data.
  331: 
  332:         If no document is cached locally then this method runs a single
  333:         getMore command. If the getMore yields any documents, the next
  334:         document is returned, otherwise, if the getMore returns no documents
  335:         (because there is no additional data) then ``None`` is returned.
  336: 
  337:         :return: The next document or ``None`` when no document is available
  338:           after running a single getMore or when the cursor is closed.
  339: 
  340:         .. versionadded:: 4.5
  341:         """
  342:         return self._try_next(get_more_allowed=True)
  343: 
  344:     def __enter__(self) -> CommandCursor[_DocumentType]:
  345:         return self
  346: 
  347:     def __exit__(self, exc_type: Any, exc_val: Any, exc_tb: Any) -> None:
  348:         self.close()
  349: 
  350: 
  351: class RawBatchCommandCursor(CommandCursor, Generic[_DocumentType]):
  352:     _getmore_class = _RawBatchGetMore
  353: 
  354:     def __init__(
  355:         self,
  356:         collection: Collection[_DocumentType],
  357:         cursor_info: Mapping[str, Any],
  358:         address: Optional[_Address],
  359:         batch_size: int = 0,
  360:         max_await_time_ms: Optional[int] = None,
  361:         session: Optional[ClientSession] = None,
  362:         explicit_session: bool = False,
  363:         comment: Any = None,
  364:     ) -> None:
  365:         """Create a new cursor / iterator over raw batches of BSON data.
  366: 
  367:         Should not be called directly by application developers -
  368:         see :meth:`~pymongo.collection.Collection.aggregate_raw_batches`
  369:         instead.
  370: 
  371:         .. seealso:: The MongoDB documentation on `cursors <https://dochub.mongodb.org/core/cursors>`_.
  372:         """
  373:         assert not cursor_info.get("firstBatch")
  374:         super().__init__(
  375:             collection,
  376:             cursor_info,
  377:             address,
  378:             batch_size,
  379:             max_await_time_ms,
  380:             session,
  381:             explicit_session,
  382:             comment,
  383:         )
  384: 
  385:     def _unpack_response(  # type: ignore[override]
  386:         self,
  387:         response: Union[_OpReply, _OpMsg],
  388:         cursor_id: Optional[int],
  389:         codec_options: CodecOptions,
  390:         user_fields: Optional[Mapping[str, Any]] = None,
  391:         legacy_response: bool = False,
  392:     ) -> list[Mapping[str, Any]]:
  393:         raw_response = response.raw_response(cursor_id, user_fields=user_fields)
  394:         if not legacy_response:
  395:             # OP_MSG returns firstBatch/nextBatch documents as a BSON array
  396:             # Re-assemble the array of documents into a document stream
  397:             _convert_raw_document_lists_to_streams(raw_response[0])
  398:         return raw_response  # type: ignore[return-value]
  399: 
  400:     def __getitem__(self, index: int) -> NoReturn:
  401:         raise InvalidOperation("Cannot call __getitem__ on RawBatchCursor")
