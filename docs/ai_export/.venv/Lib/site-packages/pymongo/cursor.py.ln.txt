    1: # Copyright 2009-present MongoDB, Inc.
    2: #
    3: # Licensed under the Apache License, Version 2.0 (the "License");
    4: # you may not use this file except in compliance with the License.
    5: # You may obtain a copy of the License at
    6: #
    7: # http://www.apache.org/licenses/LICENSE-2.0
    8: #
    9: # Unless required by applicable law or agreed to in writing, software
   10: # distributed under the License is distributed on an "AS IS" BASIS,
   11: # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   12: # See the License for the specific language governing permissions and
   13: # limitations under the License.
   14: 
   15: """Cursor class to iterate over Mongo query results."""
   16: from __future__ import annotations
   17: 
   18: import copy
   19: import warnings
   20: from collections import deque
   21: from typing import (
   22:     TYPE_CHECKING,
   23:     Any,
   24:     Generic,
   25:     Iterable,
   26:     List,
   27:     Mapping,
   28:     NoReturn,
   29:     Optional,
   30:     Sequence,
   31:     Tuple,
   32:     Union,
   33:     cast,
   34:     overload,
   35: )
   36: 
   37: from bson import RE_TYPE, _convert_raw_document_lists_to_streams
   38: from bson.code import Code
   39: from bson.son import SON
   40: from pymongo import helpers
   41: from pymongo.collation import validate_collation_or_none
   42: from pymongo.common import (
   43:     validate_is_document_type,
   44:     validate_is_mapping,
   45: )
   46: from pymongo.errors import ConnectionFailure, InvalidOperation, OperationFailure
   47: from pymongo.lock import _create_lock
   48: from pymongo.message import (
   49:     _CursorAddress,
   50:     _GetMore,
   51:     _OpMsg,
   52:     _OpReply,
   53:     _Query,
   54:     _RawBatchGetMore,
   55:     _RawBatchQuery,
   56: )
   57: from pymongo.response import PinnedResponse
   58: from pymongo.typings import _Address, _CollationIn, _DocumentOut, _DocumentType
   59: from pymongo.write_concern import validate_boolean
   60: 
   61: if TYPE_CHECKING:
   62:     from _typeshed import SupportsItems
   63: 
   64:     from bson.codec_options import CodecOptions
   65:     from pymongo.client_session import ClientSession
   66:     from pymongo.collection import Collection
   67:     from pymongo.pool import Connection
   68:     from pymongo.read_preferences import _ServerMode
   69: 
   70: 
   71: # These errors mean that the server has already killed the cursor so there is
   72: # no need to send killCursors.
   73: _CURSOR_CLOSED_ERRORS = frozenset(
   74:     [
   75:         43,  # CursorNotFound
   76:         175,  # QueryPlanKilled
   77:         237,  # CursorKilled
   78:         # On a tailable cursor, the following errors mean the capped collection
   79:         # rolled over.
   80:         # MongoDB 2.6:
   81:         # {'$err': 'Runner killed during getMore', 'code': 28617, 'ok': 0}
   82:         28617,
   83:         # MongoDB 3.0:
   84:         # {'$err': 'getMore executor error: UnknownError no details available',
   85:         #  'code': 17406, 'ok': 0}
   86:         17406,
   87:         # MongoDB 3.2 + 3.4:
   88:         # {'ok': 0.0, 'errmsg': 'GetMore command executor error:
   89:         #  CappedPositionLost: CollectionScan died due to failure to restore
   90:         #  tailable cursor position. Last seen record id: RecordId(3)',
   91:         #  'code': 96}
   92:         96,
   93:         # MongoDB 3.6+:
   94:         # {'ok': 0.0, 'errmsg': 'errmsg: "CollectionScan died due to failure to
   95:         #  restore tailable cursor position. Last seen record id: RecordId(3)"',
   96:         #  'code': 136, 'codeName': 'CappedPositionLost'}
   97:         136,
   98:     ]
   99: )
  100: 
  101: _QUERY_OPTIONS = {
  102:     "tailable_cursor": 2,
  103:     "secondary_okay": 4,
  104:     "oplog_replay": 8,
  105:     "no_timeout": 16,
  106:     "await_data": 32,
  107:     "exhaust": 64,
  108:     "partial": 128,
  109: }
  110: 
  111: 
  112: class CursorType:
  113:     NON_TAILABLE = 0
  114:     """The standard cursor type."""
  115: 
  116:     TAILABLE = _QUERY_OPTIONS["tailable_cursor"]
  117:     """The tailable cursor type.
  118: 
  119:     Tailable cursors are only for use with capped collections. They are not
  120:     closed when the last data is retrieved but are kept open and the cursor
  121:     location marks the final document position. If more data is received
  122:     iteration of the cursor will continue from the last document received.
  123:     """
  124: 
  125:     TAILABLE_AWAIT = TAILABLE | _QUERY_OPTIONS["await_data"]
  126:     """A tailable cursor with the await option set.
  127: 
  128:     Creates a tailable cursor that will wait for a few seconds after returning
  129:     the full result set so that it can capture and return additional data added
  130:     during the query.
  131:     """
  132: 
  133:     EXHAUST = _QUERY_OPTIONS["exhaust"]
  134:     """An exhaust cursor.
  135: 
  136:     MongoDB will stream batched results to the client without waiting for the
  137:     client to request each batch, reducing latency.
  138:     """
  139: 
  140: 
  141: class _ConnectionManager:
  142:     """Used with exhaust cursors to ensure the connection is returned."""
  143: 
  144:     def __init__(self, conn: Connection, more_to_come: bool):
  145:         self.conn: Optional[Connection] = conn
  146:         self.more_to_come = more_to_come
  147:         self.lock = _create_lock()
  148: 
  149:     def update_exhaust(self, more_to_come: bool) -> None:
  150:         self.more_to_come = more_to_come
  151: 
  152:     def close(self) -> None:
  153:         """Return this instance's connection to the connection pool."""
  154:         if self.conn:
  155:             self.conn.unpin()
  156:             self.conn = None
  157: 
  158: 
  159: _Sort = Union[
  160:     Sequence[Union[str, Tuple[str, Union[int, str, Mapping[str, Any]]]]], Mapping[str, Any]
  161: ]
  162: _Hint = Union[str, _Sort]
  163: 
  164: 
  165: class Cursor(Generic[_DocumentType]):
  166:     """A cursor / iterator over Mongo query results."""
  167: 
  168:     _query_class = _Query
  169:     _getmore_class = _GetMore
  170: 
  171:     def __init__(
  172:         self,
  173:         collection: Collection[_DocumentType],
  174:         filter: Optional[Mapping[str, Any]] = None,
  175:         projection: Optional[Union[Mapping[str, Any], Iterable[str]]] = None,
  176:         skip: int = 0,
  177:         limit: int = 0,
  178:         no_cursor_timeout: bool = False,
  179:         cursor_type: int = CursorType.NON_TAILABLE,
  180:         sort: Optional[_Sort] = None,
  181:         allow_partial_results: bool = False,
  182:         oplog_replay: bool = False,
  183:         batch_size: int = 0,
  184:         collation: Optional[_CollationIn] = None,
  185:         hint: Optional[_Hint] = None,
  186:         max_scan: Optional[int] = None,
  187:         max_time_ms: Optional[int] = None,
  188:         max: Optional[_Sort] = None,
  189:         min: Optional[_Sort] = None,
  190:         return_key: Optional[bool] = None,
  191:         show_record_id: Optional[bool] = None,
  192:         snapshot: Optional[bool] = None,
  193:         comment: Optional[Any] = None,
  194:         session: Optional[ClientSession] = None,
  195:         allow_disk_use: Optional[bool] = None,
  196:         let: Optional[bool] = None,
  197:     ) -> None:
  198:         """Create a new cursor.
  199: 
  200:         Should not be called directly by application developers - see
  201:         :meth:`~pymongo.collection.Collection.find` instead.
  202: 
  203:         .. seealso:: The MongoDB documentation on `cursors <https://dochub.mongodb.org/core/cursors>`_.
  204:         """
  205:         # Initialize all attributes used in __del__ before possibly raising
  206:         # an error to avoid attribute errors during garbage collection.
  207:         self.__collection: Collection[_DocumentType] = collection
  208:         self.__id: Any = None
  209:         self.__exhaust = False
  210:         self.__sock_mgr: Any = None
  211:         self.__killed = False
  212:         self.__session: Optional[ClientSession]
  213: 
  214:         if session:
  215:             self.__session = session
  216:             self.__explicit_session = True
  217:         else:
  218:             self.__session = None
  219:             self.__explicit_session = False
  220: 
  221:         spec: Mapping[str, Any] = filter or {}
  222:         validate_is_mapping("filter", spec)
  223:         if not isinstance(skip, int):
  224:             raise TypeError("skip must be an instance of int")
  225:         if not isinstance(limit, int):
  226:             raise TypeError("limit must be an instance of int")
  227:         validate_boolean("no_cursor_timeout", no_cursor_timeout)
  228:         if no_cursor_timeout and not self.__explicit_session:
  229:             warnings.warn(
  230:                 "use an explicit session with no_cursor_timeout=True "
  231:                 "otherwise the cursor may still timeout after "
  232:                 "30 minutes, for more info see "
  233:                 "https://mongodb.com/docs/v4.4/reference/method/"
  234:                 "cursor.noCursorTimeout/"
  235:                 "#session-idle-timeout-overrides-nocursortimeout",
  236:                 UserWarning,
  237:                 stacklevel=2,
  238:             )
  239:         if cursor_type not in (
  240:             CursorType.NON_TAILABLE,
  241:             CursorType.TAILABLE,
  242:             CursorType.TAILABLE_AWAIT,
  243:             CursorType.EXHAUST,
  244:         ):
  245:             raise ValueError("not a valid value for cursor_type")
  246:         validate_boolean("allow_partial_results", allow_partial_results)
  247:         validate_boolean("oplog_replay", oplog_replay)
  248:         if not isinstance(batch_size, int):
  249:             raise TypeError("batch_size must be an integer")
  250:         if batch_size < 0:
  251:             raise ValueError("batch_size must be >= 0")
  252:         # Only set if allow_disk_use is provided by the user, else None.
  253:         if allow_disk_use is not None:
  254:             allow_disk_use = validate_boolean("allow_disk_use", allow_disk_use)
  255: 
  256:         if projection is not None:
  257:             projection = helpers._fields_list_to_dict(projection, "projection")
  258: 
  259:         if let is not None:
  260:             validate_is_document_type("let", let)
  261: 
  262:         self.__let = let
  263:         self.__spec = spec
  264:         self.__has_filter = filter is not None
  265:         self.__projection = projection
  266:         self.__skip = skip
  267:         self.__limit = limit
  268:         self.__batch_size = batch_size
  269:         self.__ordering = sort and helpers._index_document(sort) or None
  270:         self.__max_scan = max_scan
  271:         self.__explain = False
  272:         self.__comment = comment
  273:         self.__max_time_ms = max_time_ms
  274:         self.__max_await_time_ms: Optional[int] = None
  275:         self.__max: Optional[Union[dict[Any, Any], _Sort]] = max
  276:         self.__min: Optional[Union[dict[Any, Any], _Sort]] = min
  277:         self.__collation = validate_collation_or_none(collation)
  278:         self.__return_key = return_key
  279:         self.__show_record_id = show_record_id
  280:         self.__allow_disk_use = allow_disk_use
  281:         self.__snapshot = snapshot
  282:         self.__hint: Union[str, dict[str, Any], None]
  283:         self.__set_hint(hint)
  284: 
  285:         # Exhaust cursor support
  286:         if cursor_type == CursorType.EXHAUST:
  287:             if self.__collection.database.client.is_mongos:
  288:                 raise InvalidOperation("Exhaust cursors are not supported by mongos")
  289:             if limit:
  290:                 raise InvalidOperation("Can't use limit and exhaust together.")
  291:             self.__exhaust = True
  292: 
  293:         # This is ugly. People want to be able to do cursor[5:5] and
  294:         # get an empty result set (old behavior was an
  295:         # exception). It's hard to do that right, though, because the
  296:         # server uses limit(0) to mean 'no limit'. So we set __empty
  297:         # in that case and check for it when iterating. We also unset
  298:         # it anytime we change __limit.
  299:         self.__empty = False
  300: 
  301:         self.__data: deque = deque()
  302:         self.__address: Optional[_Address] = None
  303:         self.__retrieved = 0
  304: 
  305:         self.__codec_options = collection.codec_options
  306:         # Read preference is set when the initial find is sent.
  307:         self.__read_preference: Optional[_ServerMode] = None
  308:         self.__read_concern = collection.read_concern
  309: 
  310:         self.__query_flags = cursor_type
  311:         if no_cursor_timeout:
  312:             self.__query_flags |= _QUERY_OPTIONS["no_timeout"]
  313:         if allow_partial_results:
  314:             self.__query_flags |= _QUERY_OPTIONS["partial"]
  315:         if oplog_replay:
  316:             self.__query_flags |= _QUERY_OPTIONS["oplog_replay"]
  317: 
  318:         # The namespace to use for find/getMore commands.
  319:         self.__dbname = collection.database.name
  320:         self.__collname = collection.name
  321: 
  322:     @property
  323:     def collection(self) -> Collection[_DocumentType]:
  324:         """The :class:`~pymongo.collection.Collection` that this
  325:         :class:`Cursor` is iterating.
  326:         """
  327:         return self.__collection
  328: 
  329:     @property
  330:     def retrieved(self) -> int:
  331:         """The number of documents retrieved so far."""
  332:         return self.__retrieved
  333: 
  334:     def __del__(self) -> None:
  335:         self.__die()
  336: 
  337:     def rewind(self) -> Cursor[_DocumentType]:
  338:         """Rewind this cursor to its unevaluated state.
  339: 
  340:         Reset this cursor if it has been partially or completely evaluated.
  341:         Any options that are present on the cursor will remain in effect.
  342:         Future iterating performed on this cursor will cause new queries to
  343:         be sent to the server, even if the resultant data has already been
  344:         retrieved by this cursor.
  345:         """
  346:         self.close()
  347:         self.__data = deque()
  348:         self.__id = None
  349:         self.__address = None
  350:         self.__retrieved = 0
  351:         self.__killed = False
  352: 
  353:         return self
  354: 
  355:     def clone(self) -> Cursor[_DocumentType]:
  356:         """Get a clone of this cursor.
  357: 
  358:         Returns a new Cursor instance with options matching those that have
  359:         been set on the current instance. The clone will be completely
  360:         unevaluated, even if the current instance has been partially or
  361:         completely evaluated.
  362:         """
  363:         return self._clone(True)
  364: 
  365:     def _clone(self, deepcopy: bool = True, base: Optional[Cursor] = None) -> Cursor:
  366:         """Internal clone helper."""
  367:         if not base:
  368:             if self.__explicit_session:
  369:                 base = self._clone_base(self.__session)
  370:             else:
  371:                 base = self._clone_base(None)
  372: 
  373:         values_to_clone = (
  374:             "spec",
  375:             "projection",
  376:             "skip",
  377:             "limit",
  378:             "max_time_ms",
  379:             "max_await_time_ms",
  380:             "comment",
  381:             "max",
  382:             "min",
  383:             "ordering",
  384:             "explain",
  385:             "hint",
  386:             "batch_size",
  387:             "max_scan",
  388:             "query_flags",
  389:             "collation",
  390:             "empty",
  391:             "show_record_id",
  392:             "return_key",
  393:             "allow_disk_use",
  394:             "snapshot",
  395:             "exhaust",
  396:             "has_filter",
  397:         )
  398:         data = {
  399:             k: v
  400:             for k, v in self.__dict__.items()
  401:             if k.startswith("_Cursor__") and k[9:] in values_to_clone
  402:         }
  403:         if deepcopy:
  404:             data = self._deepcopy(data)
  405:         base.__dict__.update(data)
  406:         return base
  407: 
  408:     def _clone_base(self, session: Optional[ClientSession]) -> Cursor:
  409:         """Creates an empty Cursor object for information to be copied into."""
  410:         return self.__class__(self.__collection, session=session)
  411: 
  412:     def __die(self, synchronous: bool = False) -> None:
  413:         """Closes this cursor."""
  414:         try:
  415:             already_killed = self.__killed
  416:         except AttributeError:
  417:             # __init__ did not run to completion (or at all).
  418:             return
  419: 
  420:         self.__killed = True
  421:         if self.__id and not already_killed:
  422:             cursor_id = self.__id
  423:             assert self.__address is not None
  424:             address = _CursorAddress(self.__address, f"{self.__dbname}.{self.__collname}")
  425:         else:
  426:             # Skip killCursors.
  427:             cursor_id = 0
  428:             address = None
  429:         self.__collection.database.client._cleanup_cursor(
  430:             synchronous,
  431:             cursor_id,
  432:             address,
  433:             self.__sock_mgr,
  434:             self.__session,
  435:             self.__explicit_session,
  436:         )
  437:         if not self.__explicit_session:
  438:             self.__session = None
  439:         self.__sock_mgr = None
  440: 
  441:     def close(self) -> None:
  442:         """Explicitly close / kill this cursor."""
  443:         self.__die(True)
  444: 
  445:     def __query_spec(self) -> Mapping[str, Any]:
  446:         """Get the spec to use for a query."""
  447:         operators: dict[str, Any] = {}
  448:         if self.__ordering:
  449:             operators["$orderby"] = self.__ordering
  450:         if self.__explain:
  451:             operators["$explain"] = True
  452:         if self.__hint:
  453:             operators["$hint"] = self.__hint
  454:         if self.__let:
  455:             operators["let"] = self.__let
  456:         if self.__comment:
  457:             operators["$comment"] = self.__comment
  458:         if self.__max_scan:
  459:             operators["$maxScan"] = self.__max_scan
  460:         if self.__max_time_ms is not None:
  461:             operators["$maxTimeMS"] = self.__max_time_ms
  462:         if self.__max:
  463:             operators["$max"] = self.__max
  464:         if self.__min:
  465:             operators["$min"] = self.__min
  466:         if self.__return_key is not None:
  467:             operators["$returnKey"] = self.__return_key
  468:         if self.__show_record_id is not None:
  469:             # This is upgraded to showRecordId for MongoDB 3.2+ "find" command.
  470:             operators["$showDiskLoc"] = self.__show_record_id
  471:         if self.__snapshot is not None:
  472:             operators["$snapshot"] = self.__snapshot
  473: 
  474:         if operators:
  475:             # Make a shallow copy so we can cleanly rewind or clone.
  476:             spec = dict(self.__spec)
  477: 
  478:             # Allow-listed commands must be wrapped in $query.
  479:             if "$query" not in spec:
  480:                 # $query has to come first
  481:                 spec = {"$query": spec}
  482: 
  483:             spec.update(operators)
  484:             return spec
  485:         # Have to wrap with $query if "query" is the first key.
  486:         # We can't just use $query anytime "query" is a key as
  487:         # that breaks commands like count and find_and_modify.
  488:         # Checking spec.keys()[0] covers the case that the spec
  489:         # was passed as an instance of SON or OrderedDict.
  490:         elif "query" in self.__spec and (
  491:             len(self.__spec) == 1 or next(iter(self.__spec)) == "query"
  492:         ):
  493:             return {"$query": self.__spec}
  494: 
  495:         return self.__spec
  496: 
  497:     def __check_okay_to_chain(self) -> None:
  498:         """Check if it is okay to chain more options onto this cursor."""
  499:         if self.__retrieved or self.__id is not None:
  500:             raise InvalidOperation("cannot set options after executing query")
  501: 
  502:     def add_option(self, mask: int) -> Cursor[_DocumentType]:
  503:         """Set arbitrary query flags using a bitmask.
  504: 
  505:         To set the tailable flag:
  506:         cursor.add_option(2)
  507:         """
  508:         if not isinstance(mask, int):
  509:             raise TypeError("mask must be an int")
  510:         self.__check_okay_to_chain()
  511: 
  512:         if mask & _QUERY_OPTIONS["exhaust"]:
  513:             if self.__limit:
  514:                 raise InvalidOperation("Can't use limit and exhaust together.")
  515:             if self.__collection.database.client.is_mongos:
  516:                 raise InvalidOperation("Exhaust cursors are not supported by mongos")
  517:             self.__exhaust = True
  518: 
  519:         self.__query_flags |= mask
  520:         return self
  521: 
  522:     def remove_option(self, mask: int) -> Cursor[_DocumentType]:
  523:         """Unset arbitrary query flags using a bitmask.
  524: 
  525:         To unset the tailable flag:
  526:         cursor.remove_option(2)
  527:         """
  528:         if not isinstance(mask, int):
  529:             raise TypeError("mask must be an int")
  530:         self.__check_okay_to_chain()
  531: 
  532:         if mask & _QUERY_OPTIONS["exhaust"]:
  533:             self.__exhaust = False
  534: 
  535:         self.__query_flags &= ~mask
  536:         return self
  537: 
  538:     def allow_disk_use(self, allow_disk_use: bool) -> Cursor[_DocumentType]:
  539:         """Specifies whether MongoDB can use temporary disk files while
  540:         processing a blocking sort operation.
  541: 
  542:         Raises :exc:`TypeError` if `allow_disk_use` is not a boolean.
  543: 
  544:         .. note:: `allow_disk_use` requires server version **>= 4.4**
  545: 
  546:         :param allow_disk_use: if True, MongoDB may use temporary
  547:             disk files to store data exceeding the system memory limit while
  548:             processing a blocking sort operation.
  549: 
  550:         .. versionadded:: 3.11
  551:         """
  552:         if not isinstance(allow_disk_use, bool):
  553:             raise TypeError("allow_disk_use must be a bool")
  554:         self.__check_okay_to_chain()
  555: 
  556:         self.__allow_disk_use = allow_disk_use
  557:         return self
  558: 
  559:     def limit(self, limit: int) -> Cursor[_DocumentType]:
  560:         """Limits the number of results to be returned by this cursor.
  561: 
  562:         Raises :exc:`TypeError` if `limit` is not an integer. Raises
  563:         :exc:`~pymongo.errors.InvalidOperation` if this :class:`Cursor`
  564:         has already been used. The last `limit` applied to this cursor
  565:         takes precedence. A limit of ``0`` is equivalent to no limit.
  566: 
  567:         :param limit: the number of results to return
  568: 
  569:         .. seealso:: The MongoDB documentation on `limit <https://dochub.mongodb.org/core/limit>`_.
  570:         """
  571:         if not isinstance(limit, int):
  572:             raise TypeError("limit must be an integer")
  573:         if self.__exhaust:
  574:             raise InvalidOperation("Can't use limit and exhaust together.")
  575:         self.__check_okay_to_chain()
  576: 
  577:         self.__empty = False
  578:         self.__limit = limit
  579:         return self
  580: 
  581:     def batch_size(self, batch_size: int) -> Cursor[_DocumentType]:
  582:         """Limits the number of documents returned in one batch. Each batch
  583:         requires a round trip to the server. It can be adjusted to optimize
  584:         performance and limit data transfer.
  585: 
  586:         .. note:: batch_size can not override MongoDB's internal limits on the
  587:            amount of data it will return to the client in a single batch (i.e
  588:            if you set batch size to 1,000,000,000, MongoDB will currently only
  589:            return 4-16MB of results per batch).
  590: 
  591:         Raises :exc:`TypeError` if `batch_size` is not an integer.
  592:         Raises :exc:`ValueError` if `batch_size` is less than ``0``.
  593:         Raises :exc:`~pymongo.errors.InvalidOperation` if this
  594:         :class:`Cursor` has already been used. The last `batch_size`
  595:         applied to this cursor takes precedence.
  596: 
  597:         :param batch_size: The size of each batch of results requested.
  598:         """
  599:         if not isinstance(batch_size, int):
  600:             raise TypeError("batch_size must be an integer")
  601:         if batch_size < 0:
  602:             raise ValueError("batch_size must be >= 0")
  603:         self.__check_okay_to_chain()
  604: 
  605:         self.__batch_size = batch_size
  606:         return self
  607: 
  608:     def skip(self, skip: int) -> Cursor[_DocumentType]:
  609:         """Skips the first `skip` results of this cursor.
  610: 
  611:         Raises :exc:`TypeError` if `skip` is not an integer. Raises
  612:         :exc:`ValueError` if `skip` is less than ``0``. Raises
  613:         :exc:`~pymongo.errors.InvalidOperation` if this :class:`Cursor` has
  614:         already been used. The last `skip` applied to this cursor takes
  615:         precedence.
  616: 
  617:         :param skip: the number of results to skip
  618:         """
  619:         if not isinstance(skip, int):
  620:             raise TypeError("skip must be an integer")
  621:         if skip < 0:
  622:             raise ValueError("skip must be >= 0")
  623:         self.__check_okay_to_chain()
  624: 
  625:         self.__skip = skip
  626:         return self
  627: 
  628:     def max_time_ms(self, max_time_ms: Optional[int]) -> Cursor[_DocumentType]:
  629:         """Specifies a time limit for a query operation. If the specified
  630:         time is exceeded, the operation will be aborted and
  631:         :exc:`~pymongo.errors.ExecutionTimeout` is raised. If `max_time_ms`
  632:         is ``None`` no limit is applied.
  633: 
  634:         Raises :exc:`TypeError` if `max_time_ms` is not an integer or ``None``.
  635:         Raises :exc:`~pymongo.errors.InvalidOperation` if this :class:`Cursor`
  636:         has already been used.
  637: 
  638:         :param max_time_ms: the time limit after which the operation is aborted
  639:         """
  640:         if not isinstance(max_time_ms, int) and max_time_ms is not None:
  641:             raise TypeError("max_time_ms must be an integer or None")
  642:         self.__check_okay_to_chain()
  643: 
  644:         self.__max_time_ms = max_time_ms
  645:         return self
  646: 
  647:     def max_await_time_ms(self, max_await_time_ms: Optional[int]) -> Cursor[_DocumentType]:
  648:         """Specifies a time limit for a getMore operation on a
  649:         :attr:`~pymongo.cursor.CursorType.TAILABLE_AWAIT` cursor. For all other
  650:         types of cursor max_await_time_ms is ignored.
  651: 
  652:         Raises :exc:`TypeError` if `max_await_time_ms` is not an integer or
  653:         ``None``. Raises :exc:`~pymongo.errors.InvalidOperation` if this
  654:         :class:`Cursor` has already been used.
  655: 
  656:         .. note:: `max_await_time_ms` requires server version **>= 3.2**
  657: 
  658:         :param max_await_time_ms: the time limit after which the operation is
  659:             aborted
  660: 
  661:         .. versionadded:: 3.2
  662:         """
  663:         if not isinstance(max_await_time_ms, int) and max_await_time_ms is not None:
  664:             raise TypeError("max_await_time_ms must be an integer or None")
  665:         self.__check_okay_to_chain()
  666: 
  667:         # Ignore max_await_time_ms if not tailable or await_data is False.
  668:         if self.__query_flags & CursorType.TAILABLE_AWAIT:
  669:             self.__max_await_time_ms = max_await_time_ms
  670: 
  671:         return self
  672: 
  673:     @overload
  674:     def __getitem__(self, index: int) -> _DocumentType:
  675:         ...
  676: 
  677:     @overload
  678:     def __getitem__(self, index: slice) -> Cursor[_DocumentType]:
  679:         ...
  680: 
  681:     def __getitem__(self, index: Union[int, slice]) -> Union[_DocumentType, Cursor[_DocumentType]]:
  682:         """Get a single document or a slice of documents from this cursor.
  683: 
  684:         .. warning:: A :class:`~Cursor` is not a Python :class:`list`. Each
  685:           index access or slice requires that a new query be run using skip
  686:           and limit. Do not iterate the cursor using index accesses.
  687:           The following example is **extremely inefficient** and may return
  688:           surprising results::
  689: 
  690:             cursor = db.collection.find()
  691:             # Warning: This runs a new query for each document.
  692:             # Don't do this!
  693:             for idx in range(10):
  694:                 print(cursor[idx])
  695: 
  696:         Raises :class:`~pymongo.errors.InvalidOperation` if this
  697:         cursor has already been used.
  698: 
  699:         To get a single document use an integral index, e.g.::
  700: 
  701:           >>> db.test.find()[50]
  702: 
  703:         An :class:`IndexError` will be raised if the index is negative
  704:         or greater than the amount of documents in this cursor. Any
  705:         limit previously applied to this cursor will be ignored.
  706: 
  707:         To get a slice of documents use a slice index, e.g.::
  708: 
  709:           >>> db.test.find()[20:25]
  710: 
  711:         This will return this cursor with a limit of ``5`` and skip of
  712:         ``20`` applied.  Using a slice index will override any prior
  713:         limits or skips applied to this cursor (including those
  714:         applied through previous calls to this method). Raises
  715:         :class:`IndexError` when the slice has a step, a negative
  716:         start value, or a stop value less than or equal to the start
  717:         value.
  718: 
  719:         :param index: An integer or slice index to be applied to this cursor
  720:         """
  721:         self.__check_okay_to_chain()
  722:         self.__empty = False
  723:         if isinstance(index, slice):
  724:             if index.step is not None:
  725:                 raise IndexError("Cursor instances do not support slice steps")
  726: 
  727:             skip = 0
  728:             if index.start is not None:
  729:                 if index.start < 0:
  730:                     raise IndexError("Cursor instances do not support negative indices")
  731:                 skip = index.start
  732: 
  733:             if index.stop is not None:
  734:                 limit = index.stop - skip
  735:                 if limit < 0:
  736:                     raise IndexError(
  737:                         "stop index must be greater than start index for slice %r" % index
  738:                     )
  739:                 if limit == 0:
  740:                     self.__empty = True
  741:             else:
  742:                 limit = 0
  743: 
  744:             self.__skip = skip
  745:             self.__limit = limit
  746:             return self
  747: 
  748:         if isinstance(index, int):
  749:             if index < 0:
  750:                 raise IndexError("Cursor instances do not support negative indices")
  751:             clone = self.clone()
  752:             clone.skip(index + self.__skip)
  753:             clone.limit(-1)  # use a hard limit
  754:             clone.__query_flags &= ~CursorType.TAILABLE_AWAIT  # PYTHON-1371
  755:             for doc in clone:
  756:                 return doc
  757:             raise IndexError("no such item for Cursor instance")
  758:         raise TypeError("index %r cannot be applied to Cursor instances" % index)
  759: 
  760:     def max_scan(self, max_scan: Optional[int]) -> Cursor[_DocumentType]:
  761:         """**DEPRECATED** - Limit the number of documents to scan when
  762:         performing the query.
  763: 
  764:         Raises :class:`~pymongo.errors.InvalidOperation` if this
  765:         cursor has already been used. Only the last :meth:`max_scan`
  766:         applied to this cursor has any effect.
  767: 
  768:         :param max_scan: the maximum number of documents to scan
  769: 
  770:         .. versionchanged:: 3.7
  771:           Deprecated :meth:`max_scan`. Support for this option is deprecated in
  772:           MongoDB 4.0. Use :meth:`max_time_ms` instead to limit server side
  773:           execution time.
  774:         """
  775:         self.__check_okay_to_chain()
  776:         self.__max_scan = max_scan
  777:         return self
  778: 
  779:     def max(self, spec: _Sort) -> Cursor[_DocumentType]:
  780:         """Adds ``max`` operator that specifies upper bound for specific index.
  781: 
  782:         When using ``max``, :meth:`~hint` should also be configured to ensure
  783:         the query uses the expected index and starting in MongoDB 4.2
  784:         :meth:`~hint` will be required.
  785: 
  786:         :param spec: a list of field, limit pairs specifying the exclusive
  787:             upper bound for all keys of a specific index in order.
  788: 
  789:         .. versionchanged:: 3.8
  790:            Deprecated cursors that use ``max`` without a :meth:`~hint`.
  791: 
  792:         .. versionadded:: 2.7
  793:         """
  794:         if not isinstance(spec, (list, tuple)):
  795:             raise TypeError("spec must be an instance of list or tuple")
  796: 
  797:         self.__check_okay_to_chain()
  798:         self.__max = dict(spec)
  799:         return self
  800: 
  801:     def min(self, spec: _Sort) -> Cursor[_DocumentType]:
  802:         """Adds ``min`` operator that specifies lower bound for specific index.
  803: 
  804:         When using ``min``, :meth:`~hint` should also be configured to ensure
  805:         the query uses the expected index and starting in MongoDB 4.2
  806:         :meth:`~hint` will be required.
  807: 
  808:         :param spec: a list of field, limit pairs specifying the inclusive
  809:             lower bound for all keys of a specific index in order.
  810: 
  811:         .. versionchanged:: 3.8
  812:            Deprecated cursors that use ``min`` without a :meth:`~hint`.
  813: 
  814:         .. versionadded:: 2.7
  815:         """
  816:         if not isinstance(spec, (list, tuple)):
  817:             raise TypeError("spec must be an instance of list or tuple")
  818: 
  819:         self.__check_okay_to_chain()
  820:         self.__min = dict(spec)
  821:         return self
  822: 
  823:     def sort(
  824:         self, key_or_list: _Hint, direction: Optional[Union[int, str]] = None
  825:     ) -> Cursor[_DocumentType]:
  826:         """Sorts this cursor's results.
  827: 
  828:         Pass a field name and a direction, either
  829:         :data:`~pymongo.ASCENDING` or :data:`~pymongo.DESCENDING`.::
  830: 
  831:             for doc in collection.find().sort('field', pymongo.ASCENDING):
  832:                 print(doc)
  833: 
  834:         To sort by multiple fields, pass a list of (key, direction) pairs.
  835:         If just a name is given, :data:`~pymongo.ASCENDING` will be inferred::
  836: 
  837:             for doc in collection.find().sort([
  838:                     'field1',
  839:                     ('field2', pymongo.DESCENDING)]):
  840:                 print(doc)
  841: 
  842:         Text search results can be sorted by relevance::
  843: 
  844:             cursor = db.test.find(
  845:                 {'$text': {'$search': 'some words'}},
  846:                 {'score': {'$meta': 'textScore'}})
  847: 
  848:             # Sort by 'score' field.
  849:             cursor.sort([('score', {'$meta': 'textScore'})])
  850: 
  851:             for doc in cursor:
  852:                 print(doc)
  853: 
  854:         For more advanced text search functionality, see MongoDB's
  855:         `Atlas Search <https://docs.atlas.mongodb.com/atlas-search/>`_.
  856: 
  857:         Raises :class:`~pymongo.errors.InvalidOperation` if this cursor has
  858:         already been used. Only the last :meth:`sort` applied to this
  859:         cursor has any effect.
  860: 
  861:         :param key_or_list: a single key or a list of (key, direction)
  862:             pairs specifying the keys to sort on
  863:         :param direction: only used if `key_or_list` is a single
  864:             key, if not given :data:`~pymongo.ASCENDING` is assumed
  865:         """
  866:         self.__check_okay_to_chain()
  867:         keys = helpers._index_list(key_or_list, direction)
  868:         self.__ordering = helpers._index_document(keys)
  869:         return self
  870: 
  871:     def distinct(self, key: str) -> list:
  872:         """Get a list of distinct values for `key` among all documents
  873:         in the result set of this query.
  874: 
  875:         Raises :class:`TypeError` if `key` is not an instance of
  876:         :class:`str`.
  877: 
  878:         The :meth:`distinct` method obeys the
  879:         :attr:`~pymongo.collection.Collection.read_preference` of the
  880:         :class:`~pymongo.collection.Collection` instance on which
  881:         :meth:`~pymongo.collection.Collection.find` was called.
  882: 
  883:         :param key: name of key for which we want to get the distinct values
  884: 
  885:         .. seealso:: :meth:`pymongo.collection.Collection.distinct`
  886:         """
  887:         options: dict[str, Any] = {}
  888:         if self.__spec:
  889:             options["query"] = self.__spec
  890:         if self.__max_time_ms is not None:
  891:             options["maxTimeMS"] = self.__max_time_ms
  892:         if self.__comment:
  893:             options["comment"] = self.__comment
  894:         if self.__collation is not None:
  895:             options["collation"] = self.__collation
  896: 
  897:         return self.__collection.distinct(key, session=self.__session, **options)
  898: 
  899:     def explain(self) -> _DocumentType:
  900:         """Returns an explain plan record for this cursor.
  901: 
  902:         .. note:: This method uses the default verbosity mode of the
  903:           `explain command
  904:           <https://mongodb.com/docs/manual/reference/command/explain/>`_,
  905:           ``allPlansExecution``. To use a different verbosity use
  906:           :meth:`~pymongo.database.Database.command` to run the explain
  907:           command directly.
  908: 
  909:         .. seealso:: The MongoDB documentation on `explain <https://dochub.mongodb.org/core/explain>`_.
  910:         """
  911:         c = self.clone()
  912:         c.__explain = True
  913: 
  914:         # always use a hard limit for explains
  915:         if c.__limit:
  916:             c.__limit = -abs(c.__limit)
  917:         return next(c)
  918: 
  919:     def __set_hint(self, index: Optional[_Hint]) -> None:
  920:         if index is None:
  921:             self.__hint = None
  922:             return
  923: 
  924:         if isinstance(index, str):
  925:             self.__hint = index
  926:         else:
  927:             self.__hint = helpers._index_document(index)
  928: 
  929:     def hint(self, index: Optional[_Hint]) -> Cursor[_DocumentType]:
  930:         """Adds a 'hint', telling Mongo the proper index to use for the query.
  931: 
  932:         Judicious use of hints can greatly improve query
  933:         performance. When doing a query on multiple fields (at least
  934:         one of which is indexed) pass the indexed field as a hint to
  935:         the query. Raises :class:`~pymongo.errors.OperationFailure` if the
  936:         provided hint requires an index that does not exist on this collection,
  937:         and raises :class:`~pymongo.errors.InvalidOperation` if this cursor has
  938:         already been used.
  939: 
  940:         `index` should be an index as passed to
  941:         :meth:`~pymongo.collection.Collection.create_index`
  942:         (e.g. ``[('field', ASCENDING)]``) or the name of the index.
  943:         If `index` is ``None`` any existing hint for this query is
  944:         cleared. The last hint applied to this cursor takes precedence
  945:         over all others.
  946: 
  947:         :param index: index to hint on (as an index specifier)
  948:         """
  949:         self.__check_okay_to_chain()
  950:         self.__set_hint(index)
  951:         return self
  952: 
  953:     def comment(self, comment: Any) -> Cursor[_DocumentType]:
  954:         """Adds a 'comment' to the cursor.
  955: 
  956:         http://mongodb.com/docs/manual/reference/operator/comment/
  957: 
  958:         :param comment: A string to attach to the query to help interpret and
  959:             trace the operation in the server logs and in profile data.
  960: 
  961:         .. versionadded:: 2.7
  962:         """
  963:         self.__check_okay_to_chain()
  964:         self.__comment = comment
  965:         return self
  966: 
  967:     def where(self, code: Union[str, Code]) -> Cursor[_DocumentType]:
  968:         """Adds a `$where`_ clause to this query.
  969: 
  970:         The `code` argument must be an instance of :class:`str` or
  971:         :class:`~bson.code.Code` containing a JavaScript expression.
  972:         This expression will be evaluated for each document scanned.
  973:         Only those documents for which the expression evaluates to
  974:         *true* will be returned as results. The keyword *this* refers
  975:         to the object currently being scanned. For example::
  976: 
  977:             # Find all documents where field "a" is less than "b" plus "c".
  978:             for doc in db.test.find().where('this.a < (this.b + this.c)'):
  979:                 print(doc)
  980: 
  981:         Raises :class:`TypeError` if `code` is not an instance of
  982:         :class:`str`. Raises :class:`~pymongo.errors.InvalidOperation` if this
  983:         :class:`Cursor` has already been used. Only the last call to
  984:         :meth:`where` applied to a :class:`Cursor` has any effect.
  985: 
  986:         .. note:: MongoDB 4.4 drops support for :class:`~bson.code.Code`
  987:           with scope variables. Consider using `$expr`_ instead.
  988: 
  989:         :param code: JavaScript expression to use as a filter
  990: 
  991:         .. _$expr: https://mongodb.com/docs/manual/reference/operator/query/expr/
  992:         .. _$where: https://mongodb.com/docs/manual/reference/operator/query/where/
  993:         """
  994:         self.__check_okay_to_chain()
  995:         if not isinstance(code, Code):
  996:             code = Code(code)
  997: 
  998:         # Avoid overwriting a filter argument that was given by the user
  999:         # when updating the spec.
 1000:         spec: dict[str, Any]
 1001:         if self.__has_filter:
 1002:             spec = dict(self.__spec)
 1003:         else:
 1004:             spec = cast(dict, self.__spec)
 1005:         spec["$where"] = code
 1006:         self.__spec = spec
 1007:         return self
 1008: 
 1009:     def collation(self, collation: Optional[_CollationIn]) -> Cursor[_DocumentType]:
 1010:         """Adds a :class:`~pymongo.collation.Collation` to this query.
 1011: 
 1012:         Raises :exc:`TypeError` if `collation` is not an instance of
 1013:         :class:`~pymongo.collation.Collation` or a ``dict``. Raises
 1014:         :exc:`~pymongo.errors.InvalidOperation` if this :class:`Cursor` has
 1015:         already been used. Only the last collation applied to this cursor has
 1016:         any effect.
 1017: 
 1018:         :param collation: An instance of :class:`~pymongo.collation.Collation`.
 1019:         """
 1020:         self.__check_okay_to_chain()
 1021:         self.__collation = validate_collation_or_none(collation)
 1022:         return self
 1023: 
 1024:     def __send_message(self, operation: Union[_Query, _GetMore]) -> None:
 1025:         """Send a query or getmore operation and handles the response.
 1026: 
 1027:         If operation is ``None`` this is an exhaust cursor, which reads
 1028:         the next result batch off the exhaust socket instead of
 1029:         sending getMore messages to the server.
 1030: 
 1031:         Can raise ConnectionFailure.
 1032:         """
 1033:         client = self.__collection.database.client
 1034:         # OP_MSG is required to support exhaust cursors with encryption.
 1035:         if client._encrypter and self.__exhaust:
 1036:             raise InvalidOperation("exhaust cursors do not support auto encryption")
 1037: 
 1038:         try:
 1039:             response = client._run_operation(
 1040:                 operation, self._unpack_response, address=self.__address
 1041:             )
 1042:         except OperationFailure as exc:
 1043:             if exc.code in _CURSOR_CLOSED_ERRORS or self.__exhaust:
 1044:                 # Don't send killCursors because the cursor is already closed.
 1045:                 self.__killed = True
 1046:             if exc.timeout:
 1047:                 self.__die(False)
 1048:             else:
 1049:                 self.close()
 1050:             # If this is a tailable cursor the error is likely
 1051:             # due to capped collection roll over. Setting
 1052:             # self.__killed to True ensures Cursor.alive will be
 1053:             # False. No need to re-raise.
 1054:             if (
 1055:                 exc.code in _CURSOR_CLOSED_ERRORS
 1056:                 and self.__query_flags & _QUERY_OPTIONS["tailable_cursor"]
 1057:             ):
 1058:                 return
 1059:             raise
 1060:         except ConnectionFailure:
 1061:             self.__killed = True
 1062:             self.close()
 1063:             raise
 1064:         except Exception:
 1065:             self.close()
 1066:             raise
 1067: 
 1068:         self.__address = response.address
 1069:         if isinstance(response, PinnedResponse):
 1070:             if not self.__sock_mgr:
 1071:                 self.__sock_mgr = _ConnectionManager(response.conn, response.more_to_come)
 1072: 
 1073:         cmd_name = operation.name
 1074:         docs = response.docs
 1075:         if response.from_command:
 1076:             if cmd_name != "explain":
 1077:                 cursor = docs[0]["cursor"]
 1078:                 self.__id = cursor["id"]
 1079:                 if cmd_name == "find":
 1080:                     documents = cursor["firstBatch"]
 1081:                     # Update the namespace used for future getMore commands.
 1082:                     ns = cursor.get("ns")
 1083:                     if ns:
 1084:                         self.__dbname, self.__collname = ns.split(".", 1)
 1085:                 else:
 1086:                     documents = cursor["nextBatch"]
 1087:                 self.__data = deque(documents)
 1088:                 self.__retrieved += len(documents)
 1089:             else:
 1090:                 self.__id = 0
 1091:                 self.__data = deque(docs)
 1092:                 self.__retrieved += len(docs)
 1093:         else:
 1094:             assert isinstance(response.data, _OpReply)
 1095:             self.__id = response.data.cursor_id
 1096:             self.__data = deque(docs)
 1097:             self.__retrieved += response.data.number_returned
 1098: 
 1099:         if self.__id == 0:
 1100:             # Don't wait for garbage collection to call __del__, return the
 1101:             # socket and the session to the pool now.
 1102:             self.close()
 1103: 
 1104:         if self.__limit and self.__id and self.__limit <= self.__retrieved:
 1105:             self.close()
 1106: 
 1107:     def _unpack_response(
 1108:         self,
 1109:         response: Union[_OpReply, _OpMsg],
 1110:         cursor_id: Optional[int],
 1111:         codec_options: CodecOptions,
 1112:         user_fields: Optional[Mapping[str, Any]] = None,
 1113:         legacy_response: bool = False,
 1114:     ) -> Sequence[_DocumentOut]:
 1115:         return response.unpack_response(cursor_id, codec_options, user_fields, legacy_response)
 1116: 
 1117:     def _read_preference(self) -> _ServerMode:
 1118:         if self.__read_preference is None:
 1119:             # Save the read preference for getMore commands.
 1120:             self.__read_preference = self.__collection._read_preference_for(self.session)
 1121:         return self.__read_preference
 1122: 
 1123:     def _refresh(self) -> int:
 1124:         """Refreshes the cursor with more data from Mongo.
 1125: 
 1126:         Returns the length of self.__data after refresh. Will exit early if
 1127:         self.__data is already non-empty. Raises OperationFailure when the
 1128:         cursor cannot be refreshed due to an error on the query.
 1129:         """
 1130:         if len(self.__data) or self.__killed:
 1131:             return len(self.__data)
 1132: 
 1133:         if not self.__session:
 1134:             self.__session = self.__collection.database.client._ensure_session()
 1135: 
 1136:         if self.__id is None:  # Query
 1137:             if (self.__min or self.__max) and not self.__hint:
 1138:                 raise InvalidOperation(
 1139:                     "Passing a 'hint' is required when using the min/max query"
 1140:                     " option to ensure the query utilizes the correct index"
 1141:                 )
 1142:             q = self._query_class(
 1143:                 self.__query_flags,
 1144:                 self.__collection.database.name,
 1145:                 self.__collection.name,
 1146:                 self.__skip,
 1147:                 self.__query_spec(),
 1148:                 self.__projection,
 1149:                 self.__codec_options,
 1150:                 self._read_preference(),
 1151:                 self.__limit,
 1152:                 self.__batch_size,
 1153:                 self.__read_concern,
 1154:                 self.__collation,
 1155:                 self.__session,
 1156:                 self.__collection.database.client,
 1157:                 self.__allow_disk_use,
 1158:                 self.__exhaust,
 1159:             )
 1160:             self.__send_message(q)
 1161:         elif self.__id:  # Get More
 1162:             if self.__limit:
 1163:                 limit = self.__limit - self.__retrieved
 1164:                 if self.__batch_size:
 1165:                     limit = min(limit, self.__batch_size)
 1166:             else:
 1167:                 limit = self.__batch_size
 1168:             # Exhaust cursors don't send getMore messages.
 1169:             g = self._getmore_class(
 1170:                 self.__dbname,
 1171:                 self.__collname,
 1172:                 limit,
 1173:                 self.__id,
 1174:                 self.__codec_options,
 1175:                 self._read_preference(),
 1176:                 self.__session,
 1177:                 self.__collection.database.client,
 1178:                 self.__max_await_time_ms,
 1179:                 self.__sock_mgr,
 1180:                 self.__exhaust,
 1181:                 self.__comment,
 1182:             )
 1183:             self.__send_message(g)
 1184: 
 1185:         return len(self.__data)
 1186: 
 1187:     @property
 1188:     def alive(self) -> bool:
 1189:         """Does this cursor have the potential to return more data?
 1190: 
 1191:         This is mostly useful with `tailable cursors
 1192:         <https://www.mongodb.com/docs/manual/core/tailable-cursors/>`_
 1193:         since they will stop iterating even though they *may* return more
 1194:         results in the future.
 1195: 
 1196:         With regular cursors, simply use a for loop instead of :attr:`alive`::
 1197: 
 1198:             for doc in collection.find():
 1199:                 print(doc)
 1200: 
 1201:         .. note:: Even if :attr:`alive` is True, :meth:`next` can raise
 1202:           :exc:`StopIteration`. :attr:`alive` can also be True while iterating
 1203:           a cursor from a failed server. In this case :attr:`alive` will
 1204:           return False after :meth:`next` fails to retrieve the next batch
 1205:           of results from the server.
 1206:         """
 1207:         return bool(len(self.__data) or (not self.__killed))
 1208: 
 1209:     @property
 1210:     def cursor_id(self) -> Optional[int]:
 1211:         """Returns the id of the cursor
 1212: 
 1213:         .. versionadded:: 2.2
 1214:         """
 1215:         return self.__id
 1216: 
 1217:     @property
 1218:     def address(self) -> Optional[tuple[str, Any]]:
 1219:         """The (host, port) of the server used, or None.
 1220: 
 1221:         .. versionchanged:: 3.0
 1222:            Renamed from "conn_id".
 1223:         """
 1224:         return self.__address
 1225: 
 1226:     @property
 1227:     def session(self) -> Optional[ClientSession]:
 1228:         """The cursor's :class:`~pymongo.client_session.ClientSession`, or None.
 1229: 
 1230:         .. versionadded:: 3.6
 1231:         """
 1232:         if self.__explicit_session:
 1233:             return self.__session
 1234:         return None
 1235: 
 1236:     def __iter__(self) -> Cursor[_DocumentType]:
 1237:         return self
 1238: 
 1239:     def next(self) -> _DocumentType:
 1240:         """Advance the cursor."""
 1241:         if self.__empty:
 1242:             raise StopIteration
 1243:         if len(self.__data) or self._refresh():
 1244:             return self.__data.popleft()
 1245:         else:
 1246:             raise StopIteration
 1247: 
 1248:     __next__ = next
 1249: 
 1250:     def __enter__(self) -> Cursor[_DocumentType]:
 1251:         return self
 1252: 
 1253:     def __exit__(self, exc_type: Any, exc_val: Any, exc_tb: Any) -> None:
 1254:         self.close()
 1255: 
 1256:     def __copy__(self) -> Cursor[_DocumentType]:
 1257:         """Support function for `copy.copy()`.
 1258: 
 1259:         .. versionadded:: 2.4
 1260:         """
 1261:         return self._clone(deepcopy=False)
 1262: 
 1263:     def __deepcopy__(self, memo: Any) -> Any:
 1264:         """Support function for `copy.deepcopy()`.
 1265: 
 1266:         .. versionadded:: 2.4
 1267:         """
 1268:         return self._clone(deepcopy=True)
 1269: 
 1270:     @overload
 1271:     def _deepcopy(self, x: Iterable, memo: Optional[dict[int, Union[list, dict]]] = None) -> list:
 1272:         ...
 1273: 
 1274:     @overload
 1275:     def _deepcopy(
 1276:         self, x: SupportsItems, memo: Optional[dict[int, Union[list, dict]]] = None
 1277:     ) -> dict:
 1278:         ...
 1279: 
 1280:     def _deepcopy(
 1281:         self, x: Union[Iterable, SupportsItems], memo: Optional[dict[int, Union[list, dict]]] = None
 1282:     ) -> Union[list, dict]:
 1283:         """Deepcopy helper for the data dictionary or list.
 1284: 
 1285:         Regular expressions cannot be deep copied but as they are immutable we
 1286:         don't have to copy them when cloning.
 1287:         """
 1288:         y: Union[list, dict]
 1289:         iterator: Iterable[tuple[Any, Any]]
 1290:         if not hasattr(x, "items"):
 1291:             y, is_list, iterator = [], True, enumerate(x)
 1292:         else:
 1293:             y, is_list, iterator = {}, False, cast("SupportsItems", x).items()
 1294:         if memo is None:
 1295:             memo = {}
 1296:         val_id = id(x)
 1297:         if val_id in memo:
 1298:             return memo[val_id]
 1299:         memo[val_id] = y
 1300: 
 1301:         for key, value in iterator:
 1302:             if isinstance(value, (dict, list)) and not isinstance(value, SON):
 1303:                 value = self._deepcopy(value, memo)  # noqa: PLW2901
 1304:             elif not isinstance(value, RE_TYPE):
 1305:                 value = copy.deepcopy(value, memo)  # noqa: PLW2901
 1306: 
 1307:             if is_list:
 1308:                 y.append(value)  # type: ignore[union-attr]
 1309:             else:
 1310:                 if not isinstance(key, RE_TYPE):
 1311:                     key = copy.deepcopy(key, memo)  # noqa: PLW2901
 1312:                 y[key] = value
 1313:         return y
 1314: 
 1315: 
 1316: class RawBatchCursor(Cursor, Generic[_DocumentType]):
 1317:     """A cursor / iterator over raw batches of BSON data from a query result."""
 1318: 
 1319:     _query_class = _RawBatchQuery
 1320:     _getmore_class = _RawBatchGetMore
 1321: 
 1322:     def __init__(self, collection: Collection[_DocumentType], *args: Any, **kwargs: Any) -> None:
 1323:         """Create a new cursor / iterator over raw batches of BSON data.
 1324: 
 1325:         Should not be called directly by application developers -
 1326:         see :meth:`~pymongo.collection.Collection.find_raw_batches`
 1327:         instead.
 1328: 
 1329:         .. seealso:: The MongoDB documentation on `cursors <https://dochub.mongodb.org/core/cursors>`_.
 1330:         """
 1331:         super().__init__(collection, *args, **kwargs)
 1332: 
 1333:     def _unpack_response(
 1334:         self,
 1335:         response: Union[_OpReply, _OpMsg],
 1336:         cursor_id: Optional[int],
 1337:         codec_options: CodecOptions[Mapping[str, Any]],
 1338:         user_fields: Optional[Mapping[str, Any]] = None,
 1339:         legacy_response: bool = False,
 1340:     ) -> list[_DocumentOut]:
 1341:         raw_response = response.raw_response(cursor_id, user_fields=user_fields)
 1342:         if not legacy_response:
 1343:             # OP_MSG returns firstBatch/nextBatch documents as a BSON array
 1344:             # Re-assemble the array of documents into a document stream
 1345:             _convert_raw_document_lists_to_streams(raw_response[0])
 1346:         return cast(List["_DocumentOut"], raw_response)
 1347: 
 1348:     def explain(self) -> _DocumentType:
 1349:         """Returns an explain plan record for this cursor.
 1350: 
 1351:         .. seealso:: The MongoDB documentation on `explain <https://dochub.mongodb.org/core/explain>`_.
 1352:         """
 1353:         clone = self._clone(deepcopy=True, base=Cursor(self.collection))
 1354:         return clone.explain()
 1355: 
 1356:     def __getitem__(self, index: Any) -> NoReturn:
 1357:         raise InvalidOperation("Cannot call __getitem__ on RawBatchCursor")
