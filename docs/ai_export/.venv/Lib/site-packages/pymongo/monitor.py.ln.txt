    1: # Copyright 2014-present MongoDB, Inc.
    2: #
    3: # Licensed under the Apache License, Version 2.0 (the "License"); you
    4: # may not use this file except in compliance with the License.  You
    5: # may obtain a copy of the License at
    6: #
    7: # http://www.apache.org/licenses/LICENSE-2.0
    8: #
    9: # Unless required by applicable law or agreed to in writing, software
   10: # distributed under the License is distributed on an "AS IS" BASIS,
   11: # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or
   12: # implied.  See the License for the specific language governing
   13: # permissions and limitations under the License.
   14: 
   15: """Class to monitor a MongoDB server on a background thread."""
   16: 
   17: from __future__ import annotations
   18: 
   19: import atexit
   20: import time
   21: import weakref
   22: from typing import TYPE_CHECKING, Any, Mapping, Optional, cast
   23: 
   24: from pymongo import common, periodic_executor
   25: from pymongo._csot import MovingMinimum
   26: from pymongo.errors import NetworkTimeout, NotPrimaryError, OperationFailure, _OperationCancelled
   27: from pymongo.hello import Hello
   28: from pymongo.lock import _create_lock
   29: from pymongo.periodic_executor import _shutdown_executors
   30: from pymongo.pool import _is_faas
   31: from pymongo.read_preferences import MovingAverage
   32: from pymongo.server_description import ServerDescription
   33: from pymongo.srv_resolver import _SrvResolver
   34: 
   35: if TYPE_CHECKING:
   36:     from pymongo.pool import Connection, Pool, _CancellationContext
   37:     from pymongo.settings import TopologySettings
   38:     from pymongo.topology import Topology
   39: 
   40: 
   41: def _sanitize(error: Exception) -> None:
   42:     """PYTHON-2433 Clear error traceback info."""
   43:     error.__traceback__ = None
   44:     error.__context__ = None
   45:     error.__cause__ = None
   46: 
   47: 
   48: class MonitorBase:
   49:     def __init__(self, topology: Topology, name: str, interval: int, min_interval: float):
   50:         """Base class to do periodic work on a background thread.
   51: 
   52:         The background thread is signaled to stop when the Topology or
   53:         this instance is freed.
   54:         """
   55: 
   56:         # We strongly reference the executor and it weakly references us via
   57:         # this closure. When the monitor is freed, stop the executor soon.
   58:         def target() -> bool:
   59:             monitor = self_ref()
   60:             if monitor is None:
   61:                 return False  # Stop the executor.
   62:             monitor._run()  # type:ignore[attr-defined]
   63:             return True
   64: 
   65:         executor = periodic_executor.PeriodicExecutor(
   66:             interval=interval, min_interval=min_interval, target=target, name=name
   67:         )
   68: 
   69:         self._executor = executor
   70: 
   71:         def _on_topology_gc(dummy: Optional[Topology] = None) -> None:
   72:             # This prevents GC from waiting 10 seconds for hello to complete
   73:             # See test_cleanup_executors_on_client_del.
   74:             monitor = self_ref()
   75:             if monitor:
   76:                 monitor.gc_safe_close()
   77: 
   78:         # Avoid cycles. When self or topology is freed, stop executor soon.
   79:         self_ref = weakref.ref(self, executor.close)
   80:         self._topology = weakref.proxy(topology, _on_topology_gc)
   81:         _register(self)
   82: 
   83:     def open(self) -> None:
   84:         """Start monitoring, or restart after a fork.
   85: 
   86:         Multiple calls have no effect.
   87:         """
   88:         self._executor.open()
   89: 
   90:     def gc_safe_close(self) -> None:
   91:         """GC safe close."""
   92:         self._executor.close()
   93: 
   94:     def close(self) -> None:
   95:         """Close and stop monitoring.
   96: 
   97:         open() restarts the monitor after closing.
   98:         """
   99:         self.gc_safe_close()
  100: 
  101:     def join(self, timeout: Optional[int] = None) -> None:
  102:         """Wait for the monitor to stop."""
  103:         self._executor.join(timeout)
  104: 
  105:     def request_check(self) -> None:
  106:         """If the monitor is sleeping, wake it soon."""
  107:         self._executor.wake()
  108: 
  109: 
  110: class Monitor(MonitorBase):
  111:     def __init__(
  112:         self,
  113:         server_description: ServerDescription,
  114:         topology: Topology,
  115:         pool: Pool,
  116:         topology_settings: TopologySettings,
  117:     ):
  118:         """Class to monitor a MongoDB server on a background thread.
  119: 
  120:         Pass an initial ServerDescription, a Topology, a Pool, and
  121:         TopologySettings.
  122: 
  123:         The Topology is weakly referenced. The Pool must be exclusive to this
  124:         Monitor.
  125:         """
  126:         super().__init__(
  127:             topology,
  128:             "pymongo_server_monitor_thread",
  129:             topology_settings.heartbeat_frequency,
  130:             common.MIN_HEARTBEAT_INTERVAL,
  131:         )
  132:         self._server_description = server_description
  133:         self._pool = pool
  134:         self._settings = topology_settings
  135:         self._listeners = self._settings._pool_options._event_listeners
  136:         self._publish = self._listeners is not None and self._listeners.enabled_for_server_heartbeat
  137:         self._cancel_context: Optional[_CancellationContext] = None
  138:         self._rtt_monitor = _RttMonitor(
  139:             topology,
  140:             topology_settings,
  141:             topology._create_pool_for_monitor(server_description.address),
  142:         )
  143:         if topology_settings.server_monitoring_mode == "stream":
  144:             self._stream = True
  145:         elif topology_settings.server_monitoring_mode == "poll":
  146:             self._stream = False
  147:         else:
  148:             self._stream = not _is_faas()
  149: 
  150:     def cancel_check(self) -> None:
  151:         """Cancel any concurrent hello check.
  152: 
  153:         Note: this is called from a weakref.proxy callback and MUST NOT take
  154:         any locks.
  155:         """
  156:         context = self._cancel_context
  157:         if context:
  158:             # Note: we cannot close the socket because doing so may cause
  159:             # concurrent reads/writes to hang until a timeout occurs
  160:             # (depending on the platform).
  161:             context.cancel()
  162: 
  163:     def _start_rtt_monitor(self) -> None:
  164:         """Start an _RttMonitor that periodically runs ping."""
  165:         # If this monitor is closed directly before (or during) this open()
  166:         # call, the _RttMonitor will not be closed. Checking if this monitor
  167:         # was closed directly after resolves the race.
  168:         self._rtt_monitor.open()
  169:         if self._executor._stopped:
  170:             self._rtt_monitor.close()
  171: 
  172:     def gc_safe_close(self) -> None:
  173:         self._executor.close()
  174:         self._rtt_monitor.gc_safe_close()
  175:         self.cancel_check()
  176: 
  177:     def close(self) -> None:
  178:         self.gc_safe_close()
  179:         self._rtt_monitor.close()
  180:         # Increment the generation and maybe close the socket. If the executor
  181:         # thread has the socket checked out, it will be closed when checked in.
  182:         self._reset_connection()
  183: 
  184:     def _reset_connection(self) -> None:
  185:         # Clear our pooled connection.
  186:         self._pool.reset()
  187: 
  188:     def _run(self) -> None:
  189:         try:
  190:             prev_sd = self._server_description
  191:             try:
  192:                 self._server_description = self._check_server()
  193:             except _OperationCancelled as exc:
  194:                 _sanitize(exc)
  195:                 # Already closed the connection, wait for the next check.
  196:                 self._server_description = ServerDescription(
  197:                     self._server_description.address, error=exc
  198:                 )
  199:                 if prev_sd.is_server_type_known:
  200:                     # Immediately retry since we've already waited 500ms to
  201:                     # discover that we've been cancelled.
  202:                     self._executor.skip_sleep()
  203:                 return
  204: 
  205:             # Update the Topology and clear the server pool on error.
  206:             self._topology.on_change(
  207:                 self._server_description,
  208:                 reset_pool=self._server_description.error,
  209:                 interrupt_connections=isinstance(self._server_description.error, NetworkTimeout),
  210:             )
  211: 
  212:             if self._stream and (
  213:                 self._server_description.is_server_type_known
  214:                 and self._server_description.topology_version
  215:             ):
  216:                 self._start_rtt_monitor()
  217:                 # Immediately check for the next streaming response.
  218:                 self._executor.skip_sleep()
  219: 
  220:             if self._server_description.error and prev_sd.is_server_type_known:
  221:                 # Immediately retry on network errors.
  222:                 self._executor.skip_sleep()
  223:         except ReferenceError:
  224:             # Topology was garbage-collected.
  225:             self.close()
  226: 
  227:     def _check_server(self) -> ServerDescription:
  228:         """Call hello or read the next streaming response.
  229: 
  230:         Returns a ServerDescription.
  231:         """
  232:         start = time.monotonic()
  233:         try:
  234:             try:
  235:                 return self._check_once()
  236:             except (OperationFailure, NotPrimaryError) as exc:
  237:                 # Update max cluster time even when hello fails.
  238:                 details = cast(Mapping[str, Any], exc.details)
  239:                 self._topology.receive_cluster_time(details.get("$clusterTime"))
  240:                 raise
  241:         except ReferenceError:
  242:             raise
  243:         except Exception as error:
  244:             _sanitize(error)
  245:             sd = self._server_description
  246:             address = sd.address
  247:             duration = time.monotonic() - start
  248:             if self._publish:
  249:                 awaited = bool(self._stream and sd.is_server_type_known and sd.topology_version)
  250:                 assert self._listeners is not None
  251:                 self._listeners.publish_server_heartbeat_failed(address, duration, error, awaited)
  252:             self._reset_connection()
  253:             if isinstance(error, _OperationCancelled):
  254:                 raise
  255:             self._rtt_monitor.reset()
  256:             # Server type defaults to Unknown.
  257:             return ServerDescription(address, error=error)
  258: 
  259:     def _check_once(self) -> ServerDescription:
  260:         """A single attempt to call hello.
  261: 
  262:         Returns a ServerDescription, or raises an exception.
  263:         """
  264:         address = self._server_description.address
  265:         if self._publish:
  266:             assert self._listeners is not None
  267:             sd = self._server_description
  268:             # XXX: "awaited" could be incorrectly set to True in the rare case
  269:             # the pool checkout closes and recreates a connection.
  270:             awaited = bool(
  271:                 self._pool.conns
  272:                 and self._stream
  273:                 and sd.is_server_type_known
  274:                 and sd.topology_version
  275:             )
  276:             self._listeners.publish_server_heartbeat_started(address, awaited)
  277: 
  278:         if self._cancel_context and self._cancel_context.cancelled:
  279:             self._reset_connection()
  280:         with self._pool.checkout() as conn:
  281:             self._cancel_context = conn.cancel_context
  282:             response, round_trip_time = self._check_with_socket(conn)
  283:             if not response.awaitable:
  284:                 self._rtt_monitor.add_sample(round_trip_time)
  285: 
  286:             avg_rtt, min_rtt = self._rtt_monitor.get()
  287:             sd = ServerDescription(address, response, avg_rtt, min_round_trip_time=min_rtt)
  288:             if self._publish:
  289:                 assert self._listeners is not None
  290:                 self._listeners.publish_server_heartbeat_succeeded(
  291:                     address, round_trip_time, response, response.awaitable
  292:                 )
  293:             return sd
  294: 
  295:     def _check_with_socket(self, conn: Connection) -> tuple[Hello, float]:
  296:         """Return (Hello, round_trip_time).
  297: 
  298:         Can raise ConnectionFailure or OperationFailure.
  299:         """
  300:         cluster_time = self._topology.max_cluster_time()
  301:         start = time.monotonic()
  302:         if conn.more_to_come:
  303:             # Read the next streaming hello (MongoDB 4.4+).
  304:             response = Hello(conn._next_reply(), awaitable=True)
  305:         elif (
  306:             self._stream and conn.performed_handshake and self._server_description.topology_version
  307:         ):
  308:             # Initiate streaming hello (MongoDB 4.4+).
  309:             response = conn._hello(
  310:                 cluster_time,
  311:                 self._server_description.topology_version,
  312:                 self._settings.heartbeat_frequency,
  313:             )
  314:         else:
  315:             # New connection handshake or polling hello (MongoDB <4.4).
  316:             response = conn._hello(cluster_time, None, None)
  317:         return response, time.monotonic() - start
  318: 
  319: 
  320: class SrvMonitor(MonitorBase):
  321:     def __init__(self, topology: Topology, topology_settings: TopologySettings):
  322:         """Class to poll SRV records on a background thread.
  323: 
  324:         Pass a Topology and a TopologySettings.
  325: 
  326:         The Topology is weakly referenced.
  327:         """
  328:         super().__init__(
  329:             topology,
  330:             "pymongo_srv_polling_thread",
  331:             common.MIN_SRV_RESCAN_INTERVAL,
  332:             topology_settings.heartbeat_frequency,
  333:         )
  334:         self._settings = topology_settings
  335:         self._seedlist = self._settings._seeds
  336:         assert isinstance(self._settings.fqdn, str)
  337:         self._fqdn: str = self._settings.fqdn
  338:         self._startup_time = time.monotonic()
  339: 
  340:     def _run(self) -> None:
  341:         # Don't poll right after creation, wait 60 seconds first
  342:         if time.monotonic() < self._startup_time + common.MIN_SRV_RESCAN_INTERVAL:
  343:             return
  344:         seedlist = self._get_seedlist()
  345:         if seedlist:
  346:             self._seedlist = seedlist
  347:             try:
  348:                 self._topology.on_srv_update(self._seedlist)
  349:             except ReferenceError:
  350:                 # Topology was garbage-collected.
  351:                 self.close()
  352: 
  353:     def _get_seedlist(self) -> Optional[list[tuple[str, Any]]]:
  354:         """Poll SRV records for a seedlist.
  355: 
  356:         Returns a list of ServerDescriptions.
  357:         """
  358:         try:
  359:             resolver = _SrvResolver(
  360:                 self._fqdn,
  361:                 self._settings.pool_options.connect_timeout,
  362:                 self._settings.srv_service_name,
  363:             )
  364:             seedlist, ttl = resolver.get_hosts_and_min_ttl()
  365:             if len(seedlist) == 0:
  366:                 # As per the spec: this should be treated as a failure.
  367:                 raise Exception
  368:         except Exception:
  369:             # As per the spec, upon encountering an error:
  370:             # - An error must not be raised
  371:             # - SRV records must be rescanned every heartbeatFrequencyMS
  372:             # - Topology must be left unchanged
  373:             self.request_check()
  374:             return None
  375:         else:
  376:             self._executor.update_interval(max(ttl, common.MIN_SRV_RESCAN_INTERVAL))
  377:             return seedlist
  378: 
  379: 
  380: class _RttMonitor(MonitorBase):
  381:     def __init__(self, topology: Topology, topology_settings: TopologySettings, pool: Pool):
  382:         """Maintain round trip times for a server.
  383: 
  384:         The Topology is weakly referenced.
  385:         """
  386:         super().__init__(
  387:             topology,
  388:             "pymongo_server_rtt_thread",
  389:             topology_settings.heartbeat_frequency,
  390:             common.MIN_HEARTBEAT_INTERVAL,
  391:         )
  392: 
  393:         self._pool = pool
  394:         self._moving_average = MovingAverage()
  395:         self._moving_min = MovingMinimum()
  396:         self._lock = _create_lock()
  397: 
  398:     def close(self) -> None:
  399:         self.gc_safe_close()
  400:         # Increment the generation and maybe close the socket. If the executor
  401:         # thread has the socket checked out, it will be closed when checked in.
  402:         self._pool.reset()
  403: 
  404:     def add_sample(self, sample: float) -> None:
  405:         """Add a RTT sample."""
  406:         with self._lock:
  407:             self._moving_average.add_sample(sample)
  408:             self._moving_min.add_sample(sample)
  409: 
  410:     def get(self) -> tuple[Optional[float], float]:
  411:         """Get the calculated average, or None if no samples yet and the min."""
  412:         with self._lock:
  413:             return self._moving_average.get(), self._moving_min.get()
  414: 
  415:     def reset(self) -> None:
  416:         """Reset the average RTT."""
  417:         with self._lock:
  418:             self._moving_average.reset()
  419:             self._moving_min.reset()
  420: 
  421:     def _run(self) -> None:
  422:         try:
  423:             # NOTE: This thread is only run when using the streaming
  424:             # heartbeat protocol (MongoDB 4.4+).
  425:             # XXX: Skip check if the server is unknown?
  426:             rtt = self._ping()
  427:             self.add_sample(rtt)
  428:         except ReferenceError:
  429:             # Topology was garbage-collected.
  430:             self.close()
  431:         except Exception:
  432:             self._pool.reset()
  433: 
  434:     def _ping(self) -> float:
  435:         """Run a "hello" command and return the RTT."""
  436:         with self._pool.checkout() as conn:
  437:             if self._executor._stopped:
  438:                 raise Exception("_RttMonitor closed")
  439:             start = time.monotonic()
  440:             conn.hello()
  441:             return time.monotonic() - start
  442: 
  443: 
  444: # Close monitors to cancel any in progress streaming checks before joining
  445: # executor threads. For an explanation of how this works see the comment
  446: # about _EXECUTORS in periodic_executor.py.
  447: _MONITORS = set()
  448: 
  449: 
  450: def _register(monitor: MonitorBase) -> None:
  451:     ref = weakref.ref(monitor, _unregister)
  452:     _MONITORS.add(ref)
  453: 
  454: 
  455: def _unregister(monitor_ref: weakref.ReferenceType[MonitorBase]) -> None:
  456:     _MONITORS.remove(monitor_ref)
  457: 
  458: 
  459: def _shutdown_monitors() -> None:
  460:     if _MONITORS is None:
  461:         return
  462: 
  463:     # Copy the set. Closing monitors removes them.
  464:     monitors = list(_MONITORS)
  465: 
  466:     # Close all monitors.
  467:     for ref in monitors:
  468:         monitor = ref()
  469:         if monitor:
  470:             monitor.gc_safe_close()
  471: 
  472:     monitor = None
  473: 
  474: 
  475: def _shutdown_resources() -> None:
  476:     # _shutdown_monitors/_shutdown_executors may already be GC'd at shutdown.
  477:     shutdown = _shutdown_monitors
  478:     if shutdown:  # type:ignore[truthy-function]
  479:         shutdown()
  480:     shutdown = _shutdown_executors
  481:     if shutdown:  # type:ignore[truthy-function]
  482:         shutdown()
  483: 
  484: 
  485: atexit.register(_shutdown_resources)
