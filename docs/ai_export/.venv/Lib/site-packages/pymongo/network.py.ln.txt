    1: # Copyright 2015-present MongoDB, Inc.
    2: #
    3: # Licensed under the Apache License, Version 2.0 (the "License");
    4: # you may not use this file except in compliance with the License.
    5: # You may obtain a copy of the License at
    6: #
    7: # http://www.apache.org/licenses/LICENSE-2.0
    8: #
    9: # Unless required by applicable law or agreed to in writing, software
   10: # distributed under the License is distributed on an "AS IS" BASIS,
   11: # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   12: # See the License for the specific language governing permissions and
   13: # limitations under the License.
   14: 
   15: """Internal network layer helper methods."""
   16: from __future__ import annotations
   17: 
   18: import datetime
   19: import errno
   20: import logging
   21: import socket
   22: import struct
   23: import time
   24: from typing import (
   25:     TYPE_CHECKING,
   26:     Any,
   27:     Mapping,
   28:     MutableMapping,
   29:     Optional,
   30:     Sequence,
   31:     Union,
   32:     cast,
   33: )
   34: 
   35: from bson import _decode_all_selective
   36: from pymongo import _csot, helpers, message, ssl_support
   37: from pymongo.common import MAX_MESSAGE_SIZE
   38: from pymongo.compression_support import _NO_COMPRESSION, decompress
   39: from pymongo.errors import (
   40:     NotPrimaryError,
   41:     OperationFailure,
   42:     ProtocolError,
   43:     _OperationCancelled,
   44: )
   45: from pymongo.logger import _COMMAND_LOGGER, _CommandStatusMessage, _debug_log
   46: from pymongo.message import _UNPACK_REPLY, _OpMsg, _OpReply
   47: from pymongo.monitoring import _is_speculative_authenticate
   48: from pymongo.socket_checker import _errno_from_exception
   49: 
   50: if TYPE_CHECKING:
   51:     from bson import CodecOptions
   52:     from pymongo.client_session import ClientSession
   53:     from pymongo.compression_support import SnappyContext, ZlibContext, ZstdContext
   54:     from pymongo.mongo_client import MongoClient
   55:     from pymongo.monitoring import _EventListeners
   56:     from pymongo.pool import Connection
   57:     from pymongo.read_concern import ReadConcern
   58:     from pymongo.read_preferences import _ServerMode
   59:     from pymongo.typings import _Address, _CollationIn, _DocumentOut, _DocumentType
   60:     from pymongo.write_concern import WriteConcern
   61: 
   62: _UNPACK_HEADER = struct.Struct("<iiii").unpack
   63: 
   64: 
   65: def command(
   66:     conn: Connection,
   67:     dbname: str,
   68:     spec: MutableMapping[str, Any],
   69:     is_mongos: bool,
   70:     read_preference: Optional[_ServerMode],
   71:     codec_options: CodecOptions[_DocumentType],
   72:     session: Optional[ClientSession],
   73:     client: Optional[MongoClient],
   74:     check: bool = True,
   75:     allowable_errors: Optional[Sequence[Union[str, int]]] = None,
   76:     address: Optional[_Address] = None,
   77:     listeners: Optional[_EventListeners] = None,
   78:     max_bson_size: Optional[int] = None,
   79:     read_concern: Optional[ReadConcern] = None,
   80:     parse_write_concern_error: bool = False,
   81:     collation: Optional[_CollationIn] = None,
   82:     compression_ctx: Union[SnappyContext, ZlibContext, ZstdContext, None] = None,
   83:     use_op_msg: bool = False,
   84:     unacknowledged: bool = False,
   85:     user_fields: Optional[Mapping[str, Any]] = None,
   86:     exhaust_allowed: bool = False,
   87:     write_concern: Optional[WriteConcern] = None,
   88: ) -> _DocumentType:
   89:     """Execute a command over the socket, or raise socket.error.
   90: 
   91:     :param conn: a Connection instance
   92:     :param dbname: name of the database on which to run the command
   93:     :param spec: a command document as an ordered dict type, eg SON.
   94:     :param is_mongos: are we connected to a mongos?
   95:     :param read_preference: a read preference
   96:     :param codec_options: a CodecOptions instance
   97:     :param session: optional ClientSession instance.
   98:     :param client: optional MongoClient instance for updating $clusterTime.
   99:     :param check: raise OperationFailure if there are errors
  100:     :param allowable_errors: errors to ignore if `check` is True
  101:     :param address: the (host, port) of `conn`
  102:     :param listeners: An instance of :class:`~pymongo.monitoring.EventListeners`
  103:     :param max_bson_size: The maximum encoded bson size for this server
  104:     :param read_concern: The read concern for this command.
  105:     :param parse_write_concern_error: Whether to parse the ``writeConcernError``
  106:         field in the command response.
  107:     :param collation: The collation for this command.
  108:     :param compression_ctx: optional compression Context.
  109:     :param use_op_msg: True if we should use OP_MSG.
  110:     :param unacknowledged: True if this is an unacknowledged command.
  111:     :param user_fields: Response fields that should be decoded
  112:         using the TypeDecoders from codec_options, passed to
  113:         bson._decode_all_selective.
  114:     :param exhaust_allowed: True if we should enable OP_MSG exhaustAllowed.
  115:     """
  116:     name = next(iter(spec))
  117:     ns = dbname + ".$cmd"
  118:     speculative_hello = False
  119: 
  120:     # Publish the original command document, perhaps with lsid and $clusterTime.
  121:     orig = spec
  122:     if is_mongos and not use_op_msg:
  123:         assert read_preference is not None
  124:         spec = message._maybe_add_read_preference(spec, read_preference)
  125:     if read_concern and not (session and session.in_transaction):
  126:         if read_concern.level:
  127:             spec["readConcern"] = read_concern.document
  128:         if session:
  129:             session._update_read_concern(spec, conn)
  130:     if collation is not None:
  131:         spec["collation"] = collation
  132: 
  133:     publish = listeners is not None and listeners.enabled_for_commands
  134:     start = datetime.datetime.now()
  135:     if publish:
  136:         speculative_hello = _is_speculative_authenticate(name, spec)
  137: 
  138:     if compression_ctx and name.lower() in _NO_COMPRESSION:
  139:         compression_ctx = None
  140: 
  141:     if client and client._encrypter and not client._encrypter._bypass_auto_encryption:
  142:         spec = orig = client._encrypter.encrypt(dbname, spec, codec_options)
  143: 
  144:     # Support CSOT
  145:     if client:
  146:         conn.apply_timeout(client, spec)
  147:     _csot.apply_write_concern(spec, write_concern)
  148: 
  149:     if use_op_msg:
  150:         flags = _OpMsg.MORE_TO_COME if unacknowledged else 0
  151:         flags |= _OpMsg.EXHAUST_ALLOWED if exhaust_allowed else 0
  152:         request_id, msg, size, max_doc_size = message._op_msg(
  153:             flags, spec, dbname, read_preference, codec_options, ctx=compression_ctx
  154:         )
  155:         # If this is an unacknowledged write then make sure the encoded doc(s)
  156:         # are small enough, otherwise rely on the server to return an error.
  157:         if unacknowledged and max_bson_size is not None and max_doc_size > max_bson_size:
  158:             message._raise_document_too_large(name, size, max_bson_size)
  159:     else:
  160:         request_id, msg, size = message._query(
  161:             0, ns, 0, -1, spec, None, codec_options, compression_ctx
  162:         )
  163: 
  164:     if max_bson_size is not None and size > max_bson_size + message._COMMAND_OVERHEAD:
  165:         message._raise_document_too_large(name, size, max_bson_size + message._COMMAND_OVERHEAD)
  166:     if client is not None:
  167:         if _COMMAND_LOGGER.isEnabledFor(logging.DEBUG):
  168:             _debug_log(
  169:                 _COMMAND_LOGGER,
  170:                 clientId=client._topology_settings._topology_id,
  171:                 message=_CommandStatusMessage.STARTED,
  172:                 command=spec,
  173:                 commandName=next(iter(spec)),
  174:                 databaseName=dbname,
  175:                 requestId=request_id,
  176:                 operationId=request_id,
  177:                 driverConnectionId=conn.id,
  178:                 serverConnectionId=conn.server_connection_id,
  179:                 serverHost=conn.address[0],
  180:                 serverPort=conn.address[1],
  181:                 serviceId=conn.service_id,
  182:             )
  183:     if publish:
  184:         assert listeners is not None
  185:         assert address is not None
  186:         listeners.publish_command_start(
  187:             orig,
  188:             dbname,
  189:             request_id,
  190:             address,
  191:             conn.server_connection_id,
  192:             service_id=conn.service_id,
  193:         )
  194: 
  195:     try:
  196:         conn.conn.sendall(msg)
  197:         if use_op_msg and unacknowledged:
  198:             # Unacknowledged, fake a successful command response.
  199:             reply = None
  200:             response_doc: _DocumentOut = {"ok": 1}
  201:         else:
  202:             reply = receive_message(conn, request_id)
  203:             conn.more_to_come = reply.more_to_come
  204:             unpacked_docs = reply.unpack_response(
  205:                 codec_options=codec_options, user_fields=user_fields
  206:             )
  207: 
  208:             response_doc = unpacked_docs[0]
  209:             if client:
  210:                 client._process_response(response_doc, session)
  211:             if check:
  212:                 helpers._check_command_response(
  213:                     response_doc,
  214:                     conn.max_wire_version,
  215:                     allowable_errors,
  216:                     parse_write_concern_error=parse_write_concern_error,
  217:                 )
  218:     except Exception as exc:
  219:         duration = datetime.datetime.now() - start
  220:         if isinstance(exc, (NotPrimaryError, OperationFailure)):
  221:             failure: _DocumentOut = exc.details  # type: ignore[assignment]
  222:         else:
  223:             failure = message._convert_exception(exc)
  224:         if client is not None:
  225:             if _COMMAND_LOGGER.isEnabledFor(logging.DEBUG):
  226:                 _debug_log(
  227:                     _COMMAND_LOGGER,
  228:                     clientId=client._topology_settings._topology_id,
  229:                     message=_CommandStatusMessage.FAILED,
  230:                     durationMS=duration,
  231:                     failure=failure,
  232:                     commandName=next(iter(spec)),
  233:                     databaseName=dbname,
  234:                     requestId=request_id,
  235:                     operationId=request_id,
  236:                     driverConnectionId=conn.id,
  237:                     serverConnectionId=conn.server_connection_id,
  238:                     serverHost=conn.address[0],
  239:                     serverPort=conn.address[1],
  240:                     serviceId=conn.service_id,
  241:                     isServerSideError=isinstance(exc, OperationFailure),
  242:                 )
  243:         if publish:
  244:             assert listeners is not None
  245:             assert address is not None
  246:             listeners.publish_command_failure(
  247:                 duration,
  248:                 failure,
  249:                 name,
  250:                 request_id,
  251:                 address,
  252:                 conn.server_connection_id,
  253:                 service_id=conn.service_id,
  254:                 database_name=dbname,
  255:             )
  256:         raise
  257:     duration = datetime.datetime.now() - start
  258:     if client is not None:
  259:         if _COMMAND_LOGGER.isEnabledFor(logging.DEBUG):
  260:             _debug_log(
  261:                 _COMMAND_LOGGER,
  262:                 clientId=client._topology_settings._topology_id,
  263:                 message=_CommandStatusMessage.SUCCEEDED,
  264:                 durationMS=duration,
  265:                 reply=response_doc,
  266:                 commandName=next(iter(spec)),
  267:                 databaseName=dbname,
  268:                 requestId=request_id,
  269:                 operationId=request_id,
  270:                 driverConnectionId=conn.id,
  271:                 serverConnectionId=conn.server_connection_id,
  272:                 serverHost=conn.address[0],
  273:                 serverPort=conn.address[1],
  274:                 serviceId=conn.service_id,
  275:                 speculative_authenticate="speculativeAuthenticate" in orig,
  276:             )
  277:     if publish:
  278:         assert listeners is not None
  279:         assert address is not None
  280:         listeners.publish_command_success(
  281:             duration,
  282:             response_doc,
  283:             name,
  284:             request_id,
  285:             address,
  286:             conn.server_connection_id,
  287:             service_id=conn.service_id,
  288:             speculative_hello=speculative_hello,
  289:             database_name=dbname,
  290:         )
  291: 
  292:     if client and client._encrypter and reply:
  293:         decrypted = client._encrypter.decrypt(reply.raw_command_response())
  294:         response_doc = cast(
  295:             "_DocumentOut", _decode_all_selective(decrypted, codec_options, user_fields)[0]
  296:         )
  297: 
  298:     return response_doc  # type: ignore[return-value]
  299: 
  300: 
  301: _UNPACK_COMPRESSION_HEADER = struct.Struct("<iiB").unpack
  302: 
  303: 
  304: def receive_message(
  305:     conn: Connection, request_id: Optional[int], max_message_size: int = MAX_MESSAGE_SIZE
  306: ) -> Union[_OpReply, _OpMsg]:
  307:     """Receive a raw BSON message or raise socket.error."""
  308:     if _csot.get_timeout():
  309:         deadline = _csot.get_deadline()
  310:     else:
  311:         timeout = conn.conn.gettimeout()
  312:         if timeout:
  313:             deadline = time.monotonic() + timeout
  314:         else:
  315:             deadline = None
  316:     # Ignore the response's request id.
  317:     length, _, response_to, op_code = _UNPACK_HEADER(_receive_data_on_socket(conn, 16, deadline))
  318:     # No request_id for exhaust cursor "getMore".
  319:     if request_id is not None:
  320:         if request_id != response_to:
  321:             raise ProtocolError(f"Got response id {response_to!r} but expected {request_id!r}")
  322:     if length <= 16:
  323:         raise ProtocolError(
  324:             f"Message length ({length!r}) not longer than standard message header size (16)"
  325:         )
  326:     if length > max_message_size:
  327:         raise ProtocolError(
  328:             f"Message length ({length!r}) is larger than server max "
  329:             f"message size ({max_message_size!r})"
  330:         )
  331:     if op_code == 2012:
  332:         op_code, _, compressor_id = _UNPACK_COMPRESSION_HEADER(
  333:             _receive_data_on_socket(conn, 9, deadline)
  334:         )
  335:         data = decompress(_receive_data_on_socket(conn, length - 25, deadline), compressor_id)
  336:     else:
  337:         data = _receive_data_on_socket(conn, length - 16, deadline)
  338: 
  339:     try:
  340:         unpack_reply = _UNPACK_REPLY[op_code]
  341:     except KeyError:
  342:         raise ProtocolError(
  343:             f"Got opcode {op_code!r} but expected {_UNPACK_REPLY.keys()!r}"
  344:         ) from None
  345:     return unpack_reply(data)
  346: 
  347: 
  348: _POLL_TIMEOUT = 0.5
  349: 
  350: 
  351: def wait_for_read(conn: Connection, deadline: Optional[float]) -> None:
  352:     """Block until at least one byte is read, or a timeout, or a cancel."""
  353:     sock = conn.conn
  354:     timed_out = False
  355:     # Check if the connection's socket has been manually closed
  356:     if sock.fileno() == -1:
  357:         return
  358:     while True:
  359:         # SSLSocket can have buffered data which won't be caught by select.
  360:         if hasattr(sock, "pending") and sock.pending() > 0:
  361:             readable = True
  362:         else:
  363:             # Wait up to 500ms for the socket to become readable and then
  364:             # check for cancellation.
  365:             if deadline:
  366:                 remaining = deadline - time.monotonic()
  367:                 # When the timeout has expired perform one final check to
  368:                 # see if the socket is readable. This helps avoid spurious
  369:                 # timeouts on AWS Lambda and other FaaS environments.
  370:                 if remaining <= 0:
  371:                     timed_out = True
  372:                 timeout = max(min(remaining, _POLL_TIMEOUT), 0)
  373:             else:
  374:                 timeout = _POLL_TIMEOUT
  375:             readable = conn.socket_checker.select(sock, read=True, timeout=timeout)
  376:         if conn.cancel_context.cancelled:
  377:             raise _OperationCancelled("operation cancelled")
  378:         if readable:
  379:             return
  380:         if timed_out:
  381:             raise socket.timeout("timed out")
  382: 
  383: 
  384: # Errors raised by sockets (and TLS sockets) when in non-blocking mode.
  385: BLOCKING_IO_ERRORS = (BlockingIOError, *ssl_support.BLOCKING_IO_ERRORS)
  386: 
  387: 
  388: def _receive_data_on_socket(conn: Connection, length: int, deadline: Optional[float]) -> memoryview:
  389:     buf = bytearray(length)
  390:     mv = memoryview(buf)
  391:     bytes_read = 0
  392:     while bytes_read < length:
  393:         try:
  394:             wait_for_read(conn, deadline)
  395:             # CSOT: Update timeout. When the timeout has expired perform one
  396:             # final non-blocking recv. This helps avoid spurious timeouts when
  397:             # the response is actually already buffered on the client.
  398:             if _csot.get_timeout() and deadline is not None:
  399:                 conn.set_conn_timeout(max(deadline - time.monotonic(), 0))
  400:             chunk_length = conn.conn.recv_into(mv[bytes_read:])
  401:         except BLOCKING_IO_ERRORS:
  402:             raise socket.timeout("timed out") from None
  403:         except OSError as exc:
  404:             if _errno_from_exception(exc) == errno.EINTR:
  405:                 continue
  406:             raise
  407:         if chunk_length == 0:
  408:             raise OSError("connection closed")
  409: 
  410:         bytes_read += chunk_length
  411: 
  412:     return mv
